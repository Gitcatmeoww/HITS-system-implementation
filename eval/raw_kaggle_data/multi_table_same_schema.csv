Dataset Name,Table Count,Folder Name,File Name,License,Description,File Type,Schema Consistency
2021-2022 NBA Player Stats,2,nba-player-stats,2021-2022 NBA Player Stats - Playoffs.csv,Attribution 4.0 International (CC BY 4.0),"### Context

This dataset contains 2021-2022 regular season NBA player stats per game.
Note that there are duplicate player names resulted from team changes.

* [2022-2023 NBA Player Stats](https://www.kaggle.com/datasets/vivovinco/20222023-nba-player-stats-regular)
* [2023-2024 NBA Player Stats](https://www.kaggle.com/datasets/vivovinco/2023-2024-nba-player-stats/data)


### Content

+500 rows and 30 columns.
Columns' description are listed below.

* Rk : Rank
* Player : Player's name
* Pos : Position
* Age : Player's age
* Tm : Team
* G : Games played
* GS : Games started
* MP : Minutes played per game
* FG : Field goals per game
* FGA : Field goal attempts per game
* FG% : Field goal percentage
* 3P : 3-point field goals per game
* 3PA : 3-point field goal attempts per game
* 3P% : 3-point field goal percentage
* 2P : 2-point field goals per game
* 2PA : 2-point field goal attempts per game
* 2P% : 2-point field goal percentage
* eFG% : Effective field goal percentage
* FT : Free throws per game
* FTA : Free throw attempts per game
* FT% : Free throw percentage
* ORB : Offensive rebounds per game
* DRB : Defensive rebounds per game
* TRB : Total rebounds per game
* AST : Assists per game
* STL : Steals per game
* BLK : Blocks per game
* TOV : Turnovers per game
* PF : Personal fouls per game
* PTS : Points per game


### Acknowledgements

Data from [Basketball Reference](https://www.basketball-reference.com/leagues/NBA_2022_per_game.html).
Image from [NBA](https://www.nba.com/news/nike-nba-city-edition-uniforms-unveiled).

**If you're reading this, please upvote.**",.csv,True
2021-2022 NBA Player Stats,2,nba-player-stats,2021-2022 NBA Player Stats - Regular.csv,Attribution 4.0 International (CC BY 4.0),"### Context

This dataset contains 2021-2022 regular season NBA player stats per game.
Note that there are duplicate player names resulted from team changes.

* [2022-2023 NBA Player Stats](https://www.kaggle.com/datasets/vivovinco/20222023-nba-player-stats-regular)
* [2023-2024 NBA Player Stats](https://www.kaggle.com/datasets/vivovinco/2023-2024-nba-player-stats/data)


### Content

+500 rows and 30 columns.
Columns' description are listed below.

* Rk : Rank
* Player : Player's name
* Pos : Position
* Age : Player's age
* Tm : Team
* G : Games played
* GS : Games started
* MP : Minutes played per game
* FG : Field goals per game
* FGA : Field goal attempts per game
* FG% : Field goal percentage
* 3P : 3-point field goals per game
* 3PA : 3-point field goal attempts per game
* 3P% : 3-point field goal percentage
* 2P : 2-point field goals per game
* 2PA : 2-point field goal attempts per game
* 2P% : 2-point field goal percentage
* eFG% : Effective field goal percentage
* FT : Free throws per game
* FTA : Free throw attempts per game
* FT% : Free throw percentage
* ORB : Offensive rebounds per game
* DRB : Defensive rebounds per game
* TRB : Total rebounds per game
* AST : Assists per game
* STL : Steals per game
* BLK : Blocks per game
* TOV : Turnovers per game
* PF : Personal fouls per game
* PTS : Points per game


### Acknowledgements

Data from [Basketball Reference](https://www.basketball-reference.com/leagues/NBA_2022_per_game.html).
Image from [NBA](https://www.nba.com/news/nike-nba-city-edition-uniforms-unveiled).

**If you're reading this, please upvote.**",.csv,True
2022-2023 NBA Player Stats,2,20222023-nba-player-stats-regular,2022-2023 NBA Player Stats - Playoffs.csv,Attribution 4.0 International (CC BY 4.0),"### Context

This dataset contains 2022-2023 regular season NBA player stats per game.
Note that there are duplicate player names resulted from team changes.

* [2021-2022 NBA Player Stats](https://www.kaggle.com/datasets/vivovinco/nba-player-stats)
* [2023-2024 NBA Player Stats](https://www.kaggle.com/datasets/vivovinco/2023-2024-nba-player-stats/data)


### Content

+500 rows and 30 columns.
Columns' description are listed below.

* Rk : Rank
* Player : Player's name
* Pos : Position
* Age : Player's age
* Tm : Team
* G : Games played
* GS : Games started
* MP : Minutes played per game
* FG : Field goals per game
* FGA : Field goal attempts per game
* FG% : Field goal percentage
* 3P : 3-point field goals per game
* 3PA : 3-point field goal attempts per game
* 3P% : 3-point field goal percentage
* 2P : 2-point field goals per game
* 2PA : 2-point field goal attempts per game
* 2P% : 2-point field goal percentage
* eFG% : Effective field goal percentage
* FT : Free throws per game
* FTA : Free throw attempts per game
* FT% : Free throw percentage
* ORB : Offensive rebounds per game
* DRB : Defensive rebounds per game
* TRB : Total rebounds per game
* AST : Assists per game
* STL : Steals per game
* BLK : Blocks per game
* TOV : Turnovers per game
* PF : Personal fouls per game
* PTS : Points per game


### Acknowledgements

Data from [Basketball Reference](https://www.basketball-reference.com/leagues/NBA_2023_per_game.html).
Image from [Clutch Points](https://clutchpoints.com/2023-nba-playoffs-finals-predictions-will-warriors-repeat-as-champions/).

**If you're reading this, please upvote.**",.csv,True
2022-2023 NBA Player Stats,2,20222023-nba-player-stats-regular,2022-2023 NBA Player Stats - Regular.csv,Attribution 4.0 International (CC BY 4.0),"### Context

This dataset contains 2022-2023 regular season NBA player stats per game.
Note that there are duplicate player names resulted from team changes.

* [2021-2022 NBA Player Stats](https://www.kaggle.com/datasets/vivovinco/nba-player-stats)
* [2023-2024 NBA Player Stats](https://www.kaggle.com/datasets/vivovinco/2023-2024-nba-player-stats/data)


### Content

+500 rows and 30 columns.
Columns' description are listed below.

* Rk : Rank
* Player : Player's name
* Pos : Position
* Age : Player's age
* Tm : Team
* G : Games played
* GS : Games started
* MP : Minutes played per game
* FG : Field goals per game
* FGA : Field goal attempts per game
* FG% : Field goal percentage
* 3P : 3-point field goals per game
* 3PA : 3-point field goal attempts per game
* 3P% : 3-point field goal percentage
* 2P : 2-point field goals per game
* 2PA : 2-point field goal attempts per game
* 2P% : 2-point field goal percentage
* eFG% : Effective field goal percentage
* FT : Free throws per game
* FTA : Free throw attempts per game
* FT% : Free throw percentage
* ORB : Offensive rebounds per game
* DRB : Defensive rebounds per game
* TRB : Total rebounds per game
* AST : Assists per game
* STL : Steals per game
* BLK : Blocks per game
* TOV : Turnovers per game
* PF : Personal fouls per game
* PTS : Points per game


### Acknowledgements

Data from [Basketball Reference](https://www.basketball-reference.com/leagues/NBA_2023_per_game.html).
Image from [Clutch Points](https://clutchpoints.com/2023-nba-playoffs-finals-predictions-will-warriors-repeat-as-champions/).

**If you're reading this, please upvote.**",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,United Arab Emirates_AE.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,South Sudan_SS.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Liechtenstein_LI.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Nauru_NR.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Fiji_FJ.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Guinea Bissau_GW.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Ethiopia_ET.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Croatia_HR.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Slovenia_SI.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Indonesia_ID.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Botswana_BW.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Greece_GR.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Egypt_EG.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,El Salvador_SV.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Montserrat_MS.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,South Africa_ZA.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Trinidad and Tobago_TT.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Kiribati_KI.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Australia_AU.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Brunei_BN.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,North Korea_KP.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Mauritania_MR.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Gabon_GA.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Tuvalu_TV.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Peru_PE.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Switzerland_CH.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,North Macedonia_MK.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Vatican City (Holy See)_VA.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,French Guiana_GF.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Luxembourg_LU.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Niger_NE.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Sri Lanka_LK.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Sierra Leone_SL.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Sint Maarten_SX.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Saint Vincent and the Grenadines_VC.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Iraq_IQ.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Namibia_NA.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Togo_TG.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Saint Pierre and Miquelon_PM.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Jamaica_JM.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Cook Islands_CK.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Rwanda_RW.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Guam_GU.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Canada_CA.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Benin_BJ.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Grenada_GD.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Guinea_GN.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Zambia_ZM.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Pakistan_PK.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Congo_CG.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,India_IN.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Tunisia_TN.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Maldives_MV.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Mongolia_MN.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Morocco_MA.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Lesotho_LS.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Mozambique_MZ.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Central African Republic_CF.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Spain_ES.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Martinique_MQ.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,France_FR.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Colombia_CO.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Burkina Faso_BF.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Curaao_CW.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Guadeloupe_GP.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Panama_PA.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Syria_SY.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Cameroon_CM.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,eSwatini_SZ.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Honduras_HN.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Libya_LY.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Falkland Islands_FK.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Ghana_GH.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Oman_OM.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Cuba_CU.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Latvia_LV.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Somalia_SO.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Nepal_NP.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Monaco_MC.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Norway_NO.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Sao Tome and Principe_ST.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Denmark_DK.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Liberia_LR.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Nigeria_NG.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Aruba_AW.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Guatemala_GT.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Israel_IL.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Cote dIvoire_CI.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Eritrea_ER.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Bulgaria_BG.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Malawi_MW.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Kyrgyzstan_KG.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Reunion_RE.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Gambia_GM.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Mauritius_MU.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,United States_US.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Uruguay_UY.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Seychelles_SC.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Malaysia_MY.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Bahrain_BH.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Equatorial Guinea_GQ.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Uganda_UG.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Slovakia_SK.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Italy_IT.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Bermuda_BM.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Cambodia_KH.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Russia_RE.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Poland_PL.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Turkmenistan_TM.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Mali_ML.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Algeria_DZ.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Montenegro_ME.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Guyana_GY.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Lebanon_LB.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Germany_DE.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Saint Martin_MF.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Yemen_YE.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Moldova_MD.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Czechia_CZ.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,San Marino_SM.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Solomon Islands_SB.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Kuwait_KW.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Ireland_IE.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Dominican Republic_DO.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Micronesia_FM.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Madagascar_MG.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Samoa_WS.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Chad_TD.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Laos_LA.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Congo Democratic Republic_CD.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Dominica_DM.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Kazakhstan_KZ.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Nicaragua_NI.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Saudi Arabia_SA.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Turkey_TR.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Cabo Verde_CV.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Isle of Man_IM.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Mayotte_YT.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Serbia_RS.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Paraguay_PY.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Bhutan_BT.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Cayman Islands_KY.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Venezuela_VE.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,South Korea_KR.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Belgium_BE.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Iceland_IS.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Northern Mariana Islands_MP.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Faroe Islands_FO.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Tonga_TO.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Burundi_BI.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Armenia_AM.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,New Zealand_NZ.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Portugal_PT.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Uzbekistan_UZ.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Papua New Guinea_PG.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,American Samoa_AS.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,US Virgin Islands_VI.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Kenya_KE.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Hungary_HU.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Saint Kitts and Nevis_KN.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Costa Rica_CR.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Argentina_AR.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Jordan_JO.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Netherlands_NL.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Mexico_MX.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,St. Barts_BL.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Bangladesh_BD.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Austria_AT.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Lithuania_LT.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Hong Kong_HK.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Guernsey_GG.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Philippines_PH.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Qatar_QA.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Saint Helena_SH.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Gibraltar_GI.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Tanzania_TZ.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Brazil_BR.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Estonia_EE.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,The Bahamas_BH.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Sweden_SE.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Finland_FI.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Zimbabwe_ZW.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Palau_PW.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Greenland_GL.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Ukraine_UA.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Iran_IR.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Malta_MT.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,China_CN.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Puerto Rico_PR.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Djibouti_DJ.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Wallis and Futuna_WF.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Thailand_TH.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Marshall Islands_MH.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Japan_JP.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Angola_AO.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Tajikistan_TJ.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Barbados_BB.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,New Caledonia_NC.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Ecuador_EC.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,East Timor_TL.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Azerbaijan_AZ.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Senegal_SN.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Chile_CL.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,British Virgin Islands_VG.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Sudan_SD.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,French Polynesia_PF.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Andorra_AD.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Bolivia_BO.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Myanmar_MM.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Belarus_BY.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Albania_AL.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,United Kingdom_GB.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Jersey_JE.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Antigua and Barbuda_AG.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Georgia_GE.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Kosovo_XK.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Vietnam_VN.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Taiwan_TW.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Bosnia and Herzegovina_BA.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Haiti_HT.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Turks and Caicos Islands_TC.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Cyprus_CY.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Singapore_SG.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Anguilla_AI.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Romania_RO.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Vanuatu_VU.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Belize_BZ.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Saint Lucia_LC.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Suriname_SR.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Afghanistan_AF.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Macau_MO.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023 Holidays Dataset,232,world-countries-holidays-dataset-2023,Comoros_KM.csv,CC0-1.0,"The ""World Countries Holidays Dataset (2023)"" is a valuable resource that meticulously compiles information on holidays and observances in **232 Countries**. The dataset includes essential columns like date, name, type, country name, country code, and count, making it a comprehensive reference for understanding holiday occurrences worldwide in 2023. This dataset is includes observances that shape the cultural and social landscape of **232 Countries** throughout the year 2023.

# Key Features

| *Column Names*        | *Meaning and Description* |
| ------------------- | ---------------------------- |
| Date (Code: Date)        | The date when the event or holiday occurs, in the format MM-DD-YYYY. |
| Name (Code: Name)        | The name of the event or holiday. |
| Type (Code: Type)        | The type of event or holiday, categorized as ['National holiday'], providing insights into its significance. |
| Country Name (Code: Country Name)  | The name of the country where the event or holiday is observed. |
| Country Code (Code: Country Code)  | The two-letter country code (ISO 3166-1 alpha-2 standard) corresponding to the country where the event or holiday is celebrated. |

# How to Use This Dataset

1. **Research (Code: Research):** Researchers can explore holiday observances across 232 countries in 2023, facilitating cross-cultural studies and in-depth analysis.
2. **Travel Planning (Code: Travel):** Travelers can plan trips by considering global holiday schedules to immerse in local celebrations and avoid travel disruptions.
3. **Business Strategy (Code: Business):** Data scientists and business professionals can analyze the data for market insights, enhancing marketing strategies and supply chain management.
4. **Education (Code: Education):** Educators can use the dataset to teach students about global cultural diversity and the significance of holidays.
5. **Event Planning (Code: Event):** Event organizers can schedule international events to align with or avoid major holidays, optimizing attendance and logistics.
",.csv,True
2023-2024 NBA Player Stats,2,2023-2024-nba-player-stats,2023-2024 NBA Player Stats - Regular.csv,Attribution 4.0 International (CC BY 4.0),"### Context

This dataset contains 2021-2022 regular season NBA player stats per game.
Note that there are duplicate player names resulted from team changes.

* [2021-2022 NBA Player Stats](https://www.kaggle.com/datasets/vivovinco/nba-player-stats)
* [2022-2023 NBA Player Stats](https://www.kaggle.com/datasets/vivovinco/20222023-nba-player-stats-regular)


### Content

+500 rows and 30 columns.
Columns' description are listed below.

* Rk : Rank
* Player : Player's name
* Pos : Position
* Age : Player's age
* Tm : Team
* G : Games played
* GS : Games started
* MP : Minutes played per game
* FG : Field goals per game
* FGA : Field goal attempts per game
* FG% : Field goal percentage
* 3P : 3-point field goals per game
* 3PA : 3-point field goal attempts per game
* 3P% : 3-point field goal percentage
* 2P : 2-point field goals per game
* 2PA : 2-point field goal attempts per game
* 2P% : 2-point field goal percentage
* eFG% : Effective field goal percentage
* FT : Free throws per game
* FTA : Free throw attempts per game
* FT% : Free throw percentage
* ORB : Offensive rebounds per game
* DRB : Defensive rebounds per game
* TRB : Total rebounds per game
* AST : Assists per game
* STL : Steals per game
* BLK : Blocks per game
* TOV : Turnovers per game
* PF : Personal fouls per game
* PTS : Points per game


### Acknowledgements

Data from [Basketball Reference](https://www.basketball-reference.com/leagues/NBA_2024_per_game.html).
Image from [NBA](https://thejk.medium.com/i-will-predict-the-2023-nba-champion-using-machine-learning-5e8df072059d).

**If you're reading this, please upvote.**",.csv,True
2023-2024 NBA Player Stats,2,2023-2024-nba-player-stats,2023-2024 NBA Player Stats - Playoffs.csv,Attribution 4.0 International (CC BY 4.0),"### Context

This dataset contains 2021-2022 regular season NBA player stats per game.
Note that there are duplicate player names resulted from team changes.

* [2021-2022 NBA Player Stats](https://www.kaggle.com/datasets/vivovinco/nba-player-stats)
* [2022-2023 NBA Player Stats](https://www.kaggle.com/datasets/vivovinco/20222023-nba-player-stats-regular)


### Content

+500 rows and 30 columns.
Columns' description are listed below.

* Rk : Rank
* Player : Player's name
* Pos : Position
* Age : Player's age
* Tm : Team
* G : Games played
* GS : Games started
* MP : Minutes played per game
* FG : Field goals per game
* FGA : Field goal attempts per game
* FG% : Field goal percentage
* 3P : 3-point field goals per game
* 3PA : 3-point field goal attempts per game
* 3P% : 3-point field goal percentage
* 2P : 2-point field goals per game
* 2PA : 2-point field goal attempts per game
* 2P% : 2-point field goal percentage
* eFG% : Effective field goal percentage
* FT : Free throws per game
* FTA : Free throw attempts per game
* FT% : Free throw percentage
* ORB : Offensive rebounds per game
* DRB : Defensive rebounds per game
* TRB : Total rebounds per game
* AST : Assists per game
* STL : Steals per game
* BLK : Blocks per game
* TOV : Turnovers per game
* PF : Personal fouls per game
* PTS : Points per game


### Acknowledgements

Data from [Basketball Reference](https://www.basketball-reference.com/leagues/NBA_2024_per_game.html).
Image from [NBA](https://thejk.medium.com/i-will-predict-the-2023-nba-champion-using-machine-learning-5e8df072059d).

**If you're reading this, please upvote.**",.csv,True
A/B Testing DataSet,2,ab-testing-dataset,test_group.csv,other,"A/B testing helps in finding a better approach to finding customers, marketing products, getting a higher reach, or anything that helps a business convert most of its target customers into actual customers.

Below are all the features in the dataset:

- Campaign Name: The name of the campaign
- Date: Date of the record
- Spend: Amount spent on the campaign in dollars
- of Impressions: Number of impressions the ad crossed through the campaign
- Reach: The number of unique impressions received in the ad
- of Website Clicks: Number of website clicks received through the ads
- of Searches: Number of users who performed searches on the website 
- of View Content: Number of users who viewed content and products on the website
- of Add to Cart: Number of users who added products to the cart
- of Purchase: Number of purchases

Two campaigns were performed by the company:

- Control Campaign
- Test Campaign",.csv,True
A/B Testing DataSet,2,ab-testing-dataset,control_group.csv,other,"A/B testing helps in finding a better approach to finding customers, marketing products, getting a higher reach, or anything that helps a business convert most of its target customers into actual customers.

Below are all the features in the dataset:

- Campaign Name: The name of the campaign
- Date: Date of the record
- Spend: Amount spent on the campaign in dollars
- of Impressions: Number of impressions the ad crossed through the campaign
- Reach: The number of unique impressions received in the ad
- of Website Clicks: Number of website clicks received through the ads
- of Searches: Number of users who performed searches on the website 
- of View Content: Number of users who viewed content and products on the website
- of Add to Cart: Number of users who added products to the cart
- of Purchase: Number of purchases

Two campaigns were performed by the company:

- Control Campaign
- Test Campaign",.csv,True
AIDS Virus Infection Prediction 💉,4,aids-virus-infection-prediction,AIDS_Classification.csv,CC0-1.0,"## **Context :**

Dataset contains healthcare statistics and categorical information about patients who have been diagnosed with AIDS. This dataset was initially published in 1996. 

## **Attribute Information :**

- time: time to failure or censoring
- trt: treatment indicator (0 = ZDV only; 1 = ZDV + ddI, 2 = ZDV + Zal, 3 = ddI only)
- age: age (yrs) at baseline
- wtkg: weight (kg) at baseline
- hemo: hemophilia (0=no, 1=yes)
- homo: homosexual activity (0=no, 1=yes)
- drugs: history of IV drug use (0=no, 1=yes)
- karnof: Karnofsky score (on a scale of 0-100)
- oprior: Non-ZDV antiretroviral therapy pre-175 (0=no, 1=yes)
- z30: ZDV in the 30 days prior to 175 (0=no, 1=yes)
- preanti: days pre-175 anti-retroviral therapy
- race: race (0=White, 1=non-white)
- gender: gender (0=F, 1=M)
- str2: antiretroviral history (0=naive, 1=experienced)
- strat: antiretroviral history stratification (1='Antiretroviral Naive',2='&gt; 1 but &lt;= 52 weeks of prior antiretroviral therapy',3='&gt; 52 weeks)
- symptom: symptomatic indicator (0=asymp, 1=symp)
- treat: treatment indicator (0=ZDV only, 1=others)
- offtrt: indicator of off-trt before 96+/-5 weeks (0=no,1=yes)
- cd40: CD4 at baseline
- cd420: CD4 at 20+/-5 weeks
- cd80: CD8 at baseline
- cd820: CD8 at 20+/-5 weeks
- infected: is infected with AIDS (0=No, 1=Yes)

## **Additional Variable Information :**
   - Personal information (age, weight, race, gender, sexual activity)
   - Medical history (hemophilia, history of IV drugs)
   - Treatment history (ZDV/non-ZDV treatment history)
   - Lab results (CD4/CD8 counts)

## **Citation :**

[https://classic.clinicaltrials.gov/ct2/show/NCT00000625](url)

## **Acknowledgment :**

### **Creators :**

1. S. Hammer
2. D. Katzenstein
3. M. Hughes
4. H. Gundacker
5. R. Schooley
6. R. Haubrich
7. W. K.
8. M. Lederman
9. J. Phair
10. M. Niu
11. M. Hirsch
12. T. Merigan

## **Donor :**

https://archive.ics.uci.edu/dataset/890/aids+clinical+trials+group+study+175",.csv,True
AIDS Virus Infection Prediction 💉,4,aids-virus-infection-prediction,AIDS_Classification_50000.csv,CC0-1.0,"## **Context :**

Dataset contains healthcare statistics and categorical information about patients who have been diagnosed with AIDS. This dataset was initially published in 1996. 

## **Attribute Information :**

- time: time to failure or censoring
- trt: treatment indicator (0 = ZDV only; 1 = ZDV + ddI, 2 = ZDV + Zal, 3 = ddI only)
- age: age (yrs) at baseline
- wtkg: weight (kg) at baseline
- hemo: hemophilia (0=no, 1=yes)
- homo: homosexual activity (0=no, 1=yes)
- drugs: history of IV drug use (0=no, 1=yes)
- karnof: Karnofsky score (on a scale of 0-100)
- oprior: Non-ZDV antiretroviral therapy pre-175 (0=no, 1=yes)
- z30: ZDV in the 30 days prior to 175 (0=no, 1=yes)
- preanti: days pre-175 anti-retroviral therapy
- race: race (0=White, 1=non-white)
- gender: gender (0=F, 1=M)
- str2: antiretroviral history (0=naive, 1=experienced)
- strat: antiretroviral history stratification (1='Antiretroviral Naive',2='&gt; 1 but &lt;= 52 weeks of prior antiretroviral therapy',3='&gt; 52 weeks)
- symptom: symptomatic indicator (0=asymp, 1=symp)
- treat: treatment indicator (0=ZDV only, 1=others)
- offtrt: indicator of off-trt before 96+/-5 weeks (0=no,1=yes)
- cd40: CD4 at baseline
- cd420: CD4 at 20+/-5 weeks
- cd80: CD8 at baseline
- cd820: CD8 at 20+/-5 weeks
- infected: is infected with AIDS (0=No, 1=Yes)

## **Additional Variable Information :**
   - Personal information (age, weight, race, gender, sexual activity)
   - Medical history (hemophilia, history of IV drugs)
   - Treatment history (ZDV/non-ZDV treatment history)
   - Lab results (CD4/CD8 counts)

## **Citation :**

[https://classic.clinicaltrials.gov/ct2/show/NCT00000625](url)

## **Acknowledgment :**

### **Creators :**

1. S. Hammer
2. D. Katzenstein
3. M. Hughes
4. H. Gundacker
5. R. Schooley
6. R. Haubrich
7. W. K.
8. M. Lederman
9. J. Phair
10. M. Niu
11. M. Hirsch
12. T. Merigan

## **Donor :**

https://archive.ics.uci.edu/dataset/890/aids+clinical+trials+group+study+175",.csv,True
AIDS Virus Infection Prediction 💉,4,aids-virus-infection-prediction,AIDS_Classification_5000.csv,CC0-1.0,"## **Context :**

Dataset contains healthcare statistics and categorical information about patients who have been diagnosed with AIDS. This dataset was initially published in 1996. 

## **Attribute Information :**

- time: time to failure or censoring
- trt: treatment indicator (0 = ZDV only; 1 = ZDV + ddI, 2 = ZDV + Zal, 3 = ddI only)
- age: age (yrs) at baseline
- wtkg: weight (kg) at baseline
- hemo: hemophilia (0=no, 1=yes)
- homo: homosexual activity (0=no, 1=yes)
- drugs: history of IV drug use (0=no, 1=yes)
- karnof: Karnofsky score (on a scale of 0-100)
- oprior: Non-ZDV antiretroviral therapy pre-175 (0=no, 1=yes)
- z30: ZDV in the 30 days prior to 175 (0=no, 1=yes)
- preanti: days pre-175 anti-retroviral therapy
- race: race (0=White, 1=non-white)
- gender: gender (0=F, 1=M)
- str2: antiretroviral history (0=naive, 1=experienced)
- strat: antiretroviral history stratification (1='Antiretroviral Naive',2='&gt; 1 but &lt;= 52 weeks of prior antiretroviral therapy',3='&gt; 52 weeks)
- symptom: symptomatic indicator (0=asymp, 1=symp)
- treat: treatment indicator (0=ZDV only, 1=others)
- offtrt: indicator of off-trt before 96+/-5 weeks (0=no,1=yes)
- cd40: CD4 at baseline
- cd420: CD4 at 20+/-5 weeks
- cd80: CD8 at baseline
- cd820: CD8 at 20+/-5 weeks
- infected: is infected with AIDS (0=No, 1=Yes)

## **Additional Variable Information :**
   - Personal information (age, weight, race, gender, sexual activity)
   - Medical history (hemophilia, history of IV drugs)
   - Treatment history (ZDV/non-ZDV treatment history)
   - Lab results (CD4/CD8 counts)

## **Citation :**

[https://classic.clinicaltrials.gov/ct2/show/NCT00000625](url)

## **Acknowledgment :**

### **Creators :**

1. S. Hammer
2. D. Katzenstein
3. M. Hughes
4. H. Gundacker
5. R. Schooley
6. R. Haubrich
7. W. K.
8. M. Lederman
9. J. Phair
10. M. Niu
11. M. Hirsch
12. T. Merigan

## **Donor :**

https://archive.ics.uci.edu/dataset/890/aids+clinical+trials+group+study+175",.csv,True
AIDS Virus Infection Prediction 💉,4,aids-virus-infection-prediction,AIDS_Classification_15000.csv,CC0-1.0,"## **Context :**

Dataset contains healthcare statistics and categorical information about patients who have been diagnosed with AIDS. This dataset was initially published in 1996. 

## **Attribute Information :**

- time: time to failure or censoring
- trt: treatment indicator (0 = ZDV only; 1 = ZDV + ddI, 2 = ZDV + Zal, 3 = ddI only)
- age: age (yrs) at baseline
- wtkg: weight (kg) at baseline
- hemo: hemophilia (0=no, 1=yes)
- homo: homosexual activity (0=no, 1=yes)
- drugs: history of IV drug use (0=no, 1=yes)
- karnof: Karnofsky score (on a scale of 0-100)
- oprior: Non-ZDV antiretroviral therapy pre-175 (0=no, 1=yes)
- z30: ZDV in the 30 days prior to 175 (0=no, 1=yes)
- preanti: days pre-175 anti-retroviral therapy
- race: race (0=White, 1=non-white)
- gender: gender (0=F, 1=M)
- str2: antiretroviral history (0=naive, 1=experienced)
- strat: antiretroviral history stratification (1='Antiretroviral Naive',2='&gt; 1 but &lt;= 52 weeks of prior antiretroviral therapy',3='&gt; 52 weeks)
- symptom: symptomatic indicator (0=asymp, 1=symp)
- treat: treatment indicator (0=ZDV only, 1=others)
- offtrt: indicator of off-trt before 96+/-5 weeks (0=no,1=yes)
- cd40: CD4 at baseline
- cd420: CD4 at 20+/-5 weeks
- cd80: CD8 at baseline
- cd820: CD8 at 20+/-5 weeks
- infected: is infected with AIDS (0=No, 1=Yes)

## **Additional Variable Information :**
   - Personal information (age, weight, race, gender, sexual activity)
   - Medical history (hemophilia, history of IV drugs)
   - Treatment history (ZDV/non-ZDV treatment history)
   - Lab results (CD4/CD8 counts)

## **Citation :**

[https://classic.clinicaltrials.gov/ct2/show/NCT00000625](url)

## **Acknowledgment :**

### **Creators :**

1. S. Hammer
2. D. Katzenstein
3. M. Hughes
4. H. Gundacker
5. R. Schooley
6. R. Haubrich
7. W. K.
8. M. Lederman
9. J. Phair
10. M. Niu
11. M. Hirsch
12. T. Merigan

## **Donor :**

https://archive.ics.uci.edu/dataset/890/aids+clinical+trials+group+study+175",.csv,True
"Adult income(train, test) dataset",2,adult-incometrain-test-dataset,adult_train.csv,other,"# **Additional Information**
Extraction was done by Barry Becker from the 1994 Census database.  A set of reasonably clean records was extracted using the following conditions: ((AAGE&gt;16) && (AGI&gt;100) && (AFNLWGT&gt;1)&& (HRSWK&gt;0))

 This data was extracted from the census bureau database found at
 http://www.census.gov/ftp/pub/DES/www/welcome.html
 Donor: Ronny Kohavi and Barry Becker,
        Data Mining and Visualization
        Silicon Graphics.
        e-mail: ronnyk@sgi.com for questions.
 Split into train-test using MLC++ GenCVFiles (2/3, 1/3 random).
 48842 instances, mix of continuous and discrete    (train=32561, test=16281)
 45222 if instances with unknown values are removed (train=30162, test=15060)
 Duplicate or conflicting instances : 6
 Class probabilities for adult.all file
 Probability for the label '&gt;50K'  : 23.93% / 24.78% (without unknowns)
 Probability for the label '&lt;=50K' : 76.07% / 75.22% (without unknowns)

 Extraction was done by Barry Becker from the 1994 Census database.  A set of
   reasonably clean records was extracted using the following conditions:
   ((AAGE&gt;16) && (AGI&gt;100) && (AFNLWGT&gt;1)&& (HRSWK&gt;0))",.csv,True
"Adult income(train, test) dataset",2,adult-incometrain-test-dataset,adult_test.csv,other,"# **Additional Information**
Extraction was done by Barry Becker from the 1994 Census database.  A set of reasonably clean records was extracted using the following conditions: ((AAGE&gt;16) && (AGI&gt;100) && (AFNLWGT&gt;1)&& (HRSWK&gt;0))

 This data was extracted from the census bureau database found at
 http://www.census.gov/ftp/pub/DES/www/welcome.html
 Donor: Ronny Kohavi and Barry Becker,
        Data Mining and Visualization
        Silicon Graphics.
        e-mail: ronnyk@sgi.com for questions.
 Split into train-test using MLC++ GenCVFiles (2/3, 1/3 random).
 48842 instances, mix of continuous and discrete    (train=32561, test=16281)
 45222 if instances with unknown values are removed (train=30162, test=15060)
 Duplicate or conflicting instances : 6
 Class probabilities for adult.all file
 Probability for the label '&gt;50K'  : 23.93% / 24.78% (without unknowns)
 Probability for the label '&lt;=50K' : 76.07% / 75.22% (without unknowns)

 Extraction was done by Barry Becker from the 1994 Census database.  A set of
   reasonably clean records was extracted using the following conditions:
   ((AAGE&gt;16) && (AGI&gt;100) && (AFNLWGT&gt;1)&& (HRSWK&gt;0))",.csv,True
Airbnb Prices in European Cities,20,airbnb-prices-in-european-cities,amsterdam_weekdays.csv,CC0-1.0,"_____
# Airbnb Prices in European Cities
### Determinants of Price by Room Type, Location, Cleanliness Rating, and More
By  [[source]](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
_____

### About this dataset
&gt; This dataset provides a comprehensive look at Airbnb prices in some of the most popular European cities. Each listing is evaluated for various attributes such as room types, cleanliness and satisfaction ratings, bedrooms, distance from the city centre, and more to capture an in-depth understanding of Airbnb prices on both weekdays and weekends. Using spatial econometric methods, we analyse and identify the determinants of Airbnb prices across these cities. Our dataset includes information such as realSum (the total price of the listing), room_type (private/shared/entire home/apt), host_is_superhost (boolean value indicating if host is a superhost or not), multi (indicator whether listing is for multiple rooms or not), biz (business indicator) , guest_satisfaction_overall (overall rating from guests camparing all listings offered by host ), bedrooms, dist (distance from city center) , lng & lat coordinates for location identification etc. We hope that this data set offers insight into how global markets are affected by social dynamics and geographical factors which in turn determine pricing strategies for optimal profitability!

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; This dataset can be used by individuals and companies to gain insight on the cost of Airbnb listings in some of the most popular European cities. It contains information on a variety of attributes such as room type, cleanliness rating, guest satisfaction, distance from the city centre, and more. In addition to exploring general trends in prices across Europe, this dataset can be used for deeper spatial econometric analysis. 
&gt; 
&gt; To begin using this dataset for your own research or analysis project: 
&gt; - Download the files which contain both weekday and weekend listings data for European cities. 
&gt; - Familiarize yourself with the columns included in each file; these provide descriptions of various attributes associated with each listing.  
&gt; - Calculate any desired summary statistics - average price per night per city or room type etc. - using statistical software (e.g Excel).  
&gt; - Perform spatial econometric analysis if desired; use specialized packages such as `spdep` or `spatialreg` in R to identify determinants of Airbnb price levels across Europe (e.g., metro distance). 
&gt; - Visualize your results with GIS software if necessary to more easily understand patterns between variables like proximity/location and price level (e.g., QGIS).   
&gt; 
&gt; By leveraging both descriptive and inferential methods while taking advantage of geographic information systems (GIS), users can apply this dataset to many interesting questions related to rental prices on Airbnb in Europe!

### Research Ideas
&gt; - Analyzing spatial trends in Airbnb prices across Europe and finding the most favorable cities for hosting.
&gt; - Comparing differences between weekday vs weekend booking patterns to project rental rates for vacationers and business travelers in European cities. 
&gt; - Using spatial econometrics methods to find important determinants of Airbnb prices in order to provide insights into areas of opportunity for improvement, or assess the effectiveness of existing policy changes concerning vacation rentals

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
&gt; 
&gt;


### License
&gt; 
&gt; 
&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: vienna_weekdays.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

_____

**File: vienna_weekends.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE).

",.csv,True
Airbnb Prices in European Cities,20,airbnb-prices-in-european-cities,barcelona_weekends.csv,CC0-1.0,"_____
# Airbnb Prices in European Cities
### Determinants of Price by Room Type, Location, Cleanliness Rating, and More
By  [[source]](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
_____

### About this dataset
&gt; This dataset provides a comprehensive look at Airbnb prices in some of the most popular European cities. Each listing is evaluated for various attributes such as room types, cleanliness and satisfaction ratings, bedrooms, distance from the city centre, and more to capture an in-depth understanding of Airbnb prices on both weekdays and weekends. Using spatial econometric methods, we analyse and identify the determinants of Airbnb prices across these cities. Our dataset includes information such as realSum (the total price of the listing), room_type (private/shared/entire home/apt), host_is_superhost (boolean value indicating if host is a superhost or not), multi (indicator whether listing is for multiple rooms or not), biz (business indicator) , guest_satisfaction_overall (overall rating from guests camparing all listings offered by host ), bedrooms, dist (distance from city center) , lng & lat coordinates for location identification etc. We hope that this data set offers insight into how global markets are affected by social dynamics and geographical factors which in turn determine pricing strategies for optimal profitability!

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; This dataset can be used by individuals and companies to gain insight on the cost of Airbnb listings in some of the most popular European cities. It contains information on a variety of attributes such as room type, cleanliness rating, guest satisfaction, distance from the city centre, and more. In addition to exploring general trends in prices across Europe, this dataset can be used for deeper spatial econometric analysis. 
&gt; 
&gt; To begin using this dataset for your own research or analysis project: 
&gt; - Download the files which contain both weekday and weekend listings data for European cities. 
&gt; - Familiarize yourself with the columns included in each file; these provide descriptions of various attributes associated with each listing.  
&gt; - Calculate any desired summary statistics - average price per night per city or room type etc. - using statistical software (e.g Excel).  
&gt; - Perform spatial econometric analysis if desired; use specialized packages such as `spdep` or `spatialreg` in R to identify determinants of Airbnb price levels across Europe (e.g., metro distance). 
&gt; - Visualize your results with GIS software if necessary to more easily understand patterns between variables like proximity/location and price level (e.g., QGIS).   
&gt; 
&gt; By leveraging both descriptive and inferential methods while taking advantage of geographic information systems (GIS), users can apply this dataset to many interesting questions related to rental prices on Airbnb in Europe!

### Research Ideas
&gt; - Analyzing spatial trends in Airbnb prices across Europe and finding the most favorable cities for hosting.
&gt; - Comparing differences between weekday vs weekend booking patterns to project rental rates for vacationers and business travelers in European cities. 
&gt; - Using spatial econometrics methods to find important determinants of Airbnb prices in order to provide insights into areas of opportunity for improvement, or assess the effectiveness of existing policy changes concerning vacation rentals

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
&gt; 
&gt;


### License
&gt; 
&gt; 
&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: vienna_weekdays.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

_____

**File: vienna_weekends.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE).

",.csv,True
Airbnb Prices in European Cities,20,airbnb-prices-in-european-cities,rome_weekdays.csv,CC0-1.0,"_____
# Airbnb Prices in European Cities
### Determinants of Price by Room Type, Location, Cleanliness Rating, and More
By  [[source]](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
_____

### About this dataset
&gt; This dataset provides a comprehensive look at Airbnb prices in some of the most popular European cities. Each listing is evaluated for various attributes such as room types, cleanliness and satisfaction ratings, bedrooms, distance from the city centre, and more to capture an in-depth understanding of Airbnb prices on both weekdays and weekends. Using spatial econometric methods, we analyse and identify the determinants of Airbnb prices across these cities. Our dataset includes information such as realSum (the total price of the listing), room_type (private/shared/entire home/apt), host_is_superhost (boolean value indicating if host is a superhost or not), multi (indicator whether listing is for multiple rooms or not), biz (business indicator) , guest_satisfaction_overall (overall rating from guests camparing all listings offered by host ), bedrooms, dist (distance from city center) , lng & lat coordinates for location identification etc. We hope that this data set offers insight into how global markets are affected by social dynamics and geographical factors which in turn determine pricing strategies for optimal profitability!

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; This dataset can be used by individuals and companies to gain insight on the cost of Airbnb listings in some of the most popular European cities. It contains information on a variety of attributes such as room type, cleanliness rating, guest satisfaction, distance from the city centre, and more. In addition to exploring general trends in prices across Europe, this dataset can be used for deeper spatial econometric analysis. 
&gt; 
&gt; To begin using this dataset for your own research or analysis project: 
&gt; - Download the files which contain both weekday and weekend listings data for European cities. 
&gt; - Familiarize yourself with the columns included in each file; these provide descriptions of various attributes associated with each listing.  
&gt; - Calculate any desired summary statistics - average price per night per city or room type etc. - using statistical software (e.g Excel).  
&gt; - Perform spatial econometric analysis if desired; use specialized packages such as `spdep` or `spatialreg` in R to identify determinants of Airbnb price levels across Europe (e.g., metro distance). 
&gt; - Visualize your results with GIS software if necessary to more easily understand patterns between variables like proximity/location and price level (e.g., QGIS).   
&gt; 
&gt; By leveraging both descriptive and inferential methods while taking advantage of geographic information systems (GIS), users can apply this dataset to many interesting questions related to rental prices on Airbnb in Europe!

### Research Ideas
&gt; - Analyzing spatial trends in Airbnb prices across Europe and finding the most favorable cities for hosting.
&gt; - Comparing differences between weekday vs weekend booking patterns to project rental rates for vacationers and business travelers in European cities. 
&gt; - Using spatial econometrics methods to find important determinants of Airbnb prices in order to provide insights into areas of opportunity for improvement, or assess the effectiveness of existing policy changes concerning vacation rentals

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
&gt; 
&gt;


### License
&gt; 
&gt; 
&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: vienna_weekdays.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

_____

**File: vienna_weekends.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE).

",.csv,True
Airbnb Prices in European Cities,20,airbnb-prices-in-european-cities,berlin_weekdays.csv,CC0-1.0,"_____
# Airbnb Prices in European Cities
### Determinants of Price by Room Type, Location, Cleanliness Rating, and More
By  [[source]](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
_____

### About this dataset
&gt; This dataset provides a comprehensive look at Airbnb prices in some of the most popular European cities. Each listing is evaluated for various attributes such as room types, cleanliness and satisfaction ratings, bedrooms, distance from the city centre, and more to capture an in-depth understanding of Airbnb prices on both weekdays and weekends. Using spatial econometric methods, we analyse and identify the determinants of Airbnb prices across these cities. Our dataset includes information such as realSum (the total price of the listing), room_type (private/shared/entire home/apt), host_is_superhost (boolean value indicating if host is a superhost or not), multi (indicator whether listing is for multiple rooms or not), biz (business indicator) , guest_satisfaction_overall (overall rating from guests camparing all listings offered by host ), bedrooms, dist (distance from city center) , lng & lat coordinates for location identification etc. We hope that this data set offers insight into how global markets are affected by social dynamics and geographical factors which in turn determine pricing strategies for optimal profitability!

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; This dataset can be used by individuals and companies to gain insight on the cost of Airbnb listings in some of the most popular European cities. It contains information on a variety of attributes such as room type, cleanliness rating, guest satisfaction, distance from the city centre, and more. In addition to exploring general trends in prices across Europe, this dataset can be used for deeper spatial econometric analysis. 
&gt; 
&gt; To begin using this dataset for your own research or analysis project: 
&gt; - Download the files which contain both weekday and weekend listings data for European cities. 
&gt; - Familiarize yourself with the columns included in each file; these provide descriptions of various attributes associated with each listing.  
&gt; - Calculate any desired summary statistics - average price per night per city or room type etc. - using statistical software (e.g Excel).  
&gt; - Perform spatial econometric analysis if desired; use specialized packages such as `spdep` or `spatialreg` in R to identify determinants of Airbnb price levels across Europe (e.g., metro distance). 
&gt; - Visualize your results with GIS software if necessary to more easily understand patterns between variables like proximity/location and price level (e.g., QGIS).   
&gt; 
&gt; By leveraging both descriptive and inferential methods while taking advantage of geographic information systems (GIS), users can apply this dataset to many interesting questions related to rental prices on Airbnb in Europe!

### Research Ideas
&gt; - Analyzing spatial trends in Airbnb prices across Europe and finding the most favorable cities for hosting.
&gt; - Comparing differences between weekday vs weekend booking patterns to project rental rates for vacationers and business travelers in European cities. 
&gt; - Using spatial econometrics methods to find important determinants of Airbnb prices in order to provide insights into areas of opportunity for improvement, or assess the effectiveness of existing policy changes concerning vacation rentals

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
&gt; 
&gt;


### License
&gt; 
&gt; 
&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: vienna_weekdays.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

_____

**File: vienna_weekends.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE).

",.csv,True
Airbnb Prices in European Cities,20,airbnb-prices-in-european-cities,budapest_weekdays.csv,CC0-1.0,"_____
# Airbnb Prices in European Cities
### Determinants of Price by Room Type, Location, Cleanliness Rating, and More
By  [[source]](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
_____

### About this dataset
&gt; This dataset provides a comprehensive look at Airbnb prices in some of the most popular European cities. Each listing is evaluated for various attributes such as room types, cleanliness and satisfaction ratings, bedrooms, distance from the city centre, and more to capture an in-depth understanding of Airbnb prices on both weekdays and weekends. Using spatial econometric methods, we analyse and identify the determinants of Airbnb prices across these cities. Our dataset includes information such as realSum (the total price of the listing), room_type (private/shared/entire home/apt), host_is_superhost (boolean value indicating if host is a superhost or not), multi (indicator whether listing is for multiple rooms or not), biz (business indicator) , guest_satisfaction_overall (overall rating from guests camparing all listings offered by host ), bedrooms, dist (distance from city center) , lng & lat coordinates for location identification etc. We hope that this data set offers insight into how global markets are affected by social dynamics and geographical factors which in turn determine pricing strategies for optimal profitability!

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; This dataset can be used by individuals and companies to gain insight on the cost of Airbnb listings in some of the most popular European cities. It contains information on a variety of attributes such as room type, cleanliness rating, guest satisfaction, distance from the city centre, and more. In addition to exploring general trends in prices across Europe, this dataset can be used for deeper spatial econometric analysis. 
&gt; 
&gt; To begin using this dataset for your own research or analysis project: 
&gt; - Download the files which contain both weekday and weekend listings data for European cities. 
&gt; - Familiarize yourself with the columns included in each file; these provide descriptions of various attributes associated with each listing.  
&gt; - Calculate any desired summary statistics - average price per night per city or room type etc. - using statistical software (e.g Excel).  
&gt; - Perform spatial econometric analysis if desired; use specialized packages such as `spdep` or `spatialreg` in R to identify determinants of Airbnb price levels across Europe (e.g., metro distance). 
&gt; - Visualize your results with GIS software if necessary to more easily understand patterns between variables like proximity/location and price level (e.g., QGIS).   
&gt; 
&gt; By leveraging both descriptive and inferential methods while taking advantage of geographic information systems (GIS), users can apply this dataset to many interesting questions related to rental prices on Airbnb in Europe!

### Research Ideas
&gt; - Analyzing spatial trends in Airbnb prices across Europe and finding the most favorable cities for hosting.
&gt; - Comparing differences between weekday vs weekend booking patterns to project rental rates for vacationers and business travelers in European cities. 
&gt; - Using spatial econometrics methods to find important determinants of Airbnb prices in order to provide insights into areas of opportunity for improvement, or assess the effectiveness of existing policy changes concerning vacation rentals

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
&gt; 
&gt;


### License
&gt; 
&gt; 
&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: vienna_weekdays.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

_____

**File: vienna_weekends.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE).

",.csv,True
Airbnb Prices in European Cities,20,airbnb-prices-in-european-cities,vienna_weekdays.csv,CC0-1.0,"_____
# Airbnb Prices in European Cities
### Determinants of Price by Room Type, Location, Cleanliness Rating, and More
By  [[source]](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
_____

### About this dataset
&gt; This dataset provides a comprehensive look at Airbnb prices in some of the most popular European cities. Each listing is evaluated for various attributes such as room types, cleanliness and satisfaction ratings, bedrooms, distance from the city centre, and more to capture an in-depth understanding of Airbnb prices on both weekdays and weekends. Using spatial econometric methods, we analyse and identify the determinants of Airbnb prices across these cities. Our dataset includes information such as realSum (the total price of the listing), room_type (private/shared/entire home/apt), host_is_superhost (boolean value indicating if host is a superhost or not), multi (indicator whether listing is for multiple rooms or not), biz (business indicator) , guest_satisfaction_overall (overall rating from guests camparing all listings offered by host ), bedrooms, dist (distance from city center) , lng & lat coordinates for location identification etc. We hope that this data set offers insight into how global markets are affected by social dynamics and geographical factors which in turn determine pricing strategies for optimal profitability!

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; This dataset can be used by individuals and companies to gain insight on the cost of Airbnb listings in some of the most popular European cities. It contains information on a variety of attributes such as room type, cleanliness rating, guest satisfaction, distance from the city centre, and more. In addition to exploring general trends in prices across Europe, this dataset can be used for deeper spatial econometric analysis. 
&gt; 
&gt; To begin using this dataset for your own research or analysis project: 
&gt; - Download the files which contain both weekday and weekend listings data for European cities. 
&gt; - Familiarize yourself with the columns included in each file; these provide descriptions of various attributes associated with each listing.  
&gt; - Calculate any desired summary statistics - average price per night per city or room type etc. - using statistical software (e.g Excel).  
&gt; - Perform spatial econometric analysis if desired; use specialized packages such as `spdep` or `spatialreg` in R to identify determinants of Airbnb price levels across Europe (e.g., metro distance). 
&gt; - Visualize your results with GIS software if necessary to more easily understand patterns between variables like proximity/location and price level (e.g., QGIS).   
&gt; 
&gt; By leveraging both descriptive and inferential methods while taking advantage of geographic information systems (GIS), users can apply this dataset to many interesting questions related to rental prices on Airbnb in Europe!

### Research Ideas
&gt; - Analyzing spatial trends in Airbnb prices across Europe and finding the most favorable cities for hosting.
&gt; - Comparing differences between weekday vs weekend booking patterns to project rental rates for vacationers and business travelers in European cities. 
&gt; - Using spatial econometrics methods to find important determinants of Airbnb prices in order to provide insights into areas of opportunity for improvement, or assess the effectiveness of existing policy changes concerning vacation rentals

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
&gt; 
&gt;


### License
&gt; 
&gt; 
&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: vienna_weekdays.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

_____

**File: vienna_weekends.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE).

",.csv,True
Airbnb Prices in European Cities,20,airbnb-prices-in-european-cities,london_weekdays.csv,CC0-1.0,"_____
# Airbnb Prices in European Cities
### Determinants of Price by Room Type, Location, Cleanliness Rating, and More
By  [[source]](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
_____

### About this dataset
&gt; This dataset provides a comprehensive look at Airbnb prices in some of the most popular European cities. Each listing is evaluated for various attributes such as room types, cleanliness and satisfaction ratings, bedrooms, distance from the city centre, and more to capture an in-depth understanding of Airbnb prices on both weekdays and weekends. Using spatial econometric methods, we analyse and identify the determinants of Airbnb prices across these cities. Our dataset includes information such as realSum (the total price of the listing), room_type (private/shared/entire home/apt), host_is_superhost (boolean value indicating if host is a superhost or not), multi (indicator whether listing is for multiple rooms or not), biz (business indicator) , guest_satisfaction_overall (overall rating from guests camparing all listings offered by host ), bedrooms, dist (distance from city center) , lng & lat coordinates for location identification etc. We hope that this data set offers insight into how global markets are affected by social dynamics and geographical factors which in turn determine pricing strategies for optimal profitability!

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; This dataset can be used by individuals and companies to gain insight on the cost of Airbnb listings in some of the most popular European cities. It contains information on a variety of attributes such as room type, cleanliness rating, guest satisfaction, distance from the city centre, and more. In addition to exploring general trends in prices across Europe, this dataset can be used for deeper spatial econometric analysis. 
&gt; 
&gt; To begin using this dataset for your own research or analysis project: 
&gt; - Download the files which contain both weekday and weekend listings data for European cities. 
&gt; - Familiarize yourself with the columns included in each file; these provide descriptions of various attributes associated with each listing.  
&gt; - Calculate any desired summary statistics - average price per night per city or room type etc. - using statistical software (e.g Excel).  
&gt; - Perform spatial econometric analysis if desired; use specialized packages such as `spdep` or `spatialreg` in R to identify determinants of Airbnb price levels across Europe (e.g., metro distance). 
&gt; - Visualize your results with GIS software if necessary to more easily understand patterns between variables like proximity/location and price level (e.g., QGIS).   
&gt; 
&gt; By leveraging both descriptive and inferential methods while taking advantage of geographic information systems (GIS), users can apply this dataset to many interesting questions related to rental prices on Airbnb in Europe!

### Research Ideas
&gt; - Analyzing spatial trends in Airbnb prices across Europe and finding the most favorable cities for hosting.
&gt; - Comparing differences between weekday vs weekend booking patterns to project rental rates for vacationers and business travelers in European cities. 
&gt; - Using spatial econometrics methods to find important determinants of Airbnb prices in order to provide insights into areas of opportunity for improvement, or assess the effectiveness of existing policy changes concerning vacation rentals

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
&gt; 
&gt;


### License
&gt; 
&gt; 
&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: vienna_weekdays.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

_____

**File: vienna_weekends.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE).

",.csv,True
Airbnb Prices in European Cities,20,airbnb-prices-in-european-cities,lisbon_weekends.csv,CC0-1.0,"_____
# Airbnb Prices in European Cities
### Determinants of Price by Room Type, Location, Cleanliness Rating, and More
By  [[source]](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
_____

### About this dataset
&gt; This dataset provides a comprehensive look at Airbnb prices in some of the most popular European cities. Each listing is evaluated for various attributes such as room types, cleanliness and satisfaction ratings, bedrooms, distance from the city centre, and more to capture an in-depth understanding of Airbnb prices on both weekdays and weekends. Using spatial econometric methods, we analyse and identify the determinants of Airbnb prices across these cities. Our dataset includes information such as realSum (the total price of the listing), room_type (private/shared/entire home/apt), host_is_superhost (boolean value indicating if host is a superhost or not), multi (indicator whether listing is for multiple rooms or not), biz (business indicator) , guest_satisfaction_overall (overall rating from guests camparing all listings offered by host ), bedrooms, dist (distance from city center) , lng & lat coordinates for location identification etc. We hope that this data set offers insight into how global markets are affected by social dynamics and geographical factors which in turn determine pricing strategies for optimal profitability!

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; This dataset can be used by individuals and companies to gain insight on the cost of Airbnb listings in some of the most popular European cities. It contains information on a variety of attributes such as room type, cleanliness rating, guest satisfaction, distance from the city centre, and more. In addition to exploring general trends in prices across Europe, this dataset can be used for deeper spatial econometric analysis. 
&gt; 
&gt; To begin using this dataset for your own research or analysis project: 
&gt; - Download the files which contain both weekday and weekend listings data for European cities. 
&gt; - Familiarize yourself with the columns included in each file; these provide descriptions of various attributes associated with each listing.  
&gt; - Calculate any desired summary statistics - average price per night per city or room type etc. - using statistical software (e.g Excel).  
&gt; - Perform spatial econometric analysis if desired; use specialized packages such as `spdep` or `spatialreg` in R to identify determinants of Airbnb price levels across Europe (e.g., metro distance). 
&gt; - Visualize your results with GIS software if necessary to more easily understand patterns between variables like proximity/location and price level (e.g., QGIS).   
&gt; 
&gt; By leveraging both descriptive and inferential methods while taking advantage of geographic information systems (GIS), users can apply this dataset to many interesting questions related to rental prices on Airbnb in Europe!

### Research Ideas
&gt; - Analyzing spatial trends in Airbnb prices across Europe and finding the most favorable cities for hosting.
&gt; - Comparing differences between weekday vs weekend booking patterns to project rental rates for vacationers and business travelers in European cities. 
&gt; - Using spatial econometrics methods to find important determinants of Airbnb prices in order to provide insights into areas of opportunity for improvement, or assess the effectiveness of existing policy changes concerning vacation rentals

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
&gt; 
&gt;


### License
&gt; 
&gt; 
&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: vienna_weekdays.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

_____

**File: vienna_weekends.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE).

",.csv,True
Airbnb Prices in European Cities,20,airbnb-prices-in-european-cities,athens_weekends.csv,CC0-1.0,"_____
# Airbnb Prices in European Cities
### Determinants of Price by Room Type, Location, Cleanliness Rating, and More
By  [[source]](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
_____

### About this dataset
&gt; This dataset provides a comprehensive look at Airbnb prices in some of the most popular European cities. Each listing is evaluated for various attributes such as room types, cleanliness and satisfaction ratings, bedrooms, distance from the city centre, and more to capture an in-depth understanding of Airbnb prices on both weekdays and weekends. Using spatial econometric methods, we analyse and identify the determinants of Airbnb prices across these cities. Our dataset includes information such as realSum (the total price of the listing), room_type (private/shared/entire home/apt), host_is_superhost (boolean value indicating if host is a superhost or not), multi (indicator whether listing is for multiple rooms or not), biz (business indicator) , guest_satisfaction_overall (overall rating from guests camparing all listings offered by host ), bedrooms, dist (distance from city center) , lng & lat coordinates for location identification etc. We hope that this data set offers insight into how global markets are affected by social dynamics and geographical factors which in turn determine pricing strategies for optimal profitability!

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; This dataset can be used by individuals and companies to gain insight on the cost of Airbnb listings in some of the most popular European cities. It contains information on a variety of attributes such as room type, cleanliness rating, guest satisfaction, distance from the city centre, and more. In addition to exploring general trends in prices across Europe, this dataset can be used for deeper spatial econometric analysis. 
&gt; 
&gt; To begin using this dataset for your own research or analysis project: 
&gt; - Download the files which contain both weekday and weekend listings data for European cities. 
&gt; - Familiarize yourself with the columns included in each file; these provide descriptions of various attributes associated with each listing.  
&gt; - Calculate any desired summary statistics - average price per night per city or room type etc. - using statistical software (e.g Excel).  
&gt; - Perform spatial econometric analysis if desired; use specialized packages such as `spdep` or `spatialreg` in R to identify determinants of Airbnb price levels across Europe (e.g., metro distance). 
&gt; - Visualize your results with GIS software if necessary to more easily understand patterns between variables like proximity/location and price level (e.g., QGIS).   
&gt; 
&gt; By leveraging both descriptive and inferential methods while taking advantage of geographic information systems (GIS), users can apply this dataset to many interesting questions related to rental prices on Airbnb in Europe!

### Research Ideas
&gt; - Analyzing spatial trends in Airbnb prices across Europe and finding the most favorable cities for hosting.
&gt; - Comparing differences between weekday vs weekend booking patterns to project rental rates for vacationers and business travelers in European cities. 
&gt; - Using spatial econometrics methods to find important determinants of Airbnb prices in order to provide insights into areas of opportunity for improvement, or assess the effectiveness of existing policy changes concerning vacation rentals

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
&gt; 
&gt;


### License
&gt; 
&gt; 
&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: vienna_weekdays.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

_____

**File: vienna_weekends.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE).

",.csv,True
Airbnb Prices in European Cities,20,airbnb-prices-in-european-cities,paris_weekends.csv,CC0-1.0,"_____
# Airbnb Prices in European Cities
### Determinants of Price by Room Type, Location, Cleanliness Rating, and More
By  [[source]](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
_____

### About this dataset
&gt; This dataset provides a comprehensive look at Airbnb prices in some of the most popular European cities. Each listing is evaluated for various attributes such as room types, cleanliness and satisfaction ratings, bedrooms, distance from the city centre, and more to capture an in-depth understanding of Airbnb prices on both weekdays and weekends. Using spatial econometric methods, we analyse and identify the determinants of Airbnb prices across these cities. Our dataset includes information such as realSum (the total price of the listing), room_type (private/shared/entire home/apt), host_is_superhost (boolean value indicating if host is a superhost or not), multi (indicator whether listing is for multiple rooms or not), biz (business indicator) , guest_satisfaction_overall (overall rating from guests camparing all listings offered by host ), bedrooms, dist (distance from city center) , lng & lat coordinates for location identification etc. We hope that this data set offers insight into how global markets are affected by social dynamics and geographical factors which in turn determine pricing strategies for optimal profitability!

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; This dataset can be used by individuals and companies to gain insight on the cost of Airbnb listings in some of the most popular European cities. It contains information on a variety of attributes such as room type, cleanliness rating, guest satisfaction, distance from the city centre, and more. In addition to exploring general trends in prices across Europe, this dataset can be used for deeper spatial econometric analysis. 
&gt; 
&gt; To begin using this dataset for your own research or analysis project: 
&gt; - Download the files which contain both weekday and weekend listings data for European cities. 
&gt; - Familiarize yourself with the columns included in each file; these provide descriptions of various attributes associated with each listing.  
&gt; - Calculate any desired summary statistics - average price per night per city or room type etc. - using statistical software (e.g Excel).  
&gt; - Perform spatial econometric analysis if desired; use specialized packages such as `spdep` or `spatialreg` in R to identify determinants of Airbnb price levels across Europe (e.g., metro distance). 
&gt; - Visualize your results with GIS software if necessary to more easily understand patterns between variables like proximity/location and price level (e.g., QGIS).   
&gt; 
&gt; By leveraging both descriptive and inferential methods while taking advantage of geographic information systems (GIS), users can apply this dataset to many interesting questions related to rental prices on Airbnb in Europe!

### Research Ideas
&gt; - Analyzing spatial trends in Airbnb prices across Europe and finding the most favorable cities for hosting.
&gt; - Comparing differences between weekday vs weekend booking patterns to project rental rates for vacationers and business travelers in European cities. 
&gt; - Using spatial econometrics methods to find important determinants of Airbnb prices in order to provide insights into areas of opportunity for improvement, or assess the effectiveness of existing policy changes concerning vacation rentals

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
&gt; 
&gt;


### License
&gt; 
&gt; 
&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: vienna_weekdays.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

_____

**File: vienna_weekends.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE).

",.csv,True
Airbnb Prices in European Cities,20,airbnb-prices-in-european-cities,barcelona_weekdays.csv,CC0-1.0,"_____
# Airbnb Prices in European Cities
### Determinants of Price by Room Type, Location, Cleanliness Rating, and More
By  [[source]](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
_____

### About this dataset
&gt; This dataset provides a comprehensive look at Airbnb prices in some of the most popular European cities. Each listing is evaluated for various attributes such as room types, cleanliness and satisfaction ratings, bedrooms, distance from the city centre, and more to capture an in-depth understanding of Airbnb prices on both weekdays and weekends. Using spatial econometric methods, we analyse and identify the determinants of Airbnb prices across these cities. Our dataset includes information such as realSum (the total price of the listing), room_type (private/shared/entire home/apt), host_is_superhost (boolean value indicating if host is a superhost or not), multi (indicator whether listing is for multiple rooms or not), biz (business indicator) , guest_satisfaction_overall (overall rating from guests camparing all listings offered by host ), bedrooms, dist (distance from city center) , lng & lat coordinates for location identification etc. We hope that this data set offers insight into how global markets are affected by social dynamics and geographical factors which in turn determine pricing strategies for optimal profitability!

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; This dataset can be used by individuals and companies to gain insight on the cost of Airbnb listings in some of the most popular European cities. It contains information on a variety of attributes such as room type, cleanliness rating, guest satisfaction, distance from the city centre, and more. In addition to exploring general trends in prices across Europe, this dataset can be used for deeper spatial econometric analysis. 
&gt; 
&gt; To begin using this dataset for your own research or analysis project: 
&gt; - Download the files which contain both weekday and weekend listings data for European cities. 
&gt; - Familiarize yourself with the columns included in each file; these provide descriptions of various attributes associated with each listing.  
&gt; - Calculate any desired summary statistics - average price per night per city or room type etc. - using statistical software (e.g Excel).  
&gt; - Perform spatial econometric analysis if desired; use specialized packages such as `spdep` or `spatialreg` in R to identify determinants of Airbnb price levels across Europe (e.g., metro distance). 
&gt; - Visualize your results with GIS software if necessary to more easily understand patterns between variables like proximity/location and price level (e.g., QGIS).   
&gt; 
&gt; By leveraging both descriptive and inferential methods while taking advantage of geographic information systems (GIS), users can apply this dataset to many interesting questions related to rental prices on Airbnb in Europe!

### Research Ideas
&gt; - Analyzing spatial trends in Airbnb prices across Europe and finding the most favorable cities for hosting.
&gt; - Comparing differences between weekday vs weekend booking patterns to project rental rates for vacationers and business travelers in European cities. 
&gt; - Using spatial econometrics methods to find important determinants of Airbnb prices in order to provide insights into areas of opportunity for improvement, or assess the effectiveness of existing policy changes concerning vacation rentals

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
&gt; 
&gt;


### License
&gt; 
&gt; 
&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: vienna_weekdays.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

_____

**File: vienna_weekends.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE).

",.csv,True
Airbnb Prices in European Cities,20,airbnb-prices-in-european-cities,berlin_weekends.csv,CC0-1.0,"_____
# Airbnb Prices in European Cities
### Determinants of Price by Room Type, Location, Cleanliness Rating, and More
By  [[source]](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
_____

### About this dataset
&gt; This dataset provides a comprehensive look at Airbnb prices in some of the most popular European cities. Each listing is evaluated for various attributes such as room types, cleanliness and satisfaction ratings, bedrooms, distance from the city centre, and more to capture an in-depth understanding of Airbnb prices on both weekdays and weekends. Using spatial econometric methods, we analyse and identify the determinants of Airbnb prices across these cities. Our dataset includes information such as realSum (the total price of the listing), room_type (private/shared/entire home/apt), host_is_superhost (boolean value indicating if host is a superhost or not), multi (indicator whether listing is for multiple rooms or not), biz (business indicator) , guest_satisfaction_overall (overall rating from guests camparing all listings offered by host ), bedrooms, dist (distance from city center) , lng & lat coordinates for location identification etc. We hope that this data set offers insight into how global markets are affected by social dynamics and geographical factors which in turn determine pricing strategies for optimal profitability!

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; This dataset can be used by individuals and companies to gain insight on the cost of Airbnb listings in some of the most popular European cities. It contains information on a variety of attributes such as room type, cleanliness rating, guest satisfaction, distance from the city centre, and more. In addition to exploring general trends in prices across Europe, this dataset can be used for deeper spatial econometric analysis. 
&gt; 
&gt; To begin using this dataset for your own research or analysis project: 
&gt; - Download the files which contain both weekday and weekend listings data for European cities. 
&gt; - Familiarize yourself with the columns included in each file; these provide descriptions of various attributes associated with each listing.  
&gt; - Calculate any desired summary statistics - average price per night per city or room type etc. - using statistical software (e.g Excel).  
&gt; - Perform spatial econometric analysis if desired; use specialized packages such as `spdep` or `spatialreg` in R to identify determinants of Airbnb price levels across Europe (e.g., metro distance). 
&gt; - Visualize your results with GIS software if necessary to more easily understand patterns between variables like proximity/location and price level (e.g., QGIS).   
&gt; 
&gt; By leveraging both descriptive and inferential methods while taking advantage of geographic information systems (GIS), users can apply this dataset to many interesting questions related to rental prices on Airbnb in Europe!

### Research Ideas
&gt; - Analyzing spatial trends in Airbnb prices across Europe and finding the most favorable cities for hosting.
&gt; - Comparing differences between weekday vs weekend booking patterns to project rental rates for vacationers and business travelers in European cities. 
&gt; - Using spatial econometrics methods to find important determinants of Airbnb prices in order to provide insights into areas of opportunity for improvement, or assess the effectiveness of existing policy changes concerning vacation rentals

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
&gt; 
&gt;


### License
&gt; 
&gt; 
&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: vienna_weekdays.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

_____

**File: vienna_weekends.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE).

",.csv,True
Airbnb Prices in European Cities,20,airbnb-prices-in-european-cities,rome_weekends.csv,CC0-1.0,"_____
# Airbnb Prices in European Cities
### Determinants of Price by Room Type, Location, Cleanliness Rating, and More
By  [[source]](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
_____

### About this dataset
&gt; This dataset provides a comprehensive look at Airbnb prices in some of the most popular European cities. Each listing is evaluated for various attributes such as room types, cleanliness and satisfaction ratings, bedrooms, distance from the city centre, and more to capture an in-depth understanding of Airbnb prices on both weekdays and weekends. Using spatial econometric methods, we analyse and identify the determinants of Airbnb prices across these cities. Our dataset includes information such as realSum (the total price of the listing), room_type (private/shared/entire home/apt), host_is_superhost (boolean value indicating if host is a superhost or not), multi (indicator whether listing is for multiple rooms or not), biz (business indicator) , guest_satisfaction_overall (overall rating from guests camparing all listings offered by host ), bedrooms, dist (distance from city center) , lng & lat coordinates for location identification etc. We hope that this data set offers insight into how global markets are affected by social dynamics and geographical factors which in turn determine pricing strategies for optimal profitability!

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; This dataset can be used by individuals and companies to gain insight on the cost of Airbnb listings in some of the most popular European cities. It contains information on a variety of attributes such as room type, cleanliness rating, guest satisfaction, distance from the city centre, and more. In addition to exploring general trends in prices across Europe, this dataset can be used for deeper spatial econometric analysis. 
&gt; 
&gt; To begin using this dataset for your own research or analysis project: 
&gt; - Download the files which contain both weekday and weekend listings data for European cities. 
&gt; - Familiarize yourself with the columns included in each file; these provide descriptions of various attributes associated with each listing.  
&gt; - Calculate any desired summary statistics - average price per night per city or room type etc. - using statistical software (e.g Excel).  
&gt; - Perform spatial econometric analysis if desired; use specialized packages such as `spdep` or `spatialreg` in R to identify determinants of Airbnb price levels across Europe (e.g., metro distance). 
&gt; - Visualize your results with GIS software if necessary to more easily understand patterns between variables like proximity/location and price level (e.g., QGIS).   
&gt; 
&gt; By leveraging both descriptive and inferential methods while taking advantage of geographic information systems (GIS), users can apply this dataset to many interesting questions related to rental prices on Airbnb in Europe!

### Research Ideas
&gt; - Analyzing spatial trends in Airbnb prices across Europe and finding the most favorable cities for hosting.
&gt; - Comparing differences between weekday vs weekend booking patterns to project rental rates for vacationers and business travelers in European cities. 
&gt; - Using spatial econometrics methods to find important determinants of Airbnb prices in order to provide insights into areas of opportunity for improvement, or assess the effectiveness of existing policy changes concerning vacation rentals

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
&gt; 
&gt;


### License
&gt; 
&gt; 
&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: vienna_weekdays.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

_____

**File: vienna_weekends.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE).

",.csv,True
Airbnb Prices in European Cities,20,airbnb-prices-in-european-cities,amsterdam_weekends.csv,CC0-1.0,"_____
# Airbnb Prices in European Cities
### Determinants of Price by Room Type, Location, Cleanliness Rating, and More
By  [[source]](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
_____

### About this dataset
&gt; This dataset provides a comprehensive look at Airbnb prices in some of the most popular European cities. Each listing is evaluated for various attributes such as room types, cleanliness and satisfaction ratings, bedrooms, distance from the city centre, and more to capture an in-depth understanding of Airbnb prices on both weekdays and weekends. Using spatial econometric methods, we analyse and identify the determinants of Airbnb prices across these cities. Our dataset includes information such as realSum (the total price of the listing), room_type (private/shared/entire home/apt), host_is_superhost (boolean value indicating if host is a superhost or not), multi (indicator whether listing is for multiple rooms or not), biz (business indicator) , guest_satisfaction_overall (overall rating from guests camparing all listings offered by host ), bedrooms, dist (distance from city center) , lng & lat coordinates for location identification etc. We hope that this data set offers insight into how global markets are affected by social dynamics and geographical factors which in turn determine pricing strategies for optimal profitability!

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; This dataset can be used by individuals and companies to gain insight on the cost of Airbnb listings in some of the most popular European cities. It contains information on a variety of attributes such as room type, cleanliness rating, guest satisfaction, distance from the city centre, and more. In addition to exploring general trends in prices across Europe, this dataset can be used for deeper spatial econometric analysis. 
&gt; 
&gt; To begin using this dataset for your own research or analysis project: 
&gt; - Download the files which contain both weekday and weekend listings data for European cities. 
&gt; - Familiarize yourself with the columns included in each file; these provide descriptions of various attributes associated with each listing.  
&gt; - Calculate any desired summary statistics - average price per night per city or room type etc. - using statistical software (e.g Excel).  
&gt; - Perform spatial econometric analysis if desired; use specialized packages such as `spdep` or `spatialreg` in R to identify determinants of Airbnb price levels across Europe (e.g., metro distance). 
&gt; - Visualize your results with GIS software if necessary to more easily understand patterns between variables like proximity/location and price level (e.g., QGIS).   
&gt; 
&gt; By leveraging both descriptive and inferential methods while taking advantage of geographic information systems (GIS), users can apply this dataset to many interesting questions related to rental prices on Airbnb in Europe!

### Research Ideas
&gt; - Analyzing spatial trends in Airbnb prices across Europe and finding the most favorable cities for hosting.
&gt; - Comparing differences between weekday vs weekend booking patterns to project rental rates for vacationers and business travelers in European cities. 
&gt; - Using spatial econometrics methods to find important determinants of Airbnb prices in order to provide insights into areas of opportunity for improvement, or assess the effectiveness of existing policy changes concerning vacation rentals

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
&gt; 
&gt;


### License
&gt; 
&gt; 
&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: vienna_weekdays.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

_____

**File: vienna_weekends.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE).

",.csv,True
Airbnb Prices in European Cities,20,airbnb-prices-in-european-cities,athens_weekdays.csv,CC0-1.0,"_____
# Airbnb Prices in European Cities
### Determinants of Price by Room Type, Location, Cleanliness Rating, and More
By  [[source]](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
_____

### About this dataset
&gt; This dataset provides a comprehensive look at Airbnb prices in some of the most popular European cities. Each listing is evaluated for various attributes such as room types, cleanliness and satisfaction ratings, bedrooms, distance from the city centre, and more to capture an in-depth understanding of Airbnb prices on both weekdays and weekends. Using spatial econometric methods, we analyse and identify the determinants of Airbnb prices across these cities. Our dataset includes information such as realSum (the total price of the listing), room_type (private/shared/entire home/apt), host_is_superhost (boolean value indicating if host is a superhost or not), multi (indicator whether listing is for multiple rooms or not), biz (business indicator) , guest_satisfaction_overall (overall rating from guests camparing all listings offered by host ), bedrooms, dist (distance from city center) , lng & lat coordinates for location identification etc. We hope that this data set offers insight into how global markets are affected by social dynamics and geographical factors which in turn determine pricing strategies for optimal profitability!

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; This dataset can be used by individuals and companies to gain insight on the cost of Airbnb listings in some of the most popular European cities. It contains information on a variety of attributes such as room type, cleanliness rating, guest satisfaction, distance from the city centre, and more. In addition to exploring general trends in prices across Europe, this dataset can be used for deeper spatial econometric analysis. 
&gt; 
&gt; To begin using this dataset for your own research or analysis project: 
&gt; - Download the files which contain both weekday and weekend listings data for European cities. 
&gt; - Familiarize yourself with the columns included in each file; these provide descriptions of various attributes associated with each listing.  
&gt; - Calculate any desired summary statistics - average price per night per city or room type etc. - using statistical software (e.g Excel).  
&gt; - Perform spatial econometric analysis if desired; use specialized packages such as `spdep` or `spatialreg` in R to identify determinants of Airbnb price levels across Europe (e.g., metro distance). 
&gt; - Visualize your results with GIS software if necessary to more easily understand patterns between variables like proximity/location and price level (e.g., QGIS).   
&gt; 
&gt; By leveraging both descriptive and inferential methods while taking advantage of geographic information systems (GIS), users can apply this dataset to many interesting questions related to rental prices on Airbnb in Europe!

### Research Ideas
&gt; - Analyzing spatial trends in Airbnb prices across Europe and finding the most favorable cities for hosting.
&gt; - Comparing differences between weekday vs weekend booking patterns to project rental rates for vacationers and business travelers in European cities. 
&gt; - Using spatial econometrics methods to find important determinants of Airbnb prices in order to provide insights into areas of opportunity for improvement, or assess the effectiveness of existing policy changes concerning vacation rentals

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
&gt; 
&gt;


### License
&gt; 
&gt; 
&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: vienna_weekdays.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

_____

**File: vienna_weekends.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE).

",.csv,True
Airbnb Prices in European Cities,20,airbnb-prices-in-european-cities,paris_weekdays.csv,CC0-1.0,"_____
# Airbnb Prices in European Cities
### Determinants of Price by Room Type, Location, Cleanliness Rating, and More
By  [[source]](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
_____

### About this dataset
&gt; This dataset provides a comprehensive look at Airbnb prices in some of the most popular European cities. Each listing is evaluated for various attributes such as room types, cleanliness and satisfaction ratings, bedrooms, distance from the city centre, and more to capture an in-depth understanding of Airbnb prices on both weekdays and weekends. Using spatial econometric methods, we analyse and identify the determinants of Airbnb prices across these cities. Our dataset includes information such as realSum (the total price of the listing), room_type (private/shared/entire home/apt), host_is_superhost (boolean value indicating if host is a superhost or not), multi (indicator whether listing is for multiple rooms or not), biz (business indicator) , guest_satisfaction_overall (overall rating from guests camparing all listings offered by host ), bedrooms, dist (distance from city center) , lng & lat coordinates for location identification etc. We hope that this data set offers insight into how global markets are affected by social dynamics and geographical factors which in turn determine pricing strategies for optimal profitability!

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; This dataset can be used by individuals and companies to gain insight on the cost of Airbnb listings in some of the most popular European cities. It contains information on a variety of attributes such as room type, cleanliness rating, guest satisfaction, distance from the city centre, and more. In addition to exploring general trends in prices across Europe, this dataset can be used for deeper spatial econometric analysis. 
&gt; 
&gt; To begin using this dataset for your own research or analysis project: 
&gt; - Download the files which contain both weekday and weekend listings data for European cities. 
&gt; - Familiarize yourself with the columns included in each file; these provide descriptions of various attributes associated with each listing.  
&gt; - Calculate any desired summary statistics - average price per night per city or room type etc. - using statistical software (e.g Excel).  
&gt; - Perform spatial econometric analysis if desired; use specialized packages such as `spdep` or `spatialreg` in R to identify determinants of Airbnb price levels across Europe (e.g., metro distance). 
&gt; - Visualize your results with GIS software if necessary to more easily understand patterns between variables like proximity/location and price level (e.g., QGIS).   
&gt; 
&gt; By leveraging both descriptive and inferential methods while taking advantage of geographic information systems (GIS), users can apply this dataset to many interesting questions related to rental prices on Airbnb in Europe!

### Research Ideas
&gt; - Analyzing spatial trends in Airbnb prices across Europe and finding the most favorable cities for hosting.
&gt; - Comparing differences between weekday vs weekend booking patterns to project rental rates for vacationers and business travelers in European cities. 
&gt; - Using spatial econometrics methods to find important determinants of Airbnb prices in order to provide insights into areas of opportunity for improvement, or assess the effectiveness of existing policy changes concerning vacation rentals

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
&gt; 
&gt;


### License
&gt; 
&gt; 
&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: vienna_weekdays.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

_____

**File: vienna_weekends.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE).

",.csv,True
Airbnb Prices in European Cities,20,airbnb-prices-in-european-cities,vienna_weekends.csv,CC0-1.0,"_____
# Airbnb Prices in European Cities
### Determinants of Price by Room Type, Location, Cleanliness Rating, and More
By  [[source]](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
_____

### About this dataset
&gt; This dataset provides a comprehensive look at Airbnb prices in some of the most popular European cities. Each listing is evaluated for various attributes such as room types, cleanliness and satisfaction ratings, bedrooms, distance from the city centre, and more to capture an in-depth understanding of Airbnb prices on both weekdays and weekends. Using spatial econometric methods, we analyse and identify the determinants of Airbnb prices across these cities. Our dataset includes information such as realSum (the total price of the listing), room_type (private/shared/entire home/apt), host_is_superhost (boolean value indicating if host is a superhost or not), multi (indicator whether listing is for multiple rooms or not), biz (business indicator) , guest_satisfaction_overall (overall rating from guests camparing all listings offered by host ), bedrooms, dist (distance from city center) , lng & lat coordinates for location identification etc. We hope that this data set offers insight into how global markets are affected by social dynamics and geographical factors which in turn determine pricing strategies for optimal profitability!

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; This dataset can be used by individuals and companies to gain insight on the cost of Airbnb listings in some of the most popular European cities. It contains information on a variety of attributes such as room type, cleanliness rating, guest satisfaction, distance from the city centre, and more. In addition to exploring general trends in prices across Europe, this dataset can be used for deeper spatial econometric analysis. 
&gt; 
&gt; To begin using this dataset for your own research or analysis project: 
&gt; - Download the files which contain both weekday and weekend listings data for European cities. 
&gt; - Familiarize yourself with the columns included in each file; these provide descriptions of various attributes associated with each listing.  
&gt; - Calculate any desired summary statistics - average price per night per city or room type etc. - using statistical software (e.g Excel).  
&gt; - Perform spatial econometric analysis if desired; use specialized packages such as `spdep` or `spatialreg` in R to identify determinants of Airbnb price levels across Europe (e.g., metro distance). 
&gt; - Visualize your results with GIS software if necessary to more easily understand patterns between variables like proximity/location and price level (e.g., QGIS).   
&gt; 
&gt; By leveraging both descriptive and inferential methods while taking advantage of geographic information systems (GIS), users can apply this dataset to many interesting questions related to rental prices on Airbnb in Europe!

### Research Ideas
&gt; - Analyzing spatial trends in Airbnb prices across Europe and finding the most favorable cities for hosting.
&gt; - Comparing differences between weekday vs weekend booking patterns to project rental rates for vacationers and business travelers in European cities. 
&gt; - Using spatial econometrics methods to find important determinants of Airbnb prices in order to provide insights into areas of opportunity for improvement, or assess the effectiveness of existing policy changes concerning vacation rentals

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
&gt; 
&gt;


### License
&gt; 
&gt; 
&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: vienna_weekdays.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

_____

**File: vienna_weekends.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE).

",.csv,True
Airbnb Prices in European Cities,20,airbnb-prices-in-european-cities,budapest_weekends.csv,CC0-1.0,"_____
# Airbnb Prices in European Cities
### Determinants of Price by Room Type, Location, Cleanliness Rating, and More
By  [[source]](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
_____

### About this dataset
&gt; This dataset provides a comprehensive look at Airbnb prices in some of the most popular European cities. Each listing is evaluated for various attributes such as room types, cleanliness and satisfaction ratings, bedrooms, distance from the city centre, and more to capture an in-depth understanding of Airbnb prices on both weekdays and weekends. Using spatial econometric methods, we analyse and identify the determinants of Airbnb prices across these cities. Our dataset includes information such as realSum (the total price of the listing), room_type (private/shared/entire home/apt), host_is_superhost (boolean value indicating if host is a superhost or not), multi (indicator whether listing is for multiple rooms or not), biz (business indicator) , guest_satisfaction_overall (overall rating from guests camparing all listings offered by host ), bedrooms, dist (distance from city center) , lng & lat coordinates for location identification etc. We hope that this data set offers insight into how global markets are affected by social dynamics and geographical factors which in turn determine pricing strategies for optimal profitability!

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; This dataset can be used by individuals and companies to gain insight on the cost of Airbnb listings in some of the most popular European cities. It contains information on a variety of attributes such as room type, cleanliness rating, guest satisfaction, distance from the city centre, and more. In addition to exploring general trends in prices across Europe, this dataset can be used for deeper spatial econometric analysis. 
&gt; 
&gt; To begin using this dataset for your own research or analysis project: 
&gt; - Download the files which contain both weekday and weekend listings data for European cities. 
&gt; - Familiarize yourself with the columns included in each file; these provide descriptions of various attributes associated with each listing.  
&gt; - Calculate any desired summary statistics - average price per night per city or room type etc. - using statistical software (e.g Excel).  
&gt; - Perform spatial econometric analysis if desired; use specialized packages such as `spdep` or `spatialreg` in R to identify determinants of Airbnb price levels across Europe (e.g., metro distance). 
&gt; - Visualize your results with GIS software if necessary to more easily understand patterns between variables like proximity/location and price level (e.g., QGIS).   
&gt; 
&gt; By leveraging both descriptive and inferential methods while taking advantage of geographic information systems (GIS), users can apply this dataset to many interesting questions related to rental prices on Airbnb in Europe!

### Research Ideas
&gt; - Analyzing spatial trends in Airbnb prices across Europe and finding the most favorable cities for hosting.
&gt; - Comparing differences between weekday vs weekend booking patterns to project rental rates for vacationers and business travelers in European cities. 
&gt; - Using spatial econometrics methods to find important determinants of Airbnb prices in order to provide insights into areas of opportunity for improvement, or assess the effectiveness of existing policy changes concerning vacation rentals

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
&gt; 
&gt;


### License
&gt; 
&gt; 
&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: vienna_weekdays.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

_____

**File: vienna_weekends.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE).

",.csv,True
Airbnb Prices in European Cities,20,airbnb-prices-in-european-cities,lisbon_weekdays.csv,CC0-1.0,"_____
# Airbnb Prices in European Cities
### Determinants of Price by Room Type, Location, Cleanliness Rating, and More
By  [[source]](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
_____

### About this dataset
&gt; This dataset provides a comprehensive look at Airbnb prices in some of the most popular European cities. Each listing is evaluated for various attributes such as room types, cleanliness and satisfaction ratings, bedrooms, distance from the city centre, and more to capture an in-depth understanding of Airbnb prices on both weekdays and weekends. Using spatial econometric methods, we analyse and identify the determinants of Airbnb prices across these cities. Our dataset includes information such as realSum (the total price of the listing), room_type (private/shared/entire home/apt), host_is_superhost (boolean value indicating if host is a superhost or not), multi (indicator whether listing is for multiple rooms or not), biz (business indicator) , guest_satisfaction_overall (overall rating from guests camparing all listings offered by host ), bedrooms, dist (distance from city center) , lng & lat coordinates for location identification etc. We hope that this data set offers insight into how global markets are affected by social dynamics and geographical factors which in turn determine pricing strategies for optimal profitability!

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; This dataset can be used by individuals and companies to gain insight on the cost of Airbnb listings in some of the most popular European cities. It contains information on a variety of attributes such as room type, cleanliness rating, guest satisfaction, distance from the city centre, and more. In addition to exploring general trends in prices across Europe, this dataset can be used for deeper spatial econometric analysis. 
&gt; 
&gt; To begin using this dataset for your own research or analysis project: 
&gt; - Download the files which contain both weekday and weekend listings data for European cities. 
&gt; - Familiarize yourself with the columns included in each file; these provide descriptions of various attributes associated with each listing.  
&gt; - Calculate any desired summary statistics - average price per night per city or room type etc. - using statistical software (e.g Excel).  
&gt; - Perform spatial econometric analysis if desired; use specialized packages such as `spdep` or `spatialreg` in R to identify determinants of Airbnb price levels across Europe (e.g., metro distance). 
&gt; - Visualize your results with GIS software if necessary to more easily understand patterns between variables like proximity/location and price level (e.g., QGIS).   
&gt; 
&gt; By leveraging both descriptive and inferential methods while taking advantage of geographic information systems (GIS), users can apply this dataset to many interesting questions related to rental prices on Airbnb in Europe!

### Research Ideas
&gt; - Analyzing spatial trends in Airbnb prices across Europe and finding the most favorable cities for hosting.
&gt; - Comparing differences between weekday vs weekend booking patterns to project rental rates for vacationers and business travelers in European cities. 
&gt; - Using spatial econometrics methods to find important determinants of Airbnb prices in order to provide insights into areas of opportunity for improvement, or assess the effectiveness of existing policy changes concerning vacation rentals

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
&gt; 
&gt;


### License
&gt; 
&gt; 
&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: vienna_weekdays.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

_____

**File: vienna_weekends.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE).

",.csv,True
Airbnb Prices in European Cities,20,airbnb-prices-in-european-cities,london_weekends.csv,CC0-1.0,"_____
# Airbnb Prices in European Cities
### Determinants of Price by Room Type, Location, Cleanliness Rating, and More
By  [[source]](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
_____

### About this dataset
&gt; This dataset provides a comprehensive look at Airbnb prices in some of the most popular European cities. Each listing is evaluated for various attributes such as room types, cleanliness and satisfaction ratings, bedrooms, distance from the city centre, and more to capture an in-depth understanding of Airbnb prices on both weekdays and weekends. Using spatial econometric methods, we analyse and identify the determinants of Airbnb prices across these cities. Our dataset includes information such as realSum (the total price of the listing), room_type (private/shared/entire home/apt), host_is_superhost (boolean value indicating if host is a superhost or not), multi (indicator whether listing is for multiple rooms or not), biz (business indicator) , guest_satisfaction_overall (overall rating from guests camparing all listings offered by host ), bedrooms, dist (distance from city center) , lng & lat coordinates for location identification etc. We hope that this data set offers insight into how global markets are affected by social dynamics and geographical factors which in turn determine pricing strategies for optimal profitability!

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; This dataset can be used by individuals and companies to gain insight on the cost of Airbnb listings in some of the most popular European cities. It contains information on a variety of attributes such as room type, cleanliness rating, guest satisfaction, distance from the city centre, and more. In addition to exploring general trends in prices across Europe, this dataset can be used for deeper spatial econometric analysis. 
&gt; 
&gt; To begin using this dataset for your own research or analysis project: 
&gt; - Download the files which contain both weekday and weekend listings data for European cities. 
&gt; - Familiarize yourself with the columns included in each file; these provide descriptions of various attributes associated with each listing.  
&gt; - Calculate any desired summary statistics - average price per night per city or room type etc. - using statistical software (e.g Excel).  
&gt; - Perform spatial econometric analysis if desired; use specialized packages such as `spdep` or `spatialreg` in R to identify determinants of Airbnb price levels across Europe (e.g., metro distance). 
&gt; - Visualize your results with GIS software if necessary to more easily understand patterns between variables like proximity/location and price level (e.g., QGIS).   
&gt; 
&gt; By leveraging both descriptive and inferential methods while taking advantage of geographic information systems (GIS), users can apply this dataset to many interesting questions related to rental prices on Airbnb in Europe!

### Research Ideas
&gt; - Analyzing spatial trends in Airbnb prices across Europe and finding the most favorable cities for hosting.
&gt; - Comparing differences between weekday vs weekend booking patterns to project rental rates for vacationers and business travelers in European cities. 
&gt; - Using spatial econometrics methods to find important determinants of Airbnb prices in order to provide insights into areas of opportunity for improvement, or assess the effectiveness of existing policy changes concerning vacation rentals

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE)
&gt; 
&gt;


### License
&gt; 
&gt; 
&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: vienna_weekdays.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

_____

**File: vienna_weekends.csv**
| Column name                    | Description                                                                |
|:-------------------------------|:---------------------------------------------------------------------------|
| **realSum**                    | The total price of the Airbnb listing. (Numeric)                           |
| **room_type**                  | The type of room being offered (e.g. private, shared, etc.). (Categorical) |
| **room_shared**                | Whether the room is shared or not. (Boolean)                               |
| **room_private**               | Whether the room is private or not. (Boolean)                              |
| **person_capacity**            | The maximum number of people that can stay in the room. (Numeric)          |
| **host_is_superhost**          | Whether the host is a superhost or not. (Boolean)                          |
| **multi**                      | Whether the listing is for multiple rooms or not. (Boolean)                |
| **biz**                        | Whether the listing is for business purposes or not. (Boolean)             |
| **cleanliness_rating**         | The cleanliness rating of the listing. (Numeric)                           |
| **guest_satisfaction_overall** | The overall guest satisfaction rating of the listing. (Numeric)            |
| **bedrooms**                   | The number of bedrooms in the listing. (Numeric)                           |
| **dist**                       | The distance from the city centre. (Numeric)                               |
| **metro_dist**                 | The distance from the nearest metro station. (Numeric)                     |
| **lng**                        | The longitude of the listing. (Numeric)                                    |
| **lat**                        | The latitude of the listing. (Numeric)                                     |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [](https://zenodo.org/record/4446043#.Y9Y9ENJBwUE).

",.csv,True
Alcohol Effects On Study,2,alcohol-effects-on-study,Portuguese.csv,Attribution 4.0 International (CC BY 4.0),"This data approach student achievement in secondary education of two Portuguese schools. The data attributes include student grades, demographic, social and school related features) and it was collected by using school reports and questionnaires. Two datasets are provided regarding the performance in two distinct subjects: Mathematics (mat) and Portuguese language (por). In [Cortez and Silva, 2008], the two datasets were modeled under binary/five-level classification and regression tasks. Important note: the target attribute G3 has a strong correlation with attributes G2 and G1. This occurs because G3 is the final year grade (issued at the 3rd period), while G1 and G2 correspond to the 1st and 2nd period grades. It is more difficult to predict G3 without G2 and G1, but such prediction is much more useful (see paper source for more details).

## Attributes for both Maths.csv (Math course) and Portuguese.csv (Portuguese language course) datasets:
| Columns | Description |
| --- | --- |
| school | student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira) |
| sex | student's sex (binary: 'F' - female or 'M' - male) |
| age | student's age (numeric: from 15 to 22) |
| address | student's home address type (binary: 'U' - urban or 'R' - rural) |
| famsize | family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3) |
| Pstatus | parent's cohabitation status (binary: 'T' - living together or 'A' - apart) |
| Medu | mother's education (numeric: 0 - none,  1 - primary education (4th grade), 2 â€“ 5th to 9th grade, 3 â€“ secondary education or 4 â€“ higher education) |
| Fedu | father's education (numeric: 0 - none,  1 - primary education (4th grade), 2 â€“ 5th to 9th grade, 3 â€“ secondary education or 4 â€“ higher education) |
| Mjob | mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other') |
| Fjob | father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other') |
| reason | reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other') |
| guardian | student's guardian (nominal: 'mother', 'father' or 'other') |
| traveltime | home to school travel time (numeric: 1 - &lt;15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - &gt;1 hour) |
| studytime | weekly study time (numeric: 1 - &lt;2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - &gt;10 hours) |
| failures | number of past class failures (numeric: n if 1&lt;=n&lt;3, else 4) |
| schoolsup | extra educational support (binary: yes or no) |
| famsup | family educational support (binary: yes or no) |
| paid | extra paid classes within the course subject (Math or Portuguese) (binary: yes or no) |
| activities | extra-curricular activities (binary: yes or no) |
| nursery | attended nursery school (binary: yes or no) |
| higher | wants to take higher education (binary: yes or no) |
| internet | Internet access at home (binary: yes or no) |
| romantic | with a romantic relationship (binary: yes or no) |
| famrel | quality of family relationships (numeric: from 1 - very bad to 5 - excellent) |
| freetime | free time after school (numeric: from 1 - very low to 5 - very high) |
| goout | going out with friends (numeric: from 1 - very low to 5 - very high) |
| Dalc | workday alcohol consumption (numeric: from 1 - very low to 5 - very high) |
| Walc | weekend alcohol consumption (numeric: from 1 - very low to 5 - very high) |
| health | current health status (numeric: from 1 - very bad to 5 - very good) |
| absences | number of school absences (numeric: from 0 to 93) |

## These grades are related with the course subject, Math or Portuguese:
| Grade | Description |
| --- | --- |
| G1 | first period grade (numeric: from 0 to 20) |
| G2 | second period grade (numeric: from 0 to 20) |
| G3 | final grade (numeric: from 0 to 20, output target) |

&gt; More
- Find More Exciting🙀 Datasets [Here](https://www.kaggle.com/whenamancodes/datasets)
- An Upvote👍 A Dayᕙ(`▿´)ᕗ , Keeps Aman Hurray Hurray..... ٩(˘◡˘)۶Haha",.csv,True
Alcohol Effects On Study,2,alcohol-effects-on-study,Maths.csv,Attribution 4.0 International (CC BY 4.0),"This data approach student achievement in secondary education of two Portuguese schools. The data attributes include student grades, demographic, social and school related features) and it was collected by using school reports and questionnaires. Two datasets are provided regarding the performance in two distinct subjects: Mathematics (mat) and Portuguese language (por). In [Cortez and Silva, 2008], the two datasets were modeled under binary/five-level classification and regression tasks. Important note: the target attribute G3 has a strong correlation with attributes G2 and G1. This occurs because G3 is the final year grade (issued at the 3rd period), while G1 and G2 correspond to the 1st and 2nd period grades. It is more difficult to predict G3 without G2 and G1, but such prediction is much more useful (see paper source for more details).

## Attributes for both Maths.csv (Math course) and Portuguese.csv (Portuguese language course) datasets:
| Columns | Description |
| --- | --- |
| school | student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira) |
| sex | student's sex (binary: 'F' - female or 'M' - male) |
| age | student's age (numeric: from 15 to 22) |
| address | student's home address type (binary: 'U' - urban or 'R' - rural) |
| famsize | family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3) |
| Pstatus | parent's cohabitation status (binary: 'T' - living together or 'A' - apart) |
| Medu | mother's education (numeric: 0 - none,  1 - primary education (4th grade), 2 â€“ 5th to 9th grade, 3 â€“ secondary education or 4 â€“ higher education) |
| Fedu | father's education (numeric: 0 - none,  1 - primary education (4th grade), 2 â€“ 5th to 9th grade, 3 â€“ secondary education or 4 â€“ higher education) |
| Mjob | mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other') |
| Fjob | father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other') |
| reason | reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other') |
| guardian | student's guardian (nominal: 'mother', 'father' or 'other') |
| traveltime | home to school travel time (numeric: 1 - &lt;15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - &gt;1 hour) |
| studytime | weekly study time (numeric: 1 - &lt;2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - &gt;10 hours) |
| failures | number of past class failures (numeric: n if 1&lt;=n&lt;3, else 4) |
| schoolsup | extra educational support (binary: yes or no) |
| famsup | family educational support (binary: yes or no) |
| paid | extra paid classes within the course subject (Math or Portuguese) (binary: yes or no) |
| activities | extra-curricular activities (binary: yes or no) |
| nursery | attended nursery school (binary: yes or no) |
| higher | wants to take higher education (binary: yes or no) |
| internet | Internet access at home (binary: yes or no) |
| romantic | with a romantic relationship (binary: yes or no) |
| famrel | quality of family relationships (numeric: from 1 - very bad to 5 - excellent) |
| freetime | free time after school (numeric: from 1 - very low to 5 - very high) |
| goout | going out with friends (numeric: from 1 - very low to 5 - very high) |
| Dalc | workday alcohol consumption (numeric: from 1 - very low to 5 - very high) |
| Walc | weekend alcohol consumption (numeric: from 1 - very low to 5 - very high) |
| health | current health status (numeric: from 1 - very bad to 5 - very good) |
| absences | number of school absences (numeric: from 0 to 93) |

## These grades are related with the course subject, Math or Portuguese:
| Grade | Description |
| --- | --- |
| G1 | first period grade (numeric: from 0 to 20) |
| G2 | second period grade (numeric: from 0 to 20) |
| G3 | final grade (numeric: from 0 to 20, output target) |

&gt; More
- Find More Exciting🙀 Datasets [Here](https://www.kaggle.com/whenamancodes/datasets)
- An Upvote👍 A Dayᕙ(`▿´)ᕗ , Keeps Aman Hurray Hurray..... ٩(˘◡˘)۶Haha",.csv,True
All-Time Stock Price Data,77,test-dataset,CSCO.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,ISRG.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,VRTX.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,GILD.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,FOX.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,SWKS.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,MCHP.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,CDNS.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,CHTR.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,WBA.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,ADI.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,ADBE.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,TCOM.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,CPRT.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,ULTA.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,PEP.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,COST.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,BKNG.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,FAST.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,KHC.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,CHKP.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,SBUX.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,INTU.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,AMZN.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,INTC.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,DOCU.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,DXCM.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,TXN.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,VRSK.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,MELI.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,WDC.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,PYPL.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,MSFT.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,ANSS.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,CTAS.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,NTES.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,VRSN.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,AMD.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,KLAC.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,NXPI.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,BIIB.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,NVDA.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,IDXX.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,EXC.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,INCY.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,MRVL.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,CMCSA.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,SIRI.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,FB.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,SGEN.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,LULU.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,ALGN.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,NFLX.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,PTON.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,TSLA.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,GOOGL.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,ILMN.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,FOXA.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,JD.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,SNPS.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,AVGO.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,REGN.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,AMGN.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,ADP.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,QCOM.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,CSX.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,FISV.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,MXIM.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,AAPL.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,TMUS.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,NTAP.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,SPLK.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,CTSH.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,MU.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,CDW.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,ASML.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
All-Time Stock Price Data,77,test-dataset,LRCX.csv,CC0-1.0,"This comprehensive dataset provides historical stock price data spanning various time periods, offering insights into the fluctuations and trends in the stock market over time. With records covering multiple decades, investors, analysts, and researchers can explore the dynamics of different stocks, industries, and market sectors.

The dataset includes essential information such as opening price, closing price, highest and lowest prices, trading volume, and adjusted closing prices. It encompasses a diverse range of stocks, including those from various exchanges and sectors, allowing for extensive analysis and comparison.

Researchers can utilize this dataset to conduct thorough analyses, develop financial models, backtest trading strategies, and gain a deeper understanding of market behavior. Investors can assess the performance of individual stocks or portfolios over extended periods, aiding in informed decision-making and risk management.

Whether you're a seasoned investor seeking historical insights or an analyst exploring market trends, this dataset serves as a valuable resource for studying the complexities of the stock market across different eras.

",.csv,True
Arabic Levantine Hate Speech Detection,2,arabic-levantine-hate-speech-detection,test.csv,CC0-1.0,"### Context

Twitter Dataset for Hate Speech dataset termed The Levantine Hate Speech and ABusive is the first Arabic Levantine Hate Speech and Abusive Language Dataset proposed in the 3rd Workshop ALW-2019 co-located with ACL-2019, Florence, Italy.

The volatile political/social atmosphere in Levantine-speaking countries, particularly, Syria and Lebanon, has been always associated with intensive online debates of toxic contents: Hate speech and abusive language. L-HSAB combines 5,846 Syrian/Lebanese political tweets labeled as normal, abusive or hate. Coping with hot political debates, the collected tweets were posted between March 2018 and February 2019.
The main classification aims are:
1- Binary Classification (Normal, Abusive):
2- Multi-Class Classification (Normal, Abusive, Hate):

### Content

The dataset is spiltted into train and test. The features are the tweet and the annotation (Normal, Abusive and Hate). Theannotation process was conducted by 3 Levantine-speaking annotators. The annotation instructions defined the 3 label categories as:

• Normal tweets are those instances with no offensive, aggressive, insulting and profanity content.

• Abusive tweets are those instances that combine offensive, aggressive, insulting or profanity content.

• Hate tweets are those instances that: (a) contain an abusive language, (b) dedicate the abusive language towards a specific person or a group of people and (c) demean or dehumanize that person or that group of people based on their descriptive identity (race, gender, religion, disability, skin color, belief).

### Acknowledgements

We would like to acknowledge Hala Mulki for sharing this data.
Hala Mulki, Hatem Haddad, Chedi Bechikh Ali, Halima Alshabani, (2019), ""L-HSAB: A Levantine Twitter Dataset for Hate Speech and Abusive Language"", in Proceedings of the Third Workshop on Abusive Language Online, Florence, Italy, 2019, pp:111–118.

",.csv,True
Arabic Levantine Hate Speech Detection,2,arabic-levantine-hate-speech-detection,train.csv,CC0-1.0,"### Context

Twitter Dataset for Hate Speech dataset termed The Levantine Hate Speech and ABusive is the first Arabic Levantine Hate Speech and Abusive Language Dataset proposed in the 3rd Workshop ALW-2019 co-located with ACL-2019, Florence, Italy.

The volatile political/social atmosphere in Levantine-speaking countries, particularly, Syria and Lebanon, has been always associated with intensive online debates of toxic contents: Hate speech and abusive language. L-HSAB combines 5,846 Syrian/Lebanese political tweets labeled as normal, abusive or hate. Coping with hot political debates, the collected tweets were posted between March 2018 and February 2019.
The main classification aims are:
1- Binary Classification (Normal, Abusive):
2- Multi-Class Classification (Normal, Abusive, Hate):

### Content

The dataset is spiltted into train and test. The features are the tweet and the annotation (Normal, Abusive and Hate). Theannotation process was conducted by 3 Levantine-speaking annotators. The annotation instructions defined the 3 label categories as:

• Normal tweets are those instances with no offensive, aggressive, insulting and profanity content.

• Abusive tweets are those instances that combine offensive, aggressive, insulting or profanity content.

• Hate tweets are those instances that: (a) contain an abusive language, (b) dedicate the abusive language towards a specific person or a group of people and (c) demean or dehumanize that person or that group of people based on their descriptive identity (race, gender, religion, disability, skin color, belief).

### Acknowledgements

We would like to acknowledge Hala Mulki for sharing this data.
Hala Mulki, Hatem Haddad, Chedi Bechikh Ali, Halima Alshabani, (2019), ""L-HSAB: A Levantine Twitter Dataset for Hate Speech and Abusive Language"", in Proceedings of the Third Workshop on Abusive Language Online, Florence, Italy, 2019, pp:111–118.

",.csv,True
Association of Tennis Professionals Matches,18,atp-matches-dataset,atp_matches_2008.csv,CC-BY-NC-SA-4.0,"# Context 

A dataset of ATP matches including individual statistics.


# Content

In these datasets there are individual csv files for ATP tournament from 2000 to 2017.

The numbers in the last columns are absolute values, using them you can calculate percentages.

##Dataset legend

All the match statistics are in absolute number format, you can convert to percentages using the total point number

    ace = absolute number of aces
    df = number of double faults
    svpt = total serve points
    1stin = 1st serve in
    1st won = points won on 1st serve
    2ndwon = points won on 2nd serve
    SvGms = serve games
    bpSaved = break point saved
    bpFaced = break point faced

# Acknowledgement

Thanks to Jeff Sackmann for the excellent work. Be sure to visit his github profile

https://github.com/JeffSackmann/tennis_atp


# Inspiration

This dataset would be likely used to develop predictive modeling of tennis matches and to do statistic research. I'm planning to add historical odds and injuries data as soon as I have the time to get them.",.csv,True
Association of Tennis Professionals Matches,18,atp-matches-dataset,atp_matches_2009.csv,CC-BY-NC-SA-4.0,"# Context 

A dataset of ATP matches including individual statistics.


# Content

In these datasets there are individual csv files for ATP tournament from 2000 to 2017.

The numbers in the last columns are absolute values, using them you can calculate percentages.

##Dataset legend

All the match statistics are in absolute number format, you can convert to percentages using the total point number

    ace = absolute number of aces
    df = number of double faults
    svpt = total serve points
    1stin = 1st serve in
    1st won = points won on 1st serve
    2ndwon = points won on 2nd serve
    SvGms = serve games
    bpSaved = break point saved
    bpFaced = break point faced

# Acknowledgement

Thanks to Jeff Sackmann for the excellent work. Be sure to visit his github profile

https://github.com/JeffSackmann/tennis_atp


# Inspiration

This dataset would be likely used to develop predictive modeling of tennis matches and to do statistic research. I'm planning to add historical odds and injuries data as soon as I have the time to get them.",.csv,True
Association of Tennis Professionals Matches,18,atp-matches-dataset,atp_matches_2010.csv,CC-BY-NC-SA-4.0,"# Context 

A dataset of ATP matches including individual statistics.


# Content

In these datasets there are individual csv files for ATP tournament from 2000 to 2017.

The numbers in the last columns are absolute values, using them you can calculate percentages.

##Dataset legend

All the match statistics are in absolute number format, you can convert to percentages using the total point number

    ace = absolute number of aces
    df = number of double faults
    svpt = total serve points
    1stin = 1st serve in
    1st won = points won on 1st serve
    2ndwon = points won on 2nd serve
    SvGms = serve games
    bpSaved = break point saved
    bpFaced = break point faced

# Acknowledgement

Thanks to Jeff Sackmann for the excellent work. Be sure to visit his github profile

https://github.com/JeffSackmann/tennis_atp


# Inspiration

This dataset would be likely used to develop predictive modeling of tennis matches and to do statistic research. I'm planning to add historical odds and injuries data as soon as I have the time to get them.",.csv,True
Association of Tennis Professionals Matches,18,atp-matches-dataset,atp_matches_2004.csv,CC-BY-NC-SA-4.0,"# Context 

A dataset of ATP matches including individual statistics.


# Content

In these datasets there are individual csv files for ATP tournament from 2000 to 2017.

The numbers in the last columns are absolute values, using them you can calculate percentages.

##Dataset legend

All the match statistics are in absolute number format, you can convert to percentages using the total point number

    ace = absolute number of aces
    df = number of double faults
    svpt = total serve points
    1stin = 1st serve in
    1st won = points won on 1st serve
    2ndwon = points won on 2nd serve
    SvGms = serve games
    bpSaved = break point saved
    bpFaced = break point faced

# Acknowledgement

Thanks to Jeff Sackmann for the excellent work. Be sure to visit his github profile

https://github.com/JeffSackmann/tennis_atp


# Inspiration

This dataset would be likely used to develop predictive modeling of tennis matches and to do statistic research. I'm planning to add historical odds and injuries data as soon as I have the time to get them.",.csv,True
Association of Tennis Professionals Matches,18,atp-matches-dataset,atp_matches_2005.csv,CC-BY-NC-SA-4.0,"# Context 

A dataset of ATP matches including individual statistics.


# Content

In these datasets there are individual csv files for ATP tournament from 2000 to 2017.

The numbers in the last columns are absolute values, using them you can calculate percentages.

##Dataset legend

All the match statistics are in absolute number format, you can convert to percentages using the total point number

    ace = absolute number of aces
    df = number of double faults
    svpt = total serve points
    1stin = 1st serve in
    1st won = points won on 1st serve
    2ndwon = points won on 2nd serve
    SvGms = serve games
    bpSaved = break point saved
    bpFaced = break point faced

# Acknowledgement

Thanks to Jeff Sackmann for the excellent work. Be sure to visit his github profile

https://github.com/JeffSackmann/tennis_atp


# Inspiration

This dataset would be likely used to develop predictive modeling of tennis matches and to do statistic research. I'm planning to add historical odds and injuries data as soon as I have the time to get them.",.csv,True
Association of Tennis Professionals Matches,18,atp-matches-dataset,atp_matches_2011.csv,CC-BY-NC-SA-4.0,"# Context 

A dataset of ATP matches including individual statistics.


# Content

In these datasets there are individual csv files for ATP tournament from 2000 to 2017.

The numbers in the last columns are absolute values, using them you can calculate percentages.

##Dataset legend

All the match statistics are in absolute number format, you can convert to percentages using the total point number

    ace = absolute number of aces
    df = number of double faults
    svpt = total serve points
    1stin = 1st serve in
    1st won = points won on 1st serve
    2ndwon = points won on 2nd serve
    SvGms = serve games
    bpSaved = break point saved
    bpFaced = break point faced

# Acknowledgement

Thanks to Jeff Sackmann for the excellent work. Be sure to visit his github profile

https://github.com/JeffSackmann/tennis_atp


# Inspiration

This dataset would be likely used to develop predictive modeling of tennis matches and to do statistic research. I'm planning to add historical odds and injuries data as soon as I have the time to get them.",.csv,True
Association of Tennis Professionals Matches,18,atp-matches-dataset,atp_matches_2007.csv,CC-BY-NC-SA-4.0,"# Context 

A dataset of ATP matches including individual statistics.


# Content

In these datasets there are individual csv files for ATP tournament from 2000 to 2017.

The numbers in the last columns are absolute values, using them you can calculate percentages.

##Dataset legend

All the match statistics are in absolute number format, you can convert to percentages using the total point number

    ace = absolute number of aces
    df = number of double faults
    svpt = total serve points
    1stin = 1st serve in
    1st won = points won on 1st serve
    2ndwon = points won on 2nd serve
    SvGms = serve games
    bpSaved = break point saved
    bpFaced = break point faced

# Acknowledgement

Thanks to Jeff Sackmann for the excellent work. Be sure to visit his github profile

https://github.com/JeffSackmann/tennis_atp


# Inspiration

This dataset would be likely used to develop predictive modeling of tennis matches and to do statistic research. I'm planning to add historical odds and injuries data as soon as I have the time to get them.",.csv,True
Association of Tennis Professionals Matches,18,atp-matches-dataset,atp_matches_2013.csv,CC-BY-NC-SA-4.0,"# Context 

A dataset of ATP matches including individual statistics.


# Content

In these datasets there are individual csv files for ATP tournament from 2000 to 2017.

The numbers in the last columns are absolute values, using them you can calculate percentages.

##Dataset legend

All the match statistics are in absolute number format, you can convert to percentages using the total point number

    ace = absolute number of aces
    df = number of double faults
    svpt = total serve points
    1stin = 1st serve in
    1st won = points won on 1st serve
    2ndwon = points won on 2nd serve
    SvGms = serve games
    bpSaved = break point saved
    bpFaced = break point faced

# Acknowledgement

Thanks to Jeff Sackmann for the excellent work. Be sure to visit his github profile

https://github.com/JeffSackmann/tennis_atp


# Inspiration

This dataset would be likely used to develop predictive modeling of tennis matches and to do statistic research. I'm planning to add historical odds and injuries data as soon as I have the time to get them.",.csv,True
Association of Tennis Professionals Matches,18,atp-matches-dataset,atp_matches_2012.csv,CC-BY-NC-SA-4.0,"# Context 

A dataset of ATP matches including individual statistics.


# Content

In these datasets there are individual csv files for ATP tournament from 2000 to 2017.

The numbers in the last columns are absolute values, using them you can calculate percentages.

##Dataset legend

All the match statistics are in absolute number format, you can convert to percentages using the total point number

    ace = absolute number of aces
    df = number of double faults
    svpt = total serve points
    1stin = 1st serve in
    1st won = points won on 1st serve
    2ndwon = points won on 2nd serve
    SvGms = serve games
    bpSaved = break point saved
    bpFaced = break point faced

# Acknowledgement

Thanks to Jeff Sackmann for the excellent work. Be sure to visit his github profile

https://github.com/JeffSackmann/tennis_atp


# Inspiration

This dataset would be likely used to develop predictive modeling of tennis matches and to do statistic research. I'm planning to add historical odds and injuries data as soon as I have the time to get them.",.csv,True
Association of Tennis Professionals Matches,18,atp-matches-dataset,atp_matches_2006.csv,CC-BY-NC-SA-4.0,"# Context 

A dataset of ATP matches including individual statistics.


# Content

In these datasets there are individual csv files for ATP tournament from 2000 to 2017.

The numbers in the last columns are absolute values, using them you can calculate percentages.

##Dataset legend

All the match statistics are in absolute number format, you can convert to percentages using the total point number

    ace = absolute number of aces
    df = number of double faults
    svpt = total serve points
    1stin = 1st serve in
    1st won = points won on 1st serve
    2ndwon = points won on 2nd serve
    SvGms = serve games
    bpSaved = break point saved
    bpFaced = break point faced

# Acknowledgement

Thanks to Jeff Sackmann for the excellent work. Be sure to visit his github profile

https://github.com/JeffSackmann/tennis_atp


# Inspiration

This dataset would be likely used to develop predictive modeling of tennis matches and to do statistic research. I'm planning to add historical odds and injuries data as soon as I have the time to get them.",.csv,True
Association of Tennis Professionals Matches,18,atp-matches-dataset,atp_matches_2002.csv,CC-BY-NC-SA-4.0,"# Context 

A dataset of ATP matches including individual statistics.


# Content

In these datasets there are individual csv files for ATP tournament from 2000 to 2017.

The numbers in the last columns are absolute values, using them you can calculate percentages.

##Dataset legend

All the match statistics are in absolute number format, you can convert to percentages using the total point number

    ace = absolute number of aces
    df = number of double faults
    svpt = total serve points
    1stin = 1st serve in
    1st won = points won on 1st serve
    2ndwon = points won on 2nd serve
    SvGms = serve games
    bpSaved = break point saved
    bpFaced = break point faced

# Acknowledgement

Thanks to Jeff Sackmann for the excellent work. Be sure to visit his github profile

https://github.com/JeffSackmann/tennis_atp


# Inspiration

This dataset would be likely used to develop predictive modeling of tennis matches and to do statistic research. I'm planning to add historical odds and injuries data as soon as I have the time to get them.",.csv,True
Association of Tennis Professionals Matches,18,atp-matches-dataset,atp_matches_2016.csv,CC-BY-NC-SA-4.0,"# Context 

A dataset of ATP matches including individual statistics.


# Content

In these datasets there are individual csv files for ATP tournament from 2000 to 2017.

The numbers in the last columns are absolute values, using them you can calculate percentages.

##Dataset legend

All the match statistics are in absolute number format, you can convert to percentages using the total point number

    ace = absolute number of aces
    df = number of double faults
    svpt = total serve points
    1stin = 1st serve in
    1st won = points won on 1st serve
    2ndwon = points won on 2nd serve
    SvGms = serve games
    bpSaved = break point saved
    bpFaced = break point faced

# Acknowledgement

Thanks to Jeff Sackmann for the excellent work. Be sure to visit his github profile

https://github.com/JeffSackmann/tennis_atp


# Inspiration

This dataset would be likely used to develop predictive modeling of tennis matches and to do statistic research. I'm planning to add historical odds and injuries data as soon as I have the time to get them.",.csv,True
Association of Tennis Professionals Matches,18,atp-matches-dataset,atp_matches_2017.csv,CC-BY-NC-SA-4.0,"# Context 

A dataset of ATP matches including individual statistics.


# Content

In these datasets there are individual csv files for ATP tournament from 2000 to 2017.

The numbers in the last columns are absolute values, using them you can calculate percentages.

##Dataset legend

All the match statistics are in absolute number format, you can convert to percentages using the total point number

    ace = absolute number of aces
    df = number of double faults
    svpt = total serve points
    1stin = 1st serve in
    1st won = points won on 1st serve
    2ndwon = points won on 2nd serve
    SvGms = serve games
    bpSaved = break point saved
    bpFaced = break point faced

# Acknowledgement

Thanks to Jeff Sackmann for the excellent work. Be sure to visit his github profile

https://github.com/JeffSackmann/tennis_atp


# Inspiration

This dataset would be likely used to develop predictive modeling of tennis matches and to do statistic research. I'm planning to add historical odds and injuries data as soon as I have the time to get them.",.csv,True
Association of Tennis Professionals Matches,18,atp-matches-dataset,atp_matches_2003.csv,CC-BY-NC-SA-4.0,"# Context 

A dataset of ATP matches including individual statistics.


# Content

In these datasets there are individual csv files for ATP tournament from 2000 to 2017.

The numbers in the last columns are absolute values, using them you can calculate percentages.

##Dataset legend

All the match statistics are in absolute number format, you can convert to percentages using the total point number

    ace = absolute number of aces
    df = number of double faults
    svpt = total serve points
    1stin = 1st serve in
    1st won = points won on 1st serve
    2ndwon = points won on 2nd serve
    SvGms = serve games
    bpSaved = break point saved
    bpFaced = break point faced

# Acknowledgement

Thanks to Jeff Sackmann for the excellent work. Be sure to visit his github profile

https://github.com/JeffSackmann/tennis_atp


# Inspiration

This dataset would be likely used to develop predictive modeling of tennis matches and to do statistic research. I'm planning to add historical odds and injuries data as soon as I have the time to get them.",.csv,True
Association of Tennis Professionals Matches,18,atp-matches-dataset,atp_matches_2015.csv,CC-BY-NC-SA-4.0,"# Context 

A dataset of ATP matches including individual statistics.


# Content

In these datasets there are individual csv files for ATP tournament from 2000 to 2017.

The numbers in the last columns are absolute values, using them you can calculate percentages.

##Dataset legend

All the match statistics are in absolute number format, you can convert to percentages using the total point number

    ace = absolute number of aces
    df = number of double faults
    svpt = total serve points
    1stin = 1st serve in
    1st won = points won on 1st serve
    2ndwon = points won on 2nd serve
    SvGms = serve games
    bpSaved = break point saved
    bpFaced = break point faced

# Acknowledgement

Thanks to Jeff Sackmann for the excellent work. Be sure to visit his github profile

https://github.com/JeffSackmann/tennis_atp


# Inspiration

This dataset would be likely used to develop predictive modeling of tennis matches and to do statistic research. I'm planning to add historical odds and injuries data as soon as I have the time to get them.",.csv,True
Association of Tennis Professionals Matches,18,atp-matches-dataset,atp_matches_2001.csv,CC-BY-NC-SA-4.0,"# Context 

A dataset of ATP matches including individual statistics.


# Content

In these datasets there are individual csv files for ATP tournament from 2000 to 2017.

The numbers in the last columns are absolute values, using them you can calculate percentages.

##Dataset legend

All the match statistics are in absolute number format, you can convert to percentages using the total point number

    ace = absolute number of aces
    df = number of double faults
    svpt = total serve points
    1stin = 1st serve in
    1st won = points won on 1st serve
    2ndwon = points won on 2nd serve
    SvGms = serve games
    bpSaved = break point saved
    bpFaced = break point faced

# Acknowledgement

Thanks to Jeff Sackmann for the excellent work. Be sure to visit his github profile

https://github.com/JeffSackmann/tennis_atp


# Inspiration

This dataset would be likely used to develop predictive modeling of tennis matches and to do statistic research. I'm planning to add historical odds and injuries data as soon as I have the time to get them.",.csv,True
Association of Tennis Professionals Matches,18,atp-matches-dataset,atp_matches_2000.csv,CC-BY-NC-SA-4.0,"# Context 

A dataset of ATP matches including individual statistics.


# Content

In these datasets there are individual csv files for ATP tournament from 2000 to 2017.

The numbers in the last columns are absolute values, using them you can calculate percentages.

##Dataset legend

All the match statistics are in absolute number format, you can convert to percentages using the total point number

    ace = absolute number of aces
    df = number of double faults
    svpt = total serve points
    1stin = 1st serve in
    1st won = points won on 1st serve
    2ndwon = points won on 2nd serve
    SvGms = serve games
    bpSaved = break point saved
    bpFaced = break point faced

# Acknowledgement

Thanks to Jeff Sackmann for the excellent work. Be sure to visit his github profile

https://github.com/JeffSackmann/tennis_atp


# Inspiration

This dataset would be likely used to develop predictive modeling of tennis matches and to do statistic research. I'm planning to add historical odds and injuries data as soon as I have the time to get them.",.csv,True
Association of Tennis Professionals Matches,18,atp-matches-dataset,atp_matches_2014.csv,CC-BY-NC-SA-4.0,"# Context 

A dataset of ATP matches including individual statistics.


# Content

In these datasets there are individual csv files for ATP tournament from 2000 to 2017.

The numbers in the last columns are absolute values, using them you can calculate percentages.

##Dataset legend

All the match statistics are in absolute number format, you can convert to percentages using the total point number

    ace = absolute number of aces
    df = number of double faults
    svpt = total serve points
    1stin = 1st serve in
    1st won = points won on 1st serve
    2ndwon = points won on 2nd serve
    SvGms = serve games
    bpSaved = break point saved
    bpFaced = break point faced

# Acknowledgement

Thanks to Jeff Sackmann for the excellent work. Be sure to visit his github profile

https://github.com/JeffSackmann/tennis_atp


# Inspiration

This dataset would be likely used to develop predictive modeling of tennis matches and to do statistic research. I'm planning to add historical odds and injuries data as soon as I have the time to get them.",.csv,True
BD-SHS,3,bdshs,val.csv,Attribution 4.0 International (CC BY 4.0),"## BD-SHS: A Benchmark Dataset for Learning to Detect Online Bangla Hate Speech in Different Social Contexts
**LREC 2022**

For more detail, you can check [our paper.](http://www.lrec-conf.org/proceedings/lrec2022/pdf/2022.lrec-1.552.pdf)

For codes and other information, you can the [official our github repo](https://github.com/naurosromim/hate-speech-dataset-for-Bengali-social-media)

## Dataset details
**abbreviations used:**

`HS` =&gt; `hate speech`

`NH` =&gt; `not hate speech`

`ind` =&gt; `Individual`

| Task  | Task description    | # labels | Labels                                            | Nature of classification |
| ----- | ------------------- | -------- | ------------------------------------------------- | ------------------------ |
| TaskA | HS detection        | 02       | `HS`, `NH`                                        | Binary (HS or NH)        |
| TaskB | HS target detection | 04       | `ind`, `male`, `female`, `group`                  | Multilabel               |
| TaskC | HS type detection   | 04       | `slander`, `religion`, `gender`, `callToViolence` | Multilabel               |

## Bibtex

```
@InProceedings{romim-EtAl:2022:LREC,
  author    = {Romim, Nauros  and  Ahmed, Mosahed  and  Islam, Md Saiful  and  Sen Sharma, Arnab  and  Talukder, Hriteshwar  and  Amin, Mohammad Ruhul},
  title     = {BD-SHS: A Benchmark Dataset for Learning to Detect Online Bangla Hate Speech in Different Social Contexts},
  booktitle      = {Proceedings of the Language Resources and Evaluation Conference},
  month          = {June},
  year           = {2022},
  address        = {Marseille, France},
  publisher      = {European Language Resources Association},
  pages     = {5153--5162},
  abstract  = {Social media platforms and online streaming services have spawned a new breed of Hate Speech (HS). Due to the massive amount of user-generated content on these sites, modern machine learning techniques are found to be feasible and cost-effective to tackle this problem. However, linguistically diverse datasets covering different social contexts in which offensive language is typically used are required to train generalizable models. In this paper, we identify the shortcomings of existing Bangla HS datasets and introduce a large manually labeled dataset BD-SHS that includes HS in different social contexts. The labeling criteria were prepared following a hierarchical annotation process, which is the first of its kind in Bangla HS to the best of our knowledge. The dataset includes more than 50,200 offensive comments crawled from online social networking sites and is at least 60\% larger than any existing Bangla HS datasets. We present the benchmark result of our dataset by training different NLP models resulting in the best one achieving an F1-score of 91.0\%. In our experiments, we found that a word embedding trained exclusively using 1.47 million comments from social media and streaming sites consistently resulted in better modeling of HS detection in comparison to other pre-trained embeddings. Our dataset and all accompanying codes is publicly available at github.com/naurosromim/hate-speech-dataset-for-Bengali-social-media},
  url       = {https://aclanthology.org/2022.lrec-1.552}
}

```",.csv,True
BD-SHS,3,bdshs,test.csv,Attribution 4.0 International (CC BY 4.0),"## BD-SHS: A Benchmark Dataset for Learning to Detect Online Bangla Hate Speech in Different Social Contexts
**LREC 2022**

For more detail, you can check [our paper.](http://www.lrec-conf.org/proceedings/lrec2022/pdf/2022.lrec-1.552.pdf)

For codes and other information, you can the [official our github repo](https://github.com/naurosromim/hate-speech-dataset-for-Bengali-social-media)

## Dataset details
**abbreviations used:**

`HS` =&gt; `hate speech`

`NH` =&gt; `not hate speech`

`ind` =&gt; `Individual`

| Task  | Task description    | # labels | Labels                                            | Nature of classification |
| ----- | ------------------- | -------- | ------------------------------------------------- | ------------------------ |
| TaskA | HS detection        | 02       | `HS`, `NH`                                        | Binary (HS or NH)        |
| TaskB | HS target detection | 04       | `ind`, `male`, `female`, `group`                  | Multilabel               |
| TaskC | HS type detection   | 04       | `slander`, `religion`, `gender`, `callToViolence` | Multilabel               |

## Bibtex

```
@InProceedings{romim-EtAl:2022:LREC,
  author    = {Romim, Nauros  and  Ahmed, Mosahed  and  Islam, Md Saiful  and  Sen Sharma, Arnab  and  Talukder, Hriteshwar  and  Amin, Mohammad Ruhul},
  title     = {BD-SHS: A Benchmark Dataset for Learning to Detect Online Bangla Hate Speech in Different Social Contexts},
  booktitle      = {Proceedings of the Language Resources and Evaluation Conference},
  month          = {June},
  year           = {2022},
  address        = {Marseille, France},
  publisher      = {European Language Resources Association},
  pages     = {5153--5162},
  abstract  = {Social media platforms and online streaming services have spawned a new breed of Hate Speech (HS). Due to the massive amount of user-generated content on these sites, modern machine learning techniques are found to be feasible and cost-effective to tackle this problem. However, linguistically diverse datasets covering different social contexts in which offensive language is typically used are required to train generalizable models. In this paper, we identify the shortcomings of existing Bangla HS datasets and introduce a large manually labeled dataset BD-SHS that includes HS in different social contexts. The labeling criteria were prepared following a hierarchical annotation process, which is the first of its kind in Bangla HS to the best of our knowledge. The dataset includes more than 50,200 offensive comments crawled from online social networking sites and is at least 60\% larger than any existing Bangla HS datasets. We present the benchmark result of our dataset by training different NLP models resulting in the best one achieving an F1-score of 91.0\%. In our experiments, we found that a word embedding trained exclusively using 1.47 million comments from social media and streaming sites consistently resulted in better modeling of HS detection in comparison to other pre-trained embeddings. Our dataset and all accompanying codes is publicly available at github.com/naurosromim/hate-speech-dataset-for-Bengali-social-media},
  url       = {https://aclanthology.org/2022.lrec-1.552}
}

```",.csv,True
BD-SHS,3,bdshs,train.csv,Attribution 4.0 International (CC BY 4.0),"## BD-SHS: A Benchmark Dataset for Learning to Detect Online Bangla Hate Speech in Different Social Contexts
**LREC 2022**

For more detail, you can check [our paper.](http://www.lrec-conf.org/proceedings/lrec2022/pdf/2022.lrec-1.552.pdf)

For codes and other information, you can the [official our github repo](https://github.com/naurosromim/hate-speech-dataset-for-Bengali-social-media)

## Dataset details
**abbreviations used:**

`HS` =&gt; `hate speech`

`NH` =&gt; `not hate speech`

`ind` =&gt; `Individual`

| Task  | Task description    | # labels | Labels                                            | Nature of classification |
| ----- | ------------------- | -------- | ------------------------------------------------- | ------------------------ |
| TaskA | HS detection        | 02       | `HS`, `NH`                                        | Binary (HS or NH)        |
| TaskB | HS target detection | 04       | `ind`, `male`, `female`, `group`                  | Multilabel               |
| TaskC | HS type detection   | 04       | `slander`, `religion`, `gender`, `callToViolence` | Multilabel               |

## Bibtex

```
@InProceedings{romim-EtAl:2022:LREC,
  author    = {Romim, Nauros  and  Ahmed, Mosahed  and  Islam, Md Saiful  and  Sen Sharma, Arnab  and  Talukder, Hriteshwar  and  Amin, Mohammad Ruhul},
  title     = {BD-SHS: A Benchmark Dataset for Learning to Detect Online Bangla Hate Speech in Different Social Contexts},
  booktitle      = {Proceedings of the Language Resources and Evaluation Conference},
  month          = {June},
  year           = {2022},
  address        = {Marseille, France},
  publisher      = {European Language Resources Association},
  pages     = {5153--5162},
  abstract  = {Social media platforms and online streaming services have spawned a new breed of Hate Speech (HS). Due to the massive amount of user-generated content on these sites, modern machine learning techniques are found to be feasible and cost-effective to tackle this problem. However, linguistically diverse datasets covering different social contexts in which offensive language is typically used are required to train generalizable models. In this paper, we identify the shortcomings of existing Bangla HS datasets and introduce a large manually labeled dataset BD-SHS that includes HS in different social contexts. The labeling criteria were prepared following a hierarchical annotation process, which is the first of its kind in Bangla HS to the best of our knowledge. The dataset includes more than 50,200 offensive comments crawled from online social networking sites and is at least 60\% larger than any existing Bangla HS datasets. We present the benchmark result of our dataset by training different NLP models resulting in the best one achieving an F1-score of 91.0\%. In our experiments, we found that a word embedding trained exclusively using 1.47 million comments from social media and streaming sites consistently resulted in better modeling of HS detection in comparison to other pre-trained embeddings. Our dataset and all accompanying codes is publicly available at github.com/naurosromim/hate-speech-dataset-for-Bengali-social-media},
  url       = {https://aclanthology.org/2022.lrec-1.552}
}

```",.csv,True
BLE RSSI Dataset for Indoor localization,2,ble-rssi-dataset,iBeacon_RSSI_Labeled.csv,CC-BY-NC-SA-4.0,"### Content

The dataset was created using the RSSI readings of an array of 13 ibeacons in the first floor of Waldo Library, Western Michigan University. Data was collected using iPhone 6S. The dataset contains two sub-datasets: a labeled dataset (1420 instances) and an unlabeled dataset (5191 instances). The recording was performed during the operational hours of the library. For the labeled dataset, the input data contains the location (label column), a timestamp, followed by RSSI readings of 13 iBeacons. RSSI measurements are negative values. Bigger RSSI values indicate closer proximity to a given iBeacon (e.g., RSSI of -65 represent a closer distance to a given iBeacon compared to RSSI of -85). For out-of-range iBeacons, the RSSI is indicated by -200. The locations related to RSSI readings are combined in one column consisting a letter for the column and a number for the row of the position. The following figure depicts the layout of the iBeacons as well as the arrange of locations. 

![iBeacons Layout](https://www.kaggle.com/mehdimka/ble-rssi-dataset/downloads/iBeacon_Layout.jpg)

### Attribute Information

 - location: The location of receiving RSSIs from ibeacons b3001 to b3013; symbolic values showing the column and row of the location on the map (e.g., A01 stands for column A, row 1). 
 - date: Datetime in the format of ‘d-m-yyyy hh:mm:ss’
 - b3001 - b3013: RSSI readings corresponding to the iBeacons; numeric, integers only.

### Acknowledgements
Provider:
Mehdi Mohammadi and Ala Al-Fuqaha, {mehdi.mohammadi, ala-alfuqaha}@wmich.edu,
Department of Computer Science,
Western Michigan University

Citation Request:

M. Mohammadi, A. Al-Fuqaha, M. Guizani, J. Oh, “Semi-supervised Deep Reinforcement Learning in Support of IoT and Smart City Services,” IEEE Internet of Things Journal, Vol. PP, No. 99, 2017.

### Inspiration

#### How unlabeled data can help for an improved learning system. How a GAN model can synthesizes viable paths based on the little labeled data and larger set of unlabeled data.  ",.csv,True
BLE RSSI Dataset for Indoor localization,2,ble-rssi-dataset,iBeacon_RSSI_Unlabeled.csv,CC-BY-NC-SA-4.0,"### Content

The dataset was created using the RSSI readings of an array of 13 ibeacons in the first floor of Waldo Library, Western Michigan University. Data was collected using iPhone 6S. The dataset contains two sub-datasets: a labeled dataset (1420 instances) and an unlabeled dataset (5191 instances). The recording was performed during the operational hours of the library. For the labeled dataset, the input data contains the location (label column), a timestamp, followed by RSSI readings of 13 iBeacons. RSSI measurements are negative values. Bigger RSSI values indicate closer proximity to a given iBeacon (e.g., RSSI of -65 represent a closer distance to a given iBeacon compared to RSSI of -85). For out-of-range iBeacons, the RSSI is indicated by -200. The locations related to RSSI readings are combined in one column consisting a letter for the column and a number for the row of the position. The following figure depicts the layout of the iBeacons as well as the arrange of locations. 

![iBeacons Layout](https://www.kaggle.com/mehdimka/ble-rssi-dataset/downloads/iBeacon_Layout.jpg)

### Attribute Information

 - location: The location of receiving RSSIs from ibeacons b3001 to b3013; symbolic values showing the column and row of the location on the map (e.g., A01 stands for column A, row 1). 
 - date: Datetime in the format of ‘d-m-yyyy hh:mm:ss’
 - b3001 - b3013: RSSI readings corresponding to the iBeacons; numeric, integers only.

### Acknowledgements
Provider:
Mehdi Mohammadi and Ala Al-Fuqaha, {mehdi.mohammadi, ala-alfuqaha}@wmich.edu,
Department of Computer Science,
Western Michigan University

Citation Request:

M. Mohammadi, A. Al-Fuqaha, M. Guizani, J. Oh, “Semi-supervised Deep Reinforcement Learning in Support of IoT and Smart City Services,” IEEE Internet of Things Journal, Vol. PP, No. 99, 2017.

### Inspiration

#### How unlabeled data can help for an improved learning system. How a GAN model can synthesizes viable paths based on the little labeled data and larger set of unlabeled data.  ",.csv,True
BTS Lyrics and Spotify Data,8,bts-lyrics,jungkook_v13.csv,CC0-1.0,"Contains and English translated lyrics and Spotify audio features data for BTS songs.

# Context
The dataset was collated mainly data from [Genius](https://genius.com), [Big Hit](https://ibighit.com/bts/eng/discography/) and Spotify. 


# About The Data
* There are files for songs by BTS as a group and songs by each individual BTS member (solos). 
* Refer to `info.md` file for more information on the columns and included albums 


# Acknowlegement
Lyrics from Genius unless otherwise stated. 

Spotify data are in columns prefixed with `spotify_`

[Banner and thumbnail image from GQ Australia](https://www.gq.com.au/culture/entertainment/bts-gq-interviews/image-gallery/7f14c79be8ac58febb72eacc7db0109b)",.csv,True
BTS Lyrics and Spotify Data,8,bts-lyrics,jhope_v13.csv,CC0-1.0,"Contains and English translated lyrics and Spotify audio features data for BTS songs.

# Context
The dataset was collated mainly data from [Genius](https://genius.com), [Big Hit](https://ibighit.com/bts/eng/discography/) and Spotify. 


# About The Data
* There are files for songs by BTS as a group and songs by each individual BTS member (solos). 
* Refer to `info.md` file for more information on the columns and included albums 


# Acknowlegement
Lyrics from Genius unless otherwise stated. 

Spotify data are in columns prefixed with `spotify_`

[Banner and thumbnail image from GQ Australia](https://www.gq.com.au/culture/entertainment/bts-gq-interviews/image-gallery/7f14c79be8ac58febb72eacc7db0109b)",.csv,True
BTS Lyrics and Spotify Data,8,bts-lyrics,jimin_v13.csv,CC0-1.0,"Contains and English translated lyrics and Spotify audio features data for BTS songs.

# Context
The dataset was collated mainly data from [Genius](https://genius.com), [Big Hit](https://ibighit.com/bts/eng/discography/) and Spotify. 


# About The Data
* There are files for songs by BTS as a group and songs by each individual BTS member (solos). 
* Refer to `info.md` file for more information on the columns and included albums 


# Acknowlegement
Lyrics from Genius unless otherwise stated. 

Spotify data are in columns prefixed with `spotify_`

[Banner and thumbnail image from GQ Australia](https://www.gq.com.au/culture/entertainment/bts-gq-interviews/image-gallery/7f14c79be8ac58febb72eacc7db0109b)",.csv,True
BTS Lyrics and Spotify Data,8,bts-lyrics,suga_v13.csv,CC0-1.0,"Contains and English translated lyrics and Spotify audio features data for BTS songs.

# Context
The dataset was collated mainly data from [Genius](https://genius.com), [Big Hit](https://ibighit.com/bts/eng/discography/) and Spotify. 


# About The Data
* There are files for songs by BTS as a group and songs by each individual BTS member (solos). 
* Refer to `info.md` file for more information on the columns and included albums 


# Acknowlegement
Lyrics from Genius unless otherwise stated. 

Spotify data are in columns prefixed with `spotify_`

[Banner and thumbnail image from GQ Australia](https://www.gq.com.au/culture/entertainment/bts-gq-interviews/image-gallery/7f14c79be8ac58febb72eacc7db0109b)",.csv,True
BTS Lyrics and Spotify Data,8,bts-lyrics,v_v13.csv,CC0-1.0,"Contains and English translated lyrics and Spotify audio features data for BTS songs.

# Context
The dataset was collated mainly data from [Genius](https://genius.com), [Big Hit](https://ibighit.com/bts/eng/discography/) and Spotify. 


# About The Data
* There are files for songs by BTS as a group and songs by each individual BTS member (solos). 
* Refer to `info.md` file for more information on the columns and included albums 


# Acknowlegement
Lyrics from Genius unless otherwise stated. 

Spotify data are in columns prefixed with `spotify_`

[Banner and thumbnail image from GQ Australia](https://www.gq.com.au/culture/entertainment/bts-gq-interviews/image-gallery/7f14c79be8ac58febb72eacc7db0109b)",.csv,True
BTS Lyrics and Spotify Data,8,bts-lyrics,jin_v13.csv,CC0-1.0,"Contains and English translated lyrics and Spotify audio features data for BTS songs.

# Context
The dataset was collated mainly data from [Genius](https://genius.com), [Big Hit](https://ibighit.com/bts/eng/discography/) and Spotify. 


# About The Data
* There are files for songs by BTS as a group and songs by each individual BTS member (solos). 
* Refer to `info.md` file for more information on the columns and included albums 


# Acknowlegement
Lyrics from Genius unless otherwise stated. 

Spotify data are in columns prefixed with `spotify_`

[Banner and thumbnail image from GQ Australia](https://www.gq.com.au/culture/entertainment/bts-gq-interviews/image-gallery/7f14c79be8ac58febb72eacc7db0109b)",.csv,True
BTS Lyrics and Spotify Data,8,bts-lyrics,rm_v13.csv,CC0-1.0,"Contains and English translated lyrics and Spotify audio features data for BTS songs.

# Context
The dataset was collated mainly data from [Genius](https://genius.com), [Big Hit](https://ibighit.com/bts/eng/discography/) and Spotify. 


# About The Data
* There are files for songs by BTS as a group and songs by each individual BTS member (solos). 
* Refer to `info.md` file for more information on the columns and included albums 


# Acknowlegement
Lyrics from Genius unless otherwise stated. 

Spotify data are in columns prefixed with `spotify_`

[Banner and thumbnail image from GQ Australia](https://www.gq.com.au/culture/entertainment/bts-gq-interviews/image-gallery/7f14c79be8ac58febb72eacc7db0109b)",.csv,True
BTS Lyrics and Spotify Data,8,bts-lyrics,bts_v13.csv,CC0-1.0,"Contains and English translated lyrics and Spotify audio features data for BTS songs.

# Context
The dataset was collated mainly data from [Genius](https://genius.com), [Big Hit](https://ibighit.com/bts/eng/discography/) and Spotify. 


# About The Data
* There are files for songs by BTS as a group and songs by each individual BTS member (solos). 
* Refer to `info.md` file for more information on the columns and included albums 


# Acknowlegement
Lyrics from Genius unless otherwise stated. 

Spotify data are in columns prefixed with `spotify_`

[Banner and thumbnail image from GQ Australia](https://www.gq.com.au/culture/entertainment/bts-gq-interviews/image-gallery/7f14c79be8ac58febb72eacc7db0109b)",.csv,True
Bangladesh Weather Dataset (1901 - 2023),2,bangladesh-weather-dataset,sorted_temp_and_rain_dataset.csv,Attribution 4.0 International (CC BY 4.0),"# 📊 Dataset README (Updated with Temporal Coverage) 📈

## Overview 🌐

This README document provides detailed information about a dataset that combines temperature 🌡️ and rainfall 🌧️ data. The temperature data is sourced from NASA's POWER Project, and the rainfall data is obtained from the Humanitarian Data Exchange (HDX) website, specifically focusing on Bangladesh rainfall data.

### Temperature Data Source 🔥

- **Source**: NASA's POWER (Prediction of Worldwide Energy Resources) Data Access Viewer
- **URL**: [NASA POWER Data Access Viewer](https://power.larc.nasa.gov/data-access-viewer/)
- **Description**: The POWER Project provides solar and meteorological data sets, primarily intended for renewable energy, sustainable buildings, agriculture, and other related applications. The temperature data from this source is a part of NASA's global meteorological data.

### Rainfall Data Source 🌧️

- **Source**: Humanitarian Data Exchange (HDX)
- **URL**: [Bangladesh Rainfall Data - HDX](https://data.humdata.org/dataset/bgd-rainfall-subnational)
- **Description**: HDX hosts various humanitarian data including climate and weather-related datasets. The rainfall data for Bangladesh is part of their collection, providing detailed subnational rainfall statistics.

## Dataset Description 📝

### Composition 📊

The dataset is a combination of the temperature and rainfall data, aligned by date to facilitate joint analysis. The key components are:

- **Temperature Data (`tem`)**: Represents the monthly average temperature, presumably in degrees Celsius.
- **Rainfall Data (`rain`)**: Indicates monthly total rainfall, presumably measured in millimeters.

### Structure 🏗️

The dataset is structured into a CSV file with the following columns:

- `tem`: Average temperature for the month.
- `Month`: The month for the data point, ranging from 1 (January) to 12 (December).
- `Year`: The year of the data point.
- `rain`: Total rainfall for the month.

### Temporal Coverage 📆

- **Earliest Date**: 1901
- **Latest Date**: 2023
- This dataset provides a historical perspective on climate trends from the earliest year of 1901 to the most recent data available up to 2023.

### Usage and Applications 🚀

This dataset is particularly useful for studying climatic patterns, seasonal changes, and long-term climate trends. Applications include but are not limited to:

- Climatological research and climate change studies.
- Agricultural planning and forecasting.
- Environmental and ecological studies.
- Resource management and planning in sectors sensitive to climatic variations.

### Limitations and Considerations 🚧

- **Geographical Specificity**: The rainfall data is specific to Bangladesh and may not represent global patterns.
- **Data Integration**: The temperature and rainfall data come from two different sources; users should consider potential discrepancies in data collection methods and accuracy.

### Updates and Maintenance 🔄

- **Data Update Frequency**: Check the source websites for the update frequency and availability of more recent data.
- **Last Updated**: Refer to the source websites for the last update date of the data.

## Licensing and Usage Rights ©️

- Users should refer to the respective source websites for information on licensing and usage rights. It is important to adhere to the terms and conditions set by the data providers.

## Contact Information 📞

For specific queries related to the temperature or rainfall data, users should contact the respective data providers through their official communication channels provided on their websites.

```bibtex
@misc{rubaiat2023bangladeshweather,
  author = {Rubaiat, Sajratul Yakin},
  title = {Bangladesh Weather Dataset},
  year = {2023},
  publisher = {Kaggle},
  url = {https://www.kaggle.com/datasets/yakinrubaiat/bangladesh-weather-dataset},
  note = {Kaggle dataset}
}
```",.csv,True
Bangladesh Weather Dataset (1901 - 2023),2,bangladesh-weather-dataset,Temp_and_rain.csv,Attribution 4.0 International (CC BY 4.0),"# 📊 Dataset README (Updated with Temporal Coverage) 📈

## Overview 🌐

This README document provides detailed information about a dataset that combines temperature 🌡️ and rainfall 🌧️ data. The temperature data is sourced from NASA's POWER Project, and the rainfall data is obtained from the Humanitarian Data Exchange (HDX) website, specifically focusing on Bangladesh rainfall data.

### Temperature Data Source 🔥

- **Source**: NASA's POWER (Prediction of Worldwide Energy Resources) Data Access Viewer
- **URL**: [NASA POWER Data Access Viewer](https://power.larc.nasa.gov/data-access-viewer/)
- **Description**: The POWER Project provides solar and meteorological data sets, primarily intended for renewable energy, sustainable buildings, agriculture, and other related applications. The temperature data from this source is a part of NASA's global meteorological data.

### Rainfall Data Source 🌧️

- **Source**: Humanitarian Data Exchange (HDX)
- **URL**: [Bangladesh Rainfall Data - HDX](https://data.humdata.org/dataset/bgd-rainfall-subnational)
- **Description**: HDX hosts various humanitarian data including climate and weather-related datasets. The rainfall data for Bangladesh is part of their collection, providing detailed subnational rainfall statistics.

## Dataset Description 📝

### Composition 📊

The dataset is a combination of the temperature and rainfall data, aligned by date to facilitate joint analysis. The key components are:

- **Temperature Data (`tem`)**: Represents the monthly average temperature, presumably in degrees Celsius.
- **Rainfall Data (`rain`)**: Indicates monthly total rainfall, presumably measured in millimeters.

### Structure 🏗️

The dataset is structured into a CSV file with the following columns:

- `tem`: Average temperature for the month.
- `Month`: The month for the data point, ranging from 1 (January) to 12 (December).
- `Year`: The year of the data point.
- `rain`: Total rainfall for the month.

### Temporal Coverage 📆

- **Earliest Date**: 1901
- **Latest Date**: 2023
- This dataset provides a historical perspective on climate trends from the earliest year of 1901 to the most recent data available up to 2023.

### Usage and Applications 🚀

This dataset is particularly useful for studying climatic patterns, seasonal changes, and long-term climate trends. Applications include but are not limited to:

- Climatological research and climate change studies.
- Agricultural planning and forecasting.
- Environmental and ecological studies.
- Resource management and planning in sectors sensitive to climatic variations.

### Limitations and Considerations 🚧

- **Geographical Specificity**: The rainfall data is specific to Bangladesh and may not represent global patterns.
- **Data Integration**: The temperature and rainfall data come from two different sources; users should consider potential discrepancies in data collection methods and accuracy.

### Updates and Maintenance 🔄

- **Data Update Frequency**: Check the source websites for the update frequency and availability of more recent data.
- **Last Updated**: Refer to the source websites for the last update date of the data.

## Licensing and Usage Rights ©️

- Users should refer to the respective source websites for information on licensing and usage rights. It is important to adhere to the terms and conditions set by the data providers.

## Contact Information 📞

For specific queries related to the temperature or rainfall data, users should contact the respective data providers through their official communication channels provided on their websites.

```bibtex
@misc{rubaiat2023bangladeshweather,
  author = {Rubaiat, Sajratul Yakin},
  title = {Bangladesh Weather Dataset},
  year = {2023},
  publisher = {Kaggle},
  url = {https://www.kaggle.com/datasets/yakinrubaiat/bangladesh-weather-dataset},
  note = {Kaggle dataset}
}
```",.csv,True
Bank Central Asia Stock Historical Price,3,bank-central-asia-stock-historical-price,BBCA.JK.csv,world-bank,"# PT Bank Central Asia Tbk Stock Historical Price (BBCA.JK) 

#### from January 2019 until present

---

### ▶ Context 📝
The dataset is taken from [Yahoo Finance website](https://finance.yahoo.com/quote/BBCA.JK/history?p=BBCA.JK). It is about the historical stock price of PT Bank Central Asia Tbk.

### ▶ Acknowledgements 🙏

I'd like to clarify that I'm only making data about the historical stock price of PT Bank Central Asia Tbk. available to **Kaggle community**. 

### ▶ Inspiration 💭

- Forecasting stock price after January 2019
- Implementing machine learning models.
- Perform data analysis/data visualization of historical stock prices.

### ▶ Log 📰
- **4 January 2024**: Initialization and fully automated update using Kaggle schedule run.

---

📷 *Image by [Wikipedia](https://id.m.wikipedia.org/wiki/Berkas:Bank_Central_Asia.svg).*",.csv,True
Bank Central Asia Stock Historical Price,3,bank-central-asia-stock-historical-price,BBCA.JK_weekly.csv,world-bank,"# PT Bank Central Asia Tbk Stock Historical Price (BBCA.JK) 

#### from January 2019 until present

---

### ▶ Context 📝
The dataset is taken from [Yahoo Finance website](https://finance.yahoo.com/quote/BBCA.JK/history?p=BBCA.JK). It is about the historical stock price of PT Bank Central Asia Tbk.

### ▶ Acknowledgements 🙏

I'd like to clarify that I'm only making data about the historical stock price of PT Bank Central Asia Tbk. available to **Kaggle community**. 

### ▶ Inspiration 💭

- Forecasting stock price after January 2019
- Implementing machine learning models.
- Perform data analysis/data visualization of historical stock prices.

### ▶ Log 📰
- **4 January 2024**: Initialization and fully automated update using Kaggle schedule run.

---

📷 *Image by [Wikipedia](https://id.m.wikipedia.org/wiki/Berkas:Bank_Central_Asia.svg).*",.csv,True
Bank Central Asia Stock Historical Price,3,bank-central-asia-stock-historical-price,BBCA.JK_monthly.csv,world-bank,"# PT Bank Central Asia Tbk Stock Historical Price (BBCA.JK) 

#### from January 2019 until present

---

### ▶ Context 📝
The dataset is taken from [Yahoo Finance website](https://finance.yahoo.com/quote/BBCA.JK/history?p=BBCA.JK). It is about the historical stock price of PT Bank Central Asia Tbk.

### ▶ Acknowledgements 🙏

I'd like to clarify that I'm only making data about the historical stock price of PT Bank Central Asia Tbk. available to **Kaggle community**. 

### ▶ Inspiration 💭

- Forecasting stock price after January 2019
- Implementing machine learning models.
- Perform data analysis/data visualization of historical stock prices.

### ▶ Log 📰
- **4 January 2024**: Initialization and fully automated update using Kaggle schedule run.

---

📷 *Image by [Wikipedia](https://id.m.wikipedia.org/wiki/Berkas:Bank_Central_Asia.svg).*",.csv,True
Bank Mandiri Stock Historical Price,3,bank-mandiri-stock-historical-price,BMRI.JK_monthly.csv,world-bank,"# PT Bank Mandiri (Persero) Tbk Stock Historical Price (BMRI.JK) 

#### from January 2019 until present

---

### ▶ Context 📝
The dataset is taken from [Yahoo Finance website](https://finance.yahoo.com/quote/BMRI.JK/history?p=BMRI.JK). It is about the historical stock price of PT Bank Mandiri (Persero) Tbk.

### ▶ Acknowledgements 🙏

I'd like to clarify that I'm only making data about the historical stock price of PT Bank Mandiri (Persero) Tbk. available to **Kaggle community**. 

### ▶ Inspiration 💭

- Forecasting stock price after January 2019
- Implementing machine learning models.
- Perform data analysis/data visualization of historical stock prices.

### ▶ Log 📰
- **4 January 2024**: Initialization and fully automated update using Kaggle schedule run.

---

📷 *Image by [Liputan6](https://www.liputan6.com/hot/read/5149339/profil-pt-bank-mandiri-sejarah-berdiri-dan-produk-produknya).*",.csv,True
Bank Mandiri Stock Historical Price,3,bank-mandiri-stock-historical-price,BMRI.JK.csv,world-bank,"# PT Bank Mandiri (Persero) Tbk Stock Historical Price (BMRI.JK) 

#### from January 2019 until present

---

### ▶ Context 📝
The dataset is taken from [Yahoo Finance website](https://finance.yahoo.com/quote/BMRI.JK/history?p=BMRI.JK). It is about the historical stock price of PT Bank Mandiri (Persero) Tbk.

### ▶ Acknowledgements 🙏

I'd like to clarify that I'm only making data about the historical stock price of PT Bank Mandiri (Persero) Tbk. available to **Kaggle community**. 

### ▶ Inspiration 💭

- Forecasting stock price after January 2019
- Implementing machine learning models.
- Perform data analysis/data visualization of historical stock prices.

### ▶ Log 📰
- **4 January 2024**: Initialization and fully automated update using Kaggle schedule run.

---

📷 *Image by [Liputan6](https://www.liputan6.com/hot/read/5149339/profil-pt-bank-mandiri-sejarah-berdiri-dan-produk-produknya).*",.csv,True
Bank Mandiri Stock Historical Price,3,bank-mandiri-stock-historical-price,BMRI.JK_weekly.csv,world-bank,"# PT Bank Mandiri (Persero) Tbk Stock Historical Price (BMRI.JK) 

#### from January 2019 until present

---

### ▶ Context 📝
The dataset is taken from [Yahoo Finance website](https://finance.yahoo.com/quote/BMRI.JK/history?p=BMRI.JK). It is about the historical stock price of PT Bank Mandiri (Persero) Tbk.

### ▶ Acknowledgements 🙏

I'd like to clarify that I'm only making data about the historical stock price of PT Bank Mandiri (Persero) Tbk. available to **Kaggle community**. 

### ▶ Inspiration 💭

- Forecasting stock price after January 2019
- Implementing machine learning models.
- Perform data analysis/data visualization of historical stock prices.

### ▶ Log 📰
- **4 January 2024**: Initialization and fully automated update using Kaggle schedule run.

---

📷 *Image by [Liputan6](https://www.liputan6.com/hot/read/5149339/profil-pt-bank-mandiri-sejarah-berdiri-dan-produk-produknya).*",.csv,True
Bank Negara Indonesia Stock Historical Price,3,bank-negara-indonesia-stock-historical-price,BBNI.JK_monthly.csv,world-bank,"# PT Bank Negara Indonesia (Persero) Tbk Stock Historical Price (BBNI.JK) 

#### from January 2019 until present

---

### ▶ Context 📝
The dataset is taken from [Yahoo Finance website](https://finance.yahoo.com/quote/BBNI.JK/history?p=BBNI.JK). It is about the historical stock price of PT Bank Negara Indonesia (Persero) Tbk.

### ▶ Acknowledgements 🙏

I'd like to clarify that I'm only making data about the historical stock price of PT Bank Negara Indonesia (Persero) Tbk. available to **Kaggle community**. 

### ▶ Inspiration 💭

- Forecasting stock price after January 2019
- Implementing machine learning models.
- Perform data analysis/data visualization of historical stock prices.

### ▶ Log 📰
- **4 January 2024**: Initialization and fully automated update using Kaggle schedule run.

---

📷 *Image by [logo.yedepe.com](https://logo.yedepe.com/logo-bni/).*",.csv,True
Bank Negara Indonesia Stock Historical Price,3,bank-negara-indonesia-stock-historical-price,BBNI.JK.csv,world-bank,"# PT Bank Negara Indonesia (Persero) Tbk Stock Historical Price (BBNI.JK) 

#### from January 2019 until present

---

### ▶ Context 📝
The dataset is taken from [Yahoo Finance website](https://finance.yahoo.com/quote/BBNI.JK/history?p=BBNI.JK). It is about the historical stock price of PT Bank Negara Indonesia (Persero) Tbk.

### ▶ Acknowledgements 🙏

I'd like to clarify that I'm only making data about the historical stock price of PT Bank Negara Indonesia (Persero) Tbk. available to **Kaggle community**. 

### ▶ Inspiration 💭

- Forecasting stock price after January 2019
- Implementing machine learning models.
- Perform data analysis/data visualization of historical stock prices.

### ▶ Log 📰
- **4 January 2024**: Initialization and fully automated update using Kaggle schedule run.

---

📷 *Image by [logo.yedepe.com](https://logo.yedepe.com/logo-bni/).*",.csv,True
Bank Negara Indonesia Stock Historical Price,3,bank-negara-indonesia-stock-historical-price,BBNI.JK_weekly.csv,world-bank,"# PT Bank Negara Indonesia (Persero) Tbk Stock Historical Price (BBNI.JK) 

#### from January 2019 until present

---

### ▶ Context 📝
The dataset is taken from [Yahoo Finance website](https://finance.yahoo.com/quote/BBNI.JK/history?p=BBNI.JK). It is about the historical stock price of PT Bank Negara Indonesia (Persero) Tbk.

### ▶ Acknowledgements 🙏

I'd like to clarify that I'm only making data about the historical stock price of PT Bank Negara Indonesia (Persero) Tbk. available to **Kaggle community**. 

### ▶ Inspiration 💭

- Forecasting stock price after January 2019
- Implementing machine learning models.
- Perform data analysis/data visualization of historical stock prices.

### ▶ Log 📰
- **4 January 2024**: Initialization and fully automated update using Kaggle schedule run.

---

📷 *Image by [logo.yedepe.com](https://logo.yedepe.com/logo-bni/).*",.csv,True
Bank Term Deposit Predictions,2,bank-term-deposit-predictions,test.csv,CC0-1.0,"_____
# Bank Term Deposit Predictions
### Predicting Subscription to Term Deposits through Marketing Campaigns
By Ankush Singal (From Huggingface) [[source]](https://huggingface.co/datasets/Andyrasika/banking-marketing)
_____

### About this dataset
> This dataset, titled Direct Marketing Campaigns for Bank Term Deposits, is a collection of data related to the direct marketing campaigns conducted by a Portuguese banking institution. These campaigns primarily involved phone calls with customers, and the objective was to determine whether or not a customer would subscribe to a term deposit offered by the bank.
> 
> The dataset contains various features that provide insights into customer attributes and campaign outcomes. These features include:
> 
> - Age: The age of the customer.
> - Job: The occupation of the customer.
> - Marital Status: The marital status of the customer.
> - Education: The education level of the customer.
> - Default: Whether or not the customer has credit in default.
> - Balance: The balance of the customer's account.
> - Housing Loan: Whether or not the customer has a housing loan.
> - Contact Communication Type: The method used to contact the customer (e.g., telephone, cellular).
> - Day: The day of the month when the last contact with the customers was made.
> - Duration: The duration (in seconds) of the last contact with customers during a campaign.
> - Campaign Contacts Count: Number of contacts performed during this campaign for each customer
> -pdays : number days passed since previously contacted form previous camapign 
> -poutcome : outcome from previous marketing campaign
> 
> 
> 
> 
> The purpose behind this dataset is to train a predictive model that can determine if a given customer will subscribe to a term deposit based on these various features. By analyzing historical data on successful and unsuccessful subscription outcomes, patterns can be identified which help predict future subscription behavior.
> 
> In addition to training data, there is also test data included in this dataset. This test data can be used to evaluate how well our trained predictive model performs when applied to new, unseen instances. 
> 
> By utilizing this dataset and applying machine learning techniques, businesses in similar domains can better understand their target audience and optimize their marketing efforts towards potential subscribers who are more likely to respond positively to these campaigns

### How to use the dataset
> 
> 
> Here are some key steps you can follow to effectively utilize this dataset:
> 
> - **Understanding the columns**: Start by understanding the different columns in the dataset. Each column represents a specific attribute or feature related to the customer and their interaction with the bank's marketing campaign. The columns include:
>    - Age: The age of the customer.
>    - Job: The occupation of the customer.
>    - Marital: The marital status of the customer.
>    - Education: The education level of the customer.
>    - Default: Whether the customer has credit in default or not.
>    - Balance: The balance of the customer's account.
>    - Housing: Whether the customer has a housing loan or not.
>    - Contact: The contact communication type with the customer.
>    - Day: The day of the month when

### Research Ideas
> - Predictive Modeling: This dataset can be used to build a predictive model to predict whether a customer will subscribe to a term deposit or not. By analyzing the various features such as age, job, marital status, education, balance, and previous marketing campaign outcomes, the model can provide insights into the likelihood of subscription.
> - Customer Segmentation: The dataset can be used for customer segmentation analysis. By clustering customers based on their characteristics and behavior, banks can identify different segments of customers with varying propensities to subscribe to term deposits. This information can then be used to tailor marketing campaigns and strategies specific to each segment.
> - Campaign Optimization: The dataset can also be used for optimizing marketing campaigns. By analyzing the effectiveness of different communication types (contact), number of contacts performed (campaign), duration of contact, and outcome of previous campaigns (poutcome), banks can gain insights into which strategies are most successful in driving subscriptions. This information can help in optimizing future campaign efforts for better results

### Acknowledgements
> If you use this dataset in your research, please credit the original authors.
> [Data Source](https://huggingface.co/datasets/Andyrasika/banking-marketing)
> 
>


### License
> 
> 
> **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
> No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: train.csv**
| Column name   | Description                                                                                        |
|:--------------|:---------------------------------------------------------------------------------------------------|
| **age**       | The age of the customer. (Numerical)                                                               |
| **job**       | The occupation/employment status of the customer. (Categorical)                                    |
| **marital**   | The marital status of the customer. (Categorical)                                                  |
| **education** | The education level attained by the customer. (Categorical)                                        |
| **default**   | Whether the customer has credit in default or not. (Categorical)                                   |
| **balance**   | The balance in the customer's account. (Numerical)                                                 |
| **housing**   | Whether the customer has a housing loan or not. (Categorical)                                      |
| **contact**   | Type of communication used to contact customers (phone, cellular, etc.). (Categorical)             |
| **day**       | Day of the month when customers were last contacted. (Numerical)                                   |
| **duration**  | Duration (in seconds) of the last contact with customers during the previous campaign. (Numerical) |
| **pdays**     | The number of days passed by after contact from the previous campaign. (Numerical)                 |
| **poutcome**  | Outcome from the previous marketing campaign. (Categorical)                                        |

_____

**File: test.csv**
| Column name   | Description                                                                                        |
|:--------------|:---------------------------------------------------------------------------------------------------|
| **age**       | The age of the customer. (Numerical)                                                               |
| **job**       | The occupation/employment status of the customer. (Categorical)                                    |
| **marital**   | The marital status of the customer. (Categorical)                                                  |
| **education** | The education level attained by the customer. (Categorical)                                        |
| **default**   | Whether the customer has credit in default or not. (Categorical)                                   |
| **balance**   | The balance in the customer's account. (Numerical)                                                 |
| **housing**   | Whether the customer has a housing loan or not. (Categorical)                                      |
| **contact**   | Type of communication used to contact customers (phone, cellular, etc.). (Categorical)             |
| **day**       | Day of the month when customers were last contacted. (Numerical)                                   |
| **duration**  | Duration (in seconds) of the last contact with customers during the previous campaign. (Numerical) |
| **pdays**     | The number of days passed by after contact from the previous campaign. (Numerical)                 |
| **poutcome**  | Outcome from the previous marketing campaign. (Categorical)                                        |

### Acknowledgements
> If you use this dataset in your research, please credit the original authors.
> If you use this dataset in your research, please credit [Ankush Singal (From Huggingface)](https://huggingface.co/datasets/Andyrasika/banking-marketing).

",.csv,True
Bank Term Deposit Predictions,2,bank-term-deposit-predictions,train.csv,CC0-1.0,"_____
# Bank Term Deposit Predictions
### Predicting Subscription to Term Deposits through Marketing Campaigns
By Ankush Singal (From Huggingface) [[source]](https://huggingface.co/datasets/Andyrasika/banking-marketing)
_____

### About this dataset
> This dataset, titled Direct Marketing Campaigns for Bank Term Deposits, is a collection of data related to the direct marketing campaigns conducted by a Portuguese banking institution. These campaigns primarily involved phone calls with customers, and the objective was to determine whether or not a customer would subscribe to a term deposit offered by the bank.
> 
> The dataset contains various features that provide insights into customer attributes and campaign outcomes. These features include:
> 
> - Age: The age of the customer.
> - Job: The occupation of the customer.
> - Marital Status: The marital status of the customer.
> - Education: The education level of the customer.
> - Default: Whether or not the customer has credit in default.
> - Balance: The balance of the customer's account.
> - Housing Loan: Whether or not the customer has a housing loan.
> - Contact Communication Type: The method used to contact the customer (e.g., telephone, cellular).
> - Day: The day of the month when the last contact with the customers was made.
> - Duration: The duration (in seconds) of the last contact with customers during a campaign.
> - Campaign Contacts Count: Number of contacts performed during this campaign for each customer
> -pdays : number days passed since previously contacted form previous camapign 
> -poutcome : outcome from previous marketing campaign
> 
> 
> 
> 
> The purpose behind this dataset is to train a predictive model that can determine if a given customer will subscribe to a term deposit based on these various features. By analyzing historical data on successful and unsuccessful subscription outcomes, patterns can be identified which help predict future subscription behavior.
> 
> In addition to training data, there is also test data included in this dataset. This test data can be used to evaluate how well our trained predictive model performs when applied to new, unseen instances. 
> 
> By utilizing this dataset and applying machine learning techniques, businesses in similar domains can better understand their target audience and optimize their marketing efforts towards potential subscribers who are more likely to respond positively to these campaigns

### How to use the dataset
> 
> 
> Here are some key steps you can follow to effectively utilize this dataset:
> 
> - **Understanding the columns**: Start by understanding the different columns in the dataset. Each column represents a specific attribute or feature related to the customer and their interaction with the bank's marketing campaign. The columns include:
>    - Age: The age of the customer.
>    - Job: The occupation of the customer.
>    - Marital: The marital status of the customer.
>    - Education: The education level of the customer.
>    - Default: Whether the customer has credit in default or not.
>    - Balance: The balance of the customer's account.
>    - Housing: Whether the customer has a housing loan or not.
>    - Contact: The contact communication type with the customer.
>    - Day: The day of the month when

### Research Ideas
> - Predictive Modeling: This dataset can be used to build a predictive model to predict whether a customer will subscribe to a term deposit or not. By analyzing the various features such as age, job, marital status, education, balance, and previous marketing campaign outcomes, the model can provide insights into the likelihood of subscription.
> - Customer Segmentation: The dataset can be used for customer segmentation analysis. By clustering customers based on their characteristics and behavior, banks can identify different segments of customers with varying propensities to subscribe to term deposits. This information can then be used to tailor marketing campaigns and strategies specific to each segment.
> - Campaign Optimization: The dataset can also be used for optimizing marketing campaigns. By analyzing the effectiveness of different communication types (contact), number of contacts performed (campaign), duration of contact, and outcome of previous campaigns (poutcome), banks can gain insights into which strategies are most successful in driving subscriptions. This information can help in optimizing future campaign efforts for better results

### Acknowledgements
> If you use this dataset in your research, please credit the original authors.
> [Data Source](https://huggingface.co/datasets/Andyrasika/banking-marketing)
> 
>


### License
> 
> 
> **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
> No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: train.csv**
| Column name   | Description                                                                                        |
|:--------------|:---------------------------------------------------------------------------------------------------|
| **age**       | The age of the customer. (Numerical)                                                               |
| **job**       | The occupation/employment status of the customer. (Categorical)                                    |
| **marital**   | The marital status of the customer. (Categorical)                                                  |
| **education** | The education level attained by the customer. (Categorical)                                        |
| **default**   | Whether the customer has credit in default or not. (Categorical)                                   |
| **balance**   | The balance in the customer's account. (Numerical)                                                 |
| **housing**   | Whether the customer has a housing loan or not. (Categorical)                                      |
| **contact**   | Type of communication used to contact customers (phone, cellular, etc.). (Categorical)             |
| **day**       | Day of the month when customers were last contacted. (Numerical)                                   |
| **duration**  | Duration (in seconds) of the last contact with customers during the previous campaign. (Numerical) |
| **pdays**     | The number of days passed by after contact from the previous campaign. (Numerical)                 |
| **poutcome**  | Outcome from the previous marketing campaign. (Categorical)                                        |

_____

**File: test.csv**
| Column name   | Description                                                                                        |
|:--------------|:---------------------------------------------------------------------------------------------------|
| **age**       | The age of the customer. (Numerical)                                                               |
| **job**       | The occupation/employment status of the customer. (Categorical)                                    |
| **marital**   | The marital status of the customer. (Categorical)                                                  |
| **education** | The education level attained by the customer. (Categorical)                                        |
| **default**   | Whether the customer has credit in default or not. (Categorical)                                   |
| **balance**   | The balance in the customer's account. (Numerical)                                                 |
| **housing**   | Whether the customer has a housing loan or not. (Categorical)                                      |
| **contact**   | Type of communication used to contact customers (phone, cellular, etc.). (Categorical)             |
| **day**       | Day of the month when customers were last contacted. (Numerical)                                   |
| **duration**  | Duration (in seconds) of the last contact with customers during the previous campaign. (Numerical) |
| **pdays**     | The number of days passed by after contact from the previous campaign. (Numerical)                 |
| **poutcome**  | Outcome from the previous marketing campaign. (Categorical)                                        |

### Acknowledgements
> If you use this dataset in your research, please credit the original authors.
> If you use this dataset in your research, please credit [Ankush Singal (From Huggingface)](https://huggingface.co/datasets/Andyrasika/banking-marketing).

",.csv,True
Banking Dataset - Marketing Targets,2,banking-dataset-marketing-targets,test.csv,CC0-1.0,"### Context

Term deposits are a major source of income for a bank.  A term deposit is a cash investment held at a financial institution. Your money is invested for an agreed rate of interest over a fixed amount of time, or term. The bank has various outreach plans to sell term deposits to their customers such as email marketing, advertisements, telephonic marketing, and digital marketing.

Telephonic marketing campaigns still remain one of the most effective way to reach out to people. However, they require huge investment as large call centers are hired to actually execute these campaigns. Hence, it is crucial to identify the customers most likely to convert beforehand so that they can be specifically targeted via call. 

The data is related to direct marketing campaigns (phone calls) of a Portuguese banking institution. The classification goal is to predict if the client will subscribe to a term deposit (variable y).


### Content

The data is related to the direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be ('yes') or not ('no') subscribed by the customer or not. The data folder contains two datasets:- 

* train.csv: 45,211 rows and 18 columns ordered by date (from May 2008 to November 2010)
* test.csv: 4521 rows and 18 columns with 10% of the examples (4521), randomly selected from train.csv

### Detailed Column Descriptions 

**bank client data:**

1 - age (numeric)
   2 - job : type of job (categorical: ""admin."",""unknown"",""unemployed"",""management"",""housemaid"",""entrepreneur"",""student"",
                                       ""blue-collar"",""self-employed"",""retired"",""technician"",""services"") 
   3 - marital : marital status (categorical: ""married"",""divorced"",""single""; note: ""divorced"" means divorced or widowed)
   4 - education (categorical: ""unknown"",""secondary"",""primary"",""tertiary"")
   5 - default: has credit in default? (binary: ""yes"",""no"")
   6 - balance: average yearly balance, in euros (numeric) 
   7 - housing: has housing loan? (binary: ""yes"",""no"")
   8 - loan: has personal loan? (binary: ""yes"",""no"")
   # related with the last contact of the current campaign:
   9 - contact: contact communication type (categorical: ""unknown"",""telephone"",""cellular"") 
  10 - day: last contact day of the month (numeric)
  11 - month: last contact month of year (categorical: ""jan"", ""feb"", ""mar"", ..., ""nov"", ""dec"")
  12 - duration: last contact duration, in seconds (numeric)
   # other attributes:
  13 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)
  14 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted)
  15 - previous: number of contacts performed before this campaign and for this client (numeric)
  16 - poutcome: outcome of the previous marketing campaign (categorical: ""unknown"",""other"",""failure"",""success"")

  **Output variable (desired target):**
  17 - y - has the client subscribed a term deposit? (binary: ""yes"",""no"")

Missing Attribute Values: None

### Citation

This dataset is publicly available for research. It has been picked up from the [UCI Machine Learning](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing#) with random sampling and a few additional columns. 

Please add this citation if you use this dataset for any further analysis.

*S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014*

### Past Usage 

The full dataset was described and analyzed in:

* S. Moro, R. Laureano and P. Cortez. Using Data Mining for Bank Direct Marketing: An Application of the CRISP-DM Methodology. 
* In P. Novais et al. (Eds.), Proceedings of the European Simulation and Modelling Conference - ESM'2011, pp. 117-121, Guimarães,  Portugal, October, 2011. EUROSIS.


### Acknowledgement

Created by: Paulo Cortez (Univ. Minho) and Sérgio Moro (ISCTE-IUL) @ 2012. Thanks to [Berkin Kaplanoğlu](https://www.kaggle.com/berkinkaplanolu) for helping with the proper column descriptions. ",.csv,True
Banking Dataset - Marketing Targets,2,banking-dataset-marketing-targets,train.csv,CC0-1.0,"### Context

Term deposits are a major source of income for a bank.  A term deposit is a cash investment held at a financial institution. Your money is invested for an agreed rate of interest over a fixed amount of time, or term. The bank has various outreach plans to sell term deposits to their customers such as email marketing, advertisements, telephonic marketing, and digital marketing.

Telephonic marketing campaigns still remain one of the most effective way to reach out to people. However, they require huge investment as large call centers are hired to actually execute these campaigns. Hence, it is crucial to identify the customers most likely to convert beforehand so that they can be specifically targeted via call. 

The data is related to direct marketing campaigns (phone calls) of a Portuguese banking institution. The classification goal is to predict if the client will subscribe to a term deposit (variable y).


### Content

The data is related to the direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be ('yes') or not ('no') subscribed by the customer or not. The data folder contains two datasets:- 

* train.csv: 45,211 rows and 18 columns ordered by date (from May 2008 to November 2010)
* test.csv: 4521 rows and 18 columns with 10% of the examples (4521), randomly selected from train.csv

### Detailed Column Descriptions 

**bank client data:**

1 - age (numeric)
   2 - job : type of job (categorical: ""admin."",""unknown"",""unemployed"",""management"",""housemaid"",""entrepreneur"",""student"",
                                       ""blue-collar"",""self-employed"",""retired"",""technician"",""services"") 
   3 - marital : marital status (categorical: ""married"",""divorced"",""single""; note: ""divorced"" means divorced or widowed)
   4 - education (categorical: ""unknown"",""secondary"",""primary"",""tertiary"")
   5 - default: has credit in default? (binary: ""yes"",""no"")
   6 - balance: average yearly balance, in euros (numeric) 
   7 - housing: has housing loan? (binary: ""yes"",""no"")
   8 - loan: has personal loan? (binary: ""yes"",""no"")
   # related with the last contact of the current campaign:
   9 - contact: contact communication type (categorical: ""unknown"",""telephone"",""cellular"") 
  10 - day: last contact day of the month (numeric)
  11 - month: last contact month of year (categorical: ""jan"", ""feb"", ""mar"", ..., ""nov"", ""dec"")
  12 - duration: last contact duration, in seconds (numeric)
   # other attributes:
  13 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)
  14 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted)
  15 - previous: number of contacts performed before this campaign and for this client (numeric)
  16 - poutcome: outcome of the previous marketing campaign (categorical: ""unknown"",""other"",""failure"",""success"")

  **Output variable (desired target):**
  17 - y - has the client subscribed a term deposit? (binary: ""yes"",""no"")

Missing Attribute Values: None

### Citation

This dataset is publicly available for research. It has been picked up from the [UCI Machine Learning](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing#) with random sampling and a few additional columns. 

Please add this citation if you use this dataset for any further analysis.

*S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014*

### Past Usage 

The full dataset was described and analyzed in:

* S. Moro, R. Laureano and P. Cortez. Using Data Mining for Bank Direct Marketing: An Application of the CRISP-DM Methodology. 
* In P. Novais et al. (Eds.), Proceedings of the European Simulation and Modelling Conference - ESM'2011, pp. 117-121, Guimarães,  Portugal, October, 2011. EUROSIS.


### Acknowledgement

Created by: Paulo Cortez (Univ. Minho) and Sérgio Moro (ISCTE-IUL) @ 2012. Thanks to [Berkin Kaplanoğlu](https://www.kaggle.com/berkinkaplanolu) for helping with the proper column descriptions. ",.csv,True
Belka-Blend,5,belka-blend,submission_0549.csv,Community Data License Agreement - Sharing - Version 1.0,"# Description
Public submission files for [Leash Bio - Predict New Medicines with BELKA Competition](https://www.kaggle.com/competitions/leash-BELKA).

# Credits:

* submission_0.585: https://www.kaggle.com/code/ahmedelfazouan/belka-1dcnn-starter-with-all-data  
* submission_0.553: https://www.kaggle.com/code/mehrankazeminia/5-belka-submission-autogluon-frag1-2-3  
* submission_0.549: https://www.kaggle.com/code/motono0223/leash-bio-automl-baseline  
* submission_0.546: https://www.kaggle.com/code/ricopue/leashbio-xgb-ecfp-10m-sample-rows  
* submission_0.527: https://www.kaggle.com/code/mehrankazeminia/p-6-6-belka-competition-submission-lgbm  ",.csv,True
Belka-Blend,5,belka-blend,submission_0553.csv,Community Data License Agreement - Sharing - Version 1.0,"# Description
Public submission files for [Leash Bio - Predict New Medicines with BELKA Competition](https://www.kaggle.com/competitions/leash-BELKA).

# Credits:

* submission_0.585: https://www.kaggle.com/code/ahmedelfazouan/belka-1dcnn-starter-with-all-data  
* submission_0.553: https://www.kaggle.com/code/mehrankazeminia/5-belka-submission-autogluon-frag1-2-3  
* submission_0.549: https://www.kaggle.com/code/motono0223/leash-bio-automl-baseline  
* submission_0.546: https://www.kaggle.com/code/ricopue/leashbio-xgb-ecfp-10m-sample-rows  
* submission_0.527: https://www.kaggle.com/code/mehrankazeminia/p-6-6-belka-competition-submission-lgbm  ",.csv,True
Belka-Blend,5,belka-blend,submission_0585.csv,Community Data License Agreement - Sharing - Version 1.0,"# Description
Public submission files for [Leash Bio - Predict New Medicines with BELKA Competition](https://www.kaggle.com/competitions/leash-BELKA).

# Credits:

* submission_0.585: https://www.kaggle.com/code/ahmedelfazouan/belka-1dcnn-starter-with-all-data  
* submission_0.553: https://www.kaggle.com/code/mehrankazeminia/5-belka-submission-autogluon-frag1-2-3  
* submission_0.549: https://www.kaggle.com/code/motono0223/leash-bio-automl-baseline  
* submission_0.546: https://www.kaggle.com/code/ricopue/leashbio-xgb-ecfp-10m-sample-rows  
* submission_0.527: https://www.kaggle.com/code/mehrankazeminia/p-6-6-belka-competition-submission-lgbm  ",.csv,True
Belka-Blend,5,belka-blend,submission_0546.csv,Community Data License Agreement - Sharing - Version 1.0,"# Description
Public submission files for [Leash Bio - Predict New Medicines with BELKA Competition](https://www.kaggle.com/competitions/leash-BELKA).

# Credits:

* submission_0.585: https://www.kaggle.com/code/ahmedelfazouan/belka-1dcnn-starter-with-all-data  
* submission_0.553: https://www.kaggle.com/code/mehrankazeminia/5-belka-submission-autogluon-frag1-2-3  
* submission_0.549: https://www.kaggle.com/code/motono0223/leash-bio-automl-baseline  
* submission_0.546: https://www.kaggle.com/code/ricopue/leashbio-xgb-ecfp-10m-sample-rows  
* submission_0.527: https://www.kaggle.com/code/mehrankazeminia/p-6-6-belka-competition-submission-lgbm  ",.csv,True
Belka-Blend,5,belka-blend,submission_0527.csv,Community Data License Agreement - Sharing - Version 1.0,"# Description
Public submission files for [Leash Bio - Predict New Medicines with BELKA Competition](https://www.kaggle.com/competitions/leash-BELKA).

# Credits:

* submission_0.585: https://www.kaggle.com/code/ahmedelfazouan/belka-1dcnn-starter-with-all-data  
* submission_0.553: https://www.kaggle.com/code/mehrankazeminia/5-belka-submission-autogluon-frag1-2-3  
* submission_0.549: https://www.kaggle.com/code/motono0223/leash-bio-automl-baseline  
* submission_0.546: https://www.kaggle.com/code/ricopue/leashbio-xgb-ecfp-10m-sample-rows  
* submission_0.527: https://www.kaggle.com/code/mehrankazeminia/p-6-6-belka-competition-submission-lgbm  ",.csv,True
Bike Buyers 1000,2,bike-buyers,bike_buyers_clean.csv,GPL-2.0,"### Bike Buyers Dataset for Exploratory Data Analysis

This dataset has details of 1000 users from different backgrounds and whether or not they buy a bike. This data can be used for prediction models using Machine Learning Algorithms. There are some NA values injected in the dataset. Use this dataset for Data Cleaning, Exploration and Visualization.

Columns - 
- ID	
- Marital Status	
- Gender	
- Income	
- Children	
- Education	
- Occupation	
- Home Owner	
- Cars	
- Commute Distance	
- Region	
- Age	
- Purchased Bike


",.csv,True
Bike Buyers 1000,2,bike-buyers,bike_buyers.csv,GPL-2.0,"### Bike Buyers Dataset for Exploratory Data Analysis

This dataset has details of 1000 users from different backgrounds and whether or not they buy a bike. This data can be used for prediction models using Machine Learning Algorithms. There are some NA values injected in the dataset. Use this dataset for Data Cleaning, Exploration and Visualization.

Columns - 
- ID	
- Marital Status	
- Gender	
- Income	
- Children	
- Education	
- Occupation	
- Home Owner	
- Cars	
- Commute Distance	
- Region	
- Age	
- Purchased Bike


",.csv,True
Biological Data Of Human Evolution Data Sets,3,biological-data-of-human-ancestors-data-sets,Evolution_DataSets.csv,Apache 2.0,"*Homininos_DataSet(1).csv is the original*/////////
*Homininos_DataSet.csv It already has the categorical values ​​encoded*

**Exploring Human Evolution Through a Comprehensive Dataset**

Introduction:

In this dataset, we delve into the fascinating story of human evolution. With 720 rows and 28 columns, this dataset covers a wide range of characteristics of different hominids, from the earliest consensual ancestors to modern Homo sapiens. This comprehensive compilation aims to facilitate the search for relationships between various key variables, thereby providing a more complete and detailed understanding of human evolution.

Objectives:

The main objective of this dataset is to facilitate the exploration and understanding of human evolution from a broader and more detailed perspective. Some specific objectives include:

Seeking relationships between important columns of the dataset.
Understanding human evolution considering the collected data.
Investigating the possible linearity of evolution over time.
Analyzing potential relationships between brain size, developed technologies, diet, and physiological modifications over time.
Significance:

This dataset is crucial for advancing our understanding of human evolution and history. It provides a solid foundation for research in various fields, from anthropology and evolutionary biology to archaeology and genetics. By allowing us to examine relationships and patterns among different variables, this dataset helps us trace the course of human evolution and gain a better understanding of our place in the tree of life.

Conclusions:

In summary, this comprehensive dataset provides us with a valuable tool for exploring human evolution in depth. With its numerous rows and columns, it allows us to delve into the complexity and diversity of our evolutionary history. By analyzing and understanding the collected data, we can gain new insights into how we have come to be what we are today and how our species has evolved over time.

This dataset not only expands our knowledge of human evolution but also inspires us to continue researching and discovering more about our shared past as a species.

I studied Biological Anthropology for 4 years at the National University of La Palta, and I had the opportunity to compile these data from classes and books such as Carbonell's ""Homínidos: las primeras ocupaciones de los continentes,"" published in 2005.

**INFO About Columns:**
Genus & Species:  (categorical) This column contains the genus and specific name of the species. It provides taxonomic information about each hominid included in the dataset, allowing for precise identification

Time :  (categorical) This column indicates the time period during which each hominid species lived. It helps to establish chronological context and understand the temporal distribution of different hominid groups.

Location:  (categorical) This column records the continent location where each hominid species lived. 

Zone: (categorical) Describes either east, west, south or north of the continent

Current Country: (categorical) Records the modern-day country associated with the location where each hominid species lived, facilitating geographical comparisons.

Habitat: (categorical) This column describes the typical habitat or environment inhabited by each hominid species. It provides information about the ecological niche and adaptation strategies of different hominids throughout history.

Cranial Capacity: (numeric) This column provides data on the cranial capacity of each hominid species. Cranial capacity is a key indicator of brain size and can offer insights into cognitive abilities and evolutionary trends.

Height: (numeric) Describes the average height or stature of each hominid species

Incisor Size: (categorical) Indicates the size of the incisors in each hominid species

Jaw Shape: (categorical) Describes the shape or morphology of the jaw in each hominid species

Torus Supraorbital: (categorical) Specifies  the shape or morphology of a supraorbital torus in each hominid species

Prognathism: (categorical) Indicates the degree of facial prognathism or protrusion in each hominid species

Foramen Mágnum Position: (categorical)  Describes the position of the foramen magnum in each hominid species

Canine Size: (categorical) Indicates the size of the canines in each hominid species

Canines Shape: (categorical) Describes the shape of the canines in each hominid species, providing information about their dietary adaptations and social behavior.

Tooth Enamel: (categorical) Specifies the characteristics of tooth enamel in each hominid species, which may indicate aspects of dietary ecology and dental health.

Tecno: (categorical) Records the presence or absence of technological advancements 

Tecno Type: (categorical) Describes the specific type or style of technology associated with each hominid species

Biped: (categorical) Indicates whether each hominid species exhibited bipedal locomotion, a key characteristic distinguishing humans from other primates.

Arms: (categorical) Describes the morphology or characteristics of the arms in each hominid species, offering insights into their locomotor adaptations and manual dexterity.

Foots: (categorical) Specifies the morphology or characteristics of the feet in each hominid species, providing information about their locomotor adaptations and foot anatomy.

Diet: (categorical) Characterizes the dietary habits or preferences of each hominid species

Sexual Dimorphism: (categorical) Indicates the degree of sexual dimorphism

Hip: (categorical) Describes the size of the hip in each hominid species

Vertical Front: (categorical) Specifies the presence or absence of verticality or curvature of the frontal bone in each hominid species, providing information about their cranial morphology.

Anatomy: (categorical) Provides additional information about the anatomical features or characteristics of each hominid species, aiding in comprehensive morphological analyses.

Migrated: (categorical) Indicates whether each hominid species exhibited migration or movement to different geographical areas, offering insights into their dispersal patterns and population dynamics.

Skeleton: (categorical) Describes additional information about anatomy",.csv,True
Biological Data Of Human Evolution Data Sets,3,biological-data-of-human-ancestors-data-sets,Homininos_DataSet.csv,Apache 2.0,"*Homininos_DataSet(1).csv is the original*/////////
*Homininos_DataSet.csv It already has the categorical values ​​encoded*

**Exploring Human Evolution Through a Comprehensive Dataset**

Introduction:

In this dataset, we delve into the fascinating story of human evolution. With 720 rows and 28 columns, this dataset covers a wide range of characteristics of different hominids, from the earliest consensual ancestors to modern Homo sapiens. This comprehensive compilation aims to facilitate the search for relationships between various key variables, thereby providing a more complete and detailed understanding of human evolution.

Objectives:

The main objective of this dataset is to facilitate the exploration and understanding of human evolution from a broader and more detailed perspective. Some specific objectives include:

Seeking relationships between important columns of the dataset.
Understanding human evolution considering the collected data.
Investigating the possible linearity of evolution over time.
Analyzing potential relationships between brain size, developed technologies, diet, and physiological modifications over time.
Significance:

This dataset is crucial for advancing our understanding of human evolution and history. It provides a solid foundation for research in various fields, from anthropology and evolutionary biology to archaeology and genetics. By allowing us to examine relationships and patterns among different variables, this dataset helps us trace the course of human evolution and gain a better understanding of our place in the tree of life.

Conclusions:

In summary, this comprehensive dataset provides us with a valuable tool for exploring human evolution in depth. With its numerous rows and columns, it allows us to delve into the complexity and diversity of our evolutionary history. By analyzing and understanding the collected data, we can gain new insights into how we have come to be what we are today and how our species has evolved over time.

This dataset not only expands our knowledge of human evolution but also inspires us to continue researching and discovering more about our shared past as a species.

I studied Biological Anthropology for 4 years at the National University of La Palta, and I had the opportunity to compile these data from classes and books such as Carbonell's ""Homínidos: las primeras ocupaciones de los continentes,"" published in 2005.

**INFO About Columns:**
Genus & Species:  (categorical) This column contains the genus and specific name of the species. It provides taxonomic information about each hominid included in the dataset, allowing for precise identification

Time :  (categorical) This column indicates the time period during which each hominid species lived. It helps to establish chronological context and understand the temporal distribution of different hominid groups.

Location:  (categorical) This column records the continent location where each hominid species lived. 

Zone: (categorical) Describes either east, west, south or north of the continent

Current Country: (categorical) Records the modern-day country associated with the location where each hominid species lived, facilitating geographical comparisons.

Habitat: (categorical) This column describes the typical habitat or environment inhabited by each hominid species. It provides information about the ecological niche and adaptation strategies of different hominids throughout history.

Cranial Capacity: (numeric) This column provides data on the cranial capacity of each hominid species. Cranial capacity is a key indicator of brain size and can offer insights into cognitive abilities and evolutionary trends.

Height: (numeric) Describes the average height or stature of each hominid species

Incisor Size: (categorical) Indicates the size of the incisors in each hominid species

Jaw Shape: (categorical) Describes the shape or morphology of the jaw in each hominid species

Torus Supraorbital: (categorical) Specifies  the shape or morphology of a supraorbital torus in each hominid species

Prognathism: (categorical) Indicates the degree of facial prognathism or protrusion in each hominid species

Foramen Mágnum Position: (categorical)  Describes the position of the foramen magnum in each hominid species

Canine Size: (categorical) Indicates the size of the canines in each hominid species

Canines Shape: (categorical) Describes the shape of the canines in each hominid species, providing information about their dietary adaptations and social behavior.

Tooth Enamel: (categorical) Specifies the characteristics of tooth enamel in each hominid species, which may indicate aspects of dietary ecology and dental health.

Tecno: (categorical) Records the presence or absence of technological advancements 

Tecno Type: (categorical) Describes the specific type or style of technology associated with each hominid species

Biped: (categorical) Indicates whether each hominid species exhibited bipedal locomotion, a key characteristic distinguishing humans from other primates.

Arms: (categorical) Describes the morphology or characteristics of the arms in each hominid species, offering insights into their locomotor adaptations and manual dexterity.

Foots: (categorical) Specifies the morphology or characteristics of the feet in each hominid species, providing information about their locomotor adaptations and foot anatomy.

Diet: (categorical) Characterizes the dietary habits or preferences of each hominid species

Sexual Dimorphism: (categorical) Indicates the degree of sexual dimorphism

Hip: (categorical) Describes the size of the hip in each hominid species

Vertical Front: (categorical) Specifies the presence or absence of verticality or curvature of the frontal bone in each hominid species, providing information about their cranial morphology.

Anatomy: (categorical) Provides additional information about the anatomical features or characteristics of each hominid species, aiding in comprehensive morphological analyses.

Migrated: (categorical) Indicates whether each hominid species exhibited migration or movement to different geographical areas, offering insights into their dispersal patterns and population dynamics.

Skeleton: (categorical) Describes additional information about anatomy",.csv,True
Biological Data Of Human Evolution Data Sets,3,biological-data-of-human-ancestors-data-sets,Homininos_DataSet (1).csv,Apache 2.0,"*Homininos_DataSet(1).csv is the original*/////////
*Homininos_DataSet.csv It already has the categorical values ​​encoded*

**Exploring Human Evolution Through a Comprehensive Dataset**

Introduction:

In this dataset, we delve into the fascinating story of human evolution. With 720 rows and 28 columns, this dataset covers a wide range of characteristics of different hominids, from the earliest consensual ancestors to modern Homo sapiens. This comprehensive compilation aims to facilitate the search for relationships between various key variables, thereby providing a more complete and detailed understanding of human evolution.

Objectives:

The main objective of this dataset is to facilitate the exploration and understanding of human evolution from a broader and more detailed perspective. Some specific objectives include:

Seeking relationships between important columns of the dataset.
Understanding human evolution considering the collected data.
Investigating the possible linearity of evolution over time.
Analyzing potential relationships between brain size, developed technologies, diet, and physiological modifications over time.
Significance:

This dataset is crucial for advancing our understanding of human evolution and history. It provides a solid foundation for research in various fields, from anthropology and evolutionary biology to archaeology and genetics. By allowing us to examine relationships and patterns among different variables, this dataset helps us trace the course of human evolution and gain a better understanding of our place in the tree of life.

Conclusions:

In summary, this comprehensive dataset provides us with a valuable tool for exploring human evolution in depth. With its numerous rows and columns, it allows us to delve into the complexity and diversity of our evolutionary history. By analyzing and understanding the collected data, we can gain new insights into how we have come to be what we are today and how our species has evolved over time.

This dataset not only expands our knowledge of human evolution but also inspires us to continue researching and discovering more about our shared past as a species.

I studied Biological Anthropology for 4 years at the National University of La Palta, and I had the opportunity to compile these data from classes and books such as Carbonell's ""Homínidos: las primeras ocupaciones de los continentes,"" published in 2005.

**INFO About Columns:**
Genus & Species:  (categorical) This column contains the genus and specific name of the species. It provides taxonomic information about each hominid included in the dataset, allowing for precise identification

Time :  (categorical) This column indicates the time period during which each hominid species lived. It helps to establish chronological context and understand the temporal distribution of different hominid groups.

Location:  (categorical) This column records the continent location where each hominid species lived. 

Zone: (categorical) Describes either east, west, south or north of the continent

Current Country: (categorical) Records the modern-day country associated with the location where each hominid species lived, facilitating geographical comparisons.

Habitat: (categorical) This column describes the typical habitat or environment inhabited by each hominid species. It provides information about the ecological niche and adaptation strategies of different hominids throughout history.

Cranial Capacity: (numeric) This column provides data on the cranial capacity of each hominid species. Cranial capacity is a key indicator of brain size and can offer insights into cognitive abilities and evolutionary trends.

Height: (numeric) Describes the average height or stature of each hominid species

Incisor Size: (categorical) Indicates the size of the incisors in each hominid species

Jaw Shape: (categorical) Describes the shape or morphology of the jaw in each hominid species

Torus Supraorbital: (categorical) Specifies  the shape or morphology of a supraorbital torus in each hominid species

Prognathism: (categorical) Indicates the degree of facial prognathism or protrusion in each hominid species

Foramen Mágnum Position: (categorical)  Describes the position of the foramen magnum in each hominid species

Canine Size: (categorical) Indicates the size of the canines in each hominid species

Canines Shape: (categorical) Describes the shape of the canines in each hominid species, providing information about their dietary adaptations and social behavior.

Tooth Enamel: (categorical) Specifies the characteristics of tooth enamel in each hominid species, which may indicate aspects of dietary ecology and dental health.

Tecno: (categorical) Records the presence or absence of technological advancements 

Tecno Type: (categorical) Describes the specific type or style of technology associated with each hominid species

Biped: (categorical) Indicates whether each hominid species exhibited bipedal locomotion, a key characteristic distinguishing humans from other primates.

Arms: (categorical) Describes the morphology or characteristics of the arms in each hominid species, offering insights into their locomotor adaptations and manual dexterity.

Foots: (categorical) Specifies the morphology or characteristics of the feet in each hominid species, providing information about their locomotor adaptations and foot anatomy.

Diet: (categorical) Characterizes the dietary habits or preferences of each hominid species

Sexual Dimorphism: (categorical) Indicates the degree of sexual dimorphism

Hip: (categorical) Describes the size of the hip in each hominid species

Vertical Front: (categorical) Specifies the presence or absence of verticality or curvature of the frontal bone in each hominid species, providing information about their cranial morphology.

Anatomy: (categorical) Provides additional information about the anatomical features or characteristics of each hominid species, aiding in comprehensive morphological analyses.

Migrated: (categorical) Indicates whether each hominid species exhibited migration or movement to different geographical areas, offering insights into their dispersal patterns and population dynamics.

Skeleton: (categorical) Describes additional information about anatomy",.csv,True
Bitcoin Price Prediction (LightWeight CSV),2,bitcoin-price-prediction,bitcoin_price_Training - Training.csv,CC0-1.0,"### Context

Coming Soon

### Content

Coming Soon


### Acknowledgements

This data is taken from coinmarketcap and it is free to use the data.
https://coinmarketcap.com/

### Warning

実際の取引にこの情報を使うときは十分ご注意ください。弊社およびコミュニティメンバーは損失の責任を取ることができません。",.csv,True
Bitcoin Price Prediction (LightWeight CSV),2,bitcoin-price-prediction,bitcoin_price_1week_Test - Test.csv,CC0-1.0,"### Context

Coming Soon

### Content

Coming Soon


### Acknowledgements

This data is taken from coinmarketcap and it is free to use the data.
https://coinmarketcap.com/

### Warning

実際の取引にこの情報を使うときは十分ご注意ください。弊社およびコミュニティメンバーは損失の責任を取ることができません。",.csv,True
Board Game Data,3,board-game-data,bgg_db_1806.csv,CC0-1.0,"# Context 

Being a fan of board games, I wanted to see if there was any correlation with a games rating and any particular quality, the first step was to collect of this data.

# Content

The data was collected in March of 2017 from the website https://boardgamegeek.com/, this site has an API to retrieve game information (though sadly XML not JSON).


# Acknowledgements

Mainly I want to thank the people who run the board game geek website for maintaining such a great resource for those of us in the hobby.


# Inspiration

I wish I had some better questions to ask of the data, perhaps somebody else can think of some good ways to get some insight of this dataset.",.csv,True
Board Game Data,3,board-game-data,bgg_db_2017_04.csv,CC0-1.0,"# Context 

Being a fan of board games, I wanted to see if there was any correlation with a games rating and any particular quality, the first step was to collect of this data.

# Content

The data was collected in March of 2017 from the website https://boardgamegeek.com/, this site has an API to retrieve game information (though sadly XML not JSON).


# Acknowledgements

Mainly I want to thank the people who run the board game geek website for maintaining such a great resource for those of us in the hobby.


# Inspiration

I wish I had some better questions to ask of the data, perhaps somebody else can think of some good ways to get some insight of this dataset.",.csv,True
Board Game Data,3,board-game-data,bgg_db_2018_01.csv,CC0-1.0,"# Context 

Being a fan of board games, I wanted to see if there was any correlation with a games rating and any particular quality, the first step was to collect of this data.

# Content

The data was collected in March of 2017 from the website https://boardgamegeek.com/, this site has an API to retrieve game information (though sadly XML not JSON).


# Acknowledgements

Mainly I want to thank the people who run the board game geek website for maintaining such a great resource for those of us in the hobby.


# Inspiration

I wish I had some better questions to ask of the data, perhaps somebody else can think of some good ways to get some insight of this dataset.",.csv,True
Brain stroke prediction dataset,2,full-filled-brain-stroke-dataset,full_data.csv,CC0-1.0,"#Story of dataset:

You can reach the original source of the data from the link.
[Original Dataset](https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset)

While working on this data, there were 210 missing data available in a single numeric column. I've tried handling missing values, treating this just like a regression problem. I got some very interesting results. And I have even seen a similar designation in one of the top-rated notebooks, but there had been no performance evaluation for this designation and I considered it a shortcoming. Then considering R_square, I thought that the pipeline-based data assignment actually had a very low result and shouldn't even be considered a regression because the result was less than 0.3 [:](https://www.kaggle.com/thomaskonstantin/analyzing-and-modeling-stroke-data) 

Instead, I found the most suitable algorithms (GradientBoostingRegressor, CatBoost, Light_GBM, and XGBoost) for a similar assignment with PyCaret, optimized it with optuna, and then developed a model using the blend method. 

###Validation data values with this model;
#### R_sqr: 0.3035774217245104
#### MSE: 32.60242593653817

I know still low, but this model showed the highest performance among all models. Then I wanted to make it available to all Kagglers.

In terms of model estimation, you can try my previous notebook: [My notebook](https://www.kaggle.com/code/zzettrkalpakbal/pycaret-regressor-for-integrating-missing-values)

**## Context: **

A stroke is a medical condition in which poor blood flow to the brain causes cell death. There are two main types of stroke: ischemic, due to lack of blood flow, and hemorrhagic, due to bleeding. Both cause parts of the brain to stop functioning properly. Signs and symptoms of a stroke may include an inability to move or feel on one side of the body, problems understanding or speaking, dizziness, or loss of vision to one side. Signs and symptoms often appear soon after the stroke has occurred. If symptoms last less than one or two hours, the stroke is a transient ischemic attack (TIA), also called a mini-stroke. A hemorrhagic stroke may also be associated with a severe headache. The symptoms of a stroke can be permanent. Long-term complications may include pneumonia and loss of bladder control.

The main risk factor for stroke is high blood pressure. Other risk factors include high blood cholesterol, tobacco smoking, obesity, diabetes mellitus, a previous TIA, end-stage kidney disease, and atrial fibrillation. An ischemic stroke is typically caused by blockage of a blood vessel, though there are also less common causes. A hemorrhagic stroke is caused by either bleeding directly into the brain or into the space between the brain's membranes. Bleeding may occur due to a ruptured brain aneurysm. Diagnosis is typically based on a physical exam and supported by medical imaging such as a CT scan or MRI scan. A CT scan can rule out bleeding, but may not necessarily rule out ischemia, which early on typically does not show up on a CT scan. Other tests such as an electrocardiogram (ECG) and blood tests are done to determine risk factors and rule out other possible causes. Low blood sugar may cause similar symptoms.

Prevention includes decreasing risk factors, surgery to open up the arteries to the brain in those with problematic carotid narrowing, and warfarin in people with atrial fibrillation. Aspirin or statins may be recommended by physicians for prevention. A stroke or TIA often requires emergency care. An ischemic stroke, if detected within three to four and half hours, may be treatable with a medication that can break down the clot. Some hemorrhagic strokes benefit from surgery. Treatment to attempt recovery of lost function is called stroke rehabilitation, and ideally takes place in a stroke unit; however, these are not available in much of the world.

**##Attribute Information**

1) gender: ""Male"", ""Female"" or ""Other""
2) age: age of the patient
3) hypertension: 0 if the patient doesn't have hypertension, 1 if the patient has hypertension
4) heart_disease: 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease
5) ever_married: ""No"" or ""Yes""
6) work_type: ""children"", ""Govt_jov"", ""Never_worked"", ""Private"" or ""Self-employed""
7) Residence_type: ""Rural"" or ""Urban""
8) avg_glucose_level: average glucose level in blood
9) bmi: body mass index
10) smoking_status: ""formerly smoked"", ""never smoked"", ""smokes"" or ""Unknown""*
11) stroke: 1 if the patient had a stroke or 0 if not

*Note: ""Unknown"" in smoking_status means that the information is unavailable for this patient




## Real data sources:
[Data](https://datahack.analyticsvidhya.com/contest/mckinsey-analytics-online-hackathon/#DiscussTab)
[IEEE article](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9264165)",.csv,True
Brain stroke prediction dataset,2,full-filled-brain-stroke-dataset,full_filled_stroke_data (1).csv,CC0-1.0,"#Story of dataset:

You can reach the original source of the data from the link.
[Original Dataset](https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset)

While working on this data, there were 210 missing data available in a single numeric column. I've tried handling missing values, treating this just like a regression problem. I got some very interesting results. And I have even seen a similar designation in one of the top-rated notebooks, but there had been no performance evaluation for this designation and I considered it a shortcoming. Then considering R_square, I thought that the pipeline-based data assignment actually had a very low result and shouldn't even be considered a regression because the result was less than 0.3 [:](https://www.kaggle.com/thomaskonstantin/analyzing-and-modeling-stroke-data) 

Instead, I found the most suitable algorithms (GradientBoostingRegressor, CatBoost, Light_GBM, and XGBoost) for a similar assignment with PyCaret, optimized it with optuna, and then developed a model using the blend method. 

###Validation data values with this model;
#### R_sqr: 0.3035774217245104
#### MSE: 32.60242593653817

I know still low, but this model showed the highest performance among all models. Then I wanted to make it available to all Kagglers.

In terms of model estimation, you can try my previous notebook: [My notebook](https://www.kaggle.com/code/zzettrkalpakbal/pycaret-regressor-for-integrating-missing-values)

**## Context: **

A stroke is a medical condition in which poor blood flow to the brain causes cell death. There are two main types of stroke: ischemic, due to lack of blood flow, and hemorrhagic, due to bleeding. Both cause parts of the brain to stop functioning properly. Signs and symptoms of a stroke may include an inability to move or feel on one side of the body, problems understanding or speaking, dizziness, or loss of vision to one side. Signs and symptoms often appear soon after the stroke has occurred. If symptoms last less than one or two hours, the stroke is a transient ischemic attack (TIA), also called a mini-stroke. A hemorrhagic stroke may also be associated with a severe headache. The symptoms of a stroke can be permanent. Long-term complications may include pneumonia and loss of bladder control.

The main risk factor for stroke is high blood pressure. Other risk factors include high blood cholesterol, tobacco smoking, obesity, diabetes mellitus, a previous TIA, end-stage kidney disease, and atrial fibrillation. An ischemic stroke is typically caused by blockage of a blood vessel, though there are also less common causes. A hemorrhagic stroke is caused by either bleeding directly into the brain or into the space between the brain's membranes. Bleeding may occur due to a ruptured brain aneurysm. Diagnosis is typically based on a physical exam and supported by medical imaging such as a CT scan or MRI scan. A CT scan can rule out bleeding, but may not necessarily rule out ischemia, which early on typically does not show up on a CT scan. Other tests such as an electrocardiogram (ECG) and blood tests are done to determine risk factors and rule out other possible causes. Low blood sugar may cause similar symptoms.

Prevention includes decreasing risk factors, surgery to open up the arteries to the brain in those with problematic carotid narrowing, and warfarin in people with atrial fibrillation. Aspirin or statins may be recommended by physicians for prevention. A stroke or TIA often requires emergency care. An ischemic stroke, if detected within three to four and half hours, may be treatable with a medication that can break down the clot. Some hemorrhagic strokes benefit from surgery. Treatment to attempt recovery of lost function is called stroke rehabilitation, and ideally takes place in a stroke unit; however, these are not available in much of the world.

**##Attribute Information**

1) gender: ""Male"", ""Female"" or ""Other""
2) age: age of the patient
3) hypertension: 0 if the patient doesn't have hypertension, 1 if the patient has hypertension
4) heart_disease: 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease
5) ever_married: ""No"" or ""Yes""
6) work_type: ""children"", ""Govt_jov"", ""Never_worked"", ""Private"" or ""Self-employed""
7) Residence_type: ""Rural"" or ""Urban""
8) avg_glucose_level: average glucose level in blood
9) bmi: body mass index
10) smoking_status: ""formerly smoked"", ""never smoked"", ""smokes"" or ""Unknown""*
11) stroke: 1 if the patient had a stroke or 0 if not

*Note: ""Unknown"" in smoking_status means that the information is unavailable for this patient




## Real data sources:
[Data](https://datahack.analyticsvidhya.com/contest/mckinsey-analytics-online-hackathon/#DiscussTab)
[IEEE article](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9264165)",.csv,True
Breast Cancer Dataset,2,breast-cancer-dataset-used-royston-and-altman,gbsg.csv,CC0-1.0,"The data set contains patient records from a 1984-1989 trial conducted by the German Breast Cancer Study Group (GBSG) of 720 patients with node positive breast cancer; it retains the 686 patients with complete data for the prognostic variables.
These data sets are used in the paper by Royston and Altman(2013). The Rotterdam data is used to create a fitted model, and the GBSG data for validation of the model. The paper gives references for the data source.
# Dataset Format
A data set with 686 observations and 11 variables.

| Columns | Description |
| --- | --- |
| pid | patient identifier |
| age | age, years |
| meno | menopausal status (0= premenopausal, 1= postmenopausal) |
| size | tumor size, mm |
| grade | tumor grade |
| nodes | number of positive lymph nodes |
| pgr | progesterone receptors (fmol/l) |
| er | estrogen receptors (fmol/l) |
| hormon | hormonal therapy, 0= no, 1= yes |
| rfstime | recurrence free survival time; days to first of recurrence, death or last follow-up |
| status | 0= alive without recurrence, 1= recurrence or death |

# References
Patrick Royston and Douglas Altman, External validation of a Cox prognostic model: principles and methods. BMC Medical Research Methodology 2013, 13:33",.csv,True
Breast Cancer Dataset,2,breast-cancer-data,breast-cancer-data.csv,other,"This breast cancer domain was obtained from the University Medical Centre, Institute of Oncology, Ljubljana, Yugoslavia.

## Number of Instances: 286

### Number of Attributes: 10
####    Attribute Information:

1. class: no-recurrence-events, recurrence-events
2. age: 10-19, 20-29, 30-39, 40-49, 50-59, 60-69, 70-79, 80-89, 90-99.
3. menopause: lt40, ge40, premeno.
4. tumor-size: 0-4, 5-9, 10-14, 15-19, 20-24, 25-29, 30-34, 35-39, 40-44, 45-49, 50-54, 55-59.
5. inv-nodes: 0-2, 3-5, 6-8, 9-11, 12-14, 15-17, 18-20, 21-23, 24-26, 27-29, 30-32, 33-35, 36-39.
6. node-caps: yes, no.
7. deg-malig: 1, 2, 3.
8. breast: left, right.
9. breast-quad: left-up, left-low, right-up,	right-low, central.
10. irradiate:	yes, no.

Missing Attribute Values: (denoted by ""?"")
   Attribute #:  Number of instances with missing values:
   6.             8
   9.             1.

Class Distribution:
    1. no-recurrence-events: 201 instances
    2. recurrence-events: 85 instances",.csv,True
CO2 Emissions,2,co2-emissions-by-country,co2_emissions_kt_by_country.csv,Attribution 4.0 International (CC BY 4.0),"The impact of greenhouse gas emissions, particularly carbon dioxide (CO2), on the earth's climate has become an increasingly important issue in recent years. CO2 emissions are produced by a variety of human activities, including the burning of fossil fuels, deforestation, and industrial processes. Understanding how much CO2 each country is emitting is crucial in developing effective climate policies and mitigating the effects of climate change.

The CO2 emissions dataset provides a comprehensive overview of the amount of CO2 emitted by each country. The dataset includes information on CO2 emissions by country from 1960 to the present day. It covers all countries in the world and is compiled from various sources, including the United Nations Framework Convention on Climate Change (UNFCCC) and the International Energy Agency (IEA).

The dataset can be used by researchers, policymakers, and the general public to gain insight into the relative contributions of different countries to global CO2 emissions. It can also be used to monitor changes in emissions over time and to assess the effectiveness of climate policies.

Overall, the CO2 emissions dataset is an important resource for understanding the global climate challenge and for developing strategies to mitigate the impact of CO2 emissions on our planet.",.csv,True
CO2 Emissions,2,co2-emissions,CO2 Emissions.csv,DbCL-1.0,"CO2 emissions have significant environmental impacts. The accumulation of CO2 in the atmosphere contributes to the greenhouse effect, trapping heat and causing global warming. This leads to various adverse effects, including rising global temperatures, sea-level rise, changes in weather patterns, and ecosystem disruptions. The long-term consequences of climate change can negatively impact human health, agriculture, biodiversity, and socio-economic systems.

Therefore, reducing CO2 emissions is crucial for mitigating climate change and minimizing its harmful effects on the environment and human well-being. This involves transitioning to cleaner and renewable energy sources, improving energy efficiency, adopting sustainable practices, and promoting conservation efforts.


",.csv,True
COVID-19: Holidays of countries,4,covid19-holidays-of-countries,holidays_df_of_70_countries_for_covid_19_2022_Temporary.csv,Attribution 4.0 International (CC BY 4.0),"### Context
This research is devoted to the analysis of the impact of holidays on the statistics of confirmed coronavirus diseases.
The Prophet using the [**holidays** library](https://github.com/dr-prodigy/python-holidays) with holidays of countries and their regions.
**As of 30 June 2020, only 62 countries** (some with regions) are available in the holidays library:
&gt; ['AR', 'AT', 'AU', 'BD', 'BE', 'BG', 'BR', 'BY', 'CA', 'CH', 'CL', 'CN', 'CO', 'CZ', 'DE', 'DK', 'DO', 'EE', 'EG', 'ES', 'FI', 'FR', 'GB', 'GR', 'HN', 'HR', 'HU', 'ID', 'IE', 'IL', 'IN', 'IS', 'IT', 'JP', 'KE', 'KR', 'LT', 'LU', 'MX', 'MY', 'NG', 'NI', 'NL', 'NO', 'NZ', 'PE', 'PH', 'PK', 'PL', 'PT', 'PY', 'RS', 'RU', 'SE', 'SG', 'SI', 'SK', 'TH', 'TR', 'UA', 'US', 'ZA'] or ['Argentina', 'Australia', 'Austria', 'Bangladesh', 'Belarus', 'Belgium', 'Brazil', 'Bulgaria', 'Canada', 'Chile', 'China',  'Colombia', 'Croatia', 'Czechia', 'Denmark', 'Dominican Republic', 'Egypt', 'Estonia', 'Finland', 'France', 'Germany', 'Greece', 'Honduras', 'Hungary', 'Iceland', 'India', 'Indonesia', 'Ireland', 'Israel', 'Italy', 'Japan', 'Kenya', 'Korea, Republic of', 'Lithuania', 'Luxembourg', 'Malaysia', 'Mexico', 'Netherlands', 'New Zealand', 'Nicaragua', 'Nigeria', 'Norway', 'Pakistan', 'Paraguay', 'Peru', 'Philippines', 'Poland', 'Portugal', 'Russian Federation', 'Serbia', 'Singapore', 'Slovakia', 'Slovenia', 'South Africa', 'Spain', 'Sweden', 'Switzerland', 'Thailand', 'Turkey', 'Ukraine', 'United Kingdom', 'United States']

I will note at once that the list of available countries in the description of the holidays library contains a lot of mistakes, which I [wrote](https://github.com/dr-prodigy/python-holidays/issues/340#issue-668480961) to the authors.

When I [asked](https://github.com/facebook/prophet/issues/1587#issue-661093141) if this list would expand, the Prophet team [made it clear](https://github.com/facebook/prophet/issues/1587#issuecomment-661982602) that they were waiting for help from the community with holidays library expand.

**As of Jan 2021 (version 8.4.1), 67 countries** (some with regions) are available in the holidays library: a number of data have been refined and countries ['BI', 'LV', 'MA', 'RO', 'VN' - two-letter country codes or alpha_2 of the country (ISO 3166)] added.

Unfortunately, the format of the holidays library is not very suitable for coronavirus problems, as it has a number of disadvantages. First, the names of the countries are given in one word, which makes it difficult for many of them to identify them according to their common names (ISO 3166). It is best that the dataset contains the common name and two-letter abbreviation in English according to ISO 3166 (see [pycountry](https://pypi.org/project/pycountry/)).
Second, the dates are not adapted to the potential impact of the holidays on coronavirus statistics. It is known that after the moment of infection, the active manifestation of symptoms occurs with a delay of 4-10 days, that is a person is likely to get into the statistics on the number of diseases only after 4-7 days. Therefore, it is advisable to use the dates window of impacts:
```
Lower_window = [4, 7]
Upper_window = [7, 10]

```However, the Prophet technology requires 
`Lower_window &lt;= 0`
But my [request](https://github.com/facebook/prophet/issues/1588#issue-661098613) to allow positive numbers in this parameter [was refused](https://github.com/facebook/prophet/issues/1588#issuecomment-661984730) by the Prophet team and [advised](https://github.com/facebook/prophet/issues/1588#issuecomment-661984730) to simply move the dates themselves.
Therefore, it is advisable to shift the holiday dates by 7 days. If the researcher thinks that 7 is too much and enough is 4 days, then he simply indicates ""Lower"" of the window in -3. Actually, by default, it makes sense to specify parameters:
```
Lower_window = -3
Upper_window = 3

```
If necessary, these settings are easy to change

### Content

This dataset:
1. Contains ISO codes, ISO names (common and official) (ISO 3166) of **70** countries (3 European countries **['Albania' - 'AL', 'Georgia' - 'GE', 'Moldova' - 'MD']** have been added).
2. Contains imported dates from the holidays library for 2020-01-20-2021-12-31 (all countries from holidays library as of Jan 2021), and the same dates, but moved 7 days forward.
3. Holidays of countries that are not in the list of holidays of the library, but which are in the data of the World Health Organization and on which considerable statistics of diseases on coronavirus are already collected.
4. Parameters for Prophet model:
`lower_window, upper_window, prior_scale`
If you find errors, please write to the [Discussion](https://www.kaggle.com/vbmokin/covid19-holidays-of-countries/discussion).

It is planned to periodically update (and, if necessary, correct) this dataset. 

### Acknowledgements

Thanks to the authors of the information resources
* [https://github.com/dr-prodigy/python-holidays](https://github.com/dr-prodigy/python-holidays)
* [https://en.wikipedia.org/wiki/List_of_holidays_by_country](https://en.wikipedia.org/wiki/List_of_holidays_by_country)
about the dates and names of holidays in different countries, which I used.

Thanks for the image to <a href=""https://pixabay.com/ru/users/iXimus-2352783/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=5062659"">iXimus</a> from <a href=""https://pixabay.com/ru/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=5062659"">Pixabay</a>


### Inspiration

The main task for which this dataset was created is to study the impact of holidays on the accuracy of predicting coronavirus diseases, identifying new patterns, and forming optimal solutions to counteract or minimize its spread.

Tasks that need to be solved to improve this dataset in order to increase the accuracy of modeling the impact of holidays on the number of coronavirus patients:
1) Expanding the list of countries
2) Clarification of holiday dates
3) Clarification of parameters 
`lower_window, upper_window, prior_scale`
they must be unique for each country and each holiday.

Also, it is advisable to carry out similar work for each region of countries, but this will not be done in this dataset.",.csv,True
COVID-19: Holidays of countries,4,covid19-holidays-of-countries,holidays_df_of_70_countries_for_covid_19_2021.csv,Attribution 4.0 International (CC BY 4.0),"### Context
This research is devoted to the analysis of the impact of holidays on the statistics of confirmed coronavirus diseases.
The Prophet using the [**holidays** library](https://github.com/dr-prodigy/python-holidays) with holidays of countries and their regions.
**As of 30 June 2020, only 62 countries** (some with regions) are available in the holidays library:
&gt; ['AR', 'AT', 'AU', 'BD', 'BE', 'BG', 'BR', 'BY', 'CA', 'CH', 'CL', 'CN', 'CO', 'CZ', 'DE', 'DK', 'DO', 'EE', 'EG', 'ES', 'FI', 'FR', 'GB', 'GR', 'HN', 'HR', 'HU', 'ID', 'IE', 'IL', 'IN', 'IS', 'IT', 'JP', 'KE', 'KR', 'LT', 'LU', 'MX', 'MY', 'NG', 'NI', 'NL', 'NO', 'NZ', 'PE', 'PH', 'PK', 'PL', 'PT', 'PY', 'RS', 'RU', 'SE', 'SG', 'SI', 'SK', 'TH', 'TR', 'UA', 'US', 'ZA'] or ['Argentina', 'Australia', 'Austria', 'Bangladesh', 'Belarus', 'Belgium', 'Brazil', 'Bulgaria', 'Canada', 'Chile', 'China',  'Colombia', 'Croatia', 'Czechia', 'Denmark', 'Dominican Republic', 'Egypt', 'Estonia', 'Finland', 'France', 'Germany', 'Greece', 'Honduras', 'Hungary', 'Iceland', 'India', 'Indonesia', 'Ireland', 'Israel', 'Italy', 'Japan', 'Kenya', 'Korea, Republic of', 'Lithuania', 'Luxembourg', 'Malaysia', 'Mexico', 'Netherlands', 'New Zealand', 'Nicaragua', 'Nigeria', 'Norway', 'Pakistan', 'Paraguay', 'Peru', 'Philippines', 'Poland', 'Portugal', 'Russian Federation', 'Serbia', 'Singapore', 'Slovakia', 'Slovenia', 'South Africa', 'Spain', 'Sweden', 'Switzerland', 'Thailand', 'Turkey', 'Ukraine', 'United Kingdom', 'United States']

I will note at once that the list of available countries in the description of the holidays library contains a lot of mistakes, which I [wrote](https://github.com/dr-prodigy/python-holidays/issues/340#issue-668480961) to the authors.

When I [asked](https://github.com/facebook/prophet/issues/1587#issue-661093141) if this list would expand, the Prophet team [made it clear](https://github.com/facebook/prophet/issues/1587#issuecomment-661982602) that they were waiting for help from the community with holidays library expand.

**As of Jan 2021 (version 8.4.1), 67 countries** (some with regions) are available in the holidays library: a number of data have been refined and countries ['BI', 'LV', 'MA', 'RO', 'VN' - two-letter country codes or alpha_2 of the country (ISO 3166)] added.

Unfortunately, the format of the holidays library is not very suitable for coronavirus problems, as it has a number of disadvantages. First, the names of the countries are given in one word, which makes it difficult for many of them to identify them according to their common names (ISO 3166). It is best that the dataset contains the common name and two-letter abbreviation in English according to ISO 3166 (see [pycountry](https://pypi.org/project/pycountry/)).
Second, the dates are not adapted to the potential impact of the holidays on coronavirus statistics. It is known that after the moment of infection, the active manifestation of symptoms occurs with a delay of 4-10 days, that is a person is likely to get into the statistics on the number of diseases only after 4-7 days. Therefore, it is advisable to use the dates window of impacts:
```
Lower_window = [4, 7]
Upper_window = [7, 10]

```However, the Prophet technology requires 
`Lower_window &lt;= 0`
But my [request](https://github.com/facebook/prophet/issues/1588#issue-661098613) to allow positive numbers in this parameter [was refused](https://github.com/facebook/prophet/issues/1588#issuecomment-661984730) by the Prophet team and [advised](https://github.com/facebook/prophet/issues/1588#issuecomment-661984730) to simply move the dates themselves.
Therefore, it is advisable to shift the holiday dates by 7 days. If the researcher thinks that 7 is too much and enough is 4 days, then he simply indicates ""Lower"" of the window in -3. Actually, by default, it makes sense to specify parameters:
```
Lower_window = -3
Upper_window = 3

```
If necessary, these settings are easy to change

### Content

This dataset:
1. Contains ISO codes, ISO names (common and official) (ISO 3166) of **70** countries (3 European countries **['Albania' - 'AL', 'Georgia' - 'GE', 'Moldova' - 'MD']** have been added).
2. Contains imported dates from the holidays library for 2020-01-20-2021-12-31 (all countries from holidays library as of Jan 2021), and the same dates, but moved 7 days forward.
3. Holidays of countries that are not in the list of holidays of the library, but which are in the data of the World Health Organization and on which considerable statistics of diseases on coronavirus are already collected.
4. Parameters for Prophet model:
`lower_window, upper_window, prior_scale`
If you find errors, please write to the [Discussion](https://www.kaggle.com/vbmokin/covid19-holidays-of-countries/discussion).

It is planned to periodically update (and, if necessary, correct) this dataset. 

### Acknowledgements

Thanks to the authors of the information resources
* [https://github.com/dr-prodigy/python-holidays](https://github.com/dr-prodigy/python-holidays)
* [https://en.wikipedia.org/wiki/List_of_holidays_by_country](https://en.wikipedia.org/wiki/List_of_holidays_by_country)
about the dates and names of holidays in different countries, which I used.

Thanks for the image to <a href=""https://pixabay.com/ru/users/iXimus-2352783/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=5062659"">iXimus</a> from <a href=""https://pixabay.com/ru/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=5062659"">Pixabay</a>


### Inspiration

The main task for which this dataset was created is to study the impact of holidays on the accuracy of predicting coronavirus diseases, identifying new patterns, and forming optimal solutions to counteract or minimize its spread.

Tasks that need to be solved to improve this dataset in order to increase the accuracy of modeling the impact of holidays on the number of coronavirus patients:
1) Expanding the list of countries
2) Clarification of holiday dates
3) Clarification of parameters 
`lower_window, upper_window, prior_scale`
they must be unique for each country and each holiday.

Also, it is advisable to carry out similar work for each region of countries, but this will not be done in this dataset.",.csv,True
COVID-19: Holidays of countries,4,covid19-holidays-of-countries,holidays_df_of_67_countries_for_covid_19.csv,Attribution 4.0 International (CC BY 4.0),"### Context
This research is devoted to the analysis of the impact of holidays on the statistics of confirmed coronavirus diseases.
The Prophet using the [**holidays** library](https://github.com/dr-prodigy/python-holidays) with holidays of countries and their regions.
**As of 30 June 2020, only 62 countries** (some with regions) are available in the holidays library:
&gt; ['AR', 'AT', 'AU', 'BD', 'BE', 'BG', 'BR', 'BY', 'CA', 'CH', 'CL', 'CN', 'CO', 'CZ', 'DE', 'DK', 'DO', 'EE', 'EG', 'ES', 'FI', 'FR', 'GB', 'GR', 'HN', 'HR', 'HU', 'ID', 'IE', 'IL', 'IN', 'IS', 'IT', 'JP', 'KE', 'KR', 'LT', 'LU', 'MX', 'MY', 'NG', 'NI', 'NL', 'NO', 'NZ', 'PE', 'PH', 'PK', 'PL', 'PT', 'PY', 'RS', 'RU', 'SE', 'SG', 'SI', 'SK', 'TH', 'TR', 'UA', 'US', 'ZA'] or ['Argentina', 'Australia', 'Austria', 'Bangladesh', 'Belarus', 'Belgium', 'Brazil', 'Bulgaria', 'Canada', 'Chile', 'China',  'Colombia', 'Croatia', 'Czechia', 'Denmark', 'Dominican Republic', 'Egypt', 'Estonia', 'Finland', 'France', 'Germany', 'Greece', 'Honduras', 'Hungary', 'Iceland', 'India', 'Indonesia', 'Ireland', 'Israel', 'Italy', 'Japan', 'Kenya', 'Korea, Republic of', 'Lithuania', 'Luxembourg', 'Malaysia', 'Mexico', 'Netherlands', 'New Zealand', 'Nicaragua', 'Nigeria', 'Norway', 'Pakistan', 'Paraguay', 'Peru', 'Philippines', 'Poland', 'Portugal', 'Russian Federation', 'Serbia', 'Singapore', 'Slovakia', 'Slovenia', 'South Africa', 'Spain', 'Sweden', 'Switzerland', 'Thailand', 'Turkey', 'Ukraine', 'United Kingdom', 'United States']

I will note at once that the list of available countries in the description of the holidays library contains a lot of mistakes, which I [wrote](https://github.com/dr-prodigy/python-holidays/issues/340#issue-668480961) to the authors.

When I [asked](https://github.com/facebook/prophet/issues/1587#issue-661093141) if this list would expand, the Prophet team [made it clear](https://github.com/facebook/prophet/issues/1587#issuecomment-661982602) that they were waiting for help from the community with holidays library expand.

**As of Jan 2021 (version 8.4.1), 67 countries** (some with regions) are available in the holidays library: a number of data have been refined and countries ['BI', 'LV', 'MA', 'RO', 'VN' - two-letter country codes or alpha_2 of the country (ISO 3166)] added.

Unfortunately, the format of the holidays library is not very suitable for coronavirus problems, as it has a number of disadvantages. First, the names of the countries are given in one word, which makes it difficult for many of them to identify them according to their common names (ISO 3166). It is best that the dataset contains the common name and two-letter abbreviation in English according to ISO 3166 (see [pycountry](https://pypi.org/project/pycountry/)).
Second, the dates are not adapted to the potential impact of the holidays on coronavirus statistics. It is known that after the moment of infection, the active manifestation of symptoms occurs with a delay of 4-10 days, that is a person is likely to get into the statistics on the number of diseases only after 4-7 days. Therefore, it is advisable to use the dates window of impacts:
```
Lower_window = [4, 7]
Upper_window = [7, 10]

```However, the Prophet technology requires 
`Lower_window &lt;= 0`
But my [request](https://github.com/facebook/prophet/issues/1588#issue-661098613) to allow positive numbers in this parameter [was refused](https://github.com/facebook/prophet/issues/1588#issuecomment-661984730) by the Prophet team and [advised](https://github.com/facebook/prophet/issues/1588#issuecomment-661984730) to simply move the dates themselves.
Therefore, it is advisable to shift the holiday dates by 7 days. If the researcher thinks that 7 is too much and enough is 4 days, then he simply indicates ""Lower"" of the window in -3. Actually, by default, it makes sense to specify parameters:
```
Lower_window = -3
Upper_window = 3

```
If necessary, these settings are easy to change

### Content

This dataset:
1. Contains ISO codes, ISO names (common and official) (ISO 3166) of **70** countries (3 European countries **['Albania' - 'AL', 'Georgia' - 'GE', 'Moldova' - 'MD']** have been added).
2. Contains imported dates from the holidays library for 2020-01-20-2021-12-31 (all countries from holidays library as of Jan 2021), and the same dates, but moved 7 days forward.
3. Holidays of countries that are not in the list of holidays of the library, but which are in the data of the World Health Organization and on which considerable statistics of diseases on coronavirus are already collected.
4. Parameters for Prophet model:
`lower_window, upper_window, prior_scale`
If you find errors, please write to the [Discussion](https://www.kaggle.com/vbmokin/covid19-holidays-of-countries/discussion).

It is planned to periodically update (and, if necessary, correct) this dataset. 

### Acknowledgements

Thanks to the authors of the information resources
* [https://github.com/dr-prodigy/python-holidays](https://github.com/dr-prodigy/python-holidays)
* [https://en.wikipedia.org/wiki/List_of_holidays_by_country](https://en.wikipedia.org/wiki/List_of_holidays_by_country)
about the dates and names of holidays in different countries, which I used.

Thanks for the image to <a href=""https://pixabay.com/ru/users/iXimus-2352783/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=5062659"">iXimus</a> from <a href=""https://pixabay.com/ru/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=5062659"">Pixabay</a>


### Inspiration

The main task for which this dataset was created is to study the impact of holidays on the accuracy of predicting coronavirus diseases, identifying new patterns, and forming optimal solutions to counteract or minimize its spread.

Tasks that need to be solved to improve this dataset in order to increase the accuracy of modeling the impact of holidays on the number of coronavirus patients:
1) Expanding the list of countries
2) Clarification of holiday dates
3) Clarification of parameters 
`lower_window, upper_window, prior_scale`
they must be unique for each country and each holiday.

Also, it is advisable to carry out similar work for each region of countries, but this will not be done in this dataset.",.csv,True
COVID-19: Holidays of countries,4,covid19-holidays-of-countries,holidays_df_of_70_countries_for_covid_19.csv,Attribution 4.0 International (CC BY 4.0),"### Context
This research is devoted to the analysis of the impact of holidays on the statistics of confirmed coronavirus diseases.
The Prophet using the [**holidays** library](https://github.com/dr-prodigy/python-holidays) with holidays of countries and their regions.
**As of 30 June 2020, only 62 countries** (some with regions) are available in the holidays library:
&gt; ['AR', 'AT', 'AU', 'BD', 'BE', 'BG', 'BR', 'BY', 'CA', 'CH', 'CL', 'CN', 'CO', 'CZ', 'DE', 'DK', 'DO', 'EE', 'EG', 'ES', 'FI', 'FR', 'GB', 'GR', 'HN', 'HR', 'HU', 'ID', 'IE', 'IL', 'IN', 'IS', 'IT', 'JP', 'KE', 'KR', 'LT', 'LU', 'MX', 'MY', 'NG', 'NI', 'NL', 'NO', 'NZ', 'PE', 'PH', 'PK', 'PL', 'PT', 'PY', 'RS', 'RU', 'SE', 'SG', 'SI', 'SK', 'TH', 'TR', 'UA', 'US', 'ZA'] or ['Argentina', 'Australia', 'Austria', 'Bangladesh', 'Belarus', 'Belgium', 'Brazil', 'Bulgaria', 'Canada', 'Chile', 'China',  'Colombia', 'Croatia', 'Czechia', 'Denmark', 'Dominican Republic', 'Egypt', 'Estonia', 'Finland', 'France', 'Germany', 'Greece', 'Honduras', 'Hungary', 'Iceland', 'India', 'Indonesia', 'Ireland', 'Israel', 'Italy', 'Japan', 'Kenya', 'Korea, Republic of', 'Lithuania', 'Luxembourg', 'Malaysia', 'Mexico', 'Netherlands', 'New Zealand', 'Nicaragua', 'Nigeria', 'Norway', 'Pakistan', 'Paraguay', 'Peru', 'Philippines', 'Poland', 'Portugal', 'Russian Federation', 'Serbia', 'Singapore', 'Slovakia', 'Slovenia', 'South Africa', 'Spain', 'Sweden', 'Switzerland', 'Thailand', 'Turkey', 'Ukraine', 'United Kingdom', 'United States']

I will note at once that the list of available countries in the description of the holidays library contains a lot of mistakes, which I [wrote](https://github.com/dr-prodigy/python-holidays/issues/340#issue-668480961) to the authors.

When I [asked](https://github.com/facebook/prophet/issues/1587#issue-661093141) if this list would expand, the Prophet team [made it clear](https://github.com/facebook/prophet/issues/1587#issuecomment-661982602) that they were waiting for help from the community with holidays library expand.

**As of Jan 2021 (version 8.4.1), 67 countries** (some with regions) are available in the holidays library: a number of data have been refined and countries ['BI', 'LV', 'MA', 'RO', 'VN' - two-letter country codes or alpha_2 of the country (ISO 3166)] added.

Unfortunately, the format of the holidays library is not very suitable for coronavirus problems, as it has a number of disadvantages. First, the names of the countries are given in one word, which makes it difficult for many of them to identify them according to their common names (ISO 3166). It is best that the dataset contains the common name and two-letter abbreviation in English according to ISO 3166 (see [pycountry](https://pypi.org/project/pycountry/)).
Second, the dates are not adapted to the potential impact of the holidays on coronavirus statistics. It is known that after the moment of infection, the active manifestation of symptoms occurs with a delay of 4-10 days, that is a person is likely to get into the statistics on the number of diseases only after 4-7 days. Therefore, it is advisable to use the dates window of impacts:
```
Lower_window = [4, 7]
Upper_window = [7, 10]

```However, the Prophet technology requires 
`Lower_window &lt;= 0`
But my [request](https://github.com/facebook/prophet/issues/1588#issue-661098613) to allow positive numbers in this parameter [was refused](https://github.com/facebook/prophet/issues/1588#issuecomment-661984730) by the Prophet team and [advised](https://github.com/facebook/prophet/issues/1588#issuecomment-661984730) to simply move the dates themselves.
Therefore, it is advisable to shift the holiday dates by 7 days. If the researcher thinks that 7 is too much and enough is 4 days, then he simply indicates ""Lower"" of the window in -3. Actually, by default, it makes sense to specify parameters:
```
Lower_window = -3
Upper_window = 3

```
If necessary, these settings are easy to change

### Content

This dataset:
1. Contains ISO codes, ISO names (common and official) (ISO 3166) of **70** countries (3 European countries **['Albania' - 'AL', 'Georgia' - 'GE', 'Moldova' - 'MD']** have been added).
2. Contains imported dates from the holidays library for 2020-01-20-2021-12-31 (all countries from holidays library as of Jan 2021), and the same dates, but moved 7 days forward.
3. Holidays of countries that are not in the list of holidays of the library, but which are in the data of the World Health Organization and on which considerable statistics of diseases on coronavirus are already collected.
4. Parameters for Prophet model:
`lower_window, upper_window, prior_scale`
If you find errors, please write to the [Discussion](https://www.kaggle.com/vbmokin/covid19-holidays-of-countries/discussion).

It is planned to periodically update (and, if necessary, correct) this dataset. 

### Acknowledgements

Thanks to the authors of the information resources
* [https://github.com/dr-prodigy/python-holidays](https://github.com/dr-prodigy/python-holidays)
* [https://en.wikipedia.org/wiki/List_of_holidays_by_country](https://en.wikipedia.org/wiki/List_of_holidays_by_country)
about the dates and names of holidays in different countries, which I used.

Thanks for the image to <a href=""https://pixabay.com/ru/users/iXimus-2352783/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=5062659"">iXimus</a> from <a href=""https://pixabay.com/ru/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=5062659"">Pixabay</a>


### Inspiration

The main task for which this dataset was created is to study the impact of holidays on the accuracy of predicting coronavirus diseases, identifying new patterns, and forming optimal solutions to counteract or minimize its spread.

Tasks that need to be solved to improve this dataset in order to increase the accuracy of modeling the impact of holidays on the number of coronavirus patients:
1) Expanding the list of countries
2) Clarification of holiday dates
3) Clarification of parameters 
`lower_window, upper_window, prior_scale`
they must be unique for each country and each holiday.

Also, it is advisable to carry out similar work for each region of countries, but this will not be done in this dataset.",.csv,True
Car Price Prediction Dataset,3,car-price-prediction-dataset,train_data.csv,Attribution 4.0 International (CC BY 4.0),"Car price prediction is a major research topic in machine learning. It's based on finance and marketing, and is a key area of research because car prices depend on many factors. 

&gt; Key features:
- **Car_Name**: Identify the brand or company name along with the specific model of each vehicle.
- **Year**: Discover the manufacturing year of the vehicles, crucial for assessing depreciation and technology advancements.
- **Selling_Price**: Selling price of car
- **Present_Price**: Current origin price of car
- **Kms_Driven**: Obtain the mileage of each vehicle, a key indicator of wear and tear and potential maintenance requirements.
- **Fuel_Type**: Learn about the type of fuel the vehicles run on, whether it's petrol or diesel.
- **Seller_Type**: Seller type weather dealer or individual
- **Transmission**: Determine the transmission type, whether automatic, manual, or another variant.
- **Owner**: How many owner of car (0, 1, 2, or 3)
",.csv,True
Car Price Prediction Dataset,3,car-price-prediction-dataset,test_data.csv,Attribution 4.0 International (CC BY 4.0),"Car price prediction is a major research topic in machine learning. It's based on finance and marketing, and is a key area of research because car prices depend on many factors. 

&gt; Key features:
- **Car_Name**: Identify the brand or company name along with the specific model of each vehicle.
- **Year**: Discover the manufacturing year of the vehicles, crucial for assessing depreciation and technology advancements.
- **Selling_Price**: Selling price of car
- **Present_Price**: Current origin price of car
- **Kms_Driven**: Obtain the mileage of each vehicle, a key indicator of wear and tear and potential maintenance requirements.
- **Fuel_Type**: Learn about the type of fuel the vehicles run on, whether it's petrol or diesel.
- **Seller_Type**: Seller type weather dealer or individual
- **Transmission**: Determine the transmission type, whether automatic, manual, or another variant.
- **Owner**: How many owner of car (0, 1, 2, or 3)
",.csv,True
Car Price Prediction Dataset,3,sample34,processes2.csv,Apache 2.0,The Car Price Prediction Dataset is designed for predicting the prices of used cars based on various features. This dataset is valuable for machine learning and regression analysis to understand the factors influencing car prices in the market.,.csv,True
Causes of Death in Indonesia,2,cause-of-death-in-indonesia,Penyebab Kematian di Indonesia yang Dilaporkan - Raw.csv,CC-BY-NC-SA-4.0,"### Context

Dataset Penyebab Kematian di Indonesia dikompilasi dalam bentuk file CSV untuk memudahkan analisis.


### Content

Data dikompilasi berdasarkan data eksplisit yang disebutkan di dalam laporan. Tidak mengikutsertakan data estimasi dan data implisit (yang hanya menyebutkan ""banyak"", ""sedikit"", dicantumkan relatif terhadap populasi, multi-intepretasi, dll). Dataset ini terdiri dari 2 file, yaitu sbb:
1. ""Penyebab Kematian di Indonesia yang Dilaporkan - Raw.csv"" : berisi data yang dikompilasi dari Profil Kesehatan Indonesia Tahun 2004 s.d Tahun 2021 dan data COVID-19. URL sumber data tercantum pada kolom ""Source URL"". Kolom ""Type"" (Jenis Penyebab Kematian) diisi oleh saya sendiri, tidak berasal dari sumber yang telah disebutkan, namun terinspirasi dari Profil Kesehatan Indonesia Tahun 2019 yang membagi Krisis Kesehatan menurut Jenis Bencana, yaitu Bencana Sosial, Bencana Alam, dan Bencana Non Alam. Dalam konteks dataset ini, saya menggunakan 3 jenis seperti itu tapi sedikit dimodifikasi, yaitu menjadi: ""Bencana Sosial"", ""Bencana Alam"", dan ""Bencana Non Alam dan Penyakit""
1. ""Penyebab Kematian di Indonesia yang Dilaporkan - Clean.csv"" : berisi data yang telah dibersihkan dari file ""Penyebab Kematian di Indonesia yang Dilaporkan - Raw.csv"", melalui metode: a) Untuk row data yang memiliki data redudancy yang lebih dari 1, dipilih data dari laporan tahun terakhir, dengan asumsi bahwa laporan tahun terakhir merupakan update/perbaikan terbaru dari data tahun yang lalu; b) Untuk row data yang memiliki data redudancy yang lebih dari 1 di tahun yang sama, dipilih data yang memiliki jumlah total paling besar. Dalam konteks validitas data, saya menyarankan Anda untuk menggunakan file ""Clean"" ini daripada file ""Raw"". File Raw tetap saya publikasikan untuk transparansi dan koreksi apabila ada informasi lebih lanjut dari Anda atau visitor lain.

Saya telah membuat video visualisasi berdasarkan dataset ini (data COVID-19 per tanggal 28/11/2020), dapat dilihat pada [Youtube (klik di sini)](https://youtu.be/95wgKOGQ5qE).

### Acknowledgements

Terima kasih kepada instansi yang telah mempublikasikan data-data ini, seperti: Kementerian Kesehatan (data Profil Kesehatan Indonesia) melalui website pusdatin.kemkes.go.id dan Satuan Tugas Penanganan COVID-19 melalui website covid19.go.id",.csv,True
Causes of Death in Indonesia,2,cause-of-death-in-indonesia,Penyebab Kematian di Indonesia yang Dilaporkan - Clean.csv,CC-BY-NC-SA-4.0,"### Context

Dataset Penyebab Kematian di Indonesia dikompilasi dalam bentuk file CSV untuk memudahkan analisis.


### Content

Data dikompilasi berdasarkan data eksplisit yang disebutkan di dalam laporan. Tidak mengikutsertakan data estimasi dan data implisit (yang hanya menyebutkan ""banyak"", ""sedikit"", dicantumkan relatif terhadap populasi, multi-intepretasi, dll). Dataset ini terdiri dari 2 file, yaitu sbb:
1. ""Penyebab Kematian di Indonesia yang Dilaporkan - Raw.csv"" : berisi data yang dikompilasi dari Profil Kesehatan Indonesia Tahun 2004 s.d Tahun 2021 dan data COVID-19. URL sumber data tercantum pada kolom ""Source URL"". Kolom ""Type"" (Jenis Penyebab Kematian) diisi oleh saya sendiri, tidak berasal dari sumber yang telah disebutkan, namun terinspirasi dari Profil Kesehatan Indonesia Tahun 2019 yang membagi Krisis Kesehatan menurut Jenis Bencana, yaitu Bencana Sosial, Bencana Alam, dan Bencana Non Alam. Dalam konteks dataset ini, saya menggunakan 3 jenis seperti itu tapi sedikit dimodifikasi, yaitu menjadi: ""Bencana Sosial"", ""Bencana Alam"", dan ""Bencana Non Alam dan Penyakit""
1. ""Penyebab Kematian di Indonesia yang Dilaporkan - Clean.csv"" : berisi data yang telah dibersihkan dari file ""Penyebab Kematian di Indonesia yang Dilaporkan - Raw.csv"", melalui metode: a) Untuk row data yang memiliki data redudancy yang lebih dari 1, dipilih data dari laporan tahun terakhir, dengan asumsi bahwa laporan tahun terakhir merupakan update/perbaikan terbaru dari data tahun yang lalu; b) Untuk row data yang memiliki data redudancy yang lebih dari 1 di tahun yang sama, dipilih data yang memiliki jumlah total paling besar. Dalam konteks validitas data, saya menyarankan Anda untuk menggunakan file ""Clean"" ini daripada file ""Raw"". File Raw tetap saya publikasikan untuk transparansi dan koreksi apabila ada informasi lebih lanjut dari Anda atau visitor lain.

Saya telah membuat video visualisasi berdasarkan dataset ini (data COVID-19 per tanggal 28/11/2020), dapat dilihat pada [Youtube (klik di sini)](https://youtu.be/95wgKOGQ5qE).

### Acknowledgements

Terima kasih kepada instansi yang telah mempublikasikan data-data ini, seperti: Kementerian Kesehatan (data Profil Kesehatan Indonesia) melalui website pusdatin.kemkes.go.id dan Satuan Tugas Penanganan COVID-19 melalui website covid19.go.id",.csv,True
Cheapest Electric Cars 2023,2,cheapest-electric-cars,Cheapestelectriccars-EVDatabase 2023.csv,CC0-1.0,"## *** Updated for 2023 ***

### Context

My research into Electric Vehicles (EV)


### Content

Cheapest EV with specs


### Acknowledgements

Scraped from https://ev-database.org/


",.csv,True
Cheapest Electric Cars 2023,2,cheapest-electric-cars,Cheapestelectriccars-EVDatabase.csv,CC0-1.0,"## *** Updated for 2023 ***

### Context

My research into Electric Vehicles (EV)


### Content

Cheapest EV with specs


### Acknowledgements

Scraped from https://ev-database.org/


",.csv,True
Chennai Water Management,2,chennai-water-management,chennai_reservoir_levels.csv,CC0-1.0,"### Context

Chennai also known as Madras is the capital of the Indian state of Tamil Nadu. Located on the Coromandel Coast off the Bay of Bengal, it is the biggest cultural, economic and educational centre of south India. 

Being my second home, the city is facing an acute water shortage now (June 2019). Chennai is entirely dependent on ground water resources to meet its water needs. There are four reservoirs in the city, namely, Red Hills, Cholavaram, Poondi and Chembarambakkam, with a combined capacity of 11,057 mcft. These are the major sources of fresh water for the city.

Apart from the reservoirs, the other sources of fresh water water are desalination plants at Nemelli and Minjur; aquifers in Neyveli, Minjur and Panchetty; Cauvery water from Veeranam lake;

Here is an attempt to put together a dataset that has the information about the various water sources available in the city. 

### Content

This dataset has details about the water availability in the four main reservoirs over the last 15 years

* Poondi
* Cholavaram
* Redhills
* Chembarambakkam

The data is available on a daily basis and the unit is million cubic feet. 

I am planning to add other data like water availability from Veeranam lake, rainfall levels etc.

### Acknowledgements

Thanks to [Chennai Metropolitan Water Supply & Sewage Board](https://chennaimetrowater.tn.gov.in/), the data is obtained from their site. 

Photo by Erda Estremera on Unsplash


### Inspiration

The idea is to see if we can use this dataset to

1. Visualize the water need / usage of the city
2. Identify whether the water sources availability will be able to meet the needs till the subsequent monsoon?
3. How bad is the current water crisis compared to previous years?
",.csv,True
Chennai Water Management,2,chennai-water-management,chennai_reservoir_rainfall.csv,CC0-1.0,"### Context

Chennai also known as Madras is the capital of the Indian state of Tamil Nadu. Located on the Coromandel Coast off the Bay of Bengal, it is the biggest cultural, economic and educational centre of south India. 

Being my second home, the city is facing an acute water shortage now (June 2019). Chennai is entirely dependent on ground water resources to meet its water needs. There are four reservoirs in the city, namely, Red Hills, Cholavaram, Poondi and Chembarambakkam, with a combined capacity of 11,057 mcft. These are the major sources of fresh water for the city.

Apart from the reservoirs, the other sources of fresh water water are desalination plants at Nemelli and Minjur; aquifers in Neyveli, Minjur and Panchetty; Cauvery water from Veeranam lake;

Here is an attempt to put together a dataset that has the information about the various water sources available in the city. 

### Content

This dataset has details about the water availability in the four main reservoirs over the last 15 years

* Poondi
* Cholavaram
* Redhills
* Chembarambakkam

The data is available on a daily basis and the unit is million cubic feet. 

I am planning to add other data like water availability from Veeranam lake, rainfall levels etc.

### Acknowledgements

Thanks to [Chennai Metropolitan Water Supply & Sewage Board](https://chennaimetrowater.tn.gov.in/), the data is obtained from their site. 

Photo by Erda Estremera on Unsplash


### Inspiration

The idea is to see if we can use this dataset to

1. Visualize the water need / usage of the city
2. Identify whether the water sources availability will be able to meet the needs till the subsequent monsoon?
3. How bad is the current water crisis compared to previous years?
",.csv,True
City Happiness Index - 2024,2,city-happiness-index-2024,test.csv,CC-BY-NC-SA-4.0,"**Dataset Name:** City Happiness Index

**Dataset Description:**

This dataset and the related codes are entirely prepared, original, and exclusive by Emirhan BULUT. The dataset includes crucial features and measurements from various cities around the world, focusing on factors that may affect the overall happiness score of each city. By analyzing these factors, we aim to gain insights into the living conditions and satisfaction of the population in urban environments.

The dataset consists of the following features:

- City: Name of the city.
- Month: The month in which the data is recorded.
- Year: The year in which the data is recorded.
- Decibel_Level: Average noise levels in decibels, indicating the auditory comfort of the citizens.
- Traffic_Density: Level of traffic density (Low, Medium, High, Very High), which might impact citizens' daily commute and stress levels.
- Green_Space_Area: Percentage of green spaces in the city, positively contributing to the mental well-being and relaxation of the inhabitants.
- Air_Quality_Index: Index measuring the quality of air, a crucial aspect affecting citizens' health and overall satisfaction.
- Happiness_Score: The average happiness score of the city (on a 1-10 scale), representing the subjective well-being of the population.
- Cost_of_Living_Index: Index measuring the cost of living in the city (relative to a reference city), which could impact the financial satisfaction of the citizens.
- Healthcare_Index: Index measuring the quality of healthcare in the city, an essential component of the population's well-being and contentment.

With these features, the dataset aims to analyze and understand the relationship between various urban factors and the happiness of a city's population. The developed Deep Q-Network model, PIYAAI_2, is designed to learn from this data to provide accurate predictions in future scenarios. Using Reinforcement Learning, the model is expected to improve its performance over time as it learns from new data and adapts to changes in the environment.",.csv,True
City Happiness Index - 2024,2,city-happiness-index-2024,train.csv,CC-BY-NC-SA-4.0,"**Dataset Name:** City Happiness Index

**Dataset Description:**

This dataset and the related codes are entirely prepared, original, and exclusive by Emirhan BULUT. The dataset includes crucial features and measurements from various cities around the world, focusing on factors that may affect the overall happiness score of each city. By analyzing these factors, we aim to gain insights into the living conditions and satisfaction of the population in urban environments.

The dataset consists of the following features:

- City: Name of the city.
- Month: The month in which the data is recorded.
- Year: The year in which the data is recorded.
- Decibel_Level: Average noise levels in decibels, indicating the auditory comfort of the citizens.
- Traffic_Density: Level of traffic density (Low, Medium, High, Very High), which might impact citizens' daily commute and stress levels.
- Green_Space_Area: Percentage of green spaces in the city, positively contributing to the mental well-being and relaxation of the inhabitants.
- Air_Quality_Index: Index measuring the quality of air, a crucial aspect affecting citizens' health and overall satisfaction.
- Happiness_Score: The average happiness score of the city (on a 1-10 scale), representing the subjective well-being of the population.
- Cost_of_Living_Index: Index measuring the cost of living in the city (relative to a reference city), which could impact the financial satisfaction of the citizens.
- Healthcare_Index: Index measuring the quality of healthcare in the city, an essential component of the population's well-being and contentment.

With these features, the dataset aims to analyze and understand the relationship between various urban factors and the happiness of a city's population. The developed Deep Q-Network model, PIYAAI_2, is designed to learn from this data to provide accurate predictions in future scenarios. Using Reinforcement Learning, the model is expected to improve its performance over time as it learns from new data and adapts to changes in the environment.",.csv,True
Country Statistics - UNData,2,undata-country-profiles,country_profile_variables.csv,CC0-1.0,"### Context

As part of [Data Science for Good : Kiva Crowdfunding][1], when I was on the lookout for various economic indicators / statistics of specific countries / regions, I came across [UNData][2] (a data access system to UN databases). 

The United Nations Statistics Division (UNSD) of the Department of Economic and Social Affairs (DESA) launched a new internet based data service for the global user community. It brings UN statistical databases within easy reach of users through a single entry point (http://data.un.org/). Users can search and download a variety of statistical resources of the UN system.

### Content
This dataset contains key statistical indicators of the countries. It covers 4 major sections

 1. General Information
 2. Economic Indicators
 3. Social Indicators
 4. Environmental & Infrastructure Indicators

The data is from 2017 when available or the most recent data previous to the year. 

I have added two files in this dataset. 

 1. country_profile_variables.csv - contains the indicator variables of all the countries present in UNData.
 2. kiva_country_profile_variables.csv - contains the indicator variables of the countries present in the Kiva Crowdfunding dataset. (Apart from country Kosovo, all the other countries are present in UNData and hence it is in this dataset as well)
 
Will be adding a new file which has the data dictionary of all the variables in the data. 

### Acknowledgements

Data is extracted from [UNData][3] website which in turn is collected from more than 20 international statistical sources compiled regularly by the Statistics Division and the Population Division of the United Nations, the statistical services of the United Nations, specialized agencies and other international organizations and institutions. Please read about the terms of use and policies [here][4].

Photo Credits : Andrew Neel on Unsplash

### Inspiration

Some interesting analysis which could be done using the dataset are

 1. Visual representation of different indicators at different countries of the world
 2. How Kiva loans are distributed based on the economic / social / other indicators.?

  [1]: https://www.kaggle.com/kiva/data-science-for-good-kiva-crowdfunding
  [2]: http://data.un.org/Host.aspx?Content=About
  [3]: http://data.un.org/Host.aspx?Content=About
  [4]: http://data.un.org/Host.aspx?Content=UNdataUse",.csv,True
Country Statistics - UNData,2,undata-country-profiles,kiva_country_profile_variables.csv,CC0-1.0,"### Context

As part of [Data Science for Good : Kiva Crowdfunding][1], when I was on the lookout for various economic indicators / statistics of specific countries / regions, I came across [UNData][2] (a data access system to UN databases). 

The United Nations Statistics Division (UNSD) of the Department of Economic and Social Affairs (DESA) launched a new internet based data service for the global user community. It brings UN statistical databases within easy reach of users through a single entry point (http://data.un.org/). Users can search and download a variety of statistical resources of the UN system.

### Content
This dataset contains key statistical indicators of the countries. It covers 4 major sections

 1. General Information
 2. Economic Indicators
 3. Social Indicators
 4. Environmental & Infrastructure Indicators

The data is from 2017 when available or the most recent data previous to the year. 

I have added two files in this dataset. 

 1. country_profile_variables.csv - contains the indicator variables of all the countries present in UNData.
 2. kiva_country_profile_variables.csv - contains the indicator variables of the countries present in the Kiva Crowdfunding dataset. (Apart from country Kosovo, all the other countries are present in UNData and hence it is in this dataset as well)
 
Will be adding a new file which has the data dictionary of all the variables in the data. 

### Acknowledgements

Data is extracted from [UNData][3] website which in turn is collected from more than 20 international statistical sources compiled regularly by the Statistics Division and the Population Division of the United Nations, the statistical services of the United Nations, specialized agencies and other international organizations and institutions. Please read about the terms of use and policies [here][4].

Photo Credits : Andrew Neel on Unsplash

### Inspiration

Some interesting analysis which could be done using the dataset are

 1. Visual representation of different indicators at different countries of the world
 2. How Kiva loans are distributed based on the economic / social / other indicators.?

  [1]: https://www.kaggle.com/kiva/data-science-for-good-kiva-crowdfunding
  [2]: http://data.un.org/Host.aspx?Content=About
  [3]: http://data.un.org/Host.aspx?Content=About
  [4]: http://data.un.org/Host.aspx?Content=UNdataUse",.csv,True
Cryptocurrency Historical Prices,23,cryptocurrencypricehistory,coin_NEM.csv,CC0-1.0,"### Context

Things like Block chain, Bitcoin, Bitcoin cash, Ethereum, Ripple etc are constantly coming in the news articles I read. So I wanted to understand more about it and [this post][1] helped me get started. Once the basics are done, the data scientist inside me started raising questions like:

1. How many cryptocurrencies are there and what are their prices and valuations?
2. Why is there a sudden surge in the interest in recent days? 



So what next? 
Now that we have the price data, I wanted to dig a little more about the factors affecting the price of coins. I started of with Bitcoin and there are quite a few parameters which affect the price of Bitcoin. Thanks to [Blockchain Info][3], I was able to get quite a few parameters on once in two day basis.

This will help understand the other factors related to Bitcoin price and also help one make future predictions in a better way than just using the historical price.


### Content

The dataset has one csv file for each currency. Price history is available on a daily basis from April 28, 2013.  This dataset has the historical price information of some of the top crypto currencies by market capitalization. 


 - Date : date of observation 
 - Open : Opening price on the given day
 - High : Highest price on the given day
 - Low : Lowest price on the given day
 - Close : Closing price on the given day
 - Volume : Volume of transactions on the given day
 - Market Cap : Market capitalization in USD



### Acknowledgements

This data is taken from [coinmarketcap][5] and it is [free][6] to use the data.


Cover Image : Photo by Thomas Malama on Unsplash

### Inspiration

Some of the questions which could be inferred from this dataset are:

 1. How did the historical prices / market capitalizations of various currencies change over time?
 2. Predicting the future price of the currencies
 3. Which currencies are more volatile and which ones are more stable?
 4. How does the price fluctuations of currencies correlate with each other?
 5. Seasonal trend in the price fluctuations



  [1]: https://www.linkedin.com/pulse/blockchain-absolute-beginners-mohit-mamoria
  [2]: https://coinmarketcap.com/
  [3]: https://blockchain.info/
  [4]: https://etherscan.io/charts
  [5]: https://coinmarketcap.com/
  [6]: https://coinmarketcap.com/faq/
  [7]: https://blockchain.info/
  [8]: https://etherscan.io/charts
  [9]: http://cs229.stanford.edu/proj2014/Isaac%20Madan,%20Shaurya%20Saluja,%20Aojia%20Zhao,Automated%20Bitcoin%20Trading%20via%20Machine%20Learning%20Algorithms.pdf",.csv,True
Cryptocurrency Historical Prices,23,cryptocurrencypricehistory,coin_EOS.csv,CC0-1.0,"### Context

Things like Block chain, Bitcoin, Bitcoin cash, Ethereum, Ripple etc are constantly coming in the news articles I read. So I wanted to understand more about it and [this post][1] helped me get started. Once the basics are done, the data scientist inside me started raising questions like:

1. How many cryptocurrencies are there and what are their prices and valuations?
2. Why is there a sudden surge in the interest in recent days? 



So what next? 
Now that we have the price data, I wanted to dig a little more about the factors affecting the price of coins. I started of with Bitcoin and there are quite a few parameters which affect the price of Bitcoin. Thanks to [Blockchain Info][3], I was able to get quite a few parameters on once in two day basis.

This will help understand the other factors related to Bitcoin price and also help one make future predictions in a better way than just using the historical price.


### Content

The dataset has one csv file for each currency. Price history is available on a daily basis from April 28, 2013.  This dataset has the historical price information of some of the top crypto currencies by market capitalization. 


 - Date : date of observation 
 - Open : Opening price on the given day
 - High : Highest price on the given day
 - Low : Lowest price on the given day
 - Close : Closing price on the given day
 - Volume : Volume of transactions on the given day
 - Market Cap : Market capitalization in USD



### Acknowledgements

This data is taken from [coinmarketcap][5] and it is [free][6] to use the data.


Cover Image : Photo by Thomas Malama on Unsplash

### Inspiration

Some of the questions which could be inferred from this dataset are:

 1. How did the historical prices / market capitalizations of various currencies change over time?
 2. Predicting the future price of the currencies
 3. Which currencies are more volatile and which ones are more stable?
 4. How does the price fluctuations of currencies correlate with each other?
 5. Seasonal trend in the price fluctuations



  [1]: https://www.linkedin.com/pulse/blockchain-absolute-beginners-mohit-mamoria
  [2]: https://coinmarketcap.com/
  [3]: https://blockchain.info/
  [4]: https://etherscan.io/charts
  [5]: https://coinmarketcap.com/
  [6]: https://coinmarketcap.com/faq/
  [7]: https://blockchain.info/
  [8]: https://etherscan.io/charts
  [9]: http://cs229.stanford.edu/proj2014/Isaac%20Madan,%20Shaurya%20Saluja,%20Aojia%20Zhao,Automated%20Bitcoin%20Trading%20via%20Machine%20Learning%20Algorithms.pdf",.csv,True
Cryptocurrency Historical Prices,23,cryptocurrencypricehistory,coin_Monero.csv,CC0-1.0,"### Context

Things like Block chain, Bitcoin, Bitcoin cash, Ethereum, Ripple etc are constantly coming in the news articles I read. So I wanted to understand more about it and [this post][1] helped me get started. Once the basics are done, the data scientist inside me started raising questions like:

1. How many cryptocurrencies are there and what are their prices and valuations?
2. Why is there a sudden surge in the interest in recent days? 



So what next? 
Now that we have the price data, I wanted to dig a little more about the factors affecting the price of coins. I started of with Bitcoin and there are quite a few parameters which affect the price of Bitcoin. Thanks to [Blockchain Info][3], I was able to get quite a few parameters on once in two day basis.

This will help understand the other factors related to Bitcoin price and also help one make future predictions in a better way than just using the historical price.


### Content

The dataset has one csv file for each currency. Price history is available on a daily basis from April 28, 2013.  This dataset has the historical price information of some of the top crypto currencies by market capitalization. 


 - Date : date of observation 
 - Open : Opening price on the given day
 - High : Highest price on the given day
 - Low : Lowest price on the given day
 - Close : Closing price on the given day
 - Volume : Volume of transactions on the given day
 - Market Cap : Market capitalization in USD



### Acknowledgements

This data is taken from [coinmarketcap][5] and it is [free][6] to use the data.


Cover Image : Photo by Thomas Malama on Unsplash

### Inspiration

Some of the questions which could be inferred from this dataset are:

 1. How did the historical prices / market capitalizations of various currencies change over time?
 2. Predicting the future price of the currencies
 3. Which currencies are more volatile and which ones are more stable?
 4. How does the price fluctuations of currencies correlate with each other?
 5. Seasonal trend in the price fluctuations



  [1]: https://www.linkedin.com/pulse/blockchain-absolute-beginners-mohit-mamoria
  [2]: https://coinmarketcap.com/
  [3]: https://blockchain.info/
  [4]: https://etherscan.io/charts
  [5]: https://coinmarketcap.com/
  [6]: https://coinmarketcap.com/faq/
  [7]: https://blockchain.info/
  [8]: https://etherscan.io/charts
  [9]: http://cs229.stanford.edu/proj2014/Isaac%20Madan,%20Shaurya%20Saluja,%20Aojia%20Zhao,Automated%20Bitcoin%20Trading%20via%20Machine%20Learning%20Algorithms.pdf",.csv,True
Cryptocurrency Historical Prices,23,cryptocurrencypricehistory,coin_Polkadot.csv,CC0-1.0,"### Context

Things like Block chain, Bitcoin, Bitcoin cash, Ethereum, Ripple etc are constantly coming in the news articles I read. So I wanted to understand more about it and [this post][1] helped me get started. Once the basics are done, the data scientist inside me started raising questions like:

1. How many cryptocurrencies are there and what are their prices and valuations?
2. Why is there a sudden surge in the interest in recent days? 



So what next? 
Now that we have the price data, I wanted to dig a little more about the factors affecting the price of coins. I started of with Bitcoin and there are quite a few parameters which affect the price of Bitcoin. Thanks to [Blockchain Info][3], I was able to get quite a few parameters on once in two day basis.

This will help understand the other factors related to Bitcoin price and also help one make future predictions in a better way than just using the historical price.


### Content

The dataset has one csv file for each currency. Price history is available on a daily basis from April 28, 2013.  This dataset has the historical price information of some of the top crypto currencies by market capitalization. 


 - Date : date of observation 
 - Open : Opening price on the given day
 - High : Highest price on the given day
 - Low : Lowest price on the given day
 - Close : Closing price on the given day
 - Volume : Volume of transactions on the given day
 - Market Cap : Market capitalization in USD



### Acknowledgements

This data is taken from [coinmarketcap][5] and it is [free][6] to use the data.


Cover Image : Photo by Thomas Malama on Unsplash

### Inspiration

Some of the questions which could be inferred from this dataset are:

 1. How did the historical prices / market capitalizations of various currencies change over time?
 2. Predicting the future price of the currencies
 3. Which currencies are more volatile and which ones are more stable?
 4. How does the price fluctuations of currencies correlate with each other?
 5. Seasonal trend in the price fluctuations



  [1]: https://www.linkedin.com/pulse/blockchain-absolute-beginners-mohit-mamoria
  [2]: https://coinmarketcap.com/
  [3]: https://blockchain.info/
  [4]: https://etherscan.io/charts
  [5]: https://coinmarketcap.com/
  [6]: https://coinmarketcap.com/faq/
  [7]: https://blockchain.info/
  [8]: https://etherscan.io/charts
  [9]: http://cs229.stanford.edu/proj2014/Isaac%20Madan,%20Shaurya%20Saluja,%20Aojia%20Zhao,Automated%20Bitcoin%20Trading%20via%20Machine%20Learning%20Algorithms.pdf",.csv,True
Cryptocurrency Historical Prices,23,cryptocurrencypricehistory,coin_USDCoin.csv,CC0-1.0,"### Context

Things like Block chain, Bitcoin, Bitcoin cash, Ethereum, Ripple etc are constantly coming in the news articles I read. So I wanted to understand more about it and [this post][1] helped me get started. Once the basics are done, the data scientist inside me started raising questions like:

1. How many cryptocurrencies are there and what are their prices and valuations?
2. Why is there a sudden surge in the interest in recent days? 



So what next? 
Now that we have the price data, I wanted to dig a little more about the factors affecting the price of coins. I started of with Bitcoin and there are quite a few parameters which affect the price of Bitcoin. Thanks to [Blockchain Info][3], I was able to get quite a few parameters on once in two day basis.

This will help understand the other factors related to Bitcoin price and also help one make future predictions in a better way than just using the historical price.


### Content

The dataset has one csv file for each currency. Price history is available on a daily basis from April 28, 2013.  This dataset has the historical price information of some of the top crypto currencies by market capitalization. 


 - Date : date of observation 
 - Open : Opening price on the given day
 - High : Highest price on the given day
 - Low : Lowest price on the given day
 - Close : Closing price on the given day
 - Volume : Volume of transactions on the given day
 - Market Cap : Market capitalization in USD



### Acknowledgements

This data is taken from [coinmarketcap][5] and it is [free][6] to use the data.


Cover Image : Photo by Thomas Malama on Unsplash

### Inspiration

Some of the questions which could be inferred from this dataset are:

 1. How did the historical prices / market capitalizations of various currencies change over time?
 2. Predicting the future price of the currencies
 3. Which currencies are more volatile and which ones are more stable?
 4. How does the price fluctuations of currencies correlate with each other?
 5. Seasonal trend in the price fluctuations



  [1]: https://www.linkedin.com/pulse/blockchain-absolute-beginners-mohit-mamoria
  [2]: https://coinmarketcap.com/
  [3]: https://blockchain.info/
  [4]: https://etherscan.io/charts
  [5]: https://coinmarketcap.com/
  [6]: https://coinmarketcap.com/faq/
  [7]: https://blockchain.info/
  [8]: https://etherscan.io/charts
  [9]: http://cs229.stanford.edu/proj2014/Isaac%20Madan,%20Shaurya%20Saluja,%20Aojia%20Zhao,Automated%20Bitcoin%20Trading%20via%20Machine%20Learning%20Algorithms.pdf",.csv,True
Cryptocurrency Historical Prices,23,cryptocurrencypricehistory,coin_Uniswap.csv,CC0-1.0,"### Context

Things like Block chain, Bitcoin, Bitcoin cash, Ethereum, Ripple etc are constantly coming in the news articles I read. So I wanted to understand more about it and [this post][1] helped me get started. Once the basics are done, the data scientist inside me started raising questions like:

1. How many cryptocurrencies are there and what are their prices and valuations?
2. Why is there a sudden surge in the interest in recent days? 



So what next? 
Now that we have the price data, I wanted to dig a little more about the factors affecting the price of coins. I started of with Bitcoin and there are quite a few parameters which affect the price of Bitcoin. Thanks to [Blockchain Info][3], I was able to get quite a few parameters on once in two day basis.

This will help understand the other factors related to Bitcoin price and also help one make future predictions in a better way than just using the historical price.


### Content

The dataset has one csv file for each currency. Price history is available on a daily basis from April 28, 2013.  This dataset has the historical price information of some of the top crypto currencies by market capitalization. 


 - Date : date of observation 
 - Open : Opening price on the given day
 - High : Highest price on the given day
 - Low : Lowest price on the given day
 - Close : Closing price on the given day
 - Volume : Volume of transactions on the given day
 - Market Cap : Market capitalization in USD



### Acknowledgements

This data is taken from [coinmarketcap][5] and it is [free][6] to use the data.


Cover Image : Photo by Thomas Malama on Unsplash

### Inspiration

Some of the questions which could be inferred from this dataset are:

 1. How did the historical prices / market capitalizations of various currencies change over time?
 2. Predicting the future price of the currencies
 3. Which currencies are more volatile and which ones are more stable?
 4. How does the price fluctuations of currencies correlate with each other?
 5. Seasonal trend in the price fluctuations



  [1]: https://www.linkedin.com/pulse/blockchain-absolute-beginners-mohit-mamoria
  [2]: https://coinmarketcap.com/
  [3]: https://blockchain.info/
  [4]: https://etherscan.io/charts
  [5]: https://coinmarketcap.com/
  [6]: https://coinmarketcap.com/faq/
  [7]: https://blockchain.info/
  [8]: https://etherscan.io/charts
  [9]: http://cs229.stanford.edu/proj2014/Isaac%20Madan,%20Shaurya%20Saluja,%20Aojia%20Zhao,Automated%20Bitcoin%20Trading%20via%20Machine%20Learning%20Algorithms.pdf",.csv,True
Cryptocurrency Historical Prices,23,cryptocurrencypricehistory,coin_BinanceCoin.csv,CC0-1.0,"### Context

Things like Block chain, Bitcoin, Bitcoin cash, Ethereum, Ripple etc are constantly coming in the news articles I read. So I wanted to understand more about it and [this post][1] helped me get started. Once the basics are done, the data scientist inside me started raising questions like:

1. How many cryptocurrencies are there and what are their prices and valuations?
2. Why is there a sudden surge in the interest in recent days? 



So what next? 
Now that we have the price data, I wanted to dig a little more about the factors affecting the price of coins. I started of with Bitcoin and there are quite a few parameters which affect the price of Bitcoin. Thanks to [Blockchain Info][3], I was able to get quite a few parameters on once in two day basis.

This will help understand the other factors related to Bitcoin price and also help one make future predictions in a better way than just using the historical price.


### Content

The dataset has one csv file for each currency. Price history is available on a daily basis from April 28, 2013.  This dataset has the historical price information of some of the top crypto currencies by market capitalization. 


 - Date : date of observation 
 - Open : Opening price on the given day
 - High : Highest price on the given day
 - Low : Lowest price on the given day
 - Close : Closing price on the given day
 - Volume : Volume of transactions on the given day
 - Market Cap : Market capitalization in USD



### Acknowledgements

This data is taken from [coinmarketcap][5] and it is [free][6] to use the data.


Cover Image : Photo by Thomas Malama on Unsplash

### Inspiration

Some of the questions which could be inferred from this dataset are:

 1. How did the historical prices / market capitalizations of various currencies change over time?
 2. Predicting the future price of the currencies
 3. Which currencies are more volatile and which ones are more stable?
 4. How does the price fluctuations of currencies correlate with each other?
 5. Seasonal trend in the price fluctuations



  [1]: https://www.linkedin.com/pulse/blockchain-absolute-beginners-mohit-mamoria
  [2]: https://coinmarketcap.com/
  [3]: https://blockchain.info/
  [4]: https://etherscan.io/charts
  [5]: https://coinmarketcap.com/
  [6]: https://coinmarketcap.com/faq/
  [7]: https://blockchain.info/
  [8]: https://etherscan.io/charts
  [9]: http://cs229.stanford.edu/proj2014/Isaac%20Madan,%20Shaurya%20Saluja,%20Aojia%20Zhao,Automated%20Bitcoin%20Trading%20via%20Machine%20Learning%20Algorithms.pdf",.csv,True
Cryptocurrency Historical Prices,23,cryptocurrencypricehistory,coin_Iota.csv,CC0-1.0,"### Context

Things like Block chain, Bitcoin, Bitcoin cash, Ethereum, Ripple etc are constantly coming in the news articles I read. So I wanted to understand more about it and [this post][1] helped me get started. Once the basics are done, the data scientist inside me started raising questions like:

1. How many cryptocurrencies are there and what are their prices and valuations?
2. Why is there a sudden surge in the interest in recent days? 



So what next? 
Now that we have the price data, I wanted to dig a little more about the factors affecting the price of coins. I started of with Bitcoin and there are quite a few parameters which affect the price of Bitcoin. Thanks to [Blockchain Info][3], I was able to get quite a few parameters on once in two day basis.

This will help understand the other factors related to Bitcoin price and also help one make future predictions in a better way than just using the historical price.


### Content

The dataset has one csv file for each currency. Price history is available on a daily basis from April 28, 2013.  This dataset has the historical price information of some of the top crypto currencies by market capitalization. 


 - Date : date of observation 
 - Open : Opening price on the given day
 - High : Highest price on the given day
 - Low : Lowest price on the given day
 - Close : Closing price on the given day
 - Volume : Volume of transactions on the given day
 - Market Cap : Market capitalization in USD



### Acknowledgements

This data is taken from [coinmarketcap][5] and it is [free][6] to use the data.


Cover Image : Photo by Thomas Malama on Unsplash

### Inspiration

Some of the questions which could be inferred from this dataset are:

 1. How did the historical prices / market capitalizations of various currencies change over time?
 2. Predicting the future price of the currencies
 3. Which currencies are more volatile and which ones are more stable?
 4. How does the price fluctuations of currencies correlate with each other?
 5. Seasonal trend in the price fluctuations



  [1]: https://www.linkedin.com/pulse/blockchain-absolute-beginners-mohit-mamoria
  [2]: https://coinmarketcap.com/
  [3]: https://blockchain.info/
  [4]: https://etherscan.io/charts
  [5]: https://coinmarketcap.com/
  [6]: https://coinmarketcap.com/faq/
  [7]: https://blockchain.info/
  [8]: https://etherscan.io/charts
  [9]: http://cs229.stanford.edu/proj2014/Isaac%20Madan,%20Shaurya%20Saluja,%20Aojia%20Zhao,Automated%20Bitcoin%20Trading%20via%20Machine%20Learning%20Algorithms.pdf",.csv,True
Cryptocurrency Historical Prices,23,cryptocurrencypricehistory,coin_Aave.csv,CC0-1.0,"### Context

Things like Block chain, Bitcoin, Bitcoin cash, Ethereum, Ripple etc are constantly coming in the news articles I read. So I wanted to understand more about it and [this post][1] helped me get started. Once the basics are done, the data scientist inside me started raising questions like:

1. How many cryptocurrencies are there and what are their prices and valuations?
2. Why is there a sudden surge in the interest in recent days? 



So what next? 
Now that we have the price data, I wanted to dig a little more about the factors affecting the price of coins. I started of with Bitcoin and there are quite a few parameters which affect the price of Bitcoin. Thanks to [Blockchain Info][3], I was able to get quite a few parameters on once in two day basis.

This will help understand the other factors related to Bitcoin price and also help one make future predictions in a better way than just using the historical price.


### Content

The dataset has one csv file for each currency. Price history is available on a daily basis from April 28, 2013.  This dataset has the historical price information of some of the top crypto currencies by market capitalization. 


 - Date : date of observation 
 - Open : Opening price on the given day
 - High : Highest price on the given day
 - Low : Lowest price on the given day
 - Close : Closing price on the given day
 - Volume : Volume of transactions on the given day
 - Market Cap : Market capitalization in USD



### Acknowledgements

This data is taken from [coinmarketcap][5] and it is [free][6] to use the data.


Cover Image : Photo by Thomas Malama on Unsplash

### Inspiration

Some of the questions which could be inferred from this dataset are:

 1. How did the historical prices / market capitalizations of various currencies change over time?
 2. Predicting the future price of the currencies
 3. Which currencies are more volatile and which ones are more stable?
 4. How does the price fluctuations of currencies correlate with each other?
 5. Seasonal trend in the price fluctuations



  [1]: https://www.linkedin.com/pulse/blockchain-absolute-beginners-mohit-mamoria
  [2]: https://coinmarketcap.com/
  [3]: https://blockchain.info/
  [4]: https://etherscan.io/charts
  [5]: https://coinmarketcap.com/
  [6]: https://coinmarketcap.com/faq/
  [7]: https://blockchain.info/
  [8]: https://etherscan.io/charts
  [9]: http://cs229.stanford.edu/proj2014/Isaac%20Madan,%20Shaurya%20Saluja,%20Aojia%20Zhao,Automated%20Bitcoin%20Trading%20via%20Machine%20Learning%20Algorithms.pdf",.csv,True
Cryptocurrency Historical Prices,23,cryptocurrencypricehistory,coin_Solana.csv,CC0-1.0,"### Context

Things like Block chain, Bitcoin, Bitcoin cash, Ethereum, Ripple etc are constantly coming in the news articles I read. So I wanted to understand more about it and [this post][1] helped me get started. Once the basics are done, the data scientist inside me started raising questions like:

1. How many cryptocurrencies are there and what are their prices and valuations?
2. Why is there a sudden surge in the interest in recent days? 



So what next? 
Now that we have the price data, I wanted to dig a little more about the factors affecting the price of coins. I started of with Bitcoin and there are quite a few parameters which affect the price of Bitcoin. Thanks to [Blockchain Info][3], I was able to get quite a few parameters on once in two day basis.

This will help understand the other factors related to Bitcoin price and also help one make future predictions in a better way than just using the historical price.


### Content

The dataset has one csv file for each currency. Price history is available on a daily basis from April 28, 2013.  This dataset has the historical price information of some of the top crypto currencies by market capitalization. 


 - Date : date of observation 
 - Open : Opening price on the given day
 - High : Highest price on the given day
 - Low : Lowest price on the given day
 - Close : Closing price on the given day
 - Volume : Volume of transactions on the given day
 - Market Cap : Market capitalization in USD



### Acknowledgements

This data is taken from [coinmarketcap][5] and it is [free][6] to use the data.


Cover Image : Photo by Thomas Malama on Unsplash

### Inspiration

Some of the questions which could be inferred from this dataset are:

 1. How did the historical prices / market capitalizations of various currencies change over time?
 2. Predicting the future price of the currencies
 3. Which currencies are more volatile and which ones are more stable?
 4. How does the price fluctuations of currencies correlate with each other?
 5. Seasonal trend in the price fluctuations



  [1]: https://www.linkedin.com/pulse/blockchain-absolute-beginners-mohit-mamoria
  [2]: https://coinmarketcap.com/
  [3]: https://blockchain.info/
  [4]: https://etherscan.io/charts
  [5]: https://coinmarketcap.com/
  [6]: https://coinmarketcap.com/faq/
  [7]: https://blockchain.info/
  [8]: https://etherscan.io/charts
  [9]: http://cs229.stanford.edu/proj2014/Isaac%20Madan,%20Shaurya%20Saluja,%20Aojia%20Zhao,Automated%20Bitcoin%20Trading%20via%20Machine%20Learning%20Algorithms.pdf",.csv,True
Cryptocurrency Historical Prices,23,cryptocurrencypricehistory,coin_Bitcoin.csv,CC0-1.0,"### Context

Things like Block chain, Bitcoin, Bitcoin cash, Ethereum, Ripple etc are constantly coming in the news articles I read. So I wanted to understand more about it and [this post][1] helped me get started. Once the basics are done, the data scientist inside me started raising questions like:

1. How many cryptocurrencies are there and what are their prices and valuations?
2. Why is there a sudden surge in the interest in recent days? 



So what next? 
Now that we have the price data, I wanted to dig a little more about the factors affecting the price of coins. I started of with Bitcoin and there are quite a few parameters which affect the price of Bitcoin. Thanks to [Blockchain Info][3], I was able to get quite a few parameters on once in two day basis.

This will help understand the other factors related to Bitcoin price and also help one make future predictions in a better way than just using the historical price.


### Content

The dataset has one csv file for each currency. Price history is available on a daily basis from April 28, 2013.  This dataset has the historical price information of some of the top crypto currencies by market capitalization. 


 - Date : date of observation 
 - Open : Opening price on the given day
 - High : Highest price on the given day
 - Low : Lowest price on the given day
 - Close : Closing price on the given day
 - Volume : Volume of transactions on the given day
 - Market Cap : Market capitalization in USD



### Acknowledgements

This data is taken from [coinmarketcap][5] and it is [free][6] to use the data.


Cover Image : Photo by Thomas Malama on Unsplash

### Inspiration

Some of the questions which could be inferred from this dataset are:

 1. How did the historical prices / market capitalizations of various currencies change over time?
 2. Predicting the future price of the currencies
 3. Which currencies are more volatile and which ones are more stable?
 4. How does the price fluctuations of currencies correlate with each other?
 5. Seasonal trend in the price fluctuations



  [1]: https://www.linkedin.com/pulse/blockchain-absolute-beginners-mohit-mamoria
  [2]: https://coinmarketcap.com/
  [3]: https://blockchain.info/
  [4]: https://etherscan.io/charts
  [5]: https://coinmarketcap.com/
  [6]: https://coinmarketcap.com/faq/
  [7]: https://blockchain.info/
  [8]: https://etherscan.io/charts
  [9]: http://cs229.stanford.edu/proj2014/Isaac%20Madan,%20Shaurya%20Saluja,%20Aojia%20Zhao,Automated%20Bitcoin%20Trading%20via%20Machine%20Learning%20Algorithms.pdf",.csv,True
Cryptocurrency Historical Prices,23,cryptocurrencypricehistory,coin_Cardano.csv,CC0-1.0,"### Context

Things like Block chain, Bitcoin, Bitcoin cash, Ethereum, Ripple etc are constantly coming in the news articles I read. So I wanted to understand more about it and [this post][1] helped me get started. Once the basics are done, the data scientist inside me started raising questions like:

1. How many cryptocurrencies are there and what are their prices and valuations?
2. Why is there a sudden surge in the interest in recent days? 



So what next? 
Now that we have the price data, I wanted to dig a little more about the factors affecting the price of coins. I started of with Bitcoin and there are quite a few parameters which affect the price of Bitcoin. Thanks to [Blockchain Info][3], I was able to get quite a few parameters on once in two day basis.

This will help understand the other factors related to Bitcoin price and also help one make future predictions in a better way than just using the historical price.


### Content

The dataset has one csv file for each currency. Price history is available on a daily basis from April 28, 2013.  This dataset has the historical price information of some of the top crypto currencies by market capitalization. 


 - Date : date of observation 
 - Open : Opening price on the given day
 - High : Highest price on the given day
 - Low : Lowest price on the given day
 - Close : Closing price on the given day
 - Volume : Volume of transactions on the given day
 - Market Cap : Market capitalization in USD



### Acknowledgements

This data is taken from [coinmarketcap][5] and it is [free][6] to use the data.


Cover Image : Photo by Thomas Malama on Unsplash

### Inspiration

Some of the questions which could be inferred from this dataset are:

 1. How did the historical prices / market capitalizations of various currencies change over time?
 2. Predicting the future price of the currencies
 3. Which currencies are more volatile and which ones are more stable?
 4. How does the price fluctuations of currencies correlate with each other?
 5. Seasonal trend in the price fluctuations



  [1]: https://www.linkedin.com/pulse/blockchain-absolute-beginners-mohit-mamoria
  [2]: https://coinmarketcap.com/
  [3]: https://blockchain.info/
  [4]: https://etherscan.io/charts
  [5]: https://coinmarketcap.com/
  [6]: https://coinmarketcap.com/faq/
  [7]: https://blockchain.info/
  [8]: https://etherscan.io/charts
  [9]: http://cs229.stanford.edu/proj2014/Isaac%20Madan,%20Shaurya%20Saluja,%20Aojia%20Zhao,Automated%20Bitcoin%20Trading%20via%20Machine%20Learning%20Algorithms.pdf",.csv,True
Cryptocurrency Historical Prices,23,cryptocurrencypricehistory,coin_Tether.csv,CC0-1.0,"### Context

Things like Block chain, Bitcoin, Bitcoin cash, Ethereum, Ripple etc are constantly coming in the news articles I read. So I wanted to understand more about it and [this post][1] helped me get started. Once the basics are done, the data scientist inside me started raising questions like:

1. How many cryptocurrencies are there and what are their prices and valuations?
2. Why is there a sudden surge in the interest in recent days? 



So what next? 
Now that we have the price data, I wanted to dig a little more about the factors affecting the price of coins. I started of with Bitcoin and there are quite a few parameters which affect the price of Bitcoin. Thanks to [Blockchain Info][3], I was able to get quite a few parameters on once in two day basis.

This will help understand the other factors related to Bitcoin price and also help one make future predictions in a better way than just using the historical price.


### Content

The dataset has one csv file for each currency. Price history is available on a daily basis from April 28, 2013.  This dataset has the historical price information of some of the top crypto currencies by market capitalization. 


 - Date : date of observation 
 - Open : Opening price on the given day
 - High : Highest price on the given day
 - Low : Lowest price on the given day
 - Close : Closing price on the given day
 - Volume : Volume of transactions on the given day
 - Market Cap : Market capitalization in USD



### Acknowledgements

This data is taken from [coinmarketcap][5] and it is [free][6] to use the data.


Cover Image : Photo by Thomas Malama on Unsplash

### Inspiration

Some of the questions which could be inferred from this dataset are:

 1. How did the historical prices / market capitalizations of various currencies change over time?
 2. Predicting the future price of the currencies
 3. Which currencies are more volatile and which ones are more stable?
 4. How does the price fluctuations of currencies correlate with each other?
 5. Seasonal trend in the price fluctuations



  [1]: https://www.linkedin.com/pulse/blockchain-absolute-beginners-mohit-mamoria
  [2]: https://coinmarketcap.com/
  [3]: https://blockchain.info/
  [4]: https://etherscan.io/charts
  [5]: https://coinmarketcap.com/
  [6]: https://coinmarketcap.com/faq/
  [7]: https://blockchain.info/
  [8]: https://etherscan.io/charts
  [9]: http://cs229.stanford.edu/proj2014/Isaac%20Madan,%20Shaurya%20Saluja,%20Aojia%20Zhao,Automated%20Bitcoin%20Trading%20via%20Machine%20Learning%20Algorithms.pdf",.csv,True
Cryptocurrency Historical Prices,23,cryptocurrencypricehistory,coin_Cosmos.csv,CC0-1.0,"### Context

Things like Block chain, Bitcoin, Bitcoin cash, Ethereum, Ripple etc are constantly coming in the news articles I read. So I wanted to understand more about it and [this post][1] helped me get started. Once the basics are done, the data scientist inside me started raising questions like:

1. How many cryptocurrencies are there and what are their prices and valuations?
2. Why is there a sudden surge in the interest in recent days? 



So what next? 
Now that we have the price data, I wanted to dig a little more about the factors affecting the price of coins. I started of with Bitcoin and there are quite a few parameters which affect the price of Bitcoin. Thanks to [Blockchain Info][3], I was able to get quite a few parameters on once in two day basis.

This will help understand the other factors related to Bitcoin price and also help one make future predictions in a better way than just using the historical price.


### Content

The dataset has one csv file for each currency. Price history is available on a daily basis from April 28, 2013.  This dataset has the historical price information of some of the top crypto currencies by market capitalization. 


 - Date : date of observation 
 - Open : Opening price on the given day
 - High : Highest price on the given day
 - Low : Lowest price on the given day
 - Close : Closing price on the given day
 - Volume : Volume of transactions on the given day
 - Market Cap : Market capitalization in USD



### Acknowledgements

This data is taken from [coinmarketcap][5] and it is [free][6] to use the data.


Cover Image : Photo by Thomas Malama on Unsplash

### Inspiration

Some of the questions which could be inferred from this dataset are:

 1. How did the historical prices / market capitalizations of various currencies change over time?
 2. Predicting the future price of the currencies
 3. Which currencies are more volatile and which ones are more stable?
 4. How does the price fluctuations of currencies correlate with each other?
 5. Seasonal trend in the price fluctuations



  [1]: https://www.linkedin.com/pulse/blockchain-absolute-beginners-mohit-mamoria
  [2]: https://coinmarketcap.com/
  [3]: https://blockchain.info/
  [4]: https://etherscan.io/charts
  [5]: https://coinmarketcap.com/
  [6]: https://coinmarketcap.com/faq/
  [7]: https://blockchain.info/
  [8]: https://etherscan.io/charts
  [9]: http://cs229.stanford.edu/proj2014/Isaac%20Madan,%20Shaurya%20Saluja,%20Aojia%20Zhao,Automated%20Bitcoin%20Trading%20via%20Machine%20Learning%20Algorithms.pdf",.csv,True
Cryptocurrency Historical Prices,23,cryptocurrencypricehistory,coin_ChainLink.csv,CC0-1.0,"### Context

Things like Block chain, Bitcoin, Bitcoin cash, Ethereum, Ripple etc are constantly coming in the news articles I read. So I wanted to understand more about it and [this post][1] helped me get started. Once the basics are done, the data scientist inside me started raising questions like:

1. How many cryptocurrencies are there and what are their prices and valuations?
2. Why is there a sudden surge in the interest in recent days? 



So what next? 
Now that we have the price data, I wanted to dig a little more about the factors affecting the price of coins. I started of with Bitcoin and there are quite a few parameters which affect the price of Bitcoin. Thanks to [Blockchain Info][3], I was able to get quite a few parameters on once in two day basis.

This will help understand the other factors related to Bitcoin price and also help one make future predictions in a better way than just using the historical price.


### Content

The dataset has one csv file for each currency. Price history is available on a daily basis from April 28, 2013.  This dataset has the historical price information of some of the top crypto currencies by market capitalization. 


 - Date : date of observation 
 - Open : Opening price on the given day
 - High : Highest price on the given day
 - Low : Lowest price on the given day
 - Close : Closing price on the given day
 - Volume : Volume of transactions on the given day
 - Market Cap : Market capitalization in USD



### Acknowledgements

This data is taken from [coinmarketcap][5] and it is [free][6] to use the data.


Cover Image : Photo by Thomas Malama on Unsplash

### Inspiration

Some of the questions which could be inferred from this dataset are:

 1. How did the historical prices / market capitalizations of various currencies change over time?
 2. Predicting the future price of the currencies
 3. Which currencies are more volatile and which ones are more stable?
 4. How does the price fluctuations of currencies correlate with each other?
 5. Seasonal trend in the price fluctuations



  [1]: https://www.linkedin.com/pulse/blockchain-absolute-beginners-mohit-mamoria
  [2]: https://coinmarketcap.com/
  [3]: https://blockchain.info/
  [4]: https://etherscan.io/charts
  [5]: https://coinmarketcap.com/
  [6]: https://coinmarketcap.com/faq/
  [7]: https://blockchain.info/
  [8]: https://etherscan.io/charts
  [9]: http://cs229.stanford.edu/proj2014/Isaac%20Madan,%20Shaurya%20Saluja,%20Aojia%20Zhao,Automated%20Bitcoin%20Trading%20via%20Machine%20Learning%20Algorithms.pdf",.csv,True
Cryptocurrency Historical Prices,23,cryptocurrencypricehistory,coin_Litecoin.csv,CC0-1.0,"### Context

Things like Block chain, Bitcoin, Bitcoin cash, Ethereum, Ripple etc are constantly coming in the news articles I read. So I wanted to understand more about it and [this post][1] helped me get started. Once the basics are done, the data scientist inside me started raising questions like:

1. How many cryptocurrencies are there and what are their prices and valuations?
2. Why is there a sudden surge in the interest in recent days? 



So what next? 
Now that we have the price data, I wanted to dig a little more about the factors affecting the price of coins. I started of with Bitcoin and there are quite a few parameters which affect the price of Bitcoin. Thanks to [Blockchain Info][3], I was able to get quite a few parameters on once in two day basis.

This will help understand the other factors related to Bitcoin price and also help one make future predictions in a better way than just using the historical price.


### Content

The dataset has one csv file for each currency. Price history is available on a daily basis from April 28, 2013.  This dataset has the historical price information of some of the top crypto currencies by market capitalization. 


 - Date : date of observation 
 - Open : Opening price on the given day
 - High : Highest price on the given day
 - Low : Lowest price on the given day
 - Close : Closing price on the given day
 - Volume : Volume of transactions on the given day
 - Market Cap : Market capitalization in USD



### Acknowledgements

This data is taken from [coinmarketcap][5] and it is [free][6] to use the data.


Cover Image : Photo by Thomas Malama on Unsplash

### Inspiration

Some of the questions which could be inferred from this dataset are:

 1. How did the historical prices / market capitalizations of various currencies change over time?
 2. Predicting the future price of the currencies
 3. Which currencies are more volatile and which ones are more stable?
 4. How does the price fluctuations of currencies correlate with each other?
 5. Seasonal trend in the price fluctuations



  [1]: https://www.linkedin.com/pulse/blockchain-absolute-beginners-mohit-mamoria
  [2]: https://coinmarketcap.com/
  [3]: https://blockchain.info/
  [4]: https://etherscan.io/charts
  [5]: https://coinmarketcap.com/
  [6]: https://coinmarketcap.com/faq/
  [7]: https://blockchain.info/
  [8]: https://etherscan.io/charts
  [9]: http://cs229.stanford.edu/proj2014/Isaac%20Madan,%20Shaurya%20Saluja,%20Aojia%20Zhao,Automated%20Bitcoin%20Trading%20via%20Machine%20Learning%20Algorithms.pdf",.csv,True
Cryptocurrency Historical Prices,23,cryptocurrencypricehistory,coin_XRP.csv,CC0-1.0,"### Context

Things like Block chain, Bitcoin, Bitcoin cash, Ethereum, Ripple etc are constantly coming in the news articles I read. So I wanted to understand more about it and [this post][1] helped me get started. Once the basics are done, the data scientist inside me started raising questions like:

1. How many cryptocurrencies are there and what are their prices and valuations?
2. Why is there a sudden surge in the interest in recent days? 



So what next? 
Now that we have the price data, I wanted to dig a little more about the factors affecting the price of coins. I started of with Bitcoin and there are quite a few parameters which affect the price of Bitcoin. Thanks to [Blockchain Info][3], I was able to get quite a few parameters on once in two day basis.

This will help understand the other factors related to Bitcoin price and also help one make future predictions in a better way than just using the historical price.


### Content

The dataset has one csv file for each currency. Price history is available on a daily basis from April 28, 2013.  This dataset has the historical price information of some of the top crypto currencies by market capitalization. 


 - Date : date of observation 
 - Open : Opening price on the given day
 - High : Highest price on the given day
 - Low : Lowest price on the given day
 - Close : Closing price on the given day
 - Volume : Volume of transactions on the given day
 - Market Cap : Market capitalization in USD



### Acknowledgements

This data is taken from [coinmarketcap][5] and it is [free][6] to use the data.


Cover Image : Photo by Thomas Malama on Unsplash

### Inspiration

Some of the questions which could be inferred from this dataset are:

 1. How did the historical prices / market capitalizations of various currencies change over time?
 2. Predicting the future price of the currencies
 3. Which currencies are more volatile and which ones are more stable?
 4. How does the price fluctuations of currencies correlate with each other?
 5. Seasonal trend in the price fluctuations



  [1]: https://www.linkedin.com/pulse/blockchain-absolute-beginners-mohit-mamoria
  [2]: https://coinmarketcap.com/
  [3]: https://blockchain.info/
  [4]: https://etherscan.io/charts
  [5]: https://coinmarketcap.com/
  [6]: https://coinmarketcap.com/faq/
  [7]: https://blockchain.info/
  [8]: https://etherscan.io/charts
  [9]: http://cs229.stanford.edu/proj2014/Isaac%20Madan,%20Shaurya%20Saluja,%20Aojia%20Zhao,Automated%20Bitcoin%20Trading%20via%20Machine%20Learning%20Algorithms.pdf",.csv,True
Cryptocurrency Historical Prices,23,cryptocurrencypricehistory,coin_Ethereum.csv,CC0-1.0,"### Context

Things like Block chain, Bitcoin, Bitcoin cash, Ethereum, Ripple etc are constantly coming in the news articles I read. So I wanted to understand more about it and [this post][1] helped me get started. Once the basics are done, the data scientist inside me started raising questions like:

1. How many cryptocurrencies are there and what are their prices and valuations?
2. Why is there a sudden surge in the interest in recent days? 



So what next? 
Now that we have the price data, I wanted to dig a little more about the factors affecting the price of coins. I started of with Bitcoin and there are quite a few parameters which affect the price of Bitcoin. Thanks to [Blockchain Info][3], I was able to get quite a few parameters on once in two day basis.

This will help understand the other factors related to Bitcoin price and also help one make future predictions in a better way than just using the historical price.


### Content

The dataset has one csv file for each currency. Price history is available on a daily basis from April 28, 2013.  This dataset has the historical price information of some of the top crypto currencies by market capitalization. 


 - Date : date of observation 
 - Open : Opening price on the given day
 - High : Highest price on the given day
 - Low : Lowest price on the given day
 - Close : Closing price on the given day
 - Volume : Volume of transactions on the given day
 - Market Cap : Market capitalization in USD



### Acknowledgements

This data is taken from [coinmarketcap][5] and it is [free][6] to use the data.


Cover Image : Photo by Thomas Malama on Unsplash

### Inspiration

Some of the questions which could be inferred from this dataset are:

 1. How did the historical prices / market capitalizations of various currencies change over time?
 2. Predicting the future price of the currencies
 3. Which currencies are more volatile and which ones are more stable?
 4. How does the price fluctuations of currencies correlate with each other?
 5. Seasonal trend in the price fluctuations



  [1]: https://www.linkedin.com/pulse/blockchain-absolute-beginners-mohit-mamoria
  [2]: https://coinmarketcap.com/
  [3]: https://blockchain.info/
  [4]: https://etherscan.io/charts
  [5]: https://coinmarketcap.com/
  [6]: https://coinmarketcap.com/faq/
  [7]: https://blockchain.info/
  [8]: https://etherscan.io/charts
  [9]: http://cs229.stanford.edu/proj2014/Isaac%20Madan,%20Shaurya%20Saluja,%20Aojia%20Zhao,Automated%20Bitcoin%20Trading%20via%20Machine%20Learning%20Algorithms.pdf",.csv,True
Cryptocurrency Historical Prices,23,cryptocurrencypricehistory,coin_Tron.csv,CC0-1.0,"### Context

Things like Block chain, Bitcoin, Bitcoin cash, Ethereum, Ripple etc are constantly coming in the news articles I read. So I wanted to understand more about it and [this post][1] helped me get started. Once the basics are done, the data scientist inside me started raising questions like:

1. How many cryptocurrencies are there and what are their prices and valuations?
2. Why is there a sudden surge in the interest in recent days? 



So what next? 
Now that we have the price data, I wanted to dig a little more about the factors affecting the price of coins. I started of with Bitcoin and there are quite a few parameters which affect the price of Bitcoin. Thanks to [Blockchain Info][3], I was able to get quite a few parameters on once in two day basis.

This will help understand the other factors related to Bitcoin price and also help one make future predictions in a better way than just using the historical price.


### Content

The dataset has one csv file for each currency. Price history is available on a daily basis from April 28, 2013.  This dataset has the historical price information of some of the top crypto currencies by market capitalization. 


 - Date : date of observation 
 - Open : Opening price on the given day
 - High : Highest price on the given day
 - Low : Lowest price on the given day
 - Close : Closing price on the given day
 - Volume : Volume of transactions on the given day
 - Market Cap : Market capitalization in USD



### Acknowledgements

This data is taken from [coinmarketcap][5] and it is [free][6] to use the data.


Cover Image : Photo by Thomas Malama on Unsplash

### Inspiration

Some of the questions which could be inferred from this dataset are:

 1. How did the historical prices / market capitalizations of various currencies change over time?
 2. Predicting the future price of the currencies
 3. Which currencies are more volatile and which ones are more stable?
 4. How does the price fluctuations of currencies correlate with each other?
 5. Seasonal trend in the price fluctuations



  [1]: https://www.linkedin.com/pulse/blockchain-absolute-beginners-mohit-mamoria
  [2]: https://coinmarketcap.com/
  [3]: https://blockchain.info/
  [4]: https://etherscan.io/charts
  [5]: https://coinmarketcap.com/
  [6]: https://coinmarketcap.com/faq/
  [7]: https://blockchain.info/
  [8]: https://etherscan.io/charts
  [9]: http://cs229.stanford.edu/proj2014/Isaac%20Madan,%20Shaurya%20Saluja,%20Aojia%20Zhao,Automated%20Bitcoin%20Trading%20via%20Machine%20Learning%20Algorithms.pdf",.csv,True
Cryptocurrency Historical Prices,23,cryptocurrencypricehistory,coin_Stellar.csv,CC0-1.0,"### Context

Things like Block chain, Bitcoin, Bitcoin cash, Ethereum, Ripple etc are constantly coming in the news articles I read. So I wanted to understand more about it and [this post][1] helped me get started. Once the basics are done, the data scientist inside me started raising questions like:

1. How many cryptocurrencies are there and what are their prices and valuations?
2. Why is there a sudden surge in the interest in recent days? 



So what next? 
Now that we have the price data, I wanted to dig a little more about the factors affecting the price of coins. I started of with Bitcoin and there are quite a few parameters which affect the price of Bitcoin. Thanks to [Blockchain Info][3], I was able to get quite a few parameters on once in two day basis.

This will help understand the other factors related to Bitcoin price and also help one make future predictions in a better way than just using the historical price.


### Content

The dataset has one csv file for each currency. Price history is available on a daily basis from April 28, 2013.  This dataset has the historical price information of some of the top crypto currencies by market capitalization. 


 - Date : date of observation 
 - Open : Opening price on the given day
 - High : Highest price on the given day
 - Low : Lowest price on the given day
 - Close : Closing price on the given day
 - Volume : Volume of transactions on the given day
 - Market Cap : Market capitalization in USD



### Acknowledgements

This data is taken from [coinmarketcap][5] and it is [free][6] to use the data.


Cover Image : Photo by Thomas Malama on Unsplash

### Inspiration

Some of the questions which could be inferred from this dataset are:

 1. How did the historical prices / market capitalizations of various currencies change over time?
 2. Predicting the future price of the currencies
 3. Which currencies are more volatile and which ones are more stable?
 4. How does the price fluctuations of currencies correlate with each other?
 5. Seasonal trend in the price fluctuations



  [1]: https://www.linkedin.com/pulse/blockchain-absolute-beginners-mohit-mamoria
  [2]: https://coinmarketcap.com/
  [3]: https://blockchain.info/
  [4]: https://etherscan.io/charts
  [5]: https://coinmarketcap.com/
  [6]: https://coinmarketcap.com/faq/
  [7]: https://blockchain.info/
  [8]: https://etherscan.io/charts
  [9]: http://cs229.stanford.edu/proj2014/Isaac%20Madan,%20Shaurya%20Saluja,%20Aojia%20Zhao,Automated%20Bitcoin%20Trading%20via%20Machine%20Learning%20Algorithms.pdf",.csv,True
Cryptocurrency Historical Prices,23,cryptocurrencypricehistory,coin_CryptocomCoin.csv,CC0-1.0,"### Context

Things like Block chain, Bitcoin, Bitcoin cash, Ethereum, Ripple etc are constantly coming in the news articles I read. So I wanted to understand more about it and [this post][1] helped me get started. Once the basics are done, the data scientist inside me started raising questions like:

1. How many cryptocurrencies are there and what are their prices and valuations?
2. Why is there a sudden surge in the interest in recent days? 



So what next? 
Now that we have the price data, I wanted to dig a little more about the factors affecting the price of coins. I started of with Bitcoin and there are quite a few parameters which affect the price of Bitcoin. Thanks to [Blockchain Info][3], I was able to get quite a few parameters on once in two day basis.

This will help understand the other factors related to Bitcoin price and also help one make future predictions in a better way than just using the historical price.


### Content

The dataset has one csv file for each currency. Price history is available on a daily basis from April 28, 2013.  This dataset has the historical price information of some of the top crypto currencies by market capitalization. 


 - Date : date of observation 
 - Open : Opening price on the given day
 - High : Highest price on the given day
 - Low : Lowest price on the given day
 - Close : Closing price on the given day
 - Volume : Volume of transactions on the given day
 - Market Cap : Market capitalization in USD



### Acknowledgements

This data is taken from [coinmarketcap][5] and it is [free][6] to use the data.


Cover Image : Photo by Thomas Malama on Unsplash

### Inspiration

Some of the questions which could be inferred from this dataset are:

 1. How did the historical prices / market capitalizations of various currencies change over time?
 2. Predicting the future price of the currencies
 3. Which currencies are more volatile and which ones are more stable?
 4. How does the price fluctuations of currencies correlate with each other?
 5. Seasonal trend in the price fluctuations



  [1]: https://www.linkedin.com/pulse/blockchain-absolute-beginners-mohit-mamoria
  [2]: https://coinmarketcap.com/
  [3]: https://blockchain.info/
  [4]: https://etherscan.io/charts
  [5]: https://coinmarketcap.com/
  [6]: https://coinmarketcap.com/faq/
  [7]: https://blockchain.info/
  [8]: https://etherscan.io/charts
  [9]: http://cs229.stanford.edu/proj2014/Isaac%20Madan,%20Shaurya%20Saluja,%20Aojia%20Zhao,Automated%20Bitcoin%20Trading%20via%20Machine%20Learning%20Algorithms.pdf",.csv,True
Cryptocurrency Historical Prices,23,cryptocurrencypricehistory,coin_Dogecoin.csv,CC0-1.0,"### Context

Things like Block chain, Bitcoin, Bitcoin cash, Ethereum, Ripple etc are constantly coming in the news articles I read. So I wanted to understand more about it and [this post][1] helped me get started. Once the basics are done, the data scientist inside me started raising questions like:

1. How many cryptocurrencies are there and what are their prices and valuations?
2. Why is there a sudden surge in the interest in recent days? 



So what next? 
Now that we have the price data, I wanted to dig a little more about the factors affecting the price of coins. I started of with Bitcoin and there are quite a few parameters which affect the price of Bitcoin. Thanks to [Blockchain Info][3], I was able to get quite a few parameters on once in two day basis.

This will help understand the other factors related to Bitcoin price and also help one make future predictions in a better way than just using the historical price.


### Content

The dataset has one csv file for each currency. Price history is available on a daily basis from April 28, 2013.  This dataset has the historical price information of some of the top crypto currencies by market capitalization. 


 - Date : date of observation 
 - Open : Opening price on the given day
 - High : Highest price on the given day
 - Low : Lowest price on the given day
 - Close : Closing price on the given day
 - Volume : Volume of transactions on the given day
 - Market Cap : Market capitalization in USD



### Acknowledgements

This data is taken from [coinmarketcap][5] and it is [free][6] to use the data.


Cover Image : Photo by Thomas Malama on Unsplash

### Inspiration

Some of the questions which could be inferred from this dataset are:

 1. How did the historical prices / market capitalizations of various currencies change over time?
 2. Predicting the future price of the currencies
 3. Which currencies are more volatile and which ones are more stable?
 4. How does the price fluctuations of currencies correlate with each other?
 5. Seasonal trend in the price fluctuations



  [1]: https://www.linkedin.com/pulse/blockchain-absolute-beginners-mohit-mamoria
  [2]: https://coinmarketcap.com/
  [3]: https://blockchain.info/
  [4]: https://etherscan.io/charts
  [5]: https://coinmarketcap.com/
  [6]: https://coinmarketcap.com/faq/
  [7]: https://blockchain.info/
  [8]: https://etherscan.io/charts
  [9]: http://cs229.stanford.edu/proj2014/Isaac%20Madan,%20Shaurya%20Saluja,%20Aojia%20Zhao,Automated%20Bitcoin%20Trading%20via%20Machine%20Learning%20Algorithms.pdf",.csv,True
Cryptocurrency Historical Prices,23,cryptocurrencypricehistory,coin_WrappedBitcoin.csv,CC0-1.0,"### Context

Things like Block chain, Bitcoin, Bitcoin cash, Ethereum, Ripple etc are constantly coming in the news articles I read. So I wanted to understand more about it and [this post][1] helped me get started. Once the basics are done, the data scientist inside me started raising questions like:

1. How many cryptocurrencies are there and what are their prices and valuations?
2. Why is there a sudden surge in the interest in recent days? 



So what next? 
Now that we have the price data, I wanted to dig a little more about the factors affecting the price of coins. I started of with Bitcoin and there are quite a few parameters which affect the price of Bitcoin. Thanks to [Blockchain Info][3], I was able to get quite a few parameters on once in two day basis.

This will help understand the other factors related to Bitcoin price and also help one make future predictions in a better way than just using the historical price.


### Content

The dataset has one csv file for each currency. Price history is available on a daily basis from April 28, 2013.  This dataset has the historical price information of some of the top crypto currencies by market capitalization. 


 - Date : date of observation 
 - Open : Opening price on the given day
 - High : Highest price on the given day
 - Low : Lowest price on the given day
 - Close : Closing price on the given day
 - Volume : Volume of transactions on the given day
 - Market Cap : Market capitalization in USD



### Acknowledgements

This data is taken from [coinmarketcap][5] and it is [free][6] to use the data.


Cover Image : Photo by Thomas Malama on Unsplash

### Inspiration

Some of the questions which could be inferred from this dataset are:

 1. How did the historical prices / market capitalizations of various currencies change over time?
 2. Predicting the future price of the currencies
 3. Which currencies are more volatile and which ones are more stable?
 4. How does the price fluctuations of currencies correlate with each other?
 5. Seasonal trend in the price fluctuations



  [1]: https://www.linkedin.com/pulse/blockchain-absolute-beginners-mohit-mamoria
  [2]: https://coinmarketcap.com/
  [3]: https://blockchain.info/
  [4]: https://etherscan.io/charts
  [5]: https://coinmarketcap.com/
  [6]: https://coinmarketcap.com/faq/
  [7]: https://blockchain.info/
  [8]: https://etherscan.io/charts
  [9]: http://cs229.stanford.edu/proj2014/Isaac%20Madan,%20Shaurya%20Saluja,%20Aojia%20Zhao,Automated%20Bitcoin%20Trading%20via%20Machine%20Learning%20Algorithms.pdf",.csv,True
Cybersecurity Risk (2022 CISA Vulnerability),5,exploring-cybersecurity-risk-via-2022-cisa-vulne,2022-06-27-enriched.csv,CC0-1.0,"_____
# Cybersecurity Risk (2022 CISA Vulnerability)
### Severity, CVSS Score, and National Security Vulnerability Types
By  [[source]](https://github.com/hrbrmstr/cisa-known-exploited-vulns)
_____

### About this dataset
&gt; This dataset presents an in-depth exploration of the security vulnerabilities across the United States from the CISA Known Exploited Vulnerabilities catalog for 2022. You'll find a number of vulnerability types and severity levels, as well as CVSS scores, vendor projects, product names, and other pertinent information. By arming yourself with this knowledge, you can better protect your network from any potential security issues that may arise - now or in the future. Dive into details such as attack vectors, complexity ratings and required actions for each vulnerability to stay prepared and protected throughout your journey! Every single detail matters when it comes to keeping yourself secure online - so explore some of these potential risks and gain valuable insights today!

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; This dataset provides a comprehensive list of security vulnerabilities in the United States from the CISA Known Exploited Vulnerabilities catalog for the year 2022, including vulnerability types, severity levels, CVSS scores, vendor projects, product names, and other relevant information. This is an important tool for organizations to better understand and manage their cybersecurity risk. 
&gt; 

&gt;  

&gt; 
&gt;  * `vendor_project`: The name of the vendor project associated with the vulnerability. 
&gt;  * `product`: The name of the product associated with the vulnerability. 
&gt;  * `vulnerability_name`: The name of the vulnerability that affects a particular product or system.  
&gt;  * `date_added`: The date on which a particular vulnerability was added to CISA’s Known Exploited Vulnerabilities catalog.  
&gt;  * `short_description`: A brief description of what makes that specific vulnerability dangerous/risky in nature.  
&gt;  * `required_action`: A clear outline or instruction as to how an organization should address/mitigate that particular vulnerability within its own network/infrastructure setup.   
&gt; *	`due_date`, :The date by which required action should be completed at minimum if any mitigation measures are taken against those weaknesses discovered from this analysis report .  			      
&gt; 
&gt;  * `notes`, A brief text field related additional insights about potential further risks and concerns related each discovered vulnerabilities         
&gt; 
&gt;  * CVSS Score and Severity assessments : CISA calculates these two indicators (Common Vulnerability Scoring System (CVSS) score & Severity) based on certain parameters by giving weighted marks in order understand it visibility regarding type & magnitude (likely impact level visllyl clearly indicating red amber gn & green status } as per internal computation). Ratings typically range from 0 - 10 indicating descn'ding order i e; 0 being Very Low' 10 - Extremely High severity or criticality        
&gt; 
&gt;  **æroup** :The group associated with that particular public exploit currently listed on US-CERT platform usually used Jigsaw puzzles piece fitting concepts to help narrowing down investigation efforts     involved directly contributed exploitsor sponsored research taking risk into account while handling each new findings ​​ ​      
&gt; 


### Research Ideas
&gt; - Analyzing the severity of different security vulnerabilities over time in order to measure effectiveness of cybersecurity efforts.
&gt; - Building a data visualization tool to showcase the different types, CVSS scores, vendor projects and products names associated with security vulnerabilities over time in the US.  
&gt; - Developing predictive analytics that can anticipate future trends and changes in security vulnerabilities to better inform CISA decisions

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://github.com/hrbrmstr/cisa-known-exploited-vulns)
&gt;  

### License 
&gt; 
&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: 2022-06-08-enriched.csv**
| Column name            | Description                                                                                      |
|:-----------------------|:-------------------------------------------------------------------------------------------------|
| **vendor_project**     | The name of the vendor project associated with the vulnerability. (String)                       |
| **product**            | The name of the product associated with the vulnerability. (String)                              |
| **vulnerability_name** | The name of the vulnerability. (String)                                                          |
| **date_added**         | The date the vulnerability was added to the CISA Known Exploited Vulnerabilities catalog. (Date) |
| **short_description**  | A brief description of the vulnerability. (String)                                               |
| **required_action**    | The action required to remediate the vulnerability. (String)                                     |
| **due_date**           | The date by which the required action must be completed. (Date)                                  |
| **notes**              | Additional notes about the vulnerability. (String)                                               |
| **grp**                | The group associated with the vulnerability. (String)                                            |
| **pub_date**           | The date the vulnerability was published. (Date)                                                 |
| **cvss**               | The Common Vulnerability Scoring System score associated with the vulnerability. (Float)         |
| **cwe**                | The Common Weakness Enumeration associated with the vulnerability. (String)                      |
| **vector**             | The vector associated with the vulnerability. (String)                                           |
| **complexity**         | The complexity associated with the vulnerability. (String)                                       |
| **severity**           | The severity level associated with the vulnerability. (String)                                   |

_____

**File: 2022-06-09-enriched.csv**
| Column name            | Description                                                                                      |
|:-----------------------|:-------------------------------------------------------------------------------------------------|
| **vendor_project**     | The name of the vendor project associated with the vulnerability. (String)                       |
| **product**            | The name of the product associated with the vulnerability. (String)                              |
| **vulnerability_name** | The name of the vulnerability. (String)                                                          |
| **date_added**         | The date the vulnerability was added to the CISA Known Exploited Vulnerabilities catalog. (Date) |
| **short_description**  | A brief description of the vulnerability. (String)                                               |
| **required_action**    | The action required to remediate the vulnerability. (String)                                     |
| **due_date**           | The date by which the required action must be completed. (Date)                                  |
| **notes**              | Additional notes about the vulnerability. (String)                                               |
| **grp**                | The group associated with the vulnerability. (String)                                            |
| **pub_date**           | The date the vulnerability was published. (Date)                                                 |
| **cvss**               | The Common Vulnerability Scoring System score associated with the vulnerability. (Float)         |
| **cwe**                | The Common Weakness Enumeration associated with the vulnerability. (String)                      |
| **vector**             | The vector associated with the vulnerability. (String)                                           |
| **complexity**         | The complexity associated with the vulnerability. (String)                                       |
| **severity**           | The severity level associated with the vulnerability. (String)                                   |

_____

**File: 2022-06-27-enriched.csv**
| Column name            | Description                                                                                      |
|:-----------------------|:-------------------------------------------------------------------------------------------------|
| **vendor_project**     | The name of the vendor project associated with the vulnerability. (String)                       |
| **product**            | The name of the product associated with the vulnerability. (String)                              |
| **vulnerability_name** | The name of the vulnerability. (String)                                                          |
| **date_added**         | The date the vulnerability was added to the CISA Known Exploited Vulnerabilities catalog. (Date) |
| **short_description**  | A brief description of the vulnerability. (String)                                               |
| **required_action**    | The action required to remediate the vulnerability. (String)                                     |
| **due_date**           | The date by which the required action must be completed. (Date)                                  |
| **notes**              | Additional notes about the vulnerability. (String)                                               |
| **grp**                | The group associated with the vulnerability. (String)                                            |
| **pub_date**           | The date the vulnerability was published. (Date)                                                 |
| **cvss**               | The Common Vulnerability Scoring System score associated with the vulnerability. (Float)         |
| **cwe**                | The Common Weakness Enumeration associated with the vulnerability. (String)                      |
| **vector**             | The vector associated with the vulnerability. (String)                                           |
| **complexity**         | The complexity associated with the vulnerability. (String)                                       |
| **severity**           | The severity level associated with the vulnerability. (String)                                   |

_____

**File: 2022-07-04-enriched.csv**
| Column name            | Description                                                                                      |
|:-----------------------|:-------------------------------------------------------------------------------------------------|
| **vendor_project**     | The name of the vendor project associated with the vulnerability. (String)                       |
| **product**            | The name of the product associated with the vulnerability. (String)                              |
| **vulnerability_name** | The name of the vulnerability. (String)                                                          |
| **date_added**         | The date the vulnerability was added to the CISA Known Exploited Vulnerabilities catalog. (Date) |
| **short_description**  | A brief description of the vulnerability. (String)                                               |
| **required_action**    | The action required to remediate the vulnerability. (String)                                     |
| **due_date**           | The date by which the required action must be completed. (Date)                                  |
| **notes**              | Additional notes about the vulnerability. (String)                                               |
| **grp**                | The group associated with the vulnerability. (String)                                            |
| **pub_date**           | The date the vulnerability was published. (Date)                                                 |
| **cvss**               | The Common Vulnerability Scoring System score associated with the vulnerability. (Float)         |
| **cwe**                | The Common Weakness Enumeration associated with the vulnerability. (String)                      |
| **vector**             | The vector associated with the vulnerability. (String)                                           |
| **complexity**         | The complexity associated with the vulnerability. (String)                                       |
| **severity**           | The severity level associated with the vulnerability. (String)                                   |

_____

**File: 2022-12-09-enriched.csv**
| Column name            | Description                                                                                      |
|:-----------------------|:-------------------------------------------------------------------------------------------------|
| **vendor_project**     | The name of the vendor project associated with the vulnerability. (String)                       |
| **product**            | The name of the product associated with the vulnerability. (String)                              |
| **vulnerability_name** | The name of the vulnerability. (String)                                                          |
| **date_added**         | The date the vulnerability was added to the CISA Known Exploited Vulnerabilities catalog. (Date) |
| **short_description**  | A brief description of the vulnerability. (String)                                               |
| **required_action**    | The action required to remediate the vulnerability. (String)                                     |
| **due_date**           | The date by which the required action must be completed. (Date)                                  |
| **notes**              | Additional notes about the vulnerability. (String)                                               |
| **grp**                | The group associated with the vulnerability. (String)                                            |
| **pub_date**           | The date the vulnerability was published. (Date)                                                 |
| **cvss**               | The Common Vulnerability Scoring System score associated with the vulnerability. (Float)         |
| **cwe**                | The Common Weakness Enumeration associated with the vulnerability. (String)                      |
| **vector**             | The vector associated with the vulnerability. (String)                                           |
| **complexity**         | The complexity associated with the vulnerability. (String)                                       |
| **severity**           | The severity level associated with the vulnerability. (String)                                   |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [](https://github.com/hrbrmstr/cisa-known-exploited-vulns).

",.csv,True
Cybersecurity Risk (2022 CISA Vulnerability),5,exploring-cybersecurity-risk-via-2022-cisa-vulne,2022-06-09-enriched.csv,CC0-1.0,"_____
# Cybersecurity Risk (2022 CISA Vulnerability)
### Severity, CVSS Score, and National Security Vulnerability Types
By  [[source]](https://github.com/hrbrmstr/cisa-known-exploited-vulns)
_____

### About this dataset
&gt; This dataset presents an in-depth exploration of the security vulnerabilities across the United States from the CISA Known Exploited Vulnerabilities catalog for 2022. You'll find a number of vulnerability types and severity levels, as well as CVSS scores, vendor projects, product names, and other pertinent information. By arming yourself with this knowledge, you can better protect your network from any potential security issues that may arise - now or in the future. Dive into details such as attack vectors, complexity ratings and required actions for each vulnerability to stay prepared and protected throughout your journey! Every single detail matters when it comes to keeping yourself secure online - so explore some of these potential risks and gain valuable insights today!

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; This dataset provides a comprehensive list of security vulnerabilities in the United States from the CISA Known Exploited Vulnerabilities catalog for the year 2022, including vulnerability types, severity levels, CVSS scores, vendor projects, product names, and other relevant information. This is an important tool for organizations to better understand and manage their cybersecurity risk. 
&gt; 

&gt;  

&gt; 
&gt;  * `vendor_project`: The name of the vendor project associated with the vulnerability. 
&gt;  * `product`: The name of the product associated with the vulnerability. 
&gt;  * `vulnerability_name`: The name of the vulnerability that affects a particular product or system.  
&gt;  * `date_added`: The date on which a particular vulnerability was added to CISA’s Known Exploited Vulnerabilities catalog.  
&gt;  * `short_description`: A brief description of what makes that specific vulnerability dangerous/risky in nature.  
&gt;  * `required_action`: A clear outline or instruction as to how an organization should address/mitigate that particular vulnerability within its own network/infrastructure setup.   
&gt; *	`due_date`, :The date by which required action should be completed at minimum if any mitigation measures are taken against those weaknesses discovered from this analysis report .  			      
&gt; 
&gt;  * `notes`, A brief text field related additional insights about potential further risks and concerns related each discovered vulnerabilities         
&gt; 
&gt;  * CVSS Score and Severity assessments : CISA calculates these two indicators (Common Vulnerability Scoring System (CVSS) score & Severity) based on certain parameters by giving weighted marks in order understand it visibility regarding type & magnitude (likely impact level visllyl clearly indicating red amber gn & green status } as per internal computation). Ratings typically range from 0 - 10 indicating descn'ding order i e; 0 being Very Low' 10 - Extremely High severity or criticality        
&gt; 
&gt;  **æroup** :The group associated with that particular public exploit currently listed on US-CERT platform usually used Jigsaw puzzles piece fitting concepts to help narrowing down investigation efforts     involved directly contributed exploitsor sponsored research taking risk into account while handling each new findings ​​ ​      
&gt; 


### Research Ideas
&gt; - Analyzing the severity of different security vulnerabilities over time in order to measure effectiveness of cybersecurity efforts.
&gt; - Building a data visualization tool to showcase the different types, CVSS scores, vendor projects and products names associated with security vulnerabilities over time in the US.  
&gt; - Developing predictive analytics that can anticipate future trends and changes in security vulnerabilities to better inform CISA decisions

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://github.com/hrbrmstr/cisa-known-exploited-vulns)
&gt;  

### License 
&gt; 
&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: 2022-06-08-enriched.csv**
| Column name            | Description                                                                                      |
|:-----------------------|:-------------------------------------------------------------------------------------------------|
| **vendor_project**     | The name of the vendor project associated with the vulnerability. (String)                       |
| **product**            | The name of the product associated with the vulnerability. (String)                              |
| **vulnerability_name** | The name of the vulnerability. (String)                                                          |
| **date_added**         | The date the vulnerability was added to the CISA Known Exploited Vulnerabilities catalog. (Date) |
| **short_description**  | A brief description of the vulnerability. (String)                                               |
| **required_action**    | The action required to remediate the vulnerability. (String)                                     |
| **due_date**           | The date by which the required action must be completed. (Date)                                  |
| **notes**              | Additional notes about the vulnerability. (String)                                               |
| **grp**                | The group associated with the vulnerability. (String)                                            |
| **pub_date**           | The date the vulnerability was published. (Date)                                                 |
| **cvss**               | The Common Vulnerability Scoring System score associated with the vulnerability. (Float)         |
| **cwe**                | The Common Weakness Enumeration associated with the vulnerability. (String)                      |
| **vector**             | The vector associated with the vulnerability. (String)                                           |
| **complexity**         | The complexity associated with the vulnerability. (String)                                       |
| **severity**           | The severity level associated with the vulnerability. (String)                                   |

_____

**File: 2022-06-09-enriched.csv**
| Column name            | Description                                                                                      |
|:-----------------------|:-------------------------------------------------------------------------------------------------|
| **vendor_project**     | The name of the vendor project associated with the vulnerability. (String)                       |
| **product**            | The name of the product associated with the vulnerability. (String)                              |
| **vulnerability_name** | The name of the vulnerability. (String)                                                          |
| **date_added**         | The date the vulnerability was added to the CISA Known Exploited Vulnerabilities catalog. (Date) |
| **short_description**  | A brief description of the vulnerability. (String)                                               |
| **required_action**    | The action required to remediate the vulnerability. (String)                                     |
| **due_date**           | The date by which the required action must be completed. (Date)                                  |
| **notes**              | Additional notes about the vulnerability. (String)                                               |
| **grp**                | The group associated with the vulnerability. (String)                                            |
| **pub_date**           | The date the vulnerability was published. (Date)                                                 |
| **cvss**               | The Common Vulnerability Scoring System score associated with the vulnerability. (Float)         |
| **cwe**                | The Common Weakness Enumeration associated with the vulnerability. (String)                      |
| **vector**             | The vector associated with the vulnerability. (String)                                           |
| **complexity**         | The complexity associated with the vulnerability. (String)                                       |
| **severity**           | The severity level associated with the vulnerability. (String)                                   |

_____

**File: 2022-06-27-enriched.csv**
| Column name            | Description                                                                                      |
|:-----------------------|:-------------------------------------------------------------------------------------------------|
| **vendor_project**     | The name of the vendor project associated with the vulnerability. (String)                       |
| **product**            | The name of the product associated with the vulnerability. (String)                              |
| **vulnerability_name** | The name of the vulnerability. (String)                                                          |
| **date_added**         | The date the vulnerability was added to the CISA Known Exploited Vulnerabilities catalog. (Date) |
| **short_description**  | A brief description of the vulnerability. (String)                                               |
| **required_action**    | The action required to remediate the vulnerability. (String)                                     |
| **due_date**           | The date by which the required action must be completed. (Date)                                  |
| **notes**              | Additional notes about the vulnerability. (String)                                               |
| **grp**                | The group associated with the vulnerability. (String)                                            |
| **pub_date**           | The date the vulnerability was published. (Date)                                                 |
| **cvss**               | The Common Vulnerability Scoring System score associated with the vulnerability. (Float)         |
| **cwe**                | The Common Weakness Enumeration associated with the vulnerability. (String)                      |
| **vector**             | The vector associated with the vulnerability. (String)                                           |
| **complexity**         | The complexity associated with the vulnerability. (String)                                       |
| **severity**           | The severity level associated with the vulnerability. (String)                                   |

_____

**File: 2022-07-04-enriched.csv**
| Column name            | Description                                                                                      |
|:-----------------------|:-------------------------------------------------------------------------------------------------|
| **vendor_project**     | The name of the vendor project associated with the vulnerability. (String)                       |
| **product**            | The name of the product associated with the vulnerability. (String)                              |
| **vulnerability_name** | The name of the vulnerability. (String)                                                          |
| **date_added**         | The date the vulnerability was added to the CISA Known Exploited Vulnerabilities catalog. (Date) |
| **short_description**  | A brief description of the vulnerability. (String)                                               |
| **required_action**    | The action required to remediate the vulnerability. (String)                                     |
| **due_date**           | The date by which the required action must be completed. (Date)                                  |
| **notes**              | Additional notes about the vulnerability. (String)                                               |
| **grp**                | The group associated with the vulnerability. (String)                                            |
| **pub_date**           | The date the vulnerability was published. (Date)                                                 |
| **cvss**               | The Common Vulnerability Scoring System score associated with the vulnerability. (Float)         |
| **cwe**                | The Common Weakness Enumeration associated with the vulnerability. (String)                      |
| **vector**             | The vector associated with the vulnerability. (String)                                           |
| **complexity**         | The complexity associated with the vulnerability. (String)                                       |
| **severity**           | The severity level associated with the vulnerability. (String)                                   |

_____

**File: 2022-12-09-enriched.csv**
| Column name            | Description                                                                                      |
|:-----------------------|:-------------------------------------------------------------------------------------------------|
| **vendor_project**     | The name of the vendor project associated with the vulnerability. (String)                       |
| **product**            | The name of the product associated with the vulnerability. (String)                              |
| **vulnerability_name** | The name of the vulnerability. (String)                                                          |
| **date_added**         | The date the vulnerability was added to the CISA Known Exploited Vulnerabilities catalog. (Date) |
| **short_description**  | A brief description of the vulnerability. (String)                                               |
| **required_action**    | The action required to remediate the vulnerability. (String)                                     |
| **due_date**           | The date by which the required action must be completed. (Date)                                  |
| **notes**              | Additional notes about the vulnerability. (String)                                               |
| **grp**                | The group associated with the vulnerability. (String)                                            |
| **pub_date**           | The date the vulnerability was published. (Date)                                                 |
| **cvss**               | The Common Vulnerability Scoring System score associated with the vulnerability. (Float)         |
| **cwe**                | The Common Weakness Enumeration associated with the vulnerability. (String)                      |
| **vector**             | The vector associated with the vulnerability. (String)                                           |
| **complexity**         | The complexity associated with the vulnerability. (String)                                       |
| **severity**           | The severity level associated with the vulnerability. (String)                                   |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [](https://github.com/hrbrmstr/cisa-known-exploited-vulns).

",.csv,True
Cybersecurity Risk (2022 CISA Vulnerability),5,exploring-cybersecurity-risk-via-2022-cisa-vulne,2022-07-04-enriched.csv,CC0-1.0,"_____
# Cybersecurity Risk (2022 CISA Vulnerability)
### Severity, CVSS Score, and National Security Vulnerability Types
By  [[source]](https://github.com/hrbrmstr/cisa-known-exploited-vulns)
_____

### About this dataset
&gt; This dataset presents an in-depth exploration of the security vulnerabilities across the United States from the CISA Known Exploited Vulnerabilities catalog for 2022. You'll find a number of vulnerability types and severity levels, as well as CVSS scores, vendor projects, product names, and other pertinent information. By arming yourself with this knowledge, you can better protect your network from any potential security issues that may arise - now or in the future. Dive into details such as attack vectors, complexity ratings and required actions for each vulnerability to stay prepared and protected throughout your journey! Every single detail matters when it comes to keeping yourself secure online - so explore some of these potential risks and gain valuable insights today!

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; This dataset provides a comprehensive list of security vulnerabilities in the United States from the CISA Known Exploited Vulnerabilities catalog for the year 2022, including vulnerability types, severity levels, CVSS scores, vendor projects, product names, and other relevant information. This is an important tool for organizations to better understand and manage their cybersecurity risk. 
&gt; 

&gt;  

&gt; 
&gt;  * `vendor_project`: The name of the vendor project associated with the vulnerability. 
&gt;  * `product`: The name of the product associated with the vulnerability. 
&gt;  * `vulnerability_name`: The name of the vulnerability that affects a particular product or system.  
&gt;  * `date_added`: The date on which a particular vulnerability was added to CISA’s Known Exploited Vulnerabilities catalog.  
&gt;  * `short_description`: A brief description of what makes that specific vulnerability dangerous/risky in nature.  
&gt;  * `required_action`: A clear outline or instruction as to how an organization should address/mitigate that particular vulnerability within its own network/infrastructure setup.   
&gt; *	`due_date`, :The date by which required action should be completed at minimum if any mitigation measures are taken against those weaknesses discovered from this analysis report .  			      
&gt; 
&gt;  * `notes`, A brief text field related additional insights about potential further risks and concerns related each discovered vulnerabilities         
&gt; 
&gt;  * CVSS Score and Severity assessments : CISA calculates these two indicators (Common Vulnerability Scoring System (CVSS) score & Severity) based on certain parameters by giving weighted marks in order understand it visibility regarding type & magnitude (likely impact level visllyl clearly indicating red amber gn & green status } as per internal computation). Ratings typically range from 0 - 10 indicating descn'ding order i e; 0 being Very Low' 10 - Extremely High severity or criticality        
&gt; 
&gt;  **æroup** :The group associated with that particular public exploit currently listed on US-CERT platform usually used Jigsaw puzzles piece fitting concepts to help narrowing down investigation efforts     involved directly contributed exploitsor sponsored research taking risk into account while handling each new findings ​​ ​      
&gt; 


### Research Ideas
&gt; - Analyzing the severity of different security vulnerabilities over time in order to measure effectiveness of cybersecurity efforts.
&gt; - Building a data visualization tool to showcase the different types, CVSS scores, vendor projects and products names associated with security vulnerabilities over time in the US.  
&gt; - Developing predictive analytics that can anticipate future trends and changes in security vulnerabilities to better inform CISA decisions

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://github.com/hrbrmstr/cisa-known-exploited-vulns)
&gt;  

### License 
&gt; 
&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: 2022-06-08-enriched.csv**
| Column name            | Description                                                                                      |
|:-----------------------|:-------------------------------------------------------------------------------------------------|
| **vendor_project**     | The name of the vendor project associated with the vulnerability. (String)                       |
| **product**            | The name of the product associated with the vulnerability. (String)                              |
| **vulnerability_name** | The name of the vulnerability. (String)                                                          |
| **date_added**         | The date the vulnerability was added to the CISA Known Exploited Vulnerabilities catalog. (Date) |
| **short_description**  | A brief description of the vulnerability. (String)                                               |
| **required_action**    | The action required to remediate the vulnerability. (String)                                     |
| **due_date**           | The date by which the required action must be completed. (Date)                                  |
| **notes**              | Additional notes about the vulnerability. (String)                                               |
| **grp**                | The group associated with the vulnerability. (String)                                            |
| **pub_date**           | The date the vulnerability was published. (Date)                                                 |
| **cvss**               | The Common Vulnerability Scoring System score associated with the vulnerability. (Float)         |
| **cwe**                | The Common Weakness Enumeration associated with the vulnerability. (String)                      |
| **vector**             | The vector associated with the vulnerability. (String)                                           |
| **complexity**         | The complexity associated with the vulnerability. (String)                                       |
| **severity**           | The severity level associated with the vulnerability. (String)                                   |

_____

**File: 2022-06-09-enriched.csv**
| Column name            | Description                                                                                      |
|:-----------------------|:-------------------------------------------------------------------------------------------------|
| **vendor_project**     | The name of the vendor project associated with the vulnerability. (String)                       |
| **product**            | The name of the product associated with the vulnerability. (String)                              |
| **vulnerability_name** | The name of the vulnerability. (String)                                                          |
| **date_added**         | The date the vulnerability was added to the CISA Known Exploited Vulnerabilities catalog. (Date) |
| **short_description**  | A brief description of the vulnerability. (String)                                               |
| **required_action**    | The action required to remediate the vulnerability. (String)                                     |
| **due_date**           | The date by which the required action must be completed. (Date)                                  |
| **notes**              | Additional notes about the vulnerability. (String)                                               |
| **grp**                | The group associated with the vulnerability. (String)                                            |
| **pub_date**           | The date the vulnerability was published. (Date)                                                 |
| **cvss**               | The Common Vulnerability Scoring System score associated with the vulnerability. (Float)         |
| **cwe**                | The Common Weakness Enumeration associated with the vulnerability. (String)                      |
| **vector**             | The vector associated with the vulnerability. (String)                                           |
| **complexity**         | The complexity associated with the vulnerability. (String)                                       |
| **severity**           | The severity level associated with the vulnerability. (String)                                   |

_____

**File: 2022-06-27-enriched.csv**
| Column name            | Description                                                                                      |
|:-----------------------|:-------------------------------------------------------------------------------------------------|
| **vendor_project**     | The name of the vendor project associated with the vulnerability. (String)                       |
| **product**            | The name of the product associated with the vulnerability. (String)                              |
| **vulnerability_name** | The name of the vulnerability. (String)                                                          |
| **date_added**         | The date the vulnerability was added to the CISA Known Exploited Vulnerabilities catalog. (Date) |
| **short_description**  | A brief description of the vulnerability. (String)                                               |
| **required_action**    | The action required to remediate the vulnerability. (String)                                     |
| **due_date**           | The date by which the required action must be completed. (Date)                                  |
| **notes**              | Additional notes about the vulnerability. (String)                                               |
| **grp**                | The group associated with the vulnerability. (String)                                            |
| **pub_date**           | The date the vulnerability was published. (Date)                                                 |
| **cvss**               | The Common Vulnerability Scoring System score associated with the vulnerability. (Float)         |
| **cwe**                | The Common Weakness Enumeration associated with the vulnerability. (String)                      |
| **vector**             | The vector associated with the vulnerability. (String)                                           |
| **complexity**         | The complexity associated with the vulnerability. (String)                                       |
| **severity**           | The severity level associated with the vulnerability. (String)                                   |

_____

**File: 2022-07-04-enriched.csv**
| Column name            | Description                                                                                      |
|:-----------------------|:-------------------------------------------------------------------------------------------------|
| **vendor_project**     | The name of the vendor project associated with the vulnerability. (String)                       |
| **product**            | The name of the product associated with the vulnerability. (String)                              |
| **vulnerability_name** | The name of the vulnerability. (String)                                                          |
| **date_added**         | The date the vulnerability was added to the CISA Known Exploited Vulnerabilities catalog. (Date) |
| **short_description**  | A brief description of the vulnerability. (String)                                               |
| **required_action**    | The action required to remediate the vulnerability. (String)                                     |
| **due_date**           | The date by which the required action must be completed. (Date)                                  |
| **notes**              | Additional notes about the vulnerability. (String)                                               |
| **grp**                | The group associated with the vulnerability. (String)                                            |
| **pub_date**           | The date the vulnerability was published. (Date)                                                 |
| **cvss**               | The Common Vulnerability Scoring System score associated with the vulnerability. (Float)         |
| **cwe**                | The Common Weakness Enumeration associated with the vulnerability. (String)                      |
| **vector**             | The vector associated with the vulnerability. (String)                                           |
| **complexity**         | The complexity associated with the vulnerability. (String)                                       |
| **severity**           | The severity level associated with the vulnerability. (String)                                   |

_____

**File: 2022-12-09-enriched.csv**
| Column name            | Description                                                                                      |
|:-----------------------|:-------------------------------------------------------------------------------------------------|
| **vendor_project**     | The name of the vendor project associated with the vulnerability. (String)                       |
| **product**            | The name of the product associated with the vulnerability. (String)                              |
| **vulnerability_name** | The name of the vulnerability. (String)                                                          |
| **date_added**         | The date the vulnerability was added to the CISA Known Exploited Vulnerabilities catalog. (Date) |
| **short_description**  | A brief description of the vulnerability. (String)                                               |
| **required_action**    | The action required to remediate the vulnerability. (String)                                     |
| **due_date**           | The date by which the required action must be completed. (Date)                                  |
| **notes**              | Additional notes about the vulnerability. (String)                                               |
| **grp**                | The group associated with the vulnerability. (String)                                            |
| **pub_date**           | The date the vulnerability was published. (Date)                                                 |
| **cvss**               | The Common Vulnerability Scoring System score associated with the vulnerability. (Float)         |
| **cwe**                | The Common Weakness Enumeration associated with the vulnerability. (String)                      |
| **vector**             | The vector associated with the vulnerability. (String)                                           |
| **complexity**         | The complexity associated with the vulnerability. (String)                                       |
| **severity**           | The severity level associated with the vulnerability. (String)                                   |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [](https://github.com/hrbrmstr/cisa-known-exploited-vulns).

",.csv,True
Cybersecurity Risk (2022 CISA Vulnerability),5,exploring-cybersecurity-risk-via-2022-cisa-vulne,2022-06-08-enriched.csv,CC0-1.0,"_____
# Cybersecurity Risk (2022 CISA Vulnerability)
### Severity, CVSS Score, and National Security Vulnerability Types
By  [[source]](https://github.com/hrbrmstr/cisa-known-exploited-vulns)
_____

### About this dataset
&gt; This dataset presents an in-depth exploration of the security vulnerabilities across the United States from the CISA Known Exploited Vulnerabilities catalog for 2022. You'll find a number of vulnerability types and severity levels, as well as CVSS scores, vendor projects, product names, and other pertinent information. By arming yourself with this knowledge, you can better protect your network from any potential security issues that may arise - now or in the future. Dive into details such as attack vectors, complexity ratings and required actions for each vulnerability to stay prepared and protected throughout your journey! Every single detail matters when it comes to keeping yourself secure online - so explore some of these potential risks and gain valuable insights today!

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; This dataset provides a comprehensive list of security vulnerabilities in the United States from the CISA Known Exploited Vulnerabilities catalog for the year 2022, including vulnerability types, severity levels, CVSS scores, vendor projects, product names, and other relevant information. This is an important tool for organizations to better understand and manage their cybersecurity risk. 
&gt; 

&gt;  

&gt; 
&gt;  * `vendor_project`: The name of the vendor project associated with the vulnerability. 
&gt;  * `product`: The name of the product associated with the vulnerability. 
&gt;  * `vulnerability_name`: The name of the vulnerability that affects a particular product or system.  
&gt;  * `date_added`: The date on which a particular vulnerability was added to CISA’s Known Exploited Vulnerabilities catalog.  
&gt;  * `short_description`: A brief description of what makes that specific vulnerability dangerous/risky in nature.  
&gt;  * `required_action`: A clear outline or instruction as to how an organization should address/mitigate that particular vulnerability within its own network/infrastructure setup.   
&gt; *	`due_date`, :The date by which required action should be completed at minimum if any mitigation measures are taken against those weaknesses discovered from this analysis report .  			      
&gt; 
&gt;  * `notes`, A brief text field related additional insights about potential further risks and concerns related each discovered vulnerabilities         
&gt; 
&gt;  * CVSS Score and Severity assessments : CISA calculates these two indicators (Common Vulnerability Scoring System (CVSS) score & Severity) based on certain parameters by giving weighted marks in order understand it visibility regarding type & magnitude (likely impact level visllyl clearly indicating red amber gn & green status } as per internal computation). Ratings typically range from 0 - 10 indicating descn'ding order i e; 0 being Very Low' 10 - Extremely High severity or criticality        
&gt; 
&gt;  **æroup** :The group associated with that particular public exploit currently listed on US-CERT platform usually used Jigsaw puzzles piece fitting concepts to help narrowing down investigation efforts     involved directly contributed exploitsor sponsored research taking risk into account while handling each new findings ​​ ​      
&gt; 


### Research Ideas
&gt; - Analyzing the severity of different security vulnerabilities over time in order to measure effectiveness of cybersecurity efforts.
&gt; - Building a data visualization tool to showcase the different types, CVSS scores, vendor projects and products names associated with security vulnerabilities over time in the US.  
&gt; - Developing predictive analytics that can anticipate future trends and changes in security vulnerabilities to better inform CISA decisions

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://github.com/hrbrmstr/cisa-known-exploited-vulns)
&gt;  

### License 
&gt; 
&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: 2022-06-08-enriched.csv**
| Column name            | Description                                                                                      |
|:-----------------------|:-------------------------------------------------------------------------------------------------|
| **vendor_project**     | The name of the vendor project associated with the vulnerability. (String)                       |
| **product**            | The name of the product associated with the vulnerability. (String)                              |
| **vulnerability_name** | The name of the vulnerability. (String)                                                          |
| **date_added**         | The date the vulnerability was added to the CISA Known Exploited Vulnerabilities catalog. (Date) |
| **short_description**  | A brief description of the vulnerability. (String)                                               |
| **required_action**    | The action required to remediate the vulnerability. (String)                                     |
| **due_date**           | The date by which the required action must be completed. (Date)                                  |
| **notes**              | Additional notes about the vulnerability. (String)                                               |
| **grp**                | The group associated with the vulnerability. (String)                                            |
| **pub_date**           | The date the vulnerability was published. (Date)                                                 |
| **cvss**               | The Common Vulnerability Scoring System score associated with the vulnerability. (Float)         |
| **cwe**                | The Common Weakness Enumeration associated with the vulnerability. (String)                      |
| **vector**             | The vector associated with the vulnerability. (String)                                           |
| **complexity**         | The complexity associated with the vulnerability. (String)                                       |
| **severity**           | The severity level associated with the vulnerability. (String)                                   |

_____

**File: 2022-06-09-enriched.csv**
| Column name            | Description                                                                                      |
|:-----------------------|:-------------------------------------------------------------------------------------------------|
| **vendor_project**     | The name of the vendor project associated with the vulnerability. (String)                       |
| **product**            | The name of the product associated with the vulnerability. (String)                              |
| **vulnerability_name** | The name of the vulnerability. (String)                                                          |
| **date_added**         | The date the vulnerability was added to the CISA Known Exploited Vulnerabilities catalog. (Date) |
| **short_description**  | A brief description of the vulnerability. (String)                                               |
| **required_action**    | The action required to remediate the vulnerability. (String)                                     |
| **due_date**           | The date by which the required action must be completed. (Date)                                  |
| **notes**              | Additional notes about the vulnerability. (String)                                               |
| **grp**                | The group associated with the vulnerability. (String)                                            |
| **pub_date**           | The date the vulnerability was published. (Date)                                                 |
| **cvss**               | The Common Vulnerability Scoring System score associated with the vulnerability. (Float)         |
| **cwe**                | The Common Weakness Enumeration associated with the vulnerability. (String)                      |
| **vector**             | The vector associated with the vulnerability. (String)                                           |
| **complexity**         | The complexity associated with the vulnerability. (String)                                       |
| **severity**           | The severity level associated with the vulnerability. (String)                                   |

_____

**File: 2022-06-27-enriched.csv**
| Column name            | Description                                                                                      |
|:-----------------------|:-------------------------------------------------------------------------------------------------|
| **vendor_project**     | The name of the vendor project associated with the vulnerability. (String)                       |
| **product**            | The name of the product associated with the vulnerability. (String)                              |
| **vulnerability_name** | The name of the vulnerability. (String)                                                          |
| **date_added**         | The date the vulnerability was added to the CISA Known Exploited Vulnerabilities catalog. (Date) |
| **short_description**  | A brief description of the vulnerability. (String)                                               |
| **required_action**    | The action required to remediate the vulnerability. (String)                                     |
| **due_date**           | The date by which the required action must be completed. (Date)                                  |
| **notes**              | Additional notes about the vulnerability. (String)                                               |
| **grp**                | The group associated with the vulnerability. (String)                                            |
| **pub_date**           | The date the vulnerability was published. (Date)                                                 |
| **cvss**               | The Common Vulnerability Scoring System score associated with the vulnerability. (Float)         |
| **cwe**                | The Common Weakness Enumeration associated with the vulnerability. (String)                      |
| **vector**             | The vector associated with the vulnerability. (String)                                           |
| **complexity**         | The complexity associated with the vulnerability. (String)                                       |
| **severity**           | The severity level associated with the vulnerability. (String)                                   |

_____

**File: 2022-07-04-enriched.csv**
| Column name            | Description                                                                                      |
|:-----------------------|:-------------------------------------------------------------------------------------------------|
| **vendor_project**     | The name of the vendor project associated with the vulnerability. (String)                       |
| **product**            | The name of the product associated with the vulnerability. (String)                              |
| **vulnerability_name** | The name of the vulnerability. (String)                                                          |
| **date_added**         | The date the vulnerability was added to the CISA Known Exploited Vulnerabilities catalog. (Date) |
| **short_description**  | A brief description of the vulnerability. (String)                                               |
| **required_action**    | The action required to remediate the vulnerability. (String)                                     |
| **due_date**           | The date by which the required action must be completed. (Date)                                  |
| **notes**              | Additional notes about the vulnerability. (String)                                               |
| **grp**                | The group associated with the vulnerability. (String)                                            |
| **pub_date**           | The date the vulnerability was published. (Date)                                                 |
| **cvss**               | The Common Vulnerability Scoring System score associated with the vulnerability. (Float)         |
| **cwe**                | The Common Weakness Enumeration associated with the vulnerability. (String)                      |
| **vector**             | The vector associated with the vulnerability. (String)                                           |
| **complexity**         | The complexity associated with the vulnerability. (String)                                       |
| **severity**           | The severity level associated with the vulnerability. (String)                                   |

_____

**File: 2022-12-09-enriched.csv**
| Column name            | Description                                                                                      |
|:-----------------------|:-------------------------------------------------------------------------------------------------|
| **vendor_project**     | The name of the vendor project associated with the vulnerability. (String)                       |
| **product**            | The name of the product associated with the vulnerability. (String)                              |
| **vulnerability_name** | The name of the vulnerability. (String)                                                          |
| **date_added**         | The date the vulnerability was added to the CISA Known Exploited Vulnerabilities catalog. (Date) |
| **short_description**  | A brief description of the vulnerability. (String)                                               |
| **required_action**    | The action required to remediate the vulnerability. (String)                                     |
| **due_date**           | The date by which the required action must be completed. (Date)                                  |
| **notes**              | Additional notes about the vulnerability. (String)                                               |
| **grp**                | The group associated with the vulnerability. (String)                                            |
| **pub_date**           | The date the vulnerability was published. (Date)                                                 |
| **cvss**               | The Common Vulnerability Scoring System score associated with the vulnerability. (Float)         |
| **cwe**                | The Common Weakness Enumeration associated with the vulnerability. (String)                      |
| **vector**             | The vector associated with the vulnerability. (String)                                           |
| **complexity**         | The complexity associated with the vulnerability. (String)                                       |
| **severity**           | The severity level associated with the vulnerability. (String)                                   |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [](https://github.com/hrbrmstr/cisa-known-exploited-vulns).

",.csv,True
Cybersecurity Risk (2022 CISA Vulnerability),5,exploring-cybersecurity-risk-via-2022-cisa-vulne,2022-12-09-enriched.csv,CC0-1.0,"_____
# Cybersecurity Risk (2022 CISA Vulnerability)
### Severity, CVSS Score, and National Security Vulnerability Types
By  [[source]](https://github.com/hrbrmstr/cisa-known-exploited-vulns)
_____

### About this dataset
&gt; This dataset presents an in-depth exploration of the security vulnerabilities across the United States from the CISA Known Exploited Vulnerabilities catalog for 2022. You'll find a number of vulnerability types and severity levels, as well as CVSS scores, vendor projects, product names, and other pertinent information. By arming yourself with this knowledge, you can better protect your network from any potential security issues that may arise - now or in the future. Dive into details such as attack vectors, complexity ratings and required actions for each vulnerability to stay prepared and protected throughout your journey! Every single detail matters when it comes to keeping yourself secure online - so explore some of these potential risks and gain valuable insights today!

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; This dataset provides a comprehensive list of security vulnerabilities in the United States from the CISA Known Exploited Vulnerabilities catalog for the year 2022, including vulnerability types, severity levels, CVSS scores, vendor projects, product names, and other relevant information. This is an important tool for organizations to better understand and manage their cybersecurity risk. 
&gt; 

&gt;  

&gt; 
&gt;  * `vendor_project`: The name of the vendor project associated with the vulnerability. 
&gt;  * `product`: The name of the product associated with the vulnerability. 
&gt;  * `vulnerability_name`: The name of the vulnerability that affects a particular product or system.  
&gt;  * `date_added`: The date on which a particular vulnerability was added to CISA’s Known Exploited Vulnerabilities catalog.  
&gt;  * `short_description`: A brief description of what makes that specific vulnerability dangerous/risky in nature.  
&gt;  * `required_action`: A clear outline or instruction as to how an organization should address/mitigate that particular vulnerability within its own network/infrastructure setup.   
&gt; *	`due_date`, :The date by which required action should be completed at minimum if any mitigation measures are taken against those weaknesses discovered from this analysis report .  			      
&gt; 
&gt;  * `notes`, A brief text field related additional insights about potential further risks and concerns related each discovered vulnerabilities         
&gt; 
&gt;  * CVSS Score and Severity assessments : CISA calculates these two indicators (Common Vulnerability Scoring System (CVSS) score & Severity) based on certain parameters by giving weighted marks in order understand it visibility regarding type & magnitude (likely impact level visllyl clearly indicating red amber gn & green status } as per internal computation). Ratings typically range from 0 - 10 indicating descn'ding order i e; 0 being Very Low' 10 - Extremely High severity or criticality        
&gt; 
&gt;  **æroup** :The group associated with that particular public exploit currently listed on US-CERT platform usually used Jigsaw puzzles piece fitting concepts to help narrowing down investigation efforts     involved directly contributed exploitsor sponsored research taking risk into account while handling each new findings ​​ ​      
&gt; 


### Research Ideas
&gt; - Analyzing the severity of different security vulnerabilities over time in order to measure effectiveness of cybersecurity efforts.
&gt; - Building a data visualization tool to showcase the different types, CVSS scores, vendor projects and products names associated with security vulnerabilities over time in the US.  
&gt; - Developing predictive analytics that can anticipate future trends and changes in security vulnerabilities to better inform CISA decisions

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://github.com/hrbrmstr/cisa-known-exploited-vulns)
&gt;  

### License 
&gt; 
&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: 2022-06-08-enriched.csv**
| Column name            | Description                                                                                      |
|:-----------------------|:-------------------------------------------------------------------------------------------------|
| **vendor_project**     | The name of the vendor project associated with the vulnerability. (String)                       |
| **product**            | The name of the product associated with the vulnerability. (String)                              |
| **vulnerability_name** | The name of the vulnerability. (String)                                                          |
| **date_added**         | The date the vulnerability was added to the CISA Known Exploited Vulnerabilities catalog. (Date) |
| **short_description**  | A brief description of the vulnerability. (String)                                               |
| **required_action**    | The action required to remediate the vulnerability. (String)                                     |
| **due_date**           | The date by which the required action must be completed. (Date)                                  |
| **notes**              | Additional notes about the vulnerability. (String)                                               |
| **grp**                | The group associated with the vulnerability. (String)                                            |
| **pub_date**           | The date the vulnerability was published. (Date)                                                 |
| **cvss**               | The Common Vulnerability Scoring System score associated with the vulnerability. (Float)         |
| **cwe**                | The Common Weakness Enumeration associated with the vulnerability. (String)                      |
| **vector**             | The vector associated with the vulnerability. (String)                                           |
| **complexity**         | The complexity associated with the vulnerability. (String)                                       |
| **severity**           | The severity level associated with the vulnerability. (String)                                   |

_____

**File: 2022-06-09-enriched.csv**
| Column name            | Description                                                                                      |
|:-----------------------|:-------------------------------------------------------------------------------------------------|
| **vendor_project**     | The name of the vendor project associated with the vulnerability. (String)                       |
| **product**            | The name of the product associated with the vulnerability. (String)                              |
| **vulnerability_name** | The name of the vulnerability. (String)                                                          |
| **date_added**         | The date the vulnerability was added to the CISA Known Exploited Vulnerabilities catalog. (Date) |
| **short_description**  | A brief description of the vulnerability. (String)                                               |
| **required_action**    | The action required to remediate the vulnerability. (String)                                     |
| **due_date**           | The date by which the required action must be completed. (Date)                                  |
| **notes**              | Additional notes about the vulnerability. (String)                                               |
| **grp**                | The group associated with the vulnerability. (String)                                            |
| **pub_date**           | The date the vulnerability was published. (Date)                                                 |
| **cvss**               | The Common Vulnerability Scoring System score associated with the vulnerability. (Float)         |
| **cwe**                | The Common Weakness Enumeration associated with the vulnerability. (String)                      |
| **vector**             | The vector associated with the vulnerability. (String)                                           |
| **complexity**         | The complexity associated with the vulnerability. (String)                                       |
| **severity**           | The severity level associated with the vulnerability. (String)                                   |

_____

**File: 2022-06-27-enriched.csv**
| Column name            | Description                                                                                      |
|:-----------------------|:-------------------------------------------------------------------------------------------------|
| **vendor_project**     | The name of the vendor project associated with the vulnerability. (String)                       |
| **product**            | The name of the product associated with the vulnerability. (String)                              |
| **vulnerability_name** | The name of the vulnerability. (String)                                                          |
| **date_added**         | The date the vulnerability was added to the CISA Known Exploited Vulnerabilities catalog. (Date) |
| **short_description**  | A brief description of the vulnerability. (String)                                               |
| **required_action**    | The action required to remediate the vulnerability. (String)                                     |
| **due_date**           | The date by which the required action must be completed. (Date)                                  |
| **notes**              | Additional notes about the vulnerability. (String)                                               |
| **grp**                | The group associated with the vulnerability. (String)                                            |
| **pub_date**           | The date the vulnerability was published. (Date)                                                 |
| **cvss**               | The Common Vulnerability Scoring System score associated with the vulnerability. (Float)         |
| **cwe**                | The Common Weakness Enumeration associated with the vulnerability. (String)                      |
| **vector**             | The vector associated with the vulnerability. (String)                                           |
| **complexity**         | The complexity associated with the vulnerability. (String)                                       |
| **severity**           | The severity level associated with the vulnerability. (String)                                   |

_____

**File: 2022-07-04-enriched.csv**
| Column name            | Description                                                                                      |
|:-----------------------|:-------------------------------------------------------------------------------------------------|
| **vendor_project**     | The name of the vendor project associated with the vulnerability. (String)                       |
| **product**            | The name of the product associated with the vulnerability. (String)                              |
| **vulnerability_name** | The name of the vulnerability. (String)                                                          |
| **date_added**         | The date the vulnerability was added to the CISA Known Exploited Vulnerabilities catalog. (Date) |
| **short_description**  | A brief description of the vulnerability. (String)                                               |
| **required_action**    | The action required to remediate the vulnerability. (String)                                     |
| **due_date**           | The date by which the required action must be completed. (Date)                                  |
| **notes**              | Additional notes about the vulnerability. (String)                                               |
| **grp**                | The group associated with the vulnerability. (String)                                            |
| **pub_date**           | The date the vulnerability was published. (Date)                                                 |
| **cvss**               | The Common Vulnerability Scoring System score associated with the vulnerability. (Float)         |
| **cwe**                | The Common Weakness Enumeration associated with the vulnerability. (String)                      |
| **vector**             | The vector associated with the vulnerability. (String)                                           |
| **complexity**         | The complexity associated with the vulnerability. (String)                                       |
| **severity**           | The severity level associated with the vulnerability. (String)                                   |

_____

**File: 2022-12-09-enriched.csv**
| Column name            | Description                                                                                      |
|:-----------------------|:-------------------------------------------------------------------------------------------------|
| **vendor_project**     | The name of the vendor project associated with the vulnerability. (String)                       |
| **product**            | The name of the product associated with the vulnerability. (String)                              |
| **vulnerability_name** | The name of the vulnerability. (String)                                                          |
| **date_added**         | The date the vulnerability was added to the CISA Known Exploited Vulnerabilities catalog. (Date) |
| **short_description**  | A brief description of the vulnerability. (String)                                               |
| **required_action**    | The action required to remediate the vulnerability. (String)                                     |
| **due_date**           | The date by which the required action must be completed. (Date)                                  |
| **notes**              | Additional notes about the vulnerability. (String)                                               |
| **grp**                | The group associated with the vulnerability. (String)                                            |
| **pub_date**           | The date the vulnerability was published. (Date)                                                 |
| **cvss**               | The Common Vulnerability Scoring System score associated with the vulnerability. (Float)         |
| **cwe**                | The Common Weakness Enumeration associated with the vulnerability. (String)                      |
| **vector**             | The vector associated with the vulnerability. (String)                                           |
| **complexity**         | The complexity associated with the vulnerability. (String)                                       |
| **severity**           | The severity level associated with the vulnerability. (String)                                   |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [](https://github.com/hrbrmstr/cisa-known-exploited-vulns).

",.csv,True
DJIA 30 Stock Time Series,33,stock-time-series-20050101-to-20171231,JPM_2006-01-01_to_2018-01-01.csv,CC0-1.0,"### Context

The script used to acquire all of the following data can be found [in this GitHub repository][1]. This repository also contains the modeling codes and will be updated continually, so welcome starring or watching!

Stock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).

          ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',

          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',

          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']

In the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.


### Content

The data is presented in a couple of formats to suit different individual's needs or computational limitations. 
I have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and
a smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.

The folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. 
The all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. 
Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.

All the files have the following columns:
Date - in format: yy-mm-dd 

Open - price of the stock at market open (this is NYSE data so all in USD)

High - Highest price reached in the day

Low	Close - Lowest price reached in the day

Volume - Number of shares traded

Name - the stock's ticker name

### Inspiration

This dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.
From these data informative stock stats such as volatility and moving averages can be easily calculated.
The million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!

### Acknowledgement 

This Data description is adapted from the dataset named 'S&amp;P 500 Stock data'.
This data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.

  [1]: https://github.com/szrlee/Stock-Time-Series-Analysis/blob/master/data_collection.ipynb",.csv,True
DJIA 30 Stock Time Series,33,stock-time-series-20050101-to-20171231,MSFT_2006-01-01_to_2018-01-01.csv,CC0-1.0,"### Context

The script used to acquire all of the following data can be found [in this GitHub repository][1]. This repository also contains the modeling codes and will be updated continually, so welcome starring or watching!

Stock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).

          ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',

          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',

          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']

In the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.


### Content

The data is presented in a couple of formats to suit different individual's needs or computational limitations. 
I have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and
a smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.

The folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. 
The all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. 
Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.

All the files have the following columns:
Date - in format: yy-mm-dd 

Open - price of the stock at market open (this is NYSE data so all in USD)

High - Highest price reached in the day

Low	Close - Lowest price reached in the day

Volume - Number of shares traded

Name - the stock's ticker name

### Inspiration

This dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.
From these data informative stock stats such as volatility and moving averages can be easily calculated.
The million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!

### Acknowledgement 

This Data description is adapted from the dataset named 'S&amp;P 500 Stock data'.
This data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.

  [1]: https://github.com/szrlee/Stock-Time-Series-Analysis/blob/master/data_collection.ipynb",.csv,True
DJIA 30 Stock Time Series,33,stock-time-series-20050101-to-20171231,JNJ_2006-01-01_to_2018-01-01.csv,CC0-1.0,"### Context

The script used to acquire all of the following data can be found [in this GitHub repository][1]. This repository also contains the modeling codes and will be updated continually, so welcome starring or watching!

Stock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).

          ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',

          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',

          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']

In the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.


### Content

The data is presented in a couple of formats to suit different individual's needs or computational limitations. 
I have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and
a smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.

The folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. 
The all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. 
Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.

All the files have the following columns:
Date - in format: yy-mm-dd 

Open - price of the stock at market open (this is NYSE data so all in USD)

High - Highest price reached in the day

Low	Close - Lowest price reached in the day

Volume - Number of shares traded

Name - the stock's ticker name

### Inspiration

This dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.
From these data informative stock stats such as volatility and moving averages can be easily calculated.
The million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!

### Acknowledgement 

This Data description is adapted from the dataset named 'S&amp;P 500 Stock data'.
This data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.

  [1]: https://github.com/szrlee/Stock-Time-Series-Analysis/blob/master/data_collection.ipynb",.csv,True
DJIA 30 Stock Time Series,33,stock-time-series-20050101-to-20171231,UNH_2006-01-01_to_2018-01-01.csv,CC0-1.0,"### Context

The script used to acquire all of the following data can be found [in this GitHub repository][1]. This repository also contains the modeling codes and will be updated continually, so welcome starring or watching!

Stock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).

          ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',

          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',

          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']

In the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.


### Content

The data is presented in a couple of formats to suit different individual's needs or computational limitations. 
I have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and
a smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.

The folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. 
The all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. 
Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.

All the files have the following columns:
Date - in format: yy-mm-dd 

Open - price of the stock at market open (this is NYSE data so all in USD)

High - Highest price reached in the day

Low	Close - Lowest price reached in the day

Volume - Number of shares traded

Name - the stock's ticker name

### Inspiration

This dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.
From these data informative stock stats such as volatility and moving averages can be easily calculated.
The million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!

### Acknowledgement 

This Data description is adapted from the dataset named 'S&amp;P 500 Stock data'.
This data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.

  [1]: https://github.com/szrlee/Stock-Time-Series-Analysis/blob/master/data_collection.ipynb",.csv,True
DJIA 30 Stock Time Series,33,stock-time-series-20050101-to-20171231,CAT_2006-01-01_to_2018-01-01.csv,CC0-1.0,"### Context

The script used to acquire all of the following data can be found [in this GitHub repository][1]. This repository also contains the modeling codes and will be updated continually, so welcome starring or watching!

Stock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).

          ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',

          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',

          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']

In the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.


### Content

The data is presented in a couple of formats to suit different individual's needs or computational limitations. 
I have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and
a smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.

The folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. 
The all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. 
Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.

All the files have the following columns:
Date - in format: yy-mm-dd 

Open - price of the stock at market open (this is NYSE data so all in USD)

High - Highest price reached in the day

Low	Close - Lowest price reached in the day

Volume - Number of shares traded

Name - the stock's ticker name

### Inspiration

This dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.
From these data informative stock stats such as volatility and moving averages can be easily calculated.
The million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!

### Acknowledgement 

This Data description is adapted from the dataset named 'S&amp;P 500 Stock data'.
This data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.

  [1]: https://github.com/szrlee/Stock-Time-Series-Analysis/blob/master/data_collection.ipynb",.csv,True
DJIA 30 Stock Time Series,33,stock-time-series-20050101-to-20171231,AABA_2006-01-01_to_2018-01-01.csv,CC0-1.0,"### Context

The script used to acquire all of the following data can be found [in this GitHub repository][1]. This repository also contains the modeling codes and will be updated continually, so welcome starring or watching!

Stock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).

          ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',

          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',

          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']

In the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.


### Content

The data is presented in a couple of formats to suit different individual's needs or computational limitations. 
I have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and
a smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.

The folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. 
The all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. 
Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.

All the files have the following columns:
Date - in format: yy-mm-dd 

Open - price of the stock at market open (this is NYSE data so all in USD)

High - Highest price reached in the day

Low	Close - Lowest price reached in the day

Volume - Number of shares traded

Name - the stock's ticker name

### Inspiration

This dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.
From these data informative stock stats such as volatility and moving averages can be easily calculated.
The million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!

### Acknowledgement 

This Data description is adapted from the dataset named 'S&amp;P 500 Stock data'.
This data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.

  [1]: https://github.com/szrlee/Stock-Time-Series-Analysis/blob/master/data_collection.ipynb",.csv,True
DJIA 30 Stock Time Series,33,stock-time-series-20050101-to-20171231,HD_2006-01-01_to_2018-01-01.csv,CC0-1.0,"### Context

The script used to acquire all of the following data can be found [in this GitHub repository][1]. This repository also contains the modeling codes and will be updated continually, so welcome starring or watching!

Stock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).

          ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',

          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',

          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']

In the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.


### Content

The data is presented in a couple of formats to suit different individual's needs or computational limitations. 
I have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and
a smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.

The folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. 
The all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. 
Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.

All the files have the following columns:
Date - in format: yy-mm-dd 

Open - price of the stock at market open (this is NYSE data so all in USD)

High - Highest price reached in the day

Low	Close - Lowest price reached in the day

Volume - Number of shares traded

Name - the stock's ticker name

### Inspiration

This dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.
From these data informative stock stats such as volatility and moving averages can be easily calculated.
The million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!

### Acknowledgement 

This Data description is adapted from the dataset named 'S&amp;P 500 Stock data'.
This data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.

  [1]: https://github.com/szrlee/Stock-Time-Series-Analysis/blob/master/data_collection.ipynb",.csv,True
DJIA 30 Stock Time Series,33,stock-time-series-20050101-to-20171231,CVX_2006-01-01_to_2018-01-01.csv,CC0-1.0,"### Context

The script used to acquire all of the following data can be found [in this GitHub repository][1]. This repository also contains the modeling codes and will be updated continually, so welcome starring or watching!

Stock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).

          ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',

          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',

          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']

In the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.


### Content

The data is presented in a couple of formats to suit different individual's needs or computational limitations. 
I have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and
a smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.

The folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. 
The all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. 
Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.

All the files have the following columns:
Date - in format: yy-mm-dd 

Open - price of the stock at market open (this is NYSE data so all in USD)

High - Highest price reached in the day

Low	Close - Lowest price reached in the day

Volume - Number of shares traded

Name - the stock's ticker name

### Inspiration

This dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.
From these data informative stock stats such as volatility and moving averages can be easily calculated.
The million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!

### Acknowledgement 

This Data description is adapted from the dataset named 'S&amp;P 500 Stock data'.
This data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.

  [1]: https://github.com/szrlee/Stock-Time-Series-Analysis/blob/master/data_collection.ipynb",.csv,True
DJIA 30 Stock Time Series,33,stock-time-series-20050101-to-20171231,MMM_2006-01-01_to_2018-01-01.csv,CC0-1.0,"### Context

The script used to acquire all of the following data can be found [in this GitHub repository][1]. This repository also contains the modeling codes and will be updated continually, so welcome starring or watching!

Stock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).

          ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',

          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',

          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']

In the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.


### Content

The data is presented in a couple of formats to suit different individual's needs or computational limitations. 
I have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and
a smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.

The folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. 
The all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. 
Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.

All the files have the following columns:
Date - in format: yy-mm-dd 

Open - price of the stock at market open (this is NYSE data so all in USD)

High - Highest price reached in the day

Low	Close - Lowest price reached in the day

Volume - Number of shares traded

Name - the stock's ticker name

### Inspiration

This dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.
From these data informative stock stats such as volatility and moving averages can be easily calculated.
The million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!

### Acknowledgement 

This Data description is adapted from the dataset named 'S&amp;P 500 Stock data'.
This data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.

  [1]: https://github.com/szrlee/Stock-Time-Series-Analysis/blob/master/data_collection.ipynb",.csv,True
DJIA 30 Stock Time Series,33,stock-time-series-20050101-to-20171231,AMZN_2006-01-01_to_2018-01-01.csv,CC0-1.0,"### Context

The script used to acquire all of the following data can be found [in this GitHub repository][1]. This repository also contains the modeling codes and will be updated continually, so welcome starring or watching!

Stock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).

          ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',

          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',

          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']

In the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.


### Content

The data is presented in a couple of formats to suit different individual's needs or computational limitations. 
I have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and
a smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.

The folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. 
The all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. 
Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.

All the files have the following columns:
Date - in format: yy-mm-dd 

Open - price of the stock at market open (this is NYSE data so all in USD)

High - Highest price reached in the day

Low	Close - Lowest price reached in the day

Volume - Number of shares traded

Name - the stock's ticker name

### Inspiration

This dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.
From these data informative stock stats such as volatility and moving averages can be easily calculated.
The million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!

### Acknowledgement 

This Data description is adapted from the dataset named 'S&amp;P 500 Stock data'.
This data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.

  [1]: https://github.com/szrlee/Stock-Time-Series-Analysis/blob/master/data_collection.ipynb",.csv,True
DJIA 30 Stock Time Series,33,stock-time-series-20050101-to-20171231,CSCO_2006-01-01_to_2018-01-01.csv,CC0-1.0,"### Context

The script used to acquire all of the following data can be found [in this GitHub repository][1]. This repository also contains the modeling codes and will be updated continually, so welcome starring or watching!

Stock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).

          ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',

          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',

          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']

In the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.


### Content

The data is presented in a couple of formats to suit different individual's needs or computational limitations. 
I have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and
a smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.

The folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. 
The all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. 
Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.

All the files have the following columns:
Date - in format: yy-mm-dd 

Open - price of the stock at market open (this is NYSE data so all in USD)

High - Highest price reached in the day

Low	Close - Lowest price reached in the day

Volume - Number of shares traded

Name - the stock's ticker name

### Inspiration

This dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.
From these data informative stock stats such as volatility and moving averages can be easily calculated.
The million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!

### Acknowledgement 

This Data description is adapted from the dataset named 'S&amp;P 500 Stock data'.
This data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.

  [1]: https://github.com/szrlee/Stock-Time-Series-Analysis/blob/master/data_collection.ipynb",.csv,True
DJIA 30 Stock Time Series,33,stock-time-series-20050101-to-20171231,XOM_2006-01-01_to_2018-01-01.csv,CC0-1.0,"### Context

The script used to acquire all of the following data can be found [in this GitHub repository][1]. This repository also contains the modeling codes and will be updated continually, so welcome starring or watching!

Stock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).

          ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',

          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',

          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']

In the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.


### Content

The data is presented in a couple of formats to suit different individual's needs or computational limitations. 
I have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and
a smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.

The folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. 
The all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. 
Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.

All the files have the following columns:
Date - in format: yy-mm-dd 

Open - price of the stock at market open (this is NYSE data so all in USD)

High - Highest price reached in the day

Low	Close - Lowest price reached in the day

Volume - Number of shares traded

Name - the stock's ticker name

### Inspiration

This dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.
From these data informative stock stats such as volatility and moving averages can be easily calculated.
The million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!

### Acknowledgement 

This Data description is adapted from the dataset named 'S&amp;P 500 Stock data'.
This data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.

  [1]: https://github.com/szrlee/Stock-Time-Series-Analysis/blob/master/data_collection.ipynb",.csv,True
DJIA 30 Stock Time Series,33,stock-time-series-20050101-to-20171231,all_stocks_2017-01-01_to_2018-01-01.csv,CC0-1.0,"### Context

The script used to acquire all of the following data can be found [in this GitHub repository][1]. This repository also contains the modeling codes and will be updated continually, so welcome starring or watching!

Stock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).

          ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',

          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',

          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']

In the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.


### Content

The data is presented in a couple of formats to suit different individual's needs or computational limitations. 
I have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and
a smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.

The folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. 
The all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. 
Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.

All the files have the following columns:
Date - in format: yy-mm-dd 

Open - price of the stock at market open (this is NYSE data so all in USD)

High - Highest price reached in the day

Low	Close - Lowest price reached in the day

Volume - Number of shares traded

Name - the stock's ticker name

### Inspiration

This dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.
From these data informative stock stats such as volatility and moving averages can be easily calculated.
The million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!

### Acknowledgement 

This Data description is adapted from the dataset named 'S&amp;P 500 Stock data'.
This data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.

  [1]: https://github.com/szrlee/Stock-Time-Series-Analysis/blob/master/data_collection.ipynb",.csv,True
DJIA 30 Stock Time Series,33,stock-time-series-20050101-to-20171231,VZ_2006-01-01_to_2018-01-01.csv,CC0-1.0,"### Context

The script used to acquire all of the following data can be found [in this GitHub repository][1]. This repository also contains the modeling codes and will be updated continually, so welcome starring or watching!

Stock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).

          ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',

          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',

          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']

In the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.


### Content

The data is presented in a couple of formats to suit different individual's needs or computational limitations. 
I have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and
a smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.

The folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. 
The all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. 
Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.

All the files have the following columns:
Date - in format: yy-mm-dd 

Open - price of the stock at market open (this is NYSE data so all in USD)

High - Highest price reached in the day

Low	Close - Lowest price reached in the day

Volume - Number of shares traded

Name - the stock's ticker name

### Inspiration

This dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.
From these data informative stock stats such as volatility and moving averages can be easily calculated.
The million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!

### Acknowledgement 

This Data description is adapted from the dataset named 'S&amp;P 500 Stock data'.
This data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.

  [1]: https://github.com/szrlee/Stock-Time-Series-Analysis/blob/master/data_collection.ipynb",.csv,True
DJIA 30 Stock Time Series,33,stock-time-series-20050101-to-20171231,WMT_2006-01-01_to_2018-01-01.csv,CC0-1.0,"### Context

The script used to acquire all of the following data can be found [in this GitHub repository][1]. This repository also contains the modeling codes and will be updated continually, so welcome starring or watching!

Stock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).

          ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',

          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',

          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']

In the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.


### Content

The data is presented in a couple of formats to suit different individual's needs or computational limitations. 
I have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and
a smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.

The folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. 
The all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. 
Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.

All the files have the following columns:
Date - in format: yy-mm-dd 

Open - price of the stock at market open (this is NYSE data so all in USD)

High - Highest price reached in the day

Low	Close - Lowest price reached in the day

Volume - Number of shares traded

Name - the stock's ticker name

### Inspiration

This dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.
From these data informative stock stats such as volatility and moving averages can be easily calculated.
The million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!

### Acknowledgement 

This Data description is adapted from the dataset named 'S&amp;P 500 Stock data'.
This data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.

  [1]: https://github.com/szrlee/Stock-Time-Series-Analysis/blob/master/data_collection.ipynb",.csv,True
DJIA 30 Stock Time Series,33,stock-time-series-20050101-to-20171231,GS_2006-01-01_to_2018-01-01.csv,CC0-1.0,"### Context

The script used to acquire all of the following data can be found [in this GitHub repository][1]. This repository also contains the modeling codes and will be updated continually, so welcome starring or watching!

Stock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).

          ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',

          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',

          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']

In the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.


### Content

The data is presented in a couple of formats to suit different individual's needs or computational limitations. 
I have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and
a smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.

The folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. 
The all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. 
Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.

All the files have the following columns:
Date - in format: yy-mm-dd 

Open - price of the stock at market open (this is NYSE data so all in USD)

High - Highest price reached in the day

Low	Close - Lowest price reached in the day

Volume - Number of shares traded

Name - the stock's ticker name

### Inspiration

This dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.
From these data informative stock stats such as volatility and moving averages can be easily calculated.
The million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!

### Acknowledgement 

This Data description is adapted from the dataset named 'S&amp;P 500 Stock data'.
This data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.

  [1]: https://github.com/szrlee/Stock-Time-Series-Analysis/blob/master/data_collection.ipynb",.csv,True
DJIA 30 Stock Time Series,33,stock-time-series-20050101-to-20171231,AAPL_2006-01-01_to_2018-01-01.csv,CC0-1.0,"### Context

The script used to acquire all of the following data can be found [in this GitHub repository][1]. This repository also contains the modeling codes and will be updated continually, so welcome starring or watching!

Stock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).

          ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',

          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',

          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']

In the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.


### Content

The data is presented in a couple of formats to suit different individual's needs or computational limitations. 
I have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and
a smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.

The folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. 
The all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. 
Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.

All the files have the following columns:
Date - in format: yy-mm-dd 

Open - price of the stock at market open (this is NYSE data so all in USD)

High - Highest price reached in the day

Low	Close - Lowest price reached in the day

Volume - Number of shares traded

Name - the stock's ticker name

### Inspiration

This dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.
From these data informative stock stats such as volatility and moving averages can be easily calculated.
The million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!

### Acknowledgement 

This Data description is adapted from the dataset named 'S&amp;P 500 Stock data'.
This data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.

  [1]: https://github.com/szrlee/Stock-Time-Series-Analysis/blob/master/data_collection.ipynb",.csv,True
DJIA 30 Stock Time Series,33,stock-time-series-20050101-to-20171231,AXP_2006-01-01_to_2018-01-01.csv,CC0-1.0,"### Context

The script used to acquire all of the following data can be found [in this GitHub repository][1]. This repository also contains the modeling codes and will be updated continually, so welcome starring or watching!

Stock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).

          ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',

          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',

          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']

In the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.


### Content

The data is presented in a couple of formats to suit different individual's needs or computational limitations. 
I have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and
a smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.

The folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. 
The all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. 
Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.

All the files have the following columns:
Date - in format: yy-mm-dd 

Open - price of the stock at market open (this is NYSE data so all in USD)

High - Highest price reached in the day

Low	Close - Lowest price reached in the day

Volume - Number of shares traded

Name - the stock's ticker name

### Inspiration

This dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.
From these data informative stock stats such as volatility and moving averages can be easily calculated.
The million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!

### Acknowledgement 

This Data description is adapted from the dataset named 'S&amp;P 500 Stock data'.
This data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.

  [1]: https://github.com/szrlee/Stock-Time-Series-Analysis/blob/master/data_collection.ipynb",.csv,True
DJIA 30 Stock Time Series,33,stock-time-series-20050101-to-20171231,all_stocks_2006-01-01_to_2018-01-01.csv,CC0-1.0,"### Context

The script used to acquire all of the following data can be found [in this GitHub repository][1]. This repository also contains the modeling codes and will be updated continually, so welcome starring or watching!

Stock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).

          ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',

          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',

          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']

In the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.


### Content

The data is presented in a couple of formats to suit different individual's needs or computational limitations. 
I have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and
a smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.

The folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. 
The all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. 
Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.

All the files have the following columns:
Date - in format: yy-mm-dd 

Open - price of the stock at market open (this is NYSE data so all in USD)

High - Highest price reached in the day

Low	Close - Lowest price reached in the day

Volume - Number of shares traded

Name - the stock's ticker name

### Inspiration

This dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.
From these data informative stock stats such as volatility and moving averages can be easily calculated.
The million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!

### Acknowledgement 

This Data description is adapted from the dataset named 'S&amp;P 500 Stock data'.
This data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.

  [1]: https://github.com/szrlee/Stock-Time-Series-Analysis/blob/master/data_collection.ipynb",.csv,True
DJIA 30 Stock Time Series,33,stock-time-series-20050101-to-20171231,GOOGL_2006-01-01_to_2018-01-01.csv,CC0-1.0,"### Context

The script used to acquire all of the following data can be found [in this GitHub repository][1]. This repository also contains the modeling codes and will be updated continually, so welcome starring or watching!

Stock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).

          ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',

          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',

          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']

In the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.


### Content

The data is presented in a couple of formats to suit different individual's needs or computational limitations. 
I have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and
a smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.

The folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. 
The all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. 
Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.

All the files have the following columns:
Date - in format: yy-mm-dd 

Open - price of the stock at market open (this is NYSE data so all in USD)

High - Highest price reached in the day

Low	Close - Lowest price reached in the day

Volume - Number of shares traded

Name - the stock's ticker name

### Inspiration

This dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.
From these data informative stock stats such as volatility and moving averages can be easily calculated.
The million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!

### Acknowledgement 

This Data description is adapted from the dataset named 'S&amp;P 500 Stock data'.
This data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.

  [1]: https://github.com/szrlee/Stock-Time-Series-Analysis/blob/master/data_collection.ipynb",.csv,True
DJIA 30 Stock Time Series,33,stock-time-series-20050101-to-20171231,UTX_2006-01-01_to_2018-01-01.csv,CC0-1.0,"### Context

The script used to acquire all of the following data can be found [in this GitHub repository][1]. This repository also contains the modeling codes and will be updated continually, so welcome starring or watching!

Stock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).

          ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',

          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',

          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']

In the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.


### Content

The data is presented in a couple of formats to suit different individual's needs or computational limitations. 
I have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and
a smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.

The folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. 
The all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. 
Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.

All the files have the following columns:
Date - in format: yy-mm-dd 

Open - price of the stock at market open (this is NYSE data so all in USD)

High - Highest price reached in the day

Low	Close - Lowest price reached in the day

Volume - Number of shares traded

Name - the stock's ticker name

### Inspiration

This dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.
From these data informative stock stats such as volatility and moving averages can be easily calculated.
The million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!

### Acknowledgement 

This Data description is adapted from the dataset named 'S&amp;P 500 Stock data'.
This data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.

  [1]: https://github.com/szrlee/Stock-Time-Series-Analysis/blob/master/data_collection.ipynb",.csv,True
DJIA 30 Stock Time Series,33,stock-time-series-20050101-to-20171231,KO_2006-01-01_to_2018-01-01.csv,CC0-1.0,"### Context

The script used to acquire all of the following data can be found [in this GitHub repository][1]. This repository also contains the modeling codes and will be updated continually, so welcome starring or watching!

Stock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).

          ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',

          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',

          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']

In the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.


### Content

The data is presented in a couple of formats to suit different individual's needs or computational limitations. 
I have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and
a smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.

The folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. 
The all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. 
Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.

All the files have the following columns:
Date - in format: yy-mm-dd 

Open - price of the stock at market open (this is NYSE data so all in USD)

High - Highest price reached in the day

Low	Close - Lowest price reached in the day

Volume - Number of shares traded

Name - the stock's ticker name

### Inspiration

This dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.
From these data informative stock stats such as volatility and moving averages can be easily calculated.
The million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!

### Acknowledgement 

This Data description is adapted from the dataset named 'S&amp;P 500 Stock data'.
This data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.

  [1]: https://github.com/szrlee/Stock-Time-Series-Analysis/blob/master/data_collection.ipynb",.csv,True
DJIA 30 Stock Time Series,33,stock-time-series-20050101-to-20171231,MRK_2006-01-01_to_2018-01-01.csv,CC0-1.0,"### Context

The script used to acquire all of the following data can be found [in this GitHub repository][1]. This repository also contains the modeling codes and will be updated continually, so welcome starring or watching!

Stock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).

          ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',

          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',

          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']

In the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.


### Content

The data is presented in a couple of formats to suit different individual's needs or computational limitations. 
I have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and
a smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.

The folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. 
The all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. 
Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.

All the files have the following columns:
Date - in format: yy-mm-dd 

Open - price of the stock at market open (this is NYSE data so all in USD)

High - Highest price reached in the day

Low	Close - Lowest price reached in the day

Volume - Number of shares traded

Name - the stock's ticker name

### Inspiration

This dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.
From these data informative stock stats such as volatility and moving averages can be easily calculated.
The million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!

### Acknowledgement 

This Data description is adapted from the dataset named 'S&amp;P 500 Stock data'.
This data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.

  [1]: https://github.com/szrlee/Stock-Time-Series-Analysis/blob/master/data_collection.ipynb",.csv,True
DJIA 30 Stock Time Series,33,stock-time-series-20050101-to-20171231,TRV_2006-01-01_to_2018-01-01.csv,CC0-1.0,"### Context

The script used to acquire all of the following data can be found [in this GitHub repository][1]. This repository also contains the modeling codes and will be updated continually, so welcome starring or watching!

Stock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).

          ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',

          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',

          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']

In the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.


### Content

The data is presented in a couple of formats to suit different individual's needs or computational limitations. 
I have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and
a smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.

The folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. 
The all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. 
Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.

All the files have the following columns:
Date - in format: yy-mm-dd 

Open - price of the stock at market open (this is NYSE data so all in USD)

High - Highest price reached in the day

Low	Close - Lowest price reached in the day

Volume - Number of shares traded

Name - the stock's ticker name

### Inspiration

This dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.
From these data informative stock stats such as volatility and moving averages can be easily calculated.
The million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!

### Acknowledgement 

This Data description is adapted from the dataset named 'S&amp;P 500 Stock data'.
This data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.

  [1]: https://github.com/szrlee/Stock-Time-Series-Analysis/blob/master/data_collection.ipynb",.csv,True
DJIA 30 Stock Time Series,33,stock-time-series-20050101-to-20171231,IBM_2006-01-01_to_2018-01-01.csv,CC0-1.0,"### Context

The script used to acquire all of the following data can be found [in this GitHub repository][1]. This repository also contains the modeling codes and will be updated continually, so welcome starring or watching!

Stock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).

          ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',

          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',

          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']

In the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.


### Content

The data is presented in a couple of formats to suit different individual's needs or computational limitations. 
I have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and
a smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.

The folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. 
The all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. 
Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.

All the files have the following columns:
Date - in format: yy-mm-dd 

Open - price of the stock at market open (this is NYSE data so all in USD)

High - Highest price reached in the day

Low	Close - Lowest price reached in the day

Volume - Number of shares traded

Name - the stock's ticker name

### Inspiration

This dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.
From these data informative stock stats such as volatility and moving averages can be easily calculated.
The million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!

### Acknowledgement 

This Data description is adapted from the dataset named 'S&amp;P 500 Stock data'.
This data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.

  [1]: https://github.com/szrlee/Stock-Time-Series-Analysis/blob/master/data_collection.ipynb",.csv,True
DJIA 30 Stock Time Series,33,stock-time-series-20050101-to-20171231,INTC_2006-01-01_to_2018-01-01.csv,CC0-1.0,"### Context

The script used to acquire all of the following data can be found [in this GitHub repository][1]. This repository also contains the modeling codes and will be updated continually, so welcome starring or watching!

Stock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).

          ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',

          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',

          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']

In the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.


### Content

The data is presented in a couple of formats to suit different individual's needs or computational limitations. 
I have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and
a smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.

The folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. 
The all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. 
Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.

All the files have the following columns:
Date - in format: yy-mm-dd 

Open - price of the stock at market open (this is NYSE data so all in USD)

High - Highest price reached in the day

Low	Close - Lowest price reached in the day

Volume - Number of shares traded

Name - the stock's ticker name

### Inspiration

This dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.
From these data informative stock stats such as volatility and moving averages can be easily calculated.
The million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!

### Acknowledgement 

This Data description is adapted from the dataset named 'S&amp;P 500 Stock data'.
This data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.

  [1]: https://github.com/szrlee/Stock-Time-Series-Analysis/blob/master/data_collection.ipynb",.csv,True
DJIA 30 Stock Time Series,33,stock-time-series-20050101-to-20171231,PFE_2006-01-01_to_2018-01-01.csv,CC0-1.0,"### Context

The script used to acquire all of the following data can be found [in this GitHub repository][1]. This repository also contains the modeling codes and will be updated continually, so welcome starring or watching!

Stock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).

          ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',

          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',

          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']

In the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.


### Content

The data is presented in a couple of formats to suit different individual's needs or computational limitations. 
I have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and
a smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.

The folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. 
The all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. 
Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.

All the files have the following columns:
Date - in format: yy-mm-dd 

Open - price of the stock at market open (this is NYSE data so all in USD)

High - Highest price reached in the day

Low	Close - Lowest price reached in the day

Volume - Number of shares traded

Name - the stock's ticker name

### Inspiration

This dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.
From these data informative stock stats such as volatility and moving averages can be easily calculated.
The million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!

### Acknowledgement 

This Data description is adapted from the dataset named 'S&amp;P 500 Stock data'.
This data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.

  [1]: https://github.com/szrlee/Stock-Time-Series-Analysis/blob/master/data_collection.ipynb",.csv,True
DJIA 30 Stock Time Series,33,stock-time-series-20050101-to-20171231,GE_2006-01-01_to_2018-01-01.csv,CC0-1.0,"### Context

The script used to acquire all of the following data can be found [in this GitHub repository][1]. This repository also contains the modeling codes and will be updated continually, so welcome starring or watching!

Stock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).

          ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',

          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',

          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']

In the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.


### Content

The data is presented in a couple of formats to suit different individual's needs or computational limitations. 
I have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and
a smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.

The folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. 
The all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. 
Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.

All the files have the following columns:
Date - in format: yy-mm-dd 

Open - price of the stock at market open (this is NYSE data so all in USD)

High - Highest price reached in the day

Low	Close - Lowest price reached in the day

Volume - Number of shares traded

Name - the stock's ticker name

### Inspiration

This dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.
From these data informative stock stats such as volatility and moving averages can be easily calculated.
The million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!

### Acknowledgement 

This Data description is adapted from the dataset named 'S&amp;P 500 Stock data'.
This data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.

  [1]: https://github.com/szrlee/Stock-Time-Series-Analysis/blob/master/data_collection.ipynb",.csv,True
DJIA 30 Stock Time Series,33,stock-time-series-20050101-to-20171231,DIS_2006-01-01_to_2018-01-01.csv,CC0-1.0,"### Context

The script used to acquire all of the following data can be found [in this GitHub repository][1]. This repository also contains the modeling codes and will be updated continually, so welcome starring or watching!

Stock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).

          ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',

          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',

          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']

In the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.


### Content

The data is presented in a couple of formats to suit different individual's needs or computational limitations. 
I have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and
a smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.

The folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. 
The all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. 
Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.

All the files have the following columns:
Date - in format: yy-mm-dd 

Open - price of the stock at market open (this is NYSE data so all in USD)

High - Highest price reached in the day

Low	Close - Lowest price reached in the day

Volume - Number of shares traded

Name - the stock's ticker name

### Inspiration

This dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.
From these data informative stock stats such as volatility and moving averages can be easily calculated.
The million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!

### Acknowledgement 

This Data description is adapted from the dataset named 'S&amp;P 500 Stock data'.
This data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.

  [1]: https://github.com/szrlee/Stock-Time-Series-Analysis/blob/master/data_collection.ipynb",.csv,True
DJIA 30 Stock Time Series,33,stock-time-series-20050101-to-20171231,PG_2006-01-01_to_2018-01-01.csv,CC0-1.0,"### Context

The script used to acquire all of the following data can be found [in this GitHub repository][1]. This repository also contains the modeling codes and will be updated continually, so welcome starring or watching!

Stock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).

          ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',

          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',

          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']

In the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.


### Content

The data is presented in a couple of formats to suit different individual's needs or computational limitations. 
I have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and
a smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.

The folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. 
The all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. 
Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.

All the files have the following columns:
Date - in format: yy-mm-dd 

Open - price of the stock at market open (this is NYSE data so all in USD)

High - Highest price reached in the day

Low	Close - Lowest price reached in the day

Volume - Number of shares traded

Name - the stock's ticker name

### Inspiration

This dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.
From these data informative stock stats such as volatility and moving averages can be easily calculated.
The million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!

### Acknowledgement 

This Data description is adapted from the dataset named 'S&amp;P 500 Stock data'.
This data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.

  [1]: https://github.com/szrlee/Stock-Time-Series-Analysis/blob/master/data_collection.ipynb",.csv,True
DJIA 30 Stock Time Series,33,stock-time-series-20050101-to-20171231,BA_2006-01-01_to_2018-01-01.csv,CC0-1.0,"### Context

The script used to acquire all of the following data can be found [in this GitHub repository][1]. This repository also contains the modeling codes and will be updated continually, so welcome starring or watching!

Stock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).

          ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',

          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',

          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']

In the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.


### Content

The data is presented in a couple of formats to suit different individual's needs or computational limitations. 
I have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and
a smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.

The folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. 
The all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. 
Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.

All the files have the following columns:
Date - in format: yy-mm-dd 

Open - price of the stock at market open (this is NYSE data so all in USD)

High - Highest price reached in the day

Low	Close - Lowest price reached in the day

Volume - Number of shares traded

Name - the stock's ticker name

### Inspiration

This dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.
From these data informative stock stats such as volatility and moving averages can be easily calculated.
The million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!

### Acknowledgement 

This Data description is adapted from the dataset named 'S&amp;P 500 Stock data'.
This data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.

  [1]: https://github.com/szrlee/Stock-Time-Series-Analysis/blob/master/data_collection.ipynb",.csv,True
DJIA 30 Stock Time Series,33,stock-time-series-20050101-to-20171231,MCD_2006-01-01_to_2018-01-01.csv,CC0-1.0,"### Context

The script used to acquire all of the following data can be found [in this GitHub repository][1]. This repository also contains the modeling codes and will be updated continually, so welcome starring or watching!

Stock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).

          ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',

          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',

          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']

In the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.


### Content

The data is presented in a couple of formats to suit different individual's needs or computational limitations. 
I have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and
a smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.

The folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. 
The all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. 
Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.

All the files have the following columns:
Date - in format: yy-mm-dd 

Open - price of the stock at market open (this is NYSE data so all in USD)

High - Highest price reached in the day

Low	Close - Lowest price reached in the day

Volume - Number of shares traded

Name - the stock's ticker name

### Inspiration

This dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.
From these data informative stock stats such as volatility and moving averages can be easily calculated.
The million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!

### Acknowledgement 

This Data description is adapted from the dataset named 'S&amp;P 500 Stock data'.
This data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.

  [1]: https://github.com/szrlee/Stock-Time-Series-Analysis/blob/master/data_collection.ipynb",.csv,True
DJIA 30 Stock Time Series,33,stock-time-series-20050101-to-20171231,NKE_2006-01-01_to_2018-01-01.csv,CC0-1.0,"### Context

The script used to acquire all of the following data can be found [in this GitHub repository][1]. This repository also contains the modeling codes and will be updated continually, so welcome starring or watching!

Stock market data can be interesting to analyze and as a further incentive, strong predictive models can have large financial payoff. The amount of financial data on the web is seemingly endless. A large and well structured dataset on a wide array of companies can be hard to come by. Here provided a dataset with historical stock prices (last 12 years) for 29 of 30 DJIA companies (excluding 'V' because it does not have the whole 12 years data).

          ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'XOM', 'GE',

          'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE',

          'PG', 'TRV', 'UTX', 'UNH', 'VZ', 'WMT', 'GOOGL', 'AMZN', 'AABA']

In the future if you wish for a more up to date dataset, this can be used to acquire new versions of the .csv files.


### Content

The data is presented in a couple of formats to suit different individual's needs or computational limitations. 
I have included files containing 13 years of stock data (in the all_stocks_2006-01-01_to_2018-01-01.csv and corresponding folder) and
a smaller version of the dataset (all_stocks_2017-01-01_to_2018-01-01.csv) with only the past year's stock data for those wishing to use something more manageable in size.

The folder individual_stocks_2006-01-01_to_2018-01-01 contains files of data for individual stocks, labelled by their stock ticker name. 
The all_stocks_2006-01-01_to_2018-01-01.csv and all_stocks_2017-01-01_to_2018-01-01.csv contain this same data, presented in merged .csv files. 
Depending on the intended use (graphing, modelling etc.) the user may prefer one of these given formats.

All the files have the following columns:
Date - in format: yy-mm-dd 

Open - price of the stock at market open (this is NYSE data so all in USD)

High - Highest price reached in the day

Low	Close - Lowest price reached in the day

Volume - Number of shares traded

Name - the stock's ticker name

### Inspiration

This dataset lends itself to a some very interesting visualizations. One can look at simple things like how prices change over time, graph an compare multiple stocks at once, or generate and graph new metrics from the data provided.
From these data informative stock stats such as volatility and moving averages can be easily calculated.
The million dollar question is: can you develop a model that can beat the market and allow you to make statistically informed trades!

### Acknowledgement 

This Data description is adapted from the dataset named 'S&amp;P 500 Stock data'.
This data is scrapped from Google finance using the python library 'pandas_datareader'. Special thanks to Kaggle, Github and the Market.

  [1]: https://github.com/szrlee/Stock-Time-Series-Analysis/blob/master/data_collection.ipynb",.csv,True
Daily Climate time series data,2,daily-climate-time-series-data,DailyDelhiClimateTest.csv,CC0-1.0,"### Content

The Dataset is fully dedicated for the developers who want to train the model on Weather Forecasting for Indian climate. This dataset provides data from **1st January 2013** to **24th April 2017** in the city of Delhi, India. The 4 parameters here are 
**meantemp, humidity, wind_speed, meanpressure**.
### Acknowledgements

This dataset has been collected from Weather Undergroud API. Dataset ownership and credit goes to them.

### Submission Deadline

Assignment 4 must be submitted by October 19, 2019 (10:00 PM). Any kernel published after this deadline will be evaluated for only 50% of the total marks.

### Inspiration

This dataset was developed as a part Assignment 4 of Data Analytics Course, 2019 at PES University, Bangalore.

",.csv,True
Daily Climate time series data,2,daily-climate-time-series-data,DailyDelhiClimateTrain.csv,CC0-1.0,"### Content

The Dataset is fully dedicated for the developers who want to train the model on Weather Forecasting for Indian climate. This dataset provides data from **1st January 2013** to **24th April 2017** in the city of Delhi, India. The 4 parameters here are 
**meantemp, humidity, wind_speed, meanpressure**.
### Acknowledgements

This dataset has been collected from Weather Undergroud API. Dataset ownership and credit goes to them.

### Submission Deadline

Assignment 4 must be submitted by October 19, 2019 (10:00 PM). Any kernel published after this deadline will be evaluated for only 50% of the total marks.

### Inspiration

This dataset was developed as a part Assignment 4 of Data Analytics Course, 2019 at PES University, Bangalore.

",.csv,True
Datasets of WEBTOON ORIGINALS,7,webtoon-originals-datasets,webtoon_originals_en.csv,CC0-1.0,"# Datasets of WEBTOON ORIGINALS
Datasets of WEBTOON ORIGINALS for the available languages on the WEBTOON platform.

![your throne-medea](https://user-images.githubusercontent.com/63270221/154731488-0ad86417-d722-4c2d-bc29-d5f3ad79fed5.jpg)

## Content
Each csv has the columns:
- `title_id` - the id number of the webtoon title
- `title`
- `genre`
- `authors` - string of a joined list of authors
- `weekdays` - the day(s) of thw week the webtoon updates, string of a joined list of days
- `length` - the number of free episodes
- `subscribers`
- `rating`
- `views`
- `likes` - total accumulated likes from all available episodes
- `status` - `ONGOING`, `HIATUS`, or `COMPLETED`
- `daily_pass` - `True` or `False`
- `synopsis`

## Use
The jupyter notebooks provided here use python 3 and the libraries required are `requests` and `pandas`.

```
pip install requests pandas
```

For the `authors` and `weekdays` columns, a list of values had been joined with commas. An example of how to work with them is given in `webtoon_dataframes.ipynb`.

I have provided the code I used to create the csv files in `get_webtoon_csv.ipynb`. A RapidAPI key is needed to use it. You can get a key by creating an account at [RapidAPI](https://rapidapi.com/) and subscribing to the [Webtoon API](https://rapidapi.com/apidojo/api/webtoon/pricing).

## Acknowledgements
Thank you to [WEBTOON](https://webtoons.com) and the creators on the platform for giving us so many great webtoons, as well as [apidojo](https://apidojo.net/) for creating the Webtoon API.",.csv,True
Datasets of WEBTOON ORIGINALS,7,webtoon-originals-datasets,webtoon_originals_fr.csv,CC0-1.0,"# Datasets of WEBTOON ORIGINALS
Datasets of WEBTOON ORIGINALS for the available languages on the WEBTOON platform.

![your throne-medea](https://user-images.githubusercontent.com/63270221/154731488-0ad86417-d722-4c2d-bc29-d5f3ad79fed5.jpg)

## Content
Each csv has the columns:
- `title_id` - the id number of the webtoon title
- `title`
- `genre`
- `authors` - string of a joined list of authors
- `weekdays` - the day(s) of thw week the webtoon updates, string of a joined list of days
- `length` - the number of free episodes
- `subscribers`
- `rating`
- `views`
- `likes` - total accumulated likes from all available episodes
- `status` - `ONGOING`, `HIATUS`, or `COMPLETED`
- `daily_pass` - `True` or `False`
- `synopsis`

## Use
The jupyter notebooks provided here use python 3 and the libraries required are `requests` and `pandas`.

```
pip install requests pandas
```

For the `authors` and `weekdays` columns, a list of values had been joined with commas. An example of how to work with them is given in `webtoon_dataframes.ipynb`.

I have provided the code I used to create the csv files in `get_webtoon_csv.ipynb`. A RapidAPI key is needed to use it. You can get a key by creating an account at [RapidAPI](https://rapidapi.com/) and subscribing to the [Webtoon API](https://rapidapi.com/apidojo/api/webtoon/pricing).

## Acknowledgements
Thank you to [WEBTOON](https://webtoons.com) and the creators on the platform for giving us so many great webtoons, as well as [apidojo](https://apidojo.net/) for creating the Webtoon API.",.csv,True
Datasets of WEBTOON ORIGINALS,7,webtoon-originals-datasets,webtoon_originals_zh-hant.csv,CC0-1.0,"# Datasets of WEBTOON ORIGINALS
Datasets of WEBTOON ORIGINALS for the available languages on the WEBTOON platform.

![your throne-medea](https://user-images.githubusercontent.com/63270221/154731488-0ad86417-d722-4c2d-bc29-d5f3ad79fed5.jpg)

## Content
Each csv has the columns:
- `title_id` - the id number of the webtoon title
- `title`
- `genre`
- `authors` - string of a joined list of authors
- `weekdays` - the day(s) of thw week the webtoon updates, string of a joined list of days
- `length` - the number of free episodes
- `subscribers`
- `rating`
- `views`
- `likes` - total accumulated likes from all available episodes
- `status` - `ONGOING`, `HIATUS`, or `COMPLETED`
- `daily_pass` - `True` or `False`
- `synopsis`

## Use
The jupyter notebooks provided here use python 3 and the libraries required are `requests` and `pandas`.

```
pip install requests pandas
```

For the `authors` and `weekdays` columns, a list of values had been joined with commas. An example of how to work with them is given in `webtoon_dataframes.ipynb`.

I have provided the code I used to create the csv files in `get_webtoon_csv.ipynb`. A RapidAPI key is needed to use it. You can get a key by creating an account at [RapidAPI](https://rapidapi.com/) and subscribing to the [Webtoon API](https://rapidapi.com/apidojo/api/webtoon/pricing).

## Acknowledgements
Thank you to [WEBTOON](https://webtoons.com) and the creators on the platform for giving us so many great webtoons, as well as [apidojo](https://apidojo.net/) for creating the Webtoon API.",.csv,True
Datasets of WEBTOON ORIGINALS,7,webtoon-originals-datasets,webtoon_originals_th.csv,CC0-1.0,"# Datasets of WEBTOON ORIGINALS
Datasets of WEBTOON ORIGINALS for the available languages on the WEBTOON platform.

![your throne-medea](https://user-images.githubusercontent.com/63270221/154731488-0ad86417-d722-4c2d-bc29-d5f3ad79fed5.jpg)

## Content
Each csv has the columns:
- `title_id` - the id number of the webtoon title
- `title`
- `genre`
- `authors` - string of a joined list of authors
- `weekdays` - the day(s) of thw week the webtoon updates, string of a joined list of days
- `length` - the number of free episodes
- `subscribers`
- `rating`
- `views`
- `likes` - total accumulated likes from all available episodes
- `status` - `ONGOING`, `HIATUS`, or `COMPLETED`
- `daily_pass` - `True` or `False`
- `synopsis`

## Use
The jupyter notebooks provided here use python 3 and the libraries required are `requests` and `pandas`.

```
pip install requests pandas
```

For the `authors` and `weekdays` columns, a list of values had been joined with commas. An example of how to work with them is given in `webtoon_dataframes.ipynb`.

I have provided the code I used to create the csv files in `get_webtoon_csv.ipynb`. A RapidAPI key is needed to use it. You can get a key by creating an account at [RapidAPI](https://rapidapi.com/) and subscribing to the [Webtoon API](https://rapidapi.com/apidojo/api/webtoon/pricing).

## Acknowledgements
Thank you to [WEBTOON](https://webtoons.com) and the creators on the platform for giving us so many great webtoons, as well as [apidojo](https://apidojo.net/) for creating the Webtoon API.",.csv,True
Datasets of WEBTOON ORIGINALS,7,webtoon-originals-datasets,webtoon_originals_id.csv,CC0-1.0,"# Datasets of WEBTOON ORIGINALS
Datasets of WEBTOON ORIGINALS for the available languages on the WEBTOON platform.

![your throne-medea](https://user-images.githubusercontent.com/63270221/154731488-0ad86417-d722-4c2d-bc29-d5f3ad79fed5.jpg)

## Content
Each csv has the columns:
- `title_id` - the id number of the webtoon title
- `title`
- `genre`
- `authors` - string of a joined list of authors
- `weekdays` - the day(s) of thw week the webtoon updates, string of a joined list of days
- `length` - the number of free episodes
- `subscribers`
- `rating`
- `views`
- `likes` - total accumulated likes from all available episodes
- `status` - `ONGOING`, `HIATUS`, or `COMPLETED`
- `daily_pass` - `True` or `False`
- `synopsis`

## Use
The jupyter notebooks provided here use python 3 and the libraries required are `requests` and `pandas`.

```
pip install requests pandas
```

For the `authors` and `weekdays` columns, a list of values had been joined with commas. An example of how to work with them is given in `webtoon_dataframes.ipynb`.

I have provided the code I used to create the csv files in `get_webtoon_csv.ipynb`. A RapidAPI key is needed to use it. You can get a key by creating an account at [RapidAPI](https://rapidapi.com/) and subscribing to the [Webtoon API](https://rapidapi.com/apidojo/api/webtoon/pricing).

## Acknowledgements
Thank you to [WEBTOON](https://webtoons.com) and the creators on the platform for giving us so many great webtoons, as well as [apidojo](https://apidojo.net/) for creating the Webtoon API.",.csv,True
Datasets of WEBTOON ORIGINALS,7,webtoon-originals-datasets,webtoon_originals_es.csv,CC0-1.0,"# Datasets of WEBTOON ORIGINALS
Datasets of WEBTOON ORIGINALS for the available languages on the WEBTOON platform.

![your throne-medea](https://user-images.githubusercontent.com/63270221/154731488-0ad86417-d722-4c2d-bc29-d5f3ad79fed5.jpg)

## Content
Each csv has the columns:
- `title_id` - the id number of the webtoon title
- `title`
- `genre`
- `authors` - string of a joined list of authors
- `weekdays` - the day(s) of thw week the webtoon updates, string of a joined list of days
- `length` - the number of free episodes
- `subscribers`
- `rating`
- `views`
- `likes` - total accumulated likes from all available episodes
- `status` - `ONGOING`, `HIATUS`, or `COMPLETED`
- `daily_pass` - `True` or `False`
- `synopsis`

## Use
The jupyter notebooks provided here use python 3 and the libraries required are `requests` and `pandas`.

```
pip install requests pandas
```

For the `authors` and `weekdays` columns, a list of values had been joined with commas. An example of how to work with them is given in `webtoon_dataframes.ipynb`.

I have provided the code I used to create the csv files in `get_webtoon_csv.ipynb`. A RapidAPI key is needed to use it. You can get a key by creating an account at [RapidAPI](https://rapidapi.com/) and subscribing to the [Webtoon API](https://rapidapi.com/apidojo/api/webtoon/pricing).

## Acknowledgements
Thank you to [WEBTOON](https://webtoons.com) and the creators on the platform for giving us so many great webtoons, as well as [apidojo](https://apidojo.net/) for creating the Webtoon API.",.csv,True
Datasets of WEBTOON ORIGINALS,7,webtoon-originals-datasets,webtoon_originals_de.csv,CC0-1.0,"# Datasets of WEBTOON ORIGINALS
Datasets of WEBTOON ORIGINALS for the available languages on the WEBTOON platform.

![your throne-medea](https://user-images.githubusercontent.com/63270221/154731488-0ad86417-d722-4c2d-bc29-d5f3ad79fed5.jpg)

## Content
Each csv has the columns:
- `title_id` - the id number of the webtoon title
- `title`
- `genre`
- `authors` - string of a joined list of authors
- `weekdays` - the day(s) of thw week the webtoon updates, string of a joined list of days
- `length` - the number of free episodes
- `subscribers`
- `rating`
- `views`
- `likes` - total accumulated likes from all available episodes
- `status` - `ONGOING`, `HIATUS`, or `COMPLETED`
- `daily_pass` - `True` or `False`
- `synopsis`

## Use
The jupyter notebooks provided here use python 3 and the libraries required are `requests` and `pandas`.

```
pip install requests pandas
```

For the `authors` and `weekdays` columns, a list of values had been joined with commas. An example of how to work with them is given in `webtoon_dataframes.ipynb`.

I have provided the code I used to create the csv files in `get_webtoon_csv.ipynb`. A RapidAPI key is needed to use it. You can get a key by creating an account at [RapidAPI](https://rapidapi.com/) and subscribing to the [Webtoon API](https://rapidapi.com/apidojo/api/webtoon/pricing).

## Acknowledgements
Thank you to [WEBTOON](https://webtoons.com) and the creators on the platform for giving us so many great webtoons, as well as [apidojo](https://apidojo.net/) for creating the Webtoon API.",.csv,True
Dental Utilization By Provider,2,dental-utilization-by-provider,dental-utilization-by-provider-cy-2018-1 (1).csv,other,"DESCRIPTION
This dataset provides beneficiary and service counts for annual dental visits, dental preventive services, dental ...
SUMMARY
This dataset provides beneficiary and service counts for annual dental visits, dental preventive services, dental treatment, and dental exams by rendering providers (by NPI) for calendar year (CY) 2018. It includes fee-for-service (FFS), Geographic Managed Care, and Pre-Paid Health Plans delivery systems. Rendering providers are categorized as either rendering or rendering at a safety net clinic. Beneficiaries are grouped by Age 0-20 and Age 21+.

Source: https://www.denti-cal.ca.gov/
Last updated at https://data.chhs.ca.gov : 2020-06-01
License: https://data.chhs.ca.gov/pages/terms",.csv,True
Dental Utilization By Provider,2,dental-utilization-by-provider,dental-utilization-by-provider.csv,other,"DESCRIPTION
This dataset provides beneficiary and service counts for annual dental visits, dental preventive services, dental ...
SUMMARY
This dataset provides beneficiary and service counts for annual dental visits, dental preventive services, dental treatment, and dental exams by rendering providers (by NPI) for calendar year (CY) 2018. It includes fee-for-service (FFS), Geographic Managed Care, and Pre-Paid Health Plans delivery systems. Rendering providers are categorized as either rendering or rendering at a safety net clinic. Beneficiaries are grouped by Age 0-20 and Age 21+.

Source: https://www.denti-cal.ca.gov/
Last updated at https://data.chhs.ca.gov : 2020-06-01
License: https://data.chhs.ca.gov/pages/terms",.csv,True
Driving Behavior,2,driving-behavior,test_motion_data.csv,Attribution 4.0 International (CC BY 4.0),"### **Context**

Aggressive driving behavior is the leading factor of road traffic accidents. As reported by the **AAA Foundation for Traffic Safety**, 106,727 fatal crashes – 55.7 percent of the total – during a recent four-year period involved drivers who committed one or more aggressive driving actions. Therefore, how to predict dangerous driving behavior quickly and accurately?

### **Solution Approach**

Aggressive driving includes speeding, sudden breaks and sudden left or right turns. All these events are reflected on accelerometer and gyroscope data. Therefore, knowing that almost everyone owns a smartphone nowadays which has a wide variety of sensors, we've designed a data collector application in android based on the accelerometer and gyroscope sensors.

### **Content**

- Sampling Rate: 2 samples (rows) per second.
- Gravitational acceleration: removed.
- Sensors: Accelerometer and Gyroscope.
- Data: 
   1.  Acceleration (X,Y,Z axis in meters per second squared (m/s2))
   2.  Rotation (X,Y, Z axis in degrees per second (°/s))  
   3.  Classification label (SLOW, NORMAL, AGGRESSIVE)
   4.  Timestamp (time in seconds)
- Driving Behaviors:
   1.  Slow
   2.  Normal
   3.  Aggressive
- Device: Samsung Galaxy S21

### **Articles**
- [Building a Driving Behaviour Dataset](http://rochi.utcluj.ro/articole/10/RoCHI2022-Cojocaru-I-1.pdf)
- [Driver Behaviour Analysis based on Deep Learning Algorithms](http://rochi.utcluj.ro/articole/10/RoCHI2022-Cojocaru-I-2.pdf)

### **Authors**

- Paul-Stefan Popescu
- Ion Cojocaru",.csv,True
Driving Behavior,2,driving-behavior,train_motion_data.csv,Attribution 4.0 International (CC BY 4.0),"### **Context**

Aggressive driving behavior is the leading factor of road traffic accidents. As reported by the **AAA Foundation for Traffic Safety**, 106,727 fatal crashes – 55.7 percent of the total – during a recent four-year period involved drivers who committed one or more aggressive driving actions. Therefore, how to predict dangerous driving behavior quickly and accurately?

### **Solution Approach**

Aggressive driving includes speeding, sudden breaks and sudden left or right turns. All these events are reflected on accelerometer and gyroscope data. Therefore, knowing that almost everyone owns a smartphone nowadays which has a wide variety of sensors, we've designed a data collector application in android based on the accelerometer and gyroscope sensors.

### **Content**

- Sampling Rate: 2 samples (rows) per second.
- Gravitational acceleration: removed.
- Sensors: Accelerometer and Gyroscope.
- Data: 
   1.  Acceleration (X,Y,Z axis in meters per second squared (m/s2))
   2.  Rotation (X,Y, Z axis in degrees per second (°/s))  
   3.  Classification label (SLOW, NORMAL, AGGRESSIVE)
   4.  Timestamp (time in seconds)
- Driving Behaviors:
   1.  Slow
   2.  Normal
   3.  Aggressive
- Device: Samsung Galaxy S21

### **Articles**
- [Building a Driving Behaviour Dataset](http://rochi.utcluj.ro/articole/10/RoCHI2022-Cojocaru-I-1.pdf)
- [Driver Behaviour Analysis based on Deep Learning Algorithms](http://rochi.utcluj.ro/articole/10/RoCHI2022-Cojocaru-I-2.pdf)

### **Authors**

- Paul-Stefan Popescu
- Ion Cojocaru",.csv,True
EDM Music Genres,2,edm-music-genres,train_data_final.csv,MIT,"# 🎶 Welcome to the **EDM genre classification dataset**! 🎶


Take a trip through the colorful world of music with our carefully put together dataset! 🎶. This dataset got 16 different music styles for you to dive into. Whether you're into the chill vibes of *Ambient* 🌌 or the energetic beats of *Big Room House* 🏠, there's something for everyone here. Each genre brings its own special sound, just waiting for you to discover. 🎵

### List of genres:

- Ambient 🌌
- Big Room House 🏠
- Drum and Bass 🥁
- Dubstep 🎵
- Future Garage/Wave Trap 🌊
- Hardcore 🔊
- Hardstyle 💥
- House 🏡
- Lo-fi 🎶
- Moombahton/Reggaeton 🎵🌴
- Phonk 🔥
- Psytrance 🌀
- Synthwave 🎹
- Techno 🎛️
- Trance 🚀
- Trap ⛓️

Each one of these genres and represented equally across both the training and testing dataset. 

### **How this dataset was curated?**

All audio clips used for feature extraction are sourced from **YouTube music mixes**, ensuring a diverse and extensive collection of musical content across different genres. Then the music files are loaded up into ""Ableton"" and sliced into equal length 3 second audio clips. These audio clips are used to extract the features. 

Inorder the keep the dataset consistent. I equalized the number of entries per genre 2500 and it is split into 2000 training features per genre and 500 testing features per genre. This data-splitting is done before feature extraction so I can guarantee that there is no data leakage, however since the music are taken from splitting  larger excerpts, some rows of data might be similar/same and not all 3 second audio clips are unique i.e., some clips might be identical since they are spliced from the same track/song. 

### **Features:** 

Each feature has both its mean value and its standard deviation value stored in individual columns *expect for label*.

#### Root Mean Square Error (RMSE):
- RMSE: 📊

#### Spectral Features:
- Spectral Centroid: 🔊
- Spectral Bandwidth: 🎶
- Spectral Rolloff: 🌟

#### Zero Crossing Rate:
- Zero Crossing Rate: 🔀

#### Mel-Frequency Cepstral Coefficients (MFCC):
- MFCC1: 🎵
- MFCC2: 🔊
(upto)
- MFCC39: 🌈
- MFCC40: 💫

#### Chroma Features:
- Chroma1: 🎹
(upto)
- Chroma12: 🎼

#### Tonnetz Features:
- Tonnetz1: 🔊
(upto)
- Tonnetz6: 🌈

#### Additional Features:
- Chroma CQT: 🔊
- Spectral Contrast: 🎶

#### Label:
- Label: 🏷️


Have fun and please make sure to upvote this because it took a me around 17 hours to build this dataset and I would greatly appreciate if you make some models with it and share it with others. Enjoy coding! ",.csv,True
EDM Music Genres,2,edm-music-genres,test_data_final.csv,MIT,"# 🎶 Welcome to the **EDM genre classification dataset**! 🎶


Take a trip through the colorful world of music with our carefully put together dataset! 🎶. This dataset got 16 different music styles for you to dive into. Whether you're into the chill vibes of *Ambient* 🌌 or the energetic beats of *Big Room House* 🏠, there's something for everyone here. Each genre brings its own special sound, just waiting for you to discover. 🎵

### List of genres:

- Ambient 🌌
- Big Room House 🏠
- Drum and Bass 🥁
- Dubstep 🎵
- Future Garage/Wave Trap 🌊
- Hardcore 🔊
- Hardstyle 💥
- House 🏡
- Lo-fi 🎶
- Moombahton/Reggaeton 🎵🌴
- Phonk 🔥
- Psytrance 🌀
- Synthwave 🎹
- Techno 🎛️
- Trance 🚀
- Trap ⛓️

Each one of these genres and represented equally across both the training and testing dataset. 

### **How this dataset was curated?**

All audio clips used for feature extraction are sourced from **YouTube music mixes**, ensuring a diverse and extensive collection of musical content across different genres. Then the music files are loaded up into ""Ableton"" and sliced into equal length 3 second audio clips. These audio clips are used to extract the features. 

Inorder the keep the dataset consistent. I equalized the number of entries per genre 2500 and it is split into 2000 training features per genre and 500 testing features per genre. This data-splitting is done before feature extraction so I can guarantee that there is no data leakage, however since the music are taken from splitting  larger excerpts, some rows of data might be similar/same and not all 3 second audio clips are unique i.e., some clips might be identical since they are spliced from the same track/song. 

### **Features:** 

Each feature has both its mean value and its standard deviation value stored in individual columns *expect for label*.

#### Root Mean Square Error (RMSE):
- RMSE: 📊

#### Spectral Features:
- Spectral Centroid: 🔊
- Spectral Bandwidth: 🎶
- Spectral Rolloff: 🌟

#### Zero Crossing Rate:
- Zero Crossing Rate: 🔀

#### Mel-Frequency Cepstral Coefficients (MFCC):
- MFCC1: 🎵
- MFCC2: 🔊
(upto)
- MFCC39: 🌈
- MFCC40: 💫

#### Chroma Features:
- Chroma1: 🎹
(upto)
- Chroma12: 🎼

#### Tonnetz Features:
- Tonnetz1: 🔊
(upto)
- Tonnetz6: 🌈

#### Additional Features:
- Chroma CQT: 🔊
- Spectral Contrast: 🎶

#### Label:
- Label: 🏷️


Have fun and please make sure to upvote this because it took a me around 17 hours to build this dataset and I would greatly appreciate if you make some models with it and share it with others. Enjoy coding! ",.csv,True
EOD data for all Dow Jones stocks,30,stock-data-dow-jones,CSCO.csv,other,"### Update
Unfortunately, the API this dataset used to pull the stock data isn't free anymore. Instead of having this auto-updating, I dropped the last version of the data files in here, so at least the historic data is still usable.


### Content

This dataset provides free end of day data for all stocks currently in the Dow Jones Industrial Average. For each of the 30 components of the index, there is one CSV file named by the stock's symbol (e.g. AAPL for Apple). Each file provides historically adjusted market-wide data (daily, max. 5 years back). See here for description of the columns: [https://iextrading.com/developer/docs/#chart][1]

Since this dataset uses remote URLs as files, it is automatically updated daily by the Kaggle platform and automatically represents the latest data.

### Acknowledgements

List of stocks and symbols as per [https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average][2]

Thanks to [https://iextrading.com][3] for providing this data for free!

### Terms of Use

Data provided for free by [IEX][4]. View [IEX’s Terms of Use][5].


  [1]: https://iextrading.com/developer/docs/#chart
  [2]: https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average
  [3]: https://iextrading.com
  [4]: https://iextrading.com/developer
  [5]: https://iextrading.com/api-exhibit-a/",.csv,True
EOD data for all Dow Jones stocks,30,stock-data-dow-jones,BA.csv,other,"### Update
Unfortunately, the API this dataset used to pull the stock data isn't free anymore. Instead of having this auto-updating, I dropped the last version of the data files in here, so at least the historic data is still usable.


### Content

This dataset provides free end of day data for all stocks currently in the Dow Jones Industrial Average. For each of the 30 components of the index, there is one CSV file named by the stock's symbol (e.g. AAPL for Apple). Each file provides historically adjusted market-wide data (daily, max. 5 years back). See here for description of the columns: [https://iextrading.com/developer/docs/#chart][1]

Since this dataset uses remote URLs as files, it is automatically updated daily by the Kaggle platform and automatically represents the latest data.

### Acknowledgements

List of stocks and symbols as per [https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average][2]

Thanks to [https://iextrading.com][3] for providing this data for free!

### Terms of Use

Data provided for free by [IEX][4]. View [IEX’s Terms of Use][5].


  [1]: https://iextrading.com/developer/docs/#chart
  [2]: https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average
  [3]: https://iextrading.com
  [4]: https://iextrading.com/developer
  [5]: https://iextrading.com/api-exhibit-a/",.csv,True
EOD data for all Dow Jones stocks,30,stock-data-dow-jones,V.csv,other,"### Update
Unfortunately, the API this dataset used to pull the stock data isn't free anymore. Instead of having this auto-updating, I dropped the last version of the data files in here, so at least the historic data is still usable.


### Content

This dataset provides free end of day data for all stocks currently in the Dow Jones Industrial Average. For each of the 30 components of the index, there is one CSV file named by the stock's symbol (e.g. AAPL for Apple). Each file provides historically adjusted market-wide data (daily, max. 5 years back). See here for description of the columns: [https://iextrading.com/developer/docs/#chart][1]

Since this dataset uses remote URLs as files, it is automatically updated daily by the Kaggle platform and automatically represents the latest data.

### Acknowledgements

List of stocks and symbols as per [https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average][2]

Thanks to [https://iextrading.com][3] for providing this data for free!

### Terms of Use

Data provided for free by [IEX][4]. View [IEX’s Terms of Use][5].


  [1]: https://iextrading.com/developer/docs/#chart
  [2]: https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average
  [3]: https://iextrading.com
  [4]: https://iextrading.com/developer
  [5]: https://iextrading.com/api-exhibit-a/",.csv,True
EOD data for all Dow Jones stocks,30,stock-data-dow-jones,WBA.csv,other,"### Update
Unfortunately, the API this dataset used to pull the stock data isn't free anymore. Instead of having this auto-updating, I dropped the last version of the data files in here, so at least the historic data is still usable.


### Content

This dataset provides free end of day data for all stocks currently in the Dow Jones Industrial Average. For each of the 30 components of the index, there is one CSV file named by the stock's symbol (e.g. AAPL for Apple). Each file provides historically adjusted market-wide data (daily, max. 5 years back). See here for description of the columns: [https://iextrading.com/developer/docs/#chart][1]

Since this dataset uses remote URLs as files, it is automatically updated daily by the Kaggle platform and automatically represents the latest data.

### Acknowledgements

List of stocks and symbols as per [https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average][2]

Thanks to [https://iextrading.com][3] for providing this data for free!

### Terms of Use

Data provided for free by [IEX][4]. View [IEX’s Terms of Use][5].


  [1]: https://iextrading.com/developer/docs/#chart
  [2]: https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average
  [3]: https://iextrading.com
  [4]: https://iextrading.com/developer
  [5]: https://iextrading.com/api-exhibit-a/",.csv,True
EOD data for all Dow Jones stocks,30,stock-data-dow-jones,UTX.csv,other,"### Update
Unfortunately, the API this dataset used to pull the stock data isn't free anymore. Instead of having this auto-updating, I dropped the last version of the data files in here, so at least the historic data is still usable.


### Content

This dataset provides free end of day data for all stocks currently in the Dow Jones Industrial Average. For each of the 30 components of the index, there is one CSV file named by the stock's symbol (e.g. AAPL for Apple). Each file provides historically adjusted market-wide data (daily, max. 5 years back). See here for description of the columns: [https://iextrading.com/developer/docs/#chart][1]

Since this dataset uses remote URLs as files, it is automatically updated daily by the Kaggle platform and automatically represents the latest data.

### Acknowledgements

List of stocks and symbols as per [https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average][2]

Thanks to [https://iextrading.com][3] for providing this data for free!

### Terms of Use

Data provided for free by [IEX][4]. View [IEX’s Terms of Use][5].


  [1]: https://iextrading.com/developer/docs/#chart
  [2]: https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average
  [3]: https://iextrading.com
  [4]: https://iextrading.com/developer
  [5]: https://iextrading.com/api-exhibit-a/",.csv,True
EOD data for all Dow Jones stocks,30,stock-data-dow-jones,MRK.csv,other,"### Update
Unfortunately, the API this dataset used to pull the stock data isn't free anymore. Instead of having this auto-updating, I dropped the last version of the data files in here, so at least the historic data is still usable.


### Content

This dataset provides free end of day data for all stocks currently in the Dow Jones Industrial Average. For each of the 30 components of the index, there is one CSV file named by the stock's symbol (e.g. AAPL for Apple). Each file provides historically adjusted market-wide data (daily, max. 5 years back). See here for description of the columns: [https://iextrading.com/developer/docs/#chart][1]

Since this dataset uses remote URLs as files, it is automatically updated daily by the Kaggle platform and automatically represents the latest data.

### Acknowledgements

List of stocks and symbols as per [https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average][2]

Thanks to [https://iextrading.com][3] for providing this data for free!

### Terms of Use

Data provided for free by [IEX][4]. View [IEX’s Terms of Use][5].


  [1]: https://iextrading.com/developer/docs/#chart
  [2]: https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average
  [3]: https://iextrading.com
  [4]: https://iextrading.com/developer
  [5]: https://iextrading.com/api-exhibit-a/",.csv,True
EOD data for all Dow Jones stocks,30,stock-data-dow-jones,PG.csv,other,"### Update
Unfortunately, the API this dataset used to pull the stock data isn't free anymore. Instead of having this auto-updating, I dropped the last version of the data files in here, so at least the historic data is still usable.


### Content

This dataset provides free end of day data for all stocks currently in the Dow Jones Industrial Average. For each of the 30 components of the index, there is one CSV file named by the stock's symbol (e.g. AAPL for Apple). Each file provides historically adjusted market-wide data (daily, max. 5 years back). See here for description of the columns: [https://iextrading.com/developer/docs/#chart][1]

Since this dataset uses remote URLs as files, it is automatically updated daily by the Kaggle platform and automatically represents the latest data.

### Acknowledgements

List of stocks and symbols as per [https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average][2]

Thanks to [https://iextrading.com][3] for providing this data for free!

### Terms of Use

Data provided for free by [IEX][4]. View [IEX’s Terms of Use][5].


  [1]: https://iextrading.com/developer/docs/#chart
  [2]: https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average
  [3]: https://iextrading.com
  [4]: https://iextrading.com/developer
  [5]: https://iextrading.com/api-exhibit-a/",.csv,True
EOD data for all Dow Jones stocks,30,stock-data-dow-jones,CAT.csv,other,"### Update
Unfortunately, the API this dataset used to pull the stock data isn't free anymore. Instead of having this auto-updating, I dropped the last version of the data files in here, so at least the historic data is still usable.


### Content

This dataset provides free end of day data for all stocks currently in the Dow Jones Industrial Average. For each of the 30 components of the index, there is one CSV file named by the stock's symbol (e.g. AAPL for Apple). Each file provides historically adjusted market-wide data (daily, max. 5 years back). See here for description of the columns: [https://iextrading.com/developer/docs/#chart][1]

Since this dataset uses remote URLs as files, it is automatically updated daily by the Kaggle platform and automatically represents the latest data.

### Acknowledgements

List of stocks and symbols as per [https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average][2]

Thanks to [https://iextrading.com][3] for providing this data for free!

### Terms of Use

Data provided for free by [IEX][4]. View [IEX’s Terms of Use][5].


  [1]: https://iextrading.com/developer/docs/#chart
  [2]: https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average
  [3]: https://iextrading.com
  [4]: https://iextrading.com/developer
  [5]: https://iextrading.com/api-exhibit-a/",.csv,True
EOD data for all Dow Jones stocks,30,stock-data-dow-jones,MCD.csv,other,"### Update
Unfortunately, the API this dataset used to pull the stock data isn't free anymore. Instead of having this auto-updating, I dropped the last version of the data files in here, so at least the historic data is still usable.


### Content

This dataset provides free end of day data for all stocks currently in the Dow Jones Industrial Average. For each of the 30 components of the index, there is one CSV file named by the stock's symbol (e.g. AAPL for Apple). Each file provides historically adjusted market-wide data (daily, max. 5 years back). See here for description of the columns: [https://iextrading.com/developer/docs/#chart][1]

Since this dataset uses remote URLs as files, it is automatically updated daily by the Kaggle platform and automatically represents the latest data.

### Acknowledgements

List of stocks and symbols as per [https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average][2]

Thanks to [https://iextrading.com][3] for providing this data for free!

### Terms of Use

Data provided for free by [IEX][4]. View [IEX’s Terms of Use][5].


  [1]: https://iextrading.com/developer/docs/#chart
  [2]: https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average
  [3]: https://iextrading.com
  [4]: https://iextrading.com/developer
  [5]: https://iextrading.com/api-exhibit-a/",.csv,True
EOD data for all Dow Jones stocks,30,stock-data-dow-jones,INTC.csv,other,"### Update
Unfortunately, the API this dataset used to pull the stock data isn't free anymore. Instead of having this auto-updating, I dropped the last version of the data files in here, so at least the historic data is still usable.


### Content

This dataset provides free end of day data for all stocks currently in the Dow Jones Industrial Average. For each of the 30 components of the index, there is one CSV file named by the stock's symbol (e.g. AAPL for Apple). Each file provides historically adjusted market-wide data (daily, max. 5 years back). See here for description of the columns: [https://iextrading.com/developer/docs/#chart][1]

Since this dataset uses remote URLs as files, it is automatically updated daily by the Kaggle platform and automatically represents the latest data.

### Acknowledgements

List of stocks and symbols as per [https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average][2]

Thanks to [https://iextrading.com][3] for providing this data for free!

### Terms of Use

Data provided for free by [IEX][4]. View [IEX’s Terms of Use][5].


  [1]: https://iextrading.com/developer/docs/#chart
  [2]: https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average
  [3]: https://iextrading.com
  [4]: https://iextrading.com/developer
  [5]: https://iextrading.com/api-exhibit-a/",.csv,True
EOD data for all Dow Jones stocks,30,stock-data-dow-jones,MMM.csv,other,"### Update
Unfortunately, the API this dataset used to pull the stock data isn't free anymore. Instead of having this auto-updating, I dropped the last version of the data files in here, so at least the historic data is still usable.


### Content

This dataset provides free end of day data for all stocks currently in the Dow Jones Industrial Average. For each of the 30 components of the index, there is one CSV file named by the stock's symbol (e.g. AAPL for Apple). Each file provides historically adjusted market-wide data (daily, max. 5 years back). See here for description of the columns: [https://iextrading.com/developer/docs/#chart][1]

Since this dataset uses remote URLs as files, it is automatically updated daily by the Kaggle platform and automatically represents the latest data.

### Acknowledgements

List of stocks and symbols as per [https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average][2]

Thanks to [https://iextrading.com][3] for providing this data for free!

### Terms of Use

Data provided for free by [IEX][4]. View [IEX’s Terms of Use][5].


  [1]: https://iextrading.com/developer/docs/#chart
  [2]: https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average
  [3]: https://iextrading.com
  [4]: https://iextrading.com/developer
  [5]: https://iextrading.com/api-exhibit-a/",.csv,True
EOD data for all Dow Jones stocks,30,stock-data-dow-jones,DWDP.csv,other,"### Update
Unfortunately, the API this dataset used to pull the stock data isn't free anymore. Instead of having this auto-updating, I dropped the last version of the data files in here, so at least the historic data is still usable.


### Content

This dataset provides free end of day data for all stocks currently in the Dow Jones Industrial Average. For each of the 30 components of the index, there is one CSV file named by the stock's symbol (e.g. AAPL for Apple). Each file provides historically adjusted market-wide data (daily, max. 5 years back). See here for description of the columns: [https://iextrading.com/developer/docs/#chart][1]

Since this dataset uses remote URLs as files, it is automatically updated daily by the Kaggle platform and automatically represents the latest data.

### Acknowledgements

List of stocks and symbols as per [https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average][2]

Thanks to [https://iextrading.com][3] for providing this data for free!

### Terms of Use

Data provided for free by [IEX][4]. View [IEX’s Terms of Use][5].


  [1]: https://iextrading.com/developer/docs/#chart
  [2]: https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average
  [3]: https://iextrading.com
  [4]: https://iextrading.com/developer
  [5]: https://iextrading.com/api-exhibit-a/",.csv,True
EOD data for all Dow Jones stocks,30,stock-data-dow-jones,KO.csv,other,"### Update
Unfortunately, the API this dataset used to pull the stock data isn't free anymore. Instead of having this auto-updating, I dropped the last version of the data files in here, so at least the historic data is still usable.


### Content

This dataset provides free end of day data for all stocks currently in the Dow Jones Industrial Average. For each of the 30 components of the index, there is one CSV file named by the stock's symbol (e.g. AAPL for Apple). Each file provides historically adjusted market-wide data (daily, max. 5 years back). See here for description of the columns: [https://iextrading.com/developer/docs/#chart][1]

Since this dataset uses remote URLs as files, it is automatically updated daily by the Kaggle platform and automatically represents the latest data.

### Acknowledgements

List of stocks and symbols as per [https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average][2]

Thanks to [https://iextrading.com][3] for providing this data for free!

### Terms of Use

Data provided for free by [IEX][4]. View [IEX’s Terms of Use][5].


  [1]: https://iextrading.com/developer/docs/#chart
  [2]: https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average
  [3]: https://iextrading.com
  [4]: https://iextrading.com/developer
  [5]: https://iextrading.com/api-exhibit-a/",.csv,True
EOD data for all Dow Jones stocks,30,stock-data-dow-jones,MSFT.csv,other,"### Update
Unfortunately, the API this dataset used to pull the stock data isn't free anymore. Instead of having this auto-updating, I dropped the last version of the data files in here, so at least the historic data is still usable.


### Content

This dataset provides free end of day data for all stocks currently in the Dow Jones Industrial Average. For each of the 30 components of the index, there is one CSV file named by the stock's symbol (e.g. AAPL for Apple). Each file provides historically adjusted market-wide data (daily, max. 5 years back). See here for description of the columns: [https://iextrading.com/developer/docs/#chart][1]

Since this dataset uses remote URLs as files, it is automatically updated daily by the Kaggle platform and automatically represents the latest data.

### Acknowledgements

List of stocks and symbols as per [https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average][2]

Thanks to [https://iextrading.com][3] for providing this data for free!

### Terms of Use

Data provided for free by [IEX][4]. View [IEX’s Terms of Use][5].


  [1]: https://iextrading.com/developer/docs/#chart
  [2]: https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average
  [3]: https://iextrading.com
  [4]: https://iextrading.com/developer
  [5]: https://iextrading.com/api-exhibit-a/",.csv,True
EOD data for all Dow Jones stocks,30,stock-data-dow-jones,HD.csv,other,"### Update
Unfortunately, the API this dataset used to pull the stock data isn't free anymore. Instead of having this auto-updating, I dropped the last version of the data files in here, so at least the historic data is still usable.


### Content

This dataset provides free end of day data for all stocks currently in the Dow Jones Industrial Average. For each of the 30 components of the index, there is one CSV file named by the stock's symbol (e.g. AAPL for Apple). Each file provides historically adjusted market-wide data (daily, max. 5 years back). See here for description of the columns: [https://iextrading.com/developer/docs/#chart][1]

Since this dataset uses remote URLs as files, it is automatically updated daily by the Kaggle platform and automatically represents the latest data.

### Acknowledgements

List of stocks and symbols as per [https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average][2]

Thanks to [https://iextrading.com][3] for providing this data for free!

### Terms of Use

Data provided for free by [IEX][4]. View [IEX’s Terms of Use][5].


  [1]: https://iextrading.com/developer/docs/#chart
  [2]: https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average
  [3]: https://iextrading.com
  [4]: https://iextrading.com/developer
  [5]: https://iextrading.com/api-exhibit-a/",.csv,True
EOD data for all Dow Jones stocks,30,stock-data-dow-jones,AXP.csv,other,"### Update
Unfortunately, the API this dataset used to pull the stock data isn't free anymore. Instead of having this auto-updating, I dropped the last version of the data files in here, so at least the historic data is still usable.


### Content

This dataset provides free end of day data for all stocks currently in the Dow Jones Industrial Average. For each of the 30 components of the index, there is one CSV file named by the stock's symbol (e.g. AAPL for Apple). Each file provides historically adjusted market-wide data (daily, max. 5 years back). See here for description of the columns: [https://iextrading.com/developer/docs/#chart][1]

Since this dataset uses remote URLs as files, it is automatically updated daily by the Kaggle platform and automatically represents the latest data.

### Acknowledgements

List of stocks and symbols as per [https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average][2]

Thanks to [https://iextrading.com][3] for providing this data for free!

### Terms of Use

Data provided for free by [IEX][4]. View [IEX’s Terms of Use][5].


  [1]: https://iextrading.com/developer/docs/#chart
  [2]: https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average
  [3]: https://iextrading.com
  [4]: https://iextrading.com/developer
  [5]: https://iextrading.com/api-exhibit-a/",.csv,True
EOD data for all Dow Jones stocks,30,stock-data-dow-jones,XOM.csv,other,"### Update
Unfortunately, the API this dataset used to pull the stock data isn't free anymore. Instead of having this auto-updating, I dropped the last version of the data files in here, so at least the historic data is still usable.


### Content

This dataset provides free end of day data for all stocks currently in the Dow Jones Industrial Average. For each of the 30 components of the index, there is one CSV file named by the stock's symbol (e.g. AAPL for Apple). Each file provides historically adjusted market-wide data (daily, max. 5 years back). See here for description of the columns: [https://iextrading.com/developer/docs/#chart][1]

Since this dataset uses remote URLs as files, it is automatically updated daily by the Kaggle platform and automatically represents the latest data.

### Acknowledgements

List of stocks and symbols as per [https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average][2]

Thanks to [https://iextrading.com][3] for providing this data for free!

### Terms of Use

Data provided for free by [IEX][4]. View [IEX’s Terms of Use][5].


  [1]: https://iextrading.com/developer/docs/#chart
  [2]: https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average
  [3]: https://iextrading.com
  [4]: https://iextrading.com/developer
  [5]: https://iextrading.com/api-exhibit-a/",.csv,True
EOD data for all Dow Jones stocks,30,stock-data-dow-jones,CVX.csv,other,"### Update
Unfortunately, the API this dataset used to pull the stock data isn't free anymore. Instead of having this auto-updating, I dropped the last version of the data files in here, so at least the historic data is still usable.


### Content

This dataset provides free end of day data for all stocks currently in the Dow Jones Industrial Average. For each of the 30 components of the index, there is one CSV file named by the stock's symbol (e.g. AAPL for Apple). Each file provides historically adjusted market-wide data (daily, max. 5 years back). See here for description of the columns: [https://iextrading.com/developer/docs/#chart][1]

Since this dataset uses remote URLs as files, it is automatically updated daily by the Kaggle platform and automatically represents the latest data.

### Acknowledgements

List of stocks and symbols as per [https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average][2]

Thanks to [https://iextrading.com][3] for providing this data for free!

### Terms of Use

Data provided for free by [IEX][4]. View [IEX’s Terms of Use][5].


  [1]: https://iextrading.com/developer/docs/#chart
  [2]: https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average
  [3]: https://iextrading.com
  [4]: https://iextrading.com/developer
  [5]: https://iextrading.com/api-exhibit-a/",.csv,True
EOD data for all Dow Jones stocks,30,stock-data-dow-jones,NKE.csv,other,"### Update
Unfortunately, the API this dataset used to pull the stock data isn't free anymore. Instead of having this auto-updating, I dropped the last version of the data files in here, so at least the historic data is still usable.


### Content

This dataset provides free end of day data for all stocks currently in the Dow Jones Industrial Average. For each of the 30 components of the index, there is one CSV file named by the stock's symbol (e.g. AAPL for Apple). Each file provides historically adjusted market-wide data (daily, max. 5 years back). See here for description of the columns: [https://iextrading.com/developer/docs/#chart][1]

Since this dataset uses remote URLs as files, it is automatically updated daily by the Kaggle platform and automatically represents the latest data.

### Acknowledgements

List of stocks and symbols as per [https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average][2]

Thanks to [https://iextrading.com][3] for providing this data for free!

### Terms of Use

Data provided for free by [IEX][4]. View [IEX’s Terms of Use][5].


  [1]: https://iextrading.com/developer/docs/#chart
  [2]: https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average
  [3]: https://iextrading.com
  [4]: https://iextrading.com/developer
  [5]: https://iextrading.com/api-exhibit-a/",.csv,True
EOD data for all Dow Jones stocks,30,stock-data-dow-jones,IBM.csv,other,"### Update
Unfortunately, the API this dataset used to pull the stock data isn't free anymore. Instead of having this auto-updating, I dropped the last version of the data files in here, so at least the historic data is still usable.


### Content

This dataset provides free end of day data for all stocks currently in the Dow Jones Industrial Average. For each of the 30 components of the index, there is one CSV file named by the stock's symbol (e.g. AAPL for Apple). Each file provides historically adjusted market-wide data (daily, max. 5 years back). See here for description of the columns: [https://iextrading.com/developer/docs/#chart][1]

Since this dataset uses remote URLs as files, it is automatically updated daily by the Kaggle platform and automatically represents the latest data.

### Acknowledgements

List of stocks and symbols as per [https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average][2]

Thanks to [https://iextrading.com][3] for providing this data for free!

### Terms of Use

Data provided for free by [IEX][4]. View [IEX’s Terms of Use][5].


  [1]: https://iextrading.com/developer/docs/#chart
  [2]: https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average
  [3]: https://iextrading.com
  [4]: https://iextrading.com/developer
  [5]: https://iextrading.com/api-exhibit-a/",.csv,True
EOD data for all Dow Jones stocks,30,stock-data-dow-jones,GS.csv,other,"### Update
Unfortunately, the API this dataset used to pull the stock data isn't free anymore. Instead of having this auto-updating, I dropped the last version of the data files in here, so at least the historic data is still usable.


### Content

This dataset provides free end of day data for all stocks currently in the Dow Jones Industrial Average. For each of the 30 components of the index, there is one CSV file named by the stock's symbol (e.g. AAPL for Apple). Each file provides historically adjusted market-wide data (daily, max. 5 years back). See here for description of the columns: [https://iextrading.com/developer/docs/#chart][1]

Since this dataset uses remote URLs as files, it is automatically updated daily by the Kaggle platform and automatically represents the latest data.

### Acknowledgements

List of stocks and symbols as per [https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average][2]

Thanks to [https://iextrading.com][3] for providing this data for free!

### Terms of Use

Data provided for free by [IEX][4]. View [IEX’s Terms of Use][5].


  [1]: https://iextrading.com/developer/docs/#chart
  [2]: https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average
  [3]: https://iextrading.com
  [4]: https://iextrading.com/developer
  [5]: https://iextrading.com/api-exhibit-a/",.csv,True
EOD data for all Dow Jones stocks,30,stock-data-dow-jones,DIS.csv,other,"### Update
Unfortunately, the API this dataset used to pull the stock data isn't free anymore. Instead of having this auto-updating, I dropped the last version of the data files in here, so at least the historic data is still usable.


### Content

This dataset provides free end of day data for all stocks currently in the Dow Jones Industrial Average. For each of the 30 components of the index, there is one CSV file named by the stock's symbol (e.g. AAPL for Apple). Each file provides historically adjusted market-wide data (daily, max. 5 years back). See here for description of the columns: [https://iextrading.com/developer/docs/#chart][1]

Since this dataset uses remote URLs as files, it is automatically updated daily by the Kaggle platform and automatically represents the latest data.

### Acknowledgements

List of stocks and symbols as per [https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average][2]

Thanks to [https://iextrading.com][3] for providing this data for free!

### Terms of Use

Data provided for free by [IEX][4]. View [IEX’s Terms of Use][5].


  [1]: https://iextrading.com/developer/docs/#chart
  [2]: https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average
  [3]: https://iextrading.com
  [4]: https://iextrading.com/developer
  [5]: https://iextrading.com/api-exhibit-a/",.csv,True
EOD data for all Dow Jones stocks,30,stock-data-dow-jones,JPM.csv,other,"### Update
Unfortunately, the API this dataset used to pull the stock data isn't free anymore. Instead of having this auto-updating, I dropped the last version of the data files in here, so at least the historic data is still usable.


### Content

This dataset provides free end of day data for all stocks currently in the Dow Jones Industrial Average. For each of the 30 components of the index, there is one CSV file named by the stock's symbol (e.g. AAPL for Apple). Each file provides historically adjusted market-wide data (daily, max. 5 years back). See here for description of the columns: [https://iextrading.com/developer/docs/#chart][1]

Since this dataset uses remote URLs as files, it is automatically updated daily by the Kaggle platform and automatically represents the latest data.

### Acknowledgements

List of stocks and symbols as per [https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average][2]

Thanks to [https://iextrading.com][3] for providing this data for free!

### Terms of Use

Data provided for free by [IEX][4]. View [IEX’s Terms of Use][5].


  [1]: https://iextrading.com/developer/docs/#chart
  [2]: https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average
  [3]: https://iextrading.com
  [4]: https://iextrading.com/developer
  [5]: https://iextrading.com/api-exhibit-a/",.csv,True
EOD data for all Dow Jones stocks,30,stock-data-dow-jones,PFE.csv,other,"### Update
Unfortunately, the API this dataset used to pull the stock data isn't free anymore. Instead of having this auto-updating, I dropped the last version of the data files in here, so at least the historic data is still usable.


### Content

This dataset provides free end of day data for all stocks currently in the Dow Jones Industrial Average. For each of the 30 components of the index, there is one CSV file named by the stock's symbol (e.g. AAPL for Apple). Each file provides historically adjusted market-wide data (daily, max. 5 years back). See here for description of the columns: [https://iextrading.com/developer/docs/#chart][1]

Since this dataset uses remote URLs as files, it is automatically updated daily by the Kaggle platform and automatically represents the latest data.

### Acknowledgements

List of stocks and symbols as per [https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average][2]

Thanks to [https://iextrading.com][3] for providing this data for free!

### Terms of Use

Data provided for free by [IEX][4]. View [IEX’s Terms of Use][5].


  [1]: https://iextrading.com/developer/docs/#chart
  [2]: https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average
  [3]: https://iextrading.com
  [4]: https://iextrading.com/developer
  [5]: https://iextrading.com/api-exhibit-a/",.csv,True
EOD data for all Dow Jones stocks,30,stock-data-dow-jones,VZ.csv,other,"### Update
Unfortunately, the API this dataset used to pull the stock data isn't free anymore. Instead of having this auto-updating, I dropped the last version of the data files in here, so at least the historic data is still usable.


### Content

This dataset provides free end of day data for all stocks currently in the Dow Jones Industrial Average. For each of the 30 components of the index, there is one CSV file named by the stock's symbol (e.g. AAPL for Apple). Each file provides historically adjusted market-wide data (daily, max. 5 years back). See here for description of the columns: [https://iextrading.com/developer/docs/#chart][1]

Since this dataset uses remote URLs as files, it is automatically updated daily by the Kaggle platform and automatically represents the latest data.

### Acknowledgements

List of stocks and symbols as per [https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average][2]

Thanks to [https://iextrading.com][3] for providing this data for free!

### Terms of Use

Data provided for free by [IEX][4]. View [IEX’s Terms of Use][5].


  [1]: https://iextrading.com/developer/docs/#chart
  [2]: https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average
  [3]: https://iextrading.com
  [4]: https://iextrading.com/developer
  [5]: https://iextrading.com/api-exhibit-a/",.csv,True
EOD data for all Dow Jones stocks,30,stock-data-dow-jones,UNH.csv,other,"### Update
Unfortunately, the API this dataset used to pull the stock data isn't free anymore. Instead of having this auto-updating, I dropped the last version of the data files in here, so at least the historic data is still usable.


### Content

This dataset provides free end of day data for all stocks currently in the Dow Jones Industrial Average. For each of the 30 components of the index, there is one CSV file named by the stock's symbol (e.g. AAPL for Apple). Each file provides historically adjusted market-wide data (daily, max. 5 years back). See here for description of the columns: [https://iextrading.com/developer/docs/#chart][1]

Since this dataset uses remote URLs as files, it is automatically updated daily by the Kaggle platform and automatically represents the latest data.

### Acknowledgements

List of stocks and symbols as per [https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average][2]

Thanks to [https://iextrading.com][3] for providing this data for free!

### Terms of Use

Data provided for free by [IEX][4]. View [IEX’s Terms of Use][5].


  [1]: https://iextrading.com/developer/docs/#chart
  [2]: https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average
  [3]: https://iextrading.com
  [4]: https://iextrading.com/developer
  [5]: https://iextrading.com/api-exhibit-a/",.csv,True
EOD data for all Dow Jones stocks,30,stock-data-dow-jones,AAPL.csv,other,"### Update
Unfortunately, the API this dataset used to pull the stock data isn't free anymore. Instead of having this auto-updating, I dropped the last version of the data files in here, so at least the historic data is still usable.


### Content

This dataset provides free end of day data for all stocks currently in the Dow Jones Industrial Average. For each of the 30 components of the index, there is one CSV file named by the stock's symbol (e.g. AAPL for Apple). Each file provides historically adjusted market-wide data (daily, max. 5 years back). See here for description of the columns: [https://iextrading.com/developer/docs/#chart][1]

Since this dataset uses remote URLs as files, it is automatically updated daily by the Kaggle platform and automatically represents the latest data.

### Acknowledgements

List of stocks and symbols as per [https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average][2]

Thanks to [https://iextrading.com][3] for providing this data for free!

### Terms of Use

Data provided for free by [IEX][4]. View [IEX’s Terms of Use][5].


  [1]: https://iextrading.com/developer/docs/#chart
  [2]: https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average
  [3]: https://iextrading.com
  [4]: https://iextrading.com/developer
  [5]: https://iextrading.com/api-exhibit-a/",.csv,True
EOD data for all Dow Jones stocks,30,stock-data-dow-jones,WMT.csv,other,"### Update
Unfortunately, the API this dataset used to pull the stock data isn't free anymore. Instead of having this auto-updating, I dropped the last version of the data files in here, so at least the historic data is still usable.


### Content

This dataset provides free end of day data for all stocks currently in the Dow Jones Industrial Average. For each of the 30 components of the index, there is one CSV file named by the stock's symbol (e.g. AAPL for Apple). Each file provides historically adjusted market-wide data (daily, max. 5 years back). See here for description of the columns: [https://iextrading.com/developer/docs/#chart][1]

Since this dataset uses remote URLs as files, it is automatically updated daily by the Kaggle platform and automatically represents the latest data.

### Acknowledgements

List of stocks and symbols as per [https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average][2]

Thanks to [https://iextrading.com][3] for providing this data for free!

### Terms of Use

Data provided for free by [IEX][4]. View [IEX’s Terms of Use][5].


  [1]: https://iextrading.com/developer/docs/#chart
  [2]: https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average
  [3]: https://iextrading.com
  [4]: https://iextrading.com/developer
  [5]: https://iextrading.com/api-exhibit-a/",.csv,True
EOD data for all Dow Jones stocks,30,stock-data-dow-jones,TRV.csv,other,"### Update
Unfortunately, the API this dataset used to pull the stock data isn't free anymore. Instead of having this auto-updating, I dropped the last version of the data files in here, so at least the historic data is still usable.


### Content

This dataset provides free end of day data for all stocks currently in the Dow Jones Industrial Average. For each of the 30 components of the index, there is one CSV file named by the stock's symbol (e.g. AAPL for Apple). Each file provides historically adjusted market-wide data (daily, max. 5 years back). See here for description of the columns: [https://iextrading.com/developer/docs/#chart][1]

Since this dataset uses remote URLs as files, it is automatically updated daily by the Kaggle platform and automatically represents the latest data.

### Acknowledgements

List of stocks and symbols as per [https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average][2]

Thanks to [https://iextrading.com][3] for providing this data for free!

### Terms of Use

Data provided for free by [IEX][4]. View [IEX’s Terms of Use][5].


  [1]: https://iextrading.com/developer/docs/#chart
  [2]: https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average
  [3]: https://iextrading.com
  [4]: https://iextrading.com/developer
  [5]: https://iextrading.com/api-exhibit-a/",.csv,True
EOD data for all Dow Jones stocks,30,stock-data-dow-jones,JNJ.csv,other,"### Update
Unfortunately, the API this dataset used to pull the stock data isn't free anymore. Instead of having this auto-updating, I dropped the last version of the data files in here, so at least the historic data is still usable.


### Content

This dataset provides free end of day data for all stocks currently in the Dow Jones Industrial Average. For each of the 30 components of the index, there is one CSV file named by the stock's symbol (e.g. AAPL for Apple). Each file provides historically adjusted market-wide data (daily, max. 5 years back). See here for description of the columns: [https://iextrading.com/developer/docs/#chart][1]

Since this dataset uses remote URLs as files, it is automatically updated daily by the Kaggle platform and automatically represents the latest data.

### Acknowledgements

List of stocks and symbols as per [https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average][2]

Thanks to [https://iextrading.com][3] for providing this data for free!

### Terms of Use

Data provided for free by [IEX][4]. View [IEX’s Terms of Use][5].


  [1]: https://iextrading.com/developer/docs/#chart
  [2]: https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average
  [3]: https://iextrading.com
  [4]: https://iextrading.com/developer
  [5]: https://iextrading.com/api-exhibit-a/",.csv,True
Earthquake dataset,2,earthquake-dataset,earthquake_1995-2023.csv,CC0-1.0,"Datasets contain records of 782 earthquakes from 1/1/2001 to 1/1/2023. The meaning of all columns is as follows:

- title: title name given to the earthquake
- magnitude: The magnitude of the earthquake
- date_time: date and time
- cdi: The maximum reported intensity for the event range
- mmi: The maximum estimated instrumental intensity for the event
- alert: The alert level - “green”, “yellow”, “orange”, and “red”
- tsunami: ""1"" for events in oceanic regions and ""0"" otherwise
- sig: A number describing how significant the event is. Larger numbers indicate a more significant event. This value is determined on a number of factors, including: magnitude, maximum MMI, felt reports, and estimated impact
- net: The ID of a data contributor. Identifies the network considered to be the preferred source of information for this event.
- nst: The total number of seismic stations used to determine earthquake location.
- dmin: Horizontal distance from the epicenter to the nearest station
- gap: The largest azimuthal gap between azimuthally adjacent stations (in degrees). In general, the smaller this number, the more reliable is the calculated horizontal position of the earthquake. Earthquake locations in which the azimuthal gap exceeds 180 degrees typically have large location and depth uncertainties
- magType: The method or algorithm used to calculate the preferred magnitude for the event
- depth: The depth where the earthquake begins to rupture
- latitude / longitude: coordinate system by means of which the position or location of any place on Earth's surface can be determined and described
- location: location within the country
- continent: continent of the earthquake hit country
- country: affected country",.csv,True
Earthquake dataset,2,earthquake-dataset,earthquake_data.csv,CC0-1.0,"Datasets contain records of 782 earthquakes from 1/1/2001 to 1/1/2023. The meaning of all columns is as follows:

- title: title name given to the earthquake
- magnitude: The magnitude of the earthquake
- date_time: date and time
- cdi: The maximum reported intensity for the event range
- mmi: The maximum estimated instrumental intensity for the event
- alert: The alert level - “green”, “yellow”, “orange”, and “red”
- tsunami: ""1"" for events in oceanic regions and ""0"" otherwise
- sig: A number describing how significant the event is. Larger numbers indicate a more significant event. This value is determined on a number of factors, including: magnitude, maximum MMI, felt reports, and estimated impact
- net: The ID of a data contributor. Identifies the network considered to be the preferred source of information for this event.
- nst: The total number of seismic stations used to determine earthquake location.
- dmin: Horizontal distance from the epicenter to the nearest station
- gap: The largest azimuthal gap between azimuthally adjacent stations (in degrees). In general, the smaller this number, the more reliable is the calculated horizontal position of the earthquake. Earthquake locations in which the azimuthal gap exceeds 180 degrees typically have large location and depth uncertainties
- magType: The method or algorithm used to calculate the preferred magnitude for the event
- depth: The depth where the earthquake begins to rupture
- latitude / longitude: coordinate system by means of which the position or location of any place on Earth's surface can be determined and described
- location: location within the country
- continent: continent of the earthquake hit country
- country: affected country",.csv,True
Emotion Classification NLP,3,emotion-classification-nlp,emotion-labels-test.csv,CC0-1.0,"### Context

Identifying emotions has become an integral part of many NLP and data science projects. With the help of this dataset, one can train and build various robust models and perform emotional analysis.  


### Content

Manual annotation of the dataset to obtain real-valued scores was done through Best-Worst Scaling (BWS), an annotation scheme shown to obtain very reliable scores (Kiritchenko and Mohammad, 2016). The data is then split into a training set and a test set. 


### Acknowledgements

WASSA-2017 Shared Task on Emotion Intensity. Saif M. Mohammad and Felipe Bravo-Marquez. In Proceedings of the EMNLP 2017 Workshop on Computational Approaches to Subjectivity, Sentiment, and Social Media (WASSA), September 2017, Copenhagen, Denmark.
BibTex

### Inspiration

Can't wait to see some awesome models based on this data",.csv,True
Emotion Classification NLP,3,emotion-classification-nlp,emotion-labels-val.csv,CC0-1.0,"### Context

Identifying emotions has become an integral part of many NLP and data science projects. With the help of this dataset, one can train and build various robust models and perform emotional analysis.  


### Content

Manual annotation of the dataset to obtain real-valued scores was done through Best-Worst Scaling (BWS), an annotation scheme shown to obtain very reliable scores (Kiritchenko and Mohammad, 2016). The data is then split into a training set and a test set. 


### Acknowledgements

WASSA-2017 Shared Task on Emotion Intensity. Saif M. Mohammad and Felipe Bravo-Marquez. In Proceedings of the EMNLP 2017 Workshop on Computational Approaches to Subjectivity, Sentiment, and Social Media (WASSA), September 2017, Copenhagen, Denmark.
BibTex

### Inspiration

Can't wait to see some awesome models based on this data",.csv,True
Emotion Classification NLP,3,emotion-classification-nlp,emotion-labels-train.csv,CC0-1.0,"### Context

Identifying emotions has become an integral part of many NLP and data science projects. With the help of this dataset, one can train and build various robust models and perform emotional analysis.  


### Content

Manual annotation of the dataset to obtain real-valued scores was done through Best-Worst Scaling (BWS), an annotation scheme shown to obtain very reliable scores (Kiritchenko and Mohammad, 2016). The data is then split into a training set and a test set. 


### Acknowledgements

WASSA-2017 Shared Task on Emotion Intensity. Saif M. Mohammad and Felipe Bravo-Marquez. In Proceedings of the EMNLP 2017 Workshop on Computational Approaches to Subjectivity, Sentiment, and Social Media (WASSA), September 2017, Copenhagen, Denmark.
BibTex

### Inspiration

Can't wait to see some awesome models based on this data",.csv,True
Emotion Dataset,3,emotion-dataset,validation.csv,Apache 2.0,"**Overview:**
This Emotion Classification dataset is designed to facilitate research and experimentation in the field of natural language processing and emotion analysis. It contains a diverse collection of text samples, each labeled with the corresponding emotion it conveys. Emotions can range from happiness and excitement to anger, sadness, and more.

**Content:**
Format: CSV
Labels: ['anger', 'joy', 'fear']

**Use Cases:**
Sentiment analysis
Emotion classification
Emotion-aware applications
Customer feedback analysis
Social media sentiment monitoring
Chatbot and virtual assistant training",.csv,True
Emotion Dataset,3,emotion-dataset,training.csv,Apache 2.0,"**Overview:**
This Emotion Classification dataset is designed to facilitate research and experimentation in the field of natural language processing and emotion analysis. It contains a diverse collection of text samples, each labeled with the corresponding emotion it conveys. Emotions can range from happiness and excitement to anger, sadness, and more.

**Content:**
Format: CSV
Labels: ['anger', 'joy', 'fear']

**Use Cases:**
Sentiment analysis
Emotion classification
Emotion-aware applications
Customer feedback analysis
Social media sentiment monitoring
Chatbot and virtual assistant training",.csv,True
Emotion Dataset,3,emotion-dataset,test.csv,Apache 2.0,"**Overview:**
This Emotion Classification dataset is designed to facilitate research and experimentation in the field of natural language processing and emotion analysis. It contains a diverse collection of text samples, each labeled with the corresponding emotion it conveys. Emotions can range from happiness and excitement to anger, sadness, and more.

**Content:**
Format: CSV
Labels: ['anger', 'joy', 'fear']

**Use Cases:**
Sentiment analysis
Emotion classification
Emotion-aware applications
Customer feedback analysis
Social media sentiment monitoring
Chatbot and virtual assistant training",.csv,True
English/Arabic Phishing Email Corpus,2,englisharabic-phishing-email-corpus,phishing-bilingual.csv,CC-BY-NC-SA-4.0,"This dataset is a balanced collection of 300 emails, equally divided between Arabic phishing attempts and legitimate messages, meticulously compiled through snowball sampling for enhanced research and analysis in cybersecuri",.csv,True
English/Arabic Phishing Email Corpus,2,englisharabic-phishing-email-corpus,legit-bilingual.csv,CC-BY-NC-SA-4.0,"This dataset is a balanced collection of 300 emails, equally divided between Arabic phishing attempts and legitimate messages, meticulously compiled through snowball sampling for enhanced research and analysis in cybersecuri",.csv,True
Ethereum(ETH-USD) Price History,2,ethereumeth-usd-price-history,ETH-USD.csv,Apache 2.0,"This dataset shows the price of Ethereum over time, collected using Yahoo Finance API. It's useful for people who want to study Ethereum's past prices to make decisions about buying or selling. You can use it to see how Ethereum's price changed over the years and find patterns in the data. Whether you're a researcher, investor, or just curious about cryptocurrency, this dataset gives you valuable information to explore Ethereum's market history.",.csv,True
Ethereum(ETH-USD) Price History,2,ethereumeth-usd-price-history,ETH_USD.csv,Apache 2.0,"This dataset shows the price of Ethereum over time, collected using Yahoo Finance API. It's useful for people who want to study Ethereum's past prices to make decisions about buying or selling. You can use it to see how Ethereum's price changed over the years and find patterns in the data. Whether you're a researcher, investor, or just curious about cryptocurrency, this dataset gives you valuable information to explore Ethereum's market history.",.csv,True
FAANG- Complete Stock Data,5,faang-complete-stock-data,Google.csv,CC0-1.0,"### Context
There are a few companies that are considered to be revolutionary. These companies also happen to be a dream place to work at for many many people across the world. These companies include - Facebook,Amazon,Apple,Netflix and Google also known as FAANG! These companies make ton of money and they help others too by giving them a chance to invest in the companies via stocks and shares. This data wass made targeting these stock prices.

### Content
The data contains information such as opening price of a stock, closing price, how much of these stocks were sold and many more things. There are 5 different CSV files in the data for each company. ",.csv,True
FAANG- Complete Stock Data,5,faang-complete-stock-data,Facebook.csv,CC0-1.0,"### Context
There are a few companies that are considered to be revolutionary. These companies also happen to be a dream place to work at for many many people across the world. These companies include - Facebook,Amazon,Apple,Netflix and Google also known as FAANG! These companies make ton of money and they help others too by giving them a chance to invest in the companies via stocks and shares. This data wass made targeting these stock prices.

### Content
The data contains information such as opening price of a stock, closing price, how much of these stocks were sold and many more things. There are 5 different CSV files in the data for each company. ",.csv,True
FAANG- Complete Stock Data,5,faang-complete-stock-data,Amazon.csv,CC0-1.0,"### Context
There are a few companies that are considered to be revolutionary. These companies also happen to be a dream place to work at for many many people across the world. These companies include - Facebook,Amazon,Apple,Netflix and Google also known as FAANG! These companies make ton of money and they help others too by giving them a chance to invest in the companies via stocks and shares. This data wass made targeting these stock prices.

### Content
The data contains information such as opening price of a stock, closing price, how much of these stocks were sold and many more things. There are 5 different CSV files in the data for each company. ",.csv,True
FAANG- Complete Stock Data,5,faang-complete-stock-data,Apple.csv,CC0-1.0,"### Context
There are a few companies that are considered to be revolutionary. These companies also happen to be a dream place to work at for many many people across the world. These companies include - Facebook,Amazon,Apple,Netflix and Google also known as FAANG! These companies make ton of money and they help others too by giving them a chance to invest in the companies via stocks and shares. This data wass made targeting these stock prices.

### Content
The data contains information such as opening price of a stock, closing price, how much of these stocks were sold and many more things. There are 5 different CSV files in the data for each company. ",.csv,True
FAANG- Complete Stock Data,5,faang-complete-stock-data,Netflix.csv,CC0-1.0,"### Context
There are a few companies that are considered to be revolutionary. These companies also happen to be a dream place to work at for many many people across the world. These companies include - Facebook,Amazon,Apple,Netflix and Google also known as FAANG! These companies make ton of money and they help others too by giving them a chance to invest in the companies via stocks and shares. This data wass made targeting these stock prices.

### Content
The data contains information such as opening price of a stock, closing price, how much of these stocks were sold and many more things. There are 5 different CSV files in the data for each company. ",.csv,True
FEM simulations,3,fem-simulations,40semi-randoms.csv,CC0-1.0,"### Context

Engineers use numerical models to analyze the behavior of the systems they are studying. By means of numerical models you can prove whether a design is safe or not, instead of making a prototype and testing it. This gives you great flexibility to modify parameters and to find a cheaper design that satisfies all the safety requirements.

But when the models are too complex, the numerical simulations can easily last from a few hours to a few days. In addition, during the optimization process you might need a few tens of trials. So in order to simplify the process we can build a simple 'surrogate' model that yields similar results to the original one. Here's when Machine Learning comes in!

### Content

The dataset contains the data of about 6000 numerical simulations (finite element models, FEM). It must be pointed out that there is no noise in the data, that is, if we run again the simulations we'd get the same results. There are 9 input parameters and 4 output results.

Inputs (continuous and positive values):
(1) load parameters: ecc, N, gammaG.
(2) material parameters: Esoil, Econc.
(3) geometry parameters: Dbot, H1, H2, H3.

Outputs (continuous values):
(1)  stress related results: Mr_t, Mt_t, Mr_c, Mt_c.

### Acknowledgements

The parametric numerical model was self-made.

### Inspiration

The data comes from deterministic numerical simulations. Under this circumstance, is there any way we can find a regression model that gives accurate results? Let's say something like 5% error (True_value / Predicted_value within the range of [0.95, 1.05]).

What would be the most appropriate regression algorithms? What accuracy can we expect?",.csv,True
FEM simulations,3,fem-simulations,5184doe.csv,CC0-1.0,"### Context

Engineers use numerical models to analyze the behavior of the systems they are studying. By means of numerical models you can prove whether a design is safe or not, instead of making a prototype and testing it. This gives you great flexibility to modify parameters and to find a cheaper design that satisfies all the safety requirements.

But when the models are too complex, the numerical simulations can easily last from a few hours to a few days. In addition, during the optimization process you might need a few tens of trials. So in order to simplify the process we can build a simple 'surrogate' model that yields similar results to the original one. Here's when Machine Learning comes in!

### Content

The dataset contains the data of about 6000 numerical simulations (finite element models, FEM). It must be pointed out that there is no noise in the data, that is, if we run again the simulations we'd get the same results. There are 9 input parameters and 4 output results.

Inputs (continuous and positive values):
(1) load parameters: ecc, N, gammaG.
(2) material parameters: Esoil, Econc.
(3) geometry parameters: Dbot, H1, H2, H3.

Outputs (continuous values):
(1)  stress related results: Mr_t, Mt_t, Mr_c, Mt_c.

### Acknowledgements

The parametric numerical model was self-made.

### Inspiration

The data comes from deterministic numerical simulations. Under this circumstance, is there any way we can find a regression model that gives accurate results? Let's say something like 5% error (True_value / Predicted_value within the range of [0.95, 1.05]).

What would be the most appropriate regression algorithms? What accuracy can we expect?",.csv,True
FEM simulations,3,fem-simulations,1000randoms.csv,CC0-1.0,"### Context

Engineers use numerical models to analyze the behavior of the systems they are studying. By means of numerical models you can prove whether a design is safe or not, instead of making a prototype and testing it. This gives you great flexibility to modify parameters and to find a cheaper design that satisfies all the safety requirements.

But when the models are too complex, the numerical simulations can easily last from a few hours to a few days. In addition, during the optimization process you might need a few tens of trials. So in order to simplify the process we can build a simple 'surrogate' model that yields similar results to the original one. Here's when Machine Learning comes in!

### Content

The dataset contains the data of about 6000 numerical simulations (finite element models, FEM). It must be pointed out that there is no noise in the data, that is, if we run again the simulations we'd get the same results. There are 9 input parameters and 4 output results.

Inputs (continuous and positive values):
(1) load parameters: ecc, N, gammaG.
(2) material parameters: Esoil, Econc.
(3) geometry parameters: Dbot, H1, H2, H3.

Outputs (continuous values):
(1)  stress related results: Mr_t, Mt_t, Mr_c, Mt_c.

### Acknowledgements

The parametric numerical model was self-made.

### Inspiration

The data comes from deterministic numerical simulations. Under this circumstance, is there any way we can find a regression model that gives accurate results? Let's say something like 5% error (True_value / Predicted_value within the range of [0.95, 1.05]).

What would be the most appropriate regression algorithms? What accuracy can we expect?",.csv,True
FIFA World Ranking 1992-2024,2,fifaworldranking,fifa_ranking-2024-04-04.csv,CC0-1.0,"### Context

I did not find dataset with data after FIFA WORLD CUP 2018 and fix it :)


### Content

##### Base table ""fifa_ranking-LASTDATE""
- **country_full** — country full name
- **country_abrv** — country abbreviation
- **rank** — current country rank
- **total_points** — current total points
- **previous_points** — total points in last rating
- **rank_change** — how rank has changed since the last publication
- **confederation** — FIFA confederations
- **rank_date** — date of rating calculation

&gt; column ID has been deleted from source",.csv,True
FIFA World Ranking 1992-2024,2,fifaworldranking,fifa_ranking-2023-07-20.csv,CC0-1.0,"### Context

I did not find dataset with data after FIFA WORLD CUP 2018 and fix it :)


### Content

##### Base table ""fifa_ranking-LASTDATE""
- **country_full** — country full name
- **country_abrv** — country abbreviation
- **rank** — current country rank
- **total_points** — current total points
- **previous_points** — total points in last rating
- **rank_change** — how rank has changed since the last publication
- **confederation** — FIFA confederations
- **rank_date** — date of rating calculation

&gt; column ID has been deleted from source",.csv,True
FOREXDATA-OHLC,2,ohlc-eurusd,EURUSDOHLC.csv,MIT,"This simple dataset was taken from MetaTrader5  containing EUR USD and NASDAQ price information such as the open, high, low, and close from one hour timeframe",.csv,True
FOREXDATA-OHLC,2,ohlc-eurusd,NAS100OHLC.csv,MIT,"This simple dataset was taken from MetaTrader5  containing EUR USD and NASDAQ price information such as the open, high, low, and close from one hour timeframe",.csv,True
Fake News football,2,fake-news-football,fake.csv,other,"## Abstract💡
* A king of yellow journalism, fake news is false information and hoaxes spread through social media and other online media to achieve a political agenda


## About this dataset 📭
* The dataset contains 20,000 real news and 20,000 fake news
* The dataset is collected from Twitter and Youm7


## Goal of creating this Dataset🎯

* Building a classification model that can accurately detect whether the news is real or fake.




### Hint
- Most data about an Egyptian league


",.csv,True
Fake News football,2,fake-news-football,real.csv,other,"## Abstract💡
* A king of yellow journalism, fake news is false information and hoaxes spread through social media and other online media to achieve a political agenda


## About this dataset 📭
* The dataset contains 20,000 real news and 20,000 fake news
* The dataset is collected from Twitter and Youm7


## Goal of creating this Dataset🎯

* Building a classification model that can accurately detect whether the news is real or fake.




### Hint
- Most data about an Egyptian league


",.csv,True
Fashion MNIST,2,fashionmnist,fashion-mnist_test.csv,other,"### Context

Fashion-MNIST is a dataset of Zalando's article images—consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Zalando intends Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.

The original MNIST dataset contains a lot of handwritten digits. Members of the AI/ML/Data Science community love this dataset and use it as a benchmark to validate their algorithms. In fact, MNIST is often the first dataset researchers try. ""If it doesn't work on MNIST, it won't work at all"", they said. ""Well, if it does work on MNIST, it may still fail on others.""

Zalando seeks to replace the original MNIST dataset

### Content

Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255. The training and test data sets have 785 columns. The first column consists of the class labels (see above), and represents the article of clothing. The rest of the columns contain the pixel-values of the associated image.

- To locate a pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27. The pixel is located on row i and column j of a 28 x 28 matrix. 
- For example, pixel31 indicates the pixel that is in the fourth column from the left, and the second row from the top, as in the ascii-diagram below.
<br><br>


**Labels**

Each training and test example is assigned to one of the following labels:

- 0	T-shirt/top
- 1	Trouser
- 2	Pullover
- 3	Dress
- 4	Coat
- 5	Sandal
- 6	Shirt
- 7	Sneaker
- 8	Bag
- 9	Ankle boot
<br><br>

TL;DR

- Each row is a separate image  
- Column 1 is the class label. 
- Remaining columns are pixel numbers (784 total). 
- Each value is the darkness of the pixel (1 to 255)

### Acknowledgements

- Original dataset was downloaded from [https://github.com/zalandoresearch/fashion-mnist][1]

- Dataset was converted to CSV with this script: [https://pjreddie.com/projects/mnist-in-csv/][2]

### License

The MIT License (MIT) Copyright © [2017] Zalando SE, https://tech.zalando.com

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

  [1]: https://github.com/zalandoresearch/fashion-mnist
  [2]: https://pjreddie.com/projects/mnist-in-csv/",.csv,True
Fashion MNIST,2,fashionmnist,fashion-mnist_train.csv,other,"### Context

Fashion-MNIST is a dataset of Zalando's article images—consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Zalando intends Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.

The original MNIST dataset contains a lot of handwritten digits. Members of the AI/ML/Data Science community love this dataset and use it as a benchmark to validate their algorithms. In fact, MNIST is often the first dataset researchers try. ""If it doesn't work on MNIST, it won't work at all"", they said. ""Well, if it does work on MNIST, it may still fail on others.""

Zalando seeks to replace the original MNIST dataset

### Content

Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255. The training and test data sets have 785 columns. The first column consists of the class labels (see above), and represents the article of clothing. The rest of the columns contain the pixel-values of the associated image.

- To locate a pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27. The pixel is located on row i and column j of a 28 x 28 matrix. 
- For example, pixel31 indicates the pixel that is in the fourth column from the left, and the second row from the top, as in the ascii-diagram below.
<br><br>


**Labels**

Each training and test example is assigned to one of the following labels:

- 0	T-shirt/top
- 1	Trouser
- 2	Pullover
- 3	Dress
- 4	Coat
- 5	Sandal
- 6	Shirt
- 7	Sneaker
- 8	Bag
- 9	Ankle boot
<br><br>

TL;DR

- Each row is a separate image  
- Column 1 is the class label. 
- Remaining columns are pixel numbers (784 total). 
- Each value is the darkness of the pixel (1 to 255)

### Acknowledgements

- Original dataset was downloaded from [https://github.com/zalandoresearch/fashion-mnist][1]

- Dataset was converted to CSV with this script: [https://pjreddie.com/projects/mnist-in-csv/][2]

### License

The MIT License (MIT) Copyright © [2017] Zalando SE, https://tech.zalando.com

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

  [1]: https://github.com/zalandoresearch/fashion-mnist
  [2]: https://pjreddie.com/projects/mnist-in-csv/",.csv,True
Fast Food Nutrition,2,fast-food,FastFoodNutritionMenuV3.csv,DbCL-1.0,"Nutritional values, including Calories and Micro-nutrients from six of the largest and most popular fast food restaurants:

- McDonald's
- Burger King
- Wendy's
- Kentucky Fried Chicken (KFC)
- Taco Bell
- Pizza Hut

**Attributes include**: Calories, Calories from Fat, Total Fat, Saturated Fat, Trans Fat, Cholesterol, Sodium, Carbs, Fiber, Sugars, Protein, and Weight Watchers Points (where available).",.csv,True
Fast Food Nutrition,2,fast-food,FastFoodNutritionMenuV2.csv,DbCL-1.0,"Nutritional values, including Calories and Micro-nutrients from six of the largest and most popular fast food restaurants:

- McDonald's
- Burger King
- Wendy's
- Kentucky Fried Chicken (KFC)
- Taco Bell
- Pizza Hut

**Attributes include**: Calories, Calories from Fat, Total Fat, Saturated Fat, Trans Fat, Cholesterol, Sodium, Carbs, Fiber, Sugars, Protein, and Weight Watchers Points (where available).",.csv,True
Flipkart Mobiles Dataset,2,flipkart-mobiles-dataset,Flipkart_Mobiles.csv,CC0-1.0,"**Flipkart Mobiles Dataset**
---
This dataset containing specs of various Mobile brands in India has been scraped from an ecommerce website 'Flipkart'. This dataset has 3114 samples with 8 attributes. There are some missing values as well.

Attributes-
1. Brand- Name of the Mobile Manufacturer
2. Model- Model number of the Mobile Phone
3. Color- Color of the model. 
4. Memory - RAM of the model (4GB,6GB,8GB, etc.)
5. Storage- ROM of the model (32GB,64GB,128GB,256GB, etc.)
6. Rating- Rating of the model based on reviews (out of 5). Missing or Null values indicate there are no ratings present for the model. 
7. Selling Price- Selling Price/Discounted Price of the model in INR when this data was scraped. Ideally price indicates the discounted price of the model
8. Original Price- Actual price of the model in INR. Missing values or null values would indicate that the product is being sold at the actual price available in the 'Price' column.

---
Inspiration-
You can use this dataset to answer some interesting questions like-
*   Different Price range segments for mobiles in India
*   Brand with most product offerings for the Indian Market
*   Brand catering to all different segments (low range, mid range, premium - *an additional data column would be required to sort the data in the above segments)
* Most common specs offered by various brands (eg. if 4 GB memory and 64GB storage models are more commonly offered by all brands)
*   Compare premium offerings by top brands
*   Most commonly offered colors by all Brands
*   Compare Two Brands based on specs
*   Are higher rated mobiles always premium or expensive?
*   Does a brand have better than 4 ratings for all its products?
*   and so on...",.csv,True
Flipkart Mobiles Dataset,2,flipkart-mobiles-dataset,Flipkart_mobile_brands_scraped_data.csv,CC0-1.0,"**Flipkart Mobiles Dataset**
---
This dataset containing specs of various Mobile brands in India has been scraped from an ecommerce website 'Flipkart'. This dataset has 3114 samples with 8 attributes. There are some missing values as well.

Attributes-
1. Brand- Name of the Mobile Manufacturer
2. Model- Model number of the Mobile Phone
3. Color- Color of the model. 
4. Memory - RAM of the model (4GB,6GB,8GB, etc.)
5. Storage- ROM of the model (32GB,64GB,128GB,256GB, etc.)
6. Rating- Rating of the model based on reviews (out of 5). Missing or Null values indicate there are no ratings present for the model. 
7. Selling Price- Selling Price/Discounted Price of the model in INR when this data was scraped. Ideally price indicates the discounted price of the model
8. Original Price- Actual price of the model in INR. Missing values or null values would indicate that the product is being sold at the actual price available in the 'Price' column.

---
Inspiration-
You can use this dataset to answer some interesting questions like-
*   Different Price range segments for mobiles in India
*   Brand with most product offerings for the Indian Market
*   Brand catering to all different segments (low range, mid range, premium - *an additional data column would be required to sort the data in the above segments)
* Most common specs offered by various brands (eg. if 4 GB memory and 64GB storage models are more commonly offered by all brands)
*   Compare premium offerings by top brands
*   Most commonly offered colors by all Brands
*   Compare Two Brands based on specs
*   Are higher rated mobiles always premium or expensive?
*   Does a brand have better than 4 ratings for all its products?
*   and so on...",.csv,True
Food Prices for Nutrition,2,food-prices-for-nutrition,2bca3f30-534f-4246-a0ad-15f6e16018bb_Data.csv,Apache 2.0,"Food Prices for Nutrition provides indicators on the cost and affordability of healthy diets in each country, showing the population’s physical and economic access to sufficient quantities of locally available items for an active and healthy life. It also provides indicators on the cost and affordability of an energy-sufficient diet and a nutrient-adequate diet. These indicators are explained in detail in the Food Prices for Nutrition DataHub here: https://www.worldbank.org/foodpricesfornutrition. ",.csv,True
Food Prices for Nutrition,2,food-prices-for-nutrition,2bca3f30-534f-4246-a0ad-15f6e16018bb_Series - Metadata.csv,Apache 2.0,"Food Prices for Nutrition provides indicators on the cost and affordability of healthy diets in each country, showing the population’s physical and economic access to sufficient quantities of locally available items for an active and healthy life. It also provides indicators on the cost and affordability of an energy-sufficient diet and a nutrient-adequate diet. These indicators are explained in detail in the Food Prices for Nutrition DataHub here: https://www.worldbank.org/foodpricesfornutrition. ",.csv,True
GICS - Global Industry Classification Standard,2,gics-global-industry-classification-standard,gics-map-2018.csv,CC-BY-NC-SA-4.0,"The [Global Industry Classification Standard (GICS)](https://en.wikipedia.org/wiki/Global_Industry_Classification_Standard) is an industry taxonomy developed in 1999 by MSCI and Standard & Poor's (S&P) for use by the global financial community. The GICS structure consists of 

* 11 sectors
* 25 industry groups, 
* 74 industries
* 163 sub-industries into which S&P has categorized all major public companies. 

The system is similar to ICB (Industry Classification Benchmark), a classification structure maintained by FTSE Group.

GICS is used as a basis for S&P and MSCI financial market indexes in which each company is assigned to a sub-industry, and to an industry, industry group, and sector, by its principal business activity.

""GICS"" is a registered trademark of McGraw Hill Financial and MSCI Inc.

The GICS schema follows this hierarchy:
```
  - Sector
         - Industry Group
                - Industry
                       - Sub-industry
```

That is, a sector is composed by industry groups, which are composed by industries which are composed by sub-industries. 

Each item in the hierarchy has an id. Each ids are prefixed by the id of the parent in the hierarchy and generally the number of the ids are increased by 5 or 10. For example the Sector  Industrials has the id `20`, the Industry group `Capital Goods` has the id is prefixed by that `20`, resulting in `2010`.


# Dataset 

The dataset is composed by CSV files (**currently 2 files**). Each representing a different version of the GICS classification.

For each file the columns are:

* SectorId (2 digits)
* Sector (string)
* IndustryGroupId (4 digits)
* IndustryGroup (string)
* IndustryId (7 digits)
* Industry (string)
* SubIndustryId (10 digits) 
* SubIndustry (string)
* SubIndustryDescription (string)

## References
* https://en.wikipedia.org/wiki/Global_Industry_Classification_Standard
* https://www.msci.com/our-solutions/indexes/gics",.csv,True
GICS - Global Industry Classification Standard,2,gics-global-industry-classification-standard,gics-map-2023.csv,CC-BY-NC-SA-4.0,"The [Global Industry Classification Standard (GICS)](https://en.wikipedia.org/wiki/Global_Industry_Classification_Standard) is an industry taxonomy developed in 1999 by MSCI and Standard & Poor's (S&P) for use by the global financial community. The GICS structure consists of 

* 11 sectors
* 25 industry groups, 
* 74 industries
* 163 sub-industries into which S&P has categorized all major public companies. 

The system is similar to ICB (Industry Classification Benchmark), a classification structure maintained by FTSE Group.

GICS is used as a basis for S&P and MSCI financial market indexes in which each company is assigned to a sub-industry, and to an industry, industry group, and sector, by its principal business activity.

""GICS"" is a registered trademark of McGraw Hill Financial and MSCI Inc.

The GICS schema follows this hierarchy:
```
  - Sector
         - Industry Group
                - Industry
                       - Sub-industry
```

That is, a sector is composed by industry groups, which are composed by industries which are composed by sub-industries. 

Each item in the hierarchy has an id. Each ids are prefixed by the id of the parent in the hierarchy and generally the number of the ids are increased by 5 or 10. For example the Sector  Industrials has the id `20`, the Industry group `Capital Goods` has the id is prefixed by that `20`, resulting in `2010`.


# Dataset 

The dataset is composed by CSV files (**currently 2 files**). Each representing a different version of the GICS classification.

For each file the columns are:

* SectorId (2 digits)
* Sector (string)
* IndustryGroupId (4 digits)
* IndustryGroup (string)
* IndustryId (7 digits)
* Industry (string)
* SubIndustryId (10 digits) 
* SubIndustry (string)
* SubIndustryDescription (string)

## References
* https://en.wikipedia.org/wiki/Global_Industry_Classification_Standard
* https://www.msci.com/our-solutions/indexes/gics",.csv,True
GSM8K - Grade School Math 8K Q&A,4,grade-school-math-8k-q-a,socratic_train.csv,CC0-1.0,"_____
# GSM8K - Grade School Math 8K Q&A
### A Linguistically Diverse Dataset for Multi-Step Reasoning Question Answering
By Huggingface Hub [[source]](https://huggingface.co/datasets/gsm8k)
_____

### About this dataset
&gt; This Grade School Math 8K Linguistically Diverse Training & Test Set is designed to help you develop and improve your understanding of multi-step reasoning question answering. The dataset contains three separate data files: the socratic_test.csv, main_test.csv, and main_train.csv, each containing a set of questions and answers related to grade school math that consists of multiple steps. Each file contains the same columns: ```question```, ```answer```. The questions contained in this dataset are thoughtfully crafted to lead you through the reasoning journey for arriving at the correct answer each time, allowing you immense opportunities for learning through practice. With over 8 thousand entries for both training and testing purposes in this GSM8K dataset, it takes advanced multi-step reasoning skills to ace these questions! Deepen your knowledge today and master any challenge with ease using this amazing GSM8K set!

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; This dataset provides a unique opportunity to study multi-step reasoning for question answering. The GSM8K Linguistically Diverse Training & Test Set consists of 8,000 questions and answers that have been created to simulate real-world scenarios in grade school mathematics. Each question is paired with one answer based on a comprehensive test set. The questions cover topics such as algebra, arithmetic, probability and more. 
&gt; 
&gt; The dataset consists of two files: main_train.csv and main_test.csv; the former contains questions and answers specifically related to grade school math while the latter includes multi-step reasoning tests for each category of the Ontario Math Curriculum (OMC). In addition, it has three columns -  Question (**Question), Answer ([**Answer]) – meaning that each row contains 3 sequential question/answer pairs making it possible to take a single path from the start of any given answer or branch out from there according to the logic construction required by each respective problem scenario; these columns can be used in combination with text analysis algorithms like ELMo or BERT to explore different formats of representation for responding accurately during natural language processing tasks such as Q&A or building predictive models for numerical data applications like measuring classifying resource efficiency initiatives or forecasting sales volumes in retail platforms..  
&gt; 
&gt; To use this dataset efficiently you should first get familiar with its structure by reading through its documentation so you are aware all available info regarding items content definition & format requirements then study examples that best suits your specific purpose whether is performing an experiment inspired by education research needs, generate insights related marketing analytics reports making predictions over artificial intelligence project capacity improvements optimization gains etcetera having full access knowledge about available source keeps you up & running from preliminary background work toward knowledge mining endeavor completion success Support User success qualitative exploration sessions make sure learn all variables definitions employed heterogeneous tools before continue Research journey starts experienced Researchers come prepared valuable resource items employed go beyond discovery false alarm halt advancement flow focus unprocessed raw values instead ensure clear cutting vision behind objectives support UserHelp plans going mean project meaningful campaign deliverables production planning safety milestones dovetail short deliveries enable design interfaces session workforce making everything automated fun entry functioning final transformation awaited offshoot Goals outcome parameters monitor life cycle management ensures ongoing projects feedbacks monitored video enactment resources tapped Proficiently balanced activity sheets tracking activities progress deliberation points evaluation radius highlights outputs primary phase visit egress collaboration agendas Client cumulative returns records capture performance illustrated collectively diarized successive setup sweetens conditions researched environments overview debriefing arcane matters turn acquaintances esteemed directives social

### Research Ideas
&gt; - Training language models for improving accuracy in natural language processing applications such as question answering or dialogue systems. 
&gt; - Generating new grade school math questions and answers using generative algorithms such as GPT-3 (Generative Pre-trained Transformer). 
&gt; - Developing smarter tutoring systems that can effectively guide a student through problem solving by providing explanations and advising on alternative approaches if the current solution isn't successful

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://huggingface.co/datasets/gsm8k)
&gt; 
&gt;


### License
&gt; 
&gt; 
&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: socratic_test.csv**
| Column name   | Description                                                              |
|:--------------|:-------------------------------------------------------------------------|
| **question**  | A column containing questions related to grade school math. (String)     |
| **answer**    | A column containing the corresponding answers to the questions. (String) |

_____

**File: main_test.csv**
| Column name   | Description                                                              |
|:--------------|:-------------------------------------------------------------------------|
| **question**  | A column containing questions related to grade school math. (String)     |
| **answer**    | A column containing the corresponding answers to the questions. (String) |

_____

**File: main_train.csv**
| Column name   | Description                                                              |
|:--------------|:-------------------------------------------------------------------------|
| **question**  | A column containing questions related to grade school math. (String)     |
| **answer**    | A column containing the corresponding answers to the questions. (String) |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [Huggingface Hub](https://huggingface.co/datasets/gsm8k).

",.csv,True
GSM8K - Grade School Math 8K Q&A,4,grade-school-math-8k-q-a,main_test.csv,CC0-1.0,"_____
# GSM8K - Grade School Math 8K Q&A
### A Linguistically Diverse Dataset for Multi-Step Reasoning Question Answering
By Huggingface Hub [[source]](https://huggingface.co/datasets/gsm8k)
_____

### About this dataset
&gt; This Grade School Math 8K Linguistically Diverse Training & Test Set is designed to help you develop and improve your understanding of multi-step reasoning question answering. The dataset contains three separate data files: the socratic_test.csv, main_test.csv, and main_train.csv, each containing a set of questions and answers related to grade school math that consists of multiple steps. Each file contains the same columns: ```question```, ```answer```. The questions contained in this dataset are thoughtfully crafted to lead you through the reasoning journey for arriving at the correct answer each time, allowing you immense opportunities for learning through practice. With over 8 thousand entries for both training and testing purposes in this GSM8K dataset, it takes advanced multi-step reasoning skills to ace these questions! Deepen your knowledge today and master any challenge with ease using this amazing GSM8K set!

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; This dataset provides a unique opportunity to study multi-step reasoning for question answering. The GSM8K Linguistically Diverse Training & Test Set consists of 8,000 questions and answers that have been created to simulate real-world scenarios in grade school mathematics. Each question is paired with one answer based on a comprehensive test set. The questions cover topics such as algebra, arithmetic, probability and more. 
&gt; 
&gt; The dataset consists of two files: main_train.csv and main_test.csv; the former contains questions and answers specifically related to grade school math while the latter includes multi-step reasoning tests for each category of the Ontario Math Curriculum (OMC). In addition, it has three columns -  Question (**Question), Answer ([**Answer]) – meaning that each row contains 3 sequential question/answer pairs making it possible to take a single path from the start of any given answer or branch out from there according to the logic construction required by each respective problem scenario; these columns can be used in combination with text analysis algorithms like ELMo or BERT to explore different formats of representation for responding accurately during natural language processing tasks such as Q&A or building predictive models for numerical data applications like measuring classifying resource efficiency initiatives or forecasting sales volumes in retail platforms..  
&gt; 
&gt; To use this dataset efficiently you should first get familiar with its structure by reading through its documentation so you are aware all available info regarding items content definition & format requirements then study examples that best suits your specific purpose whether is performing an experiment inspired by education research needs, generate insights related marketing analytics reports making predictions over artificial intelligence project capacity improvements optimization gains etcetera having full access knowledge about available source keeps you up & running from preliminary background work toward knowledge mining endeavor completion success Support User success qualitative exploration sessions make sure learn all variables definitions employed heterogeneous tools before continue Research journey starts experienced Researchers come prepared valuable resource items employed go beyond discovery false alarm halt advancement flow focus unprocessed raw values instead ensure clear cutting vision behind objectives support UserHelp plans going mean project meaningful campaign deliverables production planning safety milestones dovetail short deliveries enable design interfaces session workforce making everything automated fun entry functioning final transformation awaited offshoot Goals outcome parameters monitor life cycle management ensures ongoing projects feedbacks monitored video enactment resources tapped Proficiently balanced activity sheets tracking activities progress deliberation points evaluation radius highlights outputs primary phase visit egress collaboration agendas Client cumulative returns records capture performance illustrated collectively diarized successive setup sweetens conditions researched environments overview debriefing arcane matters turn acquaintances esteemed directives social

### Research Ideas
&gt; - Training language models for improving accuracy in natural language processing applications such as question answering or dialogue systems. 
&gt; - Generating new grade school math questions and answers using generative algorithms such as GPT-3 (Generative Pre-trained Transformer). 
&gt; - Developing smarter tutoring systems that can effectively guide a student through problem solving by providing explanations and advising on alternative approaches if the current solution isn't successful

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://huggingface.co/datasets/gsm8k)
&gt; 
&gt;


### License
&gt; 
&gt; 
&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: socratic_test.csv**
| Column name   | Description                                                              |
|:--------------|:-------------------------------------------------------------------------|
| **question**  | A column containing questions related to grade school math. (String)     |
| **answer**    | A column containing the corresponding answers to the questions. (String) |

_____

**File: main_test.csv**
| Column name   | Description                                                              |
|:--------------|:-------------------------------------------------------------------------|
| **question**  | A column containing questions related to grade school math. (String)     |
| **answer**    | A column containing the corresponding answers to the questions. (String) |

_____

**File: main_train.csv**
| Column name   | Description                                                              |
|:--------------|:-------------------------------------------------------------------------|
| **question**  | A column containing questions related to grade school math. (String)     |
| **answer**    | A column containing the corresponding answers to the questions. (String) |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [Huggingface Hub](https://huggingface.co/datasets/gsm8k).

",.csv,True
GSM8K - Grade School Math 8K Q&A,4,grade-school-math-8k-q-a,socratic_test.csv,CC0-1.0,"_____
# GSM8K - Grade School Math 8K Q&A
### A Linguistically Diverse Dataset for Multi-Step Reasoning Question Answering
By Huggingface Hub [[source]](https://huggingface.co/datasets/gsm8k)
_____

### About this dataset
&gt; This Grade School Math 8K Linguistically Diverse Training & Test Set is designed to help you develop and improve your understanding of multi-step reasoning question answering. The dataset contains three separate data files: the socratic_test.csv, main_test.csv, and main_train.csv, each containing a set of questions and answers related to grade school math that consists of multiple steps. Each file contains the same columns: ```question```, ```answer```. The questions contained in this dataset are thoughtfully crafted to lead you through the reasoning journey for arriving at the correct answer each time, allowing you immense opportunities for learning through practice. With over 8 thousand entries for both training and testing purposes in this GSM8K dataset, it takes advanced multi-step reasoning skills to ace these questions! Deepen your knowledge today and master any challenge with ease using this amazing GSM8K set!

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; This dataset provides a unique opportunity to study multi-step reasoning for question answering. The GSM8K Linguistically Diverse Training & Test Set consists of 8,000 questions and answers that have been created to simulate real-world scenarios in grade school mathematics. Each question is paired with one answer based on a comprehensive test set. The questions cover topics such as algebra, arithmetic, probability and more. 
&gt; 
&gt; The dataset consists of two files: main_train.csv and main_test.csv; the former contains questions and answers specifically related to grade school math while the latter includes multi-step reasoning tests for each category of the Ontario Math Curriculum (OMC). In addition, it has three columns -  Question (**Question), Answer ([**Answer]) – meaning that each row contains 3 sequential question/answer pairs making it possible to take a single path from the start of any given answer or branch out from there according to the logic construction required by each respective problem scenario; these columns can be used in combination with text analysis algorithms like ELMo or BERT to explore different formats of representation for responding accurately during natural language processing tasks such as Q&A or building predictive models for numerical data applications like measuring classifying resource efficiency initiatives or forecasting sales volumes in retail platforms..  
&gt; 
&gt; To use this dataset efficiently you should first get familiar with its structure by reading through its documentation so you are aware all available info regarding items content definition & format requirements then study examples that best suits your specific purpose whether is performing an experiment inspired by education research needs, generate insights related marketing analytics reports making predictions over artificial intelligence project capacity improvements optimization gains etcetera having full access knowledge about available source keeps you up & running from preliminary background work toward knowledge mining endeavor completion success Support User success qualitative exploration sessions make sure learn all variables definitions employed heterogeneous tools before continue Research journey starts experienced Researchers come prepared valuable resource items employed go beyond discovery false alarm halt advancement flow focus unprocessed raw values instead ensure clear cutting vision behind objectives support UserHelp plans going mean project meaningful campaign deliverables production planning safety milestones dovetail short deliveries enable design interfaces session workforce making everything automated fun entry functioning final transformation awaited offshoot Goals outcome parameters monitor life cycle management ensures ongoing projects feedbacks monitored video enactment resources tapped Proficiently balanced activity sheets tracking activities progress deliberation points evaluation radius highlights outputs primary phase visit egress collaboration agendas Client cumulative returns records capture performance illustrated collectively diarized successive setup sweetens conditions researched environments overview debriefing arcane matters turn acquaintances esteemed directives social

### Research Ideas
&gt; - Training language models for improving accuracy in natural language processing applications such as question answering or dialogue systems. 
&gt; - Generating new grade school math questions and answers using generative algorithms such as GPT-3 (Generative Pre-trained Transformer). 
&gt; - Developing smarter tutoring systems that can effectively guide a student through problem solving by providing explanations and advising on alternative approaches if the current solution isn't successful

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://huggingface.co/datasets/gsm8k)
&gt; 
&gt;


### License
&gt; 
&gt; 
&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: socratic_test.csv**
| Column name   | Description                                                              |
|:--------------|:-------------------------------------------------------------------------|
| **question**  | A column containing questions related to grade school math. (String)     |
| **answer**    | A column containing the corresponding answers to the questions. (String) |

_____

**File: main_test.csv**
| Column name   | Description                                                              |
|:--------------|:-------------------------------------------------------------------------|
| **question**  | A column containing questions related to grade school math. (String)     |
| **answer**    | A column containing the corresponding answers to the questions. (String) |

_____

**File: main_train.csv**
| Column name   | Description                                                              |
|:--------------|:-------------------------------------------------------------------------|
| **question**  | A column containing questions related to grade school math. (String)     |
| **answer**    | A column containing the corresponding answers to the questions. (String) |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [Huggingface Hub](https://huggingface.co/datasets/gsm8k).

",.csv,True
GSM8K - Grade School Math 8K Q&A,4,grade-school-math-8k-q-a,main_train.csv,CC0-1.0,"_____
# GSM8K - Grade School Math 8K Q&A
### A Linguistically Diverse Dataset for Multi-Step Reasoning Question Answering
By Huggingface Hub [[source]](https://huggingface.co/datasets/gsm8k)
_____

### About this dataset
&gt; This Grade School Math 8K Linguistically Diverse Training & Test Set is designed to help you develop and improve your understanding of multi-step reasoning question answering. The dataset contains three separate data files: the socratic_test.csv, main_test.csv, and main_train.csv, each containing a set of questions and answers related to grade school math that consists of multiple steps. Each file contains the same columns: ```question```, ```answer```. The questions contained in this dataset are thoughtfully crafted to lead you through the reasoning journey for arriving at the correct answer each time, allowing you immense opportunities for learning through practice. With over 8 thousand entries for both training and testing purposes in this GSM8K dataset, it takes advanced multi-step reasoning skills to ace these questions! Deepen your knowledge today and master any challenge with ease using this amazing GSM8K set!

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; This dataset provides a unique opportunity to study multi-step reasoning for question answering. The GSM8K Linguistically Diverse Training & Test Set consists of 8,000 questions and answers that have been created to simulate real-world scenarios in grade school mathematics. Each question is paired with one answer based on a comprehensive test set. The questions cover topics such as algebra, arithmetic, probability and more. 
&gt; 
&gt; The dataset consists of two files: main_train.csv and main_test.csv; the former contains questions and answers specifically related to grade school math while the latter includes multi-step reasoning tests for each category of the Ontario Math Curriculum (OMC). In addition, it has three columns -  Question (**Question), Answer ([**Answer]) – meaning that each row contains 3 sequential question/answer pairs making it possible to take a single path from the start of any given answer or branch out from there according to the logic construction required by each respective problem scenario; these columns can be used in combination with text analysis algorithms like ELMo or BERT to explore different formats of representation for responding accurately during natural language processing tasks such as Q&A or building predictive models for numerical data applications like measuring classifying resource efficiency initiatives or forecasting sales volumes in retail platforms..  
&gt; 
&gt; To use this dataset efficiently you should first get familiar with its structure by reading through its documentation so you are aware all available info regarding items content definition & format requirements then study examples that best suits your specific purpose whether is performing an experiment inspired by education research needs, generate insights related marketing analytics reports making predictions over artificial intelligence project capacity improvements optimization gains etcetera having full access knowledge about available source keeps you up & running from preliminary background work toward knowledge mining endeavor completion success Support User success qualitative exploration sessions make sure learn all variables definitions employed heterogeneous tools before continue Research journey starts experienced Researchers come prepared valuable resource items employed go beyond discovery false alarm halt advancement flow focus unprocessed raw values instead ensure clear cutting vision behind objectives support UserHelp plans going mean project meaningful campaign deliverables production planning safety milestones dovetail short deliveries enable design interfaces session workforce making everything automated fun entry functioning final transformation awaited offshoot Goals outcome parameters monitor life cycle management ensures ongoing projects feedbacks monitored video enactment resources tapped Proficiently balanced activity sheets tracking activities progress deliberation points evaluation radius highlights outputs primary phase visit egress collaboration agendas Client cumulative returns records capture performance illustrated collectively diarized successive setup sweetens conditions researched environments overview debriefing arcane matters turn acquaintances esteemed directives social

### Research Ideas
&gt; - Training language models for improving accuracy in natural language processing applications such as question answering or dialogue systems. 
&gt; - Generating new grade school math questions and answers using generative algorithms such as GPT-3 (Generative Pre-trained Transformer). 
&gt; - Developing smarter tutoring systems that can effectively guide a student through problem solving by providing explanations and advising on alternative approaches if the current solution isn't successful

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://huggingface.co/datasets/gsm8k)
&gt; 
&gt;


### License
&gt; 
&gt; 
&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: socratic_test.csv**
| Column name   | Description                                                              |
|:--------------|:-------------------------------------------------------------------------|
| **question**  | A column containing questions related to grade school math. (String)     |
| **answer**    | A column containing the corresponding answers to the questions. (String) |

_____

**File: main_test.csv**
| Column name   | Description                                                              |
|:--------------|:-------------------------------------------------------------------------|
| **question**  | A column containing questions related to grade school math. (String)     |
| **answer**    | A column containing the corresponding answers to the questions. (String) |

_____

**File: main_train.csv**
| Column name   | Description                                                              |
|:--------------|:-------------------------------------------------------------------------|
| **question**  | A column containing questions related to grade school math. (String)     |
| **answer**    | A column containing the corresponding answers to the questions. (String) |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [Huggingface Hub](https://huggingface.co/datasets/gsm8k).

",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 184 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 049 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 006 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 015 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 197 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 120 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 133 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 013 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 182 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 150 [DVDrip 764x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 265 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 135 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 252 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 207 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 230 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 169 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 126 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 170 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 221 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 216 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 243 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 019 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 056 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 045 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 188 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 139 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 176 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 043 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 050 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 022 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 031 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 161 [DVDrip 764x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 104 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 213 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 224 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 086 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 095 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 158 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 246 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 117 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 078 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 037 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 024 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 111 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 238 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 093 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 080 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 102 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 154 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 099 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 108 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 147 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 072 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 061 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 193 [DVDrip 764x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 141 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 257 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 260 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 235 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 152 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 180 [DVDrip 764x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 202 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 028 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 067 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 074 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 183 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 012 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 190 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 250 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 127 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 168 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 232 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 205 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 134 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 196 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 014 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 007 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 185 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 048 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 132 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 219 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 121 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 208 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 177 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 138 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 051 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 042 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 214 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 223 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 241 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 171 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 044 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 189 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 057 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 018 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 025 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 036 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 166 [DVDrip 764x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 079 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 103 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 081 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 092 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 258 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 110 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 160 [DVDrip 764x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 030 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 023 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 226 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 116 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 211 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 094 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 244 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 087 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 105 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 153 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 181 [DVDrip 764x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 262 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 255 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 192 [DVDrip 764x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 237 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 140 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 075 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 179 [DVDrip 764x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 066 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 029 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 249 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 194 [DVDrip 764x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 146 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 109 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 155 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 098 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 060 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 073 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 212 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 047 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 225 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 008 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 247 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 199 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 054 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 172 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 052 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 239 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 041 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 174 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 167 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 128 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 131 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 122 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 017 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 058 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 195 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 186 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 228 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 004 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 201 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 124 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 137 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 178 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 256 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 261 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 011 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 234 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 203 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 063 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 070 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 088 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 145 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 156 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 119 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 076 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 264 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 253 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 039 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 206 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 231 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 065 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 191 [DVDrip 764x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 143 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 097 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 115 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 106 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 149 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 084 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 033 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 220 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 217 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 163 [DVDrip 764x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 242 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 020 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 082 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 100 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 113 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 091 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 026 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 069 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 165 [DVDrip 764x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 035 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 040 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 053 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 259 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 129 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 175 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 227 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 198 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 055 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 210 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 245 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 009 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 046 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 159 [DVDrip 764x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 173 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 136 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 125 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 010 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 263 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 254 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 236 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 003 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 123 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 130 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 248 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 200 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 005 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 187 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 059 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 001-002 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 016 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 251 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 064 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 038 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 233 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 204 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 077 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 142 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 151 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 071 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 218 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 062 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 118 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 157 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 089 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 144 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 090 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 112 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 101 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 083 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 034 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 209 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 164 [DVDrip 764x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 068 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 027 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 148 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 085 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 107 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 114 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 096 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 021 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 215 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 222 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 162 [DVDrip 764x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[Yousei-raws] Gintama 032 [DVDrip 760x576 x264 FLAC].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Gintama Subtitles,263,gintama-subtitles,[HorribleSubs] Gintama - 240 [720p].csv,CC0-1.0,"This is a zip file that contains 262 csv files.

It contains all the subtitles of Gintama (anime).
Translator teams: HorribleSubs and Yousei-raws.

Episodes: From 0 to 265 (included)

There are four columns: Number, Start time in milliseconds, End time in milliseconds, and Text.",.csv,True
Global Hospital Beds Capacity (for covid-19),18,global-hospital-beds-capacity-for-covid19,hospital_beds_per_eurostat_v1.csv,CC0-1.0,"### DISCLAIMER
Dataset consists of historical data of pre-pandemic period and doesn’t represent the current reality which may have changed due to the spikes in demand.
This dataset has been generated in collaboration of efforts within [CoronaWhy](https://www.coronawhy.org/) community.


### Context

Last updated: April 26th 2020
Updates:
April 14th 2020 - Added missing population data
April 15th 2020 - Added Brazil statewise  ICU hospital beds dataset
April 21th 2020 - Added Italy, Spain statewise  ICU hospital beds dataset, India statewise TOTAL hospital beds dataset
April 26th 2020 - Added Sweden ICU(2019) and TOTAL(2018) beds datasets

### Purpose of the dataset

I am trying to produce a dataset that will provide a foundation for policymakers to understand the realistic capacity of healthcare providers being able to deal with the spikes in demand for intensive care. As a way to help, I’ve prepared a dataset of beds across countries and states. Work in progress dataset that should and will be updated as more data becomes available and public on weekly basis.


### Importance

This dataset is intended to be used as a baseline for understanding the typical bed capacity and coverage globally. This information is critical for understanding the impact of a high utilization event, like COVID-19.


### Current challenges

Datasets are scattered across the web and are very hard to normalize, I did my best but help would be much appreciated.


### Data sources / Acknowledgments

arcgis (USA) - https://services1.arcgis.com/Hp6G80Pky0om7QvQ/arcgis/rest/services/Hospitals_1/FeatureServer/0
KHN (USA) - https://khn.org/news/as-coronavirus-spreads-widely-millions-of-older-americans-live-in-counties-with-no-icu-beds/
datahub.io (World) - https://datahub.io/world-bank/sh.med.beds.zs
eurostat - https://data.europa.eu/euodp/en/data/dataset/vswUL3c6yKoyahrvIRyew
OECD - https://data.oecd.org/healtheqt/hospital-beds.htm
WDI (World) - https://data.worldbank.org/indicator/SH.MED.BEDS.ZS
NHP(India) - http://www.cbhidghs.nic.in/showfile.php?lid=1147 
data.gov.sg (Singapore) - https://data.gov.sg/dataset/health-facilities?view_id=91b4feed-dcb9-4720-8cb0-ac2f04b7efd0&resource_id=dee5ccce-4dfb-467f-bcb4-dc025b56b977
dati.salute.gov.it (Italy)- http://www.dati.salute.gov.it/dati/dettaglioDataset.jsp?menu=dati&idPag=96
portal.icuregswe.org (Sweden) - https://portal.icuregswe.org/seiva/en/Rapport
publications:
Intensive Care Medicine Journal (Europe) - https://link.springer.com/article/10.1007/s00134-012-2627-8
Critical Care Medicine Journal (Asia) - https://www.researchgate.net/figure/Number-of-critical-care-beds-per-100-000-population_fig1_338520008
Medicina Intensiva (Spain) - https://www.medintensiva.org/en-pdf-S2173572713000878
news:
https://lanuovaferrara.gelocal.it/italia-mondo/cronaca/2020/03/19/news/dietro-la-corsa-a-nuovi-posti-in-terapia-intensiva-gli-errori-del-passato-1.38611596
kaggle:
germany - https://www.kaggle.com/manuelblechschmidt/icu-beds-in-germany
brazil (IBGE) - https://www.kaggle.com/thiagobodruk/brazilianstates
Manual population data search from wiki


### Data columns
country,state,county,lat,lng,type,measure,beds,population,year,source,source_url
- country - country of origin, if present
- state - more granular location, if present
- lat - latitude
- lng - longtitude
- type - [TOTAL, ICU, ACUTE(some data could include ICU beds too), PSYCHIATRIC, OTHER(merged ‘SPECIAL’, ‘CHRONIC DISEASE’, ‘CHILDREN’, ‘LONG TERM CARE’, ‘REHABILITATION’, ‘WOMEN’, ‘MILITARY’]
- measure - type of measure (per 1000 inhabitants)
- beds - number of beds per 1000
- population - population of location based on multiple sources and wikipedia
- year - source year for beds and population data
- source - source of data
- source_url - URL of the original source


### Files
for each of datasource: `hospital_beds_per_source.csv`

US only: US arcgis + khn (state/county granularity): `hospital_beds_USA.csv`

Global (state(region)/county granularity): `hospital_beds_global_regional.csv`

Global (country granularity): `hospital_beds_global_v1.csv`


### Contributors

[Igor Kiulian](https://www.linkedin.com/in/igor-kiulian/) - extracting/normalizing/formatting/merging data
[Artur Kiulian](https://www.linkedin.com/in/artur-kiulian/) - helped with Kaggle setup
[Augaly S. Kiedi](https://nl.linkedin.com/in/augalyskiedi) - helped with country population data
[Kristoffer Jan Zieba](https://no.linkedin.com/in/kristoffer-zieba) - found Swedish data sources


### Possible Improvements

Find and megre more detailed (state/county wise) or newer datasource  ",.csv,True
Global Hospital Beds Capacity (for covid-19),18,global-hospital-beds-capacity-for-covid19,hospital_beds_per_ccm_journal_v1.csv,CC0-1.0,"### DISCLAIMER
Dataset consists of historical data of pre-pandemic period and doesn’t represent the current reality which may have changed due to the spikes in demand.
This dataset has been generated in collaboration of efforts within [CoronaWhy](https://www.coronawhy.org/) community.


### Context

Last updated: April 26th 2020
Updates:
April 14th 2020 - Added missing population data
April 15th 2020 - Added Brazil statewise  ICU hospital beds dataset
April 21th 2020 - Added Italy, Spain statewise  ICU hospital beds dataset, India statewise TOTAL hospital beds dataset
April 26th 2020 - Added Sweden ICU(2019) and TOTAL(2018) beds datasets

### Purpose of the dataset

I am trying to produce a dataset that will provide a foundation for policymakers to understand the realistic capacity of healthcare providers being able to deal with the spikes in demand for intensive care. As a way to help, I’ve prepared a dataset of beds across countries and states. Work in progress dataset that should and will be updated as more data becomes available and public on weekly basis.


### Importance

This dataset is intended to be used as a baseline for understanding the typical bed capacity and coverage globally. This information is critical for understanding the impact of a high utilization event, like COVID-19.


### Current challenges

Datasets are scattered across the web and are very hard to normalize, I did my best but help would be much appreciated.


### Data sources / Acknowledgments

arcgis (USA) - https://services1.arcgis.com/Hp6G80Pky0om7QvQ/arcgis/rest/services/Hospitals_1/FeatureServer/0
KHN (USA) - https://khn.org/news/as-coronavirus-spreads-widely-millions-of-older-americans-live-in-counties-with-no-icu-beds/
datahub.io (World) - https://datahub.io/world-bank/sh.med.beds.zs
eurostat - https://data.europa.eu/euodp/en/data/dataset/vswUL3c6yKoyahrvIRyew
OECD - https://data.oecd.org/healtheqt/hospital-beds.htm
WDI (World) - https://data.worldbank.org/indicator/SH.MED.BEDS.ZS
NHP(India) - http://www.cbhidghs.nic.in/showfile.php?lid=1147 
data.gov.sg (Singapore) - https://data.gov.sg/dataset/health-facilities?view_id=91b4feed-dcb9-4720-8cb0-ac2f04b7efd0&resource_id=dee5ccce-4dfb-467f-bcb4-dc025b56b977
dati.salute.gov.it (Italy)- http://www.dati.salute.gov.it/dati/dettaglioDataset.jsp?menu=dati&idPag=96
portal.icuregswe.org (Sweden) - https://portal.icuregswe.org/seiva/en/Rapport
publications:
Intensive Care Medicine Journal (Europe) - https://link.springer.com/article/10.1007/s00134-012-2627-8
Critical Care Medicine Journal (Asia) - https://www.researchgate.net/figure/Number-of-critical-care-beds-per-100-000-population_fig1_338520008
Medicina Intensiva (Spain) - https://www.medintensiva.org/en-pdf-S2173572713000878
news:
https://lanuovaferrara.gelocal.it/italia-mondo/cronaca/2020/03/19/news/dietro-la-corsa-a-nuovi-posti-in-terapia-intensiva-gli-errori-del-passato-1.38611596
kaggle:
germany - https://www.kaggle.com/manuelblechschmidt/icu-beds-in-germany
brazil (IBGE) - https://www.kaggle.com/thiagobodruk/brazilianstates
Manual population data search from wiki


### Data columns
country,state,county,lat,lng,type,measure,beds,population,year,source,source_url
- country - country of origin, if present
- state - more granular location, if present
- lat - latitude
- lng - longtitude
- type - [TOTAL, ICU, ACUTE(some data could include ICU beds too), PSYCHIATRIC, OTHER(merged ‘SPECIAL’, ‘CHRONIC DISEASE’, ‘CHILDREN’, ‘LONG TERM CARE’, ‘REHABILITATION’, ‘WOMEN’, ‘MILITARY’]
- measure - type of measure (per 1000 inhabitants)
- beds - number of beds per 1000
- population - population of location based on multiple sources and wikipedia
- year - source year for beds and population data
- source - source of data
- source_url - URL of the original source


### Files
for each of datasource: `hospital_beds_per_source.csv`

US only: US arcgis + khn (state/county granularity): `hospital_beds_USA.csv`

Global (state(region)/county granularity): `hospital_beds_global_regional.csv`

Global (country granularity): `hospital_beds_global_v1.csv`


### Contributors

[Igor Kiulian](https://www.linkedin.com/in/igor-kiulian/) - extracting/normalizing/formatting/merging data
[Artur Kiulian](https://www.linkedin.com/in/artur-kiulian/) - helped with Kaggle setup
[Augaly S. Kiedi](https://nl.linkedin.com/in/augalyskiedi) - helped with country population data
[Kristoffer Jan Zieba](https://no.linkedin.com/in/kristoffer-zieba) - found Swedish data sources


### Possible Improvements

Find and megre more detailed (state/county wise) or newer datasource  ",.csv,True
Global Hospital Beds Capacity (for covid-19),18,global-hospital-beds-capacity-for-covid19,hospital_beds_per_datahub_worldbank_v1.csv,CC0-1.0,"### DISCLAIMER
Dataset consists of historical data of pre-pandemic period and doesn’t represent the current reality which may have changed due to the spikes in demand.
This dataset has been generated in collaboration of efforts within [CoronaWhy](https://www.coronawhy.org/) community.


### Context

Last updated: April 26th 2020
Updates:
April 14th 2020 - Added missing population data
April 15th 2020 - Added Brazil statewise  ICU hospital beds dataset
April 21th 2020 - Added Italy, Spain statewise  ICU hospital beds dataset, India statewise TOTAL hospital beds dataset
April 26th 2020 - Added Sweden ICU(2019) and TOTAL(2018) beds datasets

### Purpose of the dataset

I am trying to produce a dataset that will provide a foundation for policymakers to understand the realistic capacity of healthcare providers being able to deal with the spikes in demand for intensive care. As a way to help, I’ve prepared a dataset of beds across countries and states. Work in progress dataset that should and will be updated as more data becomes available and public on weekly basis.


### Importance

This dataset is intended to be used as a baseline for understanding the typical bed capacity and coverage globally. This information is critical for understanding the impact of a high utilization event, like COVID-19.


### Current challenges

Datasets are scattered across the web and are very hard to normalize, I did my best but help would be much appreciated.


### Data sources / Acknowledgments

arcgis (USA) - https://services1.arcgis.com/Hp6G80Pky0om7QvQ/arcgis/rest/services/Hospitals_1/FeatureServer/0
KHN (USA) - https://khn.org/news/as-coronavirus-spreads-widely-millions-of-older-americans-live-in-counties-with-no-icu-beds/
datahub.io (World) - https://datahub.io/world-bank/sh.med.beds.zs
eurostat - https://data.europa.eu/euodp/en/data/dataset/vswUL3c6yKoyahrvIRyew
OECD - https://data.oecd.org/healtheqt/hospital-beds.htm
WDI (World) - https://data.worldbank.org/indicator/SH.MED.BEDS.ZS
NHP(India) - http://www.cbhidghs.nic.in/showfile.php?lid=1147 
data.gov.sg (Singapore) - https://data.gov.sg/dataset/health-facilities?view_id=91b4feed-dcb9-4720-8cb0-ac2f04b7efd0&resource_id=dee5ccce-4dfb-467f-bcb4-dc025b56b977
dati.salute.gov.it (Italy)- http://www.dati.salute.gov.it/dati/dettaglioDataset.jsp?menu=dati&idPag=96
portal.icuregswe.org (Sweden) - https://portal.icuregswe.org/seiva/en/Rapport
publications:
Intensive Care Medicine Journal (Europe) - https://link.springer.com/article/10.1007/s00134-012-2627-8
Critical Care Medicine Journal (Asia) - https://www.researchgate.net/figure/Number-of-critical-care-beds-per-100-000-population_fig1_338520008
Medicina Intensiva (Spain) - https://www.medintensiva.org/en-pdf-S2173572713000878
news:
https://lanuovaferrara.gelocal.it/italia-mondo/cronaca/2020/03/19/news/dietro-la-corsa-a-nuovi-posti-in-terapia-intensiva-gli-errori-del-passato-1.38611596
kaggle:
germany - https://www.kaggle.com/manuelblechschmidt/icu-beds-in-germany
brazil (IBGE) - https://www.kaggle.com/thiagobodruk/brazilianstates
Manual population data search from wiki


### Data columns
country,state,county,lat,lng,type,measure,beds,population,year,source,source_url
- country - country of origin, if present
- state - more granular location, if present
- lat - latitude
- lng - longtitude
- type - [TOTAL, ICU, ACUTE(some data could include ICU beds too), PSYCHIATRIC, OTHER(merged ‘SPECIAL’, ‘CHRONIC DISEASE’, ‘CHILDREN’, ‘LONG TERM CARE’, ‘REHABILITATION’, ‘WOMEN’, ‘MILITARY’]
- measure - type of measure (per 1000 inhabitants)
- beds - number of beds per 1000
- population - population of location based on multiple sources and wikipedia
- year - source year for beds and population data
- source - source of data
- source_url - URL of the original source


### Files
for each of datasource: `hospital_beds_per_source.csv`

US only: US arcgis + khn (state/county granularity): `hospital_beds_USA.csv`

Global (state(region)/county granularity): `hospital_beds_global_regional.csv`

Global (country granularity): `hospital_beds_global_v1.csv`


### Contributors

[Igor Kiulian](https://www.linkedin.com/in/igor-kiulian/) - extracting/normalizing/formatting/merging data
[Artur Kiulian](https://www.linkedin.com/in/artur-kiulian/) - helped with Kaggle setup
[Augaly S. Kiedi](https://nl.linkedin.com/in/augalyskiedi) - helped with country population data
[Kristoffer Jan Zieba](https://no.linkedin.com/in/kristoffer-zieba) - found Swedish data sources


### Possible Improvements

Find and megre more detailed (state/county wise) or newer datasource  ",.csv,True
Global Hospital Beds Capacity (for covid-19),18,global-hospital-beds-capacity-for-covid19,hospital_beds_per_india_v1.csv,CC0-1.0,"### DISCLAIMER
Dataset consists of historical data of pre-pandemic period and doesn’t represent the current reality which may have changed due to the spikes in demand.
This dataset has been generated in collaboration of efforts within [CoronaWhy](https://www.coronawhy.org/) community.


### Context

Last updated: April 26th 2020
Updates:
April 14th 2020 - Added missing population data
April 15th 2020 - Added Brazil statewise  ICU hospital beds dataset
April 21th 2020 - Added Italy, Spain statewise  ICU hospital beds dataset, India statewise TOTAL hospital beds dataset
April 26th 2020 - Added Sweden ICU(2019) and TOTAL(2018) beds datasets

### Purpose of the dataset

I am trying to produce a dataset that will provide a foundation for policymakers to understand the realistic capacity of healthcare providers being able to deal with the spikes in demand for intensive care. As a way to help, I’ve prepared a dataset of beds across countries and states. Work in progress dataset that should and will be updated as more data becomes available and public on weekly basis.


### Importance

This dataset is intended to be used as a baseline for understanding the typical bed capacity and coverage globally. This information is critical for understanding the impact of a high utilization event, like COVID-19.


### Current challenges

Datasets are scattered across the web and are very hard to normalize, I did my best but help would be much appreciated.


### Data sources / Acknowledgments

arcgis (USA) - https://services1.arcgis.com/Hp6G80Pky0om7QvQ/arcgis/rest/services/Hospitals_1/FeatureServer/0
KHN (USA) - https://khn.org/news/as-coronavirus-spreads-widely-millions-of-older-americans-live-in-counties-with-no-icu-beds/
datahub.io (World) - https://datahub.io/world-bank/sh.med.beds.zs
eurostat - https://data.europa.eu/euodp/en/data/dataset/vswUL3c6yKoyahrvIRyew
OECD - https://data.oecd.org/healtheqt/hospital-beds.htm
WDI (World) - https://data.worldbank.org/indicator/SH.MED.BEDS.ZS
NHP(India) - http://www.cbhidghs.nic.in/showfile.php?lid=1147 
data.gov.sg (Singapore) - https://data.gov.sg/dataset/health-facilities?view_id=91b4feed-dcb9-4720-8cb0-ac2f04b7efd0&resource_id=dee5ccce-4dfb-467f-bcb4-dc025b56b977
dati.salute.gov.it (Italy)- http://www.dati.salute.gov.it/dati/dettaglioDataset.jsp?menu=dati&idPag=96
portal.icuregswe.org (Sweden) - https://portal.icuregswe.org/seiva/en/Rapport
publications:
Intensive Care Medicine Journal (Europe) - https://link.springer.com/article/10.1007/s00134-012-2627-8
Critical Care Medicine Journal (Asia) - https://www.researchgate.net/figure/Number-of-critical-care-beds-per-100-000-population_fig1_338520008
Medicina Intensiva (Spain) - https://www.medintensiva.org/en-pdf-S2173572713000878
news:
https://lanuovaferrara.gelocal.it/italia-mondo/cronaca/2020/03/19/news/dietro-la-corsa-a-nuovi-posti-in-terapia-intensiva-gli-errori-del-passato-1.38611596
kaggle:
germany - https://www.kaggle.com/manuelblechschmidt/icu-beds-in-germany
brazil (IBGE) - https://www.kaggle.com/thiagobodruk/brazilianstates
Manual population data search from wiki


### Data columns
country,state,county,lat,lng,type,measure,beds,population,year,source,source_url
- country - country of origin, if present
- state - more granular location, if present
- lat - latitude
- lng - longtitude
- type - [TOTAL, ICU, ACUTE(some data could include ICU beds too), PSYCHIATRIC, OTHER(merged ‘SPECIAL’, ‘CHRONIC DISEASE’, ‘CHILDREN’, ‘LONG TERM CARE’, ‘REHABILITATION’, ‘WOMEN’, ‘MILITARY’]
- measure - type of measure (per 1000 inhabitants)
- beds - number of beds per 1000
- population - population of location based on multiple sources and wikipedia
- year - source year for beds and population data
- source - source of data
- source_url - URL of the original source


### Files
for each of datasource: `hospital_beds_per_source.csv`

US only: US arcgis + khn (state/county granularity): `hospital_beds_USA.csv`

Global (state(region)/county granularity): `hospital_beds_global_regional.csv`

Global (country granularity): `hospital_beds_global_v1.csv`


### Contributors

[Igor Kiulian](https://www.linkedin.com/in/igor-kiulian/) - extracting/normalizing/formatting/merging data
[Artur Kiulian](https://www.linkedin.com/in/artur-kiulian/) - helped with Kaggle setup
[Augaly S. Kiedi](https://nl.linkedin.com/in/augalyskiedi) - helped with country population data
[Kristoffer Jan Zieba](https://no.linkedin.com/in/kristoffer-zieba) - found Swedish data sources


### Possible Improvements

Find and megre more detailed (state/county wise) or newer datasource  ",.csv,True
Global Hospital Beds Capacity (for covid-19),18,global-hospital-beds-capacity-for-covid19,hospital_beds_per_other_v1.csv,CC0-1.0,"### DISCLAIMER
Dataset consists of historical data of pre-pandemic period and doesn’t represent the current reality which may have changed due to the spikes in demand.
This dataset has been generated in collaboration of efforts within [CoronaWhy](https://www.coronawhy.org/) community.


### Context

Last updated: April 26th 2020
Updates:
April 14th 2020 - Added missing population data
April 15th 2020 - Added Brazil statewise  ICU hospital beds dataset
April 21th 2020 - Added Italy, Spain statewise  ICU hospital beds dataset, India statewise TOTAL hospital beds dataset
April 26th 2020 - Added Sweden ICU(2019) and TOTAL(2018) beds datasets

### Purpose of the dataset

I am trying to produce a dataset that will provide a foundation for policymakers to understand the realistic capacity of healthcare providers being able to deal with the spikes in demand for intensive care. As a way to help, I’ve prepared a dataset of beds across countries and states. Work in progress dataset that should and will be updated as more data becomes available and public on weekly basis.


### Importance

This dataset is intended to be used as a baseline for understanding the typical bed capacity and coverage globally. This information is critical for understanding the impact of a high utilization event, like COVID-19.


### Current challenges

Datasets are scattered across the web and are very hard to normalize, I did my best but help would be much appreciated.


### Data sources / Acknowledgments

arcgis (USA) - https://services1.arcgis.com/Hp6G80Pky0om7QvQ/arcgis/rest/services/Hospitals_1/FeatureServer/0
KHN (USA) - https://khn.org/news/as-coronavirus-spreads-widely-millions-of-older-americans-live-in-counties-with-no-icu-beds/
datahub.io (World) - https://datahub.io/world-bank/sh.med.beds.zs
eurostat - https://data.europa.eu/euodp/en/data/dataset/vswUL3c6yKoyahrvIRyew
OECD - https://data.oecd.org/healtheqt/hospital-beds.htm
WDI (World) - https://data.worldbank.org/indicator/SH.MED.BEDS.ZS
NHP(India) - http://www.cbhidghs.nic.in/showfile.php?lid=1147 
data.gov.sg (Singapore) - https://data.gov.sg/dataset/health-facilities?view_id=91b4feed-dcb9-4720-8cb0-ac2f04b7efd0&resource_id=dee5ccce-4dfb-467f-bcb4-dc025b56b977
dati.salute.gov.it (Italy)- http://www.dati.salute.gov.it/dati/dettaglioDataset.jsp?menu=dati&idPag=96
portal.icuregswe.org (Sweden) - https://portal.icuregswe.org/seiva/en/Rapport
publications:
Intensive Care Medicine Journal (Europe) - https://link.springer.com/article/10.1007/s00134-012-2627-8
Critical Care Medicine Journal (Asia) - https://www.researchgate.net/figure/Number-of-critical-care-beds-per-100-000-population_fig1_338520008
Medicina Intensiva (Spain) - https://www.medintensiva.org/en-pdf-S2173572713000878
news:
https://lanuovaferrara.gelocal.it/italia-mondo/cronaca/2020/03/19/news/dietro-la-corsa-a-nuovi-posti-in-terapia-intensiva-gli-errori-del-passato-1.38611596
kaggle:
germany - https://www.kaggle.com/manuelblechschmidt/icu-beds-in-germany
brazil (IBGE) - https://www.kaggle.com/thiagobodruk/brazilianstates
Manual population data search from wiki


### Data columns
country,state,county,lat,lng,type,measure,beds,population,year,source,source_url
- country - country of origin, if present
- state - more granular location, if present
- lat - latitude
- lng - longtitude
- type - [TOTAL, ICU, ACUTE(some data could include ICU beds too), PSYCHIATRIC, OTHER(merged ‘SPECIAL’, ‘CHRONIC DISEASE’, ‘CHILDREN’, ‘LONG TERM CARE’, ‘REHABILITATION’, ‘WOMEN’, ‘MILITARY’]
- measure - type of measure (per 1000 inhabitants)
- beds - number of beds per 1000
- population - population of location based on multiple sources and wikipedia
- year - source year for beds and population data
- source - source of data
- source_url - URL of the original source


### Files
for each of datasource: `hospital_beds_per_source.csv`

US only: US arcgis + khn (state/county granularity): `hospital_beds_USA.csv`

Global (state(region)/county granularity): `hospital_beds_global_regional.csv`

Global (country granularity): `hospital_beds_global_v1.csv`


### Contributors

[Igor Kiulian](https://www.linkedin.com/in/igor-kiulian/) - extracting/normalizing/formatting/merging data
[Artur Kiulian](https://www.linkedin.com/in/artur-kiulian/) - helped with Kaggle setup
[Augaly S. Kiedi](https://nl.linkedin.com/in/augalyskiedi) - helped with country population data
[Kristoffer Jan Zieba](https://no.linkedin.com/in/kristoffer-zieba) - found Swedish data sources


### Possible Improvements

Find and megre more detailed (state/county wise) or newer datasource  ",.csv,True
Global Hospital Beds Capacity (for covid-19),18,global-hospital-beds-capacity-for-covid19,hospital_beds_per_germany_kaggle_v1.csv,CC0-1.0,"### DISCLAIMER
Dataset consists of historical data of pre-pandemic period and doesn’t represent the current reality which may have changed due to the spikes in demand.
This dataset has been generated in collaboration of efforts within [CoronaWhy](https://www.coronawhy.org/) community.


### Context

Last updated: April 26th 2020
Updates:
April 14th 2020 - Added missing population data
April 15th 2020 - Added Brazil statewise  ICU hospital beds dataset
April 21th 2020 - Added Italy, Spain statewise  ICU hospital beds dataset, India statewise TOTAL hospital beds dataset
April 26th 2020 - Added Sweden ICU(2019) and TOTAL(2018) beds datasets

### Purpose of the dataset

I am trying to produce a dataset that will provide a foundation for policymakers to understand the realistic capacity of healthcare providers being able to deal with the spikes in demand for intensive care. As a way to help, I’ve prepared a dataset of beds across countries and states. Work in progress dataset that should and will be updated as more data becomes available and public on weekly basis.


### Importance

This dataset is intended to be used as a baseline for understanding the typical bed capacity and coverage globally. This information is critical for understanding the impact of a high utilization event, like COVID-19.


### Current challenges

Datasets are scattered across the web and are very hard to normalize, I did my best but help would be much appreciated.


### Data sources / Acknowledgments

arcgis (USA) - https://services1.arcgis.com/Hp6G80Pky0om7QvQ/arcgis/rest/services/Hospitals_1/FeatureServer/0
KHN (USA) - https://khn.org/news/as-coronavirus-spreads-widely-millions-of-older-americans-live-in-counties-with-no-icu-beds/
datahub.io (World) - https://datahub.io/world-bank/sh.med.beds.zs
eurostat - https://data.europa.eu/euodp/en/data/dataset/vswUL3c6yKoyahrvIRyew
OECD - https://data.oecd.org/healtheqt/hospital-beds.htm
WDI (World) - https://data.worldbank.org/indicator/SH.MED.BEDS.ZS
NHP(India) - http://www.cbhidghs.nic.in/showfile.php?lid=1147 
data.gov.sg (Singapore) - https://data.gov.sg/dataset/health-facilities?view_id=91b4feed-dcb9-4720-8cb0-ac2f04b7efd0&resource_id=dee5ccce-4dfb-467f-bcb4-dc025b56b977
dati.salute.gov.it (Italy)- http://www.dati.salute.gov.it/dati/dettaglioDataset.jsp?menu=dati&idPag=96
portal.icuregswe.org (Sweden) - https://portal.icuregswe.org/seiva/en/Rapport
publications:
Intensive Care Medicine Journal (Europe) - https://link.springer.com/article/10.1007/s00134-012-2627-8
Critical Care Medicine Journal (Asia) - https://www.researchgate.net/figure/Number-of-critical-care-beds-per-100-000-population_fig1_338520008
Medicina Intensiva (Spain) - https://www.medintensiva.org/en-pdf-S2173572713000878
news:
https://lanuovaferrara.gelocal.it/italia-mondo/cronaca/2020/03/19/news/dietro-la-corsa-a-nuovi-posti-in-terapia-intensiva-gli-errori-del-passato-1.38611596
kaggle:
germany - https://www.kaggle.com/manuelblechschmidt/icu-beds-in-germany
brazil (IBGE) - https://www.kaggle.com/thiagobodruk/brazilianstates
Manual population data search from wiki


### Data columns
country,state,county,lat,lng,type,measure,beds,population,year,source,source_url
- country - country of origin, if present
- state - more granular location, if present
- lat - latitude
- lng - longtitude
- type - [TOTAL, ICU, ACUTE(some data could include ICU beds too), PSYCHIATRIC, OTHER(merged ‘SPECIAL’, ‘CHRONIC DISEASE’, ‘CHILDREN’, ‘LONG TERM CARE’, ‘REHABILITATION’, ‘WOMEN’, ‘MILITARY’]
- measure - type of measure (per 1000 inhabitants)
- beds - number of beds per 1000
- population - population of location based on multiple sources and wikipedia
- year - source year for beds and population data
- source - source of data
- source_url - URL of the original source


### Files
for each of datasource: `hospital_beds_per_source.csv`

US only: US arcgis + khn (state/county granularity): `hospital_beds_USA.csv`

Global (state(region)/county granularity): `hospital_beds_global_regional.csv`

Global (country granularity): `hospital_beds_global_v1.csv`


### Contributors

[Igor Kiulian](https://www.linkedin.com/in/igor-kiulian/) - extracting/normalizing/formatting/merging data
[Artur Kiulian](https://www.linkedin.com/in/artur-kiulian/) - helped with Kaggle setup
[Augaly S. Kiedi](https://nl.linkedin.com/in/augalyskiedi) - helped with country population data
[Kristoffer Jan Zieba](https://no.linkedin.com/in/kristoffer-zieba) - found Swedish data sources


### Possible Improvements

Find and megre more detailed (state/county wise) or newer datasource  ",.csv,True
Global Hospital Beds Capacity (for covid-19),18,global-hospital-beds-capacity-for-covid19,hospital_beds_per_icm_journal_v1.csv,CC0-1.0,"### DISCLAIMER
Dataset consists of historical data of pre-pandemic period and doesn’t represent the current reality which may have changed due to the spikes in demand.
This dataset has been generated in collaboration of efforts within [CoronaWhy](https://www.coronawhy.org/) community.


### Context

Last updated: April 26th 2020
Updates:
April 14th 2020 - Added missing population data
April 15th 2020 - Added Brazil statewise  ICU hospital beds dataset
April 21th 2020 - Added Italy, Spain statewise  ICU hospital beds dataset, India statewise TOTAL hospital beds dataset
April 26th 2020 - Added Sweden ICU(2019) and TOTAL(2018) beds datasets

### Purpose of the dataset

I am trying to produce a dataset that will provide a foundation for policymakers to understand the realistic capacity of healthcare providers being able to deal with the spikes in demand for intensive care. As a way to help, I’ve prepared a dataset of beds across countries and states. Work in progress dataset that should and will be updated as more data becomes available and public on weekly basis.


### Importance

This dataset is intended to be used as a baseline for understanding the typical bed capacity and coverage globally. This information is critical for understanding the impact of a high utilization event, like COVID-19.


### Current challenges

Datasets are scattered across the web and are very hard to normalize, I did my best but help would be much appreciated.


### Data sources / Acknowledgments

arcgis (USA) - https://services1.arcgis.com/Hp6G80Pky0om7QvQ/arcgis/rest/services/Hospitals_1/FeatureServer/0
KHN (USA) - https://khn.org/news/as-coronavirus-spreads-widely-millions-of-older-americans-live-in-counties-with-no-icu-beds/
datahub.io (World) - https://datahub.io/world-bank/sh.med.beds.zs
eurostat - https://data.europa.eu/euodp/en/data/dataset/vswUL3c6yKoyahrvIRyew
OECD - https://data.oecd.org/healtheqt/hospital-beds.htm
WDI (World) - https://data.worldbank.org/indicator/SH.MED.BEDS.ZS
NHP(India) - http://www.cbhidghs.nic.in/showfile.php?lid=1147 
data.gov.sg (Singapore) - https://data.gov.sg/dataset/health-facilities?view_id=91b4feed-dcb9-4720-8cb0-ac2f04b7efd0&resource_id=dee5ccce-4dfb-467f-bcb4-dc025b56b977
dati.salute.gov.it (Italy)- http://www.dati.salute.gov.it/dati/dettaglioDataset.jsp?menu=dati&idPag=96
portal.icuregswe.org (Sweden) - https://portal.icuregswe.org/seiva/en/Rapport
publications:
Intensive Care Medicine Journal (Europe) - https://link.springer.com/article/10.1007/s00134-012-2627-8
Critical Care Medicine Journal (Asia) - https://www.researchgate.net/figure/Number-of-critical-care-beds-per-100-000-population_fig1_338520008
Medicina Intensiva (Spain) - https://www.medintensiva.org/en-pdf-S2173572713000878
news:
https://lanuovaferrara.gelocal.it/italia-mondo/cronaca/2020/03/19/news/dietro-la-corsa-a-nuovi-posti-in-terapia-intensiva-gli-errori-del-passato-1.38611596
kaggle:
germany - https://www.kaggle.com/manuelblechschmidt/icu-beds-in-germany
brazil (IBGE) - https://www.kaggle.com/thiagobodruk/brazilianstates
Manual population data search from wiki


### Data columns
country,state,county,lat,lng,type,measure,beds,population,year,source,source_url
- country - country of origin, if present
- state - more granular location, if present
- lat - latitude
- lng - longtitude
- type - [TOTAL, ICU, ACUTE(some data could include ICU beds too), PSYCHIATRIC, OTHER(merged ‘SPECIAL’, ‘CHRONIC DISEASE’, ‘CHILDREN’, ‘LONG TERM CARE’, ‘REHABILITATION’, ‘WOMEN’, ‘MILITARY’]
- measure - type of measure (per 1000 inhabitants)
- beds - number of beds per 1000
- population - population of location based on multiple sources and wikipedia
- year - source year for beds and population data
- source - source of data
- source_url - URL of the original source


### Files
for each of datasource: `hospital_beds_per_source.csv`

US only: US arcgis + khn (state/county granularity): `hospital_beds_USA.csv`

Global (state(region)/county granularity): `hospital_beds_global_regional.csv`

Global (country granularity): `hospital_beds_global_v1.csv`


### Contributors

[Igor Kiulian](https://www.linkedin.com/in/igor-kiulian/) - extracting/normalizing/formatting/merging data
[Artur Kiulian](https://www.linkedin.com/in/artur-kiulian/) - helped with Kaggle setup
[Augaly S. Kiedi](https://nl.linkedin.com/in/augalyskiedi) - helped with country population data
[Kristoffer Jan Zieba](https://no.linkedin.com/in/kristoffer-zieba) - found Swedish data sources


### Possible Improvements

Find and megre more detailed (state/county wise) or newer datasource  ",.csv,True
Global Hospital Beds Capacity (for covid-19),18,global-hospital-beds-capacity-for-covid19,hospital_beds_per_arcgis_v1.csv,CC0-1.0,"### DISCLAIMER
Dataset consists of historical data of pre-pandemic period and doesn’t represent the current reality which may have changed due to the spikes in demand.
This dataset has been generated in collaboration of efforts within [CoronaWhy](https://www.coronawhy.org/) community.


### Context

Last updated: April 26th 2020
Updates:
April 14th 2020 - Added missing population data
April 15th 2020 - Added Brazil statewise  ICU hospital beds dataset
April 21th 2020 - Added Italy, Spain statewise  ICU hospital beds dataset, India statewise TOTAL hospital beds dataset
April 26th 2020 - Added Sweden ICU(2019) and TOTAL(2018) beds datasets

### Purpose of the dataset

I am trying to produce a dataset that will provide a foundation for policymakers to understand the realistic capacity of healthcare providers being able to deal with the spikes in demand for intensive care. As a way to help, I’ve prepared a dataset of beds across countries and states. Work in progress dataset that should and will be updated as more data becomes available and public on weekly basis.


### Importance

This dataset is intended to be used as a baseline for understanding the typical bed capacity and coverage globally. This information is critical for understanding the impact of a high utilization event, like COVID-19.


### Current challenges

Datasets are scattered across the web and are very hard to normalize, I did my best but help would be much appreciated.


### Data sources / Acknowledgments

arcgis (USA) - https://services1.arcgis.com/Hp6G80Pky0om7QvQ/arcgis/rest/services/Hospitals_1/FeatureServer/0
KHN (USA) - https://khn.org/news/as-coronavirus-spreads-widely-millions-of-older-americans-live-in-counties-with-no-icu-beds/
datahub.io (World) - https://datahub.io/world-bank/sh.med.beds.zs
eurostat - https://data.europa.eu/euodp/en/data/dataset/vswUL3c6yKoyahrvIRyew
OECD - https://data.oecd.org/healtheqt/hospital-beds.htm
WDI (World) - https://data.worldbank.org/indicator/SH.MED.BEDS.ZS
NHP(India) - http://www.cbhidghs.nic.in/showfile.php?lid=1147 
data.gov.sg (Singapore) - https://data.gov.sg/dataset/health-facilities?view_id=91b4feed-dcb9-4720-8cb0-ac2f04b7efd0&resource_id=dee5ccce-4dfb-467f-bcb4-dc025b56b977
dati.salute.gov.it (Italy)- http://www.dati.salute.gov.it/dati/dettaglioDataset.jsp?menu=dati&idPag=96
portal.icuregswe.org (Sweden) - https://portal.icuregswe.org/seiva/en/Rapport
publications:
Intensive Care Medicine Journal (Europe) - https://link.springer.com/article/10.1007/s00134-012-2627-8
Critical Care Medicine Journal (Asia) - https://www.researchgate.net/figure/Number-of-critical-care-beds-per-100-000-population_fig1_338520008
Medicina Intensiva (Spain) - https://www.medintensiva.org/en-pdf-S2173572713000878
news:
https://lanuovaferrara.gelocal.it/italia-mondo/cronaca/2020/03/19/news/dietro-la-corsa-a-nuovi-posti-in-terapia-intensiva-gli-errori-del-passato-1.38611596
kaggle:
germany - https://www.kaggle.com/manuelblechschmidt/icu-beds-in-germany
brazil (IBGE) - https://www.kaggle.com/thiagobodruk/brazilianstates
Manual population data search from wiki


### Data columns
country,state,county,lat,lng,type,measure,beds,population,year,source,source_url
- country - country of origin, if present
- state - more granular location, if present
- lat - latitude
- lng - longtitude
- type - [TOTAL, ICU, ACUTE(some data could include ICU beds too), PSYCHIATRIC, OTHER(merged ‘SPECIAL’, ‘CHRONIC DISEASE’, ‘CHILDREN’, ‘LONG TERM CARE’, ‘REHABILITATION’, ‘WOMEN’, ‘MILITARY’]
- measure - type of measure (per 1000 inhabitants)
- beds - number of beds per 1000
- population - population of location based on multiple sources and wikipedia
- year - source year for beds and population data
- source - source of data
- source_url - URL of the original source


### Files
for each of datasource: `hospital_beds_per_source.csv`

US only: US arcgis + khn (state/county granularity): `hospital_beds_USA.csv`

Global (state(region)/county granularity): `hospital_beds_global_regional.csv`

Global (country granularity): `hospital_beds_global_v1.csv`


### Contributors

[Igor Kiulian](https://www.linkedin.com/in/igor-kiulian/) - extracting/normalizing/formatting/merging data
[Artur Kiulian](https://www.linkedin.com/in/artur-kiulian/) - helped with Kaggle setup
[Augaly S. Kiedi](https://nl.linkedin.com/in/augalyskiedi) - helped with country population data
[Kristoffer Jan Zieba](https://no.linkedin.com/in/kristoffer-zieba) - found Swedish data sources


### Possible Improvements

Find and megre more detailed (state/county wise) or newer datasource  ",.csv,True
Global Hospital Beds Capacity (for covid-19),18,global-hospital-beds-capacity-for-covid19,hospital_beds_global_v1.csv,CC0-1.0,"### DISCLAIMER
Dataset consists of historical data of pre-pandemic period and doesn’t represent the current reality which may have changed due to the spikes in demand.
This dataset has been generated in collaboration of efforts within [CoronaWhy](https://www.coronawhy.org/) community.


### Context

Last updated: April 26th 2020
Updates:
April 14th 2020 - Added missing population data
April 15th 2020 - Added Brazil statewise  ICU hospital beds dataset
April 21th 2020 - Added Italy, Spain statewise  ICU hospital beds dataset, India statewise TOTAL hospital beds dataset
April 26th 2020 - Added Sweden ICU(2019) and TOTAL(2018) beds datasets

### Purpose of the dataset

I am trying to produce a dataset that will provide a foundation for policymakers to understand the realistic capacity of healthcare providers being able to deal with the spikes in demand for intensive care. As a way to help, I’ve prepared a dataset of beds across countries and states. Work in progress dataset that should and will be updated as more data becomes available and public on weekly basis.


### Importance

This dataset is intended to be used as a baseline for understanding the typical bed capacity and coverage globally. This information is critical for understanding the impact of a high utilization event, like COVID-19.


### Current challenges

Datasets are scattered across the web and are very hard to normalize, I did my best but help would be much appreciated.


### Data sources / Acknowledgments

arcgis (USA) - https://services1.arcgis.com/Hp6G80Pky0om7QvQ/arcgis/rest/services/Hospitals_1/FeatureServer/0
KHN (USA) - https://khn.org/news/as-coronavirus-spreads-widely-millions-of-older-americans-live-in-counties-with-no-icu-beds/
datahub.io (World) - https://datahub.io/world-bank/sh.med.beds.zs
eurostat - https://data.europa.eu/euodp/en/data/dataset/vswUL3c6yKoyahrvIRyew
OECD - https://data.oecd.org/healtheqt/hospital-beds.htm
WDI (World) - https://data.worldbank.org/indicator/SH.MED.BEDS.ZS
NHP(India) - http://www.cbhidghs.nic.in/showfile.php?lid=1147 
data.gov.sg (Singapore) - https://data.gov.sg/dataset/health-facilities?view_id=91b4feed-dcb9-4720-8cb0-ac2f04b7efd0&resource_id=dee5ccce-4dfb-467f-bcb4-dc025b56b977
dati.salute.gov.it (Italy)- http://www.dati.salute.gov.it/dati/dettaglioDataset.jsp?menu=dati&idPag=96
portal.icuregswe.org (Sweden) - https://portal.icuregswe.org/seiva/en/Rapport
publications:
Intensive Care Medicine Journal (Europe) - https://link.springer.com/article/10.1007/s00134-012-2627-8
Critical Care Medicine Journal (Asia) - https://www.researchgate.net/figure/Number-of-critical-care-beds-per-100-000-population_fig1_338520008
Medicina Intensiva (Spain) - https://www.medintensiva.org/en-pdf-S2173572713000878
news:
https://lanuovaferrara.gelocal.it/italia-mondo/cronaca/2020/03/19/news/dietro-la-corsa-a-nuovi-posti-in-terapia-intensiva-gli-errori-del-passato-1.38611596
kaggle:
germany - https://www.kaggle.com/manuelblechschmidt/icu-beds-in-germany
brazil (IBGE) - https://www.kaggle.com/thiagobodruk/brazilianstates
Manual population data search from wiki


### Data columns
country,state,county,lat,lng,type,measure,beds,population,year,source,source_url
- country - country of origin, if present
- state - more granular location, if present
- lat - latitude
- lng - longtitude
- type - [TOTAL, ICU, ACUTE(some data could include ICU beds too), PSYCHIATRIC, OTHER(merged ‘SPECIAL’, ‘CHRONIC DISEASE’, ‘CHILDREN’, ‘LONG TERM CARE’, ‘REHABILITATION’, ‘WOMEN’, ‘MILITARY’]
- measure - type of measure (per 1000 inhabitants)
- beds - number of beds per 1000
- population - population of location based on multiple sources and wikipedia
- year - source year for beds and population data
- source - source of data
- source_url - URL of the original source


### Files
for each of datasource: `hospital_beds_per_source.csv`

US only: US arcgis + khn (state/county granularity): `hospital_beds_USA.csv`

Global (state(region)/county granularity): `hospital_beds_global_regional.csv`

Global (country granularity): `hospital_beds_global_v1.csv`


### Contributors

[Igor Kiulian](https://www.linkedin.com/in/igor-kiulian/) - extracting/normalizing/formatting/merging data
[Artur Kiulian](https://www.linkedin.com/in/artur-kiulian/) - helped with Kaggle setup
[Augaly S. Kiedi](https://nl.linkedin.com/in/augalyskiedi) - helped with country population data
[Kristoffer Jan Zieba](https://no.linkedin.com/in/kristoffer-zieba) - found Swedish data sources


### Possible Improvements

Find and megre more detailed (state/county wise) or newer datasource  ",.csv,True
Global Hospital Beds Capacity (for covid-19),18,global-hospital-beds-capacity-for-covid19,hospital_beds_per_sweden_v1.csv,CC0-1.0,"### DISCLAIMER
Dataset consists of historical data of pre-pandemic period and doesn’t represent the current reality which may have changed due to the spikes in demand.
This dataset has been generated in collaboration of efforts within [CoronaWhy](https://www.coronawhy.org/) community.


### Context

Last updated: April 26th 2020
Updates:
April 14th 2020 - Added missing population data
April 15th 2020 - Added Brazil statewise  ICU hospital beds dataset
April 21th 2020 - Added Italy, Spain statewise  ICU hospital beds dataset, India statewise TOTAL hospital beds dataset
April 26th 2020 - Added Sweden ICU(2019) and TOTAL(2018) beds datasets

### Purpose of the dataset

I am trying to produce a dataset that will provide a foundation for policymakers to understand the realistic capacity of healthcare providers being able to deal with the spikes in demand for intensive care. As a way to help, I’ve prepared a dataset of beds across countries and states. Work in progress dataset that should and will be updated as more data becomes available and public on weekly basis.


### Importance

This dataset is intended to be used as a baseline for understanding the typical bed capacity and coverage globally. This information is critical for understanding the impact of a high utilization event, like COVID-19.


### Current challenges

Datasets are scattered across the web and are very hard to normalize, I did my best but help would be much appreciated.


### Data sources / Acknowledgments

arcgis (USA) - https://services1.arcgis.com/Hp6G80Pky0om7QvQ/arcgis/rest/services/Hospitals_1/FeatureServer/0
KHN (USA) - https://khn.org/news/as-coronavirus-spreads-widely-millions-of-older-americans-live-in-counties-with-no-icu-beds/
datahub.io (World) - https://datahub.io/world-bank/sh.med.beds.zs
eurostat - https://data.europa.eu/euodp/en/data/dataset/vswUL3c6yKoyahrvIRyew
OECD - https://data.oecd.org/healtheqt/hospital-beds.htm
WDI (World) - https://data.worldbank.org/indicator/SH.MED.BEDS.ZS
NHP(India) - http://www.cbhidghs.nic.in/showfile.php?lid=1147 
data.gov.sg (Singapore) - https://data.gov.sg/dataset/health-facilities?view_id=91b4feed-dcb9-4720-8cb0-ac2f04b7efd0&resource_id=dee5ccce-4dfb-467f-bcb4-dc025b56b977
dati.salute.gov.it (Italy)- http://www.dati.salute.gov.it/dati/dettaglioDataset.jsp?menu=dati&idPag=96
portal.icuregswe.org (Sweden) - https://portal.icuregswe.org/seiva/en/Rapport
publications:
Intensive Care Medicine Journal (Europe) - https://link.springer.com/article/10.1007/s00134-012-2627-8
Critical Care Medicine Journal (Asia) - https://www.researchgate.net/figure/Number-of-critical-care-beds-per-100-000-population_fig1_338520008
Medicina Intensiva (Spain) - https://www.medintensiva.org/en-pdf-S2173572713000878
news:
https://lanuovaferrara.gelocal.it/italia-mondo/cronaca/2020/03/19/news/dietro-la-corsa-a-nuovi-posti-in-terapia-intensiva-gli-errori-del-passato-1.38611596
kaggle:
germany - https://www.kaggle.com/manuelblechschmidt/icu-beds-in-germany
brazil (IBGE) - https://www.kaggle.com/thiagobodruk/brazilianstates
Manual population data search from wiki


### Data columns
country,state,county,lat,lng,type,measure,beds,population,year,source,source_url
- country - country of origin, if present
- state - more granular location, if present
- lat - latitude
- lng - longtitude
- type - [TOTAL, ICU, ACUTE(some data could include ICU beds too), PSYCHIATRIC, OTHER(merged ‘SPECIAL’, ‘CHRONIC DISEASE’, ‘CHILDREN’, ‘LONG TERM CARE’, ‘REHABILITATION’, ‘WOMEN’, ‘MILITARY’]
- measure - type of measure (per 1000 inhabitants)
- beds - number of beds per 1000
- population - population of location based on multiple sources and wikipedia
- year - source year for beds and population data
- source - source of data
- source_url - URL of the original source


### Files
for each of datasource: `hospital_beds_per_source.csv`

US only: US arcgis + khn (state/county granularity): `hospital_beds_USA.csv`

Global (state(region)/county granularity): `hospital_beds_global_regional.csv`

Global (country granularity): `hospital_beds_global_v1.csv`


### Contributors

[Igor Kiulian](https://www.linkedin.com/in/igor-kiulian/) - extracting/normalizing/formatting/merging data
[Artur Kiulian](https://www.linkedin.com/in/artur-kiulian/) - helped with Kaggle setup
[Augaly S. Kiedi](https://nl.linkedin.com/in/augalyskiedi) - helped with country population data
[Kristoffer Jan Zieba](https://no.linkedin.com/in/kristoffer-zieba) - found Swedish data sources


### Possible Improvements

Find and megre more detailed (state/county wise) or newer datasource  ",.csv,True
Global Hospital Beds Capacity (for covid-19),18,global-hospital-beds-capacity-for-covid19,hospital_beds_per_wdi_v1.csv,CC0-1.0,"### DISCLAIMER
Dataset consists of historical data of pre-pandemic period and doesn’t represent the current reality which may have changed due to the spikes in demand.
This dataset has been generated in collaboration of efforts within [CoronaWhy](https://www.coronawhy.org/) community.


### Context

Last updated: April 26th 2020
Updates:
April 14th 2020 - Added missing population data
April 15th 2020 - Added Brazil statewise  ICU hospital beds dataset
April 21th 2020 - Added Italy, Spain statewise  ICU hospital beds dataset, India statewise TOTAL hospital beds dataset
April 26th 2020 - Added Sweden ICU(2019) and TOTAL(2018) beds datasets

### Purpose of the dataset

I am trying to produce a dataset that will provide a foundation for policymakers to understand the realistic capacity of healthcare providers being able to deal with the spikes in demand for intensive care. As a way to help, I’ve prepared a dataset of beds across countries and states. Work in progress dataset that should and will be updated as more data becomes available and public on weekly basis.


### Importance

This dataset is intended to be used as a baseline for understanding the typical bed capacity and coverage globally. This information is critical for understanding the impact of a high utilization event, like COVID-19.


### Current challenges

Datasets are scattered across the web and are very hard to normalize, I did my best but help would be much appreciated.


### Data sources / Acknowledgments

arcgis (USA) - https://services1.arcgis.com/Hp6G80Pky0om7QvQ/arcgis/rest/services/Hospitals_1/FeatureServer/0
KHN (USA) - https://khn.org/news/as-coronavirus-spreads-widely-millions-of-older-americans-live-in-counties-with-no-icu-beds/
datahub.io (World) - https://datahub.io/world-bank/sh.med.beds.zs
eurostat - https://data.europa.eu/euodp/en/data/dataset/vswUL3c6yKoyahrvIRyew
OECD - https://data.oecd.org/healtheqt/hospital-beds.htm
WDI (World) - https://data.worldbank.org/indicator/SH.MED.BEDS.ZS
NHP(India) - http://www.cbhidghs.nic.in/showfile.php?lid=1147 
data.gov.sg (Singapore) - https://data.gov.sg/dataset/health-facilities?view_id=91b4feed-dcb9-4720-8cb0-ac2f04b7efd0&resource_id=dee5ccce-4dfb-467f-bcb4-dc025b56b977
dati.salute.gov.it (Italy)- http://www.dati.salute.gov.it/dati/dettaglioDataset.jsp?menu=dati&idPag=96
portal.icuregswe.org (Sweden) - https://portal.icuregswe.org/seiva/en/Rapport
publications:
Intensive Care Medicine Journal (Europe) - https://link.springer.com/article/10.1007/s00134-012-2627-8
Critical Care Medicine Journal (Asia) - https://www.researchgate.net/figure/Number-of-critical-care-beds-per-100-000-population_fig1_338520008
Medicina Intensiva (Spain) - https://www.medintensiva.org/en-pdf-S2173572713000878
news:
https://lanuovaferrara.gelocal.it/italia-mondo/cronaca/2020/03/19/news/dietro-la-corsa-a-nuovi-posti-in-terapia-intensiva-gli-errori-del-passato-1.38611596
kaggle:
germany - https://www.kaggle.com/manuelblechschmidt/icu-beds-in-germany
brazil (IBGE) - https://www.kaggle.com/thiagobodruk/brazilianstates
Manual population data search from wiki


### Data columns
country,state,county,lat,lng,type,measure,beds,population,year,source,source_url
- country - country of origin, if present
- state - more granular location, if present
- lat - latitude
- lng - longtitude
- type - [TOTAL, ICU, ACUTE(some data could include ICU beds too), PSYCHIATRIC, OTHER(merged ‘SPECIAL’, ‘CHRONIC DISEASE’, ‘CHILDREN’, ‘LONG TERM CARE’, ‘REHABILITATION’, ‘WOMEN’, ‘MILITARY’]
- measure - type of measure (per 1000 inhabitants)
- beds - number of beds per 1000
- population - population of location based on multiple sources and wikipedia
- year - source year for beds and population data
- source - source of data
- source_url - URL of the original source


### Files
for each of datasource: `hospital_beds_per_source.csv`

US only: US arcgis + khn (state/county granularity): `hospital_beds_USA.csv`

Global (state(region)/county granularity): `hospital_beds_global_regional.csv`

Global (country granularity): `hospital_beds_global_v1.csv`


### Contributors

[Igor Kiulian](https://www.linkedin.com/in/igor-kiulian/) - extracting/normalizing/formatting/merging data
[Artur Kiulian](https://www.linkedin.com/in/artur-kiulian/) - helped with Kaggle setup
[Augaly S. Kiedi](https://nl.linkedin.com/in/augalyskiedi) - helped with country population data
[Kristoffer Jan Zieba](https://no.linkedin.com/in/kristoffer-zieba) - found Swedish data sources


### Possible Improvements

Find and megre more detailed (state/county wise) or newer datasource  ",.csv,True
Global Hospital Beds Capacity (for covid-19),18,global-hospital-beds-capacity-for-covid19,hospital_beds_per_italy_v1.csv,CC0-1.0,"### DISCLAIMER
Dataset consists of historical data of pre-pandemic period and doesn’t represent the current reality which may have changed due to the spikes in demand.
This dataset has been generated in collaboration of efforts within [CoronaWhy](https://www.coronawhy.org/) community.


### Context

Last updated: April 26th 2020
Updates:
April 14th 2020 - Added missing population data
April 15th 2020 - Added Brazil statewise  ICU hospital beds dataset
April 21th 2020 - Added Italy, Spain statewise  ICU hospital beds dataset, India statewise TOTAL hospital beds dataset
April 26th 2020 - Added Sweden ICU(2019) and TOTAL(2018) beds datasets

### Purpose of the dataset

I am trying to produce a dataset that will provide a foundation for policymakers to understand the realistic capacity of healthcare providers being able to deal with the spikes in demand for intensive care. As a way to help, I’ve prepared a dataset of beds across countries and states. Work in progress dataset that should and will be updated as more data becomes available and public on weekly basis.


### Importance

This dataset is intended to be used as a baseline for understanding the typical bed capacity and coverage globally. This information is critical for understanding the impact of a high utilization event, like COVID-19.


### Current challenges

Datasets are scattered across the web and are very hard to normalize, I did my best but help would be much appreciated.


### Data sources / Acknowledgments

arcgis (USA) - https://services1.arcgis.com/Hp6G80Pky0om7QvQ/arcgis/rest/services/Hospitals_1/FeatureServer/0
KHN (USA) - https://khn.org/news/as-coronavirus-spreads-widely-millions-of-older-americans-live-in-counties-with-no-icu-beds/
datahub.io (World) - https://datahub.io/world-bank/sh.med.beds.zs
eurostat - https://data.europa.eu/euodp/en/data/dataset/vswUL3c6yKoyahrvIRyew
OECD - https://data.oecd.org/healtheqt/hospital-beds.htm
WDI (World) - https://data.worldbank.org/indicator/SH.MED.BEDS.ZS
NHP(India) - http://www.cbhidghs.nic.in/showfile.php?lid=1147 
data.gov.sg (Singapore) - https://data.gov.sg/dataset/health-facilities?view_id=91b4feed-dcb9-4720-8cb0-ac2f04b7efd0&resource_id=dee5ccce-4dfb-467f-bcb4-dc025b56b977
dati.salute.gov.it (Italy)- http://www.dati.salute.gov.it/dati/dettaglioDataset.jsp?menu=dati&idPag=96
portal.icuregswe.org (Sweden) - https://portal.icuregswe.org/seiva/en/Rapport
publications:
Intensive Care Medicine Journal (Europe) - https://link.springer.com/article/10.1007/s00134-012-2627-8
Critical Care Medicine Journal (Asia) - https://www.researchgate.net/figure/Number-of-critical-care-beds-per-100-000-population_fig1_338520008
Medicina Intensiva (Spain) - https://www.medintensiva.org/en-pdf-S2173572713000878
news:
https://lanuovaferrara.gelocal.it/italia-mondo/cronaca/2020/03/19/news/dietro-la-corsa-a-nuovi-posti-in-terapia-intensiva-gli-errori-del-passato-1.38611596
kaggle:
germany - https://www.kaggle.com/manuelblechschmidt/icu-beds-in-germany
brazil (IBGE) - https://www.kaggle.com/thiagobodruk/brazilianstates
Manual population data search from wiki


### Data columns
country,state,county,lat,lng,type,measure,beds,population,year,source,source_url
- country - country of origin, if present
- state - more granular location, if present
- lat - latitude
- lng - longtitude
- type - [TOTAL, ICU, ACUTE(some data could include ICU beds too), PSYCHIATRIC, OTHER(merged ‘SPECIAL’, ‘CHRONIC DISEASE’, ‘CHILDREN’, ‘LONG TERM CARE’, ‘REHABILITATION’, ‘WOMEN’, ‘MILITARY’]
- measure - type of measure (per 1000 inhabitants)
- beds - number of beds per 1000
- population - population of location based on multiple sources and wikipedia
- year - source year for beds and population data
- source - source of data
- source_url - URL of the original source


### Files
for each of datasource: `hospital_beds_per_source.csv`

US only: US arcgis + khn (state/county granularity): `hospital_beds_USA.csv`

Global (state(region)/county granularity): `hospital_beds_global_regional.csv`

Global (country granularity): `hospital_beds_global_v1.csv`


### Contributors

[Igor Kiulian](https://www.linkedin.com/in/igor-kiulian/) - extracting/normalizing/formatting/merging data
[Artur Kiulian](https://www.linkedin.com/in/artur-kiulian/) - helped with Kaggle setup
[Augaly S. Kiedi](https://nl.linkedin.com/in/augalyskiedi) - helped with country population data
[Kristoffer Jan Zieba](https://no.linkedin.com/in/kristoffer-zieba) - found Swedish data sources


### Possible Improvements

Find and megre more detailed (state/county wise) or newer datasource  ",.csv,True
Global Hospital Beds Capacity (for covid-19),18,global-hospital-beds-capacity-for-covid19,hospital_beds_global_regional_v1.csv,CC0-1.0,"### DISCLAIMER
Dataset consists of historical data of pre-pandemic period and doesn’t represent the current reality which may have changed due to the spikes in demand.
This dataset has been generated in collaboration of efforts within [CoronaWhy](https://www.coronawhy.org/) community.


### Context

Last updated: April 26th 2020
Updates:
April 14th 2020 - Added missing population data
April 15th 2020 - Added Brazil statewise  ICU hospital beds dataset
April 21th 2020 - Added Italy, Spain statewise  ICU hospital beds dataset, India statewise TOTAL hospital beds dataset
April 26th 2020 - Added Sweden ICU(2019) and TOTAL(2018) beds datasets

### Purpose of the dataset

I am trying to produce a dataset that will provide a foundation for policymakers to understand the realistic capacity of healthcare providers being able to deal with the spikes in demand for intensive care. As a way to help, I’ve prepared a dataset of beds across countries and states. Work in progress dataset that should and will be updated as more data becomes available and public on weekly basis.


### Importance

This dataset is intended to be used as a baseline for understanding the typical bed capacity and coverage globally. This information is critical for understanding the impact of a high utilization event, like COVID-19.


### Current challenges

Datasets are scattered across the web and are very hard to normalize, I did my best but help would be much appreciated.


### Data sources / Acknowledgments

arcgis (USA) - https://services1.arcgis.com/Hp6G80Pky0om7QvQ/arcgis/rest/services/Hospitals_1/FeatureServer/0
KHN (USA) - https://khn.org/news/as-coronavirus-spreads-widely-millions-of-older-americans-live-in-counties-with-no-icu-beds/
datahub.io (World) - https://datahub.io/world-bank/sh.med.beds.zs
eurostat - https://data.europa.eu/euodp/en/data/dataset/vswUL3c6yKoyahrvIRyew
OECD - https://data.oecd.org/healtheqt/hospital-beds.htm
WDI (World) - https://data.worldbank.org/indicator/SH.MED.BEDS.ZS
NHP(India) - http://www.cbhidghs.nic.in/showfile.php?lid=1147 
data.gov.sg (Singapore) - https://data.gov.sg/dataset/health-facilities?view_id=91b4feed-dcb9-4720-8cb0-ac2f04b7efd0&resource_id=dee5ccce-4dfb-467f-bcb4-dc025b56b977
dati.salute.gov.it (Italy)- http://www.dati.salute.gov.it/dati/dettaglioDataset.jsp?menu=dati&idPag=96
portal.icuregswe.org (Sweden) - https://portal.icuregswe.org/seiva/en/Rapport
publications:
Intensive Care Medicine Journal (Europe) - https://link.springer.com/article/10.1007/s00134-012-2627-8
Critical Care Medicine Journal (Asia) - https://www.researchgate.net/figure/Number-of-critical-care-beds-per-100-000-population_fig1_338520008
Medicina Intensiva (Spain) - https://www.medintensiva.org/en-pdf-S2173572713000878
news:
https://lanuovaferrara.gelocal.it/italia-mondo/cronaca/2020/03/19/news/dietro-la-corsa-a-nuovi-posti-in-terapia-intensiva-gli-errori-del-passato-1.38611596
kaggle:
germany - https://www.kaggle.com/manuelblechschmidt/icu-beds-in-germany
brazil (IBGE) - https://www.kaggle.com/thiagobodruk/brazilianstates
Manual population data search from wiki


### Data columns
country,state,county,lat,lng,type,measure,beds,population,year,source,source_url
- country - country of origin, if present
- state - more granular location, if present
- lat - latitude
- lng - longtitude
- type - [TOTAL, ICU, ACUTE(some data could include ICU beds too), PSYCHIATRIC, OTHER(merged ‘SPECIAL’, ‘CHRONIC DISEASE’, ‘CHILDREN’, ‘LONG TERM CARE’, ‘REHABILITATION’, ‘WOMEN’, ‘MILITARY’]
- measure - type of measure (per 1000 inhabitants)
- beds - number of beds per 1000
- population - population of location based on multiple sources and wikipedia
- year - source year for beds and population data
- source - source of data
- source_url - URL of the original source


### Files
for each of datasource: `hospital_beds_per_source.csv`

US only: US arcgis + khn (state/county granularity): `hospital_beds_USA.csv`

Global (state(region)/county granularity): `hospital_beds_global_regional.csv`

Global (country granularity): `hospital_beds_global_v1.csv`


### Contributors

[Igor Kiulian](https://www.linkedin.com/in/igor-kiulian/) - extracting/normalizing/formatting/merging data
[Artur Kiulian](https://www.linkedin.com/in/artur-kiulian/) - helped with Kaggle setup
[Augaly S. Kiedi](https://nl.linkedin.com/in/augalyskiedi) - helped with country population data
[Kristoffer Jan Zieba](https://no.linkedin.com/in/kristoffer-zieba) - found Swedish data sources


### Possible Improvements

Find and megre more detailed (state/county wise) or newer datasource  ",.csv,True
Global Hospital Beds Capacity (for covid-19),18,global-hospital-beds-capacity-for-covid19,hospital_beds_per_ibge_v1.csv,CC0-1.0,"### DISCLAIMER
Dataset consists of historical data of pre-pandemic period and doesn’t represent the current reality which may have changed due to the spikes in demand.
This dataset has been generated in collaboration of efforts within [CoronaWhy](https://www.coronawhy.org/) community.


### Context

Last updated: April 26th 2020
Updates:
April 14th 2020 - Added missing population data
April 15th 2020 - Added Brazil statewise  ICU hospital beds dataset
April 21th 2020 - Added Italy, Spain statewise  ICU hospital beds dataset, India statewise TOTAL hospital beds dataset
April 26th 2020 - Added Sweden ICU(2019) and TOTAL(2018) beds datasets

### Purpose of the dataset

I am trying to produce a dataset that will provide a foundation for policymakers to understand the realistic capacity of healthcare providers being able to deal with the spikes in demand for intensive care. As a way to help, I’ve prepared a dataset of beds across countries and states. Work in progress dataset that should and will be updated as more data becomes available and public on weekly basis.


### Importance

This dataset is intended to be used as a baseline for understanding the typical bed capacity and coverage globally. This information is critical for understanding the impact of a high utilization event, like COVID-19.


### Current challenges

Datasets are scattered across the web and are very hard to normalize, I did my best but help would be much appreciated.


### Data sources / Acknowledgments

arcgis (USA) - https://services1.arcgis.com/Hp6G80Pky0om7QvQ/arcgis/rest/services/Hospitals_1/FeatureServer/0
KHN (USA) - https://khn.org/news/as-coronavirus-spreads-widely-millions-of-older-americans-live-in-counties-with-no-icu-beds/
datahub.io (World) - https://datahub.io/world-bank/sh.med.beds.zs
eurostat - https://data.europa.eu/euodp/en/data/dataset/vswUL3c6yKoyahrvIRyew
OECD - https://data.oecd.org/healtheqt/hospital-beds.htm
WDI (World) - https://data.worldbank.org/indicator/SH.MED.BEDS.ZS
NHP(India) - http://www.cbhidghs.nic.in/showfile.php?lid=1147 
data.gov.sg (Singapore) - https://data.gov.sg/dataset/health-facilities?view_id=91b4feed-dcb9-4720-8cb0-ac2f04b7efd0&resource_id=dee5ccce-4dfb-467f-bcb4-dc025b56b977
dati.salute.gov.it (Italy)- http://www.dati.salute.gov.it/dati/dettaglioDataset.jsp?menu=dati&idPag=96
portal.icuregswe.org (Sweden) - https://portal.icuregswe.org/seiva/en/Rapport
publications:
Intensive Care Medicine Journal (Europe) - https://link.springer.com/article/10.1007/s00134-012-2627-8
Critical Care Medicine Journal (Asia) - https://www.researchgate.net/figure/Number-of-critical-care-beds-per-100-000-population_fig1_338520008
Medicina Intensiva (Spain) - https://www.medintensiva.org/en-pdf-S2173572713000878
news:
https://lanuovaferrara.gelocal.it/italia-mondo/cronaca/2020/03/19/news/dietro-la-corsa-a-nuovi-posti-in-terapia-intensiva-gli-errori-del-passato-1.38611596
kaggle:
germany - https://www.kaggle.com/manuelblechschmidt/icu-beds-in-germany
brazil (IBGE) - https://www.kaggle.com/thiagobodruk/brazilianstates
Manual population data search from wiki


### Data columns
country,state,county,lat,lng,type,measure,beds,population,year,source,source_url
- country - country of origin, if present
- state - more granular location, if present
- lat - latitude
- lng - longtitude
- type - [TOTAL, ICU, ACUTE(some data could include ICU beds too), PSYCHIATRIC, OTHER(merged ‘SPECIAL’, ‘CHRONIC DISEASE’, ‘CHILDREN’, ‘LONG TERM CARE’, ‘REHABILITATION’, ‘WOMEN’, ‘MILITARY’]
- measure - type of measure (per 1000 inhabitants)
- beds - number of beds per 1000
- population - population of location based on multiple sources and wikipedia
- year - source year for beds and population data
- source - source of data
- source_url - URL of the original source


### Files
for each of datasource: `hospital_beds_per_source.csv`

US only: US arcgis + khn (state/county granularity): `hospital_beds_USA.csv`

Global (state(region)/county granularity): `hospital_beds_global_regional.csv`

Global (country granularity): `hospital_beds_global_v1.csv`


### Contributors

[Igor Kiulian](https://www.linkedin.com/in/igor-kiulian/) - extracting/normalizing/formatting/merging data
[Artur Kiulian](https://www.linkedin.com/in/artur-kiulian/) - helped with Kaggle setup
[Augaly S. Kiedi](https://nl.linkedin.com/in/augalyskiedi) - helped with country population data
[Kristoffer Jan Zieba](https://no.linkedin.com/in/kristoffer-zieba) - found Swedish data sources


### Possible Improvements

Find and megre more detailed (state/county wise) or newer datasource  ",.csv,True
Global Hospital Beds Capacity (for covid-19),18,global-hospital-beds-capacity-for-covid19,hospital_beds_USA_v1.csv,CC0-1.0,"### DISCLAIMER
Dataset consists of historical data of pre-pandemic period and doesn’t represent the current reality which may have changed due to the spikes in demand.
This dataset has been generated in collaboration of efforts within [CoronaWhy](https://www.coronawhy.org/) community.


### Context

Last updated: April 26th 2020
Updates:
April 14th 2020 - Added missing population data
April 15th 2020 - Added Brazil statewise  ICU hospital beds dataset
April 21th 2020 - Added Italy, Spain statewise  ICU hospital beds dataset, India statewise TOTAL hospital beds dataset
April 26th 2020 - Added Sweden ICU(2019) and TOTAL(2018) beds datasets

### Purpose of the dataset

I am trying to produce a dataset that will provide a foundation for policymakers to understand the realistic capacity of healthcare providers being able to deal with the spikes in demand for intensive care. As a way to help, I’ve prepared a dataset of beds across countries and states. Work in progress dataset that should and will be updated as more data becomes available and public on weekly basis.


### Importance

This dataset is intended to be used as a baseline for understanding the typical bed capacity and coverage globally. This information is critical for understanding the impact of a high utilization event, like COVID-19.


### Current challenges

Datasets are scattered across the web and are very hard to normalize, I did my best but help would be much appreciated.


### Data sources / Acknowledgments

arcgis (USA) - https://services1.arcgis.com/Hp6G80Pky0om7QvQ/arcgis/rest/services/Hospitals_1/FeatureServer/0
KHN (USA) - https://khn.org/news/as-coronavirus-spreads-widely-millions-of-older-americans-live-in-counties-with-no-icu-beds/
datahub.io (World) - https://datahub.io/world-bank/sh.med.beds.zs
eurostat - https://data.europa.eu/euodp/en/data/dataset/vswUL3c6yKoyahrvIRyew
OECD - https://data.oecd.org/healtheqt/hospital-beds.htm
WDI (World) - https://data.worldbank.org/indicator/SH.MED.BEDS.ZS
NHP(India) - http://www.cbhidghs.nic.in/showfile.php?lid=1147 
data.gov.sg (Singapore) - https://data.gov.sg/dataset/health-facilities?view_id=91b4feed-dcb9-4720-8cb0-ac2f04b7efd0&resource_id=dee5ccce-4dfb-467f-bcb4-dc025b56b977
dati.salute.gov.it (Italy)- http://www.dati.salute.gov.it/dati/dettaglioDataset.jsp?menu=dati&idPag=96
portal.icuregswe.org (Sweden) - https://portal.icuregswe.org/seiva/en/Rapport
publications:
Intensive Care Medicine Journal (Europe) - https://link.springer.com/article/10.1007/s00134-012-2627-8
Critical Care Medicine Journal (Asia) - https://www.researchgate.net/figure/Number-of-critical-care-beds-per-100-000-population_fig1_338520008
Medicina Intensiva (Spain) - https://www.medintensiva.org/en-pdf-S2173572713000878
news:
https://lanuovaferrara.gelocal.it/italia-mondo/cronaca/2020/03/19/news/dietro-la-corsa-a-nuovi-posti-in-terapia-intensiva-gli-errori-del-passato-1.38611596
kaggle:
germany - https://www.kaggle.com/manuelblechschmidt/icu-beds-in-germany
brazil (IBGE) - https://www.kaggle.com/thiagobodruk/brazilianstates
Manual population data search from wiki


### Data columns
country,state,county,lat,lng,type,measure,beds,population,year,source,source_url
- country - country of origin, if present
- state - more granular location, if present
- lat - latitude
- lng - longtitude
- type - [TOTAL, ICU, ACUTE(some data could include ICU beds too), PSYCHIATRIC, OTHER(merged ‘SPECIAL’, ‘CHRONIC DISEASE’, ‘CHILDREN’, ‘LONG TERM CARE’, ‘REHABILITATION’, ‘WOMEN’, ‘MILITARY’]
- measure - type of measure (per 1000 inhabitants)
- beds - number of beds per 1000
- population - population of location based on multiple sources and wikipedia
- year - source year for beds and population data
- source - source of data
- source_url - URL of the original source


### Files
for each of datasource: `hospital_beds_per_source.csv`

US only: US arcgis + khn (state/county granularity): `hospital_beds_USA.csv`

Global (state(region)/county granularity): `hospital_beds_global_regional.csv`

Global (country granularity): `hospital_beds_global_v1.csv`


### Contributors

[Igor Kiulian](https://www.linkedin.com/in/igor-kiulian/) - extracting/normalizing/formatting/merging data
[Artur Kiulian](https://www.linkedin.com/in/artur-kiulian/) - helped with Kaggle setup
[Augaly S. Kiedi](https://nl.linkedin.com/in/augalyskiedi) - helped with country population data
[Kristoffer Jan Zieba](https://no.linkedin.com/in/kristoffer-zieba) - found Swedish data sources


### Possible Improvements

Find and megre more detailed (state/county wise) or newer datasource  ",.csv,True
Global Hospital Beds Capacity (for covid-19),18,global-hospital-beds-capacity-for-covid19,hospital_beds_per_oecd_v1.csv,CC0-1.0,"### DISCLAIMER
Dataset consists of historical data of pre-pandemic period and doesn’t represent the current reality which may have changed due to the spikes in demand.
This dataset has been generated in collaboration of efforts within [CoronaWhy](https://www.coronawhy.org/) community.


### Context

Last updated: April 26th 2020
Updates:
April 14th 2020 - Added missing population data
April 15th 2020 - Added Brazil statewise  ICU hospital beds dataset
April 21th 2020 - Added Italy, Spain statewise  ICU hospital beds dataset, India statewise TOTAL hospital beds dataset
April 26th 2020 - Added Sweden ICU(2019) and TOTAL(2018) beds datasets

### Purpose of the dataset

I am trying to produce a dataset that will provide a foundation for policymakers to understand the realistic capacity of healthcare providers being able to deal with the spikes in demand for intensive care. As a way to help, I’ve prepared a dataset of beds across countries and states. Work in progress dataset that should and will be updated as more data becomes available and public on weekly basis.


### Importance

This dataset is intended to be used as a baseline for understanding the typical bed capacity and coverage globally. This information is critical for understanding the impact of a high utilization event, like COVID-19.


### Current challenges

Datasets are scattered across the web and are very hard to normalize, I did my best but help would be much appreciated.


### Data sources / Acknowledgments

arcgis (USA) - https://services1.arcgis.com/Hp6G80Pky0om7QvQ/arcgis/rest/services/Hospitals_1/FeatureServer/0
KHN (USA) - https://khn.org/news/as-coronavirus-spreads-widely-millions-of-older-americans-live-in-counties-with-no-icu-beds/
datahub.io (World) - https://datahub.io/world-bank/sh.med.beds.zs
eurostat - https://data.europa.eu/euodp/en/data/dataset/vswUL3c6yKoyahrvIRyew
OECD - https://data.oecd.org/healtheqt/hospital-beds.htm
WDI (World) - https://data.worldbank.org/indicator/SH.MED.BEDS.ZS
NHP(India) - http://www.cbhidghs.nic.in/showfile.php?lid=1147 
data.gov.sg (Singapore) - https://data.gov.sg/dataset/health-facilities?view_id=91b4feed-dcb9-4720-8cb0-ac2f04b7efd0&resource_id=dee5ccce-4dfb-467f-bcb4-dc025b56b977
dati.salute.gov.it (Italy)- http://www.dati.salute.gov.it/dati/dettaglioDataset.jsp?menu=dati&idPag=96
portal.icuregswe.org (Sweden) - https://portal.icuregswe.org/seiva/en/Rapport
publications:
Intensive Care Medicine Journal (Europe) - https://link.springer.com/article/10.1007/s00134-012-2627-8
Critical Care Medicine Journal (Asia) - https://www.researchgate.net/figure/Number-of-critical-care-beds-per-100-000-population_fig1_338520008
Medicina Intensiva (Spain) - https://www.medintensiva.org/en-pdf-S2173572713000878
news:
https://lanuovaferrara.gelocal.it/italia-mondo/cronaca/2020/03/19/news/dietro-la-corsa-a-nuovi-posti-in-terapia-intensiva-gli-errori-del-passato-1.38611596
kaggle:
germany - https://www.kaggle.com/manuelblechschmidt/icu-beds-in-germany
brazil (IBGE) - https://www.kaggle.com/thiagobodruk/brazilianstates
Manual population data search from wiki


### Data columns
country,state,county,lat,lng,type,measure,beds,population,year,source,source_url
- country - country of origin, if present
- state - more granular location, if present
- lat - latitude
- lng - longtitude
- type - [TOTAL, ICU, ACUTE(some data could include ICU beds too), PSYCHIATRIC, OTHER(merged ‘SPECIAL’, ‘CHRONIC DISEASE’, ‘CHILDREN’, ‘LONG TERM CARE’, ‘REHABILITATION’, ‘WOMEN’, ‘MILITARY’]
- measure - type of measure (per 1000 inhabitants)
- beds - number of beds per 1000
- population - population of location based on multiple sources and wikipedia
- year - source year for beds and population data
- source - source of data
- source_url - URL of the original source


### Files
for each of datasource: `hospital_beds_per_source.csv`

US only: US arcgis + khn (state/county granularity): `hospital_beds_USA.csv`

Global (state(region)/county granularity): `hospital_beds_global_regional.csv`

Global (country granularity): `hospital_beds_global_v1.csv`


### Contributors

[Igor Kiulian](https://www.linkedin.com/in/igor-kiulian/) - extracting/normalizing/formatting/merging data
[Artur Kiulian](https://www.linkedin.com/in/artur-kiulian/) - helped with Kaggle setup
[Augaly S. Kiedi](https://nl.linkedin.com/in/augalyskiedi) - helped with country population data
[Kristoffer Jan Zieba](https://no.linkedin.com/in/kristoffer-zieba) - found Swedish data sources


### Possible Improvements

Find and megre more detailed (state/county wise) or newer datasource  ",.csv,True
Global Hospital Beds Capacity (for covid-19),18,global-hospital-beds-capacity-for-covid19,hospital_beds_per_knh_v1.csv,CC0-1.0,"### DISCLAIMER
Dataset consists of historical data of pre-pandemic period and doesn’t represent the current reality which may have changed due to the spikes in demand.
This dataset has been generated in collaboration of efforts within [CoronaWhy](https://www.coronawhy.org/) community.


### Context

Last updated: April 26th 2020
Updates:
April 14th 2020 - Added missing population data
April 15th 2020 - Added Brazil statewise  ICU hospital beds dataset
April 21th 2020 - Added Italy, Spain statewise  ICU hospital beds dataset, India statewise TOTAL hospital beds dataset
April 26th 2020 - Added Sweden ICU(2019) and TOTAL(2018) beds datasets

### Purpose of the dataset

I am trying to produce a dataset that will provide a foundation for policymakers to understand the realistic capacity of healthcare providers being able to deal with the spikes in demand for intensive care. As a way to help, I’ve prepared a dataset of beds across countries and states. Work in progress dataset that should and will be updated as more data becomes available and public on weekly basis.


### Importance

This dataset is intended to be used as a baseline for understanding the typical bed capacity and coverage globally. This information is critical for understanding the impact of a high utilization event, like COVID-19.


### Current challenges

Datasets are scattered across the web and are very hard to normalize, I did my best but help would be much appreciated.


### Data sources / Acknowledgments

arcgis (USA) - https://services1.arcgis.com/Hp6G80Pky0om7QvQ/arcgis/rest/services/Hospitals_1/FeatureServer/0
KHN (USA) - https://khn.org/news/as-coronavirus-spreads-widely-millions-of-older-americans-live-in-counties-with-no-icu-beds/
datahub.io (World) - https://datahub.io/world-bank/sh.med.beds.zs
eurostat - https://data.europa.eu/euodp/en/data/dataset/vswUL3c6yKoyahrvIRyew
OECD - https://data.oecd.org/healtheqt/hospital-beds.htm
WDI (World) - https://data.worldbank.org/indicator/SH.MED.BEDS.ZS
NHP(India) - http://www.cbhidghs.nic.in/showfile.php?lid=1147 
data.gov.sg (Singapore) - https://data.gov.sg/dataset/health-facilities?view_id=91b4feed-dcb9-4720-8cb0-ac2f04b7efd0&resource_id=dee5ccce-4dfb-467f-bcb4-dc025b56b977
dati.salute.gov.it (Italy)- http://www.dati.salute.gov.it/dati/dettaglioDataset.jsp?menu=dati&idPag=96
portal.icuregswe.org (Sweden) - https://portal.icuregswe.org/seiva/en/Rapport
publications:
Intensive Care Medicine Journal (Europe) - https://link.springer.com/article/10.1007/s00134-012-2627-8
Critical Care Medicine Journal (Asia) - https://www.researchgate.net/figure/Number-of-critical-care-beds-per-100-000-population_fig1_338520008
Medicina Intensiva (Spain) - https://www.medintensiva.org/en-pdf-S2173572713000878
news:
https://lanuovaferrara.gelocal.it/italia-mondo/cronaca/2020/03/19/news/dietro-la-corsa-a-nuovi-posti-in-terapia-intensiva-gli-errori-del-passato-1.38611596
kaggle:
germany - https://www.kaggle.com/manuelblechschmidt/icu-beds-in-germany
brazil (IBGE) - https://www.kaggle.com/thiagobodruk/brazilianstates
Manual population data search from wiki


### Data columns
country,state,county,lat,lng,type,measure,beds,population,year,source,source_url
- country - country of origin, if present
- state - more granular location, if present
- lat - latitude
- lng - longtitude
- type - [TOTAL, ICU, ACUTE(some data could include ICU beds too), PSYCHIATRIC, OTHER(merged ‘SPECIAL’, ‘CHRONIC DISEASE’, ‘CHILDREN’, ‘LONG TERM CARE’, ‘REHABILITATION’, ‘WOMEN’, ‘MILITARY’]
- measure - type of measure (per 1000 inhabitants)
- beds - number of beds per 1000
- population - population of location based on multiple sources and wikipedia
- year - source year for beds and population data
- source - source of data
- source_url - URL of the original source


### Files
for each of datasource: `hospital_beds_per_source.csv`

US only: US arcgis + khn (state/county granularity): `hospital_beds_USA.csv`

Global (state(region)/county granularity): `hospital_beds_global_regional.csv`

Global (country granularity): `hospital_beds_global_v1.csv`


### Contributors

[Igor Kiulian](https://www.linkedin.com/in/igor-kiulian/) - extracting/normalizing/formatting/merging data
[Artur Kiulian](https://www.linkedin.com/in/artur-kiulian/) - helped with Kaggle setup
[Augaly S. Kiedi](https://nl.linkedin.com/in/augalyskiedi) - helped with country population data
[Kristoffer Jan Zieba](https://no.linkedin.com/in/kristoffer-zieba) - found Swedish data sources


### Possible Improvements

Find and megre more detailed (state/county wise) or newer datasource  ",.csv,True
Global Hospital Beds Capacity (for covid-19),18,global-hospital-beds-capacity-for-covid19,hospital_beds_per_spain_v1.csv,CC0-1.0,"### DISCLAIMER
Dataset consists of historical data of pre-pandemic period and doesn’t represent the current reality which may have changed due to the spikes in demand.
This dataset has been generated in collaboration of efforts within [CoronaWhy](https://www.coronawhy.org/) community.


### Context

Last updated: April 26th 2020
Updates:
April 14th 2020 - Added missing population data
April 15th 2020 - Added Brazil statewise  ICU hospital beds dataset
April 21th 2020 - Added Italy, Spain statewise  ICU hospital beds dataset, India statewise TOTAL hospital beds dataset
April 26th 2020 - Added Sweden ICU(2019) and TOTAL(2018) beds datasets

### Purpose of the dataset

I am trying to produce a dataset that will provide a foundation for policymakers to understand the realistic capacity of healthcare providers being able to deal with the spikes in demand for intensive care. As a way to help, I’ve prepared a dataset of beds across countries and states. Work in progress dataset that should and will be updated as more data becomes available and public on weekly basis.


### Importance

This dataset is intended to be used as a baseline for understanding the typical bed capacity and coverage globally. This information is critical for understanding the impact of a high utilization event, like COVID-19.


### Current challenges

Datasets are scattered across the web and are very hard to normalize, I did my best but help would be much appreciated.


### Data sources / Acknowledgments

arcgis (USA) - https://services1.arcgis.com/Hp6G80Pky0om7QvQ/arcgis/rest/services/Hospitals_1/FeatureServer/0
KHN (USA) - https://khn.org/news/as-coronavirus-spreads-widely-millions-of-older-americans-live-in-counties-with-no-icu-beds/
datahub.io (World) - https://datahub.io/world-bank/sh.med.beds.zs
eurostat - https://data.europa.eu/euodp/en/data/dataset/vswUL3c6yKoyahrvIRyew
OECD - https://data.oecd.org/healtheqt/hospital-beds.htm
WDI (World) - https://data.worldbank.org/indicator/SH.MED.BEDS.ZS
NHP(India) - http://www.cbhidghs.nic.in/showfile.php?lid=1147 
data.gov.sg (Singapore) - https://data.gov.sg/dataset/health-facilities?view_id=91b4feed-dcb9-4720-8cb0-ac2f04b7efd0&resource_id=dee5ccce-4dfb-467f-bcb4-dc025b56b977
dati.salute.gov.it (Italy)- http://www.dati.salute.gov.it/dati/dettaglioDataset.jsp?menu=dati&idPag=96
portal.icuregswe.org (Sweden) - https://portal.icuregswe.org/seiva/en/Rapport
publications:
Intensive Care Medicine Journal (Europe) - https://link.springer.com/article/10.1007/s00134-012-2627-8
Critical Care Medicine Journal (Asia) - https://www.researchgate.net/figure/Number-of-critical-care-beds-per-100-000-population_fig1_338520008
Medicina Intensiva (Spain) - https://www.medintensiva.org/en-pdf-S2173572713000878
news:
https://lanuovaferrara.gelocal.it/italia-mondo/cronaca/2020/03/19/news/dietro-la-corsa-a-nuovi-posti-in-terapia-intensiva-gli-errori-del-passato-1.38611596
kaggle:
germany - https://www.kaggle.com/manuelblechschmidt/icu-beds-in-germany
brazil (IBGE) - https://www.kaggle.com/thiagobodruk/brazilianstates
Manual population data search from wiki


### Data columns
country,state,county,lat,lng,type,measure,beds,population,year,source,source_url
- country - country of origin, if present
- state - more granular location, if present
- lat - latitude
- lng - longtitude
- type - [TOTAL, ICU, ACUTE(some data could include ICU beds too), PSYCHIATRIC, OTHER(merged ‘SPECIAL’, ‘CHRONIC DISEASE’, ‘CHILDREN’, ‘LONG TERM CARE’, ‘REHABILITATION’, ‘WOMEN’, ‘MILITARY’]
- measure - type of measure (per 1000 inhabitants)
- beds - number of beds per 1000
- population - population of location based on multiple sources and wikipedia
- year - source year for beds and population data
- source - source of data
- source_url - URL of the original source


### Files
for each of datasource: `hospital_beds_per_source.csv`

US only: US arcgis + khn (state/county granularity): `hospital_beds_USA.csv`

Global (state(region)/county granularity): `hospital_beds_global_regional.csv`

Global (country granularity): `hospital_beds_global_v1.csv`


### Contributors

[Igor Kiulian](https://www.linkedin.com/in/igor-kiulian/) - extracting/normalizing/formatting/merging data
[Artur Kiulian](https://www.linkedin.com/in/artur-kiulian/) - helped with Kaggle setup
[Augaly S. Kiedi](https://nl.linkedin.com/in/augalyskiedi) - helped with country population data
[Kristoffer Jan Zieba](https://no.linkedin.com/in/kristoffer-zieba) - found Swedish data sources


### Possible Improvements

Find and megre more detailed (state/county wise) or newer datasource  ",.csv,True
Global News Engagement on Social Media,4,global-news-engagement-on-social-media,reuters.csv,ODC Attribution License (ODC-By),"This comprehensive dataset offers a deep dive into the social media engagement metrics of nearly 4,000 posts from four of the world's leading news channels: CNN, BBC, Al Jazeera, and Reuters. Curated to provide a holistic view of global news interaction on social media, the collection stands out for its meticulous assembly and broad spectrum of content.

**Dataset Overview:**
Spanning various global events, topics, and narratives, this dataset is a snapshot of how news is consumed and interacted with on social media platforms. It serves as a rich resource for analyzing trends, engagement patterns, and the dissemination of information across international borders.

**Data Science Applications:**
Ideal for researchers and enthusiasts in the fields of data science, media studies, and social analytics, this dataset opens doors to numerous explorations such as engagement analysis, trend forecasting, content strategy optimization, and the study of information flow in digital spaces. It also holds potential for machine learning projects aiming to predict engagement or classify content based on interaction metrics.

**Column Descriptors:**
Each record in the dataset is detailed with the following columns: 
- `text`: The title or main content of the post.
- `likes`: The number of likes each post has garnered.
- `comments`: The number of comments left by viewers.
- `shares`: How many times the post has been shared.

**Ethically Mined Data:**
The collection of this dataset was conducted with the highest ethical standards in mind, ensuring compliance with data privacy laws and platform policies. By anonymizing data where necessary and focusing solely on publicly available information, it respects both individual privacy and intellectual property rights.

Special thanks are extended to the Facebook platform and the respective news channels for their openness and the rich public data they provide. This dataset not only celebrates the vibrant exchange on social media but also underscores the importance of responsible data use and sharing in fostering understanding and innovation.",.csv,True
Global News Engagement on Social Media,4,global-news-engagement-on-social-media,cnn.csv,ODC Attribution License (ODC-By),"This comprehensive dataset offers a deep dive into the social media engagement metrics of nearly 4,000 posts from four of the world's leading news channels: CNN, BBC, Al Jazeera, and Reuters. Curated to provide a holistic view of global news interaction on social media, the collection stands out for its meticulous assembly and broad spectrum of content.

**Dataset Overview:**
Spanning various global events, topics, and narratives, this dataset is a snapshot of how news is consumed and interacted with on social media platforms. It serves as a rich resource for analyzing trends, engagement patterns, and the dissemination of information across international borders.

**Data Science Applications:**
Ideal for researchers and enthusiasts in the fields of data science, media studies, and social analytics, this dataset opens doors to numerous explorations such as engagement analysis, trend forecasting, content strategy optimization, and the study of information flow in digital spaces. It also holds potential for machine learning projects aiming to predict engagement or classify content based on interaction metrics.

**Column Descriptors:**
Each record in the dataset is detailed with the following columns: 
- `text`: The title or main content of the post.
- `likes`: The number of likes each post has garnered.
- `comments`: The number of comments left by viewers.
- `shares`: How many times the post has been shared.

**Ethically Mined Data:**
The collection of this dataset was conducted with the highest ethical standards in mind, ensuring compliance with data privacy laws and platform policies. By anonymizing data where necessary and focusing solely on publicly available information, it respects both individual privacy and intellectual property rights.

Special thanks are extended to the Facebook platform and the respective news channels for their openness and the rich public data they provide. This dataset not only celebrates the vibrant exchange on social media but also underscores the importance of responsible data use and sharing in fostering understanding and innovation.",.csv,True
Global News Engagement on Social Media,4,global-news-engagement-on-social-media,al_jazeera.csv,ODC Attribution License (ODC-By),"This comprehensive dataset offers a deep dive into the social media engagement metrics of nearly 4,000 posts from four of the world's leading news channels: CNN, BBC, Al Jazeera, and Reuters. Curated to provide a holistic view of global news interaction on social media, the collection stands out for its meticulous assembly and broad spectrum of content.

**Dataset Overview:**
Spanning various global events, topics, and narratives, this dataset is a snapshot of how news is consumed and interacted with on social media platforms. It serves as a rich resource for analyzing trends, engagement patterns, and the dissemination of information across international borders.

**Data Science Applications:**
Ideal for researchers and enthusiasts in the fields of data science, media studies, and social analytics, this dataset opens doors to numerous explorations such as engagement analysis, trend forecasting, content strategy optimization, and the study of information flow in digital spaces. It also holds potential for machine learning projects aiming to predict engagement or classify content based on interaction metrics.

**Column Descriptors:**
Each record in the dataset is detailed with the following columns: 
- `text`: The title or main content of the post.
- `likes`: The number of likes each post has garnered.
- `comments`: The number of comments left by viewers.
- `shares`: How many times the post has been shared.

**Ethically Mined Data:**
The collection of this dataset was conducted with the highest ethical standards in mind, ensuring compliance with data privacy laws and platform policies. By anonymizing data where necessary and focusing solely on publicly available information, it respects both individual privacy and intellectual property rights.

Special thanks are extended to the Facebook platform and the respective news channels for their openness and the rich public data they provide. This dataset not only celebrates the vibrant exchange on social media but also underscores the importance of responsible data use and sharing in fostering understanding and innovation.",.csv,True
Global News Engagement on Social Media,4,global-news-engagement-on-social-media,bbc.csv,ODC Attribution License (ODC-By),"This comprehensive dataset offers a deep dive into the social media engagement metrics of nearly 4,000 posts from four of the world's leading news channels: CNN, BBC, Al Jazeera, and Reuters. Curated to provide a holistic view of global news interaction on social media, the collection stands out for its meticulous assembly and broad spectrum of content.

**Dataset Overview:**
Spanning various global events, topics, and narratives, this dataset is a snapshot of how news is consumed and interacted with on social media platforms. It serves as a rich resource for analyzing trends, engagement patterns, and the dissemination of information across international borders.

**Data Science Applications:**
Ideal for researchers and enthusiasts in the fields of data science, media studies, and social analytics, this dataset opens doors to numerous explorations such as engagement analysis, trend forecasting, content strategy optimization, and the study of information flow in digital spaces. It also holds potential for machine learning projects aiming to predict engagement or classify content based on interaction metrics.

**Column Descriptors:**
Each record in the dataset is detailed with the following columns: 
- `text`: The title or main content of the post.
- `likes`: The number of likes each post has garnered.
- `comments`: The number of comments left by viewers.
- `shares`: How many times the post has been shared.

**Ethically Mined Data:**
The collection of this dataset was conducted with the highest ethical standards in mind, ensuring compliance with data privacy laws and platform policies. By anonymizing data where necessary and focusing solely on publicly available information, it respects both individual privacy and intellectual property rights.

Special thanks are extended to the Facebook platform and the respective news channels for their openness and the rich public data they provide. This dataset not only celebrates the vibrant exchange on social media but also underscores the importance of responsible data use and sharing in fostering understanding and innovation.",.csv,True
Gold Prices,2,gold-prices,annual_csv.csv,Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0),"### Context

Historical Annual and Monthly Gold Prices.


### Content

Historical Annual and Monthly Gold Prices. Retrieved from DataHub, and expected to be updated annually.


",.csv,True
Gold Prices,2,gold-prices,monthly_csv.csv,Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0),"### Context

Historical Annual and Monthly Gold Prices.


### Content

Historical Annual and Monthly Gold Prices. Retrieved from DataHub, and expected to be updated annually.


",.csv,True
Gold rates (1985 - Present),2,gold-rates-1985-jan-2022,daily_gold_rate.csv,CC0-1.0,"### Context

Gold rates differ from place to place, here is the dataset which included major six countries' Gold rates. This data can also be viewed as a Time Series data.



### Content

This dataset contains two csv files - 
-**Daily gold rates** : which includes daily data of gold rates from 1st Jan 1985 to 8th September 2023
-**Annual average gold rates** : this file includes average annual gold rate in their national currency from 1978 to 2021
-The rates are in their national currencies and per troy ounce
-Currencies included are USD, INR, AED, EUR, GBP, CNY

### Acknowledgements

This data was collected from [https://www.gold.org/goldhub](https://www.gold.org/goldhub) and then cleaned.
Banner by [Unsplash](https://unsplash.com/photos/xXq_6_Kwysc)


### Inspiration

**Things which can be done with this data:**
- Time series analysis and prediction
- EDA and Visualization of the gold rates 
- Country that has highest and lowest rate in their national currency (Latest Years)

",.csv,True
Gold rates (1985 - Present),2,gold-rates-1985-jan-2022,annual_gold_rate.csv,CC0-1.0,"### Context

Gold rates differ from place to place, here is the dataset which included major six countries' Gold rates. This data can also be viewed as a Time Series data.



### Content

This dataset contains two csv files - 
-**Daily gold rates** : which includes daily data of gold rates from 1st Jan 1985 to 8th September 2023
-**Annual average gold rates** : this file includes average annual gold rate in their national currency from 1978 to 2021
-The rates are in their national currencies and per troy ounce
-Currencies included are USD, INR, AED, EUR, GBP, CNY

### Acknowledgements

This data was collected from [https://www.gold.org/goldhub](https://www.gold.org/goldhub) and then cleaned.
Banner by [Unsplash](https://unsplash.com/photos/xXq_6_Kwysc)


### Inspiration

**Things which can be done with this data:**
- Time series analysis and prediction
- EDA and Visualization of the gold rates 
- Country that has highest and lowest rate in their national currency (Latest Years)

",.csv,True
HOUSE PRICE PREDICTION - SEATTLE,2,house-price-prediction-seattle,test.csv,CC0-1.0,"This is a **real dataset** of house prices sold in **Seattle, Washing, USA** between August and December 2022. The task is to predict the house price in this area based on several features, which are described below. 

| Feature     | Description |
| ----------- | ----------- |
| beds     | Number of bedrooms in property       |
| baths   | Number of bathrooms in property. Note 0.5 corresponds to a half-bath which has a sink and toilet but no tub or shower       |
| size    | Total floor area of property       |
| size_units   | Units of the previous measurement        |
| lot_size     | Total area of the land where the property is located on. The lot belongs to the house owner      |
| lot_size_units   | Units of the previous measurement       |
| zip_code     | Zip code. This is a postal code used in the USA       |
| price   | Price the property was sold for (US dollars)        |

Useful fact:
* 1 acre = 43560 sqft",.csv,True
HOUSE PRICE PREDICTION - SEATTLE,2,house-price-prediction-seattle,train.csv,CC0-1.0,"This is a **real dataset** of house prices sold in **Seattle, Washing, USA** between August and December 2022. The task is to predict the house price in this area based on several features, which are described below. 

| Feature     | Description |
| ----------- | ----------- |
| beds     | Number of bedrooms in property       |
| baths   | Number of bathrooms in property. Note 0.5 corresponds to a half-bath which has a sink and toilet but no tub or shower       |
| size    | Total floor area of property       |
| size_units   | Units of the previous measurement        |
| lot_size     | Total area of the land where the property is located on. The lot belongs to the house owner      |
| lot_size_units   | Units of the previous measurement       |
| zip_code     | Zip code. This is a postal code used in the USA       |
| price   | Price the property was sold for (US dollars)        |

Useful fact:
* 1 acre = 43560 sqft",.csv,True
High School Student Performance & Demographics,2,high-school-student-performance-and-demographics,student_math_clean.csv,Attribution 4.0 International (CC BY 4.0),"This dataset contains student achievement data for two Portuguese high schools. 
The data was collected using school reports and questionnaires, and includes student grades, demographics, social, parent, and school-related features.

Two datasets are provided regarding performance in two distinct subjects: Mathematics and Portuguese language. I have cleaned the original datasets so that they are easier to read and use. 

### Attributes for both student_math_cleaned.csv (Math course) and student_portuguese_cleaned.csv (Portuguese language course) datasets:
1. school - student's school (binary: ""GP"" - Gabriel Pereira or ""MS"" - Mousinho da Silveira)
2. sex - student's sex (binary: ""F"" - female or ""M"" - male)
3. age - student's age (numeric: from 15 to 22)
4. address_type - student's home address type (binary: ""Urban""  or ""Rural"")
5. family_size - family size (binary: ""Less or equal to 3"" or ""Greater than 3"")
6. parent_status - parent's cohabitation status (binary: ""Living together"" or ""Apart"")
7. mother_education - mother's education (ordinal: ""none"",  ""primary education (4th grade)"", ""5th to 9th grade"", ""secondary education"" or ""higher education"")
8. father_education - father's education (ordinal: ""none"",  ""primary education (4th grade)"", ""5th to 9th grade"", ""secondary education"" or ""higher education"")
9. mother_job - mother's job (nominal: ""teacher"", ""health"" care related, civil ""services"" (e.g. administrative or police), ""at_home"" or ""other"")
10. father_job - father's job (nominal: ""teacher"", ""health"" care related, civil ""services"" (e.g. administrative or police), ""at_home"" or ""other"")
11. reason - reason to choose this school (nominal: close to ""home"", school ""reputation"", ""course"" preference or ""other"")
12. guardian - student's guardian (nominal: ""mother"", ""father"" or ""other"")
13. travel_time - home to school travel time (ordinal: ""&lt;15 min."", ""15 to 30 min."", ""30 min. to 1 hour"", or 4 - ""&gt;1 hour"")
14. study_time - weekly study time (ordinal: 1 - ""&lt;2 hours"", ""2 to 5 hours"", ""5 to 10 hours"", or ""&gt;10 hours"")
15. class_failures - number of past class failures (numeric: n if 1&lt;=n&lt;3, else 4)
16. school_support - extra educational support (binary: yes or no)
17. family_support - family educational support (binary: yes or no)
18. extra_paid_classes - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)
19. activities - extra-curricular activities (binary: yes or no)
20. nursery - attended nursery school (binary: yes or no)
21. higher_ed - wants to take higher education (binary: yes or no)
22. internet - Internet access at home (binary: yes or no)
23. romantic_relationship - with a romantic relationship (binary: yes or no)
24. family_relationship - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)
25. free_time - free time after school (numeric: from 1 - very low to 5 - very high)
26. social - going out with friends (numeric: from 1 - very low to 5 - very high)
27. weekday_alcohol - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)
28. weekend_alcohol - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)
29. health - current health status (numeric: from 1 - very bad to 5 - very good)
30. absences - number of school absences (numeric: from 0 to 93)

### These grades are related with the course subject, Math or Portuguese:
31. grade_1 - first period grade (numeric: from 0 to 20)
32. grade_2 - second period grade (numeric: from 0 to 20)
33. final_grade - final grade (numeric: from 0 to 20, output target)

Important note: the target attribute final_grade has a strong correlation with attributes grade_2 and grade_1. This occurs because final_grade is the final year grade (issued at the 3rd period), while grade_1 and grade_2 correspond to the 1st and 2nd period grades. It is more difficult to predict final_grade without grade_2 and grade_1, but these predictions will be much more useful.

Additional note: there are 382 students that belong to both datasets, though the ID's do not match. 
These students can be identified by searching for identical attributes that characterize each student.

Please include this citation if you plan to use this database:
P. Cortez and A. Silva. Using Data Mining to Predict Secondary School Student Performance. In A. Brito and J. Teixeira Eds., Proceedings of 5th FUture BUsiness TEChnology Conference (FUBUTEC 2008) pp. 5-12, Porto, Portugal, April, 2008, EUROSIS, ISBN 978-9077381-39-7.",.csv,True
High School Student Performance & Demographics,2,high-school-student-performance-and-demographics,student_portuguese_clean.csv,Attribution 4.0 International (CC BY 4.0),"This dataset contains student achievement data for two Portuguese high schools. 
The data was collected using school reports and questionnaires, and includes student grades, demographics, social, parent, and school-related features.

Two datasets are provided regarding performance in two distinct subjects: Mathematics and Portuguese language. I have cleaned the original datasets so that they are easier to read and use. 

### Attributes for both student_math_cleaned.csv (Math course) and student_portuguese_cleaned.csv (Portuguese language course) datasets:
1. school - student's school (binary: ""GP"" - Gabriel Pereira or ""MS"" - Mousinho da Silveira)
2. sex - student's sex (binary: ""F"" - female or ""M"" - male)
3. age - student's age (numeric: from 15 to 22)
4. address_type - student's home address type (binary: ""Urban""  or ""Rural"")
5. family_size - family size (binary: ""Less or equal to 3"" or ""Greater than 3"")
6. parent_status - parent's cohabitation status (binary: ""Living together"" or ""Apart"")
7. mother_education - mother's education (ordinal: ""none"",  ""primary education (4th grade)"", ""5th to 9th grade"", ""secondary education"" or ""higher education"")
8. father_education - father's education (ordinal: ""none"",  ""primary education (4th grade)"", ""5th to 9th grade"", ""secondary education"" or ""higher education"")
9. mother_job - mother's job (nominal: ""teacher"", ""health"" care related, civil ""services"" (e.g. administrative or police), ""at_home"" or ""other"")
10. father_job - father's job (nominal: ""teacher"", ""health"" care related, civil ""services"" (e.g. administrative or police), ""at_home"" or ""other"")
11. reason - reason to choose this school (nominal: close to ""home"", school ""reputation"", ""course"" preference or ""other"")
12. guardian - student's guardian (nominal: ""mother"", ""father"" or ""other"")
13. travel_time - home to school travel time (ordinal: ""&lt;15 min."", ""15 to 30 min."", ""30 min. to 1 hour"", or 4 - ""&gt;1 hour"")
14. study_time - weekly study time (ordinal: 1 - ""&lt;2 hours"", ""2 to 5 hours"", ""5 to 10 hours"", or ""&gt;10 hours"")
15. class_failures - number of past class failures (numeric: n if 1&lt;=n&lt;3, else 4)
16. school_support - extra educational support (binary: yes or no)
17. family_support - family educational support (binary: yes or no)
18. extra_paid_classes - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)
19. activities - extra-curricular activities (binary: yes or no)
20. nursery - attended nursery school (binary: yes or no)
21. higher_ed - wants to take higher education (binary: yes or no)
22. internet - Internet access at home (binary: yes or no)
23. romantic_relationship - with a romantic relationship (binary: yes or no)
24. family_relationship - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)
25. free_time - free time after school (numeric: from 1 - very low to 5 - very high)
26. social - going out with friends (numeric: from 1 - very low to 5 - very high)
27. weekday_alcohol - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)
28. weekend_alcohol - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)
29. health - current health status (numeric: from 1 - very bad to 5 - very good)
30. absences - number of school absences (numeric: from 0 to 93)

### These grades are related with the course subject, Math or Portuguese:
31. grade_1 - first period grade (numeric: from 0 to 20)
32. grade_2 - second period grade (numeric: from 0 to 20)
33. final_grade - final grade (numeric: from 0 to 20, output target)

Important note: the target attribute final_grade has a strong correlation with attributes grade_2 and grade_1. This occurs because final_grade is the final year grade (issued at the 3rd period), while grade_1 and grade_2 correspond to the 1st and 2nd period grades. It is more difficult to predict final_grade without grade_2 and grade_1, but these predictions will be much more useful.

Additional note: there are 382 students that belong to both datasets, though the ID's do not match. 
These students can be identified by searching for identical attributes that characterize each student.

Please include this citation if you plan to use this database:
P. Cortez and A. Silva. Using Data Mining to Predict Secondary School Student Performance. In A. Brito and J. Teixeira Eds., Proceedings of 5th FUture BUsiness TEChnology Conference (FUBUTEC 2008) pp. 5-12, Porto, Portugal, April, 2008, EUROSIS, ISBN 978-9077381-39-7.",.csv,True
House Price Prediction Dataset & Code,6,house-price-prediction,Hyderabad.csv,CC0-1.0,"&gt;House price prediction dataset 

This dataset comprises housing data for various metropolitan cities of India. 
It includes:
- Collection of prices of new and resale houses
- The amenities provided for each house

This housing dataset is useful for a range of stakeholders, including real estate agents, property developers, buyers, renters, and researchers interested in analyzing housing markets and trends in metropolitan cities across India. It can be used for market analysis, price prediction, property recommendations, and various other real estate-related tasks.

Shape of dataset : (6207, 40)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F11965067%2F75861c40e86a4d2d10c044be79542436%2FCapture.JPG?generation=1704918894425981&alt=media)

Github Link : https://github.com/TusharPaul01/House-Price-Prediction

For more such dataset & code check : https://www.kaggle.com/tusharpaul2001",.csv,True
House Price Prediction Dataset & Code,6,house-price-prediction,Delhi.csv,CC0-1.0,"&gt;House price prediction dataset 

This dataset comprises housing data for various metropolitan cities of India. 
It includes:
- Collection of prices of new and resale houses
- The amenities provided for each house

This housing dataset is useful for a range of stakeholders, including real estate agents, property developers, buyers, renters, and researchers interested in analyzing housing markets and trends in metropolitan cities across India. It can be used for market analysis, price prediction, property recommendations, and various other real estate-related tasks.

Shape of dataset : (6207, 40)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F11965067%2F75861c40e86a4d2d10c044be79542436%2FCapture.JPG?generation=1704918894425981&alt=media)

Github Link : https://github.com/TusharPaul01/House-Price-Prediction

For more such dataset & code check : https://www.kaggle.com/tusharpaul2001",.csv,True
House Price Prediction Dataset & Code,6,house-price-prediction,Kolkata.csv,CC0-1.0,"&gt;House price prediction dataset 

This dataset comprises housing data for various metropolitan cities of India. 
It includes:
- Collection of prices of new and resale houses
- The amenities provided for each house

This housing dataset is useful for a range of stakeholders, including real estate agents, property developers, buyers, renters, and researchers interested in analyzing housing markets and trends in metropolitan cities across India. It can be used for market analysis, price prediction, property recommendations, and various other real estate-related tasks.

Shape of dataset : (6207, 40)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F11965067%2F75861c40e86a4d2d10c044be79542436%2FCapture.JPG?generation=1704918894425981&alt=media)

Github Link : https://github.com/TusharPaul01/House-Price-Prediction

For more such dataset & code check : https://www.kaggle.com/tusharpaul2001",.csv,True
House Price Prediction Dataset & Code,6,house-price-prediction,Chennai.csv,CC0-1.0,"&gt;House price prediction dataset 

This dataset comprises housing data for various metropolitan cities of India. 
It includes:
- Collection of prices of new and resale houses
- The amenities provided for each house

This housing dataset is useful for a range of stakeholders, including real estate agents, property developers, buyers, renters, and researchers interested in analyzing housing markets and trends in metropolitan cities across India. It can be used for market analysis, price prediction, property recommendations, and various other real estate-related tasks.

Shape of dataset : (6207, 40)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F11965067%2F75861c40e86a4d2d10c044be79542436%2FCapture.JPG?generation=1704918894425981&alt=media)

Github Link : https://github.com/TusharPaul01/House-Price-Prediction

For more such dataset & code check : https://www.kaggle.com/tusharpaul2001",.csv,True
House Price Prediction Dataset & Code,6,house-price-prediction,Mumbai.csv,CC0-1.0,"&gt;House price prediction dataset 

This dataset comprises housing data for various metropolitan cities of India. 
It includes:
- Collection of prices of new and resale houses
- The amenities provided for each house

This housing dataset is useful for a range of stakeholders, including real estate agents, property developers, buyers, renters, and researchers interested in analyzing housing markets and trends in metropolitan cities across India. It can be used for market analysis, price prediction, property recommendations, and various other real estate-related tasks.

Shape of dataset : (6207, 40)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F11965067%2F75861c40e86a4d2d10c044be79542436%2FCapture.JPG?generation=1704918894425981&alt=media)

Github Link : https://github.com/TusharPaul01/House-Price-Prediction

For more such dataset & code check : https://www.kaggle.com/tusharpaul2001",.csv,True
House Price Prediction Dataset & Code,6,house-price-prediction,Bangalore.csv,CC0-1.0,"&gt;House price prediction dataset 

This dataset comprises housing data for various metropolitan cities of India. 
It includes:
- Collection of prices of new and resale houses
- The amenities provided for each house

This housing dataset is useful for a range of stakeholders, including real estate agents, property developers, buyers, renters, and researchers interested in analyzing housing markets and trends in metropolitan cities across India. It can be used for market analysis, price prediction, property recommendations, and various other real estate-related tasks.

Shape of dataset : (6207, 40)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F11965067%2F75861c40e86a4d2d10c044be79542436%2FCapture.JPG?generation=1704918894425981&alt=media)

Github Link : https://github.com/TusharPaul01/House-Price-Prediction

For more such dataset & code check : https://www.kaggle.com/tusharpaul2001",.csv,True
Housing Prices in Metropolitan Areas of India,6,housing-prices-in-metropolitan-areas-of-india,Hyderabad.csv,CC0-1.0,"### Content
This dataset comprises data that was scraped. It includes:
- collection of prices of new and resale houses located in the metropolitan areas of India
- the amenities provided for each house

### Inspiration
With 40 explanatory variables describing various aspects of new and resale houses in the metropolitan areas of India, one can predict the final price of houses in these regions.


📌 **Note** :
Since for a set of houses, nothing was mentioned about certain amenities, '9' was used to mark such values, which could indicate the absence of information about the apartment but these values don't ascertain the absence of such a feature in real life.",.csv,True
Housing Prices in Metropolitan Areas of India,6,housing-prices-in-metropolitan-areas-of-india,Delhi.csv,CC0-1.0,"### Content
This dataset comprises data that was scraped. It includes:
- collection of prices of new and resale houses located in the metropolitan areas of India
- the amenities provided for each house

### Inspiration
With 40 explanatory variables describing various aspects of new and resale houses in the metropolitan areas of India, one can predict the final price of houses in these regions.


📌 **Note** :
Since for a set of houses, nothing was mentioned about certain amenities, '9' was used to mark such values, which could indicate the absence of information about the apartment but these values don't ascertain the absence of such a feature in real life.",.csv,True
Housing Prices in Metropolitan Areas of India,6,housing-prices-in-metropolitan-areas-of-india,Kolkata.csv,CC0-1.0,"### Content
This dataset comprises data that was scraped. It includes:
- collection of prices of new and resale houses located in the metropolitan areas of India
- the amenities provided for each house

### Inspiration
With 40 explanatory variables describing various aspects of new and resale houses in the metropolitan areas of India, one can predict the final price of houses in these regions.


📌 **Note** :
Since for a set of houses, nothing was mentioned about certain amenities, '9' was used to mark such values, which could indicate the absence of information about the apartment but these values don't ascertain the absence of such a feature in real life.",.csv,True
Housing Prices in Metropolitan Areas of India,6,housing-prices-in-metropolitan-areas-of-india,Chennai.csv,CC0-1.0,"### Content
This dataset comprises data that was scraped. It includes:
- collection of prices of new and resale houses located in the metropolitan areas of India
- the amenities provided for each house

### Inspiration
With 40 explanatory variables describing various aspects of new and resale houses in the metropolitan areas of India, one can predict the final price of houses in these regions.


📌 **Note** :
Since for a set of houses, nothing was mentioned about certain amenities, '9' was used to mark such values, which could indicate the absence of information about the apartment but these values don't ascertain the absence of such a feature in real life.",.csv,True
Housing Prices in Metropolitan Areas of India,6,housing-prices-in-metropolitan-areas-of-india,Mumbai.csv,CC0-1.0,"### Content
This dataset comprises data that was scraped. It includes:
- collection of prices of new and resale houses located in the metropolitan areas of India
- the amenities provided for each house

### Inspiration
With 40 explanatory variables describing various aspects of new and resale houses in the metropolitan areas of India, one can predict the final price of houses in these regions.


📌 **Note** :
Since for a set of houses, nothing was mentioned about certain amenities, '9' was used to mark such values, which could indicate the absence of information about the apartment but these values don't ascertain the absence of such a feature in real life.",.csv,True
Housing Prices in Metropolitan Areas of India,6,housing-prices-in-metropolitan-areas-of-india,Bangalore.csv,CC0-1.0,"### Content
This dataset comprises data that was scraped. It includes:
- collection of prices of new and resale houses located in the metropolitan areas of India
- the amenities provided for each house

### Inspiration
With 40 explanatory variables describing various aspects of new and resale houses in the metropolitan areas of India, one can predict the final price of houses in these regions.


📌 **Note** :
Since for a set of houses, nothing was mentioned about certain amenities, '9' was used to mark such values, which could indicate the absence of information about the apartment but these values don't ascertain the absence of such a feature in real life.",.csv,True
"Hurricanes and Typhoons, 1851-2014",2,hurricane-database,pacific.csv,CC0-1.0,"# Context 

The National Hurricane Center (NHC) conducts a post-storm analysis of each tropical cyclone in the Atlantic
basin (i.e., North Atlantic Ocean, Gulf of Mexico, and Caribbean Sea) and and the North Pacific Ocean to determine the official assessment of the cyclone's history. This analysis makes use of all available observations, including those that may not have been available in real time. In addition, NHC conducts ongoing reviews of any retrospective tropical cyclone analyses brought to its attention and on a regular basis updates the historical record to reflect
changes introduced.


# Content

The NHC publishes the tropical cyclone historical database in a format known as HURDAT, short for HURricane DATabase. These databases (Atlantic HURDAT2 and NE/NC Pacific HURDAT2) contain six-hourly information on the location, maximum winds, central pressure, and (starting in 2004) size of all known tropical cyclones and subtropical cyclones.",.csv,True
"Hurricanes and Typhoons, 1851-2014",2,hurricane-database,atlantic.csv,CC0-1.0,"# Context 

The National Hurricane Center (NHC) conducts a post-storm analysis of each tropical cyclone in the Atlantic
basin (i.e., North Atlantic Ocean, Gulf of Mexico, and Caribbean Sea) and and the North Pacific Ocean to determine the official assessment of the cyclone's history. This analysis makes use of all available observations, including those that may not have been available in real time. In addition, NHC conducts ongoing reviews of any retrospective tropical cyclone analyses brought to its attention and on a regular basis updates the historical record to reflect
changes introduced.


# Content

The NHC publishes the tropical cyclone historical database in a format known as HURDAT, short for HURricane DATabase. These databases (Atlantic HURDAT2 and NE/NC Pacific HURDAT2) contain six-hourly information on the location, maximum winds, central pressure, and (starting in 2004) size of all known tropical cyclones and subtropical cyclones.",.csv,True
Hyundai Motor Company Stock Historical Price,3,hyundai-motor-company-stock-historical-price,005380.KS_weekly.csv,world-bank,"# Hyundai Motor Company Stock Historical Price (005380.KS)

#### from January 2016 until Present

---

### ▶ Context 📝
The dataset is taken from [Yahoo Finance website](https://finance.yahoo.com/quote/005380.KS/history). It is about the historical stock price of Hyundai Motor Company.

### ▶ Acknowledgements 🙏

I'd like to clarify that I'm only making data about the historical stock price of Hyundai Motor Company available to **Kaggle community**. 

### ▶ Inspiration 💭

- Forecasting stock price after July 2022
- Implementing machine learning models.
- Perform data analysis/data visualization of historical stock prices.

### ▶ Log 📰
- **11 November 2022**: The datasets version now is ***fully automated update*** using Deepnote. **Read more [here](https://deepnote.com/@mario-caesar/Auto-update-Kaggle-Datasets-using-Deepnote-99b73d05-540b-4d79-a4c2-6b15730a7d8f)**.
- **19 August 2023**: Deepnote schedule run will be ***deprecated after August 2023***; Moving & updating script for update automation via **Kaggle API** using Kaggle schedule run.

---

📷 *Image by [The Punisher](https://unsplash.com/@named_aashutosh).*",.csv,True
Hyundai Motor Company Stock Historical Price,3,hyundai-motor-company-stock-historical-price,005380.KS.csv,world-bank,"# Hyundai Motor Company Stock Historical Price (005380.KS)

#### from January 2016 until Present

---

### ▶ Context 📝
The dataset is taken from [Yahoo Finance website](https://finance.yahoo.com/quote/005380.KS/history). It is about the historical stock price of Hyundai Motor Company.

### ▶ Acknowledgements 🙏

I'd like to clarify that I'm only making data about the historical stock price of Hyundai Motor Company available to **Kaggle community**. 

### ▶ Inspiration 💭

- Forecasting stock price after July 2022
- Implementing machine learning models.
- Perform data analysis/data visualization of historical stock prices.

### ▶ Log 📰
- **11 November 2022**: The datasets version now is ***fully automated update*** using Deepnote. **Read more [here](https://deepnote.com/@mario-caesar/Auto-update-Kaggle-Datasets-using-Deepnote-99b73d05-540b-4d79-a4c2-6b15730a7d8f)**.
- **19 August 2023**: Deepnote schedule run will be ***deprecated after August 2023***; Moving & updating script for update automation via **Kaggle API** using Kaggle schedule run.

---

📷 *Image by [The Punisher](https://unsplash.com/@named_aashutosh).*",.csv,True
Hyundai Motor Company Stock Historical Price,3,hyundai-motor-company-stock-historical-price,005380.KS_monthly.csv,world-bank,"# Hyundai Motor Company Stock Historical Price (005380.KS)

#### from January 2016 until Present

---

### ▶ Context 📝
The dataset is taken from [Yahoo Finance website](https://finance.yahoo.com/quote/005380.KS/history). It is about the historical stock price of Hyundai Motor Company.

### ▶ Acknowledgements 🙏

I'd like to clarify that I'm only making data about the historical stock price of Hyundai Motor Company available to **Kaggle community**. 

### ▶ Inspiration 💭

- Forecasting stock price after July 2022
- Implementing machine learning models.
- Perform data analysis/data visualization of historical stock prices.

### ▶ Log 📰
- **11 November 2022**: The datasets version now is ***fully automated update*** using Deepnote. **Read more [here](https://deepnote.com/@mario-caesar/Auto-update-Kaggle-Datasets-using-Deepnote-99b73d05-540b-4d79-a4c2-6b15730a7d8f)**.
- **19 August 2023**: Deepnote schedule run will be ***deprecated after August 2023***; Moving & updating script for update automation via **Kaggle API** using Kaggle schedule run.

---

📷 *Image by [The Punisher](https://unsplash.com/@named_aashutosh).*",.csv,True
IRIS-FLOWER-DATASETS,2,irisflowerdatasets,IRIS1.csv,CC0-1.0,"### Abstract
(from wikipedia)

The Iris flower data set or Fisher's Iris data set is a multivariate data set used and made famous by the British statistician and biologist Ronald Fisher in his 1936 paper *The use of multiple measurements in taxonomic problems* as an example of linear discriminant analysis. It is sometimes called Anderson's Iris data set because Edgar Anderson collected the data to quantify the morphologic variation of Iris flowers of three related species. Two of the three species were collected in the Gaspé Peninsula ""all from the same pasture, and picked on the same day and measured at the same time by the same person with the same apparatus"".

### The Datasets
The dataset **IRIS.CSV** consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters.

The dataset **IRIS1.CSV** is a modified version of **IRIS.CSV**, containing missing values.

### Acknowledgements
The dataset, **IRIS.CSV**, is free and is publicly available at the UCI Machine Learning Repository.",.csv,True
IRIS-FLOWER-DATASETS,2,irisflowerdatasets,IRIS.csv,CC0-1.0,"### Abstract
(from wikipedia)

The Iris flower data set or Fisher's Iris data set is a multivariate data set used and made famous by the British statistician and biologist Ronald Fisher in his 1936 paper *The use of multiple measurements in taxonomic problems* as an example of linear discriminant analysis. It is sometimes called Anderson's Iris data set because Edgar Anderson collected the data to quantify the morphologic variation of Iris flowers of three related species. Two of the three species were collected in the Gaspé Peninsula ""all from the same pasture, and picked on the same day and measured at the same time by the same person with the same apparatus"".

### The Datasets
The dataset **IRIS.CSV** consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters.

The dataset **IRIS1.CSV** is a modified version of **IRIS.CSV**, containing missing values.

### Acknowledgements
The dataset, **IRIS.CSV**, is free and is publicly available at the UCI Machine Learning Repository.",.csv,True
Import and Export by India,6,import-and-export-by-india,PC_Import_2014_2015.csv,CC-BY-SA-4.0,"<div>
<a href=""https://link.rajanand.org/sql-challenges"" target=""_blank"">
<img src=""https://link.rajanand.org/banner-01"" alt=""SQL Data Challenges"" style=""width: 700px; height: 120px""></a>
</div>
---


### Context

To better understand the imports and exports by India and how it changed in 3 years.


### Content

Import and export data available by principle commodity and country wise for 3 years from Apr'2014 to Mar'2017.

### Column Descriptions

1. pc_code: Integer, Principal Commodity Code
2. pc: String, Principal Commodity Name
3. unit: String, measurement of quantity
4. country_code:  Integer, country code
5. country_name: String, country name
6. quantity: Integer, quantify of export or import
7. value: Integer, monetary valeu of the quantity (in million USD)

### Acknowledgements

[Ministry of Commerce and Industry](http://commerce.gov.in), Govt of India has published [these](https://data.gov.in/catalog/principal-commodity-wise-export) [datasets](https://data.gov.in/catalog/principal-commodity-wise-import) in Open Govt Data Platform India portal under [Govt. Open Data License - India](https://data.gov.in/government-open-data-license-india).

### Inspiration

Some of questions I would like to be answered are

 1. Top countries by growth percentage.
 2. Top commodity by quantity or value.
 3. YoY growth of export and import.

---

<div>
<a href=""https://link.rajanand.org/sql-challenges"" target=""_blank"">
<img src=""https://link.rajanand.org/banner-02"" alt=""SQL Data Challenges"" style=""width: 700px; height: 120px""></a>
</div>
",.csv,True
Import and Export by India,6,import-and-export-by-india,PC_Import_2015_2016.csv,CC-BY-SA-4.0,"<div>
<a href=""https://link.rajanand.org/sql-challenges"" target=""_blank"">
<img src=""https://link.rajanand.org/banner-01"" alt=""SQL Data Challenges"" style=""width: 700px; height: 120px""></a>
</div>
---


### Context

To better understand the imports and exports by India and how it changed in 3 years.


### Content

Import and export data available by principle commodity and country wise for 3 years from Apr'2014 to Mar'2017.

### Column Descriptions

1. pc_code: Integer, Principal Commodity Code
2. pc: String, Principal Commodity Name
3. unit: String, measurement of quantity
4. country_code:  Integer, country code
5. country_name: String, country name
6. quantity: Integer, quantify of export or import
7. value: Integer, monetary valeu of the quantity (in million USD)

### Acknowledgements

[Ministry of Commerce and Industry](http://commerce.gov.in), Govt of India has published [these](https://data.gov.in/catalog/principal-commodity-wise-export) [datasets](https://data.gov.in/catalog/principal-commodity-wise-import) in Open Govt Data Platform India portal under [Govt. Open Data License - India](https://data.gov.in/government-open-data-license-india).

### Inspiration

Some of questions I would like to be answered are

 1. Top countries by growth percentage.
 2. Top commodity by quantity or value.
 3. YoY growth of export and import.

---

<div>
<a href=""https://link.rajanand.org/sql-challenges"" target=""_blank"">
<img src=""https://link.rajanand.org/banner-02"" alt=""SQL Data Challenges"" style=""width: 700px; height: 120px""></a>
</div>
",.csv,True
Import and Export by India,6,import-and-export-by-india,PC_Export_2015_2016.csv,CC-BY-SA-4.0,"<div>
<a href=""https://link.rajanand.org/sql-challenges"" target=""_blank"">
<img src=""https://link.rajanand.org/banner-01"" alt=""SQL Data Challenges"" style=""width: 700px; height: 120px""></a>
</div>
---


### Context

To better understand the imports and exports by India and how it changed in 3 years.


### Content

Import and export data available by principle commodity and country wise for 3 years from Apr'2014 to Mar'2017.

### Column Descriptions

1. pc_code: Integer, Principal Commodity Code
2. pc: String, Principal Commodity Name
3. unit: String, measurement of quantity
4. country_code:  Integer, country code
5. country_name: String, country name
6. quantity: Integer, quantify of export or import
7. value: Integer, monetary valeu of the quantity (in million USD)

### Acknowledgements

[Ministry of Commerce and Industry](http://commerce.gov.in), Govt of India has published [these](https://data.gov.in/catalog/principal-commodity-wise-export) [datasets](https://data.gov.in/catalog/principal-commodity-wise-import) in Open Govt Data Platform India portal under [Govt. Open Data License - India](https://data.gov.in/government-open-data-license-india).

### Inspiration

Some of questions I would like to be answered are

 1. Top countries by growth percentage.
 2. Top commodity by quantity or value.
 3. YoY growth of export and import.

---

<div>
<a href=""https://link.rajanand.org/sql-challenges"" target=""_blank"">
<img src=""https://link.rajanand.org/banner-02"" alt=""SQL Data Challenges"" style=""width: 700px; height: 120px""></a>
</div>
",.csv,True
Import and Export by India,6,import-and-export-by-india,PC_Export_2014_2015.csv,CC-BY-SA-4.0,"<div>
<a href=""https://link.rajanand.org/sql-challenges"" target=""_blank"">
<img src=""https://link.rajanand.org/banner-01"" alt=""SQL Data Challenges"" style=""width: 700px; height: 120px""></a>
</div>
---


### Context

To better understand the imports and exports by India and how it changed in 3 years.


### Content

Import and export data available by principle commodity and country wise for 3 years from Apr'2014 to Mar'2017.

### Column Descriptions

1. pc_code: Integer, Principal Commodity Code
2. pc: String, Principal Commodity Name
3. unit: String, measurement of quantity
4. country_code:  Integer, country code
5. country_name: String, country name
6. quantity: Integer, quantify of export or import
7. value: Integer, monetary valeu of the quantity (in million USD)

### Acknowledgements

[Ministry of Commerce and Industry](http://commerce.gov.in), Govt of India has published [these](https://data.gov.in/catalog/principal-commodity-wise-export) [datasets](https://data.gov.in/catalog/principal-commodity-wise-import) in Open Govt Data Platform India portal under [Govt. Open Data License - India](https://data.gov.in/government-open-data-license-india).

### Inspiration

Some of questions I would like to be answered are

 1. Top countries by growth percentage.
 2. Top commodity by quantity or value.
 3. YoY growth of export and import.

---

<div>
<a href=""https://link.rajanand.org/sql-challenges"" target=""_blank"">
<img src=""https://link.rajanand.org/banner-02"" alt=""SQL Data Challenges"" style=""width: 700px; height: 120px""></a>
</div>
",.csv,True
Import and Export by India,6,import-and-export-by-india,PC_Import_2016_2017.csv,CC-BY-SA-4.0,"<div>
<a href=""https://link.rajanand.org/sql-challenges"" target=""_blank"">
<img src=""https://link.rajanand.org/banner-01"" alt=""SQL Data Challenges"" style=""width: 700px; height: 120px""></a>
</div>
---


### Context

To better understand the imports and exports by India and how it changed in 3 years.


### Content

Import and export data available by principle commodity and country wise for 3 years from Apr'2014 to Mar'2017.

### Column Descriptions

1. pc_code: Integer, Principal Commodity Code
2. pc: String, Principal Commodity Name
3. unit: String, measurement of quantity
4. country_code:  Integer, country code
5. country_name: String, country name
6. quantity: Integer, quantify of export or import
7. value: Integer, monetary valeu of the quantity (in million USD)

### Acknowledgements

[Ministry of Commerce and Industry](http://commerce.gov.in), Govt of India has published [these](https://data.gov.in/catalog/principal-commodity-wise-export) [datasets](https://data.gov.in/catalog/principal-commodity-wise-import) in Open Govt Data Platform India portal under [Govt. Open Data License - India](https://data.gov.in/government-open-data-license-india).

### Inspiration

Some of questions I would like to be answered are

 1. Top countries by growth percentage.
 2. Top commodity by quantity or value.
 3. YoY growth of export and import.

---

<div>
<a href=""https://link.rajanand.org/sql-challenges"" target=""_blank"">
<img src=""https://link.rajanand.org/banner-02"" alt=""SQL Data Challenges"" style=""width: 700px; height: 120px""></a>
</div>
",.csv,True
Import and Export by India,6,import-and-export-by-india,PC_Export_2016_2017.csv,CC-BY-SA-4.0,"<div>
<a href=""https://link.rajanand.org/sql-challenges"" target=""_blank"">
<img src=""https://link.rajanand.org/banner-01"" alt=""SQL Data Challenges"" style=""width: 700px; height: 120px""></a>
</div>
---


### Context

To better understand the imports and exports by India and how it changed in 3 years.


### Content

Import and export data available by principle commodity and country wise for 3 years from Apr'2014 to Mar'2017.

### Column Descriptions

1. pc_code: Integer, Principal Commodity Code
2. pc: String, Principal Commodity Name
3. unit: String, measurement of quantity
4. country_code:  Integer, country code
5. country_name: String, country name
6. quantity: Integer, quantify of export or import
7. value: Integer, monetary valeu of the quantity (in million USD)

### Acknowledgements

[Ministry of Commerce and Industry](http://commerce.gov.in), Govt of India has published [these](https://data.gov.in/catalog/principal-commodity-wise-export) [datasets](https://data.gov.in/catalog/principal-commodity-wise-import) in Open Govt Data Platform India portal under [Govt. Open Data License - India](https://data.gov.in/government-open-data-license-india).

### Inspiration

Some of questions I would like to be answered are

 1. Top countries by growth percentage.
 2. Top commodity by quantity or value.
 3. YoY growth of export and import.

---

<div>
<a href=""https://link.rajanand.org/sql-challenges"" target=""_blank"">
<img src=""https://link.rajanand.org/banner-02"" alt=""SQL Data Challenges"" style=""width: 700px; height: 120px""></a>
</div>
",.csv,True
Indian Rental House Price,3,india-rental-house-price,Indian_housing_Pune_data.csv,Apache 2.0,"This dataset provides comprehensive information about rental house prices across various locations in India. It includes details such as house type, size, location, city, latitude, longitude, price, currency, number of bathrooms, number of balconies, negotiability of price, price per square foot, verification date, description of the property, security deposit, and status of furnishing (furnished, unfurnished, semi-furnished).

`Note: This is Recently scraped data of April 2024.`

### **Dataset Glossary (Column-Wise)**
- **House Type**: Type of house (e.g., apartment, villa, duplex).
- **House Size**: Size of the house in square feet or square meters.
- **Location**: Specific area or neighborhood where the property is located.
- **City**: City in India where the property is situated.
- **Latitude**: Geographic latitude coordinates of the property location.
- **Longitude**: Geographic longitude coordinates of the property location.
- **Price**: Rental price of the house.
- **Currency**: Currency in which the price is denoted (e.g., INR - Indian Rupees).
- **Number of Bathrooms**: Total number of bathrooms in the house.
- **Number of Balconies**: Total number of balconies in the house.
- **Negotiability**: Indicates whether the price is negotiable (Yes/No).
- **Price per Square Foot**: Price of the house per square foot.
- **Verification Date**: Date when the rental information was verified.
- **Description**: Additional description or details about the property.
- **Security Deposit**: Amount of security deposit required for renting the property.
- **Status**: Indicates the furnishing status of the property (furnished, unfurnished, semi-furnished).

### **Usage**
This dataset aims to provide valuable insights into the rental housing market in India, enabling analysis of rental trends, comparison of prices across different locations and property types, and understanding the impact of various factors on rental prices. Researchers, analysts, and policymakers can utilize this dataset for a wide range of applications, including real estate market analysis, urban planning, and economic research.

### **Acknowledgement**
This Dataset is created from [https://www.makaan.com/](https://www.makaan.com/). If you want to learn more, you can visit the Website.

Cover Photo by: [Playground.ai](https://playground.com/post/a-dynamic-and-lively-shot-of-a-daman--diu-haveli-of-two-flo-clrrmmk6a039gs6019ez0xpjm)",.csv,True
Indian Rental House Price,3,india-rental-house-price,Indian_housing_Mumbai_data.csv,Apache 2.0,"This dataset provides comprehensive information about rental house prices across various locations in India. It includes details such as house type, size, location, city, latitude, longitude, price, currency, number of bathrooms, number of balconies, negotiability of price, price per square foot, verification date, description of the property, security deposit, and status of furnishing (furnished, unfurnished, semi-furnished).

`Note: This is Recently scraped data of April 2024.`

### **Dataset Glossary (Column-Wise)**
- **House Type**: Type of house (e.g., apartment, villa, duplex).
- **House Size**: Size of the house in square feet or square meters.
- **Location**: Specific area or neighborhood where the property is located.
- **City**: City in India where the property is situated.
- **Latitude**: Geographic latitude coordinates of the property location.
- **Longitude**: Geographic longitude coordinates of the property location.
- **Price**: Rental price of the house.
- **Currency**: Currency in which the price is denoted (e.g., INR - Indian Rupees).
- **Number of Bathrooms**: Total number of bathrooms in the house.
- **Number of Balconies**: Total number of balconies in the house.
- **Negotiability**: Indicates whether the price is negotiable (Yes/No).
- **Price per Square Foot**: Price of the house per square foot.
- **Verification Date**: Date when the rental information was verified.
- **Description**: Additional description or details about the property.
- **Security Deposit**: Amount of security deposit required for renting the property.
- **Status**: Indicates the furnishing status of the property (furnished, unfurnished, semi-furnished).

### **Usage**
This dataset aims to provide valuable insights into the rental housing market in India, enabling analysis of rental trends, comparison of prices across different locations and property types, and understanding the impact of various factors on rental prices. Researchers, analysts, and policymakers can utilize this dataset for a wide range of applications, including real estate market analysis, urban planning, and economic research.

### **Acknowledgement**
This Dataset is created from [https://www.makaan.com/](https://www.makaan.com/). If you want to learn more, you can visit the Website.

Cover Photo by: [Playground.ai](https://playground.com/post/a-dynamic-and-lively-shot-of-a-daman--diu-haveli-of-two-flo-clrrmmk6a039gs6019ez0xpjm)",.csv,True
Indian Rental House Price,3,india-rental-house-price,Indian_housing_Delhi_data.csv,Apache 2.0,"This dataset provides comprehensive information about rental house prices across various locations in India. It includes details such as house type, size, location, city, latitude, longitude, price, currency, number of bathrooms, number of balconies, negotiability of price, price per square foot, verification date, description of the property, security deposit, and status of furnishing (furnished, unfurnished, semi-furnished).

`Note: This is Recently scraped data of April 2024.`

### **Dataset Glossary (Column-Wise)**
- **House Type**: Type of house (e.g., apartment, villa, duplex).
- **House Size**: Size of the house in square feet or square meters.
- **Location**: Specific area or neighborhood where the property is located.
- **City**: City in India where the property is situated.
- **Latitude**: Geographic latitude coordinates of the property location.
- **Longitude**: Geographic longitude coordinates of the property location.
- **Price**: Rental price of the house.
- **Currency**: Currency in which the price is denoted (e.g., INR - Indian Rupees).
- **Number of Bathrooms**: Total number of bathrooms in the house.
- **Number of Balconies**: Total number of balconies in the house.
- **Negotiability**: Indicates whether the price is negotiable (Yes/No).
- **Price per Square Foot**: Price of the house per square foot.
- **Verification Date**: Date when the rental information was verified.
- **Description**: Additional description or details about the property.
- **Security Deposit**: Amount of security deposit required for renting the property.
- **Status**: Indicates the furnishing status of the property (furnished, unfurnished, semi-furnished).

### **Usage**
This dataset aims to provide valuable insights into the rental housing market in India, enabling analysis of rental trends, comparison of prices across different locations and property types, and understanding the impact of various factors on rental prices. Researchers, analysts, and policymakers can utilize this dataset for a wide range of applications, including real estate market analysis, urban planning, and economic research.

### **Acknowledgement**
This Dataset is created from [https://www.makaan.com/](https://www.makaan.com/). If you want to learn more, you can visit the Website.

Cover Photo by: [Playground.ai](https://playground.com/post/a-dynamic-and-lively-shot-of-a-daman--diu-haveli-of-two-flo-clrrmmk6a039gs6019ez0xpjm)",.csv,True
IndicQuora,7,indicquora,Punjabi_quora.csv,MIT,"This dataset consists of 3300 pairs of question pairs derived from original Quora Question Pair Dataset.  It includes  7 languages like Hindi, Odia, Bengali, Gujarati, Marathi, Tamil and Panjabi. 

Please cite this dataset if you choose to use it.

Thanks ",.csv,True
IndicQuora,7,indicquora,Bengali_quora.csv,MIT,"This dataset consists of 3300 pairs of question pairs derived from original Quora Question Pair Dataset.  It includes  7 languages like Hindi, Odia, Bengali, Gujarati, Marathi, Tamil and Panjabi. 

Please cite this dataset if you choose to use it.

Thanks ",.csv,True
IndicQuora,7,indicquora,Odia_quora.csv,MIT,"This dataset consists of 3300 pairs of question pairs derived from original Quora Question Pair Dataset.  It includes  7 languages like Hindi, Odia, Bengali, Gujarati, Marathi, Tamil and Panjabi. 

Please cite this dataset if you choose to use it.

Thanks ",.csv,True
IndicQuora,7,indicquora,Tamil_quora.csv,MIT,"This dataset consists of 3300 pairs of question pairs derived from original Quora Question Pair Dataset.  It includes  7 languages like Hindi, Odia, Bengali, Gujarati, Marathi, Tamil and Panjabi. 

Please cite this dataset if you choose to use it.

Thanks ",.csv,True
IndicQuora,7,indicquora,Marathi_quora.csv,MIT,"This dataset consists of 3300 pairs of question pairs derived from original Quora Question Pair Dataset.  It includes  7 languages like Hindi, Odia, Bengali, Gujarati, Marathi, Tamil and Panjabi. 

Please cite this dataset if you choose to use it.

Thanks ",.csv,True
IndicQuora,7,indicquora,Gujarati_quora.csv,MIT,"This dataset consists of 3300 pairs of question pairs derived from original Quora Question Pair Dataset.  It includes  7 languages like Hindi, Odia, Bengali, Gujarati, Marathi, Tamil and Panjabi. 

Please cite this dataset if you choose to use it.

Thanks ",.csv,True
IndicQuora,7,indicquora,Hindi_quora.csv,MIT,"This dataset consists of 3300 pairs of question pairs derived from original Quora Question Pair Dataset.  It includes  7 languages like Hindi, Odia, Bengali, Gujarati, Marathi, Tamil and Panjabi. 

Please cite this dataset if you choose to use it.

Thanks ",.csv,True
Indonesia Automotive ownership (2018 - 2022),5,indonesia-automotive-ownership-2018-2022,Data Indonesian Province Automotive ownership population GDP 2019.csv,other,"Context
Datasets are a yearly release by Indonesian National Statistic Bureau. This data is combined (with selection) from tables of provincial data of (1) Automotive ownership, (2) population, and (3) Regional GDP per capita. 
Raw source:
[Automotive](https://www.bps.go.id/id/statistics-table/3/VjJ3NGRGa3dkRk5MTlU1bVNFOTVVbmQyVURSTVFUMDkjMw==/jumlah-kendaraan-bermotor-menurut-provinsi-dan-jenis-kendaraan--unit-.html?year=2022)
[Population](https://www.bps.go.id/id/statistics-table/3/V1ZSbFRUY3lTbFpEYTNsVWNGcDZjek53YkhsNFFUMDkjMw==/penduduk--laju-pertumbuhan-penduduk--distribusi-persentase-penduduk--kepadatan-penduduk--rasio-jenis-kelamin-penduduk-menurut-provinsi--2022.html?year=2022)
[Regional GDP](https://www.bps.go.id/id/statistics-table/3/YWtoQlRVZzNiMU5qU1VOSlRFeFZiRTR4VDJOTVVUMDkjMw==/produk-domestik-regional-bruto-per-kapita-atas-dasar-harga-berlaku-menurut-provinsi--ribu-rupiah-.html?year=2022)

Content
Automotive ownership data consist of vehicles type: car, bus, truck, and motorcycle. Each file of dataset represents the data of a certain year, combining those data shall give overview in yearly trend. Population and GDP datas was joined to the data, which can be utilized to observe their correlation to the trend.",.csv,True
Indonesia Automotive ownership (2018 - 2022),5,indonesia-automotive-ownership-2018-2022,Data Indonesian Province Automotive ownership population GDP 2018.csv,other,"Context
Datasets are a yearly release by Indonesian National Statistic Bureau. This data is combined (with selection) from tables of provincial data of (1) Automotive ownership, (2) population, and (3) Regional GDP per capita. 
Raw source:
[Automotive](https://www.bps.go.id/id/statistics-table/3/VjJ3NGRGa3dkRk5MTlU1bVNFOTVVbmQyVURSTVFUMDkjMw==/jumlah-kendaraan-bermotor-menurut-provinsi-dan-jenis-kendaraan--unit-.html?year=2022)
[Population](https://www.bps.go.id/id/statistics-table/3/V1ZSbFRUY3lTbFpEYTNsVWNGcDZjek53YkhsNFFUMDkjMw==/penduduk--laju-pertumbuhan-penduduk--distribusi-persentase-penduduk--kepadatan-penduduk--rasio-jenis-kelamin-penduduk-menurut-provinsi--2022.html?year=2022)
[Regional GDP](https://www.bps.go.id/id/statistics-table/3/YWtoQlRVZzNiMU5qU1VOSlRFeFZiRTR4VDJOTVVUMDkjMw==/produk-domestik-regional-bruto-per-kapita-atas-dasar-harga-berlaku-menurut-provinsi--ribu-rupiah-.html?year=2022)

Content
Automotive ownership data consist of vehicles type: car, bus, truck, and motorcycle. Each file of dataset represents the data of a certain year, combining those data shall give overview in yearly trend. Population and GDP datas was joined to the data, which can be utilized to observe their correlation to the trend.",.csv,True
Indonesia Automotive ownership (2018 - 2022),5,indonesia-automotive-ownership-2018-2022,Data Indonesian Province Automotive ownership population GDP 2022.csv,other,"Context
Datasets are a yearly release by Indonesian National Statistic Bureau. This data is combined (with selection) from tables of provincial data of (1) Automotive ownership, (2) population, and (3) Regional GDP per capita. 
Raw source:
[Automotive](https://www.bps.go.id/id/statistics-table/3/VjJ3NGRGa3dkRk5MTlU1bVNFOTVVbmQyVURSTVFUMDkjMw==/jumlah-kendaraan-bermotor-menurut-provinsi-dan-jenis-kendaraan--unit-.html?year=2022)
[Population](https://www.bps.go.id/id/statistics-table/3/V1ZSbFRUY3lTbFpEYTNsVWNGcDZjek53YkhsNFFUMDkjMw==/penduduk--laju-pertumbuhan-penduduk--distribusi-persentase-penduduk--kepadatan-penduduk--rasio-jenis-kelamin-penduduk-menurut-provinsi--2022.html?year=2022)
[Regional GDP](https://www.bps.go.id/id/statistics-table/3/YWtoQlRVZzNiMU5qU1VOSlRFeFZiRTR4VDJOTVVUMDkjMw==/produk-domestik-regional-bruto-per-kapita-atas-dasar-harga-berlaku-menurut-provinsi--ribu-rupiah-.html?year=2022)

Content
Automotive ownership data consist of vehicles type: car, bus, truck, and motorcycle. Each file of dataset represents the data of a certain year, combining those data shall give overview in yearly trend. Population and GDP datas was joined to the data, which can be utilized to observe their correlation to the trend.",.csv,True
Indonesia Automotive ownership (2018 - 2022),5,indonesia-automotive-ownership-2018-2022,Data Indonesian Province Automotive ownership population GDP 2020.csv,other,"Context
Datasets are a yearly release by Indonesian National Statistic Bureau. This data is combined (with selection) from tables of provincial data of (1) Automotive ownership, (2) population, and (3) Regional GDP per capita. 
Raw source:
[Automotive](https://www.bps.go.id/id/statistics-table/3/VjJ3NGRGa3dkRk5MTlU1bVNFOTVVbmQyVURSTVFUMDkjMw==/jumlah-kendaraan-bermotor-menurut-provinsi-dan-jenis-kendaraan--unit-.html?year=2022)
[Population](https://www.bps.go.id/id/statistics-table/3/V1ZSbFRUY3lTbFpEYTNsVWNGcDZjek53YkhsNFFUMDkjMw==/penduduk--laju-pertumbuhan-penduduk--distribusi-persentase-penduduk--kepadatan-penduduk--rasio-jenis-kelamin-penduduk-menurut-provinsi--2022.html?year=2022)
[Regional GDP](https://www.bps.go.id/id/statistics-table/3/YWtoQlRVZzNiMU5qU1VOSlRFeFZiRTR4VDJOTVVUMDkjMw==/produk-domestik-regional-bruto-per-kapita-atas-dasar-harga-berlaku-menurut-provinsi--ribu-rupiah-.html?year=2022)

Content
Automotive ownership data consist of vehicles type: car, bus, truck, and motorcycle. Each file of dataset represents the data of a certain year, combining those data shall give overview in yearly trend. Population and GDP datas was joined to the data, which can be utilized to observe their correlation to the trend.",.csv,True
Indonesia Automotive ownership (2018 - 2022),5,indonesia-automotive-ownership-2018-2022,Data Indonesian Province Automotive ownership population GDP 2021.csv,other,"Context
Datasets are a yearly release by Indonesian National Statistic Bureau. This data is combined (with selection) from tables of provincial data of (1) Automotive ownership, (2) population, and (3) Regional GDP per capita. 
Raw source:
[Automotive](https://www.bps.go.id/id/statistics-table/3/VjJ3NGRGa3dkRk5MTlU1bVNFOTVVbmQyVURSTVFUMDkjMw==/jumlah-kendaraan-bermotor-menurut-provinsi-dan-jenis-kendaraan--unit-.html?year=2022)
[Population](https://www.bps.go.id/id/statistics-table/3/V1ZSbFRUY3lTbFpEYTNsVWNGcDZjek53YkhsNFFUMDkjMw==/penduduk--laju-pertumbuhan-penduduk--distribusi-persentase-penduduk--kepadatan-penduduk--rasio-jenis-kelamin-penduduk-menurut-provinsi--2022.html?year=2022)
[Regional GDP](https://www.bps.go.id/id/statistics-table/3/YWtoQlRVZzNiMU5qU1VOSlRFeFZiRTR4VDJOTVVUMDkjMw==/produk-domestik-regional-bruto-per-kapita-atas-dasar-harga-berlaku-menurut-provinsi--ribu-rupiah-.html?year=2022)

Content
Automotive ownership data consist of vehicles type: car, bus, truck, and motorcycle. Each file of dataset represents the data of a certain year, combining those data shall give overview in yearly trend. Population and GDP datas was joined to the data, which can be utilized to observe their correlation to the trend.",.csv,True
Indonesian Food Recipes,8,indonesian-food-recipes,dataset-tempe.csv,CC0-1.0,"### Context  

Indonesian foods are well-known for their rich taste. There are many spices used even for daily foods. This dataset may give insight on how to prepare Indonesian food, in many ways. 

### Content  

This dataset contains 14000 recipes divided in 7 categories:  
- `dataset-ayam.csv` (chicken recipes)  
- `dataset-kambing.csv` (lamb recipes)   
- `dataset-sapi.csv` (beef recipes)   
- `dataset-telur.csv` (egg recipes)  
- `dataset-tahu.csv` (tofu recipes)  
- `dataset-ikan.csv` (fish recipes)  
- `dataset-tempe.csv` (tempe recipes)  

For each category, there are 5 columns:  
- Title  
- Ingredients  
- Steps  
- Love  
- URL

### Acknowledgements

All the data were taken from Cookpad on 23 Feb 2018.


### Inspiration

Dare to find out what is the unique recipe? The most strange? Or the common way to cook particular ingredients.   
Can you create your own recipe based on this dataset?",.csv,True
Indonesian Food Recipes,8,indonesian-food-recipes,dataset-ayam.csv,CC0-1.0,"### Context  

Indonesian foods are well-known for their rich taste. There are many spices used even for daily foods. This dataset may give insight on how to prepare Indonesian food, in many ways. 

### Content  

This dataset contains 14000 recipes divided in 7 categories:  
- `dataset-ayam.csv` (chicken recipes)  
- `dataset-kambing.csv` (lamb recipes)   
- `dataset-sapi.csv` (beef recipes)   
- `dataset-telur.csv` (egg recipes)  
- `dataset-tahu.csv` (tofu recipes)  
- `dataset-ikan.csv` (fish recipes)  
- `dataset-tempe.csv` (tempe recipes)  

For each category, there are 5 columns:  
- Title  
- Ingredients  
- Steps  
- Love  
- URL

### Acknowledgements

All the data were taken from Cookpad on 23 Feb 2018.


### Inspiration

Dare to find out what is the unique recipe? The most strange? Or the common way to cook particular ingredients.   
Can you create your own recipe based on this dataset?",.csv,True
Indonesian Food Recipes,8,indonesian-food-recipes,dataset-udang.csv,CC0-1.0,"### Context  

Indonesian foods are well-known for their rich taste. There are many spices used even for daily foods. This dataset may give insight on how to prepare Indonesian food, in many ways. 

### Content  

This dataset contains 14000 recipes divided in 7 categories:  
- `dataset-ayam.csv` (chicken recipes)  
- `dataset-kambing.csv` (lamb recipes)   
- `dataset-sapi.csv` (beef recipes)   
- `dataset-telur.csv` (egg recipes)  
- `dataset-tahu.csv` (tofu recipes)  
- `dataset-ikan.csv` (fish recipes)  
- `dataset-tempe.csv` (tempe recipes)  

For each category, there are 5 columns:  
- Title  
- Ingredients  
- Steps  
- Love  
- URL

### Acknowledgements

All the data were taken from Cookpad on 23 Feb 2018.


### Inspiration

Dare to find out what is the unique recipe? The most strange? Or the common way to cook particular ingredients.   
Can you create your own recipe based on this dataset?",.csv,True
Indonesian Food Recipes,8,indonesian-food-recipes,dataset-kambing.csv,CC0-1.0,"### Context  

Indonesian foods are well-known for their rich taste. There are many spices used even for daily foods. This dataset may give insight on how to prepare Indonesian food, in many ways. 

### Content  

This dataset contains 14000 recipes divided in 7 categories:  
- `dataset-ayam.csv` (chicken recipes)  
- `dataset-kambing.csv` (lamb recipes)   
- `dataset-sapi.csv` (beef recipes)   
- `dataset-telur.csv` (egg recipes)  
- `dataset-tahu.csv` (tofu recipes)  
- `dataset-ikan.csv` (fish recipes)  
- `dataset-tempe.csv` (tempe recipes)  

For each category, there are 5 columns:  
- Title  
- Ingredients  
- Steps  
- Love  
- URL

### Acknowledgements

All the data were taken from Cookpad on 23 Feb 2018.


### Inspiration

Dare to find out what is the unique recipe? The most strange? Or the common way to cook particular ingredients.   
Can you create your own recipe based on this dataset?",.csv,True
Indonesian Food Recipes,8,indonesian-food-recipes,dataset-ikan.csv,CC0-1.0,"### Context  

Indonesian foods are well-known for their rich taste. There are many spices used even for daily foods. This dataset may give insight on how to prepare Indonesian food, in many ways. 

### Content  

This dataset contains 14000 recipes divided in 7 categories:  
- `dataset-ayam.csv` (chicken recipes)  
- `dataset-kambing.csv` (lamb recipes)   
- `dataset-sapi.csv` (beef recipes)   
- `dataset-telur.csv` (egg recipes)  
- `dataset-tahu.csv` (tofu recipes)  
- `dataset-ikan.csv` (fish recipes)  
- `dataset-tempe.csv` (tempe recipes)  

For each category, there are 5 columns:  
- Title  
- Ingredients  
- Steps  
- Love  
- URL

### Acknowledgements

All the data were taken from Cookpad on 23 Feb 2018.


### Inspiration

Dare to find out what is the unique recipe? The most strange? Or the common way to cook particular ingredients.   
Can you create your own recipe based on this dataset?",.csv,True
Indonesian Food Recipes,8,indonesian-food-recipes,dataset-telur.csv,CC0-1.0,"### Context  

Indonesian foods are well-known for their rich taste. There are many spices used even for daily foods. This dataset may give insight on how to prepare Indonesian food, in many ways. 

### Content  

This dataset contains 14000 recipes divided in 7 categories:  
- `dataset-ayam.csv` (chicken recipes)  
- `dataset-kambing.csv` (lamb recipes)   
- `dataset-sapi.csv` (beef recipes)   
- `dataset-telur.csv` (egg recipes)  
- `dataset-tahu.csv` (tofu recipes)  
- `dataset-ikan.csv` (fish recipes)  
- `dataset-tempe.csv` (tempe recipes)  

For each category, there are 5 columns:  
- Title  
- Ingredients  
- Steps  
- Love  
- URL

### Acknowledgements

All the data were taken from Cookpad on 23 Feb 2018.


### Inspiration

Dare to find out what is the unique recipe? The most strange? Or the common way to cook particular ingredients.   
Can you create your own recipe based on this dataset?",.csv,True
Indonesian Food Recipes,8,indonesian-food-recipes,dataset-tahu.csv,CC0-1.0,"### Context  

Indonesian foods are well-known for their rich taste. There are many spices used even for daily foods. This dataset may give insight on how to prepare Indonesian food, in many ways. 

### Content  

This dataset contains 14000 recipes divided in 7 categories:  
- `dataset-ayam.csv` (chicken recipes)  
- `dataset-kambing.csv` (lamb recipes)   
- `dataset-sapi.csv` (beef recipes)   
- `dataset-telur.csv` (egg recipes)  
- `dataset-tahu.csv` (tofu recipes)  
- `dataset-ikan.csv` (fish recipes)  
- `dataset-tempe.csv` (tempe recipes)  

For each category, there are 5 columns:  
- Title  
- Ingredients  
- Steps  
- Love  
- URL

### Acknowledgements

All the data were taken from Cookpad on 23 Feb 2018.


### Inspiration

Dare to find out what is the unique recipe? The most strange? Or the common way to cook particular ingredients.   
Can you create your own recipe based on this dataset?",.csv,True
Indonesian Food Recipes,8,indonesian-food-recipes,dataset-sapi.csv,CC0-1.0,"### Context  

Indonesian foods are well-known for their rich taste. There are many spices used even for daily foods. This dataset may give insight on how to prepare Indonesian food, in many ways. 

### Content  

This dataset contains 14000 recipes divided in 7 categories:  
- `dataset-ayam.csv` (chicken recipes)  
- `dataset-kambing.csv` (lamb recipes)   
- `dataset-sapi.csv` (beef recipes)   
- `dataset-telur.csv` (egg recipes)  
- `dataset-tahu.csv` (tofu recipes)  
- `dataset-ikan.csv` (fish recipes)  
- `dataset-tempe.csv` (tempe recipes)  

For each category, there are 5 columns:  
- Title  
- Ingredients  
- Steps  
- Love  
- URL

### Acknowledgements

All the data were taken from Cookpad on 23 Feb 2018.


### Inspiration

Dare to find out what is the unique recipe? The most strange? Or the common way to cook particular ingredients.   
Can you create your own recipe based on this dataset?",.csv,True
Instagram fake spammer genuine accounts,2,instagram-fake-spammer-genuine-accounts,test.csv,Attribution 3.0 Unported (CC BY 3.0),"### Context

[comment]: &lt;&gt; (There's a story behind every dataset and here's your opportunity to share yours.)
Fakes and spammers are a major problem on all social media platforms, including Instagram.
This is the subject of my final-year project in which I set out to find ways of detecting them using machine learning.
In this dataset fake and spammer are interchangeable terms.


### Content

[comment]: &lt;&gt; (What's inside is more than just rows and columns. Make it easy for others to get started by describing how you acquired the data and what time period it represents, too.)
I have personally identified the spammer/fake accounts included in this dataset after carefully examining each instance and as such the dataset has high level of accuracy though there might be a couple of misidentified accounts in the spammers list as well.
The dataset has been collected using a crawler from 15-19, March 2019.


[comment]: &lt;&gt; (### Acknowledgements)

[comment]: &lt;&gt; (We wouldn't be here without the help of others. If you owe any attributions or thanks, include them here along with any citations of past research.)


### Inspiration

[comment]: &lt;&gt; (Your data will be in front of the world's largest data science community. What questions do you want to see answered?)
This dataset could be further improved in quantity and quality measures, but how much accuracy can it achieve?
Possible ways of using the models to tackle the problem?
",.csv,True
Instagram fake spammer genuine accounts,2,instagram-fake-spammer-genuine-accounts,train.csv,Attribution 3.0 Unported (CC BY 3.0),"### Context

[comment]: &lt;&gt; (There's a story behind every dataset and here's your opportunity to share yours.)
Fakes and spammers are a major problem on all social media platforms, including Instagram.
This is the subject of my final-year project in which I set out to find ways of detecting them using machine learning.
In this dataset fake and spammer are interchangeable terms.


### Content

[comment]: &lt;&gt; (What's inside is more than just rows and columns. Make it easy for others to get started by describing how you acquired the data and what time period it represents, too.)
I have personally identified the spammer/fake accounts included in this dataset after carefully examining each instance and as such the dataset has high level of accuracy though there might be a couple of misidentified accounts in the spammers list as well.
The dataset has been collected using a crawler from 15-19, March 2019.


[comment]: &lt;&gt; (### Acknowledgements)

[comment]: &lt;&gt; (We wouldn't be here without the help of others. If you owe any attributions or thanks, include them here along with any citations of past research.)


### Inspiration

[comment]: &lt;&gt; (Your data will be in front of the world's largest data science community. What questions do you want to see answered?)
This dataset could be further improved in quantity and quality measures, but how much accuracy can it achieve?
Possible ways of using the models to tackle the problem?
",.csv,True
LLM Prompt Recovery: Style Extraction with GPT3.5,2,gpt3-condenced-prompt-style,style.csv,MIT,"This is my dataset for the[ **LLM Prompt Recovery competition**](https://www.kaggle.com/competitions/llm-prompt-recovery).
This dataset has a new column, `style` which indicates the writing style of each `rewritten text` in a more simple expression based on `rewrite_prompt`, in addition to these original public datasets of,

/kaggle/input/llm-prompt-recovery-synthetic-datastore/gemma1000_w7b.csv
/kaggle/input/3000-rewritten-texts-prompt-recovery-challenge/prompts_0_500_wiki_first_para_3000.csv

For example, 

| original_text | rewrite_prompt | rewritten_text | style |
| --- | --- | --- | --- |
| Port-au-Prince, Haiti (CNN) -- Earthquake vict...	 | Turn this into an association to be joined. |  Sure, here is the association you requested:\n...	 |  association to be joined |

The original dataset has 4000 rows, however, this dataset has 3375 rows which does not have a `nan` value.
So you can use 3375 rows for training.

I used GPT3.5 to extract keywords/concepts with the prompt mentioned below.

It cost me around 0.4$ 💸 (Please give me an upvote!)
But I made this public because I need help with my approach, so please give me ideas for the competition!

**I don't think this is disruptive to the competition. I still cannot get a higher score than the mean prompt with this dataset. :(**

I was inspired by Darien's discussion, thank you. 
https://www.kaggle.com/competitions/llm-prompt-recovery/discussion/483916

## Full Prompt for GPT3.5


    These sentences are prompted to convert a sentence in a specific `style`.
    Your task is to extract an important concept of `style` for each sentence and make a list of words as a Python list.
    Output is only a Python list.　Do not say OUTPUT:
    Each `style` must follow the rules below
    - not end with a preposition
    - must make sense by itself. 
    - must not end with ""to be"". must make sense.

    EXAMPLES:
    [
        ""Make this a formal apology letter to a customer."",
        ""Style this as a professional development plan for an employee."",
        ""Turn this into a programmer's code."",
        ""Convert this into a technique to be used."",
        ""Write it as an anthem for a revolution."",
        ""Rewrite it as the first contact message from aliens."",
        ""Convert this into a technical specification document for a product"",
        ""Rewrite this as a cooperation to be engaged in."",
        ""Recast it as a declaration of a new age by the first AI president.""
    ]

    OUTPUT:
    [""formal apology letter"", ""professional development plan"", 
    ""programmer code"", ""technique to be used"",""anthem for revolution"",""first contact from aliens"",
    ""technical specification"",""cooperation to be engaged"",""declaration by AI predident""]

    INPUT:

   ",.csv,True
LLM Prompt Recovery: Style Extraction with GPT3.5,2,gpt3-condenced-prompt-style,drop-nan-3375-entries.csv,MIT,"This is my dataset for the[ **LLM Prompt Recovery competition**](https://www.kaggle.com/competitions/llm-prompt-recovery).
This dataset has a new column, `style` which indicates the writing style of each `rewritten text` in a more simple expression based on `rewrite_prompt`, in addition to these original public datasets of,

/kaggle/input/llm-prompt-recovery-synthetic-datastore/gemma1000_w7b.csv
/kaggle/input/3000-rewritten-texts-prompt-recovery-challenge/prompts_0_500_wiki_first_para_3000.csv

For example, 

| original_text | rewrite_prompt | rewritten_text | style |
| --- | --- | --- | --- |
| Port-au-Prince, Haiti (CNN) -- Earthquake vict...	 | Turn this into an association to be joined. |  Sure, here is the association you requested:\n...	 |  association to be joined |

The original dataset has 4000 rows, however, this dataset has 3375 rows which does not have a `nan` value.
So you can use 3375 rows for training.

I used GPT3.5 to extract keywords/concepts with the prompt mentioned below.

It cost me around 0.4$ 💸 (Please give me an upvote!)
But I made this public because I need help with my approach, so please give me ideas for the competition!

**I don't think this is disruptive to the competition. I still cannot get a higher score than the mean prompt with this dataset. :(**

I was inspired by Darien's discussion, thank you. 
https://www.kaggle.com/competitions/llm-prompt-recovery/discussion/483916

## Full Prompt for GPT3.5


    These sentences are prompted to convert a sentence in a specific `style`.
    Your task is to extract an important concept of `style` for each sentence and make a list of words as a Python list.
    Output is only a Python list.　Do not say OUTPUT:
    Each `style` must follow the rules below
    - not end with a preposition
    - must make sense by itself. 
    - must not end with ""to be"". must make sense.

    EXAMPLES:
    [
        ""Make this a formal apology letter to a customer."",
        ""Style this as a professional development plan for an employee."",
        ""Turn this into a programmer's code."",
        ""Convert this into a technique to be used."",
        ""Write it as an anthem for a revolution."",
        ""Rewrite it as the first contact message from aliens."",
        ""Convert this into a technical specification document for a product"",
        ""Rewrite this as a cooperation to be engaged in."",
        ""Recast it as a declaration of a new age by the first AI president.""
    ]

    OUTPUT:
    [""formal apology letter"", ""professional development plan"", 
    ""programmer code"", ""technique to be used"",""anthem for revolution"",""first contact from aliens"",
    ""technical specification"",""cooperation to be engaged"",""declaration by AI predident""]

    INPUT:

   ",.csv,True
Laptop Price Prediction using specifications 💻 ,2,laptop-price-prediction,laptops_test.csv,DbCL-1.0,"What Factors Affect Laptop Computer Prices?

Several different factors can affect laptop computer prices. These factors include the brand of computer and the number of options and add-ons included in the computer package. In addition, the amount of memory and the speed of the processor can also affect pricing. Though less common, some consumers spend additional money to purchase a computer based on the overall “look” and design of the system.

In many cases, name brand computers are more expensive than generic versions. This price increase often has more to do with name recognition than any actual superiority of the product. One major difference between name brand and generic systems is that in most cases, name brand computers offer better warranties than generic versions. Having the option of returning a computer that is malfunctioning is often enough of an incentive to encourage many consumers to spend more money.

Functionality is an important factor in determining laptop computer prices. A computer with more memory often performs better for a longer time than a computer with less memory. In addition, hard drive space is also crucial, and the size of the hard drive usually affects pricing. Many consumers may also look for digital video drivers and other types of recording devices that may affect the laptop computer prices.

Most computers come with some software pre-installed. In most cases, the more software that is installed on a computer, the more expensive it is. This is especially true if the installed programs are from well-established and recognizable software publishers. Those considering purchasing a new laptop computer should be aware that many of the pre-installed programs may be trial versions only, and will expire within a certain time period. In order to keep the programs, a code will need to be purchased, and then a permanent version of the software can be downloaded.

-Many consumers who are purchasing a new computer are buying an entire package. In addition to the computer itself, these systems typically include a monitor, keyboard, and mouse. Some packages may even include a printer or digital camera. The number of extras included in a computer package usually affects laptop computer prices.
Some industry leaders in computer manufacturing make it a selling point to offer computers in sleek styling and in a variety of colors. They may also offer unusual or contemporary system design. Though this is less important to many consumers, for those who do value “looks,” this type of system may be well worth the extra cost.",.csv,True
Laptop Price Prediction using specifications 💻 ,2,laptop-price-prediction,laptops_train.csv,DbCL-1.0,"What Factors Affect Laptop Computer Prices?

Several different factors can affect laptop computer prices. These factors include the brand of computer and the number of options and add-ons included in the computer package. In addition, the amount of memory and the speed of the processor can also affect pricing. Though less common, some consumers spend additional money to purchase a computer based on the overall “look” and design of the system.

In many cases, name brand computers are more expensive than generic versions. This price increase often has more to do with name recognition than any actual superiority of the product. One major difference between name brand and generic systems is that in most cases, name brand computers offer better warranties than generic versions. Having the option of returning a computer that is malfunctioning is often enough of an incentive to encourage many consumers to spend more money.

Functionality is an important factor in determining laptop computer prices. A computer with more memory often performs better for a longer time than a computer with less memory. In addition, hard drive space is also crucial, and the size of the hard drive usually affects pricing. Many consumers may also look for digital video drivers and other types of recording devices that may affect the laptop computer prices.

Most computers come with some software pre-installed. In most cases, the more software that is installed on a computer, the more expensive it is. This is especially true if the installed programs are from well-established and recognizable software publishers. Those considering purchasing a new laptop computer should be aware that many of the pre-installed programs may be trial versions only, and will expire within a certain time period. In order to keep the programs, a code will need to be purchased, and then a permanent version of the software can be downloaded.

-Many consumers who are purchasing a new computer are buying an entire package. In addition to the computer itself, these systems typically include a monitor, keyboard, and mouse. Some packages may even include a printer or digital camera. The number of extras included in a computer package usually affects laptop computer prices.
Some industry leaders in computer manufacturing make it a selling point to offer computers in sleek styling and in a variety of colors. They may also offer unusual or contemporary system design. Though this is less important to many consumers, for those who do value “looks,” this type of system may be well worth the extra cost.",.csv,True
Large random Spotify artist sample with metadata,2,large-random-spotify-artist-sample-with-metadata,Spotify_artist_info.csv,ODbL-1.0,"This is a (pseudo) random sample of Spotify artist metadata, including Monthly Listener counts from 2024, follower counts, genres, dates of first and most-recent releases, total number of releases and total number of tracks, as of 2024.

The dataset is designed to be *representative of the distribution of all artists on Spotify, without bias towards more well-known/popular artists.* This sets it apart from other similar datasets, retrieved using the [Spotify Web API](https://developer.spotify.com/documentation/web-api).

There are two files: `CLEANED_Spotify_artist_info.csv`(~15,000 artists) contains only artists/rows with non-null values of all columns but Popularity and Followers (Monthly Listeners is more informative than either of these). The other file, `Spotify_artist_info.csv` (~37,000 artists) retains the artists/rows with null values in these columns.

All the code associated with the creation of this dataset can be found on my [GitHub](https://github.com/sjeffreson/serch). See data Provenance (below) for further details.

All suggestions for improvement are very welcome!

# Possible usage
This dataset is particularly useful as a baseline/comparison for the exploration of bias, or for any demographic study of artists on Spotify, for example:
1. Studying how many artists on Spotify are actively-producing music, and at what rate
2. Comparing Monthly Listener distributions across different genres
3. In combination with [this dataset of artists featured on Editorial playlists](https://www.kaggle.com/datasets/sarahjeffreson/featured-spotify-artiststracks-with-metadata), a causal exploration of the factors (and biases) that might lead an artist to be featured on the Editorial playlists
4. Any other interesting ideas you have - please discuss! 🙏 

# Column description
- **ids:** Unique Spotify IDs of each artist, *str*
- **names:** Spotify artist name, *str*
- **popularity:** The Spotify-defined popularity metric, *int*
   - Note that [Spotify does not actually disclose how this is calculated](https://developer.spotify.com/documentation/web-api/reference/get-track), and so this metric should be used with caution. In broad terms, it's calculated from the popularity of an artist's tracks, which in turn is ""based, in the most part, on the total number of plays the track has had and how recent those plays are.""
- **followers:** The number of followers the artist has, *int*
- **genres:** The musical genres associated with each artist: where more than one genre is associated with an artist, separate genres are contained within quotation marks and separated by commas; where only one genre is present, no quotations marks are used, *str, empty if no genres*
   - Note that genres are often absent from the Spotify metadata, so in `CLEANED_Spotify_artist_info.csv`, we've done an additional scrape of the Spotify biographies of artists with missing genres, avoiding throwing out an additional 3,000 rows (see Provenance for details)
   - To use only the genres from the official Spotify metadata, you can apply your own cleaning to `Spotify_artist_info.csv`
- **first_release:** The year of an artist's first release, *int, -1 if no releases*
- **last_release:** The year of an artist's most recent release, as of May 2024, *int, -1 if no releases*
- **num_releases:** The total number of releases an artist has made, as of May 2024, capped at 20 (all numbers &gt;20 are set to 20) *int, -1 if no releases*
- **num_tracks:** The total number of tracks *in the artist's most recent album or single, not compilation*, as of May 2024, *int, -1 if no tracks*
- **monthly_listeners:** The number of unique monthly listeners for each artist, collected during April and May 2024. This is the most reliable measure of an artist's popularity, that's publicly available on Spotify, *float, 0 if absent*",.csv,True
Large random Spotify artist sample with metadata,2,large-random-spotify-artist-sample-with-metadata,CLEANED_Spotify_artist_info.csv,ODbL-1.0,"This is a (pseudo) random sample of Spotify artist metadata, including Monthly Listener counts from 2024, follower counts, genres, dates of first and most-recent releases, total number of releases and total number of tracks, as of 2024.

The dataset is designed to be *representative of the distribution of all artists on Spotify, without bias towards more well-known/popular artists.* This sets it apart from other similar datasets, retrieved using the [Spotify Web API](https://developer.spotify.com/documentation/web-api).

There are two files: `CLEANED_Spotify_artist_info.csv`(~15,000 artists) contains only artists/rows with non-null values of all columns but Popularity and Followers (Monthly Listeners is more informative than either of these). The other file, `Spotify_artist_info.csv` (~37,000 artists) retains the artists/rows with null values in these columns.

All the code associated with the creation of this dataset can be found on my [GitHub](https://github.com/sjeffreson/serch). See data Provenance (below) for further details.

All suggestions for improvement are very welcome!

# Possible usage
This dataset is particularly useful as a baseline/comparison for the exploration of bias, or for any demographic study of artists on Spotify, for example:
1. Studying how many artists on Spotify are actively-producing music, and at what rate
2. Comparing Monthly Listener distributions across different genres
3. In combination with [this dataset of artists featured on Editorial playlists](https://www.kaggle.com/datasets/sarahjeffreson/featured-spotify-artiststracks-with-metadata), a causal exploration of the factors (and biases) that might lead an artist to be featured on the Editorial playlists
4. Any other interesting ideas you have - please discuss! 🙏 

# Column description
- **ids:** Unique Spotify IDs of each artist, *str*
- **names:** Spotify artist name, *str*
- **popularity:** The Spotify-defined popularity metric, *int*
   - Note that [Spotify does not actually disclose how this is calculated](https://developer.spotify.com/documentation/web-api/reference/get-track), and so this metric should be used with caution. In broad terms, it's calculated from the popularity of an artist's tracks, which in turn is ""based, in the most part, on the total number of plays the track has had and how recent those plays are.""
- **followers:** The number of followers the artist has, *int*
- **genres:** The musical genres associated with each artist: where more than one genre is associated with an artist, separate genres are contained within quotation marks and separated by commas; where only one genre is present, no quotations marks are used, *str, empty if no genres*
   - Note that genres are often absent from the Spotify metadata, so in `CLEANED_Spotify_artist_info.csv`, we've done an additional scrape of the Spotify biographies of artists with missing genres, avoiding throwing out an additional 3,000 rows (see Provenance for details)
   - To use only the genres from the official Spotify metadata, you can apply your own cleaning to `Spotify_artist_info.csv`
- **first_release:** The year of an artist's first release, *int, -1 if no releases*
- **last_release:** The year of an artist's most recent release, as of May 2024, *int, -1 if no releases*
- **num_releases:** The total number of releases an artist has made, as of May 2024, capped at 20 (all numbers &gt;20 are set to 20) *int, -1 if no releases*
- **num_tracks:** The total number of tracks *in the artist's most recent album or single, not compilation*, as of May 2024, *int, -1 if no tracks*
- **monthly_listeners:** The number of unique monthly listeners for each artist, collected during April and May 2024. This is the most reliable measure of an artist's popularity, that's publicly available on Spotify, *float, 0 if absent*",.csv,True
MAANG companies Stock prices (updated daily),15,netflix-stock-price,NETFLIX_monthly.csv,CC0-1.0,"## Description
&gt; This dataset contains the full historical data of the stock prices for **MAANG** companies since their Initial Public Offering (IPO). **MAANG** is an acronym that stands for ***Meta, Amazon, Apple, Netflix, and Google***. The dataset contains daily, weekly, and monthly stock prices for each company and is automatically updated daily with the latest data obtained from [Yahoo Finance](https://finance.yahoo.com/).

## Features
&gt; - **Date**: The specific date on which the stock price was recorded.
&gt; - **Open**: The opening price of the company's stock on that particular day.
&gt; - **High**: The highest trading price of the company's stock on that day.
&gt; - **Low**: The lowest trading price of the company's stock on that day.
&gt; - **Close**: The closing price of the company's stock on that day.
&gt; - **Adj Close**: The adjusted closing price of the company's stock on that day.
&gt; - **Volume**: The total number of shares traded on that day.

## Use cases
&gt; This dataset can be utilized for a wide range of applications, including but not limited to:
- **Market Analysis**: Conduct comprehensive market studies, analyze trends, and spot seasonal patterns.
- **Investment Strategies**: Develop and backtest investment strategies based on historical price movements.
- **Forecasting**: Build predictive models to forecast future stock prices and make informed decisions.
- **Trading Algorithms**: Design and test trading algorithms to capitalize on market opportunities.

Please, provide an upvote👍if the dataset was useful for your task. It would be much appreciated😄",.csv,True
MAANG companies Stock prices (updated daily),15,netflix-stock-price,APPLE_monthly.csv,CC0-1.0,"## Description
&gt; This dataset contains the full historical data of the stock prices for **MAANG** companies since their Initial Public Offering (IPO). **MAANG** is an acronym that stands for ***Meta, Amazon, Apple, Netflix, and Google***. The dataset contains daily, weekly, and monthly stock prices for each company and is automatically updated daily with the latest data obtained from [Yahoo Finance](https://finance.yahoo.com/).

## Features
&gt; - **Date**: The specific date on which the stock price was recorded.
&gt; - **Open**: The opening price of the company's stock on that particular day.
&gt; - **High**: The highest trading price of the company's stock on that day.
&gt; - **Low**: The lowest trading price of the company's stock on that day.
&gt; - **Close**: The closing price of the company's stock on that day.
&gt; - **Adj Close**: The adjusted closing price of the company's stock on that day.
&gt; - **Volume**: The total number of shares traded on that day.

## Use cases
&gt; This dataset can be utilized for a wide range of applications, including but not limited to:
- **Market Analysis**: Conduct comprehensive market studies, analyze trends, and spot seasonal patterns.
- **Investment Strategies**: Develop and backtest investment strategies based on historical price movements.
- **Forecasting**: Build predictive models to forecast future stock prices and make informed decisions.
- **Trading Algorithms**: Design and test trading algorithms to capitalize on market opportunities.

Please, provide an upvote👍if the dataset was useful for your task. It would be much appreciated😄",.csv,True
MAANG companies Stock prices (updated daily),15,netflix-stock-price,GOOGLE_monthly.csv,CC0-1.0,"## Description
&gt; This dataset contains the full historical data of the stock prices for **MAANG** companies since their Initial Public Offering (IPO). **MAANG** is an acronym that stands for ***Meta, Amazon, Apple, Netflix, and Google***. The dataset contains daily, weekly, and monthly stock prices for each company and is automatically updated daily with the latest data obtained from [Yahoo Finance](https://finance.yahoo.com/).

## Features
&gt; - **Date**: The specific date on which the stock price was recorded.
&gt; - **Open**: The opening price of the company's stock on that particular day.
&gt; - **High**: The highest trading price of the company's stock on that day.
&gt; - **Low**: The lowest trading price of the company's stock on that day.
&gt; - **Close**: The closing price of the company's stock on that day.
&gt; - **Adj Close**: The adjusted closing price of the company's stock on that day.
&gt; - **Volume**: The total number of shares traded on that day.

## Use cases
&gt; This dataset can be utilized for a wide range of applications, including but not limited to:
- **Market Analysis**: Conduct comprehensive market studies, analyze trends, and spot seasonal patterns.
- **Investment Strategies**: Develop and backtest investment strategies based on historical price movements.
- **Forecasting**: Build predictive models to forecast future stock prices and make informed decisions.
- **Trading Algorithms**: Design and test trading algorithms to capitalize on market opportunities.

Please, provide an upvote👍if the dataset was useful for your task. It would be much appreciated😄",.csv,True
MAANG companies Stock prices (updated daily),15,netflix-stock-price,AMAZON_daily.csv,CC0-1.0,"## Description
&gt; This dataset contains the full historical data of the stock prices for **MAANG** companies since their Initial Public Offering (IPO). **MAANG** is an acronym that stands for ***Meta, Amazon, Apple, Netflix, and Google***. The dataset contains daily, weekly, and monthly stock prices for each company and is automatically updated daily with the latest data obtained from [Yahoo Finance](https://finance.yahoo.com/).

## Features
&gt; - **Date**: The specific date on which the stock price was recorded.
&gt; - **Open**: The opening price of the company's stock on that particular day.
&gt; - **High**: The highest trading price of the company's stock on that day.
&gt; - **Low**: The lowest trading price of the company's stock on that day.
&gt; - **Close**: The closing price of the company's stock on that day.
&gt; - **Adj Close**: The adjusted closing price of the company's stock on that day.
&gt; - **Volume**: The total number of shares traded on that day.

## Use cases
&gt; This dataset can be utilized for a wide range of applications, including but not limited to:
- **Market Analysis**: Conduct comprehensive market studies, analyze trends, and spot seasonal patterns.
- **Investment Strategies**: Develop and backtest investment strategies based on historical price movements.
- **Forecasting**: Build predictive models to forecast future stock prices and make informed decisions.
- **Trading Algorithms**: Design and test trading algorithms to capitalize on market opportunities.

Please, provide an upvote👍if the dataset was useful for your task. It would be much appreciated😄",.csv,True
MAANG companies Stock prices (updated daily),15,netflix-stock-price,GOOGLE_weekly.csv,CC0-1.0,"## Description
&gt; This dataset contains the full historical data of the stock prices for **MAANG** companies since their Initial Public Offering (IPO). **MAANG** is an acronym that stands for ***Meta, Amazon, Apple, Netflix, and Google***. The dataset contains daily, weekly, and monthly stock prices for each company and is automatically updated daily with the latest data obtained from [Yahoo Finance](https://finance.yahoo.com/).

## Features
&gt; - **Date**: The specific date on which the stock price was recorded.
&gt; - **Open**: The opening price of the company's stock on that particular day.
&gt; - **High**: The highest trading price of the company's stock on that day.
&gt; - **Low**: The lowest trading price of the company's stock on that day.
&gt; - **Close**: The closing price of the company's stock on that day.
&gt; - **Adj Close**: The adjusted closing price of the company's stock on that day.
&gt; - **Volume**: The total number of shares traded on that day.

## Use cases
&gt; This dataset can be utilized for a wide range of applications, including but not limited to:
- **Market Analysis**: Conduct comprehensive market studies, analyze trends, and spot seasonal patterns.
- **Investment Strategies**: Develop and backtest investment strategies based on historical price movements.
- **Forecasting**: Build predictive models to forecast future stock prices and make informed decisions.
- **Trading Algorithms**: Design and test trading algorithms to capitalize on market opportunities.

Please, provide an upvote👍if the dataset was useful for your task. It would be much appreciated😄",.csv,True
MAANG companies Stock prices (updated daily),15,netflix-stock-price,AMAZON_weekly.csv,CC0-1.0,"## Description
&gt; This dataset contains the full historical data of the stock prices for **MAANG** companies since their Initial Public Offering (IPO). **MAANG** is an acronym that stands for ***Meta, Amazon, Apple, Netflix, and Google***. The dataset contains daily, weekly, and monthly stock prices for each company and is automatically updated daily with the latest data obtained from [Yahoo Finance](https://finance.yahoo.com/).

## Features
&gt; - **Date**: The specific date on which the stock price was recorded.
&gt; - **Open**: The opening price of the company's stock on that particular day.
&gt; - **High**: The highest trading price of the company's stock on that day.
&gt; - **Low**: The lowest trading price of the company's stock on that day.
&gt; - **Close**: The closing price of the company's stock on that day.
&gt; - **Adj Close**: The adjusted closing price of the company's stock on that day.
&gt; - **Volume**: The total number of shares traded on that day.

## Use cases
&gt; This dataset can be utilized for a wide range of applications, including but not limited to:
- **Market Analysis**: Conduct comprehensive market studies, analyze trends, and spot seasonal patterns.
- **Investment Strategies**: Develop and backtest investment strategies based on historical price movements.
- **Forecasting**: Build predictive models to forecast future stock prices and make informed decisions.
- **Trading Algorithms**: Design and test trading algorithms to capitalize on market opportunities.

Please, provide an upvote👍if the dataset was useful for your task. It would be much appreciated😄",.csv,True
MAANG companies Stock prices (updated daily),15,netflix-stock-price,META_monthly.csv,CC0-1.0,"## Description
&gt; This dataset contains the full historical data of the stock prices for **MAANG** companies since their Initial Public Offering (IPO). **MAANG** is an acronym that stands for ***Meta, Amazon, Apple, Netflix, and Google***. The dataset contains daily, weekly, and monthly stock prices for each company and is automatically updated daily with the latest data obtained from [Yahoo Finance](https://finance.yahoo.com/).

## Features
&gt; - **Date**: The specific date on which the stock price was recorded.
&gt; - **Open**: The opening price of the company's stock on that particular day.
&gt; - **High**: The highest trading price of the company's stock on that day.
&gt; - **Low**: The lowest trading price of the company's stock on that day.
&gt; - **Close**: The closing price of the company's stock on that day.
&gt; - **Adj Close**: The adjusted closing price of the company's stock on that day.
&gt; - **Volume**: The total number of shares traded on that day.

## Use cases
&gt; This dataset can be utilized for a wide range of applications, including but not limited to:
- **Market Analysis**: Conduct comprehensive market studies, analyze trends, and spot seasonal patterns.
- **Investment Strategies**: Develop and backtest investment strategies based on historical price movements.
- **Forecasting**: Build predictive models to forecast future stock prices and make informed decisions.
- **Trading Algorithms**: Design and test trading algorithms to capitalize on market opportunities.

Please, provide an upvote👍if the dataset was useful for your task. It would be much appreciated😄",.csv,True
MAANG companies Stock prices (updated daily),15,netflix-stock-price,NETFLIX_weekly.csv,CC0-1.0,"## Description
&gt; This dataset contains the full historical data of the stock prices for **MAANG** companies since their Initial Public Offering (IPO). **MAANG** is an acronym that stands for ***Meta, Amazon, Apple, Netflix, and Google***. The dataset contains daily, weekly, and monthly stock prices for each company and is automatically updated daily with the latest data obtained from [Yahoo Finance](https://finance.yahoo.com/).

## Features
&gt; - **Date**: The specific date on which the stock price was recorded.
&gt; - **Open**: The opening price of the company's stock on that particular day.
&gt; - **High**: The highest trading price of the company's stock on that day.
&gt; - **Low**: The lowest trading price of the company's stock on that day.
&gt; - **Close**: The closing price of the company's stock on that day.
&gt; - **Adj Close**: The adjusted closing price of the company's stock on that day.
&gt; - **Volume**: The total number of shares traded on that day.

## Use cases
&gt; This dataset can be utilized for a wide range of applications, including but not limited to:
- **Market Analysis**: Conduct comprehensive market studies, analyze trends, and spot seasonal patterns.
- **Investment Strategies**: Develop and backtest investment strategies based on historical price movements.
- **Forecasting**: Build predictive models to forecast future stock prices and make informed decisions.
- **Trading Algorithms**: Design and test trading algorithms to capitalize on market opportunities.

Please, provide an upvote👍if the dataset was useful for your task. It would be much appreciated😄",.csv,True
MAANG companies Stock prices (updated daily),15,netflix-stock-price,GOOGLE_daily.csv,CC0-1.0,"## Description
&gt; This dataset contains the full historical data of the stock prices for **MAANG** companies since their Initial Public Offering (IPO). **MAANG** is an acronym that stands for ***Meta, Amazon, Apple, Netflix, and Google***. The dataset contains daily, weekly, and monthly stock prices for each company and is automatically updated daily with the latest data obtained from [Yahoo Finance](https://finance.yahoo.com/).

## Features
&gt; - **Date**: The specific date on which the stock price was recorded.
&gt; - **Open**: The opening price of the company's stock on that particular day.
&gt; - **High**: The highest trading price of the company's stock on that day.
&gt; - **Low**: The lowest trading price of the company's stock on that day.
&gt; - **Close**: The closing price of the company's stock on that day.
&gt; - **Adj Close**: The adjusted closing price of the company's stock on that day.
&gt; - **Volume**: The total number of shares traded on that day.

## Use cases
&gt; This dataset can be utilized for a wide range of applications, including but not limited to:
- **Market Analysis**: Conduct comprehensive market studies, analyze trends, and spot seasonal patterns.
- **Investment Strategies**: Develop and backtest investment strategies based on historical price movements.
- **Forecasting**: Build predictive models to forecast future stock prices and make informed decisions.
- **Trading Algorithms**: Design and test trading algorithms to capitalize on market opportunities.

Please, provide an upvote👍if the dataset was useful for your task. It would be much appreciated😄",.csv,True
MAANG companies Stock prices (updated daily),15,netflix-stock-price,META_daily.csv,CC0-1.0,"## Description
&gt; This dataset contains the full historical data of the stock prices for **MAANG** companies since their Initial Public Offering (IPO). **MAANG** is an acronym that stands for ***Meta, Amazon, Apple, Netflix, and Google***. The dataset contains daily, weekly, and monthly stock prices for each company and is automatically updated daily with the latest data obtained from [Yahoo Finance](https://finance.yahoo.com/).

## Features
&gt; - **Date**: The specific date on which the stock price was recorded.
&gt; - **Open**: The opening price of the company's stock on that particular day.
&gt; - **High**: The highest trading price of the company's stock on that day.
&gt; - **Low**: The lowest trading price of the company's stock on that day.
&gt; - **Close**: The closing price of the company's stock on that day.
&gt; - **Adj Close**: The adjusted closing price of the company's stock on that day.
&gt; - **Volume**: The total number of shares traded on that day.

## Use cases
&gt; This dataset can be utilized for a wide range of applications, including but not limited to:
- **Market Analysis**: Conduct comprehensive market studies, analyze trends, and spot seasonal patterns.
- **Investment Strategies**: Develop and backtest investment strategies based on historical price movements.
- **Forecasting**: Build predictive models to forecast future stock prices and make informed decisions.
- **Trading Algorithms**: Design and test trading algorithms to capitalize on market opportunities.

Please, provide an upvote👍if the dataset was useful for your task. It would be much appreciated😄",.csv,True
MAANG companies Stock prices (updated daily),15,netflix-stock-price,META_weekly.csv,CC0-1.0,"## Description
&gt; This dataset contains the full historical data of the stock prices for **MAANG** companies since their Initial Public Offering (IPO). **MAANG** is an acronym that stands for ***Meta, Amazon, Apple, Netflix, and Google***. The dataset contains daily, weekly, and monthly stock prices for each company and is automatically updated daily with the latest data obtained from [Yahoo Finance](https://finance.yahoo.com/).

## Features
&gt; - **Date**: The specific date on which the stock price was recorded.
&gt; - **Open**: The opening price of the company's stock on that particular day.
&gt; - **High**: The highest trading price of the company's stock on that day.
&gt; - **Low**: The lowest trading price of the company's stock on that day.
&gt; - **Close**: The closing price of the company's stock on that day.
&gt; - **Adj Close**: The adjusted closing price of the company's stock on that day.
&gt; - **Volume**: The total number of shares traded on that day.

## Use cases
&gt; This dataset can be utilized for a wide range of applications, including but not limited to:
- **Market Analysis**: Conduct comprehensive market studies, analyze trends, and spot seasonal patterns.
- **Investment Strategies**: Develop and backtest investment strategies based on historical price movements.
- **Forecasting**: Build predictive models to forecast future stock prices and make informed decisions.
- **Trading Algorithms**: Design and test trading algorithms to capitalize on market opportunities.

Please, provide an upvote👍if the dataset was useful for your task. It would be much appreciated😄",.csv,True
MAANG companies Stock prices (updated daily),15,netflix-stock-price,APPLE_weekly.csv,CC0-1.0,"## Description
&gt; This dataset contains the full historical data of the stock prices for **MAANG** companies since their Initial Public Offering (IPO). **MAANG** is an acronym that stands for ***Meta, Amazon, Apple, Netflix, and Google***. The dataset contains daily, weekly, and monthly stock prices for each company and is automatically updated daily with the latest data obtained from [Yahoo Finance](https://finance.yahoo.com/).

## Features
&gt; - **Date**: The specific date on which the stock price was recorded.
&gt; - **Open**: The opening price of the company's stock on that particular day.
&gt; - **High**: The highest trading price of the company's stock on that day.
&gt; - **Low**: The lowest trading price of the company's stock on that day.
&gt; - **Close**: The closing price of the company's stock on that day.
&gt; - **Adj Close**: The adjusted closing price of the company's stock on that day.
&gt; - **Volume**: The total number of shares traded on that day.

## Use cases
&gt; This dataset can be utilized for a wide range of applications, including but not limited to:
- **Market Analysis**: Conduct comprehensive market studies, analyze trends, and spot seasonal patterns.
- **Investment Strategies**: Develop and backtest investment strategies based on historical price movements.
- **Forecasting**: Build predictive models to forecast future stock prices and make informed decisions.
- **Trading Algorithms**: Design and test trading algorithms to capitalize on market opportunities.

Please, provide an upvote👍if the dataset was useful for your task. It would be much appreciated😄",.csv,True
MAANG companies Stock prices (updated daily),15,netflix-stock-price,APPLE_daily.csv,CC0-1.0,"## Description
&gt; This dataset contains the full historical data of the stock prices for **MAANG** companies since their Initial Public Offering (IPO). **MAANG** is an acronym that stands for ***Meta, Amazon, Apple, Netflix, and Google***. The dataset contains daily, weekly, and monthly stock prices for each company and is automatically updated daily with the latest data obtained from [Yahoo Finance](https://finance.yahoo.com/).

## Features
&gt; - **Date**: The specific date on which the stock price was recorded.
&gt; - **Open**: The opening price of the company's stock on that particular day.
&gt; - **High**: The highest trading price of the company's stock on that day.
&gt; - **Low**: The lowest trading price of the company's stock on that day.
&gt; - **Close**: The closing price of the company's stock on that day.
&gt; - **Adj Close**: The adjusted closing price of the company's stock on that day.
&gt; - **Volume**: The total number of shares traded on that day.

## Use cases
&gt; This dataset can be utilized for a wide range of applications, including but not limited to:
- **Market Analysis**: Conduct comprehensive market studies, analyze trends, and spot seasonal patterns.
- **Investment Strategies**: Develop and backtest investment strategies based on historical price movements.
- **Forecasting**: Build predictive models to forecast future stock prices and make informed decisions.
- **Trading Algorithms**: Design and test trading algorithms to capitalize on market opportunities.

Please, provide an upvote👍if the dataset was useful for your task. It would be much appreciated😄",.csv,True
MAANG companies Stock prices (updated daily),15,netflix-stock-price,AMAZON_monthly.csv,CC0-1.0,"## Description
&gt; This dataset contains the full historical data of the stock prices for **MAANG** companies since their Initial Public Offering (IPO). **MAANG** is an acronym that stands for ***Meta, Amazon, Apple, Netflix, and Google***. The dataset contains daily, weekly, and monthly stock prices for each company and is automatically updated daily with the latest data obtained from [Yahoo Finance](https://finance.yahoo.com/).

## Features
&gt; - **Date**: The specific date on which the stock price was recorded.
&gt; - **Open**: The opening price of the company's stock on that particular day.
&gt; - **High**: The highest trading price of the company's stock on that day.
&gt; - **Low**: The lowest trading price of the company's stock on that day.
&gt; - **Close**: The closing price of the company's stock on that day.
&gt; - **Adj Close**: The adjusted closing price of the company's stock on that day.
&gt; - **Volume**: The total number of shares traded on that day.

## Use cases
&gt; This dataset can be utilized for a wide range of applications, including but not limited to:
- **Market Analysis**: Conduct comprehensive market studies, analyze trends, and spot seasonal patterns.
- **Investment Strategies**: Develop and backtest investment strategies based on historical price movements.
- **Forecasting**: Build predictive models to forecast future stock prices and make informed decisions.
- **Trading Algorithms**: Design and test trading algorithms to capitalize on market opportunities.

Please, provide an upvote👍if the dataset was useful for your task. It would be much appreciated😄",.csv,True
MAANG companies Stock prices (updated daily),15,netflix-stock-price,NETFLIX_daily.csv,CC0-1.0,"## Description
&gt; This dataset contains the full historical data of the stock prices for **MAANG** companies since their Initial Public Offering (IPO). **MAANG** is an acronym that stands for ***Meta, Amazon, Apple, Netflix, and Google***. The dataset contains daily, weekly, and monthly stock prices for each company and is automatically updated daily with the latest data obtained from [Yahoo Finance](https://finance.yahoo.com/).

## Features
&gt; - **Date**: The specific date on which the stock price was recorded.
&gt; - **Open**: The opening price of the company's stock on that particular day.
&gt; - **High**: The highest trading price of the company's stock on that day.
&gt; - **Low**: The lowest trading price of the company's stock on that day.
&gt; - **Close**: The closing price of the company's stock on that day.
&gt; - **Adj Close**: The adjusted closing price of the company's stock on that day.
&gt; - **Volume**: The total number of shares traded on that day.

## Use cases
&gt; This dataset can be utilized for a wide range of applications, including but not limited to:
- **Market Analysis**: Conduct comprehensive market studies, analyze trends, and spot seasonal patterns.
- **Investment Strategies**: Develop and backtest investment strategies based on historical price movements.
- **Forecasting**: Build predictive models to forecast future stock prices and make informed decisions.
- **Trading Algorithms**: Design and test trading algorithms to capitalize on market opportunities.

Please, provide an upvote👍if the dataset was useful for your task. It would be much appreciated😄",.csv,True
McDonald's Nutrition,2,mcdonalds-nutrition,McDonaldsMenuNutritionV3.csv,DbCL-1.0,"All items on the McDonald's menu as of 2021, including Calories, Calories from Fat, Total Fat, Saturated Fat, Trans Fat, Cholesterol, Sodium, Carbs, Fiber, Sugars, Protein, and Weight Watchers Points.",.csv,True
McDonald's Nutrition,2,mcdonalds-nutrition,McDonaldsMenuNutritionV2.csv,DbCL-1.0,"All items on the McDonald's menu as of 2021, including Calories, Calories from Fat, Total Fat, Saturated Fat, Trans Fat, Cholesterol, Sodium, Carbs, Fiber, Sugars, Protein, and Weight Watchers Points.",.csv,True
Menstrual Health Awareness Dataset,2,menstrual-health-awareness-dataset,Training Data.csv,MIT,"# Menstrual Health Awareness dataset 

## Context
This dataset has been designed to support the training and fine-tuning of large language models (LLMs) in the context of menstruation-related topics. Its aim is to improve the capacity of LLMs to understand and generate accurate information about menstrual health, hygiene, and associated social issues.



## Dataset Composition  
The dataset comprises two CSV files:
- **Training Data.csv:** Contains 517 question-and-answer pairs related to menstruation.
- **Testing Data.csv:** Contains 45 question-and-answer pairs for model validation and testing.

## Data Content: 
Both CSV files contain a variety of questions and answers focusing on:
- Menstrual health and hygiene practices
- Common menstrual disorders and their management
- Breaking taboos and challenging stigmas associated with menstruation
- Nutritional considerations for menstrual health
- General awareness and education about menstrual cycles
- and more

## Usage and Applications
This dataset is suitable for:
- Fine-tuning LLMs to better understand menstruation-related topics
- Training models that aim to answer questions about menstrual health
- Enhancing AI systems designed to spread awareness and challenge societal taboos regarding menstruation
- Promoting public education and health literacy through AI-driven applications


## Inspiration
This small dataset has been used previously to fine-tune Google's Flan T5 Base model on Hugging Face. The content was curated to fill a gap in publicly available data for fine-tuning LLMs on menstrual health topics, providing a foundational resource for developers and researchers aiming to improve the accuracy and relevance of AI responses in this domain.


## Additional Information 
This dataset is publicly available for research and development purposes. Users are encouraged to explore its potential to advance the effectiveness and sensitivity of AI in addressing menstrual health and related issues.




",.csv,True
Menstrual Health Awareness Dataset,2,menstrual-health-awareness-dataset,Testing Data.csv,MIT,"# Menstrual Health Awareness dataset 

## Context
This dataset has been designed to support the training and fine-tuning of large language models (LLMs) in the context of menstruation-related topics. Its aim is to improve the capacity of LLMs to understand and generate accurate information about menstrual health, hygiene, and associated social issues.



## Dataset Composition  
The dataset comprises two CSV files:
- **Training Data.csv:** Contains 517 question-and-answer pairs related to menstruation.
- **Testing Data.csv:** Contains 45 question-and-answer pairs for model validation and testing.

## Data Content: 
Both CSV files contain a variety of questions and answers focusing on:
- Menstrual health and hygiene practices
- Common menstrual disorders and their management
- Breaking taboos and challenging stigmas associated with menstruation
- Nutritional considerations for menstrual health
- General awareness and education about menstrual cycles
- and more

## Usage and Applications
This dataset is suitable for:
- Fine-tuning LLMs to better understand menstruation-related topics
- Training models that aim to answer questions about menstrual health
- Enhancing AI systems designed to spread awareness and challenge societal taboos regarding menstruation
- Promoting public education and health literacy through AI-driven applications


## Inspiration
This small dataset has been used previously to fine-tune Google's Flan T5 Base model on Hugging Face. The content was curated to fill a gap in publicly available data for fine-tuning LLMs on menstrual health topics, providing a foundational resource for developers and researchers aiming to improve the accuracy and relevance of AI responses in this domain.


## Additional Information 
This dataset is publicly available for research and development purposes. Users are encouraged to explore its potential to advance the effectiveness and sensitivity of AI in addressing menstrual health and related issues.




",.csv,True
Metal/Rock Dataset,3,metalrock-dataset,metal_archive_pt1.csv,CC0-1.0,"My personal Rock/Metal Spotify playlists, the features include instrumental as well as non-instrumental data like Duration, Loudness, Mode, Speechiness, Acousticness, Instrumentalness, Liveness, Valence, Tempo. The data is extracted using Exportify service.",.csv,True
Metal/Rock Dataset,3,metalrock-dataset,metal_archive_pt2.csv,CC0-1.0,"My personal Rock/Metal Spotify playlists, the features include instrumental as well as non-instrumental data like Duration, Loudness, Mode, Speechiness, Acousticness, Instrumentalness, Liveness, Valence, Tempo. The data is extracted using Exportify service.",.csv,True
Metal/Rock Dataset,3,metalrock-dataset,mostly_rock.csv,CC0-1.0,"My personal Rock/Metal Spotify playlists, the features include instrumental as well as non-instrumental data like Duration, Loudness, Mode, Speechiness, Acousticness, Instrumentalness, Liveness, Valence, Tempo. The data is extracted using Exportify service.",.csv,True
Monthly Gold Prices (1979-2021),2,monthly-gold-prices,1979-2021.csv,other,"## Context

The database contains historic gold prices of 18 different countries in their respective currencies 


## Content

Monthly gold prices of 18 different countries starting from January 1979. Expected to be updated quarterly.
Attribute Information:

```
1. Date - Date of Observation 
2. United States(USD)
3. Europe(EUR)
4. Japan(JPY)
5. United Kingdom(GBP)
6. Canada(CAD)
7. Switzerland(CHF)
8. India(INR)
9. China(CNY)
10. Turkey(TRY)
11. Saudi Arabia(SAR)
12. Indonesia(IDR)
13. United Arab Emirates(AED)
14. Thailand(THB)
15. Vietnam(VND)
16. Egypt(EGP)
17. South Korean(KRW)
18. Australia(AUD)
19. South Africa(ZAR)
```

## Acknowledgements
https://www.gold.org/goldhub/data/gold-prices
",.csv,True
Monthly Gold Prices (1979-2021),2,monthly-gold-prices,1990-2021.csv,other,"## Context

The database contains historic gold prices of 18 different countries in their respective currencies 


## Content

Monthly gold prices of 18 different countries starting from January 1979. Expected to be updated quarterly.
Attribute Information:

```
1. Date - Date of Observation 
2. United States(USD)
3. Europe(EUR)
4. Japan(JPY)
5. United Kingdom(GBP)
6. Canada(CAD)
7. Switzerland(CHF)
8. India(INR)
9. China(CNY)
10. Turkey(TRY)
11. Saudi Arabia(SAR)
12. Indonesia(IDR)
13. United Arab Emirates(AED)
14. Thailand(THB)
15. Vietnam(VND)
16. Egypt(EGP)
17. South Korean(KRW)
18. Australia(AUD)
19. South Africa(ZAR)
```

## Acknowledgements
https://www.gold.org/goldhub/data/gold-prices
",.csv,True
Multiple Disease Prediction,2,multiple-disease-prediction,Blood_samples_dataset_balanced_2(f).csv,Apache 2.0,"A dataset to check the health, whether the person has a specific disease or he is well, based on blood samples or parameters, the data is hand madden, you can use it just for learning, i searched about the percentage of each parameter and what will happen if this parameter high or low, and which disease you might have if this parameter high or low, based on all this information and searches i created this dataset just for learning and a project idea purpose
Also, the data is already scaled in range(0,1)
## this is the percentage of each parameter:
    ""Glucose"": (70, 140),  # mg/dL
    ""Cholesterol"": (125, 200),  # mg/dL
    ""Hemoglobin"": (13.5, 17.5),  # g/dL
    ""Platelets"": (150000, 450000),  # per microliter of blood
    ""White Blood Cells"": (4000, 11000),  # per cubic millimeter of blood
    ""Red Blood Cells"": (4.2, 5.4),  # million cells per microliter of blood
    ""Hematocrit"": (38, 52),  # percentage
    ""Mean Corpuscular Volume"": (80, 100),  # femtoliters
    ""Mean Corpuscular Hemoglobin"": (27, 33),  # picograms
    ""Mean Corpuscular Hemoglobin Concentration"": (32, 36),  # grams per deciliter
    ""Insulin"": (5, 25),  # microU/mL
    ""BMI"": (18.5, 24.9),  # kg/m^2
    ""Systolic Blood Pressure"": (90, 120),  # mmHg
    ""Diastolic Blood Pressure"": (60, 80),  # mmHg
    ""Triglycerides"": (50, 150),  # mg/dL
    ""HbA1c"": (4, 6),  # percentage
    ""LDL Cholesterol"": (70, 130),  # mg/dL
    ""HDL Cholesterol"": (40, 60),  # mg/dL
    ""ALT"": (10, 40),  # U/L
    ""AST"": (10, 40),  # U/L
    ""Heart Rate"": (60, 100),  # beats per minute
    ""Creatinine"": (0.6, 1.2),  # mg/dL
    ""Troponin"": (0, 0.04),  # ng/mL
    ""C-reactive Protein"": (0, 3),  # mg/L",.csv,True
Multiple Disease Prediction,2,multiple-disease-prediction,blood_samples_dataset_test.csv,Apache 2.0,"A dataset to check the health, whether the person has a specific disease or he is well, based on blood samples or parameters, the data is hand madden, you can use it just for learning, i searched about the percentage of each parameter and what will happen if this parameter high or low, and which disease you might have if this parameter high or low, based on all this information and searches i created this dataset just for learning and a project idea purpose
Also, the data is already scaled in range(0,1)
## this is the percentage of each parameter:
    ""Glucose"": (70, 140),  # mg/dL
    ""Cholesterol"": (125, 200),  # mg/dL
    ""Hemoglobin"": (13.5, 17.5),  # g/dL
    ""Platelets"": (150000, 450000),  # per microliter of blood
    ""White Blood Cells"": (4000, 11000),  # per cubic millimeter of blood
    ""Red Blood Cells"": (4.2, 5.4),  # million cells per microliter of blood
    ""Hematocrit"": (38, 52),  # percentage
    ""Mean Corpuscular Volume"": (80, 100),  # femtoliters
    ""Mean Corpuscular Hemoglobin"": (27, 33),  # picograms
    ""Mean Corpuscular Hemoglobin Concentration"": (32, 36),  # grams per deciliter
    ""Insulin"": (5, 25),  # microU/mL
    ""BMI"": (18.5, 24.9),  # kg/m^2
    ""Systolic Blood Pressure"": (90, 120),  # mmHg
    ""Diastolic Blood Pressure"": (60, 80),  # mmHg
    ""Triglycerides"": (50, 150),  # mg/dL
    ""HbA1c"": (4, 6),  # percentage
    ""LDL Cholesterol"": (70, 130),  # mg/dL
    ""HDL Cholesterol"": (40, 60),  # mg/dL
    ""ALT"": (10, 40),  # U/L
    ""AST"": (10, 40),  # U/L
    ""Heart Rate"": (60, 100),  # beats per minute
    ""Creatinine"": (0.6, 1.2),  # mg/dL
    ""Troponin"": (0, 0.04),  # ng/mL
    ""C-reactive Protein"": (0, 3),  # mg/L",.csv,True
Music features,2,musicfeatures,data.csv,CC0-1.0,"### Context

A music genre is a conventional category that identifies pieces of music as belonging to a shared tradition or set of conventions. It is to be distinguished from musical form and musical style. The features extracted from these waves can help the machine distinguish between them. 


### Content
The features in this dataset are extracted from the dataset provided [here][1] which consists of 1000 audio tracks each 30 seconds long. It contains 10 genres, each represented by 100 tracks. The tracks are all 22050Hz Mono 16-bit audio files in .wav format. The code used to extract features is at [this][2] GitHub repo. Features are extracted using [libROSA][3] library. 


### Acknowledgements

The credits to this dataset go to [MARSYAS][4].


### Inspiration

Due to the artistic nature of music, the classifications are often arbitrary and controversial, and some genres may overlap. Train a model and know to which genre your favourite piece of music belong to.


  [1]: http://marsyas.info
  [2]: https://github.com/Insiyaa/Music-Tagging
  [3]: https://librosa.github.io/librosa/
  [4]: http://marsyas.info",.csv,True
Music features,2,musicfeatures,data_2genre.csv,CC0-1.0,"### Context

A music genre is a conventional category that identifies pieces of music as belonging to a shared tradition or set of conventions. It is to be distinguished from musical form and musical style. The features extracted from these waves can help the machine distinguish between them. 


### Content
The features in this dataset are extracted from the dataset provided [here][1] which consists of 1000 audio tracks each 30 seconds long. It contains 10 genres, each represented by 100 tracks. The tracks are all 22050Hz Mono 16-bit audio files in .wav format. The code used to extract features is at [this][2] GitHub repo. Features are extracted using [libROSA][3] library. 


### Acknowledgements

The credits to this dataset go to [MARSYAS][4].


### Inspiration

Due to the artistic nature of music, the classifications are often arbitrary and controversial, and some genres may overlap. Train a model and know to which genre your favourite piece of music belong to.


  [1]: http://marsyas.info
  [2]: https://github.com/Insiyaa/Music-Tagging
  [3]: https://librosa.github.io/librosa/
  [4]: http://marsyas.info",.csv,True
NBA Play-by-Play Data (1997-2023),27,nba-play-by-play-data-1997-2023,pbp2020.csv,CC-BY-NC-SA-4.0,"Play-by-play data scraped from NBA.com from the last 27 seasons including: 
- 16,215,625 in game events
- 33,800 games
- 5,585,654 shots

I'll update this dataset with data from 2023-24 season when it ends.",.csv,True
NBA Play-by-Play Data (1997-2023),27,nba-play-by-play-data-1997-2023,pbp2008.csv,CC-BY-NC-SA-4.0,"Play-by-play data scraped from NBA.com from the last 27 seasons including: 
- 16,215,625 in game events
- 33,800 games
- 5,585,654 shots

I'll update this dataset with data from 2023-24 season when it ends.",.csv,True
NBA Play-by-Play Data (1997-2023),27,nba-play-by-play-data-1997-2023,pbp2009.csv,CC-BY-NC-SA-4.0,"Play-by-play data scraped from NBA.com from the last 27 seasons including: 
- 16,215,625 in game events
- 33,800 games
- 5,585,654 shots

I'll update this dataset with data from 2023-24 season when it ends.",.csv,True
NBA Play-by-Play Data (1997-2023),27,nba-play-by-play-data-1997-2023,pbp2021.csv,CC-BY-NC-SA-4.0,"Play-by-play data scraped from NBA.com from the last 27 seasons including: 
- 16,215,625 in game events
- 33,800 games
- 5,585,654 shots

I'll update this dataset with data from 2023-24 season when it ends.",.csv,True
NBA Play-by-Play Data (1997-2023),27,nba-play-by-play-data-1997-2023,pbp2023.csv,CC-BY-NC-SA-4.0,"Play-by-play data scraped from NBA.com from the last 27 seasons including: 
- 16,215,625 in game events
- 33,800 games
- 5,585,654 shots

I'll update this dataset with data from 2023-24 season when it ends.",.csv,True
NBA Play-by-Play Data (1997-2023),27,nba-play-by-play-data-1997-2023,pbp2022.csv,CC-BY-NC-SA-4.0,"Play-by-play data scraped from NBA.com from the last 27 seasons including: 
- 16,215,625 in game events
- 33,800 games
- 5,585,654 shots

I'll update this dataset with data from 2023-24 season when it ends.",.csv,True
NBA Play-by-Play Data (1997-2023),27,nba-play-by-play-data-1997-2023,pbp2019.csv,CC-BY-NC-SA-4.0,"Play-by-play data scraped from NBA.com from the last 27 seasons including: 
- 16,215,625 in game events
- 33,800 games
- 5,585,654 shots

I'll update this dataset with data from 2023-24 season when it ends.",.csv,True
NBA Play-by-Play Data (1997-2023),27,nba-play-by-play-data-1997-2023,pbp2018.csv,CC-BY-NC-SA-4.0,"Play-by-play data scraped from NBA.com from the last 27 seasons including: 
- 16,215,625 in game events
- 33,800 games
- 5,585,654 shots

I'll update this dataset with data from 2023-24 season when it ends.",.csv,True
NBA Play-by-Play Data (1997-2023),27,nba-play-by-play-data-1997-2023,pbp1997.csv,CC-BY-NC-SA-4.0,"Play-by-play data scraped from NBA.com from the last 27 seasons including: 
- 16,215,625 in game events
- 33,800 games
- 5,585,654 shots

I'll update this dataset with data from 2023-24 season when it ends.",.csv,True
NBA Play-by-Play Data (1997-2023),27,nba-play-by-play-data-1997-2023,pbp1999.csv,CC-BY-NC-SA-4.0,"Play-by-play data scraped from NBA.com from the last 27 seasons including: 
- 16,215,625 in game events
- 33,800 games
- 5,585,654 shots

I'll update this dataset with data from 2023-24 season when it ends.",.csv,True
NBA Play-by-Play Data (1997-2023),27,nba-play-by-play-data-1997-2023,pbp1998.csv,CC-BY-NC-SA-4.0,"Play-by-play data scraped from NBA.com from the last 27 seasons including: 
- 16,215,625 in game events
- 33,800 games
- 5,585,654 shots

I'll update this dataset with data from 2023-24 season when it ends.",.csv,True
NBA Play-by-Play Data (1997-2023),27,nba-play-by-play-data-1997-2023,pbp2001.csv,CC-BY-NC-SA-4.0,"Play-by-play data scraped from NBA.com from the last 27 seasons including: 
- 16,215,625 in game events
- 33,800 games
- 5,585,654 shots

I'll update this dataset with data from 2023-24 season when it ends.",.csv,True
NBA Play-by-Play Data (1997-2023),27,nba-play-by-play-data-1997-2023,pbp2015.csv,CC-BY-NC-SA-4.0,"Play-by-play data scraped from NBA.com from the last 27 seasons including: 
- 16,215,625 in game events
- 33,800 games
- 5,585,654 shots

I'll update this dataset with data from 2023-24 season when it ends.",.csv,True
NBA Play-by-Play Data (1997-2023),27,nba-play-by-play-data-1997-2023,pbp2014.csv,CC-BY-NC-SA-4.0,"Play-by-play data scraped from NBA.com from the last 27 seasons including: 
- 16,215,625 in game events
- 33,800 games
- 5,585,654 shots

I'll update this dataset with data from 2023-24 season when it ends.",.csv,True
NBA Play-by-Play Data (1997-2023),27,nba-play-by-play-data-1997-2023,pbp2000.csv,CC-BY-NC-SA-4.0,"Play-by-play data scraped from NBA.com from the last 27 seasons including: 
- 16,215,625 in game events
- 33,800 games
- 5,585,654 shots

I'll update this dataset with data from 2023-24 season when it ends.",.csv,True
NBA Play-by-Play Data (1997-2023),27,nba-play-by-play-data-1997-2023,pbp2016.csv,CC-BY-NC-SA-4.0,"Play-by-play data scraped from NBA.com from the last 27 seasons including: 
- 16,215,625 in game events
- 33,800 games
- 5,585,654 shots

I'll update this dataset with data from 2023-24 season when it ends.",.csv,True
NBA Play-by-Play Data (1997-2023),27,nba-play-by-play-data-1997-2023,pbp2002.csv,CC-BY-NC-SA-4.0,"Play-by-play data scraped from NBA.com from the last 27 seasons including: 
- 16,215,625 in game events
- 33,800 games
- 5,585,654 shots

I'll update this dataset with data from 2023-24 season when it ends.",.csv,True
NBA Play-by-Play Data (1997-2023),27,nba-play-by-play-data-1997-2023,pbp2003.csv,CC-BY-NC-SA-4.0,"Play-by-play data scraped from NBA.com from the last 27 seasons including: 
- 16,215,625 in game events
- 33,800 games
- 5,585,654 shots

I'll update this dataset with data from 2023-24 season when it ends.",.csv,True
NBA Play-by-Play Data (1997-2023),27,nba-play-by-play-data-1997-2023,pbp2017.csv,CC-BY-NC-SA-4.0,"Play-by-play data scraped from NBA.com from the last 27 seasons including: 
- 16,215,625 in game events
- 33,800 games
- 5,585,654 shots

I'll update this dataset with data from 2023-24 season when it ends.",.csv,True
NBA Play-by-Play Data (1997-2023),27,nba-play-by-play-data-1997-2023,pbp2013.csv,CC-BY-NC-SA-4.0,"Play-by-play data scraped from NBA.com from the last 27 seasons including: 
- 16,215,625 in game events
- 33,800 games
- 5,585,654 shots

I'll update this dataset with data from 2023-24 season when it ends.",.csv,True
NBA Play-by-Play Data (1997-2023),27,nba-play-by-play-data-1997-2023,pbp2007.csv,CC-BY-NC-SA-4.0,"Play-by-play data scraped from NBA.com from the last 27 seasons including: 
- 16,215,625 in game events
- 33,800 games
- 5,585,654 shots

I'll update this dataset with data from 2023-24 season when it ends.",.csv,True
NBA Play-by-Play Data (1997-2023),27,nba-play-by-play-data-1997-2023,pbp2006.csv,CC-BY-NC-SA-4.0,"Play-by-play data scraped from NBA.com from the last 27 seasons including: 
- 16,215,625 in game events
- 33,800 games
- 5,585,654 shots

I'll update this dataset with data from 2023-24 season when it ends.",.csv,True
NBA Play-by-Play Data (1997-2023),27,nba-play-by-play-data-1997-2023,pbp2012.csv,CC-BY-NC-SA-4.0,"Play-by-play data scraped from NBA.com from the last 27 seasons including: 
- 16,215,625 in game events
- 33,800 games
- 5,585,654 shots

I'll update this dataset with data from 2023-24 season when it ends.",.csv,True
NBA Play-by-Play Data (1997-2023),27,nba-play-by-play-data-1997-2023,pbp2004.csv,CC-BY-NC-SA-4.0,"Play-by-play data scraped from NBA.com from the last 27 seasons including: 
- 16,215,625 in game events
- 33,800 games
- 5,585,654 shots

I'll update this dataset with data from 2023-24 season when it ends.",.csv,True
NBA Play-by-Play Data (1997-2023),27,nba-play-by-play-data-1997-2023,pbp2010.csv,CC-BY-NC-SA-4.0,"Play-by-play data scraped from NBA.com from the last 27 seasons including: 
- 16,215,625 in game events
- 33,800 games
- 5,585,654 shots

I'll update this dataset with data from 2023-24 season when it ends.",.csv,True
NBA Play-by-Play Data (1997-2023),27,nba-play-by-play-data-1997-2023,pbp2011.csv,CC-BY-NC-SA-4.0,"Play-by-play data scraped from NBA.com from the last 27 seasons including: 
- 16,215,625 in game events
- 33,800 games
- 5,585,654 shots

I'll update this dataset with data from 2023-24 season when it ends.",.csv,True
NBA Play-by-Play Data (1997-2023),27,nba-play-by-play-data-1997-2023,pbp2005.csv,CC-BY-NC-SA-4.0,"Play-by-play data scraped from NBA.com from the last 27 seasons including: 
- 16,215,625 in game events
- 33,800 games
- 5,585,654 shots

I'll update this dataset with data from 2023-24 season when it ends.",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202207_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202206_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_201904_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_201905_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202305_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202304_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_201806_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_201807_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202109_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202108_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202001_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_201912_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202210_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202211_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202103_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202102_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_201811_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_201810_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202006_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202007_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202104_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202105_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202011_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202010_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_201903_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_201902_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202201_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202112_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_201801_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202302_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202303_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_201909_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_201908_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202008_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202009_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202101_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_201812_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202002_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202003_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_201910_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_201911_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202212_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202306_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_201805_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_201804_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202204_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202205_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_201907_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_201906_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202110_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202111_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_201802_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_201803_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202209_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202208_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202301_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202012_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_201901_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202203_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202202_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_201808_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_201809_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202107_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202106_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202005_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
"NSW, AUS, Electricity Price & Demand 2018-2023",66,nsw-australia-electricity-demand-2018-2023,PRICE_AND_DEMAND_202004_NSW1.csv,other,"This data was downloaded from the [Australian Energy Market Operator (AEMO)](https://aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data), and contains 30 minute increments of electricity demand and price in NSW, Australia, from 2018 to mid 2023. This data was made publicly available by AEMO, as per their [Copyright Permission](https://aemo.com.au/privacy-and-legal-notices/copyright-permissions).",.csv,True
Nifty Strategy Indices Dataset,11,nifty-strategy-indices-dataset,NIFTY MIDCAP150 QUALITY 50_Historical_PR_01012000to01012024.csv,MIT,"# Context
The National Stock Exchange of India Limited (NSE) is the leading stock exchange of India. Nifty indices are a group of stock market indexes that track the performance of various segments of the Indian stock market. Strategy indices are designed on the basis of quantitative models / investment strategies to provide a single value for the aggregate performance of a number of companies.

# Content
The Dataset has the day level information from 1 January 2000 to 1 January 2024.

Dataset contains-
- Date - date of observation
- Open - open value of the index on that day
- High - highest value of the index on that day
- Low - lowest value of the index on that day
- Close - closing value of the index on that day",.csv,True
Nifty Strategy Indices Dataset,11,nifty-strategy-indices-dataset,NIFTY200 MOMENTUM 30_Historical_PR_01012000to01012024.csv,MIT,"# Context
The National Stock Exchange of India Limited (NSE) is the leading stock exchange of India. Nifty indices are a group of stock market indexes that track the performance of various segments of the Indian stock market. Strategy indices are designed on the basis of quantitative models / investment strategies to provide a single value for the aggregate performance of a number of companies.

# Content
The Dataset has the day level information from 1 January 2000 to 1 January 2024.

Dataset contains-
- Date - date of observation
- Open - open value of the index on that day
- High - highest value of the index on that day
- Low - lowest value of the index on that day
- Close - closing value of the index on that day",.csv,True
Nifty Strategy Indices Dataset,11,nifty-strategy-indices-dataset,NIFTY50 VALUE 20_Historical_PR_01012000to01012024.csv,MIT,"# Context
The National Stock Exchange of India Limited (NSE) is the leading stock exchange of India. Nifty indices are a group of stock market indexes that track the performance of various segments of the Indian stock market. Strategy indices are designed on the basis of quantitative models / investment strategies to provide a single value for the aggregate performance of a number of companies.

# Content
The Dataset has the day level information from 1 January 2000 to 1 January 2024.

Dataset contains-
- Date - date of observation
- Open - open value of the index on that day
- High - highest value of the index on that day
- Low - lowest value of the index on that day
- Close - closing value of the index on that day",.csv,True
Nifty Strategy Indices Dataset,11,nifty-strategy-indices-dataset,NIFTY50 EQUAL WEIGHT_Historical_PR_01012000to01012024.csv,MIT,"# Context
The National Stock Exchange of India Limited (NSE) is the leading stock exchange of India. Nifty indices are a group of stock market indexes that track the performance of various segments of the Indian stock market. Strategy indices are designed on the basis of quantitative models / investment strategies to provide a single value for the aggregate performance of a number of companies.

# Content
The Dataset has the day level information from 1 January 2000 to 1 January 2024.

Dataset contains-
- Date - date of observation
- Open - open value of the index on that day
- High - highest value of the index on that day
- Low - lowest value of the index on that day
- Close - closing value of the index on that day",.csv,True
Nifty Strategy Indices Dataset,11,nifty-strategy-indices-dataset,NIFTY SMALLCAP250 QUALITY 50_Historical_PR_01012000to01012024.csv,MIT,"# Context
The National Stock Exchange of India Limited (NSE) is the leading stock exchange of India. Nifty indices are a group of stock market indexes that track the performance of various segments of the Indian stock market. Strategy indices are designed on the basis of quantitative models / investment strategies to provide a single value for the aggregate performance of a number of companies.

# Content
The Dataset has the day level information from 1 January 2000 to 1 January 2024.

Dataset contains-
- Date - date of observation
- Open - open value of the index on that day
- High - highest value of the index on that day
- Low - lowest value of the index on that day
- Close - closing value of the index on that day",.csv,True
Nifty Strategy Indices Dataset,11,nifty-strategy-indices-dataset,NIFTY100 EQUAL WEIGHT_Historical_PR_01012000to01012024.csv,MIT,"# Context
The National Stock Exchange of India Limited (NSE) is the leading stock exchange of India. Nifty indices are a group of stock market indexes that track the performance of various segments of the Indian stock market. Strategy indices are designed on the basis of quantitative models / investment strategies to provide a single value for the aggregate performance of a number of companies.

# Content
The Dataset has the day level information from 1 January 2000 to 1 January 2024.

Dataset contains-
- Date - date of observation
- Open - open value of the index on that day
- High - highest value of the index on that day
- Low - lowest value of the index on that day
- Close - closing value of the index on that day",.csv,True
Nifty Strategy Indices Dataset,11,nifty-strategy-indices-dataset,NIFTY100 LOW VOLATILITY 30_Historical_PR_01012000to01012024.csv,MIT,"# Context
The National Stock Exchange of India Limited (NSE) is the leading stock exchange of India. Nifty indices are a group of stock market indexes that track the performance of various segments of the Indian stock market. Strategy indices are designed on the basis of quantitative models / investment strategies to provide a single value for the aggregate performance of a number of companies.

# Content
The Dataset has the day level information from 1 January 2000 to 1 January 2024.

Dataset contains-
- Date - date of observation
- Open - open value of the index on that day
- High - highest value of the index on that day
- Low - lowest value of the index on that day
- Close - closing value of the index on that day",.csv,True
Nifty Strategy Indices Dataset,11,nifty-strategy-indices-dataset,NIFTY MIDCAP150 MOMENTUM 50_Historical_PR_01012000to01012024.csv,MIT,"# Context
The National Stock Exchange of India Limited (NSE) is the leading stock exchange of India. Nifty indices are a group of stock market indexes that track the performance of various segments of the Indian stock market. Strategy indices are designed on the basis of quantitative models / investment strategies to provide a single value for the aggregate performance of a number of companies.

# Content
The Dataset has the day level information from 1 January 2000 to 1 January 2024.

Dataset contains-
- Date - date of observation
- Open - open value of the index on that day
- High - highest value of the index on that day
- Low - lowest value of the index on that day
- Close - closing value of the index on that day",.csv,True
Nifty Strategy Indices Dataset,11,nifty-strategy-indices-dataset,NIFTY ALPHA LOW-VOLATILITY 30_Historical_PR_01012000to01012024.csv,MIT,"# Context
The National Stock Exchange of India Limited (NSE) is the leading stock exchange of India. Nifty indices are a group of stock market indexes that track the performance of various segments of the Indian stock market. Strategy indices are designed on the basis of quantitative models / investment strategies to provide a single value for the aggregate performance of a number of companies.

# Content
The Dataset has the day level information from 1 January 2000 to 1 January 2024.

Dataset contains-
- Date - date of observation
- Open - open value of the index on that day
- High - highest value of the index on that day
- Low - lowest value of the index on that day
- Close - closing value of the index on that day",.csv,True
Nifty Strategy Indices Dataset,11,nifty-strategy-indices-dataset,NIFTY ALPHA 50_Historical_PR_01012000to01012024.csv,MIT,"# Context
The National Stock Exchange of India Limited (NSE) is the leading stock exchange of India. Nifty indices are a group of stock market indexes that track the performance of various segments of the Indian stock market. Strategy indices are designed on the basis of quantitative models / investment strategies to provide a single value for the aggregate performance of a number of companies.

# Content
The Dataset has the day level information from 1 January 2000 to 1 January 2024.

Dataset contains-
- Date - date of observation
- Open - open value of the index on that day
- High - highest value of the index on that day
- Low - lowest value of the index on that day
- Close - closing value of the index on that day",.csv,True
Nifty Strategy Indices Dataset,11,nifty-strategy-indices-dataset,NIFTY SMALLCAP250 MOMENTUM QUALITY 100_Historical_PR_01012000to01012024.csv,MIT,"# Context
The National Stock Exchange of India Limited (NSE) is the leading stock exchange of India. Nifty indices are a group of stock market indexes that track the performance of various segments of the Indian stock market. Strategy indices are designed on the basis of quantitative models / investment strategies to provide a single value for the aggregate performance of a number of companies.

# Content
The Dataset has the day level information from 1 January 2000 to 1 January 2024.

Dataset contains-
- Date - date of observation
- Open - open value of the index on that day
- High - highest value of the index on that day
- Low - lowest value of the index on that day
- Close - closing value of the index on that day",.csv,True
Olympic Games 2021 Medals,2,olympic-games-2021-medals,Tokyo 2021 dataset v3.csv,other,"The 2021 Games are the fourth Olympic Games to be held in Japan, following the Tokyo 1964 (Summer), Sapporo 1972 (Winter), and Nagano 1998 (Winter) games.
The 2021 Summer Olympics , officially the Games of the XXXII Olympiad and branded as Tokyo 2021, is an ongoing international multi-sport event being held from 23 July to 8 August 2021 in Tokyo, Japan, with some preliminary events that began on 21 July.
More than 11,000 athletes from 200 countries took part in these Olympic Games.

Data source: [Tokyo 2021 Olympics](https://olympics.com/tokyo-2020/olympic-games/en/results/all-sports/medal-standings.htm)",.csv,True
Olympic Games 2021 Medals,2,olympic-games-2021-medals,Tokyo 2021 dataset v4.csv,other,"The 2021 Games are the fourth Olympic Games to be held in Japan, following the Tokyo 1964 (Summer), Sapporo 1972 (Winter), and Nagano 1998 (Winter) games.
The 2021 Summer Olympics , officially the Games of the XXXII Olympiad and branded as Tokyo 2021, is an ongoing international multi-sport event being held from 23 July to 8 August 2021 in Tokyo, Japan, with some preliminary events that began on 21 July.
More than 11,000 athletes from 200 countries took part in these Olympic Games.

Data source: [Tokyo 2021 Olympics](https://olympics.com/tokyo-2020/olympic-games/en/results/all-sports/medal-standings.htm)",.csv,True
PS4E4 | Ensemble Ancillary,6,ps4e4-ensemble-ancillary,sub_pure_14648.csv,Apache 2.0,"The Dataset is contains submissions from different versions of my notebook using various feature engineering & modeling ideas. Each submission is not blended with any other submission, the idea is to use these to generalize result. 

Naming format ""sub_pure_""+score(in decimals)

",.csv,True
PS4E4 | Ensemble Ancillary,6,ps4e4-ensemble-ancillary,sub_pure_14563.csv,Apache 2.0,"The Dataset is contains submissions from different versions of my notebook using various feature engineering & modeling ideas. Each submission is not blended with any other submission, the idea is to use these to generalize result. 

Naming format ""sub_pure_""+score(in decimals)

",.csv,True
PS4E4 | Ensemble Ancillary,6,ps4e4-ensemble-ancillary,sub_pure_14572.csv,Apache 2.0,"The Dataset is contains submissions from different versions of my notebook using various feature engineering & modeling ideas. Each submission is not blended with any other submission, the idea is to use these to generalize result. 

Naming format ""sub_pure_""+score(in decimals)

",.csv,True
PS4E4 | Ensemble Ancillary,6,ps4e4-ensemble-ancillary,sub_pure_14556.csv,Apache 2.0,"The Dataset is contains submissions from different versions of my notebook using various feature engineering & modeling ideas. Each submission is not blended with any other submission, the idea is to use these to generalize result. 

Naming format ""sub_pure_""+score(in decimals)

",.csv,True
PS4E4 | Ensemble Ancillary,6,ps4e4-ensemble-ancillary,sub_pure_14685.csv,Apache 2.0,"The Dataset is contains submissions from different versions of my notebook using various feature engineering & modeling ideas. Each submission is not blended with any other submission, the idea is to use these to generalize result. 

Naming format ""sub_pure_""+score(in decimals)

",.csv,True
PS4E4 | Ensemble Ancillary,6,ps4e4-ensemble-ancillary,sub_pure_14651.csv,Apache 2.0,"The Dataset is contains submissions from different versions of my notebook using various feature engineering & modeling ideas. Each submission is not blended with any other submission, the idea is to use these to generalize result. 

Naming format ""sub_pure_""+score(in decimals)

",.csv,True
Pakistan Suicide Bombing Attacks,2,pakistansuicideattacks,PakistanSuicideAttacks Ver 11 (30-November-2017).csv,CC0-1.0,"# Context 

Pakistan Suicide Bombing Attacks (1995-2016)


Suicide bombing is an operational method in which the very act of the attack is dependent upon the death of the perpetrator. Though only 3% of all terrorist attacks around the world can be classified as suicide bombing attacks these account for 48% of the casualties. Explosions and suicide bombings have become the modus operandi of terrorist organizations throughout the world. The world is full of unwanted explosives, brutal bombings, accidents, and violent conflicts, and there is a need to understand the impact of these explosions on one’s surroundings, the environment, and most importantly on human bodies. From 1980 to 2001 (excluding 9/11/01) the average number of deaths per incident for suicide bombing attacks was 13. This number is far above the average of less than one death per incident across all types of terrorist attacks over the same time period. Suicide bombers, unlike any other device or means of destruction, can think and therefore detonate the charge at an optimal location with perfect timing to cause maximum carnage and destruction. Suicide bombers are adaptive and can quickly change targets if forced by security risk or the availability of better targets.  Suicide attacks are relatively inexpensive to fund and technologically primitive, as IEDs can be readily constructed. 

World has seen more than 3,600 suicide bombing attacks in over 40 countries since 1982. Suicide Bombing has wreaked havoc in Pakistan in the last decade or so. From only a couple of attacks before 2000, it kept escalating after the US Operation Enduring Freedom in Afghanistan, promiscuously killing hundreds of people each year, towering as one of the most prominent security threats that every single Pakistani faces today. The conundrum of suicide bombing in Pakistan has obliterated 6,982 clean-handed civilians and injured another 17,624 in a total of 475 attacks since 1995. More than 94% of these attacks have taken place after year 2006. From 2007 to 2013 the country witnessed a suicide bombing attack on every 6th day that increased to every 4th day in 2013. Counting the dead and the injured, each attack victimizes 48 people in Pakistan. 

Pakistan Body Count (www.PakistanBodyCount.org) is the oldest and most accurate running tally of suicide bombings in Pakistan. The given database (PakistanSuicideAttacks.CSV) has been populated by using majority of the data from Pakistan Body Count, and building up on it by canvassing open source newspapers, media reports, think tank analyses, and personal contacts in media and law enforcement agencies. We provide a count of the people killed and injured in suicide attacks, including the ones who died later in hospitals or homes due to injuries caused or aggravated by these attacks (second and tertiary blast injuries), making it the most authentic source for suicide attacks related data in this region.
  
We will keep releasing the updates every quarter at this page.



# Content

Geography: Pakistan

Time period: 1995-2016 

Unit of analysis: Attack

Dataset: The dataset contains detailed information of 475 suicide bombing attacks in Pakistan that killed an estimated 6,982 and injured 17,624 people. 

Variables: The dataset contains Serial No, Incident Date, Islamic Date (based on Islamic lunar calendar), approximate Time, Long-Lat, City, Province, Location, Location Sensitivity & Type, Target type and Sect, Open/Close Space (as it will change the impact of blast waves due to reflection), min and max number of people killed and injured, number of suicide bombers, amount of explosive being used and the name of hospitals where victims went for treatment.

Sources: Unclassified media articles, hospital reports, think tank analysis and reports, and government official press releases.

# Acknowledgements & References

Pakistan Body Count has been leveraged extensively in scholarly publications, reports, media articles and books. The website and the dataset has been collected and curated by the founder Zeeshan-ul-hassan Usmani. 

Users are allowed to use, copy, distribute and cite the dataset as follows: “Zeeshan-ul-hassan Usmani, Pakistan Body Count, Pakistan Suicide Bombing Attacks Dataset, Kaggle Dataset Repository, Jan 25, 2017.”

# Past Work

1.	Zeeshan-ul-hassan Usmani and Daniel Kirk, “[Simulation of Suicide Bombing – Using Computers to Save Lives][1]”, I-Universe, New York, NY, April 2011
2.	Zeeshan-ul-hassan Usmani and Daniel Kirk, “Modeling and Simulation of Explosion Effectiveness as a Function of Blast and Crowd Characteristics”, The Journal of Defense Modeling and Simulation: Applications, Methodology, Technology, Sage Publications with Society of Simulation, Vol. 6, No. 2, pp. 79-95, Vista, CA, USA, October 2009
3.	Muhammad Irfan and Zeeshan-ul-hassan Usmani, “[Suicide Terrorism and its New Target –Pakistan][2]”, in Wars, Insurgencies and Terrorist Attacks: A Psychosocial Perspective from The Muslim World, by Unaiza Niaz, Oxford University Press, Canada, July 2010 
4.	Sana Rasheed, [Data Science for Suicide Bombings][3], I-Universe, New York, NY, December 2016 
5.	Zeeshan-ul-hassan Usmani and Sana Rasheed, “Terrorism: What Data Sciences Can Do?”, 20th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD 2014, Data Framework Track) at Bloomberg,  New York, NY, USA (August 24-27, 2014)
6.	Zeeshan-ul-hassan Usmani, “Suicide Bombing Forecaster – Novel Techniques to Predict Patterns of Suicide Bombing in Pakistan”, 2012 Conference on Homeland Security, part of 2012 Autumn Simulation Multi-Conference, San Diego, CA, USA, October 28 – 31, 2012
7.	Zeeshan-ul-hassan Usmani, “BlastSim – Simulation to Save Lives”, IEEE/SIC Winter Simulation Conference, PhD Colloquium, Austin, Texas, December 13-16, 2009
8.	Zeeshan-ul-hassan Usmani, Fawzi Alghamdi, and Daniel Kirk, “BlastSim – Multi-agent Simulation of Suicide Bombing“, IEEE Symposium: Computational Intelligence for Security and Defense Applications (CISDA), Ottawa, Canada, July 8-10, 2009
9.	Zeeshan-ul-hassan Usmani, Eyosias Imana and Daniel Kirk, “Virtual Iraq – Simulation of Insurgent Attacks”, IEEE Workshop on Computational Intelligence in Virtual Environments (CIVE), March 30-April 2, 2009 
10.	Zeeshan-ul-hassan Usmani, Eyosias Imana, and Daniel Kirk, “Random Walk in Extreme Conditions – An Agent Based Simulation of Suicide Bombing”, IEEE Symposium on Intelligent Agents, March, 2009
11.	Zeeshan-ul-hassan Usmani, Eyosias Imana and Daniel Kirk, “Escaping Death – Geometrical Recommendations for High Value Targets”, IEEE International Joint Conferences on Computer, Information and Systems Sciences and Engineering (CIS2E 08), Bridgeport, CT, December 5–13, 2008
12.	Zeeshan-ul-hassan Usmani and Daniel Kirk, “Extreme Conditions for Intelligent Agents”, IEEE 2008 WI-IAT Doctoral Workshop, Sydney, Australia, December 9-12, 2008 
13.	Zeeshan-ul-hassan Usmani, Andrew English & Richard Griffith, “The Effects of a Suicide Bombing: Crowd Formations”, Inter-service/Industry Training, Simulation, and Education Conference (I/ITSEC), Orlando, FL, Nov 26-29 2007


# Inspiration

Some ideas worth exploring:

 - How many people got killed and injured per year?
 - Visualize suicide attacks on timeline
 - Find out any correlation with number of suicide bombing attacks with drone attacks
 - Find out any correlation with suicide bombing attacks with influencing events given in the dataset
 - Can we predict the next suicide bombing attack?
 - Find the correlation between blast/explosive weight and number of people killed and injured
 - Find the impact of holiday type on number of blast victims
 - Find the correlation between Islamic date and blast day/time/size/number of victims
 - Find the Top 10 locations of blasts
 - Find the names of hospitals sorted by number of victims 


# Questions? 

For detailed visit www.PakistanBodyCount.org 

Or contact Pakistan Body Count staff at info@pakistanbodycount.org 





  [1]: https://www.amazon.com/Simulation-Suicide-Bombing-Using-Computers/dp/1440194416/ref=asap_bc?ie=UTF8
  [2]: http://www.oupcanada.com/catalog/9780199060139.html
  [3]: https://www.amazon.com/Data-Science-Suicide-Bombings-Rasheed/dp/1532012969/ref=sr_1_1?s=books&ie=UTF8&qid=1485367719&sr=1-1&keywords=Sana%20Rasheed",.csv,True
Pakistan Suicide Bombing Attacks,2,pakistansuicideattacks,PakistanSuicideAttacks Ver 6 (10-October-2017).csv,CC0-1.0,"# Context 

Pakistan Suicide Bombing Attacks (1995-2016)


Suicide bombing is an operational method in which the very act of the attack is dependent upon the death of the perpetrator. Though only 3% of all terrorist attacks around the world can be classified as suicide bombing attacks these account for 48% of the casualties. Explosions and suicide bombings have become the modus operandi of terrorist organizations throughout the world. The world is full of unwanted explosives, brutal bombings, accidents, and violent conflicts, and there is a need to understand the impact of these explosions on one’s surroundings, the environment, and most importantly on human bodies. From 1980 to 2001 (excluding 9/11/01) the average number of deaths per incident for suicide bombing attacks was 13. This number is far above the average of less than one death per incident across all types of terrorist attacks over the same time period. Suicide bombers, unlike any other device or means of destruction, can think and therefore detonate the charge at an optimal location with perfect timing to cause maximum carnage and destruction. Suicide bombers are adaptive and can quickly change targets if forced by security risk or the availability of better targets.  Suicide attacks are relatively inexpensive to fund and technologically primitive, as IEDs can be readily constructed. 

World has seen more than 3,600 suicide bombing attacks in over 40 countries since 1982. Suicide Bombing has wreaked havoc in Pakistan in the last decade or so. From only a couple of attacks before 2000, it kept escalating after the US Operation Enduring Freedom in Afghanistan, promiscuously killing hundreds of people each year, towering as one of the most prominent security threats that every single Pakistani faces today. The conundrum of suicide bombing in Pakistan has obliterated 6,982 clean-handed civilians and injured another 17,624 in a total of 475 attacks since 1995. More than 94% of these attacks have taken place after year 2006. From 2007 to 2013 the country witnessed a suicide bombing attack on every 6th day that increased to every 4th day in 2013. Counting the dead and the injured, each attack victimizes 48 people in Pakistan. 

Pakistan Body Count (www.PakistanBodyCount.org) is the oldest and most accurate running tally of suicide bombings in Pakistan. The given database (PakistanSuicideAttacks.CSV) has been populated by using majority of the data from Pakistan Body Count, and building up on it by canvassing open source newspapers, media reports, think tank analyses, and personal contacts in media and law enforcement agencies. We provide a count of the people killed and injured in suicide attacks, including the ones who died later in hospitals or homes due to injuries caused or aggravated by these attacks (second and tertiary blast injuries), making it the most authentic source for suicide attacks related data in this region.
  
We will keep releasing the updates every quarter at this page.



# Content

Geography: Pakistan

Time period: 1995-2016 

Unit of analysis: Attack

Dataset: The dataset contains detailed information of 475 suicide bombing attacks in Pakistan that killed an estimated 6,982 and injured 17,624 people. 

Variables: The dataset contains Serial No, Incident Date, Islamic Date (based on Islamic lunar calendar), approximate Time, Long-Lat, City, Province, Location, Location Sensitivity & Type, Target type and Sect, Open/Close Space (as it will change the impact of blast waves due to reflection), min and max number of people killed and injured, number of suicide bombers, amount of explosive being used and the name of hospitals where victims went for treatment.

Sources: Unclassified media articles, hospital reports, think tank analysis and reports, and government official press releases.

# Acknowledgements & References

Pakistan Body Count has been leveraged extensively in scholarly publications, reports, media articles and books. The website and the dataset has been collected and curated by the founder Zeeshan-ul-hassan Usmani. 

Users are allowed to use, copy, distribute and cite the dataset as follows: “Zeeshan-ul-hassan Usmani, Pakistan Body Count, Pakistan Suicide Bombing Attacks Dataset, Kaggle Dataset Repository, Jan 25, 2017.”

# Past Work

1.	Zeeshan-ul-hassan Usmani and Daniel Kirk, “[Simulation of Suicide Bombing – Using Computers to Save Lives][1]”, I-Universe, New York, NY, April 2011
2.	Zeeshan-ul-hassan Usmani and Daniel Kirk, “Modeling and Simulation of Explosion Effectiveness as a Function of Blast and Crowd Characteristics”, The Journal of Defense Modeling and Simulation: Applications, Methodology, Technology, Sage Publications with Society of Simulation, Vol. 6, No. 2, pp. 79-95, Vista, CA, USA, October 2009
3.	Muhammad Irfan and Zeeshan-ul-hassan Usmani, “[Suicide Terrorism and its New Target –Pakistan][2]”, in Wars, Insurgencies and Terrorist Attacks: A Psychosocial Perspective from The Muslim World, by Unaiza Niaz, Oxford University Press, Canada, July 2010 
4.	Sana Rasheed, [Data Science for Suicide Bombings][3], I-Universe, New York, NY, December 2016 
5.	Zeeshan-ul-hassan Usmani and Sana Rasheed, “Terrorism: What Data Sciences Can Do?”, 20th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD 2014, Data Framework Track) at Bloomberg,  New York, NY, USA (August 24-27, 2014)
6.	Zeeshan-ul-hassan Usmani, “Suicide Bombing Forecaster – Novel Techniques to Predict Patterns of Suicide Bombing in Pakistan”, 2012 Conference on Homeland Security, part of 2012 Autumn Simulation Multi-Conference, San Diego, CA, USA, October 28 – 31, 2012
7.	Zeeshan-ul-hassan Usmani, “BlastSim – Simulation to Save Lives”, IEEE/SIC Winter Simulation Conference, PhD Colloquium, Austin, Texas, December 13-16, 2009
8.	Zeeshan-ul-hassan Usmani, Fawzi Alghamdi, and Daniel Kirk, “BlastSim – Multi-agent Simulation of Suicide Bombing“, IEEE Symposium: Computational Intelligence for Security and Defense Applications (CISDA), Ottawa, Canada, July 8-10, 2009
9.	Zeeshan-ul-hassan Usmani, Eyosias Imana and Daniel Kirk, “Virtual Iraq – Simulation of Insurgent Attacks”, IEEE Workshop on Computational Intelligence in Virtual Environments (CIVE), March 30-April 2, 2009 
10.	Zeeshan-ul-hassan Usmani, Eyosias Imana, and Daniel Kirk, “Random Walk in Extreme Conditions – An Agent Based Simulation of Suicide Bombing”, IEEE Symposium on Intelligent Agents, March, 2009
11.	Zeeshan-ul-hassan Usmani, Eyosias Imana and Daniel Kirk, “Escaping Death – Geometrical Recommendations for High Value Targets”, IEEE International Joint Conferences on Computer, Information and Systems Sciences and Engineering (CIS2E 08), Bridgeport, CT, December 5–13, 2008
12.	Zeeshan-ul-hassan Usmani and Daniel Kirk, “Extreme Conditions for Intelligent Agents”, IEEE 2008 WI-IAT Doctoral Workshop, Sydney, Australia, December 9-12, 2008 
13.	Zeeshan-ul-hassan Usmani, Andrew English & Richard Griffith, “The Effects of a Suicide Bombing: Crowd Formations”, Inter-service/Industry Training, Simulation, and Education Conference (I/ITSEC), Orlando, FL, Nov 26-29 2007


# Inspiration

Some ideas worth exploring:

 - How many people got killed and injured per year?
 - Visualize suicide attacks on timeline
 - Find out any correlation with number of suicide bombing attacks with drone attacks
 - Find out any correlation with suicide bombing attacks with influencing events given in the dataset
 - Can we predict the next suicide bombing attack?
 - Find the correlation between blast/explosive weight and number of people killed and injured
 - Find the impact of holiday type on number of blast victims
 - Find the correlation between Islamic date and blast day/time/size/number of victims
 - Find the Top 10 locations of blasts
 - Find the names of hospitals sorted by number of victims 


# Questions? 

For detailed visit www.PakistanBodyCount.org 

Or contact Pakistan Body Count staff at info@pakistanbodycount.org 





  [1]: https://www.amazon.com/Simulation-Suicide-Bombing-Using-Computers/dp/1440194416/ref=asap_bc?ie=UTF8
  [2]: http://www.oupcanada.com/catalog/9780199060139.html
  [3]: https://www.amazon.com/Data-Science-Suicide-Bombings-Rasheed/dp/1532012969/ref=sr_1_1?s=books&ie=UTF8&qid=1485367719&sr=1-1&keywords=Sana%20Rasheed",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202112F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202104F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202201F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202305F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202108F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202309F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202308F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202109F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202304F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202312F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202105F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202401F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202207F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202211F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202303F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202302F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202210F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202206F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202103F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202209F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_20210815.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202301F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202205F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202403F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202402F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202204F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202212F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202208F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202307F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202203F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202311F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202106F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202110F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202111F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202107F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202310F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202202F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Plastic Bottle Waste,38,plastic-bottle-waste,wastebase_scan_summary_202306F.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Regularly-collected data about single-use plastic bottle waste found in public spaces, identified to the level of individual commercial products.

More about the data, as well as links to other ways to acess the data, available here: [unwaste.io/data](https://www.unwaste.io/data)

### Content
This data was collected from March 2021 through March 2024 using the [Wastebase digital platform](https://wastebase.org) for crowdsourced data collection about single-use plastic waste.

Data is collected via an [app for Android or iPhone](https://wastebase.app), and then checked and linked to Brand and Product information by Wastebase Data Partners (see below).    Data is collected to the level of the specific product barcode, timestamped and location stamped.   You can search for specific data on the [Wastebase reports page](https://wastebase.org/#/reports).

Data was collected in the following countries:
- CA: Canada
- CD: Congo (Democratic Republic of)
- CM: Cameroon
- ES: Spain
- GB: United Kingdom
- GH: Ghana
- KE: Kenya
- MW: Malawi
- MZ: Mozambique
- RW: Rwanda
- TZ: Tanzania
- UG: Uganda
- ZA: South Africa
- ZM: Zambia

#### Brands with unknown ownership
Where `manufacturer_country = UK` and `manufacturer_name =UNKNOWN_ORG`, this means that the Product and Brand have been identified, but the Manufacturer who owns that Brand has not.  This is more common in the the global south, where the Manufacturer may not have a web/social media presence, and may not be required (by national legislation) to state their name and address on the product label.

### Acknowledgements
This data was collected by [Wastebase's Data Partners](https://www.unwaste.io/partners) in several countries of sub-saharan Africa as well as individual contributors in Africa, Europe and N. America.  

### Support our Work
If you would like to support our work, please consider making a financial donation at one of the links below:
- if you are in the UK:  [Crowdfunder UK Donation Page](https://www.crowdfunder.co.uk/p/wastebase)
- if you are in another country: [Chuffed Donation Page](https://chuffed.org/project/wastebase)",.csv,True
Poem Classification (NLP),2,poem-classification-nlp,Poem_classification - test_data.csv,CC0-1.0,"# dON'T FOREGET TO UPVOTE IF you think DATASET IS WORTHY OF IT .

**dISCUSS ABOUT DATASET's Problem FREELY on discussion section.**
# Poem
When I used to ask students what a poem is, I would get answers like “a painting in words,” or “a medium for self-expression,” or “a song that rhymes and displays beauty.” None of these answers ever really satisfied me, or them, and so for a while I stopped asking the question.

Then one time, I requested that my students bring in to class something that had a personal meaning to them. With their objects on their desks, I gave them three prompts: first, to write a paragraph about why they brought in the item; second, to write a paragraph describing the item empirically, as a scientist might; and third, to write a paragraph in the first person from the point of view of the item. The first two were warm-ups. Above the third paragraph I told them to write “Poem.”

Dataset is classified in 4 poem genres :Affection,Environment,Music and Death
Classify the genres based on NLP METHOD.",.csv,True
Poem Classification (NLP),2,poem-classification-nlp,Poem_classification - train_data.csv,CC0-1.0,"# dON'T FOREGET TO UPVOTE IF you think DATASET IS WORTHY OF IT .

**dISCUSS ABOUT DATASET's Problem FREELY on discussion section.**
# Poem
When I used to ask students what a poem is, I would get answers like “a painting in words,” or “a medium for self-expression,” or “a song that rhymes and displays beauty.” None of these answers ever really satisfied me, or them, and so for a while I stopped asking the question.

Then one time, I requested that my students bring in to class something that had a personal meaning to them. With their objects on their desks, I gave them three prompts: first, to write a paragraph about why they brought in the item; second, to write a paragraph describing the item empirically, as a scientist might; and third, to write a paragraph in the first person from the point of view of the item. The first two were warm-ups. Above the third paragraph I told them to write “Poem.”

Dataset is classified in 4 poem genres :Affection,Environment,Music and Death
Classify the genres based on NLP METHOD.",.csv,True
Population Pyramid 2019,11,population-pyramid-2019,Canada-2019.csv,CC0-1.0,"### Context

Population pyramids by gender for CoVid-19 affected countries.

### Acknowledgements

Source: [populationpyramid.net](populationpyramid.net)",.csv,True
Population Pyramid 2019,11,population-pyramid-2019,India-2019.csv,CC0-1.0,"### Context

Population pyramids by gender for CoVid-19 affected countries.

### Acknowledgements

Source: [populationpyramid.net](populationpyramid.net)",.csv,True
Population Pyramid 2019,11,population-pyramid-2019,France-2019.csv,CC0-1.0,"### Context

Population pyramids by gender for CoVid-19 affected countries.

### Acknowledgements

Source: [populationpyramid.net](populationpyramid.net)",.csv,True
Population Pyramid 2019,11,population-pyramid-2019,China-2019.csv,CC0-1.0,"### Context

Population pyramids by gender for CoVid-19 affected countries.

### Acknowledgements

Source: [populationpyramid.net](populationpyramid.net)",.csv,True
Population Pyramid 2019,11,population-pyramid-2019,Italy-2019.csv,CC0-1.0,"### Context

Population pyramids by gender for CoVid-19 affected countries.

### Acknowledgements

Source: [populationpyramid.net](populationpyramid.net)",.csv,True
Population Pyramid 2019,11,population-pyramid-2019,Spain-2019.csv,CC0-1.0,"### Context

Population pyramids by gender for CoVid-19 affected countries.

### Acknowledgements

Source: [populationpyramid.net](populationpyramid.net)",.csv,True
Population Pyramid 2019,11,population-pyramid-2019,Iran-2019.csv,CC0-1.0,"### Context

Population pyramids by gender for CoVid-19 affected countries.

### Acknowledgements

Source: [populationpyramid.net](populationpyramid.net)",.csv,True
Population Pyramid 2019,11,population-pyramid-2019,Germany-2019.csv,CC0-1.0,"### Context

Population pyramids by gender for CoVid-19 affected countries.

### Acknowledgements

Source: [populationpyramid.net](populationpyramid.net)",.csv,True
Population Pyramid 2019,11,population-pyramid-2019,United Kingdom-2019.csv,CC0-1.0,"### Context

Population pyramids by gender for CoVid-19 affected countries.

### Acknowledgements

Source: [populationpyramid.net](populationpyramid.net)",.csv,True
Population Pyramid 2019,11,population-pyramid-2019,United States of America-2019.csv,CC0-1.0,"### Context

Population pyramids by gender for CoVid-19 affected countries.

### Acknowledgements

Source: [populationpyramid.net](populationpyramid.net)",.csv,True
Population Pyramid 2019,11,population-pyramid-2019,Japan-2019.csv,CC0-1.0,"### Context

Population pyramids by gender for CoVid-19 affected countries.

### Acknowledgements

Source: [populationpyramid.net](populationpyramid.net)",.csv,True
Population Time Series Data,2,population-time-series-data,POP.csv,other,"### Content  

More details about each file are in the individual file descriptions.  

### Context  

This is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  

* Update Frequency: This dataset is updated daily.



### Acknowledgements

This dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  

[Cover photo](https://unsplash.com/photos/l4qxQInQQy0) by [Trevor Cole](https://unsplash.com/@trevcole) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv,True
Population Time Series Data,2,population-time-series-data,POPH.csv,other,"### Content  

More details about each file are in the individual file descriptions.  

### Context  

This is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  

* Update Frequency: This dataset is updated daily.



### Acknowledgements

This dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  

[Cover photo](https://unsplash.com/photos/l4qxQInQQy0) by [Trevor Cole](https://unsplash.com/@trevcole) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv,True
Predict Demand,2,predict-demand,test.csv,ODbL-1.0,"### Context

Hiring Competition Dataset


### Content

Predict Demand

Target Variable = ""quantity""


### Acknowledgements




### Inspiration

Demand Prediction",.csv,True
Predict Demand,2,predict-demand,train.csv,ODbL-1.0,"### Context

Hiring Competition Dataset


### Content

Predict Demand

Target Variable = ""quantity""


### Acknowledgements




### Inspiration

Demand Prediction",.csv,True
Predicting Pulsar Star,2,predicting-pulsar-starintermediate,pulsar_data_train.csv,CC-BY-NC-SA-4.0,"## Description
Pulsars are a rare type of Neutron star that produce radio emission detectable here on Earth. They are of considerable scientific interest as probes of space-time, the inter-stellar medium, and states of matter. Machine learning tools are now being used to automatically label pulsar candidates to facilitate rapid analysis. Classification systems in particular are being widely adopted,which treat the candidate data sets as binary classification problems.

Credit goes to Pavan Raj (https://www.kaggle.com/pavanraj159) from where the dataset has been collected. For the purpose of creating a challenge, certain modifications have been done to the dataset.

Original dataset can be acquired from the link Predicting a Pulsar Star (https://www.kaggle.com/pavanraj159/predicting-a-pulsar-star)

## Attribute Information:

Each candidate is described by 8 continuous variables, and a single class variable. The first four are simple statistics obtained from the integrated pulse profile (folded profile). This is an array of continuous variables that describe a longitude-resolved version of the signal that has been averaged in both time and frequency . The remaining four variables are similarly obtained from the DM-SNR curve . These are summarised below:

    1. Mean of the integrated profile.
    2. Standard deviation of the integrated profile.
    3. Excess kurtosis of the integrated profile.
    4. Skewness of the integrated profile.
    5. Mean of the DM-SNR curve.
    6. Standard deviation of the DM-SNR curve.
    7. Excess kurtosis of the DM-SNR curve.
    8. Skewness of the DM-SNR curve.
    9. Class

HTRU 2 Summary
17,898 total examples.
1,639 positive examples.
16,259 negative examples.

Source: https://archive.ics.uci.edu/ml/datasets/HTRU2

Dr Robert Lyon
University of Manchester
School of Physics and Astronomy
Alan Turing Building
Manchester M13 9PL
United Kingdom
robert.lyon '@' manchester.ac.uk

## Join Us
Join and follow the [Co-learning Lounge](https://linktr.ee/colearninglounge) for more.",.csv,True
Predicting Pulsar Star,2,predicting-pulsar-starintermediate,pulsar_data_test.csv,CC-BY-NC-SA-4.0,"## Description
Pulsars are a rare type of Neutron star that produce radio emission detectable here on Earth. They are of considerable scientific interest as probes of space-time, the inter-stellar medium, and states of matter. Machine learning tools are now being used to automatically label pulsar candidates to facilitate rapid analysis. Classification systems in particular are being widely adopted,which treat the candidate data sets as binary classification problems.

Credit goes to Pavan Raj (https://www.kaggle.com/pavanraj159) from where the dataset has been collected. For the purpose of creating a challenge, certain modifications have been done to the dataset.

Original dataset can be acquired from the link Predicting a Pulsar Star (https://www.kaggle.com/pavanraj159/predicting-a-pulsar-star)

## Attribute Information:

Each candidate is described by 8 continuous variables, and a single class variable. The first four are simple statistics obtained from the integrated pulse profile (folded profile). This is an array of continuous variables that describe a longitude-resolved version of the signal that has been averaged in both time and frequency . The remaining four variables are similarly obtained from the DM-SNR curve . These are summarised below:

    1. Mean of the integrated profile.
    2. Standard deviation of the integrated profile.
    3. Excess kurtosis of the integrated profile.
    4. Skewness of the integrated profile.
    5. Mean of the DM-SNR curve.
    6. Standard deviation of the DM-SNR curve.
    7. Excess kurtosis of the DM-SNR curve.
    8. Skewness of the DM-SNR curve.
    9. Class

HTRU 2 Summary
17,898 total examples.
1,639 positive examples.
16,259 negative examples.

Source: https://archive.ics.uci.edu/ml/datasets/HTRU2

Dr Robert Lyon
University of Manchester
School of Physics and Astronomy
Alan Turing Building
Manchester M13 9PL
United Kingdom
robert.lyon '@' manchester.ac.uk

## Join Us
Join and follow the [Co-learning Lounge](https://linktr.ee/colearninglounge) for more.",.csv,True
Premier League Statistics from 2015 to 2023,8,premier-league-statistics-from-2015-to-2023,2020-2021.csv,Apache 2.0,"I've created this dataset using the project:[Premier League Statistics Scraping](https://www.kaggle.com/code/ghaithmechi/premier-league-statistics-scraping).
It contains the statistics of the Premier League matches from 2015 to 2023.
you can use the data to do some EDA or to predict the winner for this year.
So, enjoy with the data !


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~!
 Here are some additional details about the features( columns):
1. members: the number of players.
2. foreign_players: the number of foreign players in the team.
3. mean_age: the mean age of all players.
4. salaries: monthly salary charge.
5. spending: transfer expenditure.
6. MOY: Average players rating.
7. rank: the rank of the team in the season.
8. points: points gained in the season.
9. BP: Goals.
10. BC: goals against.
11. DIF=BP-BC.
12.Gain: the number of winnes.
13. Null: number of draws.
14. defeat: Number of losses.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
for further information, visit:[foot](https://www.footmercato.net/) ",.csv,True
Premier League Statistics from 2015 to 2023,8,premier-league-statistics-from-2015-to-2023,2021-2022.csv,Apache 2.0,"I've created this dataset using the project:[Premier League Statistics Scraping](https://www.kaggle.com/code/ghaithmechi/premier-league-statistics-scraping).
It contains the statistics of the Premier League matches from 2015 to 2023.
you can use the data to do some EDA or to predict the winner for this year.
So, enjoy with the data !


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~!
 Here are some additional details about the features( columns):
1. members: the number of players.
2. foreign_players: the number of foreign players in the team.
3. mean_age: the mean age of all players.
4. salaries: monthly salary charge.
5. spending: transfer expenditure.
6. MOY: Average players rating.
7. rank: the rank of the team in the season.
8. points: points gained in the season.
9. BP: Goals.
10. BC: goals against.
11. DIF=BP-BC.
12.Gain: the number of winnes.
13. Null: number of draws.
14. defeat: Number of losses.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
for further information, visit:[foot](https://www.footmercato.net/) ",.csv,True
Premier League Statistics from 2015 to 2023,8,premier-league-statistics-from-2015-to-2023,2019-2020.csv,Apache 2.0,"I've created this dataset using the project:[Premier League Statistics Scraping](https://www.kaggle.com/code/ghaithmechi/premier-league-statistics-scraping).
It contains the statistics of the Premier League matches from 2015 to 2023.
you can use the data to do some EDA or to predict the winner for this year.
So, enjoy with the data !


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~!
 Here are some additional details about the features( columns):
1. members: the number of players.
2. foreign_players: the number of foreign players in the team.
3. mean_age: the mean age of all players.
4. salaries: monthly salary charge.
5. spending: transfer expenditure.
6. MOY: Average players rating.
7. rank: the rank of the team in the season.
8. points: points gained in the season.
9. BP: Goals.
10. BC: goals against.
11. DIF=BP-BC.
12.Gain: the number of winnes.
13. Null: number of draws.
14. defeat: Number of losses.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
for further information, visit:[foot](https://www.footmercato.net/) ",.csv,True
Premier League Statistics from 2015 to 2023,8,premier-league-statistics-from-2015-to-2023,2016-2017.csv,Apache 2.0,"I've created this dataset using the project:[Premier League Statistics Scraping](https://www.kaggle.com/code/ghaithmechi/premier-league-statistics-scraping).
It contains the statistics of the Premier League matches from 2015 to 2023.
you can use the data to do some EDA or to predict the winner for this year.
So, enjoy with the data !


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~!
 Here are some additional details about the features( columns):
1. members: the number of players.
2. foreign_players: the number of foreign players in the team.
3. mean_age: the mean age of all players.
4. salaries: monthly salary charge.
5. spending: transfer expenditure.
6. MOY: Average players rating.
7. rank: the rank of the team in the season.
8. points: points gained in the season.
9. BP: Goals.
10. BC: goals against.
11. DIF=BP-BC.
12.Gain: the number of winnes.
13. Null: number of draws.
14. defeat: Number of losses.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
for further information, visit:[foot](https://www.footmercato.net/) ",.csv,True
Premier League Statistics from 2015 to 2023,8,premier-league-statistics-from-2015-to-2023,2018-2019.csv,Apache 2.0,"I've created this dataset using the project:[Premier League Statistics Scraping](https://www.kaggle.com/code/ghaithmechi/premier-league-statistics-scraping).
It contains the statistics of the Premier League matches from 2015 to 2023.
you can use the data to do some EDA or to predict the winner for this year.
So, enjoy with the data !


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~!
 Here are some additional details about the features( columns):
1. members: the number of players.
2. foreign_players: the number of foreign players in the team.
3. mean_age: the mean age of all players.
4. salaries: monthly salary charge.
5. spending: transfer expenditure.
6. MOY: Average players rating.
7. rank: the rank of the team in the season.
8. points: points gained in the season.
9. BP: Goals.
10. BC: goals against.
11. DIF=BP-BC.
12.Gain: the number of winnes.
13. Null: number of draws.
14. defeat: Number of losses.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
for further information, visit:[foot](https://www.footmercato.net/) ",.csv,True
Premier League Statistics from 2015 to 2023,8,premier-league-statistics-from-2015-to-2023,2022-2023.csv,Apache 2.0,"I've created this dataset using the project:[Premier League Statistics Scraping](https://www.kaggle.com/code/ghaithmechi/premier-league-statistics-scraping).
It contains the statistics of the Premier League matches from 2015 to 2023.
you can use the data to do some EDA or to predict the winner for this year.
So, enjoy with the data !


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~!
 Here are some additional details about the features( columns):
1. members: the number of players.
2. foreign_players: the number of foreign players in the team.
3. mean_age: the mean age of all players.
4. salaries: monthly salary charge.
5. spending: transfer expenditure.
6. MOY: Average players rating.
7. rank: the rank of the team in the season.
8. points: points gained in the season.
9. BP: Goals.
10. BC: goals against.
11. DIF=BP-BC.
12.Gain: the number of winnes.
13. Null: number of draws.
14. defeat: Number of losses.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
for further information, visit:[foot](https://www.footmercato.net/) ",.csv,True
Premier League Statistics from 2015 to 2023,8,premier-league-statistics-from-2015-to-2023,2017-2018.csv,Apache 2.0,"I've created this dataset using the project:[Premier League Statistics Scraping](https://www.kaggle.com/code/ghaithmechi/premier-league-statistics-scraping).
It contains the statistics of the Premier League matches from 2015 to 2023.
you can use the data to do some EDA or to predict the winner for this year.
So, enjoy with the data !


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~!
 Here are some additional details about the features( columns):
1. members: the number of players.
2. foreign_players: the number of foreign players in the team.
3. mean_age: the mean age of all players.
4. salaries: monthly salary charge.
5. spending: transfer expenditure.
6. MOY: Average players rating.
7. rank: the rank of the team in the season.
8. points: points gained in the season.
9. BP: Goals.
10. BC: goals against.
11. DIF=BP-BC.
12.Gain: the number of winnes.
13. Null: number of draws.
14. defeat: Number of losses.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
for further information, visit:[foot](https://www.footmercato.net/) ",.csv,True
Premier League Statistics from 2015 to 2023,8,premier-league-statistics-from-2015-to-2023,2015-2016.csv,Apache 2.0,"I've created this dataset using the project:[Premier League Statistics Scraping](https://www.kaggle.com/code/ghaithmechi/premier-league-statistics-scraping).
It contains the statistics of the Premier League matches from 2015 to 2023.
you can use the data to do some EDA or to predict the winner for this year.
So, enjoy with the data !


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~!
 Here are some additional details about the features( columns):
1. members: the number of players.
2. foreign_players: the number of foreign players in the team.
3. mean_age: the mean age of all players.
4. salaries: monthly salary charge.
5. spending: transfer expenditure.
6. MOY: Average players rating.
7. rank: the rank of the team in the season.
8. points: points gained in the season.
9. BP: Goals.
10. BC: goals against.
11. DIF=BP-BC.
12.Gain: the number of winnes.
13. Null: number of draws.
14. defeat: Number of losses.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
for further information, visit:[foot](https://www.footmercato.net/) ",.csv,True
ReAct Gemini Data,2,react-finetune-gemma,kaggleqa_general_react_gemini.csv,MIT,"Simple ReAct trajectories generated using Gemini in a LLM Agent and the Kaggle Environment. 

See [notebook](https://www.kaggle.com/code/penpentled/kaggleqa-react-with-kaggle-api/edit) for more details.",.csv,True
ReAct Gemini Data,2,react-finetune-gemma,kaggleqa_react_gemini.csv,MIT,"Simple ReAct trajectories generated using Gemini in a LLM Agent and the Kaggle Environment. 

See [notebook](https://www.kaggle.com/code/penpentled/kaggleqa-react-with-kaggle-api/edit) for more details.",.csv,True
Red Wine Quality,2,red-wine-quality-cortez-et-al-2009,winequality-red.csv,DbCL-1.0,"### Context

The two datasets are related to red and white variants of the Portuguese ""Vinho Verde"" wine. For more details, consult the reference [Cortez et al., 2009]. Due to privacy and logistic issues, only physicochemical (inputs) and sensory (the output) variables are available (e.g. there is no data about grape types, wine brand, wine selling price, etc.). 

These datasets can be viewed as classification or regression tasks. The classes are ordered and not balanced (e.g. there are much more normal wines than excellent or poor ones). 

---
*This dataset is also available from the UCI machine learning repository, https://archive.ics.uci.edu/ml/datasets/wine+quality , I just shared it to kaggle for convenience. (If I am mistaken and the public license type disallowed me from doing so, I will take this down if requested.)*


### Content

For more information, read [Cortez et al., 2009].<br>
Input variables (based on physicochemical tests):<br>
1 - fixed acidity <br>
2 - volatile acidity <br>
3 - citric acid <br>
4 - residual sugar <br>
5 - chlorides <br>
6 - free sulfur dioxide <br> 
7 - total sulfur dioxide <br>
8 - density <br>
9 - pH <br>
10 - sulphates <br>
11 - alcohol <br>
Output variable (based on sensory data): <br>
12 - quality (score between 0 and 10) <br>

### Tips
What might be an interesting thing to do, is aside from using regression modelling, is to set an arbitrary cutoff for your dependent variable (wine quality) at e.g. 7 or higher getting classified as 'good/1' and the remainder as 'not good/0'.
This allows you to practice with hyper parameter tuning on e.g. decision tree algorithms looking at the ROC curve and the AUC value.
Without doing any kind of feature engineering or overfitting you should be able to get an AUC of .88 (without even using random forest algorithm)

**KNIME** is a great tool (GUI) that can be used for this.<br>
1 - File Reader (for csv) to linear correlation node and to interactive histogram for basic EDA.<br>
2- File Reader to 'Rule Engine Node' to turn the 10 point scale to dichtome variable (good wine and rest), the code to put in the rule engine is something like this:<br>
 -  **$quality$ > 6.5 => ""good""**<br>
 -  **TRUE => ""bad""** <br>
3- Rule Engine Node output to input of Column Filter node to filter out your original 10point feature (this prevent leaking)<br>
4- Column Filter Node output to input of Partitioning Node (your standard train/tes split, e.g. 75%/25%, choose 'random' or 'stratified')<br>
5- Partitioning Node train data split output to input of Train data split to input Decision Tree Learner node and <br>
6- Partitioning Node test data split output to input Decision Tree predictor Node<br>
7- Decision Tree learner Node output to input Decision Tree Node input<br>
8- Decision Tree output to input ROC Node.. (here you can evaluate your model base on AUC value)<br>


### Inspiration
Use machine learning to determine which physiochemical properties make a wine 'good'!



### Acknowledgements

This dataset is also available from the UCI machine learning repository, https://archive.ics.uci.edu/ml/datasets/wine+quality , I just shared it to kaggle for convenience. *(I am mistaken and the public license type disallowed me from doing so, I will take this down at first request. I am not the owner of this dataset.*

**Please include this citation if you plan to use this database: 
P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. 
Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.**

### Relevant publication

P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling wine preferences by data mining from physicochemical properties. 
In Decision Support Systems, Elsevier, 47(4):547-553, 2009. ",.csv,True
Red Wine Quality,2,red-wine-quality,winequality-red.csv,Apache 2.0,"Input variables (based on physicochemical tests):
1 - fixed acidity
2 - volatile acidity
3 - citric acid
4 - residual sugar
5 - chlorides
6 - free sulfur dioxide
7 - total sulfur dioxide
8 - density
9 - pH
10 - sulphates
11 - alcohol
Output variable (based on sensory data):
12 - quality (score between 0 and 10)

Tips
What might be an interesting thing to do, is aside from using regression modelling, is to set an arbitrary cutoff for your dependent variable (wine quality) at e.g. 7 or higher getting classified as 'good/1' and the remainder as 'not good/0'.
This allows you to practice with hyper parameter tuning on e.g. decision tree algorithms looking at the ROC curve and the AUC value.
Without doing any kind of feature engineering or overfitting you should be able to get an AUC of .88 (without even using random forest algorithm)

KNIME is a great tool (GUI) that can be used for this.
1 - File Reader (for csv) to linear correlation node and to interactive histogram for basic EDA.
2- File Reader to 'Rule Engine Node' to turn the 10 point scale to dichtome variable (good wine and rest), the code to put in the rule engine is something like this:

$quality$ &gt; 6.5 =&gt; ""good""
TRUE =&gt; ""bad""

3- Rule Engine Node output to input of Column Filter node to filter out your original 10point feature (this prevent leaking)

4- Column Filter Node output to input of Partitioning Node (your standard train/tes split, e.g. 75%/25%, choose 'random' or 'stratified')

5- Partitioning Node train data split output to input of Train data split to input Decision Tree Learner node and

6- Partitioning Node test data split output to input Decision Tree predictor Node

7- Decision Tree learner Node output to input Decision Tree Node input

8- Decision Tree output to input ROC Node.. (here you can evaluate your model base on AUC value)
Inspiration
Use machine learning to determine which physiochemical properties make a wine 'good'!",.csv,True
Retail and Retailers Sales Time Series Collection,23,retail-and-retailers-sales-time-series-collection,MRTSSM442USN.csv,other,"### Content  

More details about each file are in the individual file descriptions.  

### Context  

This is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  

* Update Frequency: This dataset is updated daily.



### Acknowledgements

This dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  

[Cover photo](https://unsplash.com/photos/5ELkI0KByF4) by [Matteo Catanese](https://unsplash.com/@matteocatanese) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv,True
Retail and Retailers Sales Time Series Collection,23,retail-and-retailers-sales-time-series-collection,RETAILSMNSA.csv,other,"### Content  

More details about each file are in the individual file descriptions.  

### Context  

This is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  

* Update Frequency: This dataset is updated daily.



### Acknowledgements

This dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  

[Cover photo](https://unsplash.com/photos/5ELkI0KByF4) by [Matteo Catanese](https://unsplash.com/@matteocatanese) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv,True
Retail and Retailers Sales Time Series Collection,23,retail-and-retailers-sales-time-series-collection,RETAILMPCSMNSA.csv,other,"### Content  

More details about each file are in the individual file descriptions.  

### Context  

This is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  

* Update Frequency: This dataset is updated daily.



### Acknowledgements

This dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  

[Cover photo](https://unsplash.com/photos/5ELkI0KByF4) by [Matteo Catanese](https://unsplash.com/@matteocatanese) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv,True
Retail and Retailers Sales Time Series Collection,23,retail-and-retailers-sales-time-series-collection,MRTSSM45112USN.csv,other,"### Content  

More details about each file are in the individual file descriptions.  

### Context  

This is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  

* Update Frequency: This dataset is updated daily.



### Acknowledgements

This dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  

[Cover photo](https://unsplash.com/photos/5ELkI0KByF4) by [Matteo Catanese](https://unsplash.com/@matteocatanese) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv,True
Retail and Retailers Sales Time Series Collection,23,retail-and-retailers-sales-time-series-collection,RETAILIMSA.csv,other,"### Content  

More details about each file are in the individual file descriptions.  

### Context  

This is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  

* Update Frequency: This dataset is updated daily.



### Acknowledgements

This dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  

[Cover photo](https://unsplash.com/photos/5ELkI0KByF4) by [Matteo Catanese](https://unsplash.com/@matteocatanese) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv,True
Retail and Retailers Sales Time Series Collection,23,retail-and-retailers-sales-time-series-collection,MRTSSM4541USS.csv,other,"### Content  

More details about each file are in the individual file descriptions.  

### Context  

This is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  

* Update Frequency: This dataset is updated daily.



### Acknowledgements

This dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  

[Cover photo](https://unsplash.com/photos/5ELkI0KByF4) by [Matteo Catanese](https://unsplash.com/@matteocatanese) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv,True
Retail and Retailers Sales Time Series Collection,23,retail-and-retailers-sales-time-series-collection,RETAILMPCSMSA.csv,other,"### Content  

More details about each file are in the individual file descriptions.  

### Context  

This is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  

* Update Frequency: This dataset is updated daily.



### Acknowledgements

This dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  

[Cover photo](https://unsplash.com/photos/5ELkI0KByF4) by [Matteo Catanese](https://unsplash.com/@matteocatanese) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv,True
Retail and Retailers Sales Time Series Collection,23,retail-and-retailers-sales-time-series-collection,MRTSSM4481USN.csv,other,"### Content  

More details about each file are in the individual file descriptions.  

### Context  

This is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  

* Update Frequency: This dataset is updated daily.



### Acknowledgements

This dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  

[Cover photo](https://unsplash.com/photos/5ELkI0KByF4) by [Matteo Catanese](https://unsplash.com/@matteocatanese) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv,True
Retail and Retailers Sales Time Series Collection,23,retail-and-retailers-sales-time-series-collection,RETAILSMSA.csv,other,"### Content  

More details about each file are in the individual file descriptions.  

### Context  

This is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  

* Update Frequency: This dataset is updated daily.



### Acknowledgements

This dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  

[Cover photo](https://unsplash.com/photos/5ELkI0KByF4) by [Matteo Catanese](https://unsplash.com/@matteocatanese) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv,True
Retail and Retailers Sales Time Series Collection,23,retail-and-retailers-sales-time-series-collection,MRTSSM44112USN.csv,other,"### Content  

More details about each file are in the individual file descriptions.  

### Context  

This is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  

* Update Frequency: This dataset is updated daily.



### Acknowledgements

This dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  

[Cover photo](https://unsplash.com/photos/5ELkI0KByF4) by [Matteo Catanese](https://unsplash.com/@matteocatanese) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv,True
Retail and Retailers Sales Time Series Collection,23,retail-and-retailers-sales-time-series-collection,RETAILIRSA.csv,other,"### Content  

More details about each file are in the individual file descriptions.  

### Context  

This is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  

* Update Frequency: This dataset is updated daily.



### Acknowledgements

This dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  

[Cover photo](https://unsplash.com/photos/5ELkI0KByF4) by [Matteo Catanese](https://unsplash.com/@matteocatanese) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv,True
Retail and Retailers Sales Time Series Collection,23,retail-and-retailers-sales-time-series-collection,MRTSSM44X72USS.csv,other,"### Content  

More details about each file are in the individual file descriptions.  

### Context  

This is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  

* Update Frequency: This dataset is updated daily.



### Acknowledgements

This dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  

[Cover photo](https://unsplash.com/photos/5ELkI0KByF4) by [Matteo Catanese](https://unsplash.com/@matteocatanese) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv,True
Retail and Retailers Sales Time Series Collection,23,retail-and-retailers-sales-time-series-collection,MRTSSM4413USS.csv,other,"### Content  

More details about each file are in the individual file descriptions.  

### Context  

This is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  

* Update Frequency: This dataset is updated daily.



### Acknowledgements

This dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  

[Cover photo](https://unsplash.com/photos/5ELkI0KByF4) by [Matteo Catanese](https://unsplash.com/@matteocatanese) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv,True
Retail and Retailers Sales Time Series Collection,23,retail-and-retailers-sales-time-series-collection,MRTSSM444USS.csv,other,"### Content  

More details about each file are in the individual file descriptions.  

### Context  

This is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  

* Update Frequency: This dataset is updated daily.



### Acknowledgements

This dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  

[Cover photo](https://unsplash.com/photos/5ELkI0KByF4) by [Matteo Catanese](https://unsplash.com/@matteocatanese) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv,True
Retail and Retailers Sales Time Series Collection,23,retail-and-retailers-sales-time-series-collection,MRTSSM448USS.csv,other,"### Content  

More details about each file are in the individual file descriptions.  

### Context  

This is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  

* Update Frequency: This dataset is updated daily.



### Acknowledgements

This dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  

[Cover photo](https://unsplash.com/photos/5ELkI0KByF4) by [Matteo Catanese](https://unsplash.com/@matteocatanese) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv,True
Retail and Retailers Sales Time Series Collection,23,retail-and-retailers-sales-time-series-collection,MRTSSM45111USN.csv,other,"### Content  

More details about each file are in the individual file descriptions.  

### Context  

This is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  

* Update Frequency: This dataset is updated daily.



### Acknowledgements

This dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  

[Cover photo](https://unsplash.com/photos/5ELkI0KByF4) by [Matteo Catanese](https://unsplash.com/@matteocatanese) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv,True
Retail and Retailers Sales Time Series Collection,23,retail-and-retailers-sales-time-series-collection,MRTSSM7221USN.csv,other,"### Content  

More details about each file are in the individual file descriptions.  

### Context  

This is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  

* Update Frequency: This dataset is updated daily.



### Acknowledgements

This dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  

[Cover photo](https://unsplash.com/photos/5ELkI0KByF4) by [Matteo Catanese](https://unsplash.com/@matteocatanese) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv,True
Retail and Retailers Sales Time Series Collection,23,retail-and-retailers-sales-time-series-collection,MRTSSM4453USN.csv,other,"### Content  

More details about each file are in the individual file descriptions.  

### Context  

This is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  

* Update Frequency: This dataset is updated daily.



### Acknowledgements

This dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  

[Cover photo](https://unsplash.com/photos/5ELkI0KByF4) by [Matteo Catanese](https://unsplash.com/@matteocatanese) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv,True
Retail and Retailers Sales Time Series Collection,23,retail-and-retailers-sales-time-series-collection,MRTSSM44000USS.csv,other,"### Content  

More details about each file are in the individual file descriptions.  

### Context  

This is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  

* Update Frequency: This dataset is updated daily.



### Acknowledgements

This dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  

[Cover photo](https://unsplash.com/photos/5ELkI0KByF4) by [Matteo Catanese](https://unsplash.com/@matteocatanese) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv,True
Retail and Retailers Sales Time Series Collection,23,retail-and-retailers-sales-time-series-collection,MRTSSM44611USN.csv,other,"### Content  

More details about each file are in the individual file descriptions.  

### Context  

This is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  

* Update Frequency: This dataset is updated daily.



### Acknowledgements

This dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  

[Cover photo](https://unsplash.com/photos/5ELkI0KByF4) by [Matteo Catanese](https://unsplash.com/@matteocatanese) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv,True
Retail and Retailers Sales Time Series Collection,23,retail-and-retailers-sales-time-series-collection,MRTSSM442USS.csv,other,"### Content  

More details about each file are in the individual file descriptions.  

### Context  

This is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  

* Update Frequency: This dataset is updated daily.



### Acknowledgements

This dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  

[Cover photo](https://unsplash.com/photos/5ELkI0KByF4) by [Matteo Catanese](https://unsplash.com/@matteocatanese) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv,True
Retail and Retailers Sales Time Series Collection,23,retail-and-retailers-sales-time-series-collection,MRTSSM44111USN.csv,other,"### Content  

More details about each file are in the individual file descriptions.  

### Context  

This is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  

* Update Frequency: This dataset is updated daily.



### Acknowledgements

This dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  

[Cover photo](https://unsplash.com/photos/5ELkI0KByF4) by [Matteo Catanese](https://unsplash.com/@matteocatanese) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv,True
Retail and Retailers Sales Time Series Collection,23,retail-and-retailers-sales-time-series-collection,MRTSMPCSM4400CUSN.csv,other,"### Content  

More details about each file are in the individual file descriptions.  

### Context  

This is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  

* Update Frequency: This dataset is updated daily.



### Acknowledgements

This dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  

[Cover photo](https://unsplash.com/photos/5ELkI0KByF4) by [Matteo Catanese](https://unsplash.com/@matteocatanese) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv,True
S&P 500 Companies with Financial Information,2,s-and-p-500-companies-with-financial-information,constituents-financials_csv.csv,CC0-1.0,"This dataset provides comprehensive financial information for companies listed in the S&P 500 index. The dataset encompasses a range of fundamental financial metrics and attributes, making it a valuable resource for financial analysis, investment research, and market insights.

### **Features:**
<br>
**Symbol:** The unique stock symbol or ticker identifier for each S&P 500 company.

**Name:** The official name or full corporate title of each company.

**Sector:** The sector to which the company belongs, categorizing it into specific industry groups within the S&P 500.

**Price:** The current trading price of the company's stock.

**Price/Earnings**: The price-to-earnings (P/E) ratio, a key valuation metric, indicating the relationship between the stock's price and its earnings per share.

**Dividend Yield:** The dividend yield, representing the ratio of the annual dividend payment to the stock's current price.


**Earnings/Share:** The earnings per share (EPS), a measure of a company's profitability, calculated as earnings divided by the number of outstanding shares.

**52 Week Low:** The lowest price at which the stock has traded over the past 52 weeks.

**52 Week High:** The highest price at which the stock has traded over the past 52 weeks.

**Market Cap:** The total market capitalization of the company, representing the product of the stock's current price and the total number of outstanding shares.

**EBITDA:** Earnings before interest, taxes, depreciation, and amortization, a measure of a company's operating performance.

**Price/Sales:** The price-to-sales ratio, which compares the stock's price to the company's revenue per share.

**Price/Book:** The price-to-book (P/B) ratio, comparing the stock's price to its book value per share, an indicator of the stock's relative value.

**SEC Filings:** Information regarding the company's filings with the U.S. Securities and Exchange Commission (SEC), providing transparency and compliance data.",.csv,True
S&P 500 Companies with Financial Information,2,sp-500-companies-with-financial-information,financials.csv,ODC Public Domain Dedication and Licence (PDDL),"### Context

This is a comprehensive dataset including numerous financial metrics that many professionals and investing gurus often use to value companies. This data is a look at the companies that comprise the S&P 500 (Standard & Poor's 500). The S&P 500 is a capitalization-weighted index of the top 500 publicly traded companies in the United States (top 500 meaning the companies with the largest market cap). The S&P 500 index is a useful index to study because it generally reflects the health of the overall U.S. stock market. The dataset was last updated in July 2020.


### Content

There are 14 rows included in this dataset:
   ```
 - 4 character variables:
        - Symbol: Ticker symbol used to uniquely identify each company on a particular stock market
        - Name: Legal name of the company
        - Sector: An area of the economy where businesses share a related product or service
        - SEC Filings: Helpful documents relating to a company

    - 10 numeric variables:
        - Price: Price per share of the company
        - Price to Earnings (PE): The ratio of a company’s share price to its earnings per share
        - Dividend Yield: The ratio of the annual dividends per share divided by the price per share
        - Earnings Per Share (EPS): A company’s profit divided by the number of shares of its stock
        - 52 week high and low: The annual high and low of a company’s share price
        - Market Cap: The market value of a company’s shares (calculated as share price x number of shares)
        - EBITDA: A company’s earnings before interest, taxes, depreciation, and amortization; often used as a proxy for its profitability
        - Price to Sales (PS): A company’s market cap divided by its total sales or revenue over the past year
        - Price to Book (PB): A company’s price per share divided by its book value
```





### Acknowledgements

I found this data on the website datahub at https://datahub.io/core/s-and-p-500-companies-financials/r/1.html. All references and citations should be given to them.


### Inspiration

What useful information can you gleam from this dataset? Are these fundamentals enough to predict a high-quality company? How can you determine high from low quality? What would you liked to have seen in this dataset?",.csv,True
Salary Prediction Data - Simple linear regression,2,salary-prediction-data-simple-linear-regression,Salary_Data.csv,CC0-1.0,"Salary Dataset with two columns , We can do Salary prediction using Simple linear regression. It has also been used in Machine Learning A to Z course.

Columns
1. Years of Experience
2. Salary",.csv,True
Salary Prediction Data - Simple linear regression,2,salary-prediction-data-simple-linear-regression,Salary Data.csv,CC0-1.0,"Salary Dataset with two columns , We can do Salary prediction using Simple linear regression. It has also been used in Machine Learning A to Z course.

Columns
1. Years of Experience
2. Salary",.csv,True
Sales and Satisfaction,2,sales-and-satisfaction,Sales_with_NaNs_v1.3.csv,CC-BY-SA-4.0,"One dataset contains missing values (NaNs) and the other does not. These datasets contain information on sales and customer satisfaction before and after an intervention, as well as purchase data for control and treatment groups. The dataset is synthetic and was created for use in statistical analysis.

## Features

**Group**
   - **Description**: Indicates whether the data point belongs to the Control or Treatment group.
   - **Categories**: `Control`, `Treatment`

**Customer_Segment**
   - **Description**: Categorizes customers based on their value.
   - **Categories**: `High Value`, `Medium Value`, `Low Value`

**Sales_Before**
   - **Description**: Sales figures before the intervention.
   - **Data Type**: Numerical

**Sales_After**
   - **Description**: Sales figures after the intervention.
   - **Data Type**: Numerical

**Customer_Satisfaction_Before**
   - **Description**: Customer satisfaction scores before the intervention.
   - **Data Type**: Numerical

**Customer_Satisfaction_After**
   - **Description**: Customer satisfaction scores after the intervention.
   - **Data Type**: Numerical

**Purchase_Made**
   - **Description**: Indicates whether a purchase was made after the intervention.
   - **Categories**: `Yes`, `No`",.csv,True
Sales and Satisfaction,2,sales-and-satisfaction,Sales_without_NaNs_v1.3.csv,CC-BY-SA-4.0,"One dataset contains missing values (NaNs) and the other does not. These datasets contain information on sales and customer satisfaction before and after an intervention, as well as purchase data for control and treatment groups. The dataset is synthetic and was created for use in statistical analysis.

## Features

**Group**
   - **Description**: Indicates whether the data point belongs to the Control or Treatment group.
   - **Categories**: `Control`, `Treatment`

**Customer_Segment**
   - **Description**: Categorizes customers based on their value.
   - **Categories**: `High Value`, `Medium Value`, `Low Value`

**Sales_Before**
   - **Description**: Sales figures before the intervention.
   - **Data Type**: Numerical

**Sales_After**
   - **Description**: Sales figures after the intervention.
   - **Data Type**: Numerical

**Customer_Satisfaction_Before**
   - **Description**: Customer satisfaction scores before the intervention.
   - **Data Type**: Numerical

**Customer_Satisfaction_After**
   - **Description**: Customer satisfaction scores after the intervention.
   - **Data Type**: Numerical

**Purchase_Made**
   - **Description**: Indicates whether a purchase was made after the intervention.
   - **Categories**: `Yes`, `No`",.csv,True
Samsung Electronics Stock Historical Price ,3,samsung-electronics-stock-historical-price,005930.KS_monthly.csv,world-bank,"# Samsung Electronics Stock Historical Price (005930.KS)

#### from June 2019 until present

---

### ▶ Context 📝
The dataset is taken from [Yahoo Finance website](https://finance.yahoo.com/quote/005930.KS/history?p=005930.KS). It is about the historical stock price of Samsung Electronics Co., Ltd.

### ▶ Acknowledgements 🙏

I'd like to clarify that I'm only making data about the historical stock price of Samsung Electronics Co., Ltd. available to **Kaggle community**. 

### ▶ Inspiration 💭

- Forecasting stock price after June 2019
- Implementing machine learning models.
- Perform data analysis/data visualization of historical stock prices.

### ▶ Log 📰
- **11 November 2022**: The datasets version now is ***fully automated update*** using Deepnote. **Read more [here](https://deepnote.com/@mario-caesar/Auto-update-Kaggle-Datasets-using-Deepnote-99b73d05-540b-4d79-a4c2-6b15730a7d8f)**.
- **13 March 2022**: Adding weekly and monthly dataset.
- **19 August 2023**: Deepnote schedule run will be ***deprecated after August 2023***; Moving & updating script for update automation via **Kaggle API** using Kaggle schedule run.

---

📷 *Image by [Babak](https://unsplash.com/@babak20).*",.csv,True
Samsung Electronics Stock Historical Price ,3,samsung-electronics-stock-historical-price,005930.KS.csv,world-bank,"# Samsung Electronics Stock Historical Price (005930.KS)

#### from June 2019 until present

---

### ▶ Context 📝
The dataset is taken from [Yahoo Finance website](https://finance.yahoo.com/quote/005930.KS/history?p=005930.KS). It is about the historical stock price of Samsung Electronics Co., Ltd.

### ▶ Acknowledgements 🙏

I'd like to clarify that I'm only making data about the historical stock price of Samsung Electronics Co., Ltd. available to **Kaggle community**. 

### ▶ Inspiration 💭

- Forecasting stock price after June 2019
- Implementing machine learning models.
- Perform data analysis/data visualization of historical stock prices.

### ▶ Log 📰
- **11 November 2022**: The datasets version now is ***fully automated update*** using Deepnote. **Read more [here](https://deepnote.com/@mario-caesar/Auto-update-Kaggle-Datasets-using-Deepnote-99b73d05-540b-4d79-a4c2-6b15730a7d8f)**.
- **13 March 2022**: Adding weekly and monthly dataset.
- **19 August 2023**: Deepnote schedule run will be ***deprecated after August 2023***; Moving & updating script for update automation via **Kaggle API** using Kaggle schedule run.

---

📷 *Image by [Babak](https://unsplash.com/@babak20).*",.csv,True
Samsung Electronics Stock Historical Price ,3,samsung-electronics-stock-historical-price,005930.KS_weekly.csv,world-bank,"# Samsung Electronics Stock Historical Price (005930.KS)

#### from June 2019 until present

---

### ▶ Context 📝
The dataset is taken from [Yahoo Finance website](https://finance.yahoo.com/quote/005930.KS/history?p=005930.KS). It is about the historical stock price of Samsung Electronics Co., Ltd.

### ▶ Acknowledgements 🙏

I'd like to clarify that I'm only making data about the historical stock price of Samsung Electronics Co., Ltd. available to **Kaggle community**. 

### ▶ Inspiration 💭

- Forecasting stock price after June 2019
- Implementing machine learning models.
- Perform data analysis/data visualization of historical stock prices.

### ▶ Log 📰
- **11 November 2022**: The datasets version now is ***fully automated update*** using Deepnote. **Read more [here](https://deepnote.com/@mario-caesar/Auto-update-Kaggle-Datasets-using-Deepnote-99b73d05-540b-4d79-a4c2-6b15730a7d8f)**.
- **13 March 2022**: Adding weekly and monthly dataset.
- **19 August 2023**: Deepnote schedule run will be ***deprecated after August 2023***; Moving & updating script for update automation via **Kaggle API** using Kaggle schedule run.

---

📷 *Image by [Babak](https://unsplash.com/@babak20).*",.csv,True
Schengen Visa Stats 2017/2018,2,schengen-visa-stats,2017-data-for-consulates.csv,EU ODP Legal Notice,"### Context

I came across term of visa-shopping, where someone would apply in a specific consulate in order to have higher odds of getting the visa or getting a higher tier visa  in general. The idea itself seemed to have a lot of rumours around it and the only way to consider it a myth/reality is by doing proper analysis over real data. Luckily, the data is here.

### Content

*The xlsx files contains a lot of sheets, breakdown of them is below:*

The 'Data for consulates' sheet contains a complete set of visa statistics for all States fully applying the Schengen acquis* and their consulates in third countries. Data are presented in bulk but the filters included on the top row allow for refined searches (it is necessary to click on the small arrows). For instance, only the data for a particular Member State/Associated country can be searched, or the data concerning a given third country or a location (city) in a third country.
The subtotals for the chosen selection are presented at the bottom of the page (""Selection subtotal in 2018""), and below (""Total visas in 2018"") appear the general totals for all Member States/Associated countries in all locations.

The second sheet entitled 'Totals - Schengen State' presents basic total values disaggregated by Schengen States ordered alphabetically. On the top of the worksheet you can find a 'Country where consulate is located' field with a drop-down button which enables filtering total data for individual third countries. 

The next two sheets present all basic total data per Schengen State, ordered by visa applications or the number of visas issued, respectively. 

The 'Visas issued consulates + BCP' sheet contains a table summarising total numbers of C uniform visas issued by individual Schengen States both at the consulates and the border crossing points.
The sheet entitled ‘Totals by third country’ presents total figures for each third country, ordered by the number of visa applications. These can also be filtered by individual countries. 'ATV totals' sheet presents a summary of data on airport transit visas (ATV).

The final sheet contains contains data for three of the Member States not yet fully applying the Schengen acquis (Bulgaria, Croatia, Romania). Cyprus did not provide any data.
All data have been provided by the Schengen States (EU Member States and Associated countries), in accordance with the Visa Code, Article 46 and Annex XII.  The data on visas applied for at the consulates of Bulgaria, Croatia and Romania concern national visas.

Types of visas 
- Airport transit visas (ATVs)
This visa entitles the holder to transit through the international transit area of airports situated on the territory of a Member State without actually entering the territory of that Member State, during a stop-over or transfer between two stages of an international flight. ""A"" visas can be issued for a single airport transit or for multiple airport transits (Multiple A). 

- Short stay visas
a) Uniform short stay visas entitle the holder to stay in the territories of all Member States for a period of maximum 90 days/180 days. Such visas may be issued for the purpose of a single entry (""uniform visas"") or multiple entries (""MEVs ""). 
b) A short stay visa with limited territorial validity (""LTV"") entitles the holder to stay only in the territory of the Member State(s) for which the visa is valid.

* Austria, Belgium, Czech Republic, Denmark, Estonia, Finland, France, Germany, Greece, Hungary, Iceland, Italy, Latvia, Lithuania, Luxembourg, Malta, Netherlands, Norway, Poland, Portugal, Slovakia, Slovenia, Spain, Sweden and Switzerland. Liechtenstein does not issue its own Schengen visas and is therefore not listed.

### Acknowledgements

This data was made available by the European Commission.

### Inspiration

Which consulates in every country are more generous than others?
Which schengen states are more generous in general?
Which consulate is the most strict one?
.... and many more that can be acheived with this dataset.",.csv,True
Schengen Visa Stats 2017/2018,2,schengen-visa-stats,2018-data-for-consulates.csv,EU ODP Legal Notice,"### Context

I came across term of visa-shopping, where someone would apply in a specific consulate in order to have higher odds of getting the visa or getting a higher tier visa  in general. The idea itself seemed to have a lot of rumours around it and the only way to consider it a myth/reality is by doing proper analysis over real data. Luckily, the data is here.

### Content

*The xlsx files contains a lot of sheets, breakdown of them is below:*

The 'Data for consulates' sheet contains a complete set of visa statistics for all States fully applying the Schengen acquis* and their consulates in third countries. Data are presented in bulk but the filters included on the top row allow for refined searches (it is necessary to click on the small arrows). For instance, only the data for a particular Member State/Associated country can be searched, or the data concerning a given third country or a location (city) in a third country.
The subtotals for the chosen selection are presented at the bottom of the page (""Selection subtotal in 2018""), and below (""Total visas in 2018"") appear the general totals for all Member States/Associated countries in all locations.

The second sheet entitled 'Totals - Schengen State' presents basic total values disaggregated by Schengen States ordered alphabetically. On the top of the worksheet you can find a 'Country where consulate is located' field with a drop-down button which enables filtering total data for individual third countries. 

The next two sheets present all basic total data per Schengen State, ordered by visa applications or the number of visas issued, respectively. 

The 'Visas issued consulates + BCP' sheet contains a table summarising total numbers of C uniform visas issued by individual Schengen States both at the consulates and the border crossing points.
The sheet entitled ‘Totals by third country’ presents total figures for each third country, ordered by the number of visa applications. These can also be filtered by individual countries. 'ATV totals' sheet presents a summary of data on airport transit visas (ATV).

The final sheet contains contains data for three of the Member States not yet fully applying the Schengen acquis (Bulgaria, Croatia, Romania). Cyprus did not provide any data.
All data have been provided by the Schengen States (EU Member States and Associated countries), in accordance with the Visa Code, Article 46 and Annex XII.  The data on visas applied for at the consulates of Bulgaria, Croatia and Romania concern national visas.

Types of visas 
- Airport transit visas (ATVs)
This visa entitles the holder to transit through the international transit area of airports situated on the territory of a Member State without actually entering the territory of that Member State, during a stop-over or transfer between two stages of an international flight. ""A"" visas can be issued for a single airport transit or for multiple airport transits (Multiple A). 

- Short stay visas
a) Uniform short stay visas entitle the holder to stay in the territories of all Member States for a period of maximum 90 days/180 days. Such visas may be issued for the purpose of a single entry (""uniform visas"") or multiple entries (""MEVs ""). 
b) A short stay visa with limited territorial validity (""LTV"") entitles the holder to stay only in the territory of the Member State(s) for which the visa is valid.

* Austria, Belgium, Czech Republic, Denmark, Estonia, Finland, France, Germany, Greece, Hungary, Iceland, Italy, Latvia, Lithuania, Luxembourg, Malta, Netherlands, Norway, Poland, Portugal, Slovakia, Slovenia, Spain, Sweden and Switzerland. Liechtenstein does not issue its own Schengen visas and is therefore not listed.

### Acknowledgements

This data was made available by the European Commission.

### Inspiration

Which consulates in every country are more generous than others?
Which schengen states are more generous in general?
Which consulate is the most strict one?
.... and many more that can be acheived with this dataset.",.csv,True
Sentiment Analysis Evaluation Dataset,4,sentiment-analysis-evaluation-dataset,Politics.csv,other,"This is a synthetically curated dataset for sentiment analysis (Text-Classification). It contains 4 files pertaining to 4 different genres namely, Education, Finance, Politics, and Sports, each of which contain 2 columns:

1. Text: This column contains a snippet of text regarding that genre
2. Label: This column contains the expected sentiment of the text - Positive or Negative

This dataset is highly useful for tasks like creating text-classification LLMs, Fine-tuning pre-trained LLMs, and honing NLP skills using Logistic Regression, N-grams, Naive Bayes, RNN, etc.

Tip: You may map the Label Column to integer values to get insights about the data.",.csv,True
Sentiment Analysis Evaluation Dataset,4,sentiment-analysis-evaluation-dataset,Education.csv,other,"This is a synthetically curated dataset for sentiment analysis (Text-Classification). It contains 4 files pertaining to 4 different genres namely, Education, Finance, Politics, and Sports, each of which contain 2 columns:

1. Text: This column contains a snippet of text regarding that genre
2. Label: This column contains the expected sentiment of the text - Positive or Negative

This dataset is highly useful for tasks like creating text-classification LLMs, Fine-tuning pre-trained LLMs, and honing NLP skills using Logistic Regression, N-grams, Naive Bayes, RNN, etc.

Tip: You may map the Label Column to integer values to get insights about the data.",.csv,True
Sentiment Analysis Evaluation Dataset,4,sentiment-analysis-evaluation-dataset,Finance.csv,other,"This is a synthetically curated dataset for sentiment analysis (Text-Classification). It contains 4 files pertaining to 4 different genres namely, Education, Finance, Politics, and Sports, each of which contain 2 columns:

1. Text: This column contains a snippet of text regarding that genre
2. Label: This column contains the expected sentiment of the text - Positive or Negative

This dataset is highly useful for tasks like creating text-classification LLMs, Fine-tuning pre-trained LLMs, and honing NLP skills using Logistic Regression, N-grams, Naive Bayes, RNN, etc.

Tip: You may map the Label Column to integer values to get insights about the data.",.csv,True
Sentiment Analysis Evaluation Dataset,4,sentiment-analysis-evaluation-dataset,Sports.csv,other,"This is a synthetically curated dataset for sentiment analysis (Text-Classification). It contains 4 files pertaining to 4 different genres namely, Education, Finance, Politics, and Sports, each of which contain 2 columns:

1. Text: This column contains a snippet of text regarding that genre
2. Label: This column contains the expected sentiment of the text - Positive or Negative

This dataset is highly useful for tasks like creating text-classification LLMs, Fine-tuning pre-trained LLMs, and honing NLP skills using Logistic Regression, N-grams, Naive Bayes, RNN, etc.

Tip: You may map the Label Column to integer values to get insights about the data.",.csv,True
Social media popularity (2009 - 2023),2,social-media-popularity-2009-2023,social_media_2.csv,CC-BY-SA-3.0,"## Context
Social media are today a very popular way of exchanging information with other people via the Internet. It's hard not to notice that over the years new ones are created and old ones ""die"". The database below presents the popularity of various social networking sites since 2009, showing the percentage of their share in the social media market.

## Content
The database saved in .csv form contains several columns. The first column contains the date (YYYY-MM) of the measurement period. Each subsequent column contains the percentage of share in the social media market, given as a percentage, rounded to 2 decimal places (if the share is less than 0.5%, the value 0 remains, even though it may constitute a very small percentage of the share). We have almost 180 rows, 15 years of data for monthly periods.

## Source
The database comes from the [Statcounter](https://gs.statcounter.com/) and is made available in the operation with CC BY-SA 3.0 license which allows to copy, use and disseminate data also for commercial purposes after providing the source.",.csv,True
Social media popularity (2009 - 2023),2,social-media-popularity-2009-2023,social_media.csv,CC-BY-SA-3.0,"## Context
Social media are today a very popular way of exchanging information with other people via the Internet. It's hard not to notice that over the years new ones are created and old ones ""die"". The database below presents the popularity of various social networking sites since 2009, showing the percentage of their share in the social media market.

## Content
The database saved in .csv form contains several columns. The first column contains the date (YYYY-MM) of the measurement period. Each subsequent column contains the percentage of share in the social media market, given as a percentage, rounded to 2 decimal places (if the share is less than 0.5%, the value 0 remains, even though it may constitute a very small percentage of the share). We have almost 180 rows, 15 years of data for monthly periods.

## Source
The database comes from the [Statcounter](https://gs.statcounter.com/) and is made available in the operation with CC BY-SA 3.0 license which allows to copy, use and disseminate data also for commercial purposes after providing the source.",.csv,True
Solar Flare Dataset (2004-2005 and 2015-2016),3,solar-flare-dataset-2004-2005-and-2015-2016,rhessi_full2002_2018_filtered.csv,Apache 2.0,"Explore the radiant dynamics of our star with the ""Solar Flare Dataset"" from NASA research team, a curated collection of solar event data spanning more than a decade, from 2004 to 2016. This dataset is meticulously organized into three key segments for targeted analysis: the complete filtered dataset (df_filter) covering comprehensive records from 2005 to 2016, and two subset intervals highlighting specific biennial snapshots from 2004 to 2005 and 2015 to 2016. Each subset is designed to facilitate comparative studies across different solar cycles and intensities of solar activity. Researchers, astrophysicists, and data enthusiasts can delve into the intricacies of solar flare occurrences, examining patterns, frequencies, and magnitudes. Whether you aim to predict future solar phenomena, analyze the progression of solar cycles, or understand the impact of solar flares on space weather, this dataset provides a robust foundation for your investigative pursuits in the cosmic realm of solar events.",.csv,True
Solar Flare Dataset (2004-2005 and 2015-2016),3,solar-flare-dataset-2004-2005-and-2015-2016,Solar_flare_RHESSI_2015_16.csv,Apache 2.0,"Explore the radiant dynamics of our star with the ""Solar Flare Dataset"" from NASA research team, a curated collection of solar event data spanning more than a decade, from 2004 to 2016. This dataset is meticulously organized into three key segments for targeted analysis: the complete filtered dataset (df_filter) covering comprehensive records from 2005 to 2016, and two subset intervals highlighting specific biennial snapshots from 2004 to 2005 and 2015 to 2016. Each subset is designed to facilitate comparative studies across different solar cycles and intensities of solar activity. Researchers, astrophysicists, and data enthusiasts can delve into the intricacies of solar flare occurrences, examining patterns, frequencies, and magnitudes. Whether you aim to predict future solar phenomena, analyze the progression of solar cycles, or understand the impact of solar flares on space weather, this dataset provides a robust foundation for your investigative pursuits in the cosmic realm of solar events.",.csv,True
Solar Flare Dataset (2004-2005 and 2015-2016),3,solar-flare-dataset-2004-2005-and-2015-2016,Solar_flare_RHESSI_2004_05.csv,Apache 2.0,"Explore the radiant dynamics of our star with the ""Solar Flare Dataset"" from NASA research team, a curated collection of solar event data spanning more than a decade, from 2004 to 2016. This dataset is meticulously organized into three key segments for targeted analysis: the complete filtered dataset (df_filter) covering comprehensive records from 2005 to 2016, and two subset intervals highlighting specific biennial snapshots from 2004 to 2005 and 2015 to 2016. Each subset is designed to facilitate comparative studies across different solar cycles and intensities of solar activity. Researchers, astrophysicists, and data enthusiasts can delve into the intricacies of solar flare occurrences, examining patterns, frequencies, and magnitudes. Whether you aim to predict future solar phenomena, analyze the progression of solar cycles, or understand the impact of solar flares on space weather, this dataset provides a robust foundation for your investigative pursuits in the cosmic realm of solar events.",.csv,True
Spanish Stocks Historical Data from 2000 to 2019,27,spanish-stocks-historical-data,bankinter.csv,other,"## Introduction

Since [Investing.com](https://www.investing.com/) does not have an API, I decided to develop this Python package in order to retrieve historical data from the companies that integrate the Continuous Spanish Stock Market. So on, I decided to generate, via [**investpy**](https://github.com/abartt/investpy), the datasets for every company so that any Data Scientist or Data Enthusiastic can handle it and abstract their own conclusions and research. 

The main purpose of developing **investpy**, the package from which these datasets have been retrieved, was to use it as the Data Extraction tool for its namesake section, for my Final Degree Project at the University of Salamanca titled ""*Machine Learning for stock investment recommendation systems*"". The package end up being so consistent, reliable and usable that it is going to be used as the main Data Extraction tool by another students in their Final Degree Projects named ""*Recommender system of banking products*"" and ""*Robo-Advisor Application*"".

## License

[MIT License](https://github.com/abartt/investpy/blob/master/LICENSE)

## Additional Information

investpy, the Python package from which datasets were generated is currently in a development beta version, so please, if needed open an [issue](https://github.com/abartt/investpy/issues) to solve all the possible problems the package may be causing or any dataset error. Also, any new ideas or proposals are welcome, and will be gladly implemented in the package if the are positive and useful.

For further information or any question feel free to contact me via email at alvarob96@usal.es

You can also check my [Medium Publication](https://medium.com/research-studies-by-alvaro-bartolome), where I upload weekly posts related to Data Science and mainly on Data Extraction techniques via Web Scraping. In this case, you can read [""investpy — a Python package for historical data extraction from the Spanish stock market""](https://medium.com/research-studies-by-alvaro-bartolome/investpy-a-python-library-for-historical-data-extraction-from-the-spanish-stock-market-ad4d564dbfc5) where I explain the basics on [investpy](https://github.com/alvarobartt/investpy) development and some insights on **Web Scraping with Python**.

## Disclaimer

This Python Package has been made for research purposes in order to fit a needs that Investing.com does not cover, so this package works like an Application Programming Interface (API) of Investing.com developed in an altruistic way. Conclude that this package is not related in any way with Investing.com or any dependant company, the only requirement for developing this package was to mention the source where data is retrieved.",.csv,True
Spanish Stocks Historical Data from 2000 to 2019,27,spanish-stocks-historical-data,banco-sabadell.csv,other,"## Introduction

Since [Investing.com](https://www.investing.com/) does not have an API, I decided to develop this Python package in order to retrieve historical data from the companies that integrate the Continuous Spanish Stock Market. So on, I decided to generate, via [**investpy**](https://github.com/abartt/investpy), the datasets for every company so that any Data Scientist or Data Enthusiastic can handle it and abstract their own conclusions and research. 

The main purpose of developing **investpy**, the package from which these datasets have been retrieved, was to use it as the Data Extraction tool for its namesake section, for my Final Degree Project at the University of Salamanca titled ""*Machine Learning for stock investment recommendation systems*"". The package end up being so consistent, reliable and usable that it is going to be used as the main Data Extraction tool by another students in their Final Degree Projects named ""*Recommender system of banking products*"" and ""*Robo-Advisor Application*"".

## License

[MIT License](https://github.com/abartt/investpy/blob/master/LICENSE)

## Additional Information

investpy, the Python package from which datasets were generated is currently in a development beta version, so please, if needed open an [issue](https://github.com/abartt/investpy/issues) to solve all the possible problems the package may be causing or any dataset error. Also, any new ideas or proposals are welcome, and will be gladly implemented in the package if the are positive and useful.

For further information or any question feel free to contact me via email at alvarob96@usal.es

You can also check my [Medium Publication](https://medium.com/research-studies-by-alvaro-bartolome), where I upload weekly posts related to Data Science and mainly on Data Extraction techniques via Web Scraping. In this case, you can read [""investpy — a Python package for historical data extraction from the Spanish stock market""](https://medium.com/research-studies-by-alvaro-bartolome/investpy-a-python-library-for-historical-data-extraction-from-the-spanish-stock-market-ad4d564dbfc5) where I explain the basics on [investpy](https://github.com/alvarobartt/investpy) development and some insights on **Web Scraping with Python**.

## Disclaimer

This Python Package has been made for research purposes in order to fit a needs that Investing.com does not cover, so this package works like an Application Programming Interface (API) of Investing.com developed in an altruistic way. Conclude that this package is not related in any way with Investing.com or any dependant company, the only requirement for developing this package was to mention the source where data is retrieved.",.csv,True
Spanish Stocks Historical Data from 2000 to 2019,27,spanish-stocks-historical-data,inditex.csv,other,"## Introduction

Since [Investing.com](https://www.investing.com/) does not have an API, I decided to develop this Python package in order to retrieve historical data from the companies that integrate the Continuous Spanish Stock Market. So on, I decided to generate, via [**investpy**](https://github.com/abartt/investpy), the datasets for every company so that any Data Scientist or Data Enthusiastic can handle it and abstract their own conclusions and research. 

The main purpose of developing **investpy**, the package from which these datasets have been retrieved, was to use it as the Data Extraction tool for its namesake section, for my Final Degree Project at the University of Salamanca titled ""*Machine Learning for stock investment recommendation systems*"". The package end up being so consistent, reliable and usable that it is going to be used as the main Data Extraction tool by another students in their Final Degree Projects named ""*Recommender system of banking products*"" and ""*Robo-Advisor Application*"".

## License

[MIT License](https://github.com/abartt/investpy/blob/master/LICENSE)

## Additional Information

investpy, the Python package from which datasets were generated is currently in a development beta version, so please, if needed open an [issue](https://github.com/abartt/investpy/issues) to solve all the possible problems the package may be causing or any dataset error. Also, any new ideas or proposals are welcome, and will be gladly implemented in the package if the are positive and useful.

For further information or any question feel free to contact me via email at alvarob96@usal.es

You can also check my [Medium Publication](https://medium.com/research-studies-by-alvaro-bartolome), where I upload weekly posts related to Data Science and mainly on Data Extraction techniques via Web Scraping. In this case, you can read [""investpy — a Python package for historical data extraction from the Spanish stock market""](https://medium.com/research-studies-by-alvaro-bartolome/investpy-a-python-library-for-historical-data-extraction-from-the-spanish-stock-market-ad4d564dbfc5) where I explain the basics on [investpy](https://github.com/alvarobartt/investpy) development and some insights on **Web Scraping with Python**.

## Disclaimer

This Python Package has been made for research purposes in order to fit a needs that Investing.com does not cover, so this package works like an Application Programming Interface (API) of Investing.com developed in an altruistic way. Conclude that this package is not related in any way with Investing.com or any dependant company, the only requirement for developing this package was to mention the source where data is retrieved.",.csv,True
Spanish Stocks Historical Data from 2000 to 2019,27,spanish-stocks-historical-data,repsol.csv,other,"## Introduction

Since [Investing.com](https://www.investing.com/) does not have an API, I decided to develop this Python package in order to retrieve historical data from the companies that integrate the Continuous Spanish Stock Market. So on, I decided to generate, via [**investpy**](https://github.com/abartt/investpy), the datasets for every company so that any Data Scientist or Data Enthusiastic can handle it and abstract their own conclusions and research. 

The main purpose of developing **investpy**, the package from which these datasets have been retrieved, was to use it as the Data Extraction tool for its namesake section, for my Final Degree Project at the University of Salamanca titled ""*Machine Learning for stock investment recommendation systems*"". The package end up being so consistent, reliable and usable that it is going to be used as the main Data Extraction tool by another students in their Final Degree Projects named ""*Recommender system of banking products*"" and ""*Robo-Advisor Application*"".

## License

[MIT License](https://github.com/abartt/investpy/blob/master/LICENSE)

## Additional Information

investpy, the Python package from which datasets were generated is currently in a development beta version, so please, if needed open an [issue](https://github.com/abartt/investpy/issues) to solve all the possible problems the package may be causing or any dataset error. Also, any new ideas or proposals are welcome, and will be gladly implemented in the package if the are positive and useful.

For further information or any question feel free to contact me via email at alvarob96@usal.es

You can also check my [Medium Publication](https://medium.com/research-studies-by-alvaro-bartolome), where I upload weekly posts related to Data Science and mainly on Data Extraction techniques via Web Scraping. In this case, you can read [""investpy — a Python package for historical data extraction from the Spanish stock market""](https://medium.com/research-studies-by-alvaro-bartolome/investpy-a-python-library-for-historical-data-extraction-from-the-spanish-stock-market-ad4d564dbfc5) where I explain the basics on [investpy](https://github.com/alvarobartt/investpy) development and some insights on **Web Scraping with Python**.

## Disclaimer

This Python Package has been made for research purposes in order to fit a needs that Investing.com does not cover, so this package works like an Application Programming Interface (API) of Investing.com developed in an altruistic way. Conclude that this package is not related in any way with Investing.com or any dependant company, the only requirement for developing this package was to mention the source where data is retrieved.",.csv,True
Spanish Stocks Historical Data from 2000 to 2019,27,spanish-stocks-historical-data,ferrovial.csv,other,"## Introduction

Since [Investing.com](https://www.investing.com/) does not have an API, I decided to develop this Python package in order to retrieve historical data from the companies that integrate the Continuous Spanish Stock Market. So on, I decided to generate, via [**investpy**](https://github.com/abartt/investpy), the datasets for every company so that any Data Scientist or Data Enthusiastic can handle it and abstract their own conclusions and research. 

The main purpose of developing **investpy**, the package from which these datasets have been retrieved, was to use it as the Data Extraction tool for its namesake section, for my Final Degree Project at the University of Salamanca titled ""*Machine Learning for stock investment recommendation systems*"". The package end up being so consistent, reliable and usable that it is going to be used as the main Data Extraction tool by another students in their Final Degree Projects named ""*Recommender system of banking products*"" and ""*Robo-Advisor Application*"".

## License

[MIT License](https://github.com/abartt/investpy/blob/master/LICENSE)

## Additional Information

investpy, the Python package from which datasets were generated is currently in a development beta version, so please, if needed open an [issue](https://github.com/abartt/investpy/issues) to solve all the possible problems the package may be causing or any dataset error. Also, any new ideas or proposals are welcome, and will be gladly implemented in the package if the are positive and useful.

For further information or any question feel free to contact me via email at alvarob96@usal.es

You can also check my [Medium Publication](https://medium.com/research-studies-by-alvaro-bartolome), where I upload weekly posts related to Data Science and mainly on Data Extraction techniques via Web Scraping. In this case, you can read [""investpy — a Python package for historical data extraction from the Spanish stock market""](https://medium.com/research-studies-by-alvaro-bartolome/investpy-a-python-library-for-historical-data-extraction-from-the-spanish-stock-market-ad4d564dbfc5) where I explain the basics on [investpy](https://github.com/alvarobartt/investpy) development and some insights on **Web Scraping with Python**.

## Disclaimer

This Python Package has been made for research purposes in order to fit a needs that Investing.com does not cover, so this package works like an Application Programming Interface (API) of Investing.com developed in an altruistic way. Conclude that this package is not related in any way with Investing.com or any dependant company, the only requirement for developing this package was to mention the source where data is retrieved.",.csv,True
Spanish Stocks Historical Data from 2000 to 2019,27,spanish-stocks-historical-data,bme.csv,other,"## Introduction

Since [Investing.com](https://www.investing.com/) does not have an API, I decided to develop this Python package in order to retrieve historical data from the companies that integrate the Continuous Spanish Stock Market. So on, I decided to generate, via [**investpy**](https://github.com/abartt/investpy), the datasets for every company so that any Data Scientist or Data Enthusiastic can handle it and abstract their own conclusions and research. 

The main purpose of developing **investpy**, the package from which these datasets have been retrieved, was to use it as the Data Extraction tool for its namesake section, for my Final Degree Project at the University of Salamanca titled ""*Machine Learning for stock investment recommendation systems*"". The package end up being so consistent, reliable and usable that it is going to be used as the main Data Extraction tool by another students in their Final Degree Projects named ""*Recommender system of banking products*"" and ""*Robo-Advisor Application*"".

## License

[MIT License](https://github.com/abartt/investpy/blob/master/LICENSE)

## Additional Information

investpy, the Python package from which datasets were generated is currently in a development beta version, so please, if needed open an [issue](https://github.com/abartt/investpy/issues) to solve all the possible problems the package may be causing or any dataset error. Also, any new ideas or proposals are welcome, and will be gladly implemented in the package if the are positive and useful.

For further information or any question feel free to contact me via email at alvarob96@usal.es

You can also check my [Medium Publication](https://medium.com/research-studies-by-alvaro-bartolome), where I upload weekly posts related to Data Science and mainly on Data Extraction techniques via Web Scraping. In this case, you can read [""investpy — a Python package for historical data extraction from the Spanish stock market""](https://medium.com/research-studies-by-alvaro-bartolome/investpy-a-python-library-for-historical-data-extraction-from-the-spanish-stock-market-ad4d564dbfc5) where I explain the basics on [investpy](https://github.com/alvarobartt/investpy) development and some insights on **Web Scraping with Python**.

## Disclaimer

This Python Package has been made for research purposes in order to fit a needs that Investing.com does not cover, so this package works like an Application Programming Interface (API) of Investing.com developed in an altruistic way. Conclude that this package is not related in any way with Investing.com or any dependant company, the only requirement for developing this package was to mention the source where data is retrieved.",.csv,True
Spanish Stocks Historical Data from 2000 to 2019,27,spanish-stocks-historical-data,atresmedia.csv,other,"## Introduction

Since [Investing.com](https://www.investing.com/) does not have an API, I decided to develop this Python package in order to retrieve historical data from the companies that integrate the Continuous Spanish Stock Market. So on, I decided to generate, via [**investpy**](https://github.com/abartt/investpy), the datasets for every company so that any Data Scientist or Data Enthusiastic can handle it and abstract their own conclusions and research. 

The main purpose of developing **investpy**, the package from which these datasets have been retrieved, was to use it as the Data Extraction tool for its namesake section, for my Final Degree Project at the University of Salamanca titled ""*Machine Learning for stock investment recommendation systems*"". The package end up being so consistent, reliable and usable that it is going to be used as the main Data Extraction tool by another students in their Final Degree Projects named ""*Recommender system of banking products*"" and ""*Robo-Advisor Application*"".

## License

[MIT License](https://github.com/abartt/investpy/blob/master/LICENSE)

## Additional Information

investpy, the Python package from which datasets were generated is currently in a development beta version, so please, if needed open an [issue](https://github.com/abartt/investpy/issues) to solve all the possible problems the package may be causing or any dataset error. Also, any new ideas or proposals are welcome, and will be gladly implemented in the package if the are positive and useful.

For further information or any question feel free to contact me via email at alvarob96@usal.es

You can also check my [Medium Publication](https://medium.com/research-studies-by-alvaro-bartolome), where I upload weekly posts related to Data Science and mainly on Data Extraction techniques via Web Scraping. In this case, you can read [""investpy — a Python package for historical data extraction from the Spanish stock market""](https://medium.com/research-studies-by-alvaro-bartolome/investpy-a-python-library-for-historical-data-extraction-from-the-spanish-stock-market-ad4d564dbfc5) where I explain the basics on [investpy](https://github.com/alvarobartt/investpy) development and some insights on **Web Scraping with Python**.

## Disclaimer

This Python Package has been made for research purposes in order to fit a needs that Investing.com does not cover, so this package works like an Application Programming Interface (API) of Investing.com developed in an altruistic way. Conclude that this package is not related in any way with Investing.com or any dependant company, the only requirement for developing this package was to mention the source where data is retrieved.",.csv,True
Spanish Stocks Historical Data from 2000 to 2019,27,spanish-stocks-historical-data,telefnica.csv,other,"## Introduction

Since [Investing.com](https://www.investing.com/) does not have an API, I decided to develop this Python package in order to retrieve historical data from the companies that integrate the Continuous Spanish Stock Market. So on, I decided to generate, via [**investpy**](https://github.com/abartt/investpy), the datasets for every company so that any Data Scientist or Data Enthusiastic can handle it and abstract their own conclusions and research. 

The main purpose of developing **investpy**, the package from which these datasets have been retrieved, was to use it as the Data Extraction tool for its namesake section, for my Final Degree Project at the University of Salamanca titled ""*Machine Learning for stock investment recommendation systems*"". The package end up being so consistent, reliable and usable that it is going to be used as the main Data Extraction tool by another students in their Final Degree Projects named ""*Recommender system of banking products*"" and ""*Robo-Advisor Application*"".

## License

[MIT License](https://github.com/abartt/investpy/blob/master/LICENSE)

## Additional Information

investpy, the Python package from which datasets were generated is currently in a development beta version, so please, if needed open an [issue](https://github.com/abartt/investpy/issues) to solve all the possible problems the package may be causing or any dataset error. Also, any new ideas or proposals are welcome, and will be gladly implemented in the package if the are positive and useful.

For further information or any question feel free to contact me via email at alvarob96@usal.es

You can also check my [Medium Publication](https://medium.com/research-studies-by-alvaro-bartolome), where I upload weekly posts related to Data Science and mainly on Data Extraction techniques via Web Scraping. In this case, you can read [""investpy — a Python package for historical data extraction from the Spanish stock market""](https://medium.com/research-studies-by-alvaro-bartolome/investpy-a-python-library-for-historical-data-extraction-from-the-spanish-stock-market-ad4d564dbfc5) where I explain the basics on [investpy](https://github.com/alvarobartt/investpy) development and some insights on **Web Scraping with Python**.

## Disclaimer

This Python Package has been made for research purposes in order to fit a needs that Investing.com does not cover, so this package works like an Application Programming Interface (API) of Investing.com developed in an altruistic way. Conclude that this package is not related in any way with Investing.com or any dependant company, the only requirement for developing this package was to mention the source where data is retrieved.",.csv,True
Spanish Stocks Historical Data from 2000 to 2019,27,spanish-stocks-historical-data,naturgy-energy.csv,other,"## Introduction

Since [Investing.com](https://www.investing.com/) does not have an API, I decided to develop this Python package in order to retrieve historical data from the companies that integrate the Continuous Spanish Stock Market. So on, I decided to generate, via [**investpy**](https://github.com/abartt/investpy), the datasets for every company so that any Data Scientist or Data Enthusiastic can handle it and abstract their own conclusions and research. 

The main purpose of developing **investpy**, the package from which these datasets have been retrieved, was to use it as the Data Extraction tool for its namesake section, for my Final Degree Project at the University of Salamanca titled ""*Machine Learning for stock investment recommendation systems*"". The package end up being so consistent, reliable and usable that it is going to be used as the main Data Extraction tool by another students in their Final Degree Projects named ""*Recommender system of banking products*"" and ""*Robo-Advisor Application*"".

## License

[MIT License](https://github.com/abartt/investpy/blob/master/LICENSE)

## Additional Information

investpy, the Python package from which datasets were generated is currently in a development beta version, so please, if needed open an [issue](https://github.com/abartt/investpy/issues) to solve all the possible problems the package may be causing or any dataset error. Also, any new ideas or proposals are welcome, and will be gladly implemented in the package if the are positive and useful.

For further information or any question feel free to contact me via email at alvarob96@usal.es

You can also check my [Medium Publication](https://medium.com/research-studies-by-alvaro-bartolome), where I upload weekly posts related to Data Science and mainly on Data Extraction techniques via Web Scraping. In this case, you can read [""investpy — a Python package for historical data extraction from the Spanish stock market""](https://medium.com/research-studies-by-alvaro-bartolome/investpy-a-python-library-for-historical-data-extraction-from-the-spanish-stock-market-ad4d564dbfc5) where I explain the basics on [investpy](https://github.com/alvarobartt/investpy) development and some insights on **Web Scraping with Python**.

## Disclaimer

This Python Package has been made for research purposes in order to fit a needs that Investing.com does not cover, so this package works like an Application Programming Interface (API) of Investing.com developed in an altruistic way. Conclude that this package is not related in any way with Investing.com or any dependant company, the only requirement for developing this package was to mention the source where data is retrieved.",.csv,True
Spanish Stocks Historical Data from 2000 to 2019,27,spanish-stocks-historical-data,abengoa.csv,other,"## Introduction

Since [Investing.com](https://www.investing.com/) does not have an API, I decided to develop this Python package in order to retrieve historical data from the companies that integrate the Continuous Spanish Stock Market. So on, I decided to generate, via [**investpy**](https://github.com/abartt/investpy), the datasets for every company so that any Data Scientist or Data Enthusiastic can handle it and abstract their own conclusions and research. 

The main purpose of developing **investpy**, the package from which these datasets have been retrieved, was to use it as the Data Extraction tool for its namesake section, for my Final Degree Project at the University of Salamanca titled ""*Machine Learning for stock investment recommendation systems*"". The package end up being so consistent, reliable and usable that it is going to be used as the main Data Extraction tool by another students in their Final Degree Projects named ""*Recommender system of banking products*"" and ""*Robo-Advisor Application*"".

## License

[MIT License](https://github.com/abartt/investpy/blob/master/LICENSE)

## Additional Information

investpy, the Python package from which datasets were generated is currently in a development beta version, so please, if needed open an [issue](https://github.com/abartt/investpy/issues) to solve all the possible problems the package may be causing or any dataset error. Also, any new ideas or proposals are welcome, and will be gladly implemented in the package if the are positive and useful.

For further information or any question feel free to contact me via email at alvarob96@usal.es

You can also check my [Medium Publication](https://medium.com/research-studies-by-alvaro-bartolome), where I upload weekly posts related to Data Science and mainly on Data Extraction techniques via Web Scraping. In this case, you can read [""investpy — a Python package for historical data extraction from the Spanish stock market""](https://medium.com/research-studies-by-alvaro-bartolome/investpy-a-python-library-for-historical-data-extraction-from-the-spanish-stock-market-ad4d564dbfc5) where I explain the basics on [investpy](https://github.com/alvarobartt/investpy) development and some insights on **Web Scraping with Python**.

## Disclaimer

This Python Package has been made for research purposes in order to fit a needs that Investing.com does not cover, so this package works like an Application Programming Interface (API) of Investing.com developed in an altruistic way. Conclude that this package is not related in any way with Investing.com or any dependant company, the only requirement for developing this package was to mention the source where data is retrieved.",.csv,True
Spanish Stocks Historical Data from 2000 to 2019,27,spanish-stocks-historical-data,acerinox.csv,other,"## Introduction

Since [Investing.com](https://www.investing.com/) does not have an API, I decided to develop this Python package in order to retrieve historical data from the companies that integrate the Continuous Spanish Stock Market. So on, I decided to generate, via [**investpy**](https://github.com/abartt/investpy), the datasets for every company so that any Data Scientist or Data Enthusiastic can handle it and abstract their own conclusions and research. 

The main purpose of developing **investpy**, the package from which these datasets have been retrieved, was to use it as the Data Extraction tool for its namesake section, for my Final Degree Project at the University of Salamanca titled ""*Machine Learning for stock investment recommendation systems*"". The package end up being so consistent, reliable and usable that it is going to be used as the main Data Extraction tool by another students in their Final Degree Projects named ""*Recommender system of banking products*"" and ""*Robo-Advisor Application*"".

## License

[MIT License](https://github.com/abartt/investpy/blob/master/LICENSE)

## Additional Information

investpy, the Python package from which datasets were generated is currently in a development beta version, so please, if needed open an [issue](https://github.com/abartt/investpy/issues) to solve all the possible problems the package may be causing or any dataset error. Also, any new ideas or proposals are welcome, and will be gladly implemented in the package if the are positive and useful.

For further information or any question feel free to contact me via email at alvarob96@usal.es

You can also check my [Medium Publication](https://medium.com/research-studies-by-alvaro-bartolome), where I upload weekly posts related to Data Science and mainly on Data Extraction techniques via Web Scraping. In this case, you can read [""investpy — a Python package for historical data extraction from the Spanish stock market""](https://medium.com/research-studies-by-alvaro-bartolome/investpy-a-python-library-for-historical-data-extraction-from-the-spanish-stock-market-ad4d564dbfc5) where I explain the basics on [investpy](https://github.com/alvarobartt/investpy) development and some insights on **Web Scraping with Python**.

## Disclaimer

This Python Package has been made for research purposes in order to fit a needs that Investing.com does not cover, so this package works like an Application Programming Interface (API) of Investing.com developed in an altruistic way. Conclude that this package is not related in any way with Investing.com or any dependant company, the only requirement for developing this package was to mention the source where data is retrieved.",.csv,True
Spanish Stocks Historical Data from 2000 to 2019,27,spanish-stocks-historical-data,enags.csv,other,"## Introduction

Since [Investing.com](https://www.investing.com/) does not have an API, I decided to develop this Python package in order to retrieve historical data from the companies that integrate the Continuous Spanish Stock Market. So on, I decided to generate, via [**investpy**](https://github.com/abartt/investpy), the datasets for every company so that any Data Scientist or Data Enthusiastic can handle it and abstract their own conclusions and research. 

The main purpose of developing **investpy**, the package from which these datasets have been retrieved, was to use it as the Data Extraction tool for its namesake section, for my Final Degree Project at the University of Salamanca titled ""*Machine Learning for stock investment recommendation systems*"". The package end up being so consistent, reliable and usable that it is going to be used as the main Data Extraction tool by another students in their Final Degree Projects named ""*Recommender system of banking products*"" and ""*Robo-Advisor Application*"".

## License

[MIT License](https://github.com/abartt/investpy/blob/master/LICENSE)

## Additional Information

investpy, the Python package from which datasets were generated is currently in a development beta version, so please, if needed open an [issue](https://github.com/abartt/investpy/issues) to solve all the possible problems the package may be causing or any dataset error. Also, any new ideas or proposals are welcome, and will be gladly implemented in the package if the are positive and useful.

For further information or any question feel free to contact me via email at alvarob96@usal.es

You can also check my [Medium Publication](https://medium.com/research-studies-by-alvaro-bartolome), where I upload weekly posts related to Data Science and mainly on Data Extraction techniques via Web Scraping. In this case, you can read [""investpy — a Python package for historical data extraction from the Spanish stock market""](https://medium.com/research-studies-by-alvaro-bartolome/investpy-a-python-library-for-historical-data-extraction-from-the-spanish-stock-market-ad4d564dbfc5) where I explain the basics on [investpy](https://github.com/alvarobartt/investpy) development and some insights on **Web Scraping with Python**.

## Disclaimer

This Python Package has been made for research purposes in order to fit a needs that Investing.com does not cover, so this package works like an Application Programming Interface (API) of Investing.com developed in an altruistic way. Conclude that this package is not related in any way with Investing.com or any dependant company, the only requirement for developing this package was to mention the source where data is retrieved.",.csv,True
Spanish Stocks Historical Data from 2000 to 2019,27,spanish-stocks-historical-data,iberdrola.csv,other,"## Introduction

Since [Investing.com](https://www.investing.com/) does not have an API, I decided to develop this Python package in order to retrieve historical data from the companies that integrate the Continuous Spanish Stock Market. So on, I decided to generate, via [**investpy**](https://github.com/abartt/investpy), the datasets for every company so that any Data Scientist or Data Enthusiastic can handle it and abstract their own conclusions and research. 

The main purpose of developing **investpy**, the package from which these datasets have been retrieved, was to use it as the Data Extraction tool for its namesake section, for my Final Degree Project at the University of Salamanca titled ""*Machine Learning for stock investment recommendation systems*"". The package end up being so consistent, reliable and usable that it is going to be used as the main Data Extraction tool by another students in their Final Degree Projects named ""*Recommender system of banking products*"" and ""*Robo-Advisor Application*"".

## License

[MIT License](https://github.com/abartt/investpy/blob/master/LICENSE)

## Additional Information

investpy, the Python package from which datasets were generated is currently in a development beta version, so please, if needed open an [issue](https://github.com/abartt/investpy/issues) to solve all the possible problems the package may be causing or any dataset error. Also, any new ideas or proposals are welcome, and will be gladly implemented in the package if the are positive and useful.

For further information or any question feel free to contact me via email at alvarob96@usal.es

You can also check my [Medium Publication](https://medium.com/research-studies-by-alvaro-bartolome), where I upload weekly posts related to Data Science and mainly on Data Extraction techniques via Web Scraping. In this case, you can read [""investpy — a Python package for historical data extraction from the Spanish stock market""](https://medium.com/research-studies-by-alvaro-bartolome/investpy-a-python-library-for-historical-data-extraction-from-the-spanish-stock-market-ad4d564dbfc5) where I explain the basics on [investpy](https://github.com/alvarobartt/investpy) development and some insights on **Web Scraping with Python**.

## Disclaimer

This Python Package has been made for research purposes in order to fit a needs that Investing.com does not cover, so this package works like an Application Programming Interface (API) of Investing.com developed in an altruistic way. Conclude that this package is not related in any way with Investing.com or any dependant company, the only requirement for developing this package was to mention the source where data is retrieved.",.csv,True
Spanish Stocks Historical Data from 2000 to 2019,27,spanish-stocks-historical-data,grifols.csv,other,"## Introduction

Since [Investing.com](https://www.investing.com/) does not have an API, I decided to develop this Python package in order to retrieve historical data from the companies that integrate the Continuous Spanish Stock Market. So on, I decided to generate, via [**investpy**](https://github.com/abartt/investpy), the datasets for every company so that any Data Scientist or Data Enthusiastic can handle it and abstract their own conclusions and research. 

The main purpose of developing **investpy**, the package from which these datasets have been retrieved, was to use it as the Data Extraction tool for its namesake section, for my Final Degree Project at the University of Salamanca titled ""*Machine Learning for stock investment recommendation systems*"". The package end up being so consistent, reliable and usable that it is going to be used as the main Data Extraction tool by another students in their Final Degree Projects named ""*Recommender system of banking products*"" and ""*Robo-Advisor Application*"".

## License

[MIT License](https://github.com/abartt/investpy/blob/master/LICENSE)

## Additional Information

investpy, the Python package from which datasets were generated is currently in a development beta version, so please, if needed open an [issue](https://github.com/abartt/investpy/issues) to solve all the possible problems the package may be causing or any dataset error. Also, any new ideas or proposals are welcome, and will be gladly implemented in the package if the are positive and useful.

For further information or any question feel free to contact me via email at alvarob96@usal.es

You can also check my [Medium Publication](https://medium.com/research-studies-by-alvaro-bartolome), where I upload weekly posts related to Data Science and mainly on Data Extraction techniques via Web Scraping. In this case, you can read [""investpy — a Python package for historical data extraction from the Spanish stock market""](https://medium.com/research-studies-by-alvaro-bartolome/investpy-a-python-library-for-historical-data-extraction-from-the-spanish-stock-market-ad4d564dbfc5) where I explain the basics on [investpy](https://github.com/alvarobartt/investpy) development and some insights on **Web Scraping with Python**.

## Disclaimer

This Python Package has been made for research purposes in order to fit a needs that Investing.com does not cover, so this package works like an Application Programming Interface (API) of Investing.com developed in an altruistic way. Conclude that this package is not related in any way with Investing.com or any dependant company, the only requirement for developing this package was to mention the source where data is retrieved.",.csv,True
Spanish Stocks Historical Data from 2000 to 2019,27,spanish-stocks-historical-data,mapfre.csv,other,"## Introduction

Since [Investing.com](https://www.investing.com/) does not have an API, I decided to develop this Python package in order to retrieve historical data from the companies that integrate the Continuous Spanish Stock Market. So on, I decided to generate, via [**investpy**](https://github.com/abartt/investpy), the datasets for every company so that any Data Scientist or Data Enthusiastic can handle it and abstract their own conclusions and research. 

The main purpose of developing **investpy**, the package from which these datasets have been retrieved, was to use it as the Data Extraction tool for its namesake section, for my Final Degree Project at the University of Salamanca titled ""*Machine Learning for stock investment recommendation systems*"". The package end up being so consistent, reliable and usable that it is going to be used as the main Data Extraction tool by another students in their Final Degree Projects named ""*Recommender system of banking products*"" and ""*Robo-Advisor Application*"".

## License

[MIT License](https://github.com/abartt/investpy/blob/master/LICENSE)

## Additional Information

investpy, the Python package from which datasets were generated is currently in a development beta version, so please, if needed open an [issue](https://github.com/abartt/investpy/issues) to solve all the possible problems the package may be causing or any dataset error. Also, any new ideas or proposals are welcome, and will be gladly implemented in the package if the are positive and useful.

For further information or any question feel free to contact me via email at alvarob96@usal.es

You can also check my [Medium Publication](https://medium.com/research-studies-by-alvaro-bartolome), where I upload weekly posts related to Data Science and mainly on Data Extraction techniques via Web Scraping. In this case, you can read [""investpy — a Python package for historical data extraction from the Spanish stock market""](https://medium.com/research-studies-by-alvaro-bartolome/investpy-a-python-library-for-historical-data-extraction-from-the-spanish-stock-market-ad4d564dbfc5) where I explain the basics on [investpy](https://github.com/alvarobartt/investpy) development and some insights on **Web Scraping with Python**.

## Disclaimer

This Python Package has been made for research purposes in order to fit a needs that Investing.com does not cover, so this package works like an Application Programming Interface (API) of Investing.com developed in an altruistic way. Conclude that this package is not related in any way with Investing.com or any dependant company, the only requirement for developing this package was to mention the source where data is retrieved.",.csv,True
Spanish Stocks Historical Data from 2000 to 2019,27,spanish-stocks-historical-data,santander.csv,other,"## Introduction

Since [Investing.com](https://www.investing.com/) does not have an API, I decided to develop this Python package in order to retrieve historical data from the companies that integrate the Continuous Spanish Stock Market. So on, I decided to generate, via [**investpy**](https://github.com/abartt/investpy), the datasets for every company so that any Data Scientist or Data Enthusiastic can handle it and abstract their own conclusions and research. 

The main purpose of developing **investpy**, the package from which these datasets have been retrieved, was to use it as the Data Extraction tool for its namesake section, for my Final Degree Project at the University of Salamanca titled ""*Machine Learning for stock investment recommendation systems*"". The package end up being so consistent, reliable and usable that it is going to be used as the main Data Extraction tool by another students in their Final Degree Projects named ""*Recommender system of banking products*"" and ""*Robo-Advisor Application*"".

## License

[MIT License](https://github.com/abartt/investpy/blob/master/LICENSE)

## Additional Information

investpy, the Python package from which datasets were generated is currently in a development beta version, so please, if needed open an [issue](https://github.com/abartt/investpy/issues) to solve all the possible problems the package may be causing or any dataset error. Also, any new ideas or proposals are welcome, and will be gladly implemented in the package if the are positive and useful.

For further information or any question feel free to contact me via email at alvarob96@usal.es

You can also check my [Medium Publication](https://medium.com/research-studies-by-alvaro-bartolome), where I upload weekly posts related to Data Science and mainly on Data Extraction techniques via Web Scraping. In this case, you can read [""investpy — a Python package for historical data extraction from the Spanish stock market""](https://medium.com/research-studies-by-alvaro-bartolome/investpy-a-python-library-for-historical-data-extraction-from-the-spanish-stock-market-ad4d564dbfc5) where I explain the basics on [investpy](https://github.com/alvarobartt/investpy) development and some insights on **Web Scraping with Python**.

## Disclaimer

This Python Package has been made for research purposes in order to fit a needs that Investing.com does not cover, so this package works like an Application Programming Interface (API) of Investing.com developed in an altruistic way. Conclude that this package is not related in any way with Investing.com or any dependant company, the only requirement for developing this package was to mention the source where data is retrieved.",.csv,True
Spanish Stocks Historical Data from 2000 to 2019,27,spanish-stocks-historical-data,colonial.csv,other,"## Introduction

Since [Investing.com](https://www.investing.com/) does not have an API, I decided to develop this Python package in order to retrieve historical data from the companies that integrate the Continuous Spanish Stock Market. So on, I decided to generate, via [**investpy**](https://github.com/abartt/investpy), the datasets for every company so that any Data Scientist or Data Enthusiastic can handle it and abstract their own conclusions and research. 

The main purpose of developing **investpy**, the package from which these datasets have been retrieved, was to use it as the Data Extraction tool for its namesake section, for my Final Degree Project at the University of Salamanca titled ""*Machine Learning for stock investment recommendation systems*"". The package end up being so consistent, reliable and usable that it is going to be used as the main Data Extraction tool by another students in their Final Degree Projects named ""*Recommender system of banking products*"" and ""*Robo-Advisor Application*"".

## License

[MIT License](https://github.com/abartt/investpy/blob/master/LICENSE)

## Additional Information

investpy, the Python package from which datasets were generated is currently in a development beta version, so please, if needed open an [issue](https://github.com/abartt/investpy/issues) to solve all the possible problems the package may be causing or any dataset error. Also, any new ideas or proposals are welcome, and will be gladly implemented in the package if the are positive and useful.

For further information or any question feel free to contact me via email at alvarob96@usal.es

You can also check my [Medium Publication](https://medium.com/research-studies-by-alvaro-bartolome), where I upload weekly posts related to Data Science and mainly on Data Extraction techniques via Web Scraping. In this case, you can read [""investpy — a Python package for historical data extraction from the Spanish stock market""](https://medium.com/research-studies-by-alvaro-bartolome/investpy-a-python-library-for-historical-data-extraction-from-the-spanish-stock-market-ad4d564dbfc5) where I explain the basics on [investpy](https://github.com/alvarobartt/investpy) development and some insights on **Web Scraping with Python**.

## Disclaimer

This Python Package has been made for research purposes in order to fit a needs that Investing.com does not cover, so this package works like an Application Programming Interface (API) of Investing.com developed in an altruistic way. Conclude that this package is not related in any way with Investing.com or any dependant company, the only requirement for developing this package was to mention the source where data is retrieved.",.csv,True
Spanish Stocks Historical Data from 2000 to 2019,27,spanish-stocks-historical-data,mediaset.csv,other,"## Introduction

Since [Investing.com](https://www.investing.com/) does not have an API, I decided to develop this Python package in order to retrieve historical data from the companies that integrate the Continuous Spanish Stock Market. So on, I decided to generate, via [**investpy**](https://github.com/abartt/investpy), the datasets for every company so that any Data Scientist or Data Enthusiastic can handle it and abstract their own conclusions and research. 

The main purpose of developing **investpy**, the package from which these datasets have been retrieved, was to use it as the Data Extraction tool for its namesake section, for my Final Degree Project at the University of Salamanca titled ""*Machine Learning for stock investment recommendation systems*"". The package end up being so consistent, reliable and usable that it is going to be used as the main Data Extraction tool by another students in their Final Degree Projects named ""*Recommender system of banking products*"" and ""*Robo-Advisor Application*"".

## License

[MIT License](https://github.com/abartt/investpy/blob/master/LICENSE)

## Additional Information

investpy, the Python package from which datasets were generated is currently in a development beta version, so please, if needed open an [issue](https://github.com/abartt/investpy/issues) to solve all the possible problems the package may be causing or any dataset error. Also, any new ideas or proposals are welcome, and will be gladly implemented in the package if the are positive and useful.

For further information or any question feel free to contact me via email at alvarob96@usal.es

You can also check my [Medium Publication](https://medium.com/research-studies-by-alvaro-bartolome), where I upload weekly posts related to Data Science and mainly on Data Extraction techniques via Web Scraping. In this case, you can read [""investpy — a Python package for historical data extraction from the Spanish stock market""](https://medium.com/research-studies-by-alvaro-bartolome/investpy-a-python-library-for-historical-data-extraction-from-the-spanish-stock-market-ad4d564dbfc5) where I explain the basics on [investpy](https://github.com/alvarobartt/investpy) development and some insights on **Web Scraping with Python**.

## Disclaimer

This Python Package has been made for research purposes in order to fit a needs that Investing.com does not cover, so this package works like an Application Programming Interface (API) of Investing.com developed in an altruistic way. Conclude that this package is not related in any way with Investing.com or any dependant company, the only requirement for developing this package was to mention the source where data is retrieved.",.csv,True
Spanish Stocks Historical Data from 2000 to 2019,27,spanish-stocks-historical-data,bbva.csv,other,"## Introduction

Since [Investing.com](https://www.investing.com/) does not have an API, I decided to develop this Python package in order to retrieve historical data from the companies that integrate the Continuous Spanish Stock Market. So on, I decided to generate, via [**investpy**](https://github.com/abartt/investpy), the datasets for every company so that any Data Scientist or Data Enthusiastic can handle it and abstract their own conclusions and research. 

The main purpose of developing **investpy**, the package from which these datasets have been retrieved, was to use it as the Data Extraction tool for its namesake section, for my Final Degree Project at the University of Salamanca titled ""*Machine Learning for stock investment recommendation systems*"". The package end up being so consistent, reliable and usable that it is going to be used as the main Data Extraction tool by another students in their Final Degree Projects named ""*Recommender system of banking products*"" and ""*Robo-Advisor Application*"".

## License

[MIT License](https://github.com/abartt/investpy/blob/master/LICENSE)

## Additional Information

investpy, the Python package from which datasets were generated is currently in a development beta version, so please, if needed open an [issue](https://github.com/abartt/investpy/issues) to solve all the possible problems the package may be causing or any dataset error. Also, any new ideas or proposals are welcome, and will be gladly implemented in the package if the are positive and useful.

For further information or any question feel free to contact me via email at alvarob96@usal.es

You can also check my [Medium Publication](https://medium.com/research-studies-by-alvaro-bartolome), where I upload weekly posts related to Data Science and mainly on Data Extraction techniques via Web Scraping. In this case, you can read [""investpy — a Python package for historical data extraction from the Spanish stock market""](https://medium.com/research-studies-by-alvaro-bartolome/investpy-a-python-library-for-historical-data-extraction-from-the-spanish-stock-market-ad4d564dbfc5) where I explain the basics on [investpy](https://github.com/alvarobartt/investpy) development and some insights on **Web Scraping with Python**.

## Disclaimer

This Python Package has been made for research purposes in order to fit a needs that Investing.com does not cover, so this package works like an Application Programming Interface (API) of Investing.com developed in an altruistic way. Conclude that this package is not related in any way with Investing.com or any dependant company, the only requirement for developing this package was to mention the source where data is retrieved.",.csv,True
Spanish Stocks Historical Data from 2000 to 2019,27,spanish-stocks-historical-data,acciona.csv,other,"## Introduction

Since [Investing.com](https://www.investing.com/) does not have an API, I decided to develop this Python package in order to retrieve historical data from the companies that integrate the Continuous Spanish Stock Market. So on, I decided to generate, via [**investpy**](https://github.com/abartt/investpy), the datasets for every company so that any Data Scientist or Data Enthusiastic can handle it and abstract their own conclusions and research. 

The main purpose of developing **investpy**, the package from which these datasets have been retrieved, was to use it as the Data Extraction tool for its namesake section, for my Final Degree Project at the University of Salamanca titled ""*Machine Learning for stock investment recommendation systems*"". The package end up being so consistent, reliable and usable that it is going to be used as the main Data Extraction tool by another students in their Final Degree Projects named ""*Recommender system of banking products*"" and ""*Robo-Advisor Application*"".

## License

[MIT License](https://github.com/abartt/investpy/blob/master/LICENSE)

## Additional Information

investpy, the Python package from which datasets were generated is currently in a development beta version, so please, if needed open an [issue](https://github.com/abartt/investpy/issues) to solve all the possible problems the package may be causing or any dataset error. Also, any new ideas or proposals are welcome, and will be gladly implemented in the package if the are positive and useful.

For further information or any question feel free to contact me via email at alvarob96@usal.es

You can also check my [Medium Publication](https://medium.com/research-studies-by-alvaro-bartolome), where I upload weekly posts related to Data Science and mainly on Data Extraction techniques via Web Scraping. In this case, you can read [""investpy — a Python package for historical data extraction from the Spanish stock market""](https://medium.com/research-studies-by-alvaro-bartolome/investpy-a-python-library-for-historical-data-extraction-from-the-spanish-stock-market-ad4d564dbfc5) where I explain the basics on [investpy](https://github.com/alvarobartt/investpy) development and some insights on **Web Scraping with Python**.

## Disclaimer

This Python Package has been made for research purposes in order to fit a needs that Investing.com does not cover, so this package works like an Application Programming Interface (API) of Investing.com developed in an altruistic way. Conclude that this package is not related in any way with Investing.com or any dependant company, the only requirement for developing this package was to mention the source where data is retrieved.",.csv,True
Spanish Stocks Historical Data from 2000 to 2019,27,spanish-stocks-historical-data,acs.csv,other,"## Introduction

Since [Investing.com](https://www.investing.com/) does not have an API, I decided to develop this Python package in order to retrieve historical data from the companies that integrate the Continuous Spanish Stock Market. So on, I decided to generate, via [**investpy**](https://github.com/abartt/investpy), the datasets for every company so that any Data Scientist or Data Enthusiastic can handle it and abstract their own conclusions and research. 

The main purpose of developing **investpy**, the package from which these datasets have been retrieved, was to use it as the Data Extraction tool for its namesake section, for my Final Degree Project at the University of Salamanca titled ""*Machine Learning for stock investment recommendation systems*"". The package end up being so consistent, reliable and usable that it is going to be used as the main Data Extraction tool by another students in their Final Degree Projects named ""*Recommender system of banking products*"" and ""*Robo-Advisor Application*"".

## License

[MIT License](https://github.com/abartt/investpy/blob/master/LICENSE)

## Additional Information

investpy, the Python package from which datasets were generated is currently in a development beta version, so please, if needed open an [issue](https://github.com/abartt/investpy/issues) to solve all the possible problems the package may be causing or any dataset error. Also, any new ideas or proposals are welcome, and will be gladly implemented in the package if the are positive and useful.

For further information or any question feel free to contact me via email at alvarob96@usal.es

You can also check my [Medium Publication](https://medium.com/research-studies-by-alvaro-bartolome), where I upload weekly posts related to Data Science and mainly on Data Extraction techniques via Web Scraping. In this case, you can read [""investpy — a Python package for historical data extraction from the Spanish stock market""](https://medium.com/research-studies-by-alvaro-bartolome/investpy-a-python-library-for-historical-data-extraction-from-the-spanish-stock-market-ad4d564dbfc5) where I explain the basics on [investpy](https://github.com/alvarobartt/investpy) development and some insights on **Web Scraping with Python**.

## Disclaimer

This Python Package has been made for research purposes in order to fit a needs that Investing.com does not cover, so this package works like an Application Programming Interface (API) of Investing.com developed in an altruistic way. Conclude that this package is not related in any way with Investing.com or any dependant company, the only requirement for developing this package was to mention the source where data is retrieved.",.csv,True
Spanish Stocks Historical Data from 2000 to 2019,27,spanish-stocks-historical-data,caixabank.csv,other,"## Introduction

Since [Investing.com](https://www.investing.com/) does not have an API, I decided to develop this Python package in order to retrieve historical data from the companies that integrate the Continuous Spanish Stock Market. So on, I decided to generate, via [**investpy**](https://github.com/abartt/investpy), the datasets for every company so that any Data Scientist or Data Enthusiastic can handle it and abstract their own conclusions and research. 

The main purpose of developing **investpy**, the package from which these datasets have been retrieved, was to use it as the Data Extraction tool for its namesake section, for my Final Degree Project at the University of Salamanca titled ""*Machine Learning for stock investment recommendation systems*"". The package end up being so consistent, reliable and usable that it is going to be used as the main Data Extraction tool by another students in their Final Degree Projects named ""*Recommender system of banking products*"" and ""*Robo-Advisor Application*"".

## License

[MIT License](https://github.com/abartt/investpy/blob/master/LICENSE)

## Additional Information

investpy, the Python package from which datasets were generated is currently in a development beta version, so please, if needed open an [issue](https://github.com/abartt/investpy/issues) to solve all the possible problems the package may be causing or any dataset error. Also, any new ideas or proposals are welcome, and will be gladly implemented in the package if the are positive and useful.

For further information or any question feel free to contact me via email at alvarob96@usal.es

You can also check my [Medium Publication](https://medium.com/research-studies-by-alvaro-bartolome), where I upload weekly posts related to Data Science and mainly on Data Extraction techniques via Web Scraping. In this case, you can read [""investpy — a Python package for historical data extraction from the Spanish stock market""](https://medium.com/research-studies-by-alvaro-bartolome/investpy-a-python-library-for-historical-data-extraction-from-the-spanish-stock-market-ad4d564dbfc5) where I explain the basics on [investpy](https://github.com/alvarobartt/investpy) development and some insights on **Web Scraping with Python**.

## Disclaimer

This Python Package has been made for research purposes in order to fit a needs that Investing.com does not cover, so this package works like an Application Programming Interface (API) of Investing.com developed in an altruistic way. Conclude that this package is not related in any way with Investing.com or any dependant company, the only requirement for developing this package was to mention the source where data is retrieved.",.csv,True
Spanish Stocks Historical Data from 2000 to 2019,27,spanish-stocks-historical-data,indra.csv,other,"## Introduction

Since [Investing.com](https://www.investing.com/) does not have an API, I decided to develop this Python package in order to retrieve historical data from the companies that integrate the Continuous Spanish Stock Market. So on, I decided to generate, via [**investpy**](https://github.com/abartt/investpy), the datasets for every company so that any Data Scientist or Data Enthusiastic can handle it and abstract their own conclusions and research. 

The main purpose of developing **investpy**, the package from which these datasets have been retrieved, was to use it as the Data Extraction tool for its namesake section, for my Final Degree Project at the University of Salamanca titled ""*Machine Learning for stock investment recommendation systems*"". The package end up being so consistent, reliable and usable that it is going to be used as the main Data Extraction tool by another students in their Final Degree Projects named ""*Recommender system of banking products*"" and ""*Robo-Advisor Application*"".

## License

[MIT License](https://github.com/abartt/investpy/blob/master/LICENSE)

## Additional Information

investpy, the Python package from which datasets were generated is currently in a development beta version, so please, if needed open an [issue](https://github.com/abartt/investpy/issues) to solve all the possible problems the package may be causing or any dataset error. Also, any new ideas or proposals are welcome, and will be gladly implemented in the package if the are positive and useful.

For further information or any question feel free to contact me via email at alvarob96@usal.es

You can also check my [Medium Publication](https://medium.com/research-studies-by-alvaro-bartolome), where I upload weekly posts related to Data Science and mainly on Data Extraction techniques via Web Scraping. In this case, you can read [""investpy — a Python package for historical data extraction from the Spanish stock market""](https://medium.com/research-studies-by-alvaro-bartolome/investpy-a-python-library-for-historical-data-extraction-from-the-spanish-stock-market-ad4d564dbfc5) where I explain the basics on [investpy](https://github.com/alvarobartt/investpy) development and some insights on **Web Scraping with Python**.

## Disclaimer

This Python Package has been made for research purposes in order to fit a needs that Investing.com does not cover, so this package works like an Application Programming Interface (API) of Investing.com developed in an altruistic way. Conclude that this package is not related in any way with Investing.com or any dependant company, the only requirement for developing this package was to mention the source where data is retrieved.",.csv,True
Spanish Stocks Historical Data from 2000 to 2019,27,spanish-stocks-historical-data,siemens-gamesa.csv,other,"## Introduction

Since [Investing.com](https://www.investing.com/) does not have an API, I decided to develop this Python package in order to retrieve historical data from the companies that integrate the Continuous Spanish Stock Market. So on, I decided to generate, via [**investpy**](https://github.com/abartt/investpy), the datasets for every company so that any Data Scientist or Data Enthusiastic can handle it and abstract their own conclusions and research. 

The main purpose of developing **investpy**, the package from which these datasets have been retrieved, was to use it as the Data Extraction tool for its namesake section, for my Final Degree Project at the University of Salamanca titled ""*Machine Learning for stock investment recommendation systems*"". The package end up being so consistent, reliable and usable that it is going to be used as the main Data Extraction tool by another students in their Final Degree Projects named ""*Recommender system of banking products*"" and ""*Robo-Advisor Application*"".

## License

[MIT License](https://github.com/abartt/investpy/blob/master/LICENSE)

## Additional Information

investpy, the Python package from which datasets were generated is currently in a development beta version, so please, if needed open an [issue](https://github.com/abartt/investpy/issues) to solve all the possible problems the package may be causing or any dataset error. Also, any new ideas or proposals are welcome, and will be gladly implemented in the package if the are positive and useful.

For further information or any question feel free to contact me via email at alvarob96@usal.es

You can also check my [Medium Publication](https://medium.com/research-studies-by-alvaro-bartolome), where I upload weekly posts related to Data Science and mainly on Data Extraction techniques via Web Scraping. In this case, you can read [""investpy — a Python package for historical data extraction from the Spanish stock market""](https://medium.com/research-studies-by-alvaro-bartolome/investpy-a-python-library-for-historical-data-extraction-from-the-spanish-stock-market-ad4d564dbfc5) where I explain the basics on [investpy](https://github.com/alvarobartt/investpy) development and some insights on **Web Scraping with Python**.

## Disclaimer

This Python Package has been made for research purposes in order to fit a needs that Investing.com does not cover, so this package works like an Application Programming Interface (API) of Investing.com developed in an altruistic way. Conclude that this package is not related in any way with Investing.com or any dependant company, the only requirement for developing this package was to mention the source where data is retrieved.",.csv,True
Spanish Stocks Historical Data from 2000 to 2019,27,spanish-stocks-historical-data,red-elctrica.csv,other,"## Introduction

Since [Investing.com](https://www.investing.com/) does not have an API, I decided to develop this Python package in order to retrieve historical data from the companies that integrate the Continuous Spanish Stock Market. So on, I decided to generate, via [**investpy**](https://github.com/abartt/investpy), the datasets for every company so that any Data Scientist or Data Enthusiastic can handle it and abstract their own conclusions and research. 

The main purpose of developing **investpy**, the package from which these datasets have been retrieved, was to use it as the Data Extraction tool for its namesake section, for my Final Degree Project at the University of Salamanca titled ""*Machine Learning for stock investment recommendation systems*"". The package end up being so consistent, reliable and usable that it is going to be used as the main Data Extraction tool by another students in their Final Degree Projects named ""*Recommender system of banking products*"" and ""*Robo-Advisor Application*"".

## License

[MIT License](https://github.com/abartt/investpy/blob/master/LICENSE)

## Additional Information

investpy, the Python package from which datasets were generated is currently in a development beta version, so please, if needed open an [issue](https://github.com/abartt/investpy/issues) to solve all the possible problems the package may be causing or any dataset error. Also, any new ideas or proposals are welcome, and will be gladly implemented in the package if the are positive and useful.

For further information or any question feel free to contact me via email at alvarob96@usal.es

You can also check my [Medium Publication](https://medium.com/research-studies-by-alvaro-bartolome), where I upload weekly posts related to Data Science and mainly on Data Extraction techniques via Web Scraping. In this case, you can read [""investpy — a Python package for historical data extraction from the Spanish stock market""](https://medium.com/research-studies-by-alvaro-bartolome/investpy-a-python-library-for-historical-data-extraction-from-the-spanish-stock-market-ad4d564dbfc5) where I explain the basics on [investpy](https://github.com/alvarobartt/investpy) development and some insights on **Web Scraping with Python**.

## Disclaimer

This Python Package has been made for research purposes in order to fit a needs that Investing.com does not cover, so this package works like an Application Programming Interface (API) of Investing.com developed in an altruistic way. Conclude that this package is not related in any way with Investing.com or any dependant company, the only requirement for developing this package was to mention the source where data is retrieved.",.csv,True
Spanish Stocks Historical Data from 2000 to 2019,27,spanish-stocks-historical-data,fcc.csv,other,"## Introduction

Since [Investing.com](https://www.investing.com/) does not have an API, I decided to develop this Python package in order to retrieve historical data from the companies that integrate the Continuous Spanish Stock Market. So on, I decided to generate, via [**investpy**](https://github.com/abartt/investpy), the datasets for every company so that any Data Scientist or Data Enthusiastic can handle it and abstract their own conclusions and research. 

The main purpose of developing **investpy**, the package from which these datasets have been retrieved, was to use it as the Data Extraction tool for its namesake section, for my Final Degree Project at the University of Salamanca titled ""*Machine Learning for stock investment recommendation systems*"". The package end up being so consistent, reliable and usable that it is going to be used as the main Data Extraction tool by another students in their Final Degree Projects named ""*Recommender system of banking products*"" and ""*Robo-Advisor Application*"".

## License

[MIT License](https://github.com/abartt/investpy/blob/master/LICENSE)

## Additional Information

investpy, the Python package from which datasets were generated is currently in a development beta version, so please, if needed open an [issue](https://github.com/abartt/investpy/issues) to solve all the possible problems the package may be causing or any dataset error. Also, any new ideas or proposals are welcome, and will be gladly implemented in the package if the are positive and useful.

For further information or any question feel free to contact me via email at alvarob96@usal.es

You can also check my [Medium Publication](https://medium.com/research-studies-by-alvaro-bartolome), where I upload weekly posts related to Data Science and mainly on Data Extraction techniques via Web Scraping. In this case, you can read [""investpy — a Python package for historical data extraction from the Spanish stock market""](https://medium.com/research-studies-by-alvaro-bartolome/investpy-a-python-library-for-historical-data-extraction-from-the-spanish-stock-market-ad4d564dbfc5) where I explain the basics on [investpy](https://github.com/alvarobartt/investpy) development and some insights on **Web Scraping with Python**.

## Disclaimer

This Python Package has been made for research purposes in order to fit a needs that Investing.com does not cover, so this package works like an Application Programming Interface (API) of Investing.com developed in an altruistic way. Conclude that this package is not related in any way with Investing.com or any dependant company, the only requirement for developing this package was to mention the source where data is retrieved.",.csv,True
Spanish Stocks Historical Data from 2000 to 2019,27,spanish-stocks-historical-data,sacyr.csv,other,"## Introduction

Since [Investing.com](https://www.investing.com/) does not have an API, I decided to develop this Python package in order to retrieve historical data from the companies that integrate the Continuous Spanish Stock Market. So on, I decided to generate, via [**investpy**](https://github.com/abartt/investpy), the datasets for every company so that any Data Scientist or Data Enthusiastic can handle it and abstract their own conclusions and research. 

The main purpose of developing **investpy**, the package from which these datasets have been retrieved, was to use it as the Data Extraction tool for its namesake section, for my Final Degree Project at the University of Salamanca titled ""*Machine Learning for stock investment recommendation systems*"". The package end up being so consistent, reliable and usable that it is going to be used as the main Data Extraction tool by another students in their Final Degree Projects named ""*Recommender system of banking products*"" and ""*Robo-Advisor Application*"".

## License

[MIT License](https://github.com/abartt/investpy/blob/master/LICENSE)

## Additional Information

investpy, the Python package from which datasets were generated is currently in a development beta version, so please, if needed open an [issue](https://github.com/abartt/investpy/issues) to solve all the possible problems the package may be causing or any dataset error. Also, any new ideas or proposals are welcome, and will be gladly implemented in the package if the are positive and useful.

For further information or any question feel free to contact me via email at alvarob96@usal.es

You can also check my [Medium Publication](https://medium.com/research-studies-by-alvaro-bartolome), where I upload weekly posts related to Data Science and mainly on Data Extraction techniques via Web Scraping. In this case, you can read [""investpy — a Python package for historical data extraction from the Spanish stock market""](https://medium.com/research-studies-by-alvaro-bartolome/investpy-a-python-library-for-historical-data-extraction-from-the-spanish-stock-market-ad4d564dbfc5) where I explain the basics on [investpy](https://github.com/alvarobartt/investpy) development and some insights on **Web Scraping with Python**.

## Disclaimer

This Python Package has been made for research purposes in order to fit a needs that Investing.com does not cover, so this package works like an Application Programming Interface (API) of Investing.com developed in an altruistic way. Conclude that this package is not related in any way with Investing.com or any dependant company, the only requirement for developing this package was to mention the source where data is retrieved.",.csv,True
Store Complaints,2,store-complaints,Store_Complaints (2).csv,other,"The dataset is a fictional collection of customer complaints related to a supermarket. It contains 300 rows of data, with each row representing a unique complaint. The dataset includes the following columns:

1. Complaint ID: A unique identifier for each complaint.
2. Customer Name: The name of the customer who lodged the complaint.
3. Complaint Type: The type of complaint raised by the customer, such as product, delivery, staff, etc.
4. Staff Name: The name of the staff member associated with the complaint.
5. Department: The department of the supermarket to which the complaint relates.
6. Product Details: Details about the specific product mentioned in the complaint.
7. Date of Complaint: The date when the complaint was made.
8. Store Location: The location or name of the store where the complaint was made.

The dataset provides a variety of complaints across different complaint types, staff members, departments, and store locations. The data can be used to analyze patterns, identify areas for improvement, and develop strategies to enhance customer service in the supermarket.

Please note that this dataset is entirely fictional and created for demonstration purposes.",.csv,True
Store Complaints,2,store-complaints,Store_Complaints.csv,other,"The dataset is a fictional collection of customer complaints related to a supermarket. It contains 300 rows of data, with each row representing a unique complaint. The dataset includes the following columns:

1. Complaint ID: A unique identifier for each complaint.
2. Customer Name: The name of the customer who lodged the complaint.
3. Complaint Type: The type of complaint raised by the customer, such as product, delivery, staff, etc.
4. Staff Name: The name of the staff member associated with the complaint.
5. Department: The department of the supermarket to which the complaint relates.
6. Product Details: Details about the specific product mentioned in the complaint.
7. Date of Complaint: The date when the complaint was made.
8. Store Location: The location or name of the store where the complaint was made.

The dataset provides a variety of complaints across different complaint types, staff members, departments, and store locations. The data can be used to analyze patterns, identify areas for improvement, and develop strategies to enhance customer service in the supermarket.

Please note that this dataset is entirely fictional and created for demonstration purposes.",.csv,True
Stress Analysis in Social Media,2,stress-analysis-in-social-media,dreaddit-train.csv,other,"### Context

We live in an era where there is a surplus of information flowing in every second. Sometimes this leads to stress. ☹️ 
Too much stress can negatively impact our health and may lead to headaches, high blood pressure, heart problems, diabetes, skin conditions, asthma, arthritis, depression, and anxiety.

### Content

A dataset of lengthy multi-domain social media data for identifying stress from five different categories of Reddit communities.

### Acknowledgements

Turcan, E., & McKeown, K. (2019). Dreaddit: A Reddit dataset for stress analysis in social media. arXiv preprint arXiv:1911.00133.",.csv,True
Stress Analysis in Social Media,2,stress-analysis-in-social-media,dreaddit-test.csv,other,"### Context

We live in an era where there is a surplus of information flowing in every second. Sometimes this leads to stress. ☹️ 
Too much stress can negatively impact our health and may lead to headaches, high blood pressure, heart problems, diabetes, skin conditions, asthma, arthritis, depression, and anxiety.

### Content

A dataset of lengthy multi-domain social media data for identifying stress from five different categories of Reddit communities.

### Acknowledgements

Turcan, E., & McKeown, K. (2019). Dreaddit: A Reddit dataset for stress analysis in social media. arXiv preprint arXiv:1911.00133.",.csv,True
Student Alcohol Consumption,2,student-alcohol-consumption,student-por.csv,CC0-1.0,"<h2>Context:</h2>

The data were obtained in a survey of students math and portuguese language courses in secondary school. It contains a lot of interesting social, gender and study information about students.  You can use it for some EDA or try to predict students final grade.

<h2>Content:</h2>

Attributes for both student-mat.csv (Math course) and student-por.csv (Portuguese language course) datasets: 

1. school - student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira)
2. sex - student's sex (binary: 'F' - female or 'M' - male) 
3. age - student's age (numeric: from 15 to 22) 
4. address - student's home address type (binary: 'U' - urban or 'R' - rural) 
5. famsize - family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3) 
6. Pstatus - parent's cohabitation status (binary: 'T' - living together or 'A' - apart)
7. Medu - mother's education (numeric: 0 - none,  1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)
8. Fedu - father's education (numeric: 0 - none,  1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)
9. Mjob - mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other') 
10. Fjob - father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other') 
11. reason - reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other') 
12. guardian - student's guardian (nominal: 'mother', 'father' or 'other') 
13. traveltime - home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour) 
14. studytime - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours) 
15. failures - number of past class failures (numeric: n if 1<=n<3, else 4) 
16. schoolsup - extra educational support (binary: yes or no) 
17. famsup - family educational support (binary: yes or no) 
18. paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no) 
19. activities - extra-curricular activities (binary: yes or no) 
20. nursery - attended nursery school (binary: yes or no) 
21. higher - wants to take higher education (binary: yes or no) 
22. internet - Internet access at home (binary: yes or no) 
23. romantic - with a romantic relationship (binary: yes or no) 
24. famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent) 
25. freetime - free time after school (numeric: from 1 - very low to 5 - very high) 
26. goout - going out with friends (numeric: from 1 - very low to 5 - very high) 
27. Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high) 
28. Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high) 
29. health - current health status (numeric: from 1 - very bad to 5 - very good) 
30. absences - number of school absences (numeric: from 0 to 93) 

These grades are related with the course subject, Math or Portuguese: 

31. G1 - first period grade (numeric: from 0 to 20) 
31. G2 - second period grade (numeric: from 0 to 20) 
32. G3 - final grade (numeric: from 0 to 20, output target) 

**Additional note:** there are several (382) students that belong to both datasets . 
These students can be identified by searching for identical attributes
that characterize each student, as shown in the annexed R file.

<h2>Source Information</h2>

P. Cortez and A. Silva. Using Data Mining to Predict Secondary School Student Performance. In A. Brito and J. Teixeira Eds., Proceedings of 5th FUture BUsiness TEChnology Conference (FUBUTEC 2008) pp. 5-12, Porto, Portugal, April, 2008, EUROSIS, ISBN 978-9077381-39-7.

Fabio Pagnotta, Hossain Mohammad Amran. 
Email:fabio.pagnotta@studenti.unicam.it, mohammadamra.hossain '@' studenti.unicam.it 
University Of Camerino

https://archive.ics.uci.edu/ml/datasets/STUDENT+ALCOHOL+CONSUMPTION",.csv,True
Student Alcohol Consumption,2,student-alcohol-consumption,student-mat.csv,CC0-1.0,"<h2>Context:</h2>

The data were obtained in a survey of students math and portuguese language courses in secondary school. It contains a lot of interesting social, gender and study information about students.  You can use it for some EDA or try to predict students final grade.

<h2>Content:</h2>

Attributes for both student-mat.csv (Math course) and student-por.csv (Portuguese language course) datasets: 

1. school - student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira)
2. sex - student's sex (binary: 'F' - female or 'M' - male) 
3. age - student's age (numeric: from 15 to 22) 
4. address - student's home address type (binary: 'U' - urban or 'R' - rural) 
5. famsize - family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3) 
6. Pstatus - parent's cohabitation status (binary: 'T' - living together or 'A' - apart)
7. Medu - mother's education (numeric: 0 - none,  1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)
8. Fedu - father's education (numeric: 0 - none,  1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)
9. Mjob - mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other') 
10. Fjob - father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other') 
11. reason - reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other') 
12. guardian - student's guardian (nominal: 'mother', 'father' or 'other') 
13. traveltime - home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour) 
14. studytime - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours) 
15. failures - number of past class failures (numeric: n if 1<=n<3, else 4) 
16. schoolsup - extra educational support (binary: yes or no) 
17. famsup - family educational support (binary: yes or no) 
18. paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no) 
19. activities - extra-curricular activities (binary: yes or no) 
20. nursery - attended nursery school (binary: yes or no) 
21. higher - wants to take higher education (binary: yes or no) 
22. internet - Internet access at home (binary: yes or no) 
23. romantic - with a romantic relationship (binary: yes or no) 
24. famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent) 
25. freetime - free time after school (numeric: from 1 - very low to 5 - very high) 
26. goout - going out with friends (numeric: from 1 - very low to 5 - very high) 
27. Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high) 
28. Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high) 
29. health - current health status (numeric: from 1 - very bad to 5 - very good) 
30. absences - number of school absences (numeric: from 0 to 93) 

These grades are related with the course subject, Math or Portuguese: 

31. G1 - first period grade (numeric: from 0 to 20) 
31. G2 - second period grade (numeric: from 0 to 20) 
32. G3 - final grade (numeric: from 0 to 20, output target) 

**Additional note:** there are several (382) students that belong to both datasets . 
These students can be identified by searching for identical attributes
that characterize each student, as shown in the annexed R file.

<h2>Source Information</h2>

P. Cortez and A. Silva. Using Data Mining to Predict Secondary School Student Performance. In A. Brito and J. Teixeira Eds., Proceedings of 5th FUture BUsiness TEChnology Conference (FUBUTEC 2008) pp. 5-12, Porto, Portugal, April, 2008, EUROSIS, ISBN 978-9077381-39-7.

Fabio Pagnotta, Hossain Mohammad Amran. 
Email:fabio.pagnotta@studenti.unicam.it, mohammadamra.hossain '@' studenti.unicam.it 
University Of Camerino

https://archive.ics.uci.edu/ml/datasets/STUDENT+ALCOHOL+CONSUMPTION",.csv,True
Student Exam Performance Prediction,2,student-exam-performance-prediction,student_exam_data_new.csv,Apache 2.0,"The dataset is designed for predicting whether a student will pass or fail an exam based on the number of study hours and their scores in the previous exam. 

Features:
Study Hours (numeric): Represents the number of hours a student spent studying for the upcoming exam.
Previous Exam Score (numeric): Indicates the student's score in the previous exam.
Pass/Fail (binary): The target variable, where 1 represents a pass and 0 represents a fail in the current exam.

**Description: **

Features:
Study Hours (numeric): Represents the number of hours a student spent studying for the upcoming exam.
Previous Exam Score (numeric): Indicates the student's score in the previous exam.
Pass/Fail (binary): The target variable, where 1 represents a pass and 0 represents a fail in the current exam.
Dataset Size:
The dataset consists of data for 500 students, ensuring a diverse range of study patterns and previous exam performances.",.csv,True
Student Exam Performance Prediction,2,student-exam-performance-prediction,student_exam_data.csv,Apache 2.0,"The dataset is designed for predicting whether a student will pass or fail an exam based on the number of study hours and their scores in the previous exam. 

Features:
Study Hours (numeric): Represents the number of hours a student spent studying for the upcoming exam.
Previous Exam Score (numeric): Indicates the student's score in the previous exam.
Pass/Fail (binary): The target variable, where 1 represents a pass and 0 represents a fail in the current exam.

**Description: **

Features:
Study Hours (numeric): Represents the number of hours a student spent studying for the upcoming exam.
Previous Exam Score (numeric): Indicates the student's score in the previous exam.
Pass/Fail (binary): The target variable, where 1 represents a pass and 0 represents a fail in the current exam.
Dataset Size:
The dataset consists of data for 500 students, ensuring a diverse range of study patterns and previous exam performances.",.csv,True
Student Performance,2,student-performance,Portuguese.csv,Attribution 4.0 International (CC BY 4.0),"This data approach student achievement in secondary education of two Portuguese schools. The data attributes include student grades, demographic, social and school related features) and it was collected by using school reports and questionnaires. Two datasets are provided regarding the performance in two distinct subjects: Mathematics (mat) and Portuguese language (por). In [Cortez and Silva, 2008], the two datasets were modeled under binary/five-level classification and regression tasks. Important note: the target attribute G3 has a strong correlation with attributes G2 and G1. This occurs because G3 is the final year grade (issued at the 3rd period), while G1 and G2 correspond to the 1st and 2nd period grades. It is more difficult to predict G3 without G2 and G1, but such prediction is much more useful (see paper source for more details).

## Attributes for both Maths.csv (Math course) and Portuguese.csv (Portuguese language course) datasets:
| Columns | Description |
| --- | --- |
| school | student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira) |
| sex | student's sex (binary: 'F' - female or 'M' - male) |
| age | student's age (numeric: from 15 to 22) |
| address | student's home address type (binary: 'U' - urban or 'R' - rural) |
| famsize | family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3) |
| Pstatus | parent's cohabitation status (binary: 'T' - living together or 'A' - apart) |
| Medu | mother's education (numeric: 0 - none,  1 - primary education (4th grade), 2 â€“ 5th to 9th grade, 3 â€“ secondary education or 4 â€“ higher education) |
| Fedu | father's education (numeric: 0 - none,  1 - primary education (4th grade), 2 â€“ 5th to 9th grade, 3 â€“ secondary education or 4 â€“ higher education) |
| Mjob | mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other') |
| Fjob | father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other') |
| reason | reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other') |
| guardian | student's guardian (nominal: 'mother', 'father' or 'other') |
| traveltime | home to school travel time (numeric: 1 - &lt;15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - &gt;1 hour) |
| studytime | weekly study time (numeric: 1 - &lt;2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - &gt;10 hours) |
| failures | number of past class failures (numeric: n if 1&lt;=n&lt;3, else 4) |
| schoolsup | extra educational support (binary: yes or no) |
| famsup | family educational support (binary: yes or no) |
| paid | extra paid classes within the course subject (Math or Portuguese) (binary: yes or no) |
| activities | extra-curricular activities (binary: yes or no) |
| nursery | attended nursery school (binary: yes or no) |
| higher | wants to take higher education (binary: yes or no) |
| internet | Internet access at home (binary: yes or no) |
| romantic | with a romantic relationship (binary: yes or no) |
| famrel | quality of family relationships (numeric: from 1 - very bad to 5 - excellent) |
| freetime | free time after school (numeric: from 1 - very low to 5 - very high) |
| goout | going out with friends (numeric: from 1 - very low to 5 - very high) |
| Dalc | workday alcohol consumption (numeric: from 1 - very low to 5 - very high) |
| Walc | weekend alcohol consumption (numeric: from 1 - very low to 5 - very high) |
| health | current health status (numeric: from 1 - very bad to 5 - very good) |
| absences | number of school absences (numeric: from 0 to 93) |

## These grades are related with the course subject, Math or Portuguese:
| Grade | Description |
| --- | --- |
| G1 | first period grade (numeric: from 0 to 20) |
| G2 | second period grade (numeric: from 0 to 20) |
| G3 | final grade (numeric: from 0 to 20, output target) |


&gt; More
- Find More Exciting🙀 Datasets [Here](https://www.kaggle.com/whenamancodes/datasets)
- An Upvote👍 A Dayᕙ(`▿´)ᕗ , Keeps Aman Hurray Hurray..... ٩(˘◡˘)۶Haha",.csv,True
Student Performance,2,student-performance,Maths.csv,Attribution 4.0 International (CC BY 4.0),"This data approach student achievement in secondary education of two Portuguese schools. The data attributes include student grades, demographic, social and school related features) and it was collected by using school reports and questionnaires. Two datasets are provided regarding the performance in two distinct subjects: Mathematics (mat) and Portuguese language (por). In [Cortez and Silva, 2008], the two datasets were modeled under binary/five-level classification and regression tasks. Important note: the target attribute G3 has a strong correlation with attributes G2 and G1. This occurs because G3 is the final year grade (issued at the 3rd period), while G1 and G2 correspond to the 1st and 2nd period grades. It is more difficult to predict G3 without G2 and G1, but such prediction is much more useful (see paper source for more details).

## Attributes for both Maths.csv (Math course) and Portuguese.csv (Portuguese language course) datasets:
| Columns | Description |
| --- | --- |
| school | student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira) |
| sex | student's sex (binary: 'F' - female or 'M' - male) |
| age | student's age (numeric: from 15 to 22) |
| address | student's home address type (binary: 'U' - urban or 'R' - rural) |
| famsize | family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3) |
| Pstatus | parent's cohabitation status (binary: 'T' - living together or 'A' - apart) |
| Medu | mother's education (numeric: 0 - none,  1 - primary education (4th grade), 2 â€“ 5th to 9th grade, 3 â€“ secondary education or 4 â€“ higher education) |
| Fedu | father's education (numeric: 0 - none,  1 - primary education (4th grade), 2 â€“ 5th to 9th grade, 3 â€“ secondary education or 4 â€“ higher education) |
| Mjob | mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other') |
| Fjob | father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other') |
| reason | reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other') |
| guardian | student's guardian (nominal: 'mother', 'father' or 'other') |
| traveltime | home to school travel time (numeric: 1 - &lt;15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - &gt;1 hour) |
| studytime | weekly study time (numeric: 1 - &lt;2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - &gt;10 hours) |
| failures | number of past class failures (numeric: n if 1&lt;=n&lt;3, else 4) |
| schoolsup | extra educational support (binary: yes or no) |
| famsup | family educational support (binary: yes or no) |
| paid | extra paid classes within the course subject (Math or Portuguese) (binary: yes or no) |
| activities | extra-curricular activities (binary: yes or no) |
| nursery | attended nursery school (binary: yes or no) |
| higher | wants to take higher education (binary: yes or no) |
| internet | Internet access at home (binary: yes or no) |
| romantic | with a romantic relationship (binary: yes or no) |
| famrel | quality of family relationships (numeric: from 1 - very bad to 5 - excellent) |
| freetime | free time after school (numeric: from 1 - very low to 5 - very high) |
| goout | going out with friends (numeric: from 1 - very low to 5 - very high) |
| Dalc | workday alcohol consumption (numeric: from 1 - very low to 5 - very high) |
| Walc | weekend alcohol consumption (numeric: from 1 - very low to 5 - very high) |
| health | current health status (numeric: from 1 - very bad to 5 - very good) |
| absences | number of school absences (numeric: from 0 to 93) |

## These grades are related with the course subject, Math or Portuguese:
| Grade | Description |
| --- | --- |
| G1 | first period grade (numeric: from 0 to 20) |
| G2 | second period grade (numeric: from 0 to 20) |
| G3 | final grade (numeric: from 0 to 20, output target) |


&gt; More
- Find More Exciting🙀 Datasets [Here](https://www.kaggle.com/whenamancodes/datasets)
- An Upvote👍 A Dayᕙ(`▿´)ᕗ , Keeps Aman Hurray Hurray..... ٩(˘◡˘)۶Haha",.csv,True
Student Performance Prediction,2,student-performance-prediction,mat2.csv,Apache 2.0,"## Welcome! 🥳

👏 **Upvote this dataset** if you find it interesting !


This data approach **student achievement** in secondary education of **two Portuguese schools**. The data attributes include **student grades, demographic, social and school** related features and it was collected by using school reports and questionnaires. 

Two datasets are provided regarding the performance in two distinct subjects: **Mathematics (mat.csv) and Portuguese language (por.csv)**. In [Cortez and Silva, 2008], the two datasets were modeled under binary/five-level classification and regression tasks.

## Dataset Description

#### Attributes for both **student-mat.csv** (Math course) and **student-por.csv** (Portuguese language course) datasets:

| Variable | Description |
| --- | --- |
| `school` | student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira) |
| `sex` | student's sex (binary: 'F' - female or 'M' - male) |
| `age` | student's age (numeric: from 15 to 22) |
| `address` | student's home address type (binary: 'U' - urban or 'R' - rural) |
| `famsize` | family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3) |
| `Pstatus` | parent's cohabitation status (binary: 'T' - living together or 'A' - apart) |
| `Medu` | mother's education (numeric: 0 - none, 1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education) |
| `Fedu` | father's education (numeric: 0 - none, 1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education) |
| `Mjob` | mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other') |
| `Fjob` | father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other') |
| `reason` | reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other') |
| `guardian` | student's guardian (nominal: 'mother', 'father' or 'other') |
| `traveltime` | home to school travel time (numeric: 1 - &lt;15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - &gt;1 hour) |
| `studytime` | weekly study time (numeric: 1 - &lt;2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - &gt;10 hours) |
| `failures` | number of past class failures (numeric: n if 1&lt;=n&lt;3, else 4) |
| `schoolsup` | extra educational support (binary: yes or no) |
| `famsup` | family educational support (binary: yes or no) |
| `paid` | extra paid classes within the course subject (Math or Portuguese) (binary: yes or no) |
| `activities` | extra-curricular activities (binary: yes or no) |
| `nursery` | attended nursery school (binary: yes or no) |
| `higher` | wants to take higher education (binary: yes or no) |
| `internet` | Internet access at home (binary: yes or no) |
| `romantic` | with a romantic relationship (binary: yes or no) |
| `famrel` | quality of family relationships (numeric: from 1 - very bad to 5 - excellent) |
| `freetime` | free time after school (numeric: from 1 - very low to 5 - very high) |
| `goout` | going out with friends (numeric: from 1 - very low to 5 - very high) |
| `Dalc` | workday alcohol consumption (numeric: from 1 - very low to 5 - very high) |
| `Walc` | weekend alcohol consumption (numeric: from 1 - very low to 5 - very high) |
| `health` | current health status (numeric: from 1 - very bad to 5 - very good) |
| `absences` | number of school absences (numeric: from 0 to 93) |



#### these grades are related with the **course subject**, Math or Portuguese:
`G1` - first period grade (numeric: from 0 to 20)
`G2` - second period grade (numeric: from 0 to 20)
`G3` - final grade (numeric: from 0 to 20, output target)",.csv,True
Student Performance Prediction,2,student-performance-prediction,por2.csv,Apache 2.0,"## Welcome! 🥳

👏 **Upvote this dataset** if you find it interesting !


This data approach **student achievement** in secondary education of **two Portuguese schools**. The data attributes include **student grades, demographic, social and school** related features and it was collected by using school reports and questionnaires. 

Two datasets are provided regarding the performance in two distinct subjects: **Mathematics (mat.csv) and Portuguese language (por.csv)**. In [Cortez and Silva, 2008], the two datasets were modeled under binary/five-level classification and regression tasks.

## Dataset Description

#### Attributes for both **student-mat.csv** (Math course) and **student-por.csv** (Portuguese language course) datasets:

| Variable | Description |
| --- | --- |
| `school` | student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira) |
| `sex` | student's sex (binary: 'F' - female or 'M' - male) |
| `age` | student's age (numeric: from 15 to 22) |
| `address` | student's home address type (binary: 'U' - urban or 'R' - rural) |
| `famsize` | family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3) |
| `Pstatus` | parent's cohabitation status (binary: 'T' - living together or 'A' - apart) |
| `Medu` | mother's education (numeric: 0 - none, 1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education) |
| `Fedu` | father's education (numeric: 0 - none, 1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education) |
| `Mjob` | mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other') |
| `Fjob` | father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other') |
| `reason` | reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other') |
| `guardian` | student's guardian (nominal: 'mother', 'father' or 'other') |
| `traveltime` | home to school travel time (numeric: 1 - &lt;15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - &gt;1 hour) |
| `studytime` | weekly study time (numeric: 1 - &lt;2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - &gt;10 hours) |
| `failures` | number of past class failures (numeric: n if 1&lt;=n&lt;3, else 4) |
| `schoolsup` | extra educational support (binary: yes or no) |
| `famsup` | family educational support (binary: yes or no) |
| `paid` | extra paid classes within the course subject (Math or Portuguese) (binary: yes or no) |
| `activities` | extra-curricular activities (binary: yes or no) |
| `nursery` | attended nursery school (binary: yes or no) |
| `higher` | wants to take higher education (binary: yes or no) |
| `internet` | Internet access at home (binary: yes or no) |
| `romantic` | with a romantic relationship (binary: yes or no) |
| `famrel` | quality of family relationships (numeric: from 1 - very bad to 5 - excellent) |
| `freetime` | free time after school (numeric: from 1 - very low to 5 - very high) |
| `goout` | going out with friends (numeric: from 1 - very low to 5 - very high) |
| `Dalc` | workday alcohol consumption (numeric: from 1 - very low to 5 - very high) |
| `Walc` | weekend alcohol consumption (numeric: from 1 - very low to 5 - very high) |
| `health` | current health status (numeric: from 1 - very bad to 5 - very good) |
| `absences` | number of school absences (numeric: from 0 to 93) |



#### these grades are related with the **course subject**, Math or Portuguese:
`G1` - first period grade (numeric: from 0 to 20)
`G2` - second period grade (numeric: from 0 to 20)
`G3` - final grade (numeric: from 0 to 20, output target)",.csv,True
Student Study Hours,2,student-study-hours,score.csv,CC0-1.0,The data set contains two columns.  that is the number of hours student studied and the marks they got. we can apply simple linear regression to predict the marks of the student given their number of study hours.,.csv,True
Student Study Hours,2,student-study-hours,score_updated.csv,CC0-1.0,The data set contains two columns.  that is the number of hours student studied and the marks they got. we can apply simple linear regression to predict the marks of the student given their number of study hours.,.csv,True
Sundanese Twitter Dataset emotions classification,2,sundanese-twitter-dataset,test.csv,Attribution 4.0 International (CC BY 4.0),"This dataset contains tweet of the second-largest local language in Indonesia and is used for emotion classification.

**Dataset Characteristics:** Tabular

**Subject Area:** Computer Science

**Associated Tasks:** Classification

**Instances:** 2510



# Dataset Information

**For what purpose was the dataset created?**

This dataset is created as contribution for NLP research particularly in Indonesia 

**Who funded the creation of the dataset?**

This dataset is self-funded

**What do the instances in this dataset represent?**

tweet

**Are there recommended data splits?**

No

**Was there any data preprocessing performed?**

tokenization, stopword removal, stemming

**Has Missing Values?**

No

# Introductory Paper

**Title:** Sundanese Twitter Dataset for Emotion Classification

**Authors:** Oddy Virgantara Putra; Fathin Muhammad Wasmanson; Triana Harmini; Shoffin Nahwa Utama. 2020

**Journal:** Published in Conference

**Link:** [https://ieeexplore.ieee.org/abstract/document/9297929](url)

# Abstract of Introductory Paper

Sundanese is the second-largest tribe in Indonesia which possesses many dialects. This condition has gained attention for many researchers to analyze emotion especially on social media. However, with barely available Sundanese dataset, this condition makes understanding sundanese emotion is a challenging task. In this research, we proposed a dataset for emotion classification of Sundanese text. The preprocessing includes case folding, stopwords removal, stemming, tokenizing, and text representation. Prior to classification, for the feature generation, we utilize term frequency-inverse document frequency (TFIDF). We evaluated our dataset using k-Fold Cross Validation. Our experiments with the proposed method exhibit an effective result for machine learning classification. Furthermore, as far as we know, this is the first Sundanese emotion dataset available for public.


# Cite

**Citation:** `Putra,Oddy Virgantara. (2021). Sundanese Twitter Dataset. UCI Machine Learning Repository. https://doi.org/10.24432/C5MK8C.`

**BibTex:** `@misc{misc_sundanese_twitter_dataset_695,
  author       = {Putra,Oddy Virgantara},
  title        = {{Sundanese Twitter Dataset}},
  year         = {2021},
  howpublished = {UCI Machine Learning Repository},
  note         = {{DOI}: https://doi.org/10.24432/C5MK8C}
}`

",.csv,True
Sundanese Twitter Dataset emotions classification,2,sundanese-twitter-dataset,data.csv,Attribution 4.0 International (CC BY 4.0),"This dataset contains tweet of the second-largest local language in Indonesia and is used for emotion classification.

**Dataset Characteristics:** Tabular

**Subject Area:** Computer Science

**Associated Tasks:** Classification

**Instances:** 2510



# Dataset Information

**For what purpose was the dataset created?**

This dataset is created as contribution for NLP research particularly in Indonesia 

**Who funded the creation of the dataset?**

This dataset is self-funded

**What do the instances in this dataset represent?**

tweet

**Are there recommended data splits?**

No

**Was there any data preprocessing performed?**

tokenization, stopword removal, stemming

**Has Missing Values?**

No

# Introductory Paper

**Title:** Sundanese Twitter Dataset for Emotion Classification

**Authors:** Oddy Virgantara Putra; Fathin Muhammad Wasmanson; Triana Harmini; Shoffin Nahwa Utama. 2020

**Journal:** Published in Conference

**Link:** [https://ieeexplore.ieee.org/abstract/document/9297929](url)

# Abstract of Introductory Paper

Sundanese is the second-largest tribe in Indonesia which possesses many dialects. This condition has gained attention for many researchers to analyze emotion especially on social media. However, with barely available Sundanese dataset, this condition makes understanding sundanese emotion is a challenging task. In this research, we proposed a dataset for emotion classification of Sundanese text. The preprocessing includes case folding, stopwords removal, stemming, tokenizing, and text representation. Prior to classification, for the feature generation, we utilize term frequency-inverse document frequency (TFIDF). We evaluated our dataset using k-Fold Cross Validation. Our experiments with the proposed method exhibit an effective result for machine learning classification. Furthermore, as far as we know, this is the first Sundanese emotion dataset available for public.


# Cite

**Citation:** `Putra,Oddy Virgantara. (2021). Sundanese Twitter Dataset. UCI Machine Learning Repository. https://doi.org/10.24432/C5MK8C.`

**BibTex:** `@misc{misc_sundanese_twitter_dataset_695,
  author       = {Putra,Oddy Virgantara},
  title        = {{Sundanese Twitter Dataset}},
  year         = {2021},
  howpublished = {UCI Machine Learning Repository},
  note         = {{DOI}: https://doi.org/10.24432/C5MK8C}
}`

",.csv,True
Sustainable Energy Investment Forecast Dataset,4,sustainable-energy-investment-forecast-dataset,cleandata.csv,Attribution 4.0 International (CC BY 4.0),"Here's a list of all the indicators from the dataset with their names and descriptions:


1. **CleanFuelAccess**
   - Long Name: CO2 emissions (metric tons per capita)
   - Long Definition: Access to clean fuels and technologies for cooking is the proportion of the total population primarily using clean cooking fuels and technologies for cooking. Kerosene is excluded from clean cooking fuels under WHO guidelines.

   **Temiz Yakıt Erişimi**
   - Uzun İsim: Kişi Başına CO2 Emisyonları (metrik ton)
   - Uzun Tanım: Temiz yakıt ve teknolojilere erişim, toplam nüfusun temel olarak temiz yemek pişirme yakıtları ve teknolojilerini kullanma oranını ifade eder. Temiz yemek pişirme yakıtları arasında WHO yönergelerine göre kerosen (gazyağı) hariçtir.

 + Temiz yakıt erişimi, insanların temiz yakıt ve teknolojileri kullanarak yemek pişirme alışkanlıklarını ne kadar yaygın olarak benimsediklerini gösteren bir ölçüttür. Bu, çevre dostu yakıtların kullanılmasıyla oluşan karbon emisyonlarının kişi başına düşen miktarını ölçmek için kullanılır. Kerosen ( Aydınlatma, Isıtma vb.) gibi kirletici yakıtlar temiz yakıtların dışında tutulur.

2. **ElectricityAccess**
   - Long Name: Access to clean fuels and technologies for cooking (% of population)
   - Long Definition: Access to electricity is the percentage of the population with access to electricity. Electrification data are collected from industry, national surveys, and international sources.

    **Elektrik Erişimi**
  - Uzun İsim: Temiz yakıt ve teknolojilere erişim (% nüfusa göre)
  - Uzun Tanım: Elektrik erişimi, nüfusun ne kadarının elektriğe erişiminin olduğunu gösteren bir orandır. Elektrifikasyon verileri, endüstriyel kaynaklar, ulusal anketler ve uluslararası kaynaklardan toplanır.

 + Elektrik erişimi, bir toplumun veya bölgenin elektrik enerjisine ne kadar yaygın bir şekilde erişebildiğini ölçen bir göstergedir. Bu, bir yerdeki enerji altyapısının gelişmişliğini ve elektrik kullanımının yaygınlığını belirlemek için kullanılır.

3. **CO2Emissions**
   - Long Name: Access to electricity (% of population)
   - Long Definition: Carbon dioxide emissions are those stemming from the burning of fossil fuels and the manufacture of cement. They include carbon dioxide produced during the consumption of solid, liquid, and gas fuels and gas flaring.

   **CO2 Emisyonları**
   - Uzun İsim: Elektriğe Erişim (% nüfusa göre)
   - Uzun Tanım: Karbon dioksit emisyonları, fosil yakıtların yakılmasından ve çimento üretiminden kaynaklanan emisyonlar dır. Bunlar, katı, sıvı ve gaz yakıtlarının tüketimi sırasında üretilen karbon dioksiti ve gaz yakma işleminden kaynaklanan emisyonları içerir.

 + CO2 emisyonları, fosil yakıtların ve diğer endüstriyel işlemlerin çevreye saldığı karbon dioksit gazını ifade eder. Bu emisyonlar, sera etkisi yaratarak iklim değişikliğine katkıda bulunabilir. Bu nedenle, fosil yakıtların kullanımının azaltılması ve daha temiz enerji kaynaklarının tercih edilmesi, karbon emisyonlarını azaltma hedeflerini destekler.

4. **ElecPowerConsumption**
   - Long Name: Electric power consumption (kWh per capita)
   - Long Definition: Electric power consumption measures the production of power plants and combined heat and power plants less transmission, distribution, and transformation losses and own use by heat and power plants.

    **Elektrik Enerjisi Tüketimi**
   - Uzun İsim: Kişi Başına Elektrik Enerjisi Tüketimi (kWh)
   - Uzun Tanım: Elektrik enerjisi tüketimi, enerji santralleri ve kombine ısı ve enerji santrallerinin üretimini, iletim, dağıtım ve dönüşüm kayıplarını ve ısı ve enerji santralleri tarafından kendi kullanımlarını içermeyen enerji tüketimini ölçer.

 + Elektrik enerjisi tüketimi, bir toplumun veya bölgenin elektrik enerjisi ne kadar tükettiğini gösteren bir ölçüttür. Bu, enerji üretimi ve dağıtımıyla ilgili verileri ifade eder ve enerji kaynaklarının kullanımının ve enerji altyapısının etkinliğinin bir göstergesidir. Kişi başına elektrik enerjisi tüketimi, bir kişinin ortalama olarak ne kadar elektrik kullandığını gösterir.

5. **CoalElectricity**
   - Long Name: Electricity production from coal sources (% of total)
   - Long Definition: Sources of electricity refer to the inputs used to generate electricity. Coal refers to all coal and brown coal, both primary (including hard coal and lignite-brown coal) and derived fuels (including patent fuel, coke oven coke, gas coke, coke oven gas, and blast furnace gas). Peat is also included in this category.

    **Kömür Kaynaklı Elektrik**
    - Uzun İsim: Kömür kaynaklı elektrik üretimi (toplamın yüzdesi)
    - Uzun Tanım: Elektrik kaynakları, elektrik üretmek için kullanılan girdileri ifade eder. Kömür, tüm kömür ve kahverengi kömürü içerir, hem birincil (sert kömür ve linyit-kahverengi kömür dahil) hem de türetilmiş yakıtları (patent yakıt, kok fırını kokusu, gaz kokusu, kok fırını gazı ve yüksek fırın gazı dahil). Turba da bu kategoriye dahildir.

 + Kömür kaynaklı elektrik, toplam elektrik üretiminin ne kadarının kömür gibi fosil yakıtlardan geldiğini gösteren bir ölçüttür. Kömür, elektrik üretimi için kullanılan önemli bir enerji kaynağıdır, ancak çevresel etkileri ve karbon emisyonları nedeniyle çevre açısından sorunlu olarak kabul edilir. Bu nedenle, kömür kaynaklı elektrik üretiminin azaltılması, temiz enerji kaynaklarının teşvik edilmesi ve enerji verimliliğinin artırılması, sürdürülebilir enerji hedeflerine katkıda bulunabilir.

6. **HydroElectricity**
   - Long Name: Electricity production from hydroelectric sources (% of total)
   - Long Definition: Sources of electricity refer to the inputs used to generate electricity. Hydropower refers to electricity produced by hydroelectric power plants.

   **Hidroelektrik Elektrik**
   - Uzun İsim: Hidroelektrik kaynaklı elektrik üretimi (toplamın yüzdesi)
   - Uzun Tanım: Elektrik kaynakları, elektrik üretmek için kullanılan girdileri ifade eder. Hidroelektrik enerji, hidroelektrik santralleri tarafından üretilen elektriği ifade eder.

+ Hidroelektrik elektrik, toplam elektrik üretiminin ne kadarının hidroelektrik santraller gibi su kaynaklarından geldiğini gösteren bir ölçüttür. Bu tür elektrik üretimi, suyun kinetik enerjisini elektriğe dönüştüren hidroelektrik santraller kullanılarak gerçekleştirilir. Hidroelektrik enerji temiz ve sürdürülebilir bir enerji kaynağı olarak kabul edilir ve karbon emisyonlarını azaltma çabalarına katkıda bulunabilir.

7. **GasElectricity**
   - Long Name: Electricity production from natural gas sources (% of total)
   - Long Definition: Sources of electricity refer to the inputs used to generate electricity. Gas refers to natural gas but excludes natural gas liquids.

   **Doğalgaz Elektriği**
   - Uzun İsim: Doğalgaz kaynaklı elektrik üretimi (toplamın yüzdesi)
   - Uzun Tanım: Elektrik üretimi için kullanılan kaynaklar, elektrik üretiminde kullanılan girdilere atıfta bulunur. ""Gaz,"" doğalgazı ifade eder, ancak doğalgaz sıvılarını içermez.

 + Doğalgaz Elektriği, toplam elektrik üretiminin ne kadarının doğalgaz kaynaklarından geldiğini gösteren bir ölçüttür. Bu terim, elektrik üretimi için kullanılan girdileri ifade ederken ""gaz"" doğalgazı ifade eder, ancak doğalgaz sıvılarını kapsamaz. Yani, bu, elektriğin doğalgaz kullanılarak üretildiği oranı gösterir.

8. **NuclearElectricity**
   - Long Name: Electricity production from nuclear sources (% of total)
   - Long Definition: Sources of electricity refer to the inputs used to generate electricity. Nuclear power refers to electricity produced by nuclear power plants.

   **Nükleer Elektrik**
   - Uzun İsim: Nükleer kaynaklı elektrik üretimi (toplamın yüzdesi)
   - Uzun Tanım: Elektrik üretimi için kullanılan girdilere atıfta bulunan elektrik kaynakları. Nükleer enerji, nükleer enerji santralleri tarafından üretilen elektriği ifade eder.

 + Nükleer Elektrik, toplam elektrik üretiminin ne kadarının nükleer kaynaklardan geldiğini gösteren bir ölçüttür. Bu terim, elektrik üretimi için kullanılan girdilere atıfta bulunurken ""nükleer enerji,"" nükleer enerji santralleri tarafından üretilen elektriği ifade eder.

9. **OilElectricity**
   - Long Name: Electricity production from oil sources (% of total)
   - Long Definition: Sources of electricity refer to the inputs used to generate electricity. Oil refers to crude oil and petroleum products.

    **Petrol Elektriği**
   - Uzun İsim: Petrol kaynaklı elektrik üretimi (toplamın yüzdesi)
   - Uzun Tanım: Elektrik üretimi için kullanılan girdilere atıfta bulunan elektrik kaynakları. ""Petrol,"" ham petrol ve petrol ürünlerini ifade eder.

 + Petrol Elektriği, toplam elektrik üretiminin ne kadarının petrol kaynaklarından geldiğini gösteren bir ölçüttür. Bu terim, elektrik üretimi için kullanılan girdilere atıfta bulunurken ""petrol,"" ham petrol ve petrol ürünlerini ifade eder.

10.**RenewableElectricity**
    - Long Name: Electricity production from renewable sources, excluding hydroelectric (% of total)
    - Long Definition: Electricity production from renewable sources, excluding hydroelectric, includes geothermal, solar, tides, wind, biomass, and biofuels.

    **Yenilenebilir Enerji Elektriği**
   - Uzun İsim: Hidroelektrik dışındaki yenilenebilir kaynaklardan elektrik üretimi (toplamın yüzdesi)
   - Uzun Tanım: Hidroelektrik dışındaki yenilenebilir kaynaklardan, yani jeotermal, güneş, gelgit, rüzgar, biyokütle ve biyoyakıtlardan elektrik üretimi.

 + Yenilenebilir Enerji Elektriği, hidroelektrik dışındaki yenilenebilir kaynaklardan (jeotermal, güneş, gelgit, rüzgar, biyokütle ve biyoyakıtlar) elde edilen elektriğin, toplam elektrik üretiminin yüzdesini ifade eder. Bu, sürdürülebilir ve çevre dostu enerji üretiminin payını ölçmek için kullanılır.

11. **RenewableElectricity_kWh**
    - Long Name: Electricity production from renewable sources, excluding hydroelectric (kWh)
    - Long Definition: Electricity production from renewable sources, excluding hydroelectric, includes geothermal, solar, tides, wind, biomass, and biofuels.

    **Yenilenebilir Enerji Elektriği (kWh)**
   - Uzun İsim: Hidroelektrik dışındaki yenilenebilir kaynaklardan elektrik üretimi (kWh cinsinden)
   - Uzun Tanım: Hidroelektrik dışındaki yenilenebilir kaynaklardan, yani jeotermal, güneş, gelgit, rüzgar, biyokütle ve biyoyakıtlardan elektrik üretimi (kWh cinsinden).

 + Yenilenebilir Enerji Elektriği (kWh), hidroelektrik dışındaki yenilenebilir kaynaklardan (jeotermal, güneş, gelgit, rüzgar, biyokütle ve biyoyakıtlar) elde edilen elektriği ölçer ve bu elektriğin miktarını kilowatt saat (kWh) cinsinden ifade eder. Bu, sürdürülebilir enerji üretiminin miktarını belirlemek için kullanılır.

12. **EnergyIntensity**
    - Long Name: Energy intensity level of primary energy (MJ/$2017 PPP GDP)
    - Long Definition: Energy intensity level of primary energy is the ratio between energy supply and gross domestic product measured at purchasing power parity. It indicates how much energy is used to produce one unit of economic output.

    **Enerji Yoğunluğu**
   - Uzun İsim: Birincil enerjinin enerji yoğunluğu düzeyi (MJ/$2017 PPP GSYİH)
   - Uzun Tanım: Birincil enerjinin enerji yoğunluğu düzeyi, satın alma gücü paritesi ile ölçülen enerji arzı ile gayri safi yurt içi hasıla (GSYİH) arasındaki oranı ifade eder. Bu, bir birim ekonomik üretim için ne kadar enerji kullanıldığını gösterir.

 + Enerji Yoğunluğu, enerji arzı ile GSYİH arasındaki oranı kullanarak ekonomik üretim için ne kadar enerji harcandığını gösteren bir ölçüttür. Bu, enerji kullanımının ekonomik verimliliğini belirlemek için kullanılır.

13. **EnergyUse**
    - Long Name: Energy use (kg of oil equivalent per capita)
    - Long Definition: Energy use refers to the use of primary energy before transformation to other end-use fuels, which includes indigenous production plus imports and stock changes, minus exports and fuels supplied to ships and aircraft engaged in international transport.

    **Enerji Kullanımı**
   - Uzun İsim: Kişi başına düşen enerji kullanımı (ton petrol eşdeğeri cinsinden)
   - Uzun Tanım: Enerji kullanımı, diğer kullanım yakıtlarına dönüşmeden önce birincil enerjinin kullanımını ifade eder. Bu, yerel üretimi ve ithalatları, stok değişikliklerini içerirken, ihracatları ve uluslararası taşımacılık yapan gemilere ve uçaklara sağlanan yakıtları çıkarır.

 + Enerji Kullanımı, birincil enerjinin diğer kullanım formlarına dönüşmeden önceki kullanımını ifade eder ve kişi başına düşen enerji tüketimini ton petrol eşdeğeri cinsinden ölçer. Bu, enerji tüketiminin kişi başına dağılımını gösterir.

14. **FossilFuelConsumption**
    - Long Name: Fossil fuel energy consumption (% of total)
    - Long Definition: Fossil fuel comprises coal, oil, petroleum, and natural gas products.

    **Fosil Yakıt Tüketimi**
   - Uzun İsim: Toplamın yüzdesine göre fosil yakıt enerjisi tüketimi
   - Uzun Tanım: Fosil yakıtlar, kömür, petrol, petrol ürünleri ve doğalgaz ürünlerini içerir. Bu, toplam enerji tüketiminin ne kadarının fosil yakıtlardan geldiğini gösterir.

 + Fosil Yakıt Tüketimi, enerji tüketiminin ne kadarının fosil yakıtlardan (kömür, petrol, petrol ürünleri ve doğalgaz) kaynaklandığını gösteren bir ölçüttür. Bu, enerji kaynaklarının kullanımının çevresel etkilerini değerlendirmek ve enerji dönüşümünün sürdürülebilirliğini incelemek için önemlidir.

15. **GDPGrowth**
    - Long Name: GDP growth (annual %)
    - Long Definition: Annual percentage growth rate of GDP at market prices based on constant local currency. It is expressed in U.S. dollars and represents the sum of gross value added by all resident producers in the economy.

    **GDP Büyüme Hızı**
   - Uzun İsim: GDP ""Gross Domestic Product"" büyüme hızı (yıllık %)
   - Uzun Tanım: Sabit yerel para birimine dayalı olarak piyasa fiyatlarıyla GDP'nin yıllık yüzde büyüme hızı. Bu, ABD doları cinsinden ifade edilir ve ekonominin tüm yerel üreticileri tarafından katkıda bulunulan brüt katma değeri temsil eder.

 + GDP Büyüme Hızı, piyasa fiyatlarına dayalı olarak sabit yerel para birimindeki yıllık GDP büyüme hızını ölçer. Bu, ekonominin tüm yerel üreticilerinin ekonomiye katkısının toplamını temsil eder ve genellikle ekonominin büyüme veya daralma eğilimini gösterir.

16. **GDPPerCapita**
    - Long Name: GDP per capita (current US$)
    - Long Definition: GDP per capita is gross domestic product divided by midyear population. It is expressed in current U.S. dollars and represents the sum of gross value added by all resident producers in the economy.

    **Kişi Başına GDP**
   - Uzun İsim: Kişi başına düşen GDP (güncel ABD doları cinsinden)
   - Uzun Tanım: Kişi başına düşen GDP, GDP'nin yıl ortası nüfusuyla bölünmesiyle hesaplanır. Bu, güncel ABD doları cinsinden ifade edilir ve ekonominin tüm yerel üreticileri tarafından katkıda bulunulan brüt katma değeri toplamını temsil eder.

 + Kişi Başına GDP, GDP'nin ülkenin yıl ortası nüfusuna bölünmesiyle hesaplanan bir göstergedir. Bu, kişi başına düşen ekonomik üretimi ölçmek için kullanılır ve bir ülkenin ekonomik refah seviyesini değerlendirmek için önemlidir.

17. **PrivateEnergyInvest**
    - Long Name: Investment in energy with private participation (current US$)
    - Long Definition: Investment in energy projects with private participation refers to commitments to infrastructure projects in energy (electricity and natural gas: generation, transmission, and distribution) that have reached financial closure and serve the public. It excludes movable assets and small projects such as windmills.

    **Özel Katılımlı Enerji Yatırımı**
   - Uzun İsim: Özel katılımlı enerji projelerine yapılan yatırım (güncel ABD doları cinsinden)
   - Uzun Tanım: Özel katılımlı enerji projelerine yapılan yatırım, enerji altyapı projelerine (elektrik ve doğalgaz: üretim, iletim ve dağıtım) finansal kapanışa ulaşmış ve kamu hizmeti sunan taahhütleri ifade eder. Bu, taşınabilir varlıkları ve rüzgar türbinleri gibi küçük projeleri içermez.

 + Özel Katılımlı Enerji Yatırımı, kamu hizmeti sunan enerji altyapı projelerine yapılan finansal taahhütlere odaklanan yatırımları ifade eder. Bu, özellikle elektrik ve doğalgaz sektörlerinde büyük projelere yönelik yatırımı gösterir ve küçük projeleri veya taşınabilir varlıkları kapsamaz.

18. **LandArea**
    - Long Name: Land area (sq. km)
    - Long Definition: Land area is a country's total area, excluding area under inland water bodies, national claims to the continental shelf, and exclusive economic zones. It includes major rivers and lakes.

    **Arazi Alanı** 
   - Uzun İsim: Arazi alanı (km² cinsinden)
   - Uzun Tanım: Arazi alanı, bir ülkenin iç sularda bulunan alanlar, kıta sahanlığına yönelik ulusal talepler ve özel ekonomik bölgeleri hariç tutarak hesaplanan toplam alanını ifade eder. Bu, büyük nehirleri ve gölleri içerir.

 + Arazi Alanı, bir ülkenin kara yüzeyinin, iç sulardan, kıta sahanlığındaki ulusal taleplerden ve özel ekonomik bölgelerden hariç tutularak hesaplanan toplam alanını temsil eder. Bu, bir ülkenin toprak büyüklüğünü gösterir ve içerisine büyük nehirler ve gölleri de dahil eder.

19. **PopDensity**
    - Long Name: Population density (people per sq. km of land area)
    - Long Definition: Population density is midyear population divided by land area in square kilometers, based on the de facto definition of population.

    ** Nüfus Yoğunluğu**
   - Uzun İsim: Nüfus yoğunluğu (arazi alanı başına kişi sayısı olarak)
   - Uzun Tanım: Nüfus yoğunluğu, yılın ortasındaki nüfusun arazi alanı (kare kilometre cinsinden) ile bölünmesiyle hesaplanır ve nüfusun de facto tanımına dayanır.

 + Nüfus Yoğunluğu, yılın ortasındaki nüfusun arazi alanına (kare kilometre cinsinden) bölünmesiyle hesaplanan bir göstergedir ve bir bölgedeki kişi sayısının yoğunluğunu ölçer.

20. **TotalPopulation**
    - Long Name: Population, total
    - Long Definition: Total population is based on the de facto definition of population, counting all residents regardless of legal status or citizenship.

    **Toplam Nüfus**
   - Uzun İsim: Toplam nüfus
   - Uzun Tanım: Toplam nüfus, nüfusun de facto tanımına dayanarak, hukuki statü veya vatandaşlık durumuna bakılmaksızın tüm yerleşikleri sayan bir göstergedir.

 + Toplam Nüfus, hukuki statü veya vatandaşlık durumundan bağımsız olarak tüm yerleşikleri sayarak hesaplanan bir nüfus ölçüsüdür.

21. **Private Partnership Investment in Energy (Current US$)**
    - Long Name: Public private partnerships investment in energy (current US$)
    - Long Definition: Public Private Partnerships in energy (current US$) refer to commitments to infrastructure projects in energy (electricity and natural gas transmission and distribution) that have reached financial closure and serve the public. It excludes divestitures and merchant projects.

    **Enerjide Kamu-Özel Ortaklığı Yatırımı (Güncel ABD Doları)**
   - Uzun İsim: Enerjide kamu-özel ortaklığı yatırımı (güncel ABD doları cinsinden)
   - Uzun Tanım: Enerjide Kamu-Özel Ortaklıkları (güncel ABD doları) enerji altyapı projelerine (elektrik ve doğalgaz iletim ve dağıtım) yapılan taahhütleri ifade eder. Bu projeler finansal kapanışa ulaşmış ve halka hizmet vermektedir. Bu tanım, varlık satışlarını ve tüccar projelerini içermez.

 + Enerjide Kamu-Özel Ortaklığı Yatırımı, halka hizmet veren enerji altyapı projelerine yapılan finansal taahhütleri ifade eder ve varlık satışlarını ve tüccar projelerini kapsamaz.

22. **RenewableEnergyConsumption**
    - Long Name: Renewable energy consumption (% of total final energy consumption)
    - Long Definition: Renewable energy consumption is the share of renewable energy in total final energy consumption.

    **Yenilenebilir Enerji Tüketimi**
   - Uzun İsim: Yenilenebilir enerji tüketimi (toplam nihai enerji tüketiminin yüzdesi)
   - Uzun Tanım: Yenilenebilir enerji tüketimi, toplam nihai enerji tüketiminin içindeki yenilenebilir enerjinin payını ifade eder.

 + Yenilenebilir Enerji Tüketimi, toplam nihai enerji tüketiminin içindeki yenilenebilir enerjinin yüzdesini gösterir. Bu, bir ülkenin enerji tüketiminin ne kadarının yenilenebilir kaynaklardan geldiğini gösteren bir ölçüttür ve sürdürülebilir enerji kullanımının bir göstergesidir.

23. **TotalGHGEmissions**
    - Long Name: Total greenhouse gas emissions (kt of CO2 equivalent)
    - Long Definition: Total greenhouse gas emissions in kt of CO2 equivalent include CO2 totals excluding short-cycle biomass burning, all anthropogenic CH4 sources, N2O sources, and F-gases (HFCs, PFCs, and SF6).

    **Toplam sera gazı emisyonları**
   - Uzun İsim: Toplam sera gazı emisyonları (kt CO2 eşdeğeri cinsinden)
   - Uzun Tanım: kt CO2 eşdeğerindeki toplam sera gazı emisyonları, kısa döngü biyokütle yanmasını dışlayan CO2 toplamlarını, tüm antropojenik CH4 kaynaklarını, N2O kaynaklarını ve F-gazlarını (HFC'ler, PFC'ler ve SF6) içerir.

 + Toplam Sera Gazı Emisyonları, kt CO2 eşdeğeri cinsinden ifade edilen ve CO2 dışında diğer sera gazlarını (CH4, N2O ve F-gazları) içeren emisyonların toplamını temsil eder. Bu, bir ülkenin sera gazı emisyonlarını ölçmek için kullanılır ve çevresel etkileri ve iklim değişikliği ile ilgili verileri değerlendirmek için önemlidir.

24. **Latitude**
- **Indicator Name:** Latitude
- **Description:** Latitude of the country's centroid in decimal degrees.

    **Enlem**
   - Uzun İsim: Enlem
   - Uzun Tanım: Ülkenin merkez noktasının enlemi ondalık derece cinsinden ifade edilir.

 + Enlem, bir ülkenin merkez noktasının yeryüzündeki konumunu belirlemek için kullanılan bir koordinat ölçüsüdür ve enlem hatları Kuzey ve Güney yönlerindeki konumları tanımlar.

25. **Longitude**
- **Indicator Name:** Longitude
- **Description:** Longitude of the country's centroid in decimal degrees.

    **Boylam**
   - Uzun İsim: Boylam
   - Uzun Tanım: Ülkenin merkez noktasının boylamı ondalık derece cinsinden ifade edilir.

 + Boylam, bir ülkenin merkez noktasının yeryüzündeki konumunu belirlemek için kullanılan bir koordinat ölçüsüdür ve boylam hatları Doğu ve Batı yönlerindeki konumları tanımlar.

****Sources / Kaynaklar:
****

1. **Climate Watch Historical GHG Emissions (1990-2020)**
   - Source: World Resources Institute
   - Topic: Environment: Emissions
   - URL: [Climate Watch GHG Emissions](https://www.climatewatchdata.org/ghg-emissions)

2. **IEA Statistics**
   - Source: OECD/IEA 2014
   - Topic: Environment: Energy production & use
   - URL: [IEA Statistics](http://www.iea.org/stats/index.asp)
   - Note: Subject to [IEA Terms and Conditions](https://www.iea.org/t&c/termsandconditions/)

3. **Tracking SDG 7: The Energy Progress Report (2023)**
   - Source: IEA, IRENA, UNSD, World Bank, WHO
   - Topic: Environment: Energy production & use
   - Source: World Bank, Washington DC
   - License: Creative Commons Attribution—NonCommercial 3.0 IGO (CC BY-NC 3.0 IGO)

4. **Private Participation in Infrastructure Project Database**
   - Source: World Bank
   - Topic: Private Sector & Trade: Private infrastructure investment
   - URL: [PPI World Bank](http://ppi.worldbank.org)

5. **Food and Agriculture Organization**
   - Source: Electronic files and website
   - Topic: Environment: Land use

6. **United Nations Population Division**
   - Source: World Population Prospects: 2022 Revision
   - Topic: Health: Population: Structure

7. **Food and Agriculture Organization and World Bank population estimates**
   - Source: Population estimates
   - Topic: Environment: Density & urbanization

8. **World Bank national accounts data**
   - Source: National accounts: US$ at current prices: Aggregate indicators
   - Topic: Economic Policy & Debt: National accounts

9. **World Bank national accounts data**
   - Source: National accounts: Growth rates
   - Topic: Economic Policy & Debt: National accounts
",.csv,True
Sustainable Energy Investment Forecast Dataset,4,sustainable-energy-investment-forecast-dataset,cleandataTurkiye.csv,Attribution 4.0 International (CC BY 4.0),"Here's a list of all the indicators from the dataset with their names and descriptions:


1. **CleanFuelAccess**
   - Long Name: CO2 emissions (metric tons per capita)
   - Long Definition: Access to clean fuels and technologies for cooking is the proportion of the total population primarily using clean cooking fuels and technologies for cooking. Kerosene is excluded from clean cooking fuels under WHO guidelines.

   **Temiz Yakıt Erişimi**
   - Uzun İsim: Kişi Başına CO2 Emisyonları (metrik ton)
   - Uzun Tanım: Temiz yakıt ve teknolojilere erişim, toplam nüfusun temel olarak temiz yemek pişirme yakıtları ve teknolojilerini kullanma oranını ifade eder. Temiz yemek pişirme yakıtları arasında WHO yönergelerine göre kerosen (gazyağı) hariçtir.

 + Temiz yakıt erişimi, insanların temiz yakıt ve teknolojileri kullanarak yemek pişirme alışkanlıklarını ne kadar yaygın olarak benimsediklerini gösteren bir ölçüttür. Bu, çevre dostu yakıtların kullanılmasıyla oluşan karbon emisyonlarının kişi başına düşen miktarını ölçmek için kullanılır. Kerosen ( Aydınlatma, Isıtma vb.) gibi kirletici yakıtlar temiz yakıtların dışında tutulur.

2. **ElectricityAccess**
   - Long Name: Access to clean fuels and technologies for cooking (% of population)
   - Long Definition: Access to electricity is the percentage of the population with access to electricity. Electrification data are collected from industry, national surveys, and international sources.

    **Elektrik Erişimi**
  - Uzun İsim: Temiz yakıt ve teknolojilere erişim (% nüfusa göre)
  - Uzun Tanım: Elektrik erişimi, nüfusun ne kadarının elektriğe erişiminin olduğunu gösteren bir orandır. Elektrifikasyon verileri, endüstriyel kaynaklar, ulusal anketler ve uluslararası kaynaklardan toplanır.

 + Elektrik erişimi, bir toplumun veya bölgenin elektrik enerjisine ne kadar yaygın bir şekilde erişebildiğini ölçen bir göstergedir. Bu, bir yerdeki enerji altyapısının gelişmişliğini ve elektrik kullanımının yaygınlığını belirlemek için kullanılır.

3. **CO2Emissions**
   - Long Name: Access to electricity (% of population)
   - Long Definition: Carbon dioxide emissions are those stemming from the burning of fossil fuels and the manufacture of cement. They include carbon dioxide produced during the consumption of solid, liquid, and gas fuels and gas flaring.

   **CO2 Emisyonları**
   - Uzun İsim: Elektriğe Erişim (% nüfusa göre)
   - Uzun Tanım: Karbon dioksit emisyonları, fosil yakıtların yakılmasından ve çimento üretiminden kaynaklanan emisyonlar dır. Bunlar, katı, sıvı ve gaz yakıtlarının tüketimi sırasında üretilen karbon dioksiti ve gaz yakma işleminden kaynaklanan emisyonları içerir.

 + CO2 emisyonları, fosil yakıtların ve diğer endüstriyel işlemlerin çevreye saldığı karbon dioksit gazını ifade eder. Bu emisyonlar, sera etkisi yaratarak iklim değişikliğine katkıda bulunabilir. Bu nedenle, fosil yakıtların kullanımının azaltılması ve daha temiz enerji kaynaklarının tercih edilmesi, karbon emisyonlarını azaltma hedeflerini destekler.

4. **ElecPowerConsumption**
   - Long Name: Electric power consumption (kWh per capita)
   - Long Definition: Electric power consumption measures the production of power plants and combined heat and power plants less transmission, distribution, and transformation losses and own use by heat and power plants.

    **Elektrik Enerjisi Tüketimi**
   - Uzun İsim: Kişi Başına Elektrik Enerjisi Tüketimi (kWh)
   - Uzun Tanım: Elektrik enerjisi tüketimi, enerji santralleri ve kombine ısı ve enerji santrallerinin üretimini, iletim, dağıtım ve dönüşüm kayıplarını ve ısı ve enerji santralleri tarafından kendi kullanımlarını içermeyen enerji tüketimini ölçer.

 + Elektrik enerjisi tüketimi, bir toplumun veya bölgenin elektrik enerjisi ne kadar tükettiğini gösteren bir ölçüttür. Bu, enerji üretimi ve dağıtımıyla ilgili verileri ifade eder ve enerji kaynaklarının kullanımının ve enerji altyapısının etkinliğinin bir göstergesidir. Kişi başına elektrik enerjisi tüketimi, bir kişinin ortalama olarak ne kadar elektrik kullandığını gösterir.

5. **CoalElectricity**
   - Long Name: Electricity production from coal sources (% of total)
   - Long Definition: Sources of electricity refer to the inputs used to generate electricity. Coal refers to all coal and brown coal, both primary (including hard coal and lignite-brown coal) and derived fuels (including patent fuel, coke oven coke, gas coke, coke oven gas, and blast furnace gas). Peat is also included in this category.

    **Kömür Kaynaklı Elektrik**
    - Uzun İsim: Kömür kaynaklı elektrik üretimi (toplamın yüzdesi)
    - Uzun Tanım: Elektrik kaynakları, elektrik üretmek için kullanılan girdileri ifade eder. Kömür, tüm kömür ve kahverengi kömürü içerir, hem birincil (sert kömür ve linyit-kahverengi kömür dahil) hem de türetilmiş yakıtları (patent yakıt, kok fırını kokusu, gaz kokusu, kok fırını gazı ve yüksek fırın gazı dahil). Turba da bu kategoriye dahildir.

 + Kömür kaynaklı elektrik, toplam elektrik üretiminin ne kadarının kömür gibi fosil yakıtlardan geldiğini gösteren bir ölçüttür. Kömür, elektrik üretimi için kullanılan önemli bir enerji kaynağıdır, ancak çevresel etkileri ve karbon emisyonları nedeniyle çevre açısından sorunlu olarak kabul edilir. Bu nedenle, kömür kaynaklı elektrik üretiminin azaltılması, temiz enerji kaynaklarının teşvik edilmesi ve enerji verimliliğinin artırılması, sürdürülebilir enerji hedeflerine katkıda bulunabilir.

6. **HydroElectricity**
   - Long Name: Electricity production from hydroelectric sources (% of total)
   - Long Definition: Sources of electricity refer to the inputs used to generate electricity. Hydropower refers to electricity produced by hydroelectric power plants.

   **Hidroelektrik Elektrik**
   - Uzun İsim: Hidroelektrik kaynaklı elektrik üretimi (toplamın yüzdesi)
   - Uzun Tanım: Elektrik kaynakları, elektrik üretmek için kullanılan girdileri ifade eder. Hidroelektrik enerji, hidroelektrik santralleri tarafından üretilen elektriği ifade eder.

+ Hidroelektrik elektrik, toplam elektrik üretiminin ne kadarının hidroelektrik santraller gibi su kaynaklarından geldiğini gösteren bir ölçüttür. Bu tür elektrik üretimi, suyun kinetik enerjisini elektriğe dönüştüren hidroelektrik santraller kullanılarak gerçekleştirilir. Hidroelektrik enerji temiz ve sürdürülebilir bir enerji kaynağı olarak kabul edilir ve karbon emisyonlarını azaltma çabalarına katkıda bulunabilir.

7. **GasElectricity**
   - Long Name: Electricity production from natural gas sources (% of total)
   - Long Definition: Sources of electricity refer to the inputs used to generate electricity. Gas refers to natural gas but excludes natural gas liquids.

   **Doğalgaz Elektriği**
   - Uzun İsim: Doğalgaz kaynaklı elektrik üretimi (toplamın yüzdesi)
   - Uzun Tanım: Elektrik üretimi için kullanılan kaynaklar, elektrik üretiminde kullanılan girdilere atıfta bulunur. ""Gaz,"" doğalgazı ifade eder, ancak doğalgaz sıvılarını içermez.

 + Doğalgaz Elektriği, toplam elektrik üretiminin ne kadarının doğalgaz kaynaklarından geldiğini gösteren bir ölçüttür. Bu terim, elektrik üretimi için kullanılan girdileri ifade ederken ""gaz"" doğalgazı ifade eder, ancak doğalgaz sıvılarını kapsamaz. Yani, bu, elektriğin doğalgaz kullanılarak üretildiği oranı gösterir.

8. **NuclearElectricity**
   - Long Name: Electricity production from nuclear sources (% of total)
   - Long Definition: Sources of electricity refer to the inputs used to generate electricity. Nuclear power refers to electricity produced by nuclear power plants.

   **Nükleer Elektrik**
   - Uzun İsim: Nükleer kaynaklı elektrik üretimi (toplamın yüzdesi)
   - Uzun Tanım: Elektrik üretimi için kullanılan girdilere atıfta bulunan elektrik kaynakları. Nükleer enerji, nükleer enerji santralleri tarafından üretilen elektriği ifade eder.

 + Nükleer Elektrik, toplam elektrik üretiminin ne kadarının nükleer kaynaklardan geldiğini gösteren bir ölçüttür. Bu terim, elektrik üretimi için kullanılan girdilere atıfta bulunurken ""nükleer enerji,"" nükleer enerji santralleri tarafından üretilen elektriği ifade eder.

9. **OilElectricity**
   - Long Name: Electricity production from oil sources (% of total)
   - Long Definition: Sources of electricity refer to the inputs used to generate electricity. Oil refers to crude oil and petroleum products.

    **Petrol Elektriği**
   - Uzun İsim: Petrol kaynaklı elektrik üretimi (toplamın yüzdesi)
   - Uzun Tanım: Elektrik üretimi için kullanılan girdilere atıfta bulunan elektrik kaynakları. ""Petrol,"" ham petrol ve petrol ürünlerini ifade eder.

 + Petrol Elektriği, toplam elektrik üretiminin ne kadarının petrol kaynaklarından geldiğini gösteren bir ölçüttür. Bu terim, elektrik üretimi için kullanılan girdilere atıfta bulunurken ""petrol,"" ham petrol ve petrol ürünlerini ifade eder.

10.**RenewableElectricity**
    - Long Name: Electricity production from renewable sources, excluding hydroelectric (% of total)
    - Long Definition: Electricity production from renewable sources, excluding hydroelectric, includes geothermal, solar, tides, wind, biomass, and biofuels.

    **Yenilenebilir Enerji Elektriği**
   - Uzun İsim: Hidroelektrik dışındaki yenilenebilir kaynaklardan elektrik üretimi (toplamın yüzdesi)
   - Uzun Tanım: Hidroelektrik dışındaki yenilenebilir kaynaklardan, yani jeotermal, güneş, gelgit, rüzgar, biyokütle ve biyoyakıtlardan elektrik üretimi.

 + Yenilenebilir Enerji Elektriği, hidroelektrik dışındaki yenilenebilir kaynaklardan (jeotermal, güneş, gelgit, rüzgar, biyokütle ve biyoyakıtlar) elde edilen elektriğin, toplam elektrik üretiminin yüzdesini ifade eder. Bu, sürdürülebilir ve çevre dostu enerji üretiminin payını ölçmek için kullanılır.

11. **RenewableElectricity_kWh**
    - Long Name: Electricity production from renewable sources, excluding hydroelectric (kWh)
    - Long Definition: Electricity production from renewable sources, excluding hydroelectric, includes geothermal, solar, tides, wind, biomass, and biofuels.

    **Yenilenebilir Enerji Elektriği (kWh)**
   - Uzun İsim: Hidroelektrik dışındaki yenilenebilir kaynaklardan elektrik üretimi (kWh cinsinden)
   - Uzun Tanım: Hidroelektrik dışındaki yenilenebilir kaynaklardan, yani jeotermal, güneş, gelgit, rüzgar, biyokütle ve biyoyakıtlardan elektrik üretimi (kWh cinsinden).

 + Yenilenebilir Enerji Elektriği (kWh), hidroelektrik dışındaki yenilenebilir kaynaklardan (jeotermal, güneş, gelgit, rüzgar, biyokütle ve biyoyakıtlar) elde edilen elektriği ölçer ve bu elektriğin miktarını kilowatt saat (kWh) cinsinden ifade eder. Bu, sürdürülebilir enerji üretiminin miktarını belirlemek için kullanılır.

12. **EnergyIntensity**
    - Long Name: Energy intensity level of primary energy (MJ/$2017 PPP GDP)
    - Long Definition: Energy intensity level of primary energy is the ratio between energy supply and gross domestic product measured at purchasing power parity. It indicates how much energy is used to produce one unit of economic output.

    **Enerji Yoğunluğu**
   - Uzun İsim: Birincil enerjinin enerji yoğunluğu düzeyi (MJ/$2017 PPP GSYİH)
   - Uzun Tanım: Birincil enerjinin enerji yoğunluğu düzeyi, satın alma gücü paritesi ile ölçülen enerji arzı ile gayri safi yurt içi hasıla (GSYİH) arasındaki oranı ifade eder. Bu, bir birim ekonomik üretim için ne kadar enerji kullanıldığını gösterir.

 + Enerji Yoğunluğu, enerji arzı ile GSYİH arasındaki oranı kullanarak ekonomik üretim için ne kadar enerji harcandığını gösteren bir ölçüttür. Bu, enerji kullanımının ekonomik verimliliğini belirlemek için kullanılır.

13. **EnergyUse**
    - Long Name: Energy use (kg of oil equivalent per capita)
    - Long Definition: Energy use refers to the use of primary energy before transformation to other end-use fuels, which includes indigenous production plus imports and stock changes, minus exports and fuels supplied to ships and aircraft engaged in international transport.

    **Enerji Kullanımı**
   - Uzun İsim: Kişi başına düşen enerji kullanımı (ton petrol eşdeğeri cinsinden)
   - Uzun Tanım: Enerji kullanımı, diğer kullanım yakıtlarına dönüşmeden önce birincil enerjinin kullanımını ifade eder. Bu, yerel üretimi ve ithalatları, stok değişikliklerini içerirken, ihracatları ve uluslararası taşımacılık yapan gemilere ve uçaklara sağlanan yakıtları çıkarır.

 + Enerji Kullanımı, birincil enerjinin diğer kullanım formlarına dönüşmeden önceki kullanımını ifade eder ve kişi başına düşen enerji tüketimini ton petrol eşdeğeri cinsinden ölçer. Bu, enerji tüketiminin kişi başına dağılımını gösterir.

14. **FossilFuelConsumption**
    - Long Name: Fossil fuel energy consumption (% of total)
    - Long Definition: Fossil fuel comprises coal, oil, petroleum, and natural gas products.

    **Fosil Yakıt Tüketimi**
   - Uzun İsim: Toplamın yüzdesine göre fosil yakıt enerjisi tüketimi
   - Uzun Tanım: Fosil yakıtlar, kömür, petrol, petrol ürünleri ve doğalgaz ürünlerini içerir. Bu, toplam enerji tüketiminin ne kadarının fosil yakıtlardan geldiğini gösterir.

 + Fosil Yakıt Tüketimi, enerji tüketiminin ne kadarının fosil yakıtlardan (kömür, petrol, petrol ürünleri ve doğalgaz) kaynaklandığını gösteren bir ölçüttür. Bu, enerji kaynaklarının kullanımının çevresel etkilerini değerlendirmek ve enerji dönüşümünün sürdürülebilirliğini incelemek için önemlidir.

15. **GDPGrowth**
    - Long Name: GDP growth (annual %)
    - Long Definition: Annual percentage growth rate of GDP at market prices based on constant local currency. It is expressed in U.S. dollars and represents the sum of gross value added by all resident producers in the economy.

    **GDP Büyüme Hızı**
   - Uzun İsim: GDP ""Gross Domestic Product"" büyüme hızı (yıllık %)
   - Uzun Tanım: Sabit yerel para birimine dayalı olarak piyasa fiyatlarıyla GDP'nin yıllık yüzde büyüme hızı. Bu, ABD doları cinsinden ifade edilir ve ekonominin tüm yerel üreticileri tarafından katkıda bulunulan brüt katma değeri temsil eder.

 + GDP Büyüme Hızı, piyasa fiyatlarına dayalı olarak sabit yerel para birimindeki yıllık GDP büyüme hızını ölçer. Bu, ekonominin tüm yerel üreticilerinin ekonomiye katkısının toplamını temsil eder ve genellikle ekonominin büyüme veya daralma eğilimini gösterir.

16. **GDPPerCapita**
    - Long Name: GDP per capita (current US$)
    - Long Definition: GDP per capita is gross domestic product divided by midyear population. It is expressed in current U.S. dollars and represents the sum of gross value added by all resident producers in the economy.

    **Kişi Başına GDP**
   - Uzun İsim: Kişi başına düşen GDP (güncel ABD doları cinsinden)
   - Uzun Tanım: Kişi başına düşen GDP, GDP'nin yıl ortası nüfusuyla bölünmesiyle hesaplanır. Bu, güncel ABD doları cinsinden ifade edilir ve ekonominin tüm yerel üreticileri tarafından katkıda bulunulan brüt katma değeri toplamını temsil eder.

 + Kişi Başına GDP, GDP'nin ülkenin yıl ortası nüfusuna bölünmesiyle hesaplanan bir göstergedir. Bu, kişi başına düşen ekonomik üretimi ölçmek için kullanılır ve bir ülkenin ekonomik refah seviyesini değerlendirmek için önemlidir.

17. **PrivateEnergyInvest**
    - Long Name: Investment in energy with private participation (current US$)
    - Long Definition: Investment in energy projects with private participation refers to commitments to infrastructure projects in energy (electricity and natural gas: generation, transmission, and distribution) that have reached financial closure and serve the public. It excludes movable assets and small projects such as windmills.

    **Özel Katılımlı Enerji Yatırımı**
   - Uzun İsim: Özel katılımlı enerji projelerine yapılan yatırım (güncel ABD doları cinsinden)
   - Uzun Tanım: Özel katılımlı enerji projelerine yapılan yatırım, enerji altyapı projelerine (elektrik ve doğalgaz: üretim, iletim ve dağıtım) finansal kapanışa ulaşmış ve kamu hizmeti sunan taahhütleri ifade eder. Bu, taşınabilir varlıkları ve rüzgar türbinleri gibi küçük projeleri içermez.

 + Özel Katılımlı Enerji Yatırımı, kamu hizmeti sunan enerji altyapı projelerine yapılan finansal taahhütlere odaklanan yatırımları ifade eder. Bu, özellikle elektrik ve doğalgaz sektörlerinde büyük projelere yönelik yatırımı gösterir ve küçük projeleri veya taşınabilir varlıkları kapsamaz.

18. **LandArea**
    - Long Name: Land area (sq. km)
    - Long Definition: Land area is a country's total area, excluding area under inland water bodies, national claims to the continental shelf, and exclusive economic zones. It includes major rivers and lakes.

    **Arazi Alanı** 
   - Uzun İsim: Arazi alanı (km² cinsinden)
   - Uzun Tanım: Arazi alanı, bir ülkenin iç sularda bulunan alanlar, kıta sahanlığına yönelik ulusal talepler ve özel ekonomik bölgeleri hariç tutarak hesaplanan toplam alanını ifade eder. Bu, büyük nehirleri ve gölleri içerir.

 + Arazi Alanı, bir ülkenin kara yüzeyinin, iç sulardan, kıta sahanlığındaki ulusal taleplerden ve özel ekonomik bölgelerden hariç tutularak hesaplanan toplam alanını temsil eder. Bu, bir ülkenin toprak büyüklüğünü gösterir ve içerisine büyük nehirler ve gölleri de dahil eder.

19. **PopDensity**
    - Long Name: Population density (people per sq. km of land area)
    - Long Definition: Population density is midyear population divided by land area in square kilometers, based on the de facto definition of population.

    ** Nüfus Yoğunluğu**
   - Uzun İsim: Nüfus yoğunluğu (arazi alanı başına kişi sayısı olarak)
   - Uzun Tanım: Nüfus yoğunluğu, yılın ortasındaki nüfusun arazi alanı (kare kilometre cinsinden) ile bölünmesiyle hesaplanır ve nüfusun de facto tanımına dayanır.

 + Nüfus Yoğunluğu, yılın ortasındaki nüfusun arazi alanına (kare kilometre cinsinden) bölünmesiyle hesaplanan bir göstergedir ve bir bölgedeki kişi sayısının yoğunluğunu ölçer.

20. **TotalPopulation**
    - Long Name: Population, total
    - Long Definition: Total population is based on the de facto definition of population, counting all residents regardless of legal status or citizenship.

    **Toplam Nüfus**
   - Uzun İsim: Toplam nüfus
   - Uzun Tanım: Toplam nüfus, nüfusun de facto tanımına dayanarak, hukuki statü veya vatandaşlık durumuna bakılmaksızın tüm yerleşikleri sayan bir göstergedir.

 + Toplam Nüfus, hukuki statü veya vatandaşlık durumundan bağımsız olarak tüm yerleşikleri sayarak hesaplanan bir nüfus ölçüsüdür.

21. **Private Partnership Investment in Energy (Current US$)**
    - Long Name: Public private partnerships investment in energy (current US$)
    - Long Definition: Public Private Partnerships in energy (current US$) refer to commitments to infrastructure projects in energy (electricity and natural gas transmission and distribution) that have reached financial closure and serve the public. It excludes divestitures and merchant projects.

    **Enerjide Kamu-Özel Ortaklığı Yatırımı (Güncel ABD Doları)**
   - Uzun İsim: Enerjide kamu-özel ortaklığı yatırımı (güncel ABD doları cinsinden)
   - Uzun Tanım: Enerjide Kamu-Özel Ortaklıkları (güncel ABD doları) enerji altyapı projelerine (elektrik ve doğalgaz iletim ve dağıtım) yapılan taahhütleri ifade eder. Bu projeler finansal kapanışa ulaşmış ve halka hizmet vermektedir. Bu tanım, varlık satışlarını ve tüccar projelerini içermez.

 + Enerjide Kamu-Özel Ortaklığı Yatırımı, halka hizmet veren enerji altyapı projelerine yapılan finansal taahhütleri ifade eder ve varlık satışlarını ve tüccar projelerini kapsamaz.

22. **RenewableEnergyConsumption**
    - Long Name: Renewable energy consumption (% of total final energy consumption)
    - Long Definition: Renewable energy consumption is the share of renewable energy in total final energy consumption.

    **Yenilenebilir Enerji Tüketimi**
   - Uzun İsim: Yenilenebilir enerji tüketimi (toplam nihai enerji tüketiminin yüzdesi)
   - Uzun Tanım: Yenilenebilir enerji tüketimi, toplam nihai enerji tüketiminin içindeki yenilenebilir enerjinin payını ifade eder.

 + Yenilenebilir Enerji Tüketimi, toplam nihai enerji tüketiminin içindeki yenilenebilir enerjinin yüzdesini gösterir. Bu, bir ülkenin enerji tüketiminin ne kadarının yenilenebilir kaynaklardan geldiğini gösteren bir ölçüttür ve sürdürülebilir enerji kullanımının bir göstergesidir.

23. **TotalGHGEmissions**
    - Long Name: Total greenhouse gas emissions (kt of CO2 equivalent)
    - Long Definition: Total greenhouse gas emissions in kt of CO2 equivalent include CO2 totals excluding short-cycle biomass burning, all anthropogenic CH4 sources, N2O sources, and F-gases (HFCs, PFCs, and SF6).

    **Toplam sera gazı emisyonları**
   - Uzun İsim: Toplam sera gazı emisyonları (kt CO2 eşdeğeri cinsinden)
   - Uzun Tanım: kt CO2 eşdeğerindeki toplam sera gazı emisyonları, kısa döngü biyokütle yanmasını dışlayan CO2 toplamlarını, tüm antropojenik CH4 kaynaklarını, N2O kaynaklarını ve F-gazlarını (HFC'ler, PFC'ler ve SF6) içerir.

 + Toplam Sera Gazı Emisyonları, kt CO2 eşdeğeri cinsinden ifade edilen ve CO2 dışında diğer sera gazlarını (CH4, N2O ve F-gazları) içeren emisyonların toplamını temsil eder. Bu, bir ülkenin sera gazı emisyonlarını ölçmek için kullanılır ve çevresel etkileri ve iklim değişikliği ile ilgili verileri değerlendirmek için önemlidir.

24. **Latitude**
- **Indicator Name:** Latitude
- **Description:** Latitude of the country's centroid in decimal degrees.

    **Enlem**
   - Uzun İsim: Enlem
   - Uzun Tanım: Ülkenin merkez noktasının enlemi ondalık derece cinsinden ifade edilir.

 + Enlem, bir ülkenin merkez noktasının yeryüzündeki konumunu belirlemek için kullanılan bir koordinat ölçüsüdür ve enlem hatları Kuzey ve Güney yönlerindeki konumları tanımlar.

25. **Longitude**
- **Indicator Name:** Longitude
- **Description:** Longitude of the country's centroid in decimal degrees.

    **Boylam**
   - Uzun İsim: Boylam
   - Uzun Tanım: Ülkenin merkez noktasının boylamı ondalık derece cinsinden ifade edilir.

 + Boylam, bir ülkenin merkez noktasının yeryüzündeki konumunu belirlemek için kullanılan bir koordinat ölçüsüdür ve boylam hatları Doğu ve Batı yönlerindeki konumları tanımlar.

****Sources / Kaynaklar:
****

1. **Climate Watch Historical GHG Emissions (1990-2020)**
   - Source: World Resources Institute
   - Topic: Environment: Emissions
   - URL: [Climate Watch GHG Emissions](https://www.climatewatchdata.org/ghg-emissions)

2. **IEA Statistics**
   - Source: OECD/IEA 2014
   - Topic: Environment: Energy production & use
   - URL: [IEA Statistics](http://www.iea.org/stats/index.asp)
   - Note: Subject to [IEA Terms and Conditions](https://www.iea.org/t&c/termsandconditions/)

3. **Tracking SDG 7: The Energy Progress Report (2023)**
   - Source: IEA, IRENA, UNSD, World Bank, WHO
   - Topic: Environment: Energy production & use
   - Source: World Bank, Washington DC
   - License: Creative Commons Attribution—NonCommercial 3.0 IGO (CC BY-NC 3.0 IGO)

4. **Private Participation in Infrastructure Project Database**
   - Source: World Bank
   - Topic: Private Sector & Trade: Private infrastructure investment
   - URL: [PPI World Bank](http://ppi.worldbank.org)

5. **Food and Agriculture Organization**
   - Source: Electronic files and website
   - Topic: Environment: Land use

6. **United Nations Population Division**
   - Source: World Population Prospects: 2022 Revision
   - Topic: Health: Population: Structure

7. **Food and Agriculture Organization and World Bank population estimates**
   - Source: Population estimates
   - Topic: Environment: Density & urbanization

8. **World Bank national accounts data**
   - Source: National accounts: US$ at current prices: Aggregate indicators
   - Topic: Economic Policy & Debt: National accounts

9. **World Bank national accounts data**
   - Source: National accounts: Growth rates
   - Topic: Economic Policy & Debt: National accounts
",.csv,True
Sustainable Energy Investment Forecast Dataset,4,sustainable-energy-investment-forecast-dataset,new_data.csv,Attribution 4.0 International (CC BY 4.0),"Here's a list of all the indicators from the dataset with their names and descriptions:


1. **CleanFuelAccess**
   - Long Name: CO2 emissions (metric tons per capita)
   - Long Definition: Access to clean fuels and technologies for cooking is the proportion of the total population primarily using clean cooking fuels and technologies for cooking. Kerosene is excluded from clean cooking fuels under WHO guidelines.

   **Temiz Yakıt Erişimi**
   - Uzun İsim: Kişi Başına CO2 Emisyonları (metrik ton)
   - Uzun Tanım: Temiz yakıt ve teknolojilere erişim, toplam nüfusun temel olarak temiz yemek pişirme yakıtları ve teknolojilerini kullanma oranını ifade eder. Temiz yemek pişirme yakıtları arasında WHO yönergelerine göre kerosen (gazyağı) hariçtir.

 + Temiz yakıt erişimi, insanların temiz yakıt ve teknolojileri kullanarak yemek pişirme alışkanlıklarını ne kadar yaygın olarak benimsediklerini gösteren bir ölçüttür. Bu, çevre dostu yakıtların kullanılmasıyla oluşan karbon emisyonlarının kişi başına düşen miktarını ölçmek için kullanılır. Kerosen ( Aydınlatma, Isıtma vb.) gibi kirletici yakıtlar temiz yakıtların dışında tutulur.

2. **ElectricityAccess**
   - Long Name: Access to clean fuels and technologies for cooking (% of population)
   - Long Definition: Access to electricity is the percentage of the population with access to electricity. Electrification data are collected from industry, national surveys, and international sources.

    **Elektrik Erişimi**
  - Uzun İsim: Temiz yakıt ve teknolojilere erişim (% nüfusa göre)
  - Uzun Tanım: Elektrik erişimi, nüfusun ne kadarının elektriğe erişiminin olduğunu gösteren bir orandır. Elektrifikasyon verileri, endüstriyel kaynaklar, ulusal anketler ve uluslararası kaynaklardan toplanır.

 + Elektrik erişimi, bir toplumun veya bölgenin elektrik enerjisine ne kadar yaygın bir şekilde erişebildiğini ölçen bir göstergedir. Bu, bir yerdeki enerji altyapısının gelişmişliğini ve elektrik kullanımının yaygınlığını belirlemek için kullanılır.

3. **CO2Emissions**
   - Long Name: Access to electricity (% of population)
   - Long Definition: Carbon dioxide emissions are those stemming from the burning of fossil fuels and the manufacture of cement. They include carbon dioxide produced during the consumption of solid, liquid, and gas fuels and gas flaring.

   **CO2 Emisyonları**
   - Uzun İsim: Elektriğe Erişim (% nüfusa göre)
   - Uzun Tanım: Karbon dioksit emisyonları, fosil yakıtların yakılmasından ve çimento üretiminden kaynaklanan emisyonlar dır. Bunlar, katı, sıvı ve gaz yakıtlarının tüketimi sırasında üretilen karbon dioksiti ve gaz yakma işleminden kaynaklanan emisyonları içerir.

 + CO2 emisyonları, fosil yakıtların ve diğer endüstriyel işlemlerin çevreye saldığı karbon dioksit gazını ifade eder. Bu emisyonlar, sera etkisi yaratarak iklim değişikliğine katkıda bulunabilir. Bu nedenle, fosil yakıtların kullanımının azaltılması ve daha temiz enerji kaynaklarının tercih edilmesi, karbon emisyonlarını azaltma hedeflerini destekler.

4. **ElecPowerConsumption**
   - Long Name: Electric power consumption (kWh per capita)
   - Long Definition: Electric power consumption measures the production of power plants and combined heat and power plants less transmission, distribution, and transformation losses and own use by heat and power plants.

    **Elektrik Enerjisi Tüketimi**
   - Uzun İsim: Kişi Başına Elektrik Enerjisi Tüketimi (kWh)
   - Uzun Tanım: Elektrik enerjisi tüketimi, enerji santralleri ve kombine ısı ve enerji santrallerinin üretimini, iletim, dağıtım ve dönüşüm kayıplarını ve ısı ve enerji santralleri tarafından kendi kullanımlarını içermeyen enerji tüketimini ölçer.

 + Elektrik enerjisi tüketimi, bir toplumun veya bölgenin elektrik enerjisi ne kadar tükettiğini gösteren bir ölçüttür. Bu, enerji üretimi ve dağıtımıyla ilgili verileri ifade eder ve enerji kaynaklarının kullanımının ve enerji altyapısının etkinliğinin bir göstergesidir. Kişi başına elektrik enerjisi tüketimi, bir kişinin ortalama olarak ne kadar elektrik kullandığını gösterir.

5. **CoalElectricity**
   - Long Name: Electricity production from coal sources (% of total)
   - Long Definition: Sources of electricity refer to the inputs used to generate electricity. Coal refers to all coal and brown coal, both primary (including hard coal and lignite-brown coal) and derived fuels (including patent fuel, coke oven coke, gas coke, coke oven gas, and blast furnace gas). Peat is also included in this category.

    **Kömür Kaynaklı Elektrik**
    - Uzun İsim: Kömür kaynaklı elektrik üretimi (toplamın yüzdesi)
    - Uzun Tanım: Elektrik kaynakları, elektrik üretmek için kullanılan girdileri ifade eder. Kömür, tüm kömür ve kahverengi kömürü içerir, hem birincil (sert kömür ve linyit-kahverengi kömür dahil) hem de türetilmiş yakıtları (patent yakıt, kok fırını kokusu, gaz kokusu, kok fırını gazı ve yüksek fırın gazı dahil). Turba da bu kategoriye dahildir.

 + Kömür kaynaklı elektrik, toplam elektrik üretiminin ne kadarının kömür gibi fosil yakıtlardan geldiğini gösteren bir ölçüttür. Kömür, elektrik üretimi için kullanılan önemli bir enerji kaynağıdır, ancak çevresel etkileri ve karbon emisyonları nedeniyle çevre açısından sorunlu olarak kabul edilir. Bu nedenle, kömür kaynaklı elektrik üretiminin azaltılması, temiz enerji kaynaklarının teşvik edilmesi ve enerji verimliliğinin artırılması, sürdürülebilir enerji hedeflerine katkıda bulunabilir.

6. **HydroElectricity**
   - Long Name: Electricity production from hydroelectric sources (% of total)
   - Long Definition: Sources of electricity refer to the inputs used to generate electricity. Hydropower refers to electricity produced by hydroelectric power plants.

   **Hidroelektrik Elektrik**
   - Uzun İsim: Hidroelektrik kaynaklı elektrik üretimi (toplamın yüzdesi)
   - Uzun Tanım: Elektrik kaynakları, elektrik üretmek için kullanılan girdileri ifade eder. Hidroelektrik enerji, hidroelektrik santralleri tarafından üretilen elektriği ifade eder.

+ Hidroelektrik elektrik, toplam elektrik üretiminin ne kadarının hidroelektrik santraller gibi su kaynaklarından geldiğini gösteren bir ölçüttür. Bu tür elektrik üretimi, suyun kinetik enerjisini elektriğe dönüştüren hidroelektrik santraller kullanılarak gerçekleştirilir. Hidroelektrik enerji temiz ve sürdürülebilir bir enerji kaynağı olarak kabul edilir ve karbon emisyonlarını azaltma çabalarına katkıda bulunabilir.

7. **GasElectricity**
   - Long Name: Electricity production from natural gas sources (% of total)
   - Long Definition: Sources of electricity refer to the inputs used to generate electricity. Gas refers to natural gas but excludes natural gas liquids.

   **Doğalgaz Elektriği**
   - Uzun İsim: Doğalgaz kaynaklı elektrik üretimi (toplamın yüzdesi)
   - Uzun Tanım: Elektrik üretimi için kullanılan kaynaklar, elektrik üretiminde kullanılan girdilere atıfta bulunur. ""Gaz,"" doğalgazı ifade eder, ancak doğalgaz sıvılarını içermez.

 + Doğalgaz Elektriği, toplam elektrik üretiminin ne kadarının doğalgaz kaynaklarından geldiğini gösteren bir ölçüttür. Bu terim, elektrik üretimi için kullanılan girdileri ifade ederken ""gaz"" doğalgazı ifade eder, ancak doğalgaz sıvılarını kapsamaz. Yani, bu, elektriğin doğalgaz kullanılarak üretildiği oranı gösterir.

8. **NuclearElectricity**
   - Long Name: Electricity production from nuclear sources (% of total)
   - Long Definition: Sources of electricity refer to the inputs used to generate electricity. Nuclear power refers to electricity produced by nuclear power plants.

   **Nükleer Elektrik**
   - Uzun İsim: Nükleer kaynaklı elektrik üretimi (toplamın yüzdesi)
   - Uzun Tanım: Elektrik üretimi için kullanılan girdilere atıfta bulunan elektrik kaynakları. Nükleer enerji, nükleer enerji santralleri tarafından üretilen elektriği ifade eder.

 + Nükleer Elektrik, toplam elektrik üretiminin ne kadarının nükleer kaynaklardan geldiğini gösteren bir ölçüttür. Bu terim, elektrik üretimi için kullanılan girdilere atıfta bulunurken ""nükleer enerji,"" nükleer enerji santralleri tarafından üretilen elektriği ifade eder.

9. **OilElectricity**
   - Long Name: Electricity production from oil sources (% of total)
   - Long Definition: Sources of electricity refer to the inputs used to generate electricity. Oil refers to crude oil and petroleum products.

    **Petrol Elektriği**
   - Uzun İsim: Petrol kaynaklı elektrik üretimi (toplamın yüzdesi)
   - Uzun Tanım: Elektrik üretimi için kullanılan girdilere atıfta bulunan elektrik kaynakları. ""Petrol,"" ham petrol ve petrol ürünlerini ifade eder.

 + Petrol Elektriği, toplam elektrik üretiminin ne kadarının petrol kaynaklarından geldiğini gösteren bir ölçüttür. Bu terim, elektrik üretimi için kullanılan girdilere atıfta bulunurken ""petrol,"" ham petrol ve petrol ürünlerini ifade eder.

10.**RenewableElectricity**
    - Long Name: Electricity production from renewable sources, excluding hydroelectric (% of total)
    - Long Definition: Electricity production from renewable sources, excluding hydroelectric, includes geothermal, solar, tides, wind, biomass, and biofuels.

    **Yenilenebilir Enerji Elektriği**
   - Uzun İsim: Hidroelektrik dışındaki yenilenebilir kaynaklardan elektrik üretimi (toplamın yüzdesi)
   - Uzun Tanım: Hidroelektrik dışındaki yenilenebilir kaynaklardan, yani jeotermal, güneş, gelgit, rüzgar, biyokütle ve biyoyakıtlardan elektrik üretimi.

 + Yenilenebilir Enerji Elektriği, hidroelektrik dışındaki yenilenebilir kaynaklardan (jeotermal, güneş, gelgit, rüzgar, biyokütle ve biyoyakıtlar) elde edilen elektriğin, toplam elektrik üretiminin yüzdesini ifade eder. Bu, sürdürülebilir ve çevre dostu enerji üretiminin payını ölçmek için kullanılır.

11. **RenewableElectricity_kWh**
    - Long Name: Electricity production from renewable sources, excluding hydroelectric (kWh)
    - Long Definition: Electricity production from renewable sources, excluding hydroelectric, includes geothermal, solar, tides, wind, biomass, and biofuels.

    **Yenilenebilir Enerji Elektriği (kWh)**
   - Uzun İsim: Hidroelektrik dışındaki yenilenebilir kaynaklardan elektrik üretimi (kWh cinsinden)
   - Uzun Tanım: Hidroelektrik dışındaki yenilenebilir kaynaklardan, yani jeotermal, güneş, gelgit, rüzgar, biyokütle ve biyoyakıtlardan elektrik üretimi (kWh cinsinden).

 + Yenilenebilir Enerji Elektriği (kWh), hidroelektrik dışındaki yenilenebilir kaynaklardan (jeotermal, güneş, gelgit, rüzgar, biyokütle ve biyoyakıtlar) elde edilen elektriği ölçer ve bu elektriğin miktarını kilowatt saat (kWh) cinsinden ifade eder. Bu, sürdürülebilir enerji üretiminin miktarını belirlemek için kullanılır.

12. **EnergyIntensity**
    - Long Name: Energy intensity level of primary energy (MJ/$2017 PPP GDP)
    - Long Definition: Energy intensity level of primary energy is the ratio between energy supply and gross domestic product measured at purchasing power parity. It indicates how much energy is used to produce one unit of economic output.

    **Enerji Yoğunluğu**
   - Uzun İsim: Birincil enerjinin enerji yoğunluğu düzeyi (MJ/$2017 PPP GSYİH)
   - Uzun Tanım: Birincil enerjinin enerji yoğunluğu düzeyi, satın alma gücü paritesi ile ölçülen enerji arzı ile gayri safi yurt içi hasıla (GSYİH) arasındaki oranı ifade eder. Bu, bir birim ekonomik üretim için ne kadar enerji kullanıldığını gösterir.

 + Enerji Yoğunluğu, enerji arzı ile GSYİH arasındaki oranı kullanarak ekonomik üretim için ne kadar enerji harcandığını gösteren bir ölçüttür. Bu, enerji kullanımının ekonomik verimliliğini belirlemek için kullanılır.

13. **EnergyUse**
    - Long Name: Energy use (kg of oil equivalent per capita)
    - Long Definition: Energy use refers to the use of primary energy before transformation to other end-use fuels, which includes indigenous production plus imports and stock changes, minus exports and fuels supplied to ships and aircraft engaged in international transport.

    **Enerji Kullanımı**
   - Uzun İsim: Kişi başına düşen enerji kullanımı (ton petrol eşdeğeri cinsinden)
   - Uzun Tanım: Enerji kullanımı, diğer kullanım yakıtlarına dönüşmeden önce birincil enerjinin kullanımını ifade eder. Bu, yerel üretimi ve ithalatları, stok değişikliklerini içerirken, ihracatları ve uluslararası taşımacılık yapan gemilere ve uçaklara sağlanan yakıtları çıkarır.

 + Enerji Kullanımı, birincil enerjinin diğer kullanım formlarına dönüşmeden önceki kullanımını ifade eder ve kişi başına düşen enerji tüketimini ton petrol eşdeğeri cinsinden ölçer. Bu, enerji tüketiminin kişi başına dağılımını gösterir.

14. **FossilFuelConsumption**
    - Long Name: Fossil fuel energy consumption (% of total)
    - Long Definition: Fossil fuel comprises coal, oil, petroleum, and natural gas products.

    **Fosil Yakıt Tüketimi**
   - Uzun İsim: Toplamın yüzdesine göre fosil yakıt enerjisi tüketimi
   - Uzun Tanım: Fosil yakıtlar, kömür, petrol, petrol ürünleri ve doğalgaz ürünlerini içerir. Bu, toplam enerji tüketiminin ne kadarının fosil yakıtlardan geldiğini gösterir.

 + Fosil Yakıt Tüketimi, enerji tüketiminin ne kadarının fosil yakıtlardan (kömür, petrol, petrol ürünleri ve doğalgaz) kaynaklandığını gösteren bir ölçüttür. Bu, enerji kaynaklarının kullanımının çevresel etkilerini değerlendirmek ve enerji dönüşümünün sürdürülebilirliğini incelemek için önemlidir.

15. **GDPGrowth**
    - Long Name: GDP growth (annual %)
    - Long Definition: Annual percentage growth rate of GDP at market prices based on constant local currency. It is expressed in U.S. dollars and represents the sum of gross value added by all resident producers in the economy.

    **GDP Büyüme Hızı**
   - Uzun İsim: GDP ""Gross Domestic Product"" büyüme hızı (yıllık %)
   - Uzun Tanım: Sabit yerel para birimine dayalı olarak piyasa fiyatlarıyla GDP'nin yıllık yüzde büyüme hızı. Bu, ABD doları cinsinden ifade edilir ve ekonominin tüm yerel üreticileri tarafından katkıda bulunulan brüt katma değeri temsil eder.

 + GDP Büyüme Hızı, piyasa fiyatlarına dayalı olarak sabit yerel para birimindeki yıllık GDP büyüme hızını ölçer. Bu, ekonominin tüm yerel üreticilerinin ekonomiye katkısının toplamını temsil eder ve genellikle ekonominin büyüme veya daralma eğilimini gösterir.

16. **GDPPerCapita**
    - Long Name: GDP per capita (current US$)
    - Long Definition: GDP per capita is gross domestic product divided by midyear population. It is expressed in current U.S. dollars and represents the sum of gross value added by all resident producers in the economy.

    **Kişi Başına GDP**
   - Uzun İsim: Kişi başına düşen GDP (güncel ABD doları cinsinden)
   - Uzun Tanım: Kişi başına düşen GDP, GDP'nin yıl ortası nüfusuyla bölünmesiyle hesaplanır. Bu, güncel ABD doları cinsinden ifade edilir ve ekonominin tüm yerel üreticileri tarafından katkıda bulunulan brüt katma değeri toplamını temsil eder.

 + Kişi Başına GDP, GDP'nin ülkenin yıl ortası nüfusuna bölünmesiyle hesaplanan bir göstergedir. Bu, kişi başına düşen ekonomik üretimi ölçmek için kullanılır ve bir ülkenin ekonomik refah seviyesini değerlendirmek için önemlidir.

17. **PrivateEnergyInvest**
    - Long Name: Investment in energy with private participation (current US$)
    - Long Definition: Investment in energy projects with private participation refers to commitments to infrastructure projects in energy (electricity and natural gas: generation, transmission, and distribution) that have reached financial closure and serve the public. It excludes movable assets and small projects such as windmills.

    **Özel Katılımlı Enerji Yatırımı**
   - Uzun İsim: Özel katılımlı enerji projelerine yapılan yatırım (güncel ABD doları cinsinden)
   - Uzun Tanım: Özel katılımlı enerji projelerine yapılan yatırım, enerji altyapı projelerine (elektrik ve doğalgaz: üretim, iletim ve dağıtım) finansal kapanışa ulaşmış ve kamu hizmeti sunan taahhütleri ifade eder. Bu, taşınabilir varlıkları ve rüzgar türbinleri gibi küçük projeleri içermez.

 + Özel Katılımlı Enerji Yatırımı, kamu hizmeti sunan enerji altyapı projelerine yapılan finansal taahhütlere odaklanan yatırımları ifade eder. Bu, özellikle elektrik ve doğalgaz sektörlerinde büyük projelere yönelik yatırımı gösterir ve küçük projeleri veya taşınabilir varlıkları kapsamaz.

18. **LandArea**
    - Long Name: Land area (sq. km)
    - Long Definition: Land area is a country's total area, excluding area under inland water bodies, national claims to the continental shelf, and exclusive economic zones. It includes major rivers and lakes.

    **Arazi Alanı** 
   - Uzun İsim: Arazi alanı (km² cinsinden)
   - Uzun Tanım: Arazi alanı, bir ülkenin iç sularda bulunan alanlar, kıta sahanlığına yönelik ulusal talepler ve özel ekonomik bölgeleri hariç tutarak hesaplanan toplam alanını ifade eder. Bu, büyük nehirleri ve gölleri içerir.

 + Arazi Alanı, bir ülkenin kara yüzeyinin, iç sulardan, kıta sahanlığındaki ulusal taleplerden ve özel ekonomik bölgelerden hariç tutularak hesaplanan toplam alanını temsil eder. Bu, bir ülkenin toprak büyüklüğünü gösterir ve içerisine büyük nehirler ve gölleri de dahil eder.

19. **PopDensity**
    - Long Name: Population density (people per sq. km of land area)
    - Long Definition: Population density is midyear population divided by land area in square kilometers, based on the de facto definition of population.

    ** Nüfus Yoğunluğu**
   - Uzun İsim: Nüfus yoğunluğu (arazi alanı başına kişi sayısı olarak)
   - Uzun Tanım: Nüfus yoğunluğu, yılın ortasındaki nüfusun arazi alanı (kare kilometre cinsinden) ile bölünmesiyle hesaplanır ve nüfusun de facto tanımına dayanır.

 + Nüfus Yoğunluğu, yılın ortasındaki nüfusun arazi alanına (kare kilometre cinsinden) bölünmesiyle hesaplanan bir göstergedir ve bir bölgedeki kişi sayısının yoğunluğunu ölçer.

20. **TotalPopulation**
    - Long Name: Population, total
    - Long Definition: Total population is based on the de facto definition of population, counting all residents regardless of legal status or citizenship.

    **Toplam Nüfus**
   - Uzun İsim: Toplam nüfus
   - Uzun Tanım: Toplam nüfus, nüfusun de facto tanımına dayanarak, hukuki statü veya vatandaşlık durumuna bakılmaksızın tüm yerleşikleri sayan bir göstergedir.

 + Toplam Nüfus, hukuki statü veya vatandaşlık durumundan bağımsız olarak tüm yerleşikleri sayarak hesaplanan bir nüfus ölçüsüdür.

21. **Private Partnership Investment in Energy (Current US$)**
    - Long Name: Public private partnerships investment in energy (current US$)
    - Long Definition: Public Private Partnerships in energy (current US$) refer to commitments to infrastructure projects in energy (electricity and natural gas transmission and distribution) that have reached financial closure and serve the public. It excludes divestitures and merchant projects.

    **Enerjide Kamu-Özel Ortaklığı Yatırımı (Güncel ABD Doları)**
   - Uzun İsim: Enerjide kamu-özel ortaklığı yatırımı (güncel ABD doları cinsinden)
   - Uzun Tanım: Enerjide Kamu-Özel Ortaklıkları (güncel ABD doları) enerji altyapı projelerine (elektrik ve doğalgaz iletim ve dağıtım) yapılan taahhütleri ifade eder. Bu projeler finansal kapanışa ulaşmış ve halka hizmet vermektedir. Bu tanım, varlık satışlarını ve tüccar projelerini içermez.

 + Enerjide Kamu-Özel Ortaklığı Yatırımı, halka hizmet veren enerji altyapı projelerine yapılan finansal taahhütleri ifade eder ve varlık satışlarını ve tüccar projelerini kapsamaz.

22. **RenewableEnergyConsumption**
    - Long Name: Renewable energy consumption (% of total final energy consumption)
    - Long Definition: Renewable energy consumption is the share of renewable energy in total final energy consumption.

    **Yenilenebilir Enerji Tüketimi**
   - Uzun İsim: Yenilenebilir enerji tüketimi (toplam nihai enerji tüketiminin yüzdesi)
   - Uzun Tanım: Yenilenebilir enerji tüketimi, toplam nihai enerji tüketiminin içindeki yenilenebilir enerjinin payını ifade eder.

 + Yenilenebilir Enerji Tüketimi, toplam nihai enerji tüketiminin içindeki yenilenebilir enerjinin yüzdesini gösterir. Bu, bir ülkenin enerji tüketiminin ne kadarının yenilenebilir kaynaklardan geldiğini gösteren bir ölçüttür ve sürdürülebilir enerji kullanımının bir göstergesidir.

23. **TotalGHGEmissions**
    - Long Name: Total greenhouse gas emissions (kt of CO2 equivalent)
    - Long Definition: Total greenhouse gas emissions in kt of CO2 equivalent include CO2 totals excluding short-cycle biomass burning, all anthropogenic CH4 sources, N2O sources, and F-gases (HFCs, PFCs, and SF6).

    **Toplam sera gazı emisyonları**
   - Uzun İsim: Toplam sera gazı emisyonları (kt CO2 eşdeğeri cinsinden)
   - Uzun Tanım: kt CO2 eşdeğerindeki toplam sera gazı emisyonları, kısa döngü biyokütle yanmasını dışlayan CO2 toplamlarını, tüm antropojenik CH4 kaynaklarını, N2O kaynaklarını ve F-gazlarını (HFC'ler, PFC'ler ve SF6) içerir.

 + Toplam Sera Gazı Emisyonları, kt CO2 eşdeğeri cinsinden ifade edilen ve CO2 dışında diğer sera gazlarını (CH4, N2O ve F-gazları) içeren emisyonların toplamını temsil eder. Bu, bir ülkenin sera gazı emisyonlarını ölçmek için kullanılır ve çevresel etkileri ve iklim değişikliği ile ilgili verileri değerlendirmek için önemlidir.

24. **Latitude**
- **Indicator Name:** Latitude
- **Description:** Latitude of the country's centroid in decimal degrees.

    **Enlem**
   - Uzun İsim: Enlem
   - Uzun Tanım: Ülkenin merkez noktasının enlemi ondalık derece cinsinden ifade edilir.

 + Enlem, bir ülkenin merkez noktasının yeryüzündeki konumunu belirlemek için kullanılan bir koordinat ölçüsüdür ve enlem hatları Kuzey ve Güney yönlerindeki konumları tanımlar.

25. **Longitude**
- **Indicator Name:** Longitude
- **Description:** Longitude of the country's centroid in decimal degrees.

    **Boylam**
   - Uzun İsim: Boylam
   - Uzun Tanım: Ülkenin merkez noktasının boylamı ondalık derece cinsinden ifade edilir.

 + Boylam, bir ülkenin merkez noktasının yeryüzündeki konumunu belirlemek için kullanılan bir koordinat ölçüsüdür ve boylam hatları Doğu ve Batı yönlerindeki konumları tanımlar.

****Sources / Kaynaklar:
****

1. **Climate Watch Historical GHG Emissions (1990-2020)**
   - Source: World Resources Institute
   - Topic: Environment: Emissions
   - URL: [Climate Watch GHG Emissions](https://www.climatewatchdata.org/ghg-emissions)

2. **IEA Statistics**
   - Source: OECD/IEA 2014
   - Topic: Environment: Energy production & use
   - URL: [IEA Statistics](http://www.iea.org/stats/index.asp)
   - Note: Subject to [IEA Terms and Conditions](https://www.iea.org/t&c/termsandconditions/)

3. **Tracking SDG 7: The Energy Progress Report (2023)**
   - Source: IEA, IRENA, UNSD, World Bank, WHO
   - Topic: Environment: Energy production & use
   - Source: World Bank, Washington DC
   - License: Creative Commons Attribution—NonCommercial 3.0 IGO (CC BY-NC 3.0 IGO)

4. **Private Participation in Infrastructure Project Database**
   - Source: World Bank
   - Topic: Private Sector & Trade: Private infrastructure investment
   - URL: [PPI World Bank](http://ppi.worldbank.org)

5. **Food and Agriculture Organization**
   - Source: Electronic files and website
   - Topic: Environment: Land use

6. **United Nations Population Division**
   - Source: World Population Prospects: 2022 Revision
   - Topic: Health: Population: Structure

7. **Food and Agriculture Organization and World Bank population estimates**
   - Source: Population estimates
   - Topic: Environment: Density & urbanization

8. **World Bank national accounts data**
   - Source: National accounts: US$ at current prices: Aggregate indicators
   - Topic: Economic Policy & Debt: National accounts

9. **World Bank national accounts data**
   - Source: National accounts: Growth rates
   - Topic: Economic Policy & Debt: National accounts
",.csv,True
Sustainable Energy Investment Forecast Dataset,4,sustainable-energy-investment-forecast-dataset,clean_regional_data.csv,Attribution 4.0 International (CC BY 4.0),"Here's a list of all the indicators from the dataset with their names and descriptions:


1. **CleanFuelAccess**
   - Long Name: CO2 emissions (metric tons per capita)
   - Long Definition: Access to clean fuels and technologies for cooking is the proportion of the total population primarily using clean cooking fuels and technologies for cooking. Kerosene is excluded from clean cooking fuels under WHO guidelines.

   **Temiz Yakıt Erişimi**
   - Uzun İsim: Kişi Başına CO2 Emisyonları (metrik ton)
   - Uzun Tanım: Temiz yakıt ve teknolojilere erişim, toplam nüfusun temel olarak temiz yemek pişirme yakıtları ve teknolojilerini kullanma oranını ifade eder. Temiz yemek pişirme yakıtları arasında WHO yönergelerine göre kerosen (gazyağı) hariçtir.

 + Temiz yakıt erişimi, insanların temiz yakıt ve teknolojileri kullanarak yemek pişirme alışkanlıklarını ne kadar yaygın olarak benimsediklerini gösteren bir ölçüttür. Bu, çevre dostu yakıtların kullanılmasıyla oluşan karbon emisyonlarının kişi başına düşen miktarını ölçmek için kullanılır. Kerosen ( Aydınlatma, Isıtma vb.) gibi kirletici yakıtlar temiz yakıtların dışında tutulur.

2. **ElectricityAccess**
   - Long Name: Access to clean fuels and technologies for cooking (% of population)
   - Long Definition: Access to electricity is the percentage of the population with access to electricity. Electrification data are collected from industry, national surveys, and international sources.

    **Elektrik Erişimi**
  - Uzun İsim: Temiz yakıt ve teknolojilere erişim (% nüfusa göre)
  - Uzun Tanım: Elektrik erişimi, nüfusun ne kadarının elektriğe erişiminin olduğunu gösteren bir orandır. Elektrifikasyon verileri, endüstriyel kaynaklar, ulusal anketler ve uluslararası kaynaklardan toplanır.

 + Elektrik erişimi, bir toplumun veya bölgenin elektrik enerjisine ne kadar yaygın bir şekilde erişebildiğini ölçen bir göstergedir. Bu, bir yerdeki enerji altyapısının gelişmişliğini ve elektrik kullanımının yaygınlığını belirlemek için kullanılır.

3. **CO2Emissions**
   - Long Name: Access to electricity (% of population)
   - Long Definition: Carbon dioxide emissions are those stemming from the burning of fossil fuels and the manufacture of cement. They include carbon dioxide produced during the consumption of solid, liquid, and gas fuels and gas flaring.

   **CO2 Emisyonları**
   - Uzun İsim: Elektriğe Erişim (% nüfusa göre)
   - Uzun Tanım: Karbon dioksit emisyonları, fosil yakıtların yakılmasından ve çimento üretiminden kaynaklanan emisyonlar dır. Bunlar, katı, sıvı ve gaz yakıtlarının tüketimi sırasında üretilen karbon dioksiti ve gaz yakma işleminden kaynaklanan emisyonları içerir.

 + CO2 emisyonları, fosil yakıtların ve diğer endüstriyel işlemlerin çevreye saldığı karbon dioksit gazını ifade eder. Bu emisyonlar, sera etkisi yaratarak iklim değişikliğine katkıda bulunabilir. Bu nedenle, fosil yakıtların kullanımının azaltılması ve daha temiz enerji kaynaklarının tercih edilmesi, karbon emisyonlarını azaltma hedeflerini destekler.

4. **ElecPowerConsumption**
   - Long Name: Electric power consumption (kWh per capita)
   - Long Definition: Electric power consumption measures the production of power plants and combined heat and power plants less transmission, distribution, and transformation losses and own use by heat and power plants.

    **Elektrik Enerjisi Tüketimi**
   - Uzun İsim: Kişi Başına Elektrik Enerjisi Tüketimi (kWh)
   - Uzun Tanım: Elektrik enerjisi tüketimi, enerji santralleri ve kombine ısı ve enerji santrallerinin üretimini, iletim, dağıtım ve dönüşüm kayıplarını ve ısı ve enerji santralleri tarafından kendi kullanımlarını içermeyen enerji tüketimini ölçer.

 + Elektrik enerjisi tüketimi, bir toplumun veya bölgenin elektrik enerjisi ne kadar tükettiğini gösteren bir ölçüttür. Bu, enerji üretimi ve dağıtımıyla ilgili verileri ifade eder ve enerji kaynaklarının kullanımının ve enerji altyapısının etkinliğinin bir göstergesidir. Kişi başına elektrik enerjisi tüketimi, bir kişinin ortalama olarak ne kadar elektrik kullandığını gösterir.

5. **CoalElectricity**
   - Long Name: Electricity production from coal sources (% of total)
   - Long Definition: Sources of electricity refer to the inputs used to generate electricity. Coal refers to all coal and brown coal, both primary (including hard coal and lignite-brown coal) and derived fuels (including patent fuel, coke oven coke, gas coke, coke oven gas, and blast furnace gas). Peat is also included in this category.

    **Kömür Kaynaklı Elektrik**
    - Uzun İsim: Kömür kaynaklı elektrik üretimi (toplamın yüzdesi)
    - Uzun Tanım: Elektrik kaynakları, elektrik üretmek için kullanılan girdileri ifade eder. Kömür, tüm kömür ve kahverengi kömürü içerir, hem birincil (sert kömür ve linyit-kahverengi kömür dahil) hem de türetilmiş yakıtları (patent yakıt, kok fırını kokusu, gaz kokusu, kok fırını gazı ve yüksek fırın gazı dahil). Turba da bu kategoriye dahildir.

 + Kömür kaynaklı elektrik, toplam elektrik üretiminin ne kadarının kömür gibi fosil yakıtlardan geldiğini gösteren bir ölçüttür. Kömür, elektrik üretimi için kullanılan önemli bir enerji kaynağıdır, ancak çevresel etkileri ve karbon emisyonları nedeniyle çevre açısından sorunlu olarak kabul edilir. Bu nedenle, kömür kaynaklı elektrik üretiminin azaltılması, temiz enerji kaynaklarının teşvik edilmesi ve enerji verimliliğinin artırılması, sürdürülebilir enerji hedeflerine katkıda bulunabilir.

6. **HydroElectricity**
   - Long Name: Electricity production from hydroelectric sources (% of total)
   - Long Definition: Sources of electricity refer to the inputs used to generate electricity. Hydropower refers to electricity produced by hydroelectric power plants.

   **Hidroelektrik Elektrik**
   - Uzun İsim: Hidroelektrik kaynaklı elektrik üretimi (toplamın yüzdesi)
   - Uzun Tanım: Elektrik kaynakları, elektrik üretmek için kullanılan girdileri ifade eder. Hidroelektrik enerji, hidroelektrik santralleri tarafından üretilen elektriği ifade eder.

+ Hidroelektrik elektrik, toplam elektrik üretiminin ne kadarının hidroelektrik santraller gibi su kaynaklarından geldiğini gösteren bir ölçüttür. Bu tür elektrik üretimi, suyun kinetik enerjisini elektriğe dönüştüren hidroelektrik santraller kullanılarak gerçekleştirilir. Hidroelektrik enerji temiz ve sürdürülebilir bir enerji kaynağı olarak kabul edilir ve karbon emisyonlarını azaltma çabalarına katkıda bulunabilir.

7. **GasElectricity**
   - Long Name: Electricity production from natural gas sources (% of total)
   - Long Definition: Sources of electricity refer to the inputs used to generate electricity. Gas refers to natural gas but excludes natural gas liquids.

   **Doğalgaz Elektriği**
   - Uzun İsim: Doğalgaz kaynaklı elektrik üretimi (toplamın yüzdesi)
   - Uzun Tanım: Elektrik üretimi için kullanılan kaynaklar, elektrik üretiminde kullanılan girdilere atıfta bulunur. ""Gaz,"" doğalgazı ifade eder, ancak doğalgaz sıvılarını içermez.

 + Doğalgaz Elektriği, toplam elektrik üretiminin ne kadarının doğalgaz kaynaklarından geldiğini gösteren bir ölçüttür. Bu terim, elektrik üretimi için kullanılan girdileri ifade ederken ""gaz"" doğalgazı ifade eder, ancak doğalgaz sıvılarını kapsamaz. Yani, bu, elektriğin doğalgaz kullanılarak üretildiği oranı gösterir.

8. **NuclearElectricity**
   - Long Name: Electricity production from nuclear sources (% of total)
   - Long Definition: Sources of electricity refer to the inputs used to generate electricity. Nuclear power refers to electricity produced by nuclear power plants.

   **Nükleer Elektrik**
   - Uzun İsim: Nükleer kaynaklı elektrik üretimi (toplamın yüzdesi)
   - Uzun Tanım: Elektrik üretimi için kullanılan girdilere atıfta bulunan elektrik kaynakları. Nükleer enerji, nükleer enerji santralleri tarafından üretilen elektriği ifade eder.

 + Nükleer Elektrik, toplam elektrik üretiminin ne kadarının nükleer kaynaklardan geldiğini gösteren bir ölçüttür. Bu terim, elektrik üretimi için kullanılan girdilere atıfta bulunurken ""nükleer enerji,"" nükleer enerji santralleri tarafından üretilen elektriği ifade eder.

9. **OilElectricity**
   - Long Name: Electricity production from oil sources (% of total)
   - Long Definition: Sources of electricity refer to the inputs used to generate electricity. Oil refers to crude oil and petroleum products.

    **Petrol Elektriği**
   - Uzun İsim: Petrol kaynaklı elektrik üretimi (toplamın yüzdesi)
   - Uzun Tanım: Elektrik üretimi için kullanılan girdilere atıfta bulunan elektrik kaynakları. ""Petrol,"" ham petrol ve petrol ürünlerini ifade eder.

 + Petrol Elektriği, toplam elektrik üretiminin ne kadarının petrol kaynaklarından geldiğini gösteren bir ölçüttür. Bu terim, elektrik üretimi için kullanılan girdilere atıfta bulunurken ""petrol,"" ham petrol ve petrol ürünlerini ifade eder.

10.**RenewableElectricity**
    - Long Name: Electricity production from renewable sources, excluding hydroelectric (% of total)
    - Long Definition: Electricity production from renewable sources, excluding hydroelectric, includes geothermal, solar, tides, wind, biomass, and biofuels.

    **Yenilenebilir Enerji Elektriği**
   - Uzun İsim: Hidroelektrik dışındaki yenilenebilir kaynaklardan elektrik üretimi (toplamın yüzdesi)
   - Uzun Tanım: Hidroelektrik dışındaki yenilenebilir kaynaklardan, yani jeotermal, güneş, gelgit, rüzgar, biyokütle ve biyoyakıtlardan elektrik üretimi.

 + Yenilenebilir Enerji Elektriği, hidroelektrik dışındaki yenilenebilir kaynaklardan (jeotermal, güneş, gelgit, rüzgar, biyokütle ve biyoyakıtlar) elde edilen elektriğin, toplam elektrik üretiminin yüzdesini ifade eder. Bu, sürdürülebilir ve çevre dostu enerji üretiminin payını ölçmek için kullanılır.

11. **RenewableElectricity_kWh**
    - Long Name: Electricity production from renewable sources, excluding hydroelectric (kWh)
    - Long Definition: Electricity production from renewable sources, excluding hydroelectric, includes geothermal, solar, tides, wind, biomass, and biofuels.

    **Yenilenebilir Enerji Elektriği (kWh)**
   - Uzun İsim: Hidroelektrik dışındaki yenilenebilir kaynaklardan elektrik üretimi (kWh cinsinden)
   - Uzun Tanım: Hidroelektrik dışındaki yenilenebilir kaynaklardan, yani jeotermal, güneş, gelgit, rüzgar, biyokütle ve biyoyakıtlardan elektrik üretimi (kWh cinsinden).

 + Yenilenebilir Enerji Elektriği (kWh), hidroelektrik dışındaki yenilenebilir kaynaklardan (jeotermal, güneş, gelgit, rüzgar, biyokütle ve biyoyakıtlar) elde edilen elektriği ölçer ve bu elektriğin miktarını kilowatt saat (kWh) cinsinden ifade eder. Bu, sürdürülebilir enerji üretiminin miktarını belirlemek için kullanılır.

12. **EnergyIntensity**
    - Long Name: Energy intensity level of primary energy (MJ/$2017 PPP GDP)
    - Long Definition: Energy intensity level of primary energy is the ratio between energy supply and gross domestic product measured at purchasing power parity. It indicates how much energy is used to produce one unit of economic output.

    **Enerji Yoğunluğu**
   - Uzun İsim: Birincil enerjinin enerji yoğunluğu düzeyi (MJ/$2017 PPP GSYİH)
   - Uzun Tanım: Birincil enerjinin enerji yoğunluğu düzeyi, satın alma gücü paritesi ile ölçülen enerji arzı ile gayri safi yurt içi hasıla (GSYİH) arasındaki oranı ifade eder. Bu, bir birim ekonomik üretim için ne kadar enerji kullanıldığını gösterir.

 + Enerji Yoğunluğu, enerji arzı ile GSYİH arasındaki oranı kullanarak ekonomik üretim için ne kadar enerji harcandığını gösteren bir ölçüttür. Bu, enerji kullanımının ekonomik verimliliğini belirlemek için kullanılır.

13. **EnergyUse**
    - Long Name: Energy use (kg of oil equivalent per capita)
    - Long Definition: Energy use refers to the use of primary energy before transformation to other end-use fuels, which includes indigenous production plus imports and stock changes, minus exports and fuels supplied to ships and aircraft engaged in international transport.

    **Enerji Kullanımı**
   - Uzun İsim: Kişi başına düşen enerji kullanımı (ton petrol eşdeğeri cinsinden)
   - Uzun Tanım: Enerji kullanımı, diğer kullanım yakıtlarına dönüşmeden önce birincil enerjinin kullanımını ifade eder. Bu, yerel üretimi ve ithalatları, stok değişikliklerini içerirken, ihracatları ve uluslararası taşımacılık yapan gemilere ve uçaklara sağlanan yakıtları çıkarır.

 + Enerji Kullanımı, birincil enerjinin diğer kullanım formlarına dönüşmeden önceki kullanımını ifade eder ve kişi başına düşen enerji tüketimini ton petrol eşdeğeri cinsinden ölçer. Bu, enerji tüketiminin kişi başına dağılımını gösterir.

14. **FossilFuelConsumption**
    - Long Name: Fossil fuel energy consumption (% of total)
    - Long Definition: Fossil fuel comprises coal, oil, petroleum, and natural gas products.

    **Fosil Yakıt Tüketimi**
   - Uzun İsim: Toplamın yüzdesine göre fosil yakıt enerjisi tüketimi
   - Uzun Tanım: Fosil yakıtlar, kömür, petrol, petrol ürünleri ve doğalgaz ürünlerini içerir. Bu, toplam enerji tüketiminin ne kadarının fosil yakıtlardan geldiğini gösterir.

 + Fosil Yakıt Tüketimi, enerji tüketiminin ne kadarının fosil yakıtlardan (kömür, petrol, petrol ürünleri ve doğalgaz) kaynaklandığını gösteren bir ölçüttür. Bu, enerji kaynaklarının kullanımının çevresel etkilerini değerlendirmek ve enerji dönüşümünün sürdürülebilirliğini incelemek için önemlidir.

15. **GDPGrowth**
    - Long Name: GDP growth (annual %)
    - Long Definition: Annual percentage growth rate of GDP at market prices based on constant local currency. It is expressed in U.S. dollars and represents the sum of gross value added by all resident producers in the economy.

    **GDP Büyüme Hızı**
   - Uzun İsim: GDP ""Gross Domestic Product"" büyüme hızı (yıllık %)
   - Uzun Tanım: Sabit yerel para birimine dayalı olarak piyasa fiyatlarıyla GDP'nin yıllık yüzde büyüme hızı. Bu, ABD doları cinsinden ifade edilir ve ekonominin tüm yerel üreticileri tarafından katkıda bulunulan brüt katma değeri temsil eder.

 + GDP Büyüme Hızı, piyasa fiyatlarına dayalı olarak sabit yerel para birimindeki yıllık GDP büyüme hızını ölçer. Bu, ekonominin tüm yerel üreticilerinin ekonomiye katkısının toplamını temsil eder ve genellikle ekonominin büyüme veya daralma eğilimini gösterir.

16. **GDPPerCapita**
    - Long Name: GDP per capita (current US$)
    - Long Definition: GDP per capita is gross domestic product divided by midyear population. It is expressed in current U.S. dollars and represents the sum of gross value added by all resident producers in the economy.

    **Kişi Başına GDP**
   - Uzun İsim: Kişi başına düşen GDP (güncel ABD doları cinsinden)
   - Uzun Tanım: Kişi başına düşen GDP, GDP'nin yıl ortası nüfusuyla bölünmesiyle hesaplanır. Bu, güncel ABD doları cinsinden ifade edilir ve ekonominin tüm yerel üreticileri tarafından katkıda bulunulan brüt katma değeri toplamını temsil eder.

 + Kişi Başına GDP, GDP'nin ülkenin yıl ortası nüfusuna bölünmesiyle hesaplanan bir göstergedir. Bu, kişi başına düşen ekonomik üretimi ölçmek için kullanılır ve bir ülkenin ekonomik refah seviyesini değerlendirmek için önemlidir.

17. **PrivateEnergyInvest**
    - Long Name: Investment in energy with private participation (current US$)
    - Long Definition: Investment in energy projects with private participation refers to commitments to infrastructure projects in energy (electricity and natural gas: generation, transmission, and distribution) that have reached financial closure and serve the public. It excludes movable assets and small projects such as windmills.

    **Özel Katılımlı Enerji Yatırımı**
   - Uzun İsim: Özel katılımlı enerji projelerine yapılan yatırım (güncel ABD doları cinsinden)
   - Uzun Tanım: Özel katılımlı enerji projelerine yapılan yatırım, enerji altyapı projelerine (elektrik ve doğalgaz: üretim, iletim ve dağıtım) finansal kapanışa ulaşmış ve kamu hizmeti sunan taahhütleri ifade eder. Bu, taşınabilir varlıkları ve rüzgar türbinleri gibi küçük projeleri içermez.

 + Özel Katılımlı Enerji Yatırımı, kamu hizmeti sunan enerji altyapı projelerine yapılan finansal taahhütlere odaklanan yatırımları ifade eder. Bu, özellikle elektrik ve doğalgaz sektörlerinde büyük projelere yönelik yatırımı gösterir ve küçük projeleri veya taşınabilir varlıkları kapsamaz.

18. **LandArea**
    - Long Name: Land area (sq. km)
    - Long Definition: Land area is a country's total area, excluding area under inland water bodies, national claims to the continental shelf, and exclusive economic zones. It includes major rivers and lakes.

    **Arazi Alanı** 
   - Uzun İsim: Arazi alanı (km² cinsinden)
   - Uzun Tanım: Arazi alanı, bir ülkenin iç sularda bulunan alanlar, kıta sahanlığına yönelik ulusal talepler ve özel ekonomik bölgeleri hariç tutarak hesaplanan toplam alanını ifade eder. Bu, büyük nehirleri ve gölleri içerir.

 + Arazi Alanı, bir ülkenin kara yüzeyinin, iç sulardan, kıta sahanlığındaki ulusal taleplerden ve özel ekonomik bölgelerden hariç tutularak hesaplanan toplam alanını temsil eder. Bu, bir ülkenin toprak büyüklüğünü gösterir ve içerisine büyük nehirler ve gölleri de dahil eder.

19. **PopDensity**
    - Long Name: Population density (people per sq. km of land area)
    - Long Definition: Population density is midyear population divided by land area in square kilometers, based on the de facto definition of population.

    ** Nüfus Yoğunluğu**
   - Uzun İsim: Nüfus yoğunluğu (arazi alanı başına kişi sayısı olarak)
   - Uzun Tanım: Nüfus yoğunluğu, yılın ortasındaki nüfusun arazi alanı (kare kilometre cinsinden) ile bölünmesiyle hesaplanır ve nüfusun de facto tanımına dayanır.

 + Nüfus Yoğunluğu, yılın ortasındaki nüfusun arazi alanına (kare kilometre cinsinden) bölünmesiyle hesaplanan bir göstergedir ve bir bölgedeki kişi sayısının yoğunluğunu ölçer.

20. **TotalPopulation**
    - Long Name: Population, total
    - Long Definition: Total population is based on the de facto definition of population, counting all residents regardless of legal status or citizenship.

    **Toplam Nüfus**
   - Uzun İsim: Toplam nüfus
   - Uzun Tanım: Toplam nüfus, nüfusun de facto tanımına dayanarak, hukuki statü veya vatandaşlık durumuna bakılmaksızın tüm yerleşikleri sayan bir göstergedir.

 + Toplam Nüfus, hukuki statü veya vatandaşlık durumundan bağımsız olarak tüm yerleşikleri sayarak hesaplanan bir nüfus ölçüsüdür.

21. **Private Partnership Investment in Energy (Current US$)**
    - Long Name: Public private partnerships investment in energy (current US$)
    - Long Definition: Public Private Partnerships in energy (current US$) refer to commitments to infrastructure projects in energy (electricity and natural gas transmission and distribution) that have reached financial closure and serve the public. It excludes divestitures and merchant projects.

    **Enerjide Kamu-Özel Ortaklığı Yatırımı (Güncel ABD Doları)**
   - Uzun İsim: Enerjide kamu-özel ortaklığı yatırımı (güncel ABD doları cinsinden)
   - Uzun Tanım: Enerjide Kamu-Özel Ortaklıkları (güncel ABD doları) enerji altyapı projelerine (elektrik ve doğalgaz iletim ve dağıtım) yapılan taahhütleri ifade eder. Bu projeler finansal kapanışa ulaşmış ve halka hizmet vermektedir. Bu tanım, varlık satışlarını ve tüccar projelerini içermez.

 + Enerjide Kamu-Özel Ortaklığı Yatırımı, halka hizmet veren enerji altyapı projelerine yapılan finansal taahhütleri ifade eder ve varlık satışlarını ve tüccar projelerini kapsamaz.

22. **RenewableEnergyConsumption**
    - Long Name: Renewable energy consumption (% of total final energy consumption)
    - Long Definition: Renewable energy consumption is the share of renewable energy in total final energy consumption.

    **Yenilenebilir Enerji Tüketimi**
   - Uzun İsim: Yenilenebilir enerji tüketimi (toplam nihai enerji tüketiminin yüzdesi)
   - Uzun Tanım: Yenilenebilir enerji tüketimi, toplam nihai enerji tüketiminin içindeki yenilenebilir enerjinin payını ifade eder.

 + Yenilenebilir Enerji Tüketimi, toplam nihai enerji tüketiminin içindeki yenilenebilir enerjinin yüzdesini gösterir. Bu, bir ülkenin enerji tüketiminin ne kadarının yenilenebilir kaynaklardan geldiğini gösteren bir ölçüttür ve sürdürülebilir enerji kullanımının bir göstergesidir.

23. **TotalGHGEmissions**
    - Long Name: Total greenhouse gas emissions (kt of CO2 equivalent)
    - Long Definition: Total greenhouse gas emissions in kt of CO2 equivalent include CO2 totals excluding short-cycle biomass burning, all anthropogenic CH4 sources, N2O sources, and F-gases (HFCs, PFCs, and SF6).

    **Toplam sera gazı emisyonları**
   - Uzun İsim: Toplam sera gazı emisyonları (kt CO2 eşdeğeri cinsinden)
   - Uzun Tanım: kt CO2 eşdeğerindeki toplam sera gazı emisyonları, kısa döngü biyokütle yanmasını dışlayan CO2 toplamlarını, tüm antropojenik CH4 kaynaklarını, N2O kaynaklarını ve F-gazlarını (HFC'ler, PFC'ler ve SF6) içerir.

 + Toplam Sera Gazı Emisyonları, kt CO2 eşdeğeri cinsinden ifade edilen ve CO2 dışında diğer sera gazlarını (CH4, N2O ve F-gazları) içeren emisyonların toplamını temsil eder. Bu, bir ülkenin sera gazı emisyonlarını ölçmek için kullanılır ve çevresel etkileri ve iklim değişikliği ile ilgili verileri değerlendirmek için önemlidir.

24. **Latitude**
- **Indicator Name:** Latitude
- **Description:** Latitude of the country's centroid in decimal degrees.

    **Enlem**
   - Uzun İsim: Enlem
   - Uzun Tanım: Ülkenin merkez noktasının enlemi ondalık derece cinsinden ifade edilir.

 + Enlem, bir ülkenin merkez noktasının yeryüzündeki konumunu belirlemek için kullanılan bir koordinat ölçüsüdür ve enlem hatları Kuzey ve Güney yönlerindeki konumları tanımlar.

25. **Longitude**
- **Indicator Name:** Longitude
- **Description:** Longitude of the country's centroid in decimal degrees.

    **Boylam**
   - Uzun İsim: Boylam
   - Uzun Tanım: Ülkenin merkez noktasının boylamı ondalık derece cinsinden ifade edilir.

 + Boylam, bir ülkenin merkez noktasının yeryüzündeki konumunu belirlemek için kullanılan bir koordinat ölçüsüdür ve boylam hatları Doğu ve Batı yönlerindeki konumları tanımlar.

****Sources / Kaynaklar:
****

1. **Climate Watch Historical GHG Emissions (1990-2020)**
   - Source: World Resources Institute
   - Topic: Environment: Emissions
   - URL: [Climate Watch GHG Emissions](https://www.climatewatchdata.org/ghg-emissions)

2. **IEA Statistics**
   - Source: OECD/IEA 2014
   - Topic: Environment: Energy production & use
   - URL: [IEA Statistics](http://www.iea.org/stats/index.asp)
   - Note: Subject to [IEA Terms and Conditions](https://www.iea.org/t&c/termsandconditions/)

3. **Tracking SDG 7: The Energy Progress Report (2023)**
   - Source: IEA, IRENA, UNSD, World Bank, WHO
   - Topic: Environment: Energy production & use
   - Source: World Bank, Washington DC
   - License: Creative Commons Attribution—NonCommercial 3.0 IGO (CC BY-NC 3.0 IGO)

4. **Private Participation in Infrastructure Project Database**
   - Source: World Bank
   - Topic: Private Sector & Trade: Private infrastructure investment
   - URL: [PPI World Bank](http://ppi.worldbank.org)

5. **Food and Agriculture Organization**
   - Source: Electronic files and website
   - Topic: Environment: Land use

6. **United Nations Population Division**
   - Source: World Population Prospects: 2022 Revision
   - Topic: Health: Population: Structure

7. **Food and Agriculture Organization and World Bank population estimates**
   - Source: Population estimates
   - Topic: Environment: Density & urbanization

8. **World Bank national accounts data**
   - Source: National accounts: US$ at current prices: Aggregate indicators
   - Topic: Economic Policy & Debt: National accounts

9. **World Bank national accounts data**
   - Source: National accounts: Growth rates
   - Topic: Economic Policy & Debt: National accounts
",.csv,True
Taylor Swift Song Lyrics (All Albums),9,taylor-swift-song-lyrics-all-albums,02-fearless_taylors_version.csv,CC-BY-SA-4.0,"### Context

The following albums were included:
1. [Taylor Swift (2006)](https://open.spotify.com/album/5eyZZoQEFQWRHkV2xgAeBw?si=QMW62hX7RDuPq95Jgkh_Vw)
2. [Fearless (Taylor's Version) (2021)](https://open.spotify.com/album/4hDok0OAJd57SGIT8xuWJH?si=LTSeAgbUTeCTgBkuM5CWiA)
3. [Speak Now (Deluxe Package) (2010)](https://open.spotify.com/album/6S6JQWzUrJVcJLK4fi74Fw?si=gJFRCD94TDqUtOVYOxnE3w)
4. [Red (Deluxe Edition) (2012)](https://open.spotify.com/album/1KVKqWeRuXsJDLTW0VuD29?si=hbSetLVBTeCuoP5YLZXx7Q)
5. [1989 (Deluxe) (2014)](https://open.spotify.com/album/1yGbNOtRIgdIiGHOEBaZWf?si=tVrwXonTQ9KrddNh1JJShQ)
6. [reputation (2017)](https://open.spotify.com/album/6DEjYFkNZh67HP7R9PSZvv?si=1F4DPLl2QjeHiESDVV1dNw)
7. [Lover (2019)](https://open.spotify.com/album/1NAmidJlEaVgA3MpcPFYGq?si=4u6GlPl8S2iuMNvzwdi8XA)
8. [folklore (deluxe version) (2020)](https://open.spotify.com/album/1pzvBxYgT6OVwJLtHkrdQK?si=1jUpnSQsQsalcNOP297yvg)
9. [evermore (deluxe version) (2020)](https://open.spotify.com/album/6AORtDjduMM3bupSWzbTSG?si=0mjcdVJxTaqPeSkQcvNf4g)

### Content

To understand our data better, let's define each column.
* album_name - Name of the album
* track_title - Name of the song
* track_n - Track number
* lyric - Lyric at each line
* line - Line number per song

### Acknowledgements

The dataset was extracted from genius.com.",.csv,True
Taylor Swift Song Lyrics (All Albums),9,taylor-swift-song-lyrics-all-albums,04-red_deluxe_edition.csv,CC-BY-SA-4.0,"### Context

The following albums were included:
1. [Taylor Swift (2006)](https://open.spotify.com/album/5eyZZoQEFQWRHkV2xgAeBw?si=QMW62hX7RDuPq95Jgkh_Vw)
2. [Fearless (Taylor's Version) (2021)](https://open.spotify.com/album/4hDok0OAJd57SGIT8xuWJH?si=LTSeAgbUTeCTgBkuM5CWiA)
3. [Speak Now (Deluxe Package) (2010)](https://open.spotify.com/album/6S6JQWzUrJVcJLK4fi74Fw?si=gJFRCD94TDqUtOVYOxnE3w)
4. [Red (Deluxe Edition) (2012)](https://open.spotify.com/album/1KVKqWeRuXsJDLTW0VuD29?si=hbSetLVBTeCuoP5YLZXx7Q)
5. [1989 (Deluxe) (2014)](https://open.spotify.com/album/1yGbNOtRIgdIiGHOEBaZWf?si=tVrwXonTQ9KrddNh1JJShQ)
6. [reputation (2017)](https://open.spotify.com/album/6DEjYFkNZh67HP7R9PSZvv?si=1F4DPLl2QjeHiESDVV1dNw)
7. [Lover (2019)](https://open.spotify.com/album/1NAmidJlEaVgA3MpcPFYGq?si=4u6GlPl8S2iuMNvzwdi8XA)
8. [folklore (deluxe version) (2020)](https://open.spotify.com/album/1pzvBxYgT6OVwJLtHkrdQK?si=1jUpnSQsQsalcNOP297yvg)
9. [evermore (deluxe version) (2020)](https://open.spotify.com/album/6AORtDjduMM3bupSWzbTSG?si=0mjcdVJxTaqPeSkQcvNf4g)

### Content

To understand our data better, let's define each column.
* album_name - Name of the album
* track_title - Name of the song
* track_n - Track number
* lyric - Lyric at each line
* line - Line number per song

### Acknowledgements

The dataset was extracted from genius.com.",.csv,True
Taylor Swift Song Lyrics (All Albums),9,taylor-swift-song-lyrics-all-albums,05-1989_deluxe.csv,CC-BY-SA-4.0,"### Context

The following albums were included:
1. [Taylor Swift (2006)](https://open.spotify.com/album/5eyZZoQEFQWRHkV2xgAeBw?si=QMW62hX7RDuPq95Jgkh_Vw)
2. [Fearless (Taylor's Version) (2021)](https://open.spotify.com/album/4hDok0OAJd57SGIT8xuWJH?si=LTSeAgbUTeCTgBkuM5CWiA)
3. [Speak Now (Deluxe Package) (2010)](https://open.spotify.com/album/6S6JQWzUrJVcJLK4fi74Fw?si=gJFRCD94TDqUtOVYOxnE3w)
4. [Red (Deluxe Edition) (2012)](https://open.spotify.com/album/1KVKqWeRuXsJDLTW0VuD29?si=hbSetLVBTeCuoP5YLZXx7Q)
5. [1989 (Deluxe) (2014)](https://open.spotify.com/album/1yGbNOtRIgdIiGHOEBaZWf?si=tVrwXonTQ9KrddNh1JJShQ)
6. [reputation (2017)](https://open.spotify.com/album/6DEjYFkNZh67HP7R9PSZvv?si=1F4DPLl2QjeHiESDVV1dNw)
7. [Lover (2019)](https://open.spotify.com/album/1NAmidJlEaVgA3MpcPFYGq?si=4u6GlPl8S2iuMNvzwdi8XA)
8. [folklore (deluxe version) (2020)](https://open.spotify.com/album/1pzvBxYgT6OVwJLtHkrdQK?si=1jUpnSQsQsalcNOP297yvg)
9. [evermore (deluxe version) (2020)](https://open.spotify.com/album/6AORtDjduMM3bupSWzbTSG?si=0mjcdVJxTaqPeSkQcvNf4g)

### Content

To understand our data better, let's define each column.
* album_name - Name of the album
* track_title - Name of the song
* track_n - Track number
* lyric - Lyric at each line
* line - Line number per song

### Acknowledgements

The dataset was extracted from genius.com.",.csv,True
Taylor Swift Song Lyrics (All Albums),9,taylor-swift-song-lyrics-all-albums,06-reputation.csv,CC-BY-SA-4.0,"### Context

The following albums were included:
1. [Taylor Swift (2006)](https://open.spotify.com/album/5eyZZoQEFQWRHkV2xgAeBw?si=QMW62hX7RDuPq95Jgkh_Vw)
2. [Fearless (Taylor's Version) (2021)](https://open.spotify.com/album/4hDok0OAJd57SGIT8xuWJH?si=LTSeAgbUTeCTgBkuM5CWiA)
3. [Speak Now (Deluxe Package) (2010)](https://open.spotify.com/album/6S6JQWzUrJVcJLK4fi74Fw?si=gJFRCD94TDqUtOVYOxnE3w)
4. [Red (Deluxe Edition) (2012)](https://open.spotify.com/album/1KVKqWeRuXsJDLTW0VuD29?si=hbSetLVBTeCuoP5YLZXx7Q)
5. [1989 (Deluxe) (2014)](https://open.spotify.com/album/1yGbNOtRIgdIiGHOEBaZWf?si=tVrwXonTQ9KrddNh1JJShQ)
6. [reputation (2017)](https://open.spotify.com/album/6DEjYFkNZh67HP7R9PSZvv?si=1F4DPLl2QjeHiESDVV1dNw)
7. [Lover (2019)](https://open.spotify.com/album/1NAmidJlEaVgA3MpcPFYGq?si=4u6GlPl8S2iuMNvzwdi8XA)
8. [folklore (deluxe version) (2020)](https://open.spotify.com/album/1pzvBxYgT6OVwJLtHkrdQK?si=1jUpnSQsQsalcNOP297yvg)
9. [evermore (deluxe version) (2020)](https://open.spotify.com/album/6AORtDjduMM3bupSWzbTSG?si=0mjcdVJxTaqPeSkQcvNf4g)

### Content

To understand our data better, let's define each column.
* album_name - Name of the album
* track_title - Name of the song
* track_n - Track number
* lyric - Lyric at each line
* line - Line number per song

### Acknowledgements

The dataset was extracted from genius.com.",.csv,True
Taylor Swift Song Lyrics (All Albums),9,taylor-swift-song-lyrics-all-albums,01-taylor_swift.csv,CC-BY-SA-4.0,"### Context

The following albums were included:
1. [Taylor Swift (2006)](https://open.spotify.com/album/5eyZZoQEFQWRHkV2xgAeBw?si=QMW62hX7RDuPq95Jgkh_Vw)
2. [Fearless (Taylor's Version) (2021)](https://open.spotify.com/album/4hDok0OAJd57SGIT8xuWJH?si=LTSeAgbUTeCTgBkuM5CWiA)
3. [Speak Now (Deluxe Package) (2010)](https://open.spotify.com/album/6S6JQWzUrJVcJLK4fi74Fw?si=gJFRCD94TDqUtOVYOxnE3w)
4. [Red (Deluxe Edition) (2012)](https://open.spotify.com/album/1KVKqWeRuXsJDLTW0VuD29?si=hbSetLVBTeCuoP5YLZXx7Q)
5. [1989 (Deluxe) (2014)](https://open.spotify.com/album/1yGbNOtRIgdIiGHOEBaZWf?si=tVrwXonTQ9KrddNh1JJShQ)
6. [reputation (2017)](https://open.spotify.com/album/6DEjYFkNZh67HP7R9PSZvv?si=1F4DPLl2QjeHiESDVV1dNw)
7. [Lover (2019)](https://open.spotify.com/album/1NAmidJlEaVgA3MpcPFYGq?si=4u6GlPl8S2iuMNvzwdi8XA)
8. [folklore (deluxe version) (2020)](https://open.spotify.com/album/1pzvBxYgT6OVwJLtHkrdQK?si=1jUpnSQsQsalcNOP297yvg)
9. [evermore (deluxe version) (2020)](https://open.spotify.com/album/6AORtDjduMM3bupSWzbTSG?si=0mjcdVJxTaqPeSkQcvNf4g)

### Content

To understand our data better, let's define each column.
* album_name - Name of the album
* track_title - Name of the song
* track_n - Track number
* lyric - Lyric at each line
* line - Line number per song

### Acknowledgements

The dataset was extracted from genius.com.",.csv,True
Taylor Swift Song Lyrics (All Albums),9,taylor-swift-song-lyrics-all-albums,08-folklore_deluxe_version.csv,CC-BY-SA-4.0,"### Context

The following albums were included:
1. [Taylor Swift (2006)](https://open.spotify.com/album/5eyZZoQEFQWRHkV2xgAeBw?si=QMW62hX7RDuPq95Jgkh_Vw)
2. [Fearless (Taylor's Version) (2021)](https://open.spotify.com/album/4hDok0OAJd57SGIT8xuWJH?si=LTSeAgbUTeCTgBkuM5CWiA)
3. [Speak Now (Deluxe Package) (2010)](https://open.spotify.com/album/6S6JQWzUrJVcJLK4fi74Fw?si=gJFRCD94TDqUtOVYOxnE3w)
4. [Red (Deluxe Edition) (2012)](https://open.spotify.com/album/1KVKqWeRuXsJDLTW0VuD29?si=hbSetLVBTeCuoP5YLZXx7Q)
5. [1989 (Deluxe) (2014)](https://open.spotify.com/album/1yGbNOtRIgdIiGHOEBaZWf?si=tVrwXonTQ9KrddNh1JJShQ)
6. [reputation (2017)](https://open.spotify.com/album/6DEjYFkNZh67HP7R9PSZvv?si=1F4DPLl2QjeHiESDVV1dNw)
7. [Lover (2019)](https://open.spotify.com/album/1NAmidJlEaVgA3MpcPFYGq?si=4u6GlPl8S2iuMNvzwdi8XA)
8. [folklore (deluxe version) (2020)](https://open.spotify.com/album/1pzvBxYgT6OVwJLtHkrdQK?si=1jUpnSQsQsalcNOP297yvg)
9. [evermore (deluxe version) (2020)](https://open.spotify.com/album/6AORtDjduMM3bupSWzbTSG?si=0mjcdVJxTaqPeSkQcvNf4g)

### Content

To understand our data better, let's define each column.
* album_name - Name of the album
* track_title - Name of the song
* track_n - Track number
* lyric - Lyric at each line
* line - Line number per song

### Acknowledgements

The dataset was extracted from genius.com.",.csv,True
Taylor Swift Song Lyrics (All Albums),9,taylor-swift-song-lyrics-all-albums,07-lover.csv,CC-BY-SA-4.0,"### Context

The following albums were included:
1. [Taylor Swift (2006)](https://open.spotify.com/album/5eyZZoQEFQWRHkV2xgAeBw?si=QMW62hX7RDuPq95Jgkh_Vw)
2. [Fearless (Taylor's Version) (2021)](https://open.spotify.com/album/4hDok0OAJd57SGIT8xuWJH?si=LTSeAgbUTeCTgBkuM5CWiA)
3. [Speak Now (Deluxe Package) (2010)](https://open.spotify.com/album/6S6JQWzUrJVcJLK4fi74Fw?si=gJFRCD94TDqUtOVYOxnE3w)
4. [Red (Deluxe Edition) (2012)](https://open.spotify.com/album/1KVKqWeRuXsJDLTW0VuD29?si=hbSetLVBTeCuoP5YLZXx7Q)
5. [1989 (Deluxe) (2014)](https://open.spotify.com/album/1yGbNOtRIgdIiGHOEBaZWf?si=tVrwXonTQ9KrddNh1JJShQ)
6. [reputation (2017)](https://open.spotify.com/album/6DEjYFkNZh67HP7R9PSZvv?si=1F4DPLl2QjeHiESDVV1dNw)
7. [Lover (2019)](https://open.spotify.com/album/1NAmidJlEaVgA3MpcPFYGq?si=4u6GlPl8S2iuMNvzwdi8XA)
8. [folklore (deluxe version) (2020)](https://open.spotify.com/album/1pzvBxYgT6OVwJLtHkrdQK?si=1jUpnSQsQsalcNOP297yvg)
9. [evermore (deluxe version) (2020)](https://open.spotify.com/album/6AORtDjduMM3bupSWzbTSG?si=0mjcdVJxTaqPeSkQcvNf4g)

### Content

To understand our data better, let's define each column.
* album_name - Name of the album
* track_title - Name of the song
* track_n - Track number
* lyric - Lyric at each line
* line - Line number per song

### Acknowledgements

The dataset was extracted from genius.com.",.csv,True
Taylor Swift Song Lyrics (All Albums),9,taylor-swift-song-lyrics-all-albums,09-evermore_deluxe_version.csv,CC-BY-SA-4.0,"### Context

The following albums were included:
1. [Taylor Swift (2006)](https://open.spotify.com/album/5eyZZoQEFQWRHkV2xgAeBw?si=QMW62hX7RDuPq95Jgkh_Vw)
2. [Fearless (Taylor's Version) (2021)](https://open.spotify.com/album/4hDok0OAJd57SGIT8xuWJH?si=LTSeAgbUTeCTgBkuM5CWiA)
3. [Speak Now (Deluxe Package) (2010)](https://open.spotify.com/album/6S6JQWzUrJVcJLK4fi74Fw?si=gJFRCD94TDqUtOVYOxnE3w)
4. [Red (Deluxe Edition) (2012)](https://open.spotify.com/album/1KVKqWeRuXsJDLTW0VuD29?si=hbSetLVBTeCuoP5YLZXx7Q)
5. [1989 (Deluxe) (2014)](https://open.spotify.com/album/1yGbNOtRIgdIiGHOEBaZWf?si=tVrwXonTQ9KrddNh1JJShQ)
6. [reputation (2017)](https://open.spotify.com/album/6DEjYFkNZh67HP7R9PSZvv?si=1F4DPLl2QjeHiESDVV1dNw)
7. [Lover (2019)](https://open.spotify.com/album/1NAmidJlEaVgA3MpcPFYGq?si=4u6GlPl8S2iuMNvzwdi8XA)
8. [folklore (deluxe version) (2020)](https://open.spotify.com/album/1pzvBxYgT6OVwJLtHkrdQK?si=1jUpnSQsQsalcNOP297yvg)
9. [evermore (deluxe version) (2020)](https://open.spotify.com/album/6AORtDjduMM3bupSWzbTSG?si=0mjcdVJxTaqPeSkQcvNf4g)

### Content

To understand our data better, let's define each column.
* album_name - Name of the album
* track_title - Name of the song
* track_n - Track number
* lyric - Lyric at each line
* line - Line number per song

### Acknowledgements

The dataset was extracted from genius.com.",.csv,True
Taylor Swift Song Lyrics (All Albums),9,taylor-swift-song-lyrics-all-albums,03-speak_now_deluxe_package.csv,CC-BY-SA-4.0,"### Context

The following albums were included:
1. [Taylor Swift (2006)](https://open.spotify.com/album/5eyZZoQEFQWRHkV2xgAeBw?si=QMW62hX7RDuPq95Jgkh_Vw)
2. [Fearless (Taylor's Version) (2021)](https://open.spotify.com/album/4hDok0OAJd57SGIT8xuWJH?si=LTSeAgbUTeCTgBkuM5CWiA)
3. [Speak Now (Deluxe Package) (2010)](https://open.spotify.com/album/6S6JQWzUrJVcJLK4fi74Fw?si=gJFRCD94TDqUtOVYOxnE3w)
4. [Red (Deluxe Edition) (2012)](https://open.spotify.com/album/1KVKqWeRuXsJDLTW0VuD29?si=hbSetLVBTeCuoP5YLZXx7Q)
5. [1989 (Deluxe) (2014)](https://open.spotify.com/album/1yGbNOtRIgdIiGHOEBaZWf?si=tVrwXonTQ9KrddNh1JJShQ)
6. [reputation (2017)](https://open.spotify.com/album/6DEjYFkNZh67HP7R9PSZvv?si=1F4DPLl2QjeHiESDVV1dNw)
7. [Lover (2019)](https://open.spotify.com/album/1NAmidJlEaVgA3MpcPFYGq?si=4u6GlPl8S2iuMNvzwdi8XA)
8. [folklore (deluxe version) (2020)](https://open.spotify.com/album/1pzvBxYgT6OVwJLtHkrdQK?si=1jUpnSQsQsalcNOP297yvg)
9. [evermore (deluxe version) (2020)](https://open.spotify.com/album/6AORtDjduMM3bupSWzbTSG?si=0mjcdVJxTaqPeSkQcvNf4g)

### Content

To understand our data better, let's define each column.
* album_name - Name of the album
* track_title - Name of the song
* track_n - Track number
* lyric - Lyric at each line
* line - Line number per song

### Acknowledgements

The dataset was extracted from genius.com.",.csv,True
Temperature Time-Series for some Brazilian cities,12,temperature-timeseries-for-some-brazilian-cities,station_goiania.csv,DbCL-1.0,"# Temperature Time-Series for some Brazilian cities

Do you ever wonder how are temperatures in Brazilian cities? Too hot? Cold weather sometimes?
And what about climate changes? Is Brazil getting hotter?

This is your chance to check it out!

## Context

This datasets are collected in order to provide some answers for the above question through Data Analysis. Maybe you want to try some Machine Learning model in order to practice and predict the evolution of temperature in some Brazilian cities.

## Content

The content is provided by [NOAA GHCN v4](https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-monthly-version-4) and post-processed by [NASA's GISTEMP v4](https://data.giss.nasa.gov/gistemp/station_data_v4_globe/).

In summary, each data file contains a temperature time series for a station named according to the city. The time series provides temperature records by month for each year. Some mean measurement is calculated, like `metANN` and `D-J-F`. I can't give details about these quantities, nor how they are calculated. Please refer for NASA GISTEMP website in this regard. The most important seems to be `metANN`, which is an annual temperature mean.

## Acknowledgements

These datasets are provided through [NASA's GISTEMP v4](https://data.giss.nasa.gov/gistemp/station_data_v4_globe/) and recorded by [NOAA GHCN v4](https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-monthly-version-4). Thanks for researchers and staffs for the really nice work!",.csv,True
Temperature Time-Series for some Brazilian cities,12,temperature-timeseries-for-some-brazilian-cities,station_belem.csv,DbCL-1.0,"# Temperature Time-Series for some Brazilian cities

Do you ever wonder how are temperatures in Brazilian cities? Too hot? Cold weather sometimes?
And what about climate changes? Is Brazil getting hotter?

This is your chance to check it out!

## Context

This datasets are collected in order to provide some answers for the above question through Data Analysis. Maybe you want to try some Machine Learning model in order to practice and predict the evolution of temperature in some Brazilian cities.

## Content

The content is provided by [NOAA GHCN v4](https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-monthly-version-4) and post-processed by [NASA's GISTEMP v4](https://data.giss.nasa.gov/gistemp/station_data_v4_globe/).

In summary, each data file contains a temperature time series for a station named according to the city. The time series provides temperature records by month for each year. Some mean measurement is calculated, like `metANN` and `D-J-F`. I can't give details about these quantities, nor how they are calculated. Please refer for NASA GISTEMP website in this regard. The most important seems to be `metANN`, which is an annual temperature mean.

## Acknowledgements

These datasets are provided through [NASA's GISTEMP v4](https://data.giss.nasa.gov/gistemp/station_data_v4_globe/) and recorded by [NOAA GHCN v4](https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-monthly-version-4). Thanks for researchers and staffs for the really nice work!",.csv,True
Temperature Time-Series for some Brazilian cities,12,temperature-timeseries-for-some-brazilian-cities,station_sao_paulo.csv,DbCL-1.0,"# Temperature Time-Series for some Brazilian cities

Do you ever wonder how are temperatures in Brazilian cities? Too hot? Cold weather sometimes?
And what about climate changes? Is Brazil getting hotter?

This is your chance to check it out!

## Context

This datasets are collected in order to provide some answers for the above question through Data Analysis. Maybe you want to try some Machine Learning model in order to practice and predict the evolution of temperature in some Brazilian cities.

## Content

The content is provided by [NOAA GHCN v4](https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-monthly-version-4) and post-processed by [NASA's GISTEMP v4](https://data.giss.nasa.gov/gistemp/station_data_v4_globe/).

In summary, each data file contains a temperature time series for a station named according to the city. The time series provides temperature records by month for each year. Some mean measurement is calculated, like `metANN` and `D-J-F`. I can't give details about these quantities, nor how they are calculated. Please refer for NASA GISTEMP website in this regard. The most important seems to be `metANN`, which is an annual temperature mean.

## Acknowledgements

These datasets are provided through [NASA's GISTEMP v4](https://data.giss.nasa.gov/gistemp/station_data_v4_globe/) and recorded by [NOAA GHCN v4](https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-monthly-version-4). Thanks for researchers and staffs for the really nice work!",.csv,True
Temperature Time-Series for some Brazilian cities,12,temperature-timeseries-for-some-brazilian-cities,station_curitiba.csv,DbCL-1.0,"# Temperature Time-Series for some Brazilian cities

Do you ever wonder how are temperatures in Brazilian cities? Too hot? Cold weather sometimes?
And what about climate changes? Is Brazil getting hotter?

This is your chance to check it out!

## Context

This datasets are collected in order to provide some answers for the above question through Data Analysis. Maybe you want to try some Machine Learning model in order to practice and predict the evolution of temperature in some Brazilian cities.

## Content

The content is provided by [NOAA GHCN v4](https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-monthly-version-4) and post-processed by [NASA's GISTEMP v4](https://data.giss.nasa.gov/gistemp/station_data_v4_globe/).

In summary, each data file contains a temperature time series for a station named according to the city. The time series provides temperature records by month for each year. Some mean measurement is calculated, like `metANN` and `D-J-F`. I can't give details about these quantities, nor how they are calculated. Please refer for NASA GISTEMP website in this regard. The most important seems to be `metANN`, which is an annual temperature mean.

## Acknowledgements

These datasets are provided through [NASA's GISTEMP v4](https://data.giss.nasa.gov/gistemp/station_data_v4_globe/) and recorded by [NOAA GHCN v4](https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-monthly-version-4). Thanks for researchers and staffs for the really nice work!",.csv,True
Temperature Time-Series for some Brazilian cities,12,temperature-timeseries-for-some-brazilian-cities,station_rio.csv,DbCL-1.0,"# Temperature Time-Series for some Brazilian cities

Do you ever wonder how are temperatures in Brazilian cities? Too hot? Cold weather sometimes?
And what about climate changes? Is Brazil getting hotter?

This is your chance to check it out!

## Context

This datasets are collected in order to provide some answers for the above question through Data Analysis. Maybe you want to try some Machine Learning model in order to practice and predict the evolution of temperature in some Brazilian cities.

## Content

The content is provided by [NOAA GHCN v4](https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-monthly-version-4) and post-processed by [NASA's GISTEMP v4](https://data.giss.nasa.gov/gistemp/station_data_v4_globe/).

In summary, each data file contains a temperature time series for a station named according to the city. The time series provides temperature records by month for each year. Some mean measurement is calculated, like `metANN` and `D-J-F`. I can't give details about these quantities, nor how they are calculated. Please refer for NASA GISTEMP website in this regard. The most important seems to be `metANN`, which is an annual temperature mean.

## Acknowledgements

These datasets are provided through [NASA's GISTEMP v4](https://data.giss.nasa.gov/gistemp/station_data_v4_globe/) and recorded by [NOAA GHCN v4](https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-monthly-version-4). Thanks for researchers and staffs for the really nice work!",.csv,True
Temperature Time-Series for some Brazilian cities,12,temperature-timeseries-for-some-brazilian-cities,station_recife.csv,DbCL-1.0,"# Temperature Time-Series for some Brazilian cities

Do you ever wonder how are temperatures in Brazilian cities? Too hot? Cold weather sometimes?
And what about climate changes? Is Brazil getting hotter?

This is your chance to check it out!

## Context

This datasets are collected in order to provide some answers for the above question through Data Analysis. Maybe you want to try some Machine Learning model in order to practice and predict the evolution of temperature in some Brazilian cities.

## Content

The content is provided by [NOAA GHCN v4](https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-monthly-version-4) and post-processed by [NASA's GISTEMP v4](https://data.giss.nasa.gov/gistemp/station_data_v4_globe/).

In summary, each data file contains a temperature time series for a station named according to the city. The time series provides temperature records by month for each year. Some mean measurement is calculated, like `metANN` and `D-J-F`. I can't give details about these quantities, nor how they are calculated. Please refer for NASA GISTEMP website in this regard. The most important seems to be `metANN`, which is an annual temperature mean.

## Acknowledgements

These datasets are provided through [NASA's GISTEMP v4](https://data.giss.nasa.gov/gistemp/station_data_v4_globe/) and recorded by [NOAA GHCN v4](https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-monthly-version-4). Thanks for researchers and staffs for the really nice work!",.csv,True
Temperature Time-Series for some Brazilian cities,12,temperature-timeseries-for-some-brazilian-cities,station_sao_luiz.csv,DbCL-1.0,"# Temperature Time-Series for some Brazilian cities

Do you ever wonder how are temperatures in Brazilian cities? Too hot? Cold weather sometimes?
And what about climate changes? Is Brazil getting hotter?

This is your chance to check it out!

## Context

This datasets are collected in order to provide some answers for the above question through Data Analysis. Maybe you want to try some Machine Learning model in order to practice and predict the evolution of temperature in some Brazilian cities.

## Content

The content is provided by [NOAA GHCN v4](https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-monthly-version-4) and post-processed by [NASA's GISTEMP v4](https://data.giss.nasa.gov/gistemp/station_data_v4_globe/).

In summary, each data file contains a temperature time series for a station named according to the city. The time series provides temperature records by month for each year. Some mean measurement is calculated, like `metANN` and `D-J-F`. I can't give details about these quantities, nor how they are calculated. Please refer for NASA GISTEMP website in this regard. The most important seems to be `metANN`, which is an annual temperature mean.

## Acknowledgements

These datasets are provided through [NASA's GISTEMP v4](https://data.giss.nasa.gov/gistemp/station_data_v4_globe/) and recorded by [NOAA GHCN v4](https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-monthly-version-4). Thanks for researchers and staffs for the really nice work!",.csv,True
Temperature Time-Series for some Brazilian cities,12,temperature-timeseries-for-some-brazilian-cities,station_vitoria.csv,DbCL-1.0,"# Temperature Time-Series for some Brazilian cities

Do you ever wonder how are temperatures in Brazilian cities? Too hot? Cold weather sometimes?
And what about climate changes? Is Brazil getting hotter?

This is your chance to check it out!

## Context

This datasets are collected in order to provide some answers for the above question through Data Analysis. Maybe you want to try some Machine Learning model in order to practice and predict the evolution of temperature in some Brazilian cities.

## Content

The content is provided by [NOAA GHCN v4](https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-monthly-version-4) and post-processed by [NASA's GISTEMP v4](https://data.giss.nasa.gov/gistemp/station_data_v4_globe/).

In summary, each data file contains a temperature time series for a station named according to the city. The time series provides temperature records by month for each year. Some mean measurement is calculated, like `metANN` and `D-J-F`. I can't give details about these quantities, nor how they are calculated. Please refer for NASA GISTEMP website in this regard. The most important seems to be `metANN`, which is an annual temperature mean.

## Acknowledgements

These datasets are provided through [NASA's GISTEMP v4](https://data.giss.nasa.gov/gistemp/station_data_v4_globe/) and recorded by [NOAA GHCN v4](https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-monthly-version-4). Thanks for researchers and staffs for the really nice work!",.csv,True
Temperature Time-Series for some Brazilian cities,12,temperature-timeseries-for-some-brazilian-cities,station_manaus.csv,DbCL-1.0,"# Temperature Time-Series for some Brazilian cities

Do you ever wonder how are temperatures in Brazilian cities? Too hot? Cold weather sometimes?
And what about climate changes? Is Brazil getting hotter?

This is your chance to check it out!

## Context

This datasets are collected in order to provide some answers for the above question through Data Analysis. Maybe you want to try some Machine Learning model in order to practice and predict the evolution of temperature in some Brazilian cities.

## Content

The content is provided by [NOAA GHCN v4](https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-monthly-version-4) and post-processed by [NASA's GISTEMP v4](https://data.giss.nasa.gov/gistemp/station_data_v4_globe/).

In summary, each data file contains a temperature time series for a station named according to the city. The time series provides temperature records by month for each year. Some mean measurement is calculated, like `metANN` and `D-J-F`. I can't give details about these quantities, nor how they are calculated. Please refer for NASA GISTEMP website in this regard. The most important seems to be `metANN`, which is an annual temperature mean.

## Acknowledgements

These datasets are provided through [NASA's GISTEMP v4](https://data.giss.nasa.gov/gistemp/station_data_v4_globe/) and recorded by [NOAA GHCN v4](https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-monthly-version-4). Thanks for researchers and staffs for the really nice work!",.csv,True
Temperature Time-Series for some Brazilian cities,12,temperature-timeseries-for-some-brazilian-cities,station_salvador.csv,DbCL-1.0,"# Temperature Time-Series for some Brazilian cities

Do you ever wonder how are temperatures in Brazilian cities? Too hot? Cold weather sometimes?
And what about climate changes? Is Brazil getting hotter?

This is your chance to check it out!

## Context

This datasets are collected in order to provide some answers for the above question through Data Analysis. Maybe you want to try some Machine Learning model in order to practice and predict the evolution of temperature in some Brazilian cities.

## Content

The content is provided by [NOAA GHCN v4](https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-monthly-version-4) and post-processed by [NASA's GISTEMP v4](https://data.giss.nasa.gov/gistemp/station_data_v4_globe/).

In summary, each data file contains a temperature time series for a station named according to the city. The time series provides temperature records by month for each year. Some mean measurement is calculated, like `metANN` and `D-J-F`. I can't give details about these quantities, nor how they are calculated. Please refer for NASA GISTEMP website in this regard. The most important seems to be `metANN`, which is an annual temperature mean.

## Acknowledgements

These datasets are provided through [NASA's GISTEMP v4](https://data.giss.nasa.gov/gistemp/station_data_v4_globe/) and recorded by [NOAA GHCN v4](https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-monthly-version-4). Thanks for researchers and staffs for the really nice work!",.csv,True
Temperature Time-Series for some Brazilian cities,12,temperature-timeseries-for-some-brazilian-cities,station_macapa.csv,DbCL-1.0,"# Temperature Time-Series for some Brazilian cities

Do you ever wonder how are temperatures in Brazilian cities? Too hot? Cold weather sometimes?
And what about climate changes? Is Brazil getting hotter?

This is your chance to check it out!

## Context

This datasets are collected in order to provide some answers for the above question through Data Analysis. Maybe you want to try some Machine Learning model in order to practice and predict the evolution of temperature in some Brazilian cities.

## Content

The content is provided by [NOAA GHCN v4](https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-monthly-version-4) and post-processed by [NASA's GISTEMP v4](https://data.giss.nasa.gov/gistemp/station_data_v4_globe/).

In summary, each data file contains a temperature time series for a station named according to the city. The time series provides temperature records by month for each year. Some mean measurement is calculated, like `metANN` and `D-J-F`. I can't give details about these quantities, nor how they are calculated. Please refer for NASA GISTEMP website in this regard. The most important seems to be `metANN`, which is an annual temperature mean.

## Acknowledgements

These datasets are provided through [NASA's GISTEMP v4](https://data.giss.nasa.gov/gistemp/station_data_v4_globe/) and recorded by [NOAA GHCN v4](https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-monthly-version-4). Thanks for researchers and staffs for the really nice work!",.csv,True
Temperature Time-Series for some Brazilian cities,12,temperature-timeseries-for-some-brazilian-cities,station_fortaleza.csv,DbCL-1.0,"# Temperature Time-Series for some Brazilian cities

Do you ever wonder how are temperatures in Brazilian cities? Too hot? Cold weather sometimes?
And what about climate changes? Is Brazil getting hotter?

This is your chance to check it out!

## Context

This datasets are collected in order to provide some answers for the above question through Data Analysis. Maybe you want to try some Machine Learning model in order to practice and predict the evolution of temperature in some Brazilian cities.

## Content

The content is provided by [NOAA GHCN v4](https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-monthly-version-4) and post-processed by [NASA's GISTEMP v4](https://data.giss.nasa.gov/gistemp/station_data_v4_globe/).

In summary, each data file contains a temperature time series for a station named according to the city. The time series provides temperature records by month for each year. Some mean measurement is calculated, like `metANN` and `D-J-F`. I can't give details about these quantities, nor how they are calculated. Please refer for NASA GISTEMP website in this regard. The most important seems to be `metANN`, which is an annual temperature mean.

## Acknowledgements

These datasets are provided through [NASA's GISTEMP v4](https://data.giss.nasa.gov/gistemp/station_data_v4_globe/) and recorded by [NOAA GHCN v4](https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-monthly-version-4). Thanks for researchers and staffs for the really nice work!",.csv,True
The Linear Ordering Problem over 14 heuristics,16,the-linear-ordering-problem-over-14-heuristics,lop_results_100_ft10000.csv,MIT,"# Link to the scientific paper explaining this dataset generation: [here](https://drive.google.com/file/d/11dYHZ5u5o2gzJErVUtRpNYjl9HfqU5dQ/view?usp=sharing)

Results for each algorithm are saved in a CSV format in this database. The file names are built as follow:

$$
\text{lop\_result\_} \cup \text{pivotingRule} \cup \text{neighborhoodStrategy} \cup \text{initialSolutionMethod} \cup \text{\_ft} \cup \text{FIRST\_THRESHOLD} \cup \text{.csv}
$$

For `pivotingRule`:
- 0 = first threshold
- 1 = best threshold

For `neighborhoodStrategy`:
- 0 = transpose (i.e., exchange with immediate neighbor)
- 1 = exchange
- 2 = insert
- 3 = Variable Neighborhood Descent (VND) with transpose --&gt; exchange --&gt; insert
- 4 = VND with transpose --&gt; insert --&gt; exchange

For `initialSolutionMethod`:
- 0 = random initial solution
- 1 = Chenery and Watanabe initial solution

Finally, we remind that `FIRST_THRESHOLD` gives a pruning method for first improvement. The final result is slightly below the one with `FIRST_THRESHOLD = 0`, but the algorithm becomes ~9x faster. For all first thresholds, `FIRST_THRESHOLD` was set on 10,000, except for first transpose as the transpose algorithm where it is 0 because itis fast enough (no first improvement is accepted under an minimum 10,000 improvement, and if not found divide this threshold by 2 until 50 is reached).

### Content of the CSV files

All CSV files have the same columns:
- **FileName**
- **Time** (time of execution in seconds for each instance)
- **InitialCost** (depends on initial method)
- **FinalCost** (after the algorithm was applied)
- **PercentageImprovement** (compared to the initial cost)
- **PercentageOfBestKnown** (compared to the best known cost)",.csv,True
The Linear Ordering Problem over 14 heuristics,16,the-linear-ordering-problem-over-14-heuristics,lop_results_000_ft0.csv,MIT,"# Link to the scientific paper explaining this dataset generation: [here](https://drive.google.com/file/d/11dYHZ5u5o2gzJErVUtRpNYjl9HfqU5dQ/view?usp=sharing)

Results for each algorithm are saved in a CSV format in this database. The file names are built as follow:

$$
\text{lop\_result\_} \cup \text{pivotingRule} \cup \text{neighborhoodStrategy} \cup \text{initialSolutionMethod} \cup \text{\_ft} \cup \text{FIRST\_THRESHOLD} \cup \text{.csv}
$$

For `pivotingRule`:
- 0 = first threshold
- 1 = best threshold

For `neighborhoodStrategy`:
- 0 = transpose (i.e., exchange with immediate neighbor)
- 1 = exchange
- 2 = insert
- 3 = Variable Neighborhood Descent (VND) with transpose --&gt; exchange --&gt; insert
- 4 = VND with transpose --&gt; insert --&gt; exchange

For `initialSolutionMethod`:
- 0 = random initial solution
- 1 = Chenery and Watanabe initial solution

Finally, we remind that `FIRST_THRESHOLD` gives a pruning method for first improvement. The final result is slightly below the one with `FIRST_THRESHOLD = 0`, but the algorithm becomes ~9x faster. For all first thresholds, `FIRST_THRESHOLD` was set on 10,000, except for first transpose as the transpose algorithm where it is 0 because itis fast enough (no first improvement is accepted under an minimum 10,000 improvement, and if not found divide this threshold by 2 until 50 is reached).

### Content of the CSV files

All CSV files have the same columns:
- **FileName**
- **Time** (time of execution in seconds for each instance)
- **InitialCost** (depends on initial method)
- **FinalCost** (after the algorithm was applied)
- **PercentageImprovement** (compared to the initial cost)
- **PercentageOfBestKnown** (compared to the best known cost)",.csv,True
The Linear Ordering Problem over 14 heuristics,16,the-linear-ordering-problem-over-14-heuristics,lop_results_020_ft10000.csv,MIT,"# Link to the scientific paper explaining this dataset generation: [here](https://drive.google.com/file/d/11dYHZ5u5o2gzJErVUtRpNYjl9HfqU5dQ/view?usp=sharing)

Results for each algorithm are saved in a CSV format in this database. The file names are built as follow:

$$
\text{lop\_result\_} \cup \text{pivotingRule} \cup \text{neighborhoodStrategy} \cup \text{initialSolutionMethod} \cup \text{\_ft} \cup \text{FIRST\_THRESHOLD} \cup \text{.csv}
$$

For `pivotingRule`:
- 0 = first threshold
- 1 = best threshold

For `neighborhoodStrategy`:
- 0 = transpose (i.e., exchange with immediate neighbor)
- 1 = exchange
- 2 = insert
- 3 = Variable Neighborhood Descent (VND) with transpose --&gt; exchange --&gt; insert
- 4 = VND with transpose --&gt; insert --&gt; exchange

For `initialSolutionMethod`:
- 0 = random initial solution
- 1 = Chenery and Watanabe initial solution

Finally, we remind that `FIRST_THRESHOLD` gives a pruning method for first improvement. The final result is slightly below the one with `FIRST_THRESHOLD = 0`, but the algorithm becomes ~9x faster. For all first thresholds, `FIRST_THRESHOLD` was set on 10,000, except for first transpose as the transpose algorithm where it is 0 because itis fast enough (no first improvement is accepted under an minimum 10,000 improvement, and if not found divide this threshold by 2 until 50 is reached).

### Content of the CSV files

All CSV files have the same columns:
- **FileName**
- **Time** (time of execution in seconds for each instance)
- **InitialCost** (depends on initial method)
- **FinalCost** (after the algorithm was applied)
- **PercentageImprovement** (compared to the initial cost)
- **PercentageOfBestKnown** (compared to the best known cost)",.csv,True
The Linear Ordering Problem over 14 heuristics,16,the-linear-ordering-problem-over-14-heuristics,lop_results_110_ft10000.csv,MIT,"# Link to the scientific paper explaining this dataset generation: [here](https://drive.google.com/file/d/11dYHZ5u5o2gzJErVUtRpNYjl9HfqU5dQ/view?usp=sharing)

Results for each algorithm are saved in a CSV format in this database. The file names are built as follow:

$$
\text{lop\_result\_} \cup \text{pivotingRule} \cup \text{neighborhoodStrategy} \cup \text{initialSolutionMethod} \cup \text{\_ft} \cup \text{FIRST\_THRESHOLD} \cup \text{.csv}
$$

For `pivotingRule`:
- 0 = first threshold
- 1 = best threshold

For `neighborhoodStrategy`:
- 0 = transpose (i.e., exchange with immediate neighbor)
- 1 = exchange
- 2 = insert
- 3 = Variable Neighborhood Descent (VND) with transpose --&gt; exchange --&gt; insert
- 4 = VND with transpose --&gt; insert --&gt; exchange

For `initialSolutionMethod`:
- 0 = random initial solution
- 1 = Chenery and Watanabe initial solution

Finally, we remind that `FIRST_THRESHOLD` gives a pruning method for first improvement. The final result is slightly below the one with `FIRST_THRESHOLD = 0`, but the algorithm becomes ~9x faster. For all first thresholds, `FIRST_THRESHOLD` was set on 10,000, except for first transpose as the transpose algorithm where it is 0 because itis fast enough (no first improvement is accepted under an minimum 10,000 improvement, and if not found divide this threshold by 2 until 50 is reached).

### Content of the CSV files

All CSV files have the same columns:
- **FileName**
- **Time** (time of execution in seconds for each instance)
- **InitialCost** (depends on initial method)
- **FinalCost** (after the algorithm was applied)
- **PercentageImprovement** (compared to the initial cost)
- **PercentageOfBestKnown** (compared to the best known cost)",.csv,True
The Linear Ordering Problem over 14 heuristics,16,the-linear-ordering-problem-over-14-heuristics,lop_results_001_ft0.csv,MIT,"# Link to the scientific paper explaining this dataset generation: [here](https://drive.google.com/file/d/11dYHZ5u5o2gzJErVUtRpNYjl9HfqU5dQ/view?usp=sharing)

Results for each algorithm are saved in a CSV format in this database. The file names are built as follow:

$$
\text{lop\_result\_} \cup \text{pivotingRule} \cup \text{neighborhoodStrategy} \cup \text{initialSolutionMethod} \cup \text{\_ft} \cup \text{FIRST\_THRESHOLD} \cup \text{.csv}
$$

For `pivotingRule`:
- 0 = first threshold
- 1 = best threshold

For `neighborhoodStrategy`:
- 0 = transpose (i.e., exchange with immediate neighbor)
- 1 = exchange
- 2 = insert
- 3 = Variable Neighborhood Descent (VND) with transpose --&gt; exchange --&gt; insert
- 4 = VND with transpose --&gt; insert --&gt; exchange

For `initialSolutionMethod`:
- 0 = random initial solution
- 1 = Chenery and Watanabe initial solution

Finally, we remind that `FIRST_THRESHOLD` gives a pruning method for first improvement. The final result is slightly below the one with `FIRST_THRESHOLD = 0`, but the algorithm becomes ~9x faster. For all first thresholds, `FIRST_THRESHOLD` was set on 10,000, except for first transpose as the transpose algorithm where it is 0 because itis fast enough (no first improvement is accepted under an minimum 10,000 improvement, and if not found divide this threshold by 2 until 50 is reached).

### Content of the CSV files

All CSV files have the same columns:
- **FileName**
- **Time** (time of execution in seconds for each instance)
- **InitialCost** (depends on initial method)
- **FinalCost** (after the algorithm was applied)
- **PercentageImprovement** (compared to the initial cost)
- **PercentageOfBestKnown** (compared to the best known cost)",.csv,True
The Linear Ordering Problem over 14 heuristics,16,the-linear-ordering-problem-over-14-heuristics,lop_results_001_ft10000.csv,MIT,"# Link to the scientific paper explaining this dataset generation: [here](https://drive.google.com/file/d/11dYHZ5u5o2gzJErVUtRpNYjl9HfqU5dQ/view?usp=sharing)

Results for each algorithm are saved in a CSV format in this database. The file names are built as follow:

$$
\text{lop\_result\_} \cup \text{pivotingRule} \cup \text{neighborhoodStrategy} \cup \text{initialSolutionMethod} \cup \text{\_ft} \cup \text{FIRST\_THRESHOLD} \cup \text{.csv}
$$

For `pivotingRule`:
- 0 = first threshold
- 1 = best threshold

For `neighborhoodStrategy`:
- 0 = transpose (i.e., exchange with immediate neighbor)
- 1 = exchange
- 2 = insert
- 3 = Variable Neighborhood Descent (VND) with transpose --&gt; exchange --&gt; insert
- 4 = VND with transpose --&gt; insert --&gt; exchange

For `initialSolutionMethod`:
- 0 = random initial solution
- 1 = Chenery and Watanabe initial solution

Finally, we remind that `FIRST_THRESHOLD` gives a pruning method for first improvement. The final result is slightly below the one with `FIRST_THRESHOLD = 0`, but the algorithm becomes ~9x faster. For all first thresholds, `FIRST_THRESHOLD` was set on 10,000, except for first transpose as the transpose algorithm where it is 0 because itis fast enough (no first improvement is accepted under an minimum 10,000 improvement, and if not found divide this threshold by 2 until 50 is reached).

### Content of the CSV files

All CSV files have the same columns:
- **FileName**
- **Time** (time of execution in seconds for each instance)
- **InitialCost** (depends on initial method)
- **FinalCost** (after the algorithm was applied)
- **PercentageImprovement** (compared to the initial cost)
- **PercentageOfBestKnown** (compared to the best known cost)",.csv,True
The Linear Ordering Problem over 14 heuristics,16,the-linear-ordering-problem-over-14-heuristics,lop_results_121_ft10000.csv,MIT,"# Link to the scientific paper explaining this dataset generation: [here](https://drive.google.com/file/d/11dYHZ5u5o2gzJErVUtRpNYjl9HfqU5dQ/view?usp=sharing)

Results for each algorithm are saved in a CSV format in this database. The file names are built as follow:

$$
\text{lop\_result\_} \cup \text{pivotingRule} \cup \text{neighborhoodStrategy} \cup \text{initialSolutionMethod} \cup \text{\_ft} \cup \text{FIRST\_THRESHOLD} \cup \text{.csv}
$$

For `pivotingRule`:
- 0 = first threshold
- 1 = best threshold

For `neighborhoodStrategy`:
- 0 = transpose (i.e., exchange with immediate neighbor)
- 1 = exchange
- 2 = insert
- 3 = Variable Neighborhood Descent (VND) with transpose --&gt; exchange --&gt; insert
- 4 = VND with transpose --&gt; insert --&gt; exchange

For `initialSolutionMethod`:
- 0 = random initial solution
- 1 = Chenery and Watanabe initial solution

Finally, we remind that `FIRST_THRESHOLD` gives a pruning method for first improvement. The final result is slightly below the one with `FIRST_THRESHOLD = 0`, but the algorithm becomes ~9x faster. For all first thresholds, `FIRST_THRESHOLD` was set on 10,000, except for first transpose as the transpose algorithm where it is 0 because itis fast enough (no first improvement is accepted under an minimum 10,000 improvement, and if not found divide this threshold by 2 until 50 is reached).

### Content of the CSV files

All CSV files have the same columns:
- **FileName**
- **Time** (time of execution in seconds for each instance)
- **InitialCost** (depends on initial method)
- **FinalCost** (after the algorithm was applied)
- **PercentageImprovement** (compared to the initial cost)
- **PercentageOfBestKnown** (compared to the best known cost)",.csv,True
The Linear Ordering Problem over 14 heuristics,16,the-linear-ordering-problem-over-14-heuristics,lop_results_011_ft10000.csv,MIT,"# Link to the scientific paper explaining this dataset generation: [here](https://drive.google.com/file/d/11dYHZ5u5o2gzJErVUtRpNYjl9HfqU5dQ/view?usp=sharing)

Results for each algorithm are saved in a CSV format in this database. The file names are built as follow:

$$
\text{lop\_result\_} \cup \text{pivotingRule} \cup \text{neighborhoodStrategy} \cup \text{initialSolutionMethod} \cup \text{\_ft} \cup \text{FIRST\_THRESHOLD} \cup \text{.csv}
$$

For `pivotingRule`:
- 0 = first threshold
- 1 = best threshold

For `neighborhoodStrategy`:
- 0 = transpose (i.e., exchange with immediate neighbor)
- 1 = exchange
- 2 = insert
- 3 = Variable Neighborhood Descent (VND) with transpose --&gt; exchange --&gt; insert
- 4 = VND with transpose --&gt; insert --&gt; exchange

For `initialSolutionMethod`:
- 0 = random initial solution
- 1 = Chenery and Watanabe initial solution

Finally, we remind that `FIRST_THRESHOLD` gives a pruning method for first improvement. The final result is slightly below the one with `FIRST_THRESHOLD = 0`, but the algorithm becomes ~9x faster. For all first thresholds, `FIRST_THRESHOLD` was set on 10,000, except for first transpose as the transpose algorithm where it is 0 because itis fast enough (no first improvement is accepted under an minimum 10,000 improvement, and if not found divide this threshold by 2 until 50 is reached).

### Content of the CSV files

All CSV files have the same columns:
- **FileName**
- **Time** (time of execution in seconds for each instance)
- **InitialCost** (depends on initial method)
- **FinalCost** (after the algorithm was applied)
- **PercentageImprovement** (compared to the initial cost)
- **PercentageOfBestKnown** (compared to the best known cost)",.csv,True
The Linear Ordering Problem over 14 heuristics,16,the-linear-ordering-problem-over-14-heuristics,lop_results_111_ft10000.csv,MIT,"# Link to the scientific paper explaining this dataset generation: [here](https://drive.google.com/file/d/11dYHZ5u5o2gzJErVUtRpNYjl9HfqU5dQ/view?usp=sharing)

Results for each algorithm are saved in a CSV format in this database. The file names are built as follow:

$$
\text{lop\_result\_} \cup \text{pivotingRule} \cup \text{neighborhoodStrategy} \cup \text{initialSolutionMethod} \cup \text{\_ft} \cup \text{FIRST\_THRESHOLD} \cup \text{.csv}
$$

For `pivotingRule`:
- 0 = first threshold
- 1 = best threshold

For `neighborhoodStrategy`:
- 0 = transpose (i.e., exchange with immediate neighbor)
- 1 = exchange
- 2 = insert
- 3 = Variable Neighborhood Descent (VND) with transpose --&gt; exchange --&gt; insert
- 4 = VND with transpose --&gt; insert --&gt; exchange

For `initialSolutionMethod`:
- 0 = random initial solution
- 1 = Chenery and Watanabe initial solution

Finally, we remind that `FIRST_THRESHOLD` gives a pruning method for first improvement. The final result is slightly below the one with `FIRST_THRESHOLD = 0`, but the algorithm becomes ~9x faster. For all first thresholds, `FIRST_THRESHOLD` was set on 10,000, except for first transpose as the transpose algorithm where it is 0 because itis fast enough (no first improvement is accepted under an minimum 10,000 improvement, and if not found divide this threshold by 2 until 50 is reached).

### Content of the CSV files

All CSV files have the same columns:
- **FileName**
- **Time** (time of execution in seconds for each instance)
- **InitialCost** (depends on initial method)
- **FinalCost** (after the algorithm was applied)
- **PercentageImprovement** (compared to the initial cost)
- **PercentageOfBestKnown** (compared to the best known cost)",.csv,True
The Linear Ordering Problem over 14 heuristics,16,the-linear-ordering-problem-over-14-heuristics,lop_results_031_ft10000.csv,MIT,"# Link to the scientific paper explaining this dataset generation: [here](https://drive.google.com/file/d/11dYHZ5u5o2gzJErVUtRpNYjl9HfqU5dQ/view?usp=sharing)

Results for each algorithm are saved in a CSV format in this database. The file names are built as follow:

$$
\text{lop\_result\_} \cup \text{pivotingRule} \cup \text{neighborhoodStrategy} \cup \text{initialSolutionMethod} \cup \text{\_ft} \cup \text{FIRST\_THRESHOLD} \cup \text{.csv}
$$

For `pivotingRule`:
- 0 = first threshold
- 1 = best threshold

For `neighborhoodStrategy`:
- 0 = transpose (i.e., exchange with immediate neighbor)
- 1 = exchange
- 2 = insert
- 3 = Variable Neighborhood Descent (VND) with transpose --&gt; exchange --&gt; insert
- 4 = VND with transpose --&gt; insert --&gt; exchange

For `initialSolutionMethod`:
- 0 = random initial solution
- 1 = Chenery and Watanabe initial solution

Finally, we remind that `FIRST_THRESHOLD` gives a pruning method for first improvement. The final result is slightly below the one with `FIRST_THRESHOLD = 0`, but the algorithm becomes ~9x faster. For all first thresholds, `FIRST_THRESHOLD` was set on 10,000, except for first transpose as the transpose algorithm where it is 0 because itis fast enough (no first improvement is accepted under an minimum 10,000 improvement, and if not found divide this threshold by 2 until 50 is reached).

### Content of the CSV files

All CSV files have the same columns:
- **FileName**
- **Time** (time of execution in seconds for each instance)
- **InitialCost** (depends on initial method)
- **FinalCost** (after the algorithm was applied)
- **PercentageImprovement** (compared to the initial cost)
- **PercentageOfBestKnown** (compared to the best known cost)",.csv,True
The Linear Ordering Problem over 14 heuristics,16,the-linear-ordering-problem-over-14-heuristics,lop_results_041_ft10000.csv,MIT,"# Link to the scientific paper explaining this dataset generation: [here](https://drive.google.com/file/d/11dYHZ5u5o2gzJErVUtRpNYjl9HfqU5dQ/view?usp=sharing)

Results for each algorithm are saved in a CSV format in this database. The file names are built as follow:

$$
\text{lop\_result\_} \cup \text{pivotingRule} \cup \text{neighborhoodStrategy} \cup \text{initialSolutionMethod} \cup \text{\_ft} \cup \text{FIRST\_THRESHOLD} \cup \text{.csv}
$$

For `pivotingRule`:
- 0 = first threshold
- 1 = best threshold

For `neighborhoodStrategy`:
- 0 = transpose (i.e., exchange with immediate neighbor)
- 1 = exchange
- 2 = insert
- 3 = Variable Neighborhood Descent (VND) with transpose --&gt; exchange --&gt; insert
- 4 = VND with transpose --&gt; insert --&gt; exchange

For `initialSolutionMethod`:
- 0 = random initial solution
- 1 = Chenery and Watanabe initial solution

Finally, we remind that `FIRST_THRESHOLD` gives a pruning method for first improvement. The final result is slightly below the one with `FIRST_THRESHOLD = 0`, but the algorithm becomes ~9x faster. For all first thresholds, `FIRST_THRESHOLD` was set on 10,000, except for first transpose as the transpose algorithm where it is 0 because itis fast enough (no first improvement is accepted under an minimum 10,000 improvement, and if not found divide this threshold by 2 until 50 is reached).

### Content of the CSV files

All CSV files have the same columns:
- **FileName**
- **Time** (time of execution in seconds for each instance)
- **InitialCost** (depends on initial method)
- **FinalCost** (after the algorithm was applied)
- **PercentageImprovement** (compared to the initial cost)
- **PercentageOfBestKnown** (compared to the best known cost)",.csv,True
The Linear Ordering Problem over 14 heuristics,16,the-linear-ordering-problem-over-14-heuristics,lop_results_021_ft10000.csv,MIT,"# Link to the scientific paper explaining this dataset generation: [here](https://drive.google.com/file/d/11dYHZ5u5o2gzJErVUtRpNYjl9HfqU5dQ/view?usp=sharing)

Results for each algorithm are saved in a CSV format in this database. The file names are built as follow:

$$
\text{lop\_result\_} \cup \text{pivotingRule} \cup \text{neighborhoodStrategy} \cup \text{initialSolutionMethod} \cup \text{\_ft} \cup \text{FIRST\_THRESHOLD} \cup \text{.csv}
$$

For `pivotingRule`:
- 0 = first threshold
- 1 = best threshold

For `neighborhoodStrategy`:
- 0 = transpose (i.e., exchange with immediate neighbor)
- 1 = exchange
- 2 = insert
- 3 = Variable Neighborhood Descent (VND) with transpose --&gt; exchange --&gt; insert
- 4 = VND with transpose --&gt; insert --&gt; exchange

For `initialSolutionMethod`:
- 0 = random initial solution
- 1 = Chenery and Watanabe initial solution

Finally, we remind that `FIRST_THRESHOLD` gives a pruning method for first improvement. The final result is slightly below the one with `FIRST_THRESHOLD = 0`, but the algorithm becomes ~9x faster. For all first thresholds, `FIRST_THRESHOLD` was set on 10,000, except for first transpose as the transpose algorithm where it is 0 because itis fast enough (no first improvement is accepted under an minimum 10,000 improvement, and if not found divide this threshold by 2 until 50 is reached).

### Content of the CSV files

All CSV files have the same columns:
- **FileName**
- **Time** (time of execution in seconds for each instance)
- **InitialCost** (depends on initial method)
- **FinalCost** (after the algorithm was applied)
- **PercentageImprovement** (compared to the initial cost)
- **PercentageOfBestKnown** (compared to the best known cost)",.csv,True
The Linear Ordering Problem over 14 heuristics,16,the-linear-ordering-problem-over-14-heuristics,lop_results_101_ft10000.csv,MIT,"# Link to the scientific paper explaining this dataset generation: [here](https://drive.google.com/file/d/11dYHZ5u5o2gzJErVUtRpNYjl9HfqU5dQ/view?usp=sharing)

Results for each algorithm are saved in a CSV format in this database. The file names are built as follow:

$$
\text{lop\_result\_} \cup \text{pivotingRule} \cup \text{neighborhoodStrategy} \cup \text{initialSolutionMethod} \cup \text{\_ft} \cup \text{FIRST\_THRESHOLD} \cup \text{.csv}
$$

For `pivotingRule`:
- 0 = first threshold
- 1 = best threshold

For `neighborhoodStrategy`:
- 0 = transpose (i.e., exchange with immediate neighbor)
- 1 = exchange
- 2 = insert
- 3 = Variable Neighborhood Descent (VND) with transpose --&gt; exchange --&gt; insert
- 4 = VND with transpose --&gt; insert --&gt; exchange

For `initialSolutionMethod`:
- 0 = random initial solution
- 1 = Chenery and Watanabe initial solution

Finally, we remind that `FIRST_THRESHOLD` gives a pruning method for first improvement. The final result is slightly below the one with `FIRST_THRESHOLD = 0`, but the algorithm becomes ~9x faster. For all first thresholds, `FIRST_THRESHOLD` was set on 10,000, except for first transpose as the transpose algorithm where it is 0 because itis fast enough (no first improvement is accepted under an minimum 10,000 improvement, and if not found divide this threshold by 2 until 50 is reached).

### Content of the CSV files

All CSV files have the same columns:
- **FileName**
- **Time** (time of execution in seconds for each instance)
- **InitialCost** (depends on initial method)
- **FinalCost** (after the algorithm was applied)
- **PercentageImprovement** (compared to the initial cost)
- **PercentageOfBestKnown** (compared to the best known cost)",.csv,True
The Linear Ordering Problem over 14 heuristics,16,the-linear-ordering-problem-over-14-heuristics,lop_results_010_ft10000.csv,MIT,"# Link to the scientific paper explaining this dataset generation: [here](https://drive.google.com/file/d/11dYHZ5u5o2gzJErVUtRpNYjl9HfqU5dQ/view?usp=sharing)

Results for each algorithm are saved in a CSV format in this database. The file names are built as follow:

$$
\text{lop\_result\_} \cup \text{pivotingRule} \cup \text{neighborhoodStrategy} \cup \text{initialSolutionMethod} \cup \text{\_ft} \cup \text{FIRST\_THRESHOLD} \cup \text{.csv}
$$

For `pivotingRule`:
- 0 = first threshold
- 1 = best threshold

For `neighborhoodStrategy`:
- 0 = transpose (i.e., exchange with immediate neighbor)
- 1 = exchange
- 2 = insert
- 3 = Variable Neighborhood Descent (VND) with transpose --&gt; exchange --&gt; insert
- 4 = VND with transpose --&gt; insert --&gt; exchange

For `initialSolutionMethod`:
- 0 = random initial solution
- 1 = Chenery and Watanabe initial solution

Finally, we remind that `FIRST_THRESHOLD` gives a pruning method for first improvement. The final result is slightly below the one with `FIRST_THRESHOLD = 0`, but the algorithm becomes ~9x faster. For all first thresholds, `FIRST_THRESHOLD` was set on 10,000, except for first transpose as the transpose algorithm where it is 0 because itis fast enough (no first improvement is accepted under an minimum 10,000 improvement, and if not found divide this threshold by 2 until 50 is reached).

### Content of the CSV files

All CSV files have the same columns:
- **FileName**
- **Time** (time of execution in seconds for each instance)
- **InitialCost** (depends on initial method)
- **FinalCost** (after the algorithm was applied)
- **PercentageImprovement** (compared to the initial cost)
- **PercentageOfBestKnown** (compared to the best known cost)",.csv,True
The Linear Ordering Problem over 14 heuristics,16,the-linear-ordering-problem-over-14-heuristics,lop_results_120_ft10000.csv,MIT,"# Link to the scientific paper explaining this dataset generation: [here](https://drive.google.com/file/d/11dYHZ5u5o2gzJErVUtRpNYjl9HfqU5dQ/view?usp=sharing)

Results for each algorithm are saved in a CSV format in this database. The file names are built as follow:

$$
\text{lop\_result\_} \cup \text{pivotingRule} \cup \text{neighborhoodStrategy} \cup \text{initialSolutionMethod} \cup \text{\_ft} \cup \text{FIRST\_THRESHOLD} \cup \text{.csv}
$$

For `pivotingRule`:
- 0 = first threshold
- 1 = best threshold

For `neighborhoodStrategy`:
- 0 = transpose (i.e., exchange with immediate neighbor)
- 1 = exchange
- 2 = insert
- 3 = Variable Neighborhood Descent (VND) with transpose --&gt; exchange --&gt; insert
- 4 = VND with transpose --&gt; insert --&gt; exchange

For `initialSolutionMethod`:
- 0 = random initial solution
- 1 = Chenery and Watanabe initial solution

Finally, we remind that `FIRST_THRESHOLD` gives a pruning method for first improvement. The final result is slightly below the one with `FIRST_THRESHOLD = 0`, but the algorithm becomes ~9x faster. For all first thresholds, `FIRST_THRESHOLD` was set on 10,000, except for first transpose as the transpose algorithm where it is 0 because itis fast enough (no first improvement is accepted under an minimum 10,000 improvement, and if not found divide this threshold by 2 until 50 is reached).

### Content of the CSV files

All CSV files have the same columns:
- **FileName**
- **Time** (time of execution in seconds for each instance)
- **InitialCost** (depends on initial method)
- **FinalCost** (after the algorithm was applied)
- **PercentageImprovement** (compared to the initial cost)
- **PercentageOfBestKnown** (compared to the best known cost)",.csv,True
The Linear Ordering Problem over 14 heuristics,16,the-linear-ordering-problem-over-14-heuristics,lop_results_000_ft10000.csv,MIT,"# Link to the scientific paper explaining this dataset generation: [here](https://drive.google.com/file/d/11dYHZ5u5o2gzJErVUtRpNYjl9HfqU5dQ/view?usp=sharing)

Results for each algorithm are saved in a CSV format in this database. The file names are built as follow:

$$
\text{lop\_result\_} \cup \text{pivotingRule} \cup \text{neighborhoodStrategy} \cup \text{initialSolutionMethod} \cup \text{\_ft} \cup \text{FIRST\_THRESHOLD} \cup \text{.csv}
$$

For `pivotingRule`:
- 0 = first threshold
- 1 = best threshold

For `neighborhoodStrategy`:
- 0 = transpose (i.e., exchange with immediate neighbor)
- 1 = exchange
- 2 = insert
- 3 = Variable Neighborhood Descent (VND) with transpose --&gt; exchange --&gt; insert
- 4 = VND with transpose --&gt; insert --&gt; exchange

For `initialSolutionMethod`:
- 0 = random initial solution
- 1 = Chenery and Watanabe initial solution

Finally, we remind that `FIRST_THRESHOLD` gives a pruning method for first improvement. The final result is slightly below the one with `FIRST_THRESHOLD = 0`, but the algorithm becomes ~9x faster. For all first thresholds, `FIRST_THRESHOLD` was set on 10,000, except for first transpose as the transpose algorithm where it is 0 because itis fast enough (no first improvement is accepted under an minimum 10,000 improvement, and if not found divide this threshold by 2 until 50 is reached).

### Content of the CSV files

All CSV files have the same columns:
- **FileName**
- **Time** (time of execution in seconds for each instance)
- **InitialCost** (depends on initial method)
- **FinalCost** (after the algorithm was applied)
- **PercentageImprovement** (compared to the initial cost)
- **PercentageOfBestKnown** (compared to the best known cost)",.csv,True
The Spotify Hit Predictor Dataset (1960-2019),6,the-spotify-hit-predictor-dataset,dataset-of-90s.csv,CC-BY-NC-SA-4.0,"### Context

This is a dataset consisting of features for tracks fetched using Spotify's Web API. The tracks are labeled '1' or '0' ('Hit' or 'Flop') depending on some criteria of the author.
This dataset can be used to make a classification model that predicts whether a track would be a 'Hit' or not.
	
(Note: The author does not objectively considers a track inferior, bad or a failure if its labeled 'Flop'. 'Flop' here merely implies that it is a track that probably could not be considered popular in the mainstream.)

Here's an implementation of this idea in the form of a website that I made. http://www.hitpredictor.in/

I did not use this specific dataset, but a smaller version of it.
	
### Content
Here's the scripts that I used to construct this dataset. The repo is very messy, so warnings ahead:

https://github.com/fortyTwo102/hitpredictor-decade-util

For further reading: https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/

	- track: The Name of the track.

	- artist: The Name of the Artist.

	- uri: The resource identifier for the track.

	- danceability: Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable. 

	- energy: Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy. 

	- key: The estimated overall key of the track. Integers map to pitches using standard Pitch Class notation. E.g. 0 = C, 1 = C?/D?, 2 = D, and so on. If no key was detected, the value is -1.

	- loudness: The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typical range between -60 and 0 db. 
		   
	- mode: Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.

	- speechiness: Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks. 

	- acousticness: A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic. The distribution of values for this feature look like this:
	
	- instrumentalness: Predicts whether a track contains no vocals. “Ooh” and “aah” sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly “vocal”. The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0. The distribution of values for this feature look like this:
	
	- liveness: Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live.
	
	- valence: A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).
	
	- tempo: The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration. 
	
	- duration_ms: 	The duration of the track in milliseconds.
	
	- time_signature: An estimated overall time signature of a track. The time signature (meter) is a notational convention to specify how many beats are in each bar (or measure).
	
	- chorus_hit: This the the author's best estimate of when the chorus would start for the track. Its the timestamp of the start of the third section of the track. This feature was extracted from the data received by the API call for Audio Analysis of that particular track.
	
	- sections: The number of sections the particular track has. This feature was extracted from the data received by the API call for Audio Analysis of that particular track.
	
	- target: The target variable for the track. It can be either '0' or '1'. '1' implies that this song has featured in the weekly list (Issued by Billboards) of Hot-100 tracks in that decade at least once and is therefore a 'hit'. '0' Implies that the track is a 'flop'.
		
		  The author's condition of a track being 'flop' is as follows:

			- The track must not appear in the 'hit' list of that decade.
			- The track's artist must not appear in the 'hit' list of that decade.
			- The track must belong to a genre that could be considered non-mainstream and / or avant-garde. 
			- The track's genre must not have a song in the 'hit' list.
			- The track must have 'US' as one of its markets.


### Acknowledgements

- ""spotipy"": Python module for Spotify's API (https://pypi.org/project/spotipy/)

- ""billboard"": Python module for Billboard's API (https://pypi.org/project/billboard.py/)

- Spotify, the company itself. For keeping a database of such in-depth details of every track in their library. And for exposing their API for the world to use.


### Inspiration

Is pop music really formulaic? 
If yes, can you prove it using science?",.csv,True
The Spotify Hit Predictor Dataset (1960-2019),6,the-spotify-hit-predictor-dataset,dataset-of-80s.csv,CC-BY-NC-SA-4.0,"### Context

This is a dataset consisting of features for tracks fetched using Spotify's Web API. The tracks are labeled '1' or '0' ('Hit' or 'Flop') depending on some criteria of the author.
This dataset can be used to make a classification model that predicts whether a track would be a 'Hit' or not.
	
(Note: The author does not objectively considers a track inferior, bad or a failure if its labeled 'Flop'. 'Flop' here merely implies that it is a track that probably could not be considered popular in the mainstream.)

Here's an implementation of this idea in the form of a website that I made. http://www.hitpredictor.in/

I did not use this specific dataset, but a smaller version of it.
	
### Content
Here's the scripts that I used to construct this dataset. The repo is very messy, so warnings ahead:

https://github.com/fortyTwo102/hitpredictor-decade-util

For further reading: https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/

	- track: The Name of the track.

	- artist: The Name of the Artist.

	- uri: The resource identifier for the track.

	- danceability: Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable. 

	- energy: Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy. 

	- key: The estimated overall key of the track. Integers map to pitches using standard Pitch Class notation. E.g. 0 = C, 1 = C?/D?, 2 = D, and so on. If no key was detected, the value is -1.

	- loudness: The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typical range between -60 and 0 db. 
		   
	- mode: Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.

	- speechiness: Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks. 

	- acousticness: A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic. The distribution of values for this feature look like this:
	
	- instrumentalness: Predicts whether a track contains no vocals. “Ooh” and “aah” sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly “vocal”. The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0. The distribution of values for this feature look like this:
	
	- liveness: Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live.
	
	- valence: A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).
	
	- tempo: The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration. 
	
	- duration_ms: 	The duration of the track in milliseconds.
	
	- time_signature: An estimated overall time signature of a track. The time signature (meter) is a notational convention to specify how many beats are in each bar (or measure).
	
	- chorus_hit: This the the author's best estimate of when the chorus would start for the track. Its the timestamp of the start of the third section of the track. This feature was extracted from the data received by the API call for Audio Analysis of that particular track.
	
	- sections: The number of sections the particular track has. This feature was extracted from the data received by the API call for Audio Analysis of that particular track.
	
	- target: The target variable for the track. It can be either '0' or '1'. '1' implies that this song has featured in the weekly list (Issued by Billboards) of Hot-100 tracks in that decade at least once and is therefore a 'hit'. '0' Implies that the track is a 'flop'.
		
		  The author's condition of a track being 'flop' is as follows:

			- The track must not appear in the 'hit' list of that decade.
			- The track's artist must not appear in the 'hit' list of that decade.
			- The track must belong to a genre that could be considered non-mainstream and / or avant-garde. 
			- The track's genre must not have a song in the 'hit' list.
			- The track must have 'US' as one of its markets.


### Acknowledgements

- ""spotipy"": Python module for Spotify's API (https://pypi.org/project/spotipy/)

- ""billboard"": Python module for Billboard's API (https://pypi.org/project/billboard.py/)

- Spotify, the company itself. For keeping a database of such in-depth details of every track in their library. And for exposing their API for the world to use.


### Inspiration

Is pop music really formulaic? 
If yes, can you prove it using science?",.csv,True
The Spotify Hit Predictor Dataset (1960-2019),6,the-spotify-hit-predictor-dataset,dataset-of-00s.csv,CC-BY-NC-SA-4.0,"### Context

This is a dataset consisting of features for tracks fetched using Spotify's Web API. The tracks are labeled '1' or '0' ('Hit' or 'Flop') depending on some criteria of the author.
This dataset can be used to make a classification model that predicts whether a track would be a 'Hit' or not.
	
(Note: The author does not objectively considers a track inferior, bad or a failure if its labeled 'Flop'. 'Flop' here merely implies that it is a track that probably could not be considered popular in the mainstream.)

Here's an implementation of this idea in the form of a website that I made. http://www.hitpredictor.in/

I did not use this specific dataset, but a smaller version of it.
	
### Content
Here's the scripts that I used to construct this dataset. The repo is very messy, so warnings ahead:

https://github.com/fortyTwo102/hitpredictor-decade-util

For further reading: https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/

	- track: The Name of the track.

	- artist: The Name of the Artist.

	- uri: The resource identifier for the track.

	- danceability: Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable. 

	- energy: Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy. 

	- key: The estimated overall key of the track. Integers map to pitches using standard Pitch Class notation. E.g. 0 = C, 1 = C?/D?, 2 = D, and so on. If no key was detected, the value is -1.

	- loudness: The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typical range between -60 and 0 db. 
		   
	- mode: Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.

	- speechiness: Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks. 

	- acousticness: A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic. The distribution of values for this feature look like this:
	
	- instrumentalness: Predicts whether a track contains no vocals. “Ooh” and “aah” sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly “vocal”. The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0. The distribution of values for this feature look like this:
	
	- liveness: Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live.
	
	- valence: A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).
	
	- tempo: The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration. 
	
	- duration_ms: 	The duration of the track in milliseconds.
	
	- time_signature: An estimated overall time signature of a track. The time signature (meter) is a notational convention to specify how many beats are in each bar (or measure).
	
	- chorus_hit: This the the author's best estimate of when the chorus would start for the track. Its the timestamp of the start of the third section of the track. This feature was extracted from the data received by the API call for Audio Analysis of that particular track.
	
	- sections: The number of sections the particular track has. This feature was extracted from the data received by the API call for Audio Analysis of that particular track.
	
	- target: The target variable for the track. It can be either '0' or '1'. '1' implies that this song has featured in the weekly list (Issued by Billboards) of Hot-100 tracks in that decade at least once and is therefore a 'hit'. '0' Implies that the track is a 'flop'.
		
		  The author's condition of a track being 'flop' is as follows:

			- The track must not appear in the 'hit' list of that decade.
			- The track's artist must not appear in the 'hit' list of that decade.
			- The track must belong to a genre that could be considered non-mainstream and / or avant-garde. 
			- The track's genre must not have a song in the 'hit' list.
			- The track must have 'US' as one of its markets.


### Acknowledgements

- ""spotipy"": Python module for Spotify's API (https://pypi.org/project/spotipy/)

- ""billboard"": Python module for Billboard's API (https://pypi.org/project/billboard.py/)

- Spotify, the company itself. For keeping a database of such in-depth details of every track in their library. And for exposing their API for the world to use.


### Inspiration

Is pop music really formulaic? 
If yes, can you prove it using science?",.csv,True
The Spotify Hit Predictor Dataset (1960-2019),6,the-spotify-hit-predictor-dataset,dataset-of-60s.csv,CC-BY-NC-SA-4.0,"### Context

This is a dataset consisting of features for tracks fetched using Spotify's Web API. The tracks are labeled '1' or '0' ('Hit' or 'Flop') depending on some criteria of the author.
This dataset can be used to make a classification model that predicts whether a track would be a 'Hit' or not.
	
(Note: The author does not objectively considers a track inferior, bad or a failure if its labeled 'Flop'. 'Flop' here merely implies that it is a track that probably could not be considered popular in the mainstream.)

Here's an implementation of this idea in the form of a website that I made. http://www.hitpredictor.in/

I did not use this specific dataset, but a smaller version of it.
	
### Content
Here's the scripts that I used to construct this dataset. The repo is very messy, so warnings ahead:

https://github.com/fortyTwo102/hitpredictor-decade-util

For further reading: https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/

	- track: The Name of the track.

	- artist: The Name of the Artist.

	- uri: The resource identifier for the track.

	- danceability: Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable. 

	- energy: Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy. 

	- key: The estimated overall key of the track. Integers map to pitches using standard Pitch Class notation. E.g. 0 = C, 1 = C?/D?, 2 = D, and so on. If no key was detected, the value is -1.

	- loudness: The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typical range between -60 and 0 db. 
		   
	- mode: Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.

	- speechiness: Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks. 

	- acousticness: A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic. The distribution of values for this feature look like this:
	
	- instrumentalness: Predicts whether a track contains no vocals. “Ooh” and “aah” sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly “vocal”. The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0. The distribution of values for this feature look like this:
	
	- liveness: Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live.
	
	- valence: A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).
	
	- tempo: The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration. 
	
	- duration_ms: 	The duration of the track in milliseconds.
	
	- time_signature: An estimated overall time signature of a track. The time signature (meter) is a notational convention to specify how many beats are in each bar (or measure).
	
	- chorus_hit: This the the author's best estimate of when the chorus would start for the track. Its the timestamp of the start of the third section of the track. This feature was extracted from the data received by the API call for Audio Analysis of that particular track.
	
	- sections: The number of sections the particular track has. This feature was extracted from the data received by the API call for Audio Analysis of that particular track.
	
	- target: The target variable for the track. It can be either '0' or '1'. '1' implies that this song has featured in the weekly list (Issued by Billboards) of Hot-100 tracks in that decade at least once and is therefore a 'hit'. '0' Implies that the track is a 'flop'.
		
		  The author's condition of a track being 'flop' is as follows:

			- The track must not appear in the 'hit' list of that decade.
			- The track's artist must not appear in the 'hit' list of that decade.
			- The track must belong to a genre that could be considered non-mainstream and / or avant-garde. 
			- The track's genre must not have a song in the 'hit' list.
			- The track must have 'US' as one of its markets.


### Acknowledgements

- ""spotipy"": Python module for Spotify's API (https://pypi.org/project/spotipy/)

- ""billboard"": Python module for Billboard's API (https://pypi.org/project/billboard.py/)

- Spotify, the company itself. For keeping a database of such in-depth details of every track in their library. And for exposing their API for the world to use.


### Inspiration

Is pop music really formulaic? 
If yes, can you prove it using science?",.csv,True
The Spotify Hit Predictor Dataset (1960-2019),6,the-spotify-hit-predictor-dataset,dataset-of-10s.csv,CC-BY-NC-SA-4.0,"### Context

This is a dataset consisting of features for tracks fetched using Spotify's Web API. The tracks are labeled '1' or '0' ('Hit' or 'Flop') depending on some criteria of the author.
This dataset can be used to make a classification model that predicts whether a track would be a 'Hit' or not.
	
(Note: The author does not objectively considers a track inferior, bad or a failure if its labeled 'Flop'. 'Flop' here merely implies that it is a track that probably could not be considered popular in the mainstream.)

Here's an implementation of this idea in the form of a website that I made. http://www.hitpredictor.in/

I did not use this specific dataset, but a smaller version of it.
	
### Content
Here's the scripts that I used to construct this dataset. The repo is very messy, so warnings ahead:

https://github.com/fortyTwo102/hitpredictor-decade-util

For further reading: https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/

	- track: The Name of the track.

	- artist: The Name of the Artist.

	- uri: The resource identifier for the track.

	- danceability: Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable. 

	- energy: Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy. 

	- key: The estimated overall key of the track. Integers map to pitches using standard Pitch Class notation. E.g. 0 = C, 1 = C?/D?, 2 = D, and so on. If no key was detected, the value is -1.

	- loudness: The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typical range between -60 and 0 db. 
		   
	- mode: Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.

	- speechiness: Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks. 

	- acousticness: A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic. The distribution of values for this feature look like this:
	
	- instrumentalness: Predicts whether a track contains no vocals. “Ooh” and “aah” sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly “vocal”. The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0. The distribution of values for this feature look like this:
	
	- liveness: Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live.
	
	- valence: A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).
	
	- tempo: The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration. 
	
	- duration_ms: 	The duration of the track in milliseconds.
	
	- time_signature: An estimated overall time signature of a track. The time signature (meter) is a notational convention to specify how many beats are in each bar (or measure).
	
	- chorus_hit: This the the author's best estimate of when the chorus would start for the track. Its the timestamp of the start of the third section of the track. This feature was extracted from the data received by the API call for Audio Analysis of that particular track.
	
	- sections: The number of sections the particular track has. This feature was extracted from the data received by the API call for Audio Analysis of that particular track.
	
	- target: The target variable for the track. It can be either '0' or '1'. '1' implies that this song has featured in the weekly list (Issued by Billboards) of Hot-100 tracks in that decade at least once and is therefore a 'hit'. '0' Implies that the track is a 'flop'.
		
		  The author's condition of a track being 'flop' is as follows:

			- The track must not appear in the 'hit' list of that decade.
			- The track's artist must not appear in the 'hit' list of that decade.
			- The track must belong to a genre that could be considered non-mainstream and / or avant-garde. 
			- The track's genre must not have a song in the 'hit' list.
			- The track must have 'US' as one of its markets.


### Acknowledgements

- ""spotipy"": Python module for Spotify's API (https://pypi.org/project/spotipy/)

- ""billboard"": Python module for Billboard's API (https://pypi.org/project/billboard.py/)

- Spotify, the company itself. For keeping a database of such in-depth details of every track in their library. And for exposing their API for the world to use.


### Inspiration

Is pop music really formulaic? 
If yes, can you prove it using science?",.csv,True
The Spotify Hit Predictor Dataset (1960-2019),6,the-spotify-hit-predictor-dataset,dataset-of-70s.csv,CC-BY-NC-SA-4.0,"### Context

This is a dataset consisting of features for tracks fetched using Spotify's Web API. The tracks are labeled '1' or '0' ('Hit' or 'Flop') depending on some criteria of the author.
This dataset can be used to make a classification model that predicts whether a track would be a 'Hit' or not.
	
(Note: The author does not objectively considers a track inferior, bad or a failure if its labeled 'Flop'. 'Flop' here merely implies that it is a track that probably could not be considered popular in the mainstream.)

Here's an implementation of this idea in the form of a website that I made. http://www.hitpredictor.in/

I did not use this specific dataset, but a smaller version of it.
	
### Content
Here's the scripts that I used to construct this dataset. The repo is very messy, so warnings ahead:

https://github.com/fortyTwo102/hitpredictor-decade-util

For further reading: https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/

	- track: The Name of the track.

	- artist: The Name of the Artist.

	- uri: The resource identifier for the track.

	- danceability: Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable. 

	- energy: Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy. 

	- key: The estimated overall key of the track. Integers map to pitches using standard Pitch Class notation. E.g. 0 = C, 1 = C?/D?, 2 = D, and so on. If no key was detected, the value is -1.

	- loudness: The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typical range between -60 and 0 db. 
		   
	- mode: Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.

	- speechiness: Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks. 

	- acousticness: A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic. The distribution of values for this feature look like this:
	
	- instrumentalness: Predicts whether a track contains no vocals. “Ooh” and “aah” sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly “vocal”. The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0. The distribution of values for this feature look like this:
	
	- liveness: Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live.
	
	- valence: A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).
	
	- tempo: The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration. 
	
	- duration_ms: 	The duration of the track in milliseconds.
	
	- time_signature: An estimated overall time signature of a track. The time signature (meter) is a notational convention to specify how many beats are in each bar (or measure).
	
	- chorus_hit: This the the author's best estimate of when the chorus would start for the track. Its the timestamp of the start of the third section of the track. This feature was extracted from the data received by the API call for Audio Analysis of that particular track.
	
	- sections: The number of sections the particular track has. This feature was extracted from the data received by the API call for Audio Analysis of that particular track.
	
	- target: The target variable for the track. It can be either '0' or '1'. '1' implies that this song has featured in the weekly list (Issued by Billboards) of Hot-100 tracks in that decade at least once and is therefore a 'hit'. '0' Implies that the track is a 'flop'.
		
		  The author's condition of a track being 'flop' is as follows:

			- The track must not appear in the 'hit' list of that decade.
			- The track's artist must not appear in the 'hit' list of that decade.
			- The track must belong to a genre that could be considered non-mainstream and / or avant-garde. 
			- The track's genre must not have a song in the 'hit' list.
			- The track must have 'US' as one of its markets.


### Acknowledgements

- ""spotipy"": Python module for Spotify's API (https://pypi.org/project/spotipy/)

- ""billboard"": Python module for Billboard's API (https://pypi.org/project/billboard.py/)

- Spotify, the company itself. For keeping a database of such in-depth details of every track in their library. And for exposing their API for the world to use.


### Inspiration

Is pop music really formulaic? 
If yes, can you prove it using science?",.csv,True
Time Series Practice Dataset,2,time-series-practice-dataset,test.csv,CC0-1.0,"### Context

This dataset is intended for anybody who wants to practice and improve their time series skills. 

### Content

This dataset contains simulated time series data covering 10 years (2010-2019). The features include date, store id, product id and number sold. The train.csv covers the years 2010-2018 and the test.csv covers 2019 only. The are 7 unique stores and 10 unique products. The are no null values. The objective is to predict the number sold feature in the test.csv. 

I created this time series data using multiple features including various long term trends, year-long seasonality patterns, weekday/weekend effects and noise. Moreover, the products and the stores are supposed to be weakly correlated. 

### Assessment

To compare with other peoples solutions, I recommend using the MAPE (Mean Absolute Percentage Error) metric.",.csv,True
Time Series Practice Dataset,2,time-series-practice-dataset,train.csv,CC0-1.0,"### Context

This dataset is intended for anybody who wants to practice and improve their time series skills. 

### Content

This dataset contains simulated time series data covering 10 years (2010-2019). The features include date, store id, product id and number sold. The train.csv covers the years 2010-2018 and the test.csv covers 2019 only. The are 7 unique stores and 10 unique products. The are no null values. The objective is to predict the number sold feature in the test.csv. 

I created this time series data using multiple features including various long term trends, year-long seasonality patterns, weekday/weekend effects and noise. Moreover, the products and the stores are supposed to be weakly correlated. 

### Assessment

To compare with other peoples solutions, I recommend using the MAPE (Mean Absolute Percentage Error) metric.",.csv,True
Top 100 Korean Drama (MyDramaList),2,top-100-korean-drama-mydramalist,top100_kdrama.csv,CC0-1.0,"### 🔥NEW DATASET
I have recently published another dataset with information about Korean Drama. This dataset has more than 100 Korean drama for eveyone to explore. Also, I have included information regarding reviews and actors as well. <br>
Check out the new dataset via this link: **https://www.kaggle.com/datasets/chanoncharuchinda/korean-drama-2015-23-actor-and-reviewmydramalist**


### Top 100 Korean Drama on MyDramaList

According to mydramalist.com, ""MyDramaList.com is a community-based project which provides Asian drama & movie fans"".  On the website, fans can ""create their very own drama watchlists, rate dramas and films, write reviews"" and many more engaging activities. This dataset ranks the Top 100 Korean Drama rating given by the users on the website. 

### Content

* Name: Korean Drama name
* Year of release: Release year of the drama
* Aired Date: Aired Date (start) - (end)
* Aired On: Aired on what day(s) of the week
* Number of Episode: How many episodes are there
* Network: What Network is the drama aired on
* Duration: How long is one episode approximately
* Content Rating: Content rate for appropriate audience
* Synopsis: Short story of the drama
* Cast: Actors and Actresses in the drama
* Genre: Genre that the drama is listed in 
* Tags: Tags that the drama is listed in 
* Rank: Ranking on the website
* Rating: Rating by the users on the website out of ten

### Acknowledgements

This data is taken from the website https://mydramalist.com/shows/top_korean_dramas?page=1. This is my first time doing web scrapping. I wouldn't be able to do it without the help of StackOverflow and YouTube.

### Inspiration

I have been a huge fan of Korean Drama and K pop since high-school.  It is fun to integrate what I love with my interest toward data science. Some of the interesting questions (possibly tasks) here would be:

1. What is/are the popular Genres and Theme (Tags column) and does it leads to higher rating? 
2. Does the day at which is the drama is aired affects its rating?
3. Create a recommendation system for the Drama (and check with the recommendation by the website)

The possibility is endless...keep striving!

",.csv,True
Top 100 Korean Drama (MyDramaList),2,top-100-korean-drama-mydramalist,top100_kdrama_aug_2023.csv,CC0-1.0,"### 🔥NEW DATASET
I have recently published another dataset with information about Korean Drama. This dataset has more than 100 Korean drama for eveyone to explore. Also, I have included information regarding reviews and actors as well. <br>
Check out the new dataset via this link: **https://www.kaggle.com/datasets/chanoncharuchinda/korean-drama-2015-23-actor-and-reviewmydramalist**


### Top 100 Korean Drama on MyDramaList

According to mydramalist.com, ""MyDramaList.com is a community-based project which provides Asian drama & movie fans"".  On the website, fans can ""create their very own drama watchlists, rate dramas and films, write reviews"" and many more engaging activities. This dataset ranks the Top 100 Korean Drama rating given by the users on the website. 

### Content

* Name: Korean Drama name
* Year of release: Release year of the drama
* Aired Date: Aired Date (start) - (end)
* Aired On: Aired on what day(s) of the week
* Number of Episode: How many episodes are there
* Network: What Network is the drama aired on
* Duration: How long is one episode approximately
* Content Rating: Content rate for appropriate audience
* Synopsis: Short story of the drama
* Cast: Actors and Actresses in the drama
* Genre: Genre that the drama is listed in 
* Tags: Tags that the drama is listed in 
* Rank: Ranking on the website
* Rating: Rating by the users on the website out of ten

### Acknowledgements

This data is taken from the website https://mydramalist.com/shows/top_korean_dramas?page=1. This is my first time doing web scrapping. I wouldn't be able to do it without the help of StackOverflow and YouTube.

### Inspiration

I have been a huge fan of Korean Drama and K pop since high-school.  It is fun to integrate what I love with my interest toward data science. Some of the interesting questions (possibly tasks) here would be:

1. What is/are the popular Genres and Theme (Tags column) and does it leads to higher rating? 
2. Does the day at which is the drama is aired affects its rating?
3. Create a recommendation system for the Drama (and check with the recommendation by the website)

The possibility is endless...keep striving!

",.csv,True
Total Business Inventories and Sales Data,8,total-business-inventories-and-sales-data,BUSINV.csv,other,"### Content  

More details about each file are in the individual file descriptions.  

### Context  

This is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  

* Update Frequency: This dataset is updated daily.



### Acknowledgements

This dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  

[Cover photo](https://unsplash.com/photos/qE1jxYXiwOA) by [Petr Sevcovic](https://unsplash.com/@sevcovic23) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv,True
Total Business Inventories and Sales Data,8,total-business-inventories-and-sales-data,TOTBUSSMSA.csv,other,"### Content  

More details about each file are in the individual file descriptions.  

### Context  

This is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  

* Update Frequency: This dataset is updated daily.



### Acknowledgements

This dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  

[Cover photo](https://unsplash.com/photos/qE1jxYXiwOA) by [Petr Sevcovic](https://unsplash.com/@sevcovic23) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv,True
Total Business Inventories and Sales Data,8,total-business-inventories-and-sales-data,TOTBUSMPCSMSA.csv,other,"### Content  

More details about each file are in the individual file descriptions.  

### Context  

This is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  

* Update Frequency: This dataset is updated daily.



### Acknowledgements

This dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  

[Cover photo](https://unsplash.com/photos/qE1jxYXiwOA) by [Petr Sevcovic](https://unsplash.com/@sevcovic23) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv,True
Total Business Inventories and Sales Data,8,total-business-inventories-and-sales-data,TOTBUSMPCIMSA.csv,other,"### Content  

More details about each file are in the individual file descriptions.  

### Context  

This is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  

* Update Frequency: This dataset is updated daily.



### Acknowledgements

This dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  

[Cover photo](https://unsplash.com/photos/qE1jxYXiwOA) by [Petr Sevcovic](https://unsplash.com/@sevcovic23) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv,True
Total Business Inventories and Sales Data,8,total-business-inventories-and-sales-data,TOTBUSIMNSA.csv,other,"### Content  

More details about each file are in the individual file descriptions.  

### Context  

This is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  

* Update Frequency: This dataset is updated daily.



### Acknowledgements

This dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  

[Cover photo](https://unsplash.com/photos/qE1jxYXiwOA) by [Petr Sevcovic](https://unsplash.com/@sevcovic23) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv,True
Total Business Inventories and Sales Data,8,total-business-inventories-and-sales-data,ISRATIO.csv,other,"### Content  

More details about each file are in the individual file descriptions.  

### Context  

This is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  

* Update Frequency: This dataset is updated daily.



### Acknowledgements

This dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  

[Cover photo](https://unsplash.com/photos/qE1jxYXiwOA) by [Petr Sevcovic](https://unsplash.com/@sevcovic23) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv,True
Total Business Inventories and Sales Data,8,total-business-inventories-and-sales-data,TOTBUSIRNSA.csv,other,"### Content  

More details about each file are in the individual file descriptions.  

### Context  

This is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  

* Update Frequency: This dataset is updated daily.



### Acknowledgements

This dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  

[Cover photo](https://unsplash.com/photos/qE1jxYXiwOA) by [Petr Sevcovic](https://unsplash.com/@sevcovic23) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv,True
Total Business Inventories and Sales Data,8,total-business-inventories-and-sales-data,TOTBUSSMNSA.csv,other,"### Content  

More details about each file are in the individual file descriptions.  

### Context  

This is a dataset from the [U.S. Census Bureau](http://www.census.gov/) hosted by the Federal Reserve Economic Database (FRED). FRED has a data platform found [here](https://fred.stlouisfed.org/) and they update their information according the amount of data that is brought in. Explore the U.S. Census Bureau using Kaggle and all of the data sources available through the U.S. Census Bureau [organization page](https://www.kaggle.com/census)!  

* Update Frequency: This dataset is updated daily.



### Acknowledgements

This dataset is maintained using FRED's [API](https://research.stlouisfed.org/docs/api/fred/) and Kaggle's [API](https://github.com/Kaggle/kaggle-api).  

[Cover photo](https://unsplash.com/photos/qE1jxYXiwOA) by [Petr Sevcovic](https://unsplash.com/@sevcovic23) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv,True
Traffic Prediction Dataset,2,traffic-prediction-dataset,Traffic.csv,other,"Traffic congestion and related problems are a common concern in urban areas. Understanding traffic patterns and analyzing data can provide valuable insights for transportation planning, infrastructure development, and congestion management. 

**What exactly is this dataset and how was it created?**
it is a valuable resource for studying traffic conditions as it contains information collected by a computer vision model. The model detects four classes of vehicles: cars, bikes, buses, and trucks. The dataset is stored in a CSV file and includes additional columns such as time in hours, date, days of the week, and counts for each vehicle type (CarCount, BikeCount, BusCount, TruckCount). The ""Total"" column represents the total count of all vehicle types detected within a 15-minute duration. 

The dataset is updated every 15 minutes, providing a comprehensive view of traffic patterns over the course of one month. Additionally, the dataset includes a column indicating the traffic situation categorized into four classes: 1-Heavy, 2-High, 3-Normal, and 4-Low. This information can help assess the severity of congestion and monitor traffic conditions at different times and days of the week.

**In what cases can it be useful?**
The dataset is useful in transportation planning, congestion management, and traffic flow analysis. It helps understand vehicle demand, identify congested areas, and inform infrastructure improvements. The dataset enables targeted interventions like signal optimizations and lane adjustments. It allows researchers to study traffic patterns by hour, day, or specific dates and explore correlations with external factors. It supports transportation research on vehicle relationships and traffic behavior. Urban planners can assess traffic impact for zoning and infrastructure decisions. Overall, the dataset empowers stakeholders to make data-driven decisions, enhance urban mobility, and create efficient and sustainable cities.

**Is there a new update?**
Yes, in the next update, the dataset will be expanded to include the speed of the cars. Additionally, the data will not be limited to a single route; instead, it will encompass a traffic intersection. This expansion aims to provide a more comprehensive understanding of traffic dynamics and enable better analysis and decision-making for traffic management. The inclusion of speed data will offer insights into the flow and efficiency of vehicles, further enhancing the dataset's value for transportation planning and congestion management efforts.

Thanks",.csv,True
Traffic Prediction Dataset,2,traffic-prediction-dataset,TrafficTwoMonth.csv,other,"Traffic congestion and related problems are a common concern in urban areas. Understanding traffic patterns and analyzing data can provide valuable insights for transportation planning, infrastructure development, and congestion management. 

**What exactly is this dataset and how was it created?**
it is a valuable resource for studying traffic conditions as it contains information collected by a computer vision model. The model detects four classes of vehicles: cars, bikes, buses, and trucks. The dataset is stored in a CSV file and includes additional columns such as time in hours, date, days of the week, and counts for each vehicle type (CarCount, BikeCount, BusCount, TruckCount). The ""Total"" column represents the total count of all vehicle types detected within a 15-minute duration. 

The dataset is updated every 15 minutes, providing a comprehensive view of traffic patterns over the course of one month. Additionally, the dataset includes a column indicating the traffic situation categorized into four classes: 1-Heavy, 2-High, 3-Normal, and 4-Low. This information can help assess the severity of congestion and monitor traffic conditions at different times and days of the week.

**In what cases can it be useful?**
The dataset is useful in transportation planning, congestion management, and traffic flow analysis. It helps understand vehicle demand, identify congested areas, and inform infrastructure improvements. The dataset enables targeted interventions like signal optimizations and lane adjustments. It allows researchers to study traffic patterns by hour, day, or specific dates and explore correlations with external factors. It supports transportation research on vehicle relationships and traffic behavior. Urban planners can assess traffic impact for zoning and infrastructure decisions. Overall, the dataset empowers stakeholders to make data-driven decisions, enhance urban mobility, and create efficient and sustainable cities.

**Is there a new update?**
Yes, in the next update, the dataset will be expanded to include the speed of the cars. Additionally, the data will not be limited to a single route; instead, it will encompass a traffic intersection. This expansion aims to provide a more comprehensive understanding of traffic dynamics and enable better analysis and decision-making for traffic management. The inclusion of speed data will offer insights into the flow and efficiency of vehicles, further enhancing the dataset's value for transportation planning and congestion management efforts.

Thanks",.csv,True
Travel destinations reviews in Sri Lanka,2,travel-destinations-reviews-in-sir-lanka,Destination Reviews_(raw).csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"The dataset comprises reviews of travel destinations in Sri Lanka, gathered from Google Maps. It consists of four primary columns: ""Destination,"" ""District,"" ""Timespan,"" and ""Review."" The ""Destination"" column denotes the specific places or attractions within Sri Lanka that travelers have reviewed. The ""District"" column categorizes these destinations into different administrative regions, including Badulla, Colombo, Galle, Gampaha, Hambanthota, Hatton, Kalutara, Kurunegala, Matale, Matara, Ratnapura, and Kandy. The ""Timespan"" column indicates when the reviews were posted or the period during which the reviewers visited these destinations. Finally, the ""Review"" column contains the textual feedback or opinions shared by travelers regarding their experiences at these various locations. This dataset could be invaluable for understanding the popularity, appeal, and overall perception of different travel destinations across Sri Lanka, providing insights for tourism management, marketing strategies, and further analysis.",.csv,True
Travel destinations reviews in Sri Lanka,2,travel-destinations-reviews-in-sir-lanka,Destination Reviews (final).csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"The dataset comprises reviews of travel destinations in Sri Lanka, gathered from Google Maps. It consists of four primary columns: ""Destination,"" ""District,"" ""Timespan,"" and ""Review."" The ""Destination"" column denotes the specific places or attractions within Sri Lanka that travelers have reviewed. The ""District"" column categorizes these destinations into different administrative regions, including Badulla, Colombo, Galle, Gampaha, Hambanthota, Hatton, Kalutara, Kurunegala, Matale, Matara, Ratnapura, and Kandy. The ""Timespan"" column indicates when the reviews were posted or the period during which the reviewers visited these destinations. Finally, the ""Review"" column contains the textual feedback or opinions shared by travelers regarding their experiences at these various locations. This dataset could be invaluable for understanding the popularity, appeal, and overall perception of different travel destinations across Sri Lanka, providing insights for tourism management, marketing strategies, and further analysis.",.csv,True
Trending YouTube Video Statistics,10,youtube-new,MXvideos.csv,CC0-1.0,"UPDATE: Source code used for collecting this data [released here](https://github.com/DataSnaek/Trending-YouTube-Scraper)

### Context

YouTube (the world-famous video sharing website) maintains a list of the [top trending videos](https://www.youtube.com/feed/trending) on the platform. [According to Variety magazine](http://variety.com/2017/digital/news/youtube-2017-top-trending-videos-music-videos-1202631416/), “To determine the year’s top-trending videos, YouTube uses a combination of factors including measuring users interactions (number of views, shares, comments and likes). Note that they’re not the most-viewed videos overall for the calendar year”. Top performers on the YouTube trending list are music videos (such as the famously virile “Gangam Style”), celebrity and/or reality TV performances, and the random dude-with-a-camera viral videos that YouTube is well-known for.

This dataset is a daily record of the top trending YouTube videos.

Note that this dataset is a structurally improved version of [this dataset](https://www.kaggle.com/datasnaek/youtube).

### Content

This dataset includes several months (and counting) of data on daily trending YouTube videos. Data is included for the US, GB, DE, CA, and FR regions (USA, Great Britain, Germany, Canada, and France, respectively), with up to 200 listed trending videos per day.

EDIT: Now includes data from RU, MX, KR, JP and IN regions (Russia, Mexico, South Korea, Japan and India respectively) over the same time period.  

Each region’s data is in a separate file. Data includes the video title, channel title, publish time, tags, views, likes and dislikes, description, and comment count.

The data also includes a `category_id` field, which varies between regions. To retrieve the categories for a specific video, find it in the associated `JSON`. One such file is included for each of the five regions in the dataset.

For more information on specific columns in the dataset refer to the [column metadata](https://www.kaggle.com/datasnaek/youtube-new/data).

### Acknowledgements

This dataset was collected using the YouTube API.

### Inspiration

Possible uses for this dataset could include:

* Sentiment analysis in a variety of forms
* Categorising YouTube videos based on their comments and statistics.
* Training ML algorithms like RNNs to generate their own YouTube comments.
* Analysing what factors affect how popular a YouTube video will be.
* Statistical analysis over time.

For further inspiration, see the kernels on this dataset!",.csv,True
Trending YouTube Video Statistics,10,youtube-new,INvideos.csv,CC0-1.0,"UPDATE: Source code used for collecting this data [released here](https://github.com/DataSnaek/Trending-YouTube-Scraper)

### Context

YouTube (the world-famous video sharing website) maintains a list of the [top trending videos](https://www.youtube.com/feed/trending) on the platform. [According to Variety magazine](http://variety.com/2017/digital/news/youtube-2017-top-trending-videos-music-videos-1202631416/), “To determine the year’s top-trending videos, YouTube uses a combination of factors including measuring users interactions (number of views, shares, comments and likes). Note that they’re not the most-viewed videos overall for the calendar year”. Top performers on the YouTube trending list are music videos (such as the famously virile “Gangam Style”), celebrity and/or reality TV performances, and the random dude-with-a-camera viral videos that YouTube is well-known for.

This dataset is a daily record of the top trending YouTube videos.

Note that this dataset is a structurally improved version of [this dataset](https://www.kaggle.com/datasnaek/youtube).

### Content

This dataset includes several months (and counting) of data on daily trending YouTube videos. Data is included for the US, GB, DE, CA, and FR regions (USA, Great Britain, Germany, Canada, and France, respectively), with up to 200 listed trending videos per day.

EDIT: Now includes data from RU, MX, KR, JP and IN regions (Russia, Mexico, South Korea, Japan and India respectively) over the same time period.  

Each region’s data is in a separate file. Data includes the video title, channel title, publish time, tags, views, likes and dislikes, description, and comment count.

The data also includes a `category_id` field, which varies between regions. To retrieve the categories for a specific video, find it in the associated `JSON`. One such file is included for each of the five regions in the dataset.

For more information on specific columns in the dataset refer to the [column metadata](https://www.kaggle.com/datasnaek/youtube-new/data).

### Acknowledgements

This dataset was collected using the YouTube API.

### Inspiration

Possible uses for this dataset could include:

* Sentiment analysis in a variety of forms
* Categorising YouTube videos based on their comments and statistics.
* Training ML algorithms like RNNs to generate their own YouTube comments.
* Analysing what factors affect how popular a YouTube video will be.
* Statistical analysis over time.

For further inspiration, see the kernels on this dataset!",.csv,True
Trending YouTube Video Statistics,10,youtube-new,DEvideos.csv,CC0-1.0,"UPDATE: Source code used for collecting this data [released here](https://github.com/DataSnaek/Trending-YouTube-Scraper)

### Context

YouTube (the world-famous video sharing website) maintains a list of the [top trending videos](https://www.youtube.com/feed/trending) on the platform. [According to Variety magazine](http://variety.com/2017/digital/news/youtube-2017-top-trending-videos-music-videos-1202631416/), “To determine the year’s top-trending videos, YouTube uses a combination of factors including measuring users interactions (number of views, shares, comments and likes). Note that they’re not the most-viewed videos overall for the calendar year”. Top performers on the YouTube trending list are music videos (such as the famously virile “Gangam Style”), celebrity and/or reality TV performances, and the random dude-with-a-camera viral videos that YouTube is well-known for.

This dataset is a daily record of the top trending YouTube videos.

Note that this dataset is a structurally improved version of [this dataset](https://www.kaggle.com/datasnaek/youtube).

### Content

This dataset includes several months (and counting) of data on daily trending YouTube videos. Data is included for the US, GB, DE, CA, and FR regions (USA, Great Britain, Germany, Canada, and France, respectively), with up to 200 listed trending videos per day.

EDIT: Now includes data from RU, MX, KR, JP and IN regions (Russia, Mexico, South Korea, Japan and India respectively) over the same time period.  

Each region’s data is in a separate file. Data includes the video title, channel title, publish time, tags, views, likes and dislikes, description, and comment count.

The data also includes a `category_id` field, which varies between regions. To retrieve the categories for a specific video, find it in the associated `JSON`. One such file is included for each of the five regions in the dataset.

For more information on specific columns in the dataset refer to the [column metadata](https://www.kaggle.com/datasnaek/youtube-new/data).

### Acknowledgements

This dataset was collected using the YouTube API.

### Inspiration

Possible uses for this dataset could include:

* Sentiment analysis in a variety of forms
* Categorising YouTube videos based on their comments and statistics.
* Training ML algorithms like RNNs to generate their own YouTube comments.
* Analysing what factors affect how popular a YouTube video will be.
* Statistical analysis over time.

For further inspiration, see the kernels on this dataset!",.csv,True
Trending YouTube Video Statistics,10,youtube-new,JPvideos.csv,CC0-1.0,"UPDATE: Source code used for collecting this data [released here](https://github.com/DataSnaek/Trending-YouTube-Scraper)

### Context

YouTube (the world-famous video sharing website) maintains a list of the [top trending videos](https://www.youtube.com/feed/trending) on the platform. [According to Variety magazine](http://variety.com/2017/digital/news/youtube-2017-top-trending-videos-music-videos-1202631416/), “To determine the year’s top-trending videos, YouTube uses a combination of factors including measuring users interactions (number of views, shares, comments and likes). Note that they’re not the most-viewed videos overall for the calendar year”. Top performers on the YouTube trending list are music videos (such as the famously virile “Gangam Style”), celebrity and/or reality TV performances, and the random dude-with-a-camera viral videos that YouTube is well-known for.

This dataset is a daily record of the top trending YouTube videos.

Note that this dataset is a structurally improved version of [this dataset](https://www.kaggle.com/datasnaek/youtube).

### Content

This dataset includes several months (and counting) of data on daily trending YouTube videos. Data is included for the US, GB, DE, CA, and FR regions (USA, Great Britain, Germany, Canada, and France, respectively), with up to 200 listed trending videos per day.

EDIT: Now includes data from RU, MX, KR, JP and IN regions (Russia, Mexico, South Korea, Japan and India respectively) over the same time period.  

Each region’s data is in a separate file. Data includes the video title, channel title, publish time, tags, views, likes and dislikes, description, and comment count.

The data also includes a `category_id` field, which varies between regions. To retrieve the categories for a specific video, find it in the associated `JSON`. One such file is included for each of the five regions in the dataset.

For more information on specific columns in the dataset refer to the [column metadata](https://www.kaggle.com/datasnaek/youtube-new/data).

### Acknowledgements

This dataset was collected using the YouTube API.

### Inspiration

Possible uses for this dataset could include:

* Sentiment analysis in a variety of forms
* Categorising YouTube videos based on their comments and statistics.
* Training ML algorithms like RNNs to generate their own YouTube comments.
* Analysing what factors affect how popular a YouTube video will be.
* Statistical analysis over time.

For further inspiration, see the kernels on this dataset!",.csv,True
Trending YouTube Video Statistics,10,youtube-new,KRvideos.csv,CC0-1.0,"UPDATE: Source code used for collecting this data [released here](https://github.com/DataSnaek/Trending-YouTube-Scraper)

### Context

YouTube (the world-famous video sharing website) maintains a list of the [top trending videos](https://www.youtube.com/feed/trending) on the platform. [According to Variety magazine](http://variety.com/2017/digital/news/youtube-2017-top-trending-videos-music-videos-1202631416/), “To determine the year’s top-trending videos, YouTube uses a combination of factors including measuring users interactions (number of views, shares, comments and likes). Note that they’re not the most-viewed videos overall for the calendar year”. Top performers on the YouTube trending list are music videos (such as the famously virile “Gangam Style”), celebrity and/or reality TV performances, and the random dude-with-a-camera viral videos that YouTube is well-known for.

This dataset is a daily record of the top trending YouTube videos.

Note that this dataset is a structurally improved version of [this dataset](https://www.kaggle.com/datasnaek/youtube).

### Content

This dataset includes several months (and counting) of data on daily trending YouTube videos. Data is included for the US, GB, DE, CA, and FR regions (USA, Great Britain, Germany, Canada, and France, respectively), with up to 200 listed trending videos per day.

EDIT: Now includes data from RU, MX, KR, JP and IN regions (Russia, Mexico, South Korea, Japan and India respectively) over the same time period.  

Each region’s data is in a separate file. Data includes the video title, channel title, publish time, tags, views, likes and dislikes, description, and comment count.

The data also includes a `category_id` field, which varies between regions. To retrieve the categories for a specific video, find it in the associated `JSON`. One such file is included for each of the five regions in the dataset.

For more information on specific columns in the dataset refer to the [column metadata](https://www.kaggle.com/datasnaek/youtube-new/data).

### Acknowledgements

This dataset was collected using the YouTube API.

### Inspiration

Possible uses for this dataset could include:

* Sentiment analysis in a variety of forms
* Categorising YouTube videos based on their comments and statistics.
* Training ML algorithms like RNNs to generate their own YouTube comments.
* Analysing what factors affect how popular a YouTube video will be.
* Statistical analysis over time.

For further inspiration, see the kernels on this dataset!",.csv,True
Trending YouTube Video Statistics,10,youtube-new,CAvideos.csv,CC0-1.0,"UPDATE: Source code used for collecting this data [released here](https://github.com/DataSnaek/Trending-YouTube-Scraper)

### Context

YouTube (the world-famous video sharing website) maintains a list of the [top trending videos](https://www.youtube.com/feed/trending) on the platform. [According to Variety magazine](http://variety.com/2017/digital/news/youtube-2017-top-trending-videos-music-videos-1202631416/), “To determine the year’s top-trending videos, YouTube uses a combination of factors including measuring users interactions (number of views, shares, comments and likes). Note that they’re not the most-viewed videos overall for the calendar year”. Top performers on the YouTube trending list are music videos (such as the famously virile “Gangam Style”), celebrity and/or reality TV performances, and the random dude-with-a-camera viral videos that YouTube is well-known for.

This dataset is a daily record of the top trending YouTube videos.

Note that this dataset is a structurally improved version of [this dataset](https://www.kaggle.com/datasnaek/youtube).

### Content

This dataset includes several months (and counting) of data on daily trending YouTube videos. Data is included for the US, GB, DE, CA, and FR regions (USA, Great Britain, Germany, Canada, and France, respectively), with up to 200 listed trending videos per day.

EDIT: Now includes data from RU, MX, KR, JP and IN regions (Russia, Mexico, South Korea, Japan and India respectively) over the same time period.  

Each region’s data is in a separate file. Data includes the video title, channel title, publish time, tags, views, likes and dislikes, description, and comment count.

The data also includes a `category_id` field, which varies between regions. To retrieve the categories for a specific video, find it in the associated `JSON`. One such file is included for each of the five regions in the dataset.

For more information on specific columns in the dataset refer to the [column metadata](https://www.kaggle.com/datasnaek/youtube-new/data).

### Acknowledgements

This dataset was collected using the YouTube API.

### Inspiration

Possible uses for this dataset could include:

* Sentiment analysis in a variety of forms
* Categorising YouTube videos based on their comments and statistics.
* Training ML algorithms like RNNs to generate their own YouTube comments.
* Analysing what factors affect how popular a YouTube video will be.
* Statistical analysis over time.

For further inspiration, see the kernels on this dataset!",.csv,True
Trending YouTube Video Statistics,10,youtube-new,RUvideos.csv,CC0-1.0,"UPDATE: Source code used for collecting this data [released here](https://github.com/DataSnaek/Trending-YouTube-Scraper)

### Context

YouTube (the world-famous video sharing website) maintains a list of the [top trending videos](https://www.youtube.com/feed/trending) on the platform. [According to Variety magazine](http://variety.com/2017/digital/news/youtube-2017-top-trending-videos-music-videos-1202631416/), “To determine the year’s top-trending videos, YouTube uses a combination of factors including measuring users interactions (number of views, shares, comments and likes). Note that they’re not the most-viewed videos overall for the calendar year”. Top performers on the YouTube trending list are music videos (such as the famously virile “Gangam Style”), celebrity and/or reality TV performances, and the random dude-with-a-camera viral videos that YouTube is well-known for.

This dataset is a daily record of the top trending YouTube videos.

Note that this dataset is a structurally improved version of [this dataset](https://www.kaggle.com/datasnaek/youtube).

### Content

This dataset includes several months (and counting) of data on daily trending YouTube videos. Data is included for the US, GB, DE, CA, and FR regions (USA, Great Britain, Germany, Canada, and France, respectively), with up to 200 listed trending videos per day.

EDIT: Now includes data from RU, MX, KR, JP and IN regions (Russia, Mexico, South Korea, Japan and India respectively) over the same time period.  

Each region’s data is in a separate file. Data includes the video title, channel title, publish time, tags, views, likes and dislikes, description, and comment count.

The data also includes a `category_id` field, which varies between regions. To retrieve the categories for a specific video, find it in the associated `JSON`. One such file is included for each of the five regions in the dataset.

For more information on specific columns in the dataset refer to the [column metadata](https://www.kaggle.com/datasnaek/youtube-new/data).

### Acknowledgements

This dataset was collected using the YouTube API.

### Inspiration

Possible uses for this dataset could include:

* Sentiment analysis in a variety of forms
* Categorising YouTube videos based on their comments and statistics.
* Training ML algorithms like RNNs to generate their own YouTube comments.
* Analysing what factors affect how popular a YouTube video will be.
* Statistical analysis over time.

For further inspiration, see the kernels on this dataset!",.csv,True
Trending YouTube Video Statistics,10,youtube-new,FRvideos.csv,CC0-1.0,"UPDATE: Source code used for collecting this data [released here](https://github.com/DataSnaek/Trending-YouTube-Scraper)

### Context

YouTube (the world-famous video sharing website) maintains a list of the [top trending videos](https://www.youtube.com/feed/trending) on the platform. [According to Variety magazine](http://variety.com/2017/digital/news/youtube-2017-top-trending-videos-music-videos-1202631416/), “To determine the year’s top-trending videos, YouTube uses a combination of factors including measuring users interactions (number of views, shares, comments and likes). Note that they’re not the most-viewed videos overall for the calendar year”. Top performers on the YouTube trending list are music videos (such as the famously virile “Gangam Style”), celebrity and/or reality TV performances, and the random dude-with-a-camera viral videos that YouTube is well-known for.

This dataset is a daily record of the top trending YouTube videos.

Note that this dataset is a structurally improved version of [this dataset](https://www.kaggle.com/datasnaek/youtube).

### Content

This dataset includes several months (and counting) of data on daily trending YouTube videos. Data is included for the US, GB, DE, CA, and FR regions (USA, Great Britain, Germany, Canada, and France, respectively), with up to 200 listed trending videos per day.

EDIT: Now includes data from RU, MX, KR, JP and IN regions (Russia, Mexico, South Korea, Japan and India respectively) over the same time period.  

Each region’s data is in a separate file. Data includes the video title, channel title, publish time, tags, views, likes and dislikes, description, and comment count.

The data also includes a `category_id` field, which varies between regions. To retrieve the categories for a specific video, find it in the associated `JSON`. One such file is included for each of the five regions in the dataset.

For more information on specific columns in the dataset refer to the [column metadata](https://www.kaggle.com/datasnaek/youtube-new/data).

### Acknowledgements

This dataset was collected using the YouTube API.

### Inspiration

Possible uses for this dataset could include:

* Sentiment analysis in a variety of forms
* Categorising YouTube videos based on their comments and statistics.
* Training ML algorithms like RNNs to generate their own YouTube comments.
* Analysing what factors affect how popular a YouTube video will be.
* Statistical analysis over time.

For further inspiration, see the kernels on this dataset!",.csv,True
Trending YouTube Video Statistics,10,youtube-new,USvideos.csv,CC0-1.0,"UPDATE: Source code used for collecting this data [released here](https://github.com/DataSnaek/Trending-YouTube-Scraper)

### Context

YouTube (the world-famous video sharing website) maintains a list of the [top trending videos](https://www.youtube.com/feed/trending) on the platform. [According to Variety magazine](http://variety.com/2017/digital/news/youtube-2017-top-trending-videos-music-videos-1202631416/), “To determine the year’s top-trending videos, YouTube uses a combination of factors including measuring users interactions (number of views, shares, comments and likes). Note that they’re not the most-viewed videos overall for the calendar year”. Top performers on the YouTube trending list are music videos (such as the famously virile “Gangam Style”), celebrity and/or reality TV performances, and the random dude-with-a-camera viral videos that YouTube is well-known for.

This dataset is a daily record of the top trending YouTube videos.

Note that this dataset is a structurally improved version of [this dataset](https://www.kaggle.com/datasnaek/youtube).

### Content

This dataset includes several months (and counting) of data on daily trending YouTube videos. Data is included for the US, GB, DE, CA, and FR regions (USA, Great Britain, Germany, Canada, and France, respectively), with up to 200 listed trending videos per day.

EDIT: Now includes data from RU, MX, KR, JP and IN regions (Russia, Mexico, South Korea, Japan and India respectively) over the same time period.  

Each region’s data is in a separate file. Data includes the video title, channel title, publish time, tags, views, likes and dislikes, description, and comment count.

The data also includes a `category_id` field, which varies between regions. To retrieve the categories for a specific video, find it in the associated `JSON`. One such file is included for each of the five regions in the dataset.

For more information on specific columns in the dataset refer to the [column metadata](https://www.kaggle.com/datasnaek/youtube-new/data).

### Acknowledgements

This dataset was collected using the YouTube API.

### Inspiration

Possible uses for this dataset could include:

* Sentiment analysis in a variety of forms
* Categorising YouTube videos based on their comments and statistics.
* Training ML algorithms like RNNs to generate their own YouTube comments.
* Analysing what factors affect how popular a YouTube video will be.
* Statistical analysis over time.

For further inspiration, see the kernels on this dataset!",.csv,True
Trending YouTube Video Statistics,10,youtube-new,GBvideos.csv,CC0-1.0,"UPDATE: Source code used for collecting this data [released here](https://github.com/DataSnaek/Trending-YouTube-Scraper)

### Context

YouTube (the world-famous video sharing website) maintains a list of the [top trending videos](https://www.youtube.com/feed/trending) on the platform. [According to Variety magazine](http://variety.com/2017/digital/news/youtube-2017-top-trending-videos-music-videos-1202631416/), “To determine the year’s top-trending videos, YouTube uses a combination of factors including measuring users interactions (number of views, shares, comments and likes). Note that they’re not the most-viewed videos overall for the calendar year”. Top performers on the YouTube trending list are music videos (such as the famously virile “Gangam Style”), celebrity and/or reality TV performances, and the random dude-with-a-camera viral videos that YouTube is well-known for.

This dataset is a daily record of the top trending YouTube videos.

Note that this dataset is a structurally improved version of [this dataset](https://www.kaggle.com/datasnaek/youtube).

### Content

This dataset includes several months (and counting) of data on daily trending YouTube videos. Data is included for the US, GB, DE, CA, and FR regions (USA, Great Britain, Germany, Canada, and France, respectively), with up to 200 listed trending videos per day.

EDIT: Now includes data from RU, MX, KR, JP and IN regions (Russia, Mexico, South Korea, Japan and India respectively) over the same time period.  

Each region’s data is in a separate file. Data includes the video title, channel title, publish time, tags, views, likes and dislikes, description, and comment count.

The data also includes a `category_id` field, which varies between regions. To retrieve the categories for a specific video, find it in the associated `JSON`. One such file is included for each of the five regions in the dataset.

For more information on specific columns in the dataset refer to the [column metadata](https://www.kaggle.com/datasnaek/youtube-new/data).

### Acknowledgements

This dataset was collected using the YouTube API.

### Inspiration

Possible uses for this dataset could include:

* Sentiment analysis in a variety of forms
* Categorising YouTube videos based on their comments and statistics.
* Training ML algorithms like RNNs to generate their own YouTube comments.
* Analysing what factors affect how popular a YouTube video will be.
* Statistical analysis over time.

For further inspiration, see the kernels on this dataset!",.csv,True
Tweets with Sarcasm and Irony,2,tweets-with-sarcasm-and-irony,test.csv,CC0-1.0,"### Context

I replicated and created a dataset of tweets classified into one of the 4 classes: Regular, Sarcasm, Figurative and Irony

### Content

The dataset consists of 2 files, `train.csv` and `test.csv`.

Both these files contain 2 columns:
- `tweet`: The text of the tweet
- `class`: The respective class to which the tweet belongs. There are 4 classes -:
    - Irony
    - Sarcasm
    - Regular
    - Figurative (both irony and sarcasm)


### Reference

- Jennifer Ling, Roman Klinger: “An Empirical, Quantitative Analysis of the Differences between Sarcasm and Irony”. Semantic Sentiment and Emotion Workshop, ESWC, Crete. Greece. 2016",.csv,True
Tweets with Sarcasm and Irony,2,tweets-with-sarcasm-and-irony,train.csv,CC0-1.0,"### Context

I replicated and created a dataset of tweets classified into one of the 4 classes: Regular, Sarcasm, Figurative and Irony

### Content

The dataset consists of 2 files, `train.csv` and `test.csv`.

Both these files contain 2 columns:
- `tweet`: The text of the tweet
- `class`: The respective class to which the tweet belongs. There are 4 classes -:
    - Irony
    - Sarcasm
    - Regular
    - Figurative (both irony and sarcasm)


### Reference

- Jennifer Ling, Roman Klinger: “An Empirical, Quantitative Analysis of the Differences between Sarcasm and Irony”. Semantic Sentiment and Emotion Workshop, ESWC, Crete. Greece. 2016",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_nm_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_nj_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_mt_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_ms_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_sd_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_va_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_oh_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_sc_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_az_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_ca_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_il_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_hi_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_ga_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_vt_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_ma_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_wv_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_ia_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_ct_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_wi_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_ny_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_tn_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_ut_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_co_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_ky_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_me_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_al_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_nc_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_nd_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_ak_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_md_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_fl_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_la_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_id_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_ar_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_ne_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_ri_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_nh_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_de_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_wa_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_tx_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_in_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_wy_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_mi_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_mn_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_or_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_ok_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_dc_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_mo_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_pa_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_ks_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
USGS Streamgages (All 50 States),51,usgs-streamgages-all-50-states,usgs_streamgages_nv_20240516.csv,CC0-1.0,"The United States Geological Survey (USGS) has over 10,000 streamgages, which measure the flow and height of waterways around the country.

There are 51 CSVs, one for each state and Washington, D.C., which have the following data columns for each streamgage:
- `agency` -  the agency that owns the streamgage (almost always USGS)
- `location_id` - the unique ID for the streamgage
- `name` - the name of the streamgage (e.g. ""COLORADO RIVER BELOW GLEN CANYON DAM, AZ"")
- `latitude` - the latitude in degrees, minutes, seconds format (dd°mm'ss"")
- `longitude` - the longitude  in degrees, minutes, seconds format (dd°mm'ss"")
- `lat_long_type` - the coordinate system for latitude/longitude (e.g. NAD 27, NAD 83, etc.)
- `county` - the county that the streamgage is in
- `hydrologic_unit` - the ID of area of land, the ""[hydrologic unit](https://nas.er.usgs.gov/hucs.aspx),"" that drains into the waterway
- `drainage_area` - the parea of land where precipitation drains into the waterway](https://waterdata.usgs.gov/wa/nwis/current?type=basinda) measured by the streamgage
- `datum_of_gage` - the elevation ([kind of](https://waterdata.usgs.gov/wa/nwis/current/?type=datum)) of the streamgage, which the stream's gage height is measured against
- `datum_type` - the standard that was used to calculate the datum (e.g. NGVD29 or NAVD88).

## License and Copyright
All data is in the US Public Domain thanks to the USGS. However, they request that you [adhere to these guidelines](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits) and give credit to them wherever is feasible.

## Related Data
* [USGS Streamgages by the Numbers](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgages-numbers)
* [USGS Streamgaging Network](https://www.usgs.gov/mission-areas/water-resources/science/usgs-streamgaging-network)
* [National Water Dashboard](https://dashboard.waterdata.usgs.gov/)",.csv,True
UjiIndoorLoc: An indoor localization dataset,2,UjiIndoorLoc,ValidationData.csv,CC-BY-SA-4.0,"# Context 

This data set is focused on WLAN fingerprint positioning technologies and methodologies (also know as WiFi Fingerprinting). It was the official database used in the IPIN2015 competition. 

Many real world applications need to know the localization of a user in the world to provide their services. Therefore, automatic user localization has been a hot research topic in the last years. Automatic user localization consists of estimating the position of the user (latitude, longitude and altitude) by using an electronic device, usually a mobile phone. Outdoor localization problem can be solved very accurately thanks to the inclusion of GPS sensors into the mobile devices. However, indoor localization is still an open problem mainly due to the loss of GPS signal in indoor environments. Although, there are some indoor positioning technologies and methodologies, this database is focused on WLAN fingerprint-based ones (also know as WiFi Fingerprinting).

Although there are many papers in the literature trying to solve the indoor localization problem using a WLAN fingerprint-based method, there still exists one important drawback in this field which is the lack of a common database for comparison purposes. So, UJIIndoorLoc database is presented to overcome this gap. 

The UJIIndoorLoc database covers three buildings of Universitat Jaume I ([http://www.uji.es][1]) with 4 or more floors and almost 110.000m2. It can be used for classification, e.g. actual building and floor identification, or regression, e.g. actual longitude and latitude estimation. It was created in 2013 by means of more than 20 different users and 25 Android devices. The database consists of 19937 training/reference records (trainingData.csv file) and 1111 validation/test records (validationData.csv file)

The 529 attributes contain the WiFi fingerprint, the coordinates where it was taken, and other useful information.

Each WiFi fingerprint can be characterized by the detected Wireless Access Points (WAPs) and the corresponding Received Signal Strength Intensity (RSSI). The intensity values are represented as negative integer values ranging -104dBm (extremely poor signal) to 0dbM. The positive value 100 is used to denote when a WAP was not detected. During the database creation, 520 different WAPs were detected. Thus, the WiFi fingerprint is composed by 520 intensity values.

Then the coordinates (latitude, longitude, floor) and Building ID are provided as the attributes to be predicted.

The particular space (offices, labs, etc.) and the relative position (inside/outside the space) where the capture was taken have been recorded. Outside means that the capture was taken in front of the door of the space.

Information about who (user), how (android device & version) and when (timestamp) WiFi capture was taken is also recorded. 

# Content

 - Attributes 001 to 520 (WAP001-WAP520): Intensity value for WAP001.
   Negative integer values from -104 to 0 and +100. Positive value 100
   used if WAP001 was not detected.
   
 - Attribute 521 (Longitude): Longitude. Negative real values from
   -7695.9387549299299000 to -7299.786516730871000
   
 - Attribute 522 (Latitude): Latitude. Positive real values from
   4864745.7450159714 to 4865017.3646842018.
   
 - Attribute 523 (Floor): Altitude in floors inside the building.
   Integer values from 0 to 4. 
 
 - Attribute 524 (BuildingID): ID to identify the building. Measures
   were taken in three different buildings. Categorical integer values
   from 0 to 2.
   
 - Attribute 525 (SpaceID): Internal ID number to identify the Space (office, corridor, classroom) where the capture was taken.  Categorical integer values.
   
 - Attribute 526 (RelativePosition): Relative position with respect to the Space (1 - Inside, 2 - Outside in Front of the door). Categorical integer values.
   
 - Attribute 527 (UserID): User identifier (see below). Categorical integer values.
   
 - Attribute 528 (PhoneID): Android device identifier (see below). Categorical integer values.

 - Attribute 529 (Timestamp): UNIX Time when the capture was taken.  Integer value.

# Relevent Paper

More information can be found in this paper:

Joaquín Torres-Sospedra, Raúl Montoliu, Adolfo Martínez-Usó, Tomar J. Arnau, Joan P. Avariento, Mauri Benedito-Bordonau, Joaquín Huerta. UJIIndoorLoc: A New Multi-building and Multi-floor Database for WLAN Fingerprint-based Indoor Localization Problems. In Proceedings of the Fifth International Conference on Indoor Positioning and Indoor Navigation, 2014.

Available at: [http://www.ipin2014.org/wp/pdf/4A-3.pdf][2]

If your are going to use this dataset in your research, please cite this paper

# Acknowledgements

The dataset was created by: 

Joaquín Torres-Sospedra, Raul Montoliu, Adolfo Martínez-Usó, Tomar J. Arnau, Joan P. Avariento, Mauri Benedito-Bordonau, Joaquín Huerta, Yasmina Andreu, óscar Belmonte, Vicent Castelló, Irene Garcia-Martí, Diego Gargallo, Carlos Gonzalez, Nadal Francisco, Josep López, Ruben Martínez, Roberto Mediero, Javier Ortells, Nacho Piqueras, Ianisse Quizán, David Rambla, Luis E. Rodríguez, Eva Salvador Balaguer, Ana Sanchís, Carlos Serra, and Sergi Trilles.

# Inspiration

The objective is to estimate the building, floor and coordinates (latitude and longitude) of the 1111 samples included in the validation set. Since the real values of the building, floor and coordinates are also included, it is posible to determine the localization error.

The formula used in the IPIN2015 competition was the mean of the localization error of each sample. The localization error of each sample can be estimated as follows:

Error = building_penality * building_error + floor_penality * floor_error + coordinates_error

where:

 - building_error is 1 if the estimated building is not equal to the
   real one. 0 otherwise 
 - floor_error is 1 if the estimated floor is not
   equal to the real one. 0 otherwise 
 - coordinates_error is sqrt(   (estimated_latitude - real_latitude)^2 +  (estimated_longitude-real_longitude)^2)

In the IPIN2015 competition building_penalty and floor_penalty where set to 50 and 4 meters, respectively.


  [1]: http://www.uji.es
  [2]: http://www.ipin2014.org/wp/pdf/4A-3.pdf",.csv,True
UjiIndoorLoc: An indoor localization dataset,2,UjiIndoorLoc,TrainingData.csv,CC-BY-SA-4.0,"# Context 

This data set is focused on WLAN fingerprint positioning technologies and methodologies (also know as WiFi Fingerprinting). It was the official database used in the IPIN2015 competition. 

Many real world applications need to know the localization of a user in the world to provide their services. Therefore, automatic user localization has been a hot research topic in the last years. Automatic user localization consists of estimating the position of the user (latitude, longitude and altitude) by using an electronic device, usually a mobile phone. Outdoor localization problem can be solved very accurately thanks to the inclusion of GPS sensors into the mobile devices. However, indoor localization is still an open problem mainly due to the loss of GPS signal in indoor environments. Although, there are some indoor positioning technologies and methodologies, this database is focused on WLAN fingerprint-based ones (also know as WiFi Fingerprinting).

Although there are many papers in the literature trying to solve the indoor localization problem using a WLAN fingerprint-based method, there still exists one important drawback in this field which is the lack of a common database for comparison purposes. So, UJIIndoorLoc database is presented to overcome this gap. 

The UJIIndoorLoc database covers three buildings of Universitat Jaume I ([http://www.uji.es][1]) with 4 or more floors and almost 110.000m2. It can be used for classification, e.g. actual building and floor identification, or regression, e.g. actual longitude and latitude estimation. It was created in 2013 by means of more than 20 different users and 25 Android devices. The database consists of 19937 training/reference records (trainingData.csv file) and 1111 validation/test records (validationData.csv file)

The 529 attributes contain the WiFi fingerprint, the coordinates where it was taken, and other useful information.

Each WiFi fingerprint can be characterized by the detected Wireless Access Points (WAPs) and the corresponding Received Signal Strength Intensity (RSSI). The intensity values are represented as negative integer values ranging -104dBm (extremely poor signal) to 0dbM. The positive value 100 is used to denote when a WAP was not detected. During the database creation, 520 different WAPs were detected. Thus, the WiFi fingerprint is composed by 520 intensity values.

Then the coordinates (latitude, longitude, floor) and Building ID are provided as the attributes to be predicted.

The particular space (offices, labs, etc.) and the relative position (inside/outside the space) where the capture was taken have been recorded. Outside means that the capture was taken in front of the door of the space.

Information about who (user), how (android device & version) and when (timestamp) WiFi capture was taken is also recorded. 

# Content

 - Attributes 001 to 520 (WAP001-WAP520): Intensity value for WAP001.
   Negative integer values from -104 to 0 and +100. Positive value 100
   used if WAP001 was not detected.
   
 - Attribute 521 (Longitude): Longitude. Negative real values from
   -7695.9387549299299000 to -7299.786516730871000
   
 - Attribute 522 (Latitude): Latitude. Positive real values from
   4864745.7450159714 to 4865017.3646842018.
   
 - Attribute 523 (Floor): Altitude in floors inside the building.
   Integer values from 0 to 4. 
 
 - Attribute 524 (BuildingID): ID to identify the building. Measures
   were taken in three different buildings. Categorical integer values
   from 0 to 2.
   
 - Attribute 525 (SpaceID): Internal ID number to identify the Space (office, corridor, classroom) where the capture was taken.  Categorical integer values.
   
 - Attribute 526 (RelativePosition): Relative position with respect to the Space (1 - Inside, 2 - Outside in Front of the door). Categorical integer values.
   
 - Attribute 527 (UserID): User identifier (see below). Categorical integer values.
   
 - Attribute 528 (PhoneID): Android device identifier (see below). Categorical integer values.

 - Attribute 529 (Timestamp): UNIX Time when the capture was taken.  Integer value.

# Relevent Paper

More information can be found in this paper:

Joaquín Torres-Sospedra, Raúl Montoliu, Adolfo Martínez-Usó, Tomar J. Arnau, Joan P. Avariento, Mauri Benedito-Bordonau, Joaquín Huerta. UJIIndoorLoc: A New Multi-building and Multi-floor Database for WLAN Fingerprint-based Indoor Localization Problems. In Proceedings of the Fifth International Conference on Indoor Positioning and Indoor Navigation, 2014.

Available at: [http://www.ipin2014.org/wp/pdf/4A-3.pdf][2]

If your are going to use this dataset in your research, please cite this paper

# Acknowledgements

The dataset was created by: 

Joaquín Torres-Sospedra, Raul Montoliu, Adolfo Martínez-Usó, Tomar J. Arnau, Joan P. Avariento, Mauri Benedito-Bordonau, Joaquín Huerta, Yasmina Andreu, óscar Belmonte, Vicent Castelló, Irene Garcia-Martí, Diego Gargallo, Carlos Gonzalez, Nadal Francisco, Josep López, Ruben Martínez, Roberto Mediero, Javier Ortells, Nacho Piqueras, Ianisse Quizán, David Rambla, Luis E. Rodríguez, Eva Salvador Balaguer, Ana Sanchís, Carlos Serra, and Sergi Trilles.

# Inspiration

The objective is to estimate the building, floor and coordinates (latitude and longitude) of the 1111 samples included in the validation set. Since the real values of the building, floor and coordinates are also included, it is posible to determine the localization error.

The formula used in the IPIN2015 competition was the mean of the localization error of each sample. The localization error of each sample can be estimated as follows:

Error = building_penality * building_error + floor_penality * floor_error + coordinates_error

where:

 - building_error is 1 if the estimated building is not equal to the
   real one. 0 otherwise 
 - floor_error is 1 if the estimated floor is not
   equal to the real one. 0 otherwise 
 - coordinates_error is sqrt(   (estimated_latitude - real_latitude)^2 +  (estimated_longitude-real_longitude)^2)

In the IPIN2015 competition building_penalty and floor_penalty where set to 50 and 4 meters, respectively.


  [1]: http://www.uji.es
  [2]: http://www.ipin2014.org/wp/pdf/4A-3.pdf",.csv,True
Uniqlo (FastRetailing) Stock Price Prediction,2,uniqlo-fastretailing-stock-price-prediction,Uniqlo(FastRetailing) 2012-2016 Training - stocks2012-2016.csv,CC0-1.0,"### Context

We are doing Fintech data hakathon in Tokyo everyweek. Let's predict stock price in Tokyo Stock Exchange.

毎週水曜日東京・渋谷で開催している、Team AI ""FinTech Data Hackathon""の題材として、
身近なユニクロ(ファーストリテイリング)の株価予測モデルをオープンイノベーションで構築します。
https://www.meetup.com/Machine-Learning-Meetup-by-team-ai/events/242154425/

### Content

Training; 5 year daily stock price info of FastRetailing(Uniqlo). You should predict ""close"" price.
Test: 1 week daily stock price

### Acknowledgements

Thanks to open market data http://k-db.com/


### Inspiration

Let's build basic stock prediction model together!
 公開されたモデルを実際の取引に使う場合は十分注意ください。弊社側やコミュニティメンバー側では損失の責任は持てません。",.csv,True
Uniqlo (FastRetailing) Stock Price Prediction,2,uniqlo-fastretailing-stock-price-prediction,Uniqlo(FastRetailing) 2017 Test - stocks2017.csv,CC0-1.0,"### Context

We are doing Fintech data hakathon in Tokyo everyweek. Let's predict stock price in Tokyo Stock Exchange.

毎週水曜日東京・渋谷で開催している、Team AI ""FinTech Data Hackathon""の題材として、
身近なユニクロ(ファーストリテイリング)の株価予測モデルをオープンイノベーションで構築します。
https://www.meetup.com/Machine-Learning-Meetup-by-team-ai/events/242154425/

### Content

Training; 5 year daily stock price info of FastRetailing(Uniqlo). You should predict ""close"" price.
Test: 1 week daily stock price

### Acknowledgements

Thanks to open market data http://k-db.com/


### Inspiration

Let's build basic stock prediction model together!
 公開されたモデルを実際の取引に使う場合は十分注意ください。弊社側やコミュニティメンバー側では損失の責任は持てません。",.csv,True
Vector Borne Disease Prediction ,2,vector-borne-disease-prediction,testt.csv,CC0-1.0,"Use Trainn.csv for training desired ML Model.
All symptoms and Prognosis included associated with 11 Vector Borne Diseases.
Chikungunya
Dengue
Zika
Yellow Fever
Raft Valley Fever
West Nile Fever
Malaria
Tungiasis
Japanese Encephalitis
Plague
Lyme Disease",.csv,True
Vector Borne Disease Prediction ,2,vector-borne-disease-prediction,trainn.csv,CC0-1.0,"Use Trainn.csv for training desired ML Model.
All symptoms and Prognosis included associated with 11 Vector Borne Diseases.
Chikungunya
Dengue
Zika
Yellow Fever
Raft Valley Fever
West Nile Fever
Malaria
Tungiasis
Japanese Encephalitis
Plague
Lyme Disease",.csv,True
VertebralColumnDataSet,2,vertebralcolumndataset,column_2C.csv,other,"### Vertebral Column Data Set
Download: Data Folder-http://archive.ics.uci.edu/ml/machine-learning-databases/00212/

Data Set Description, http://archive.ics.uci.edu/ml/machine-learning-databases/00212/

**Abstract**: Data set containing values for six biomechanical features used to classify orthopaedic patients into 3 classes (``normal``, ``disk hernia `` or ``spondilolysthesis``) or 2 classes (``normal`` or ``abnormal``).


- Data Set Characteristics: Multivariate
- Attribute Characteristics: Real
- Associated Tasks: Classification
- Number of Instances: 310
- Number of Attributes: 6
- Missing Values? N/A
- Area: N/A
- Date Donated: 2011-08-09

### **Source**:

Guilherme de Alencar Barreto (guilherme '@' deti.ufc.br) & Ajalmar RÃªgo da Rocha Neto (ajalmar '@' ifce.edu.br), Department of Teleinformatics Engineering, Federal University of CearÃ¡, Fortaleza, Ceará¡, Brazil.

Henrique Antonio Fonseca da Mota Filho (hdamota '@' gmail.com), Hospital Monte Klinikum, Fortaleza, Ceará¡, Brazil.

### **Data Set Information**:

Biomedical data set built by Dr. Henrique da Mota during a medical residence period in the Group of Applied Research in Orthopaedics (GARO) of the Centre MÃ©dico-Chirurgical de RÃ©adaptation des Massues, Lyon, France. The data have been organized in two different but related classification tasks. The first task consists in classifying patients as belonging to one out of three categories: Normal (100 patients), Disk Hernia (60 patients) or Spondylolisthesis (150 patients). For the second task, the categories Disk Hernia and Spondylolisthesis were merged into a single category labelled as 'abnormal'. Thus, the second task consists in classifying patients as belonging to one out of two categories: Normal (100 patients) or Abnormal (210 patients). We provide files also for use within the WEKA environment.

### **Attribute Information**:

Each patient is represented in the data set by six biomechanical attributes derived from the shape and orientation of the pelvis and lumbar spine (in this order): pelvic incidence, pelvic tilt, lumbar lordosis angle, sacral slope, pelvic radius and grade of spondylolisthesis. The following convention is used for the class labels: DH (Disk Hernia), Spondylolisthesis (SL), Normal (NO) and Abnormal (AB).

### Relevant Papers:

(1) Berthonnaud, E., Dimnet, J., Roussouly, P. & Labelle, H. (2005). 'Analysis of the sagittal balance of the spine and pelvis using shape and orientation parameters', Journal of Spinal Disorders & Techniques, 18(1):40â€“47.

(2) Rocha Neto, A. R. & Barreto, G. A. (2009). 'On the Application of Ensembles of Classifiers to the Diagnosis of Pathologies of the Vertebral Column: A Comparative Analysis', IEEE Latin America Transactions, 7(4):487-496.

(3) Rocha Neto, A. R., Sousa, R., Barreto, G. A. & Cardoso, J. S. (2011). 'Diagnostic of Pathology on the Vertebral Column with Embedded Reject Optionâ€, Proceedings of the 5th Iberian Conference on Pattern Recognition and Image Analysis (IbPRIA'2011), Gran Canaria, Spain, Lecture Notes on Computer Science, vol. 6669, p. 588-595.


",.csv,True
VertebralColumnDataSet,2,vertebralcolumndataset,column_3C.csv,other,"### Vertebral Column Data Set
Download: Data Folder-http://archive.ics.uci.edu/ml/machine-learning-databases/00212/

Data Set Description, http://archive.ics.uci.edu/ml/machine-learning-databases/00212/

**Abstract**: Data set containing values for six biomechanical features used to classify orthopaedic patients into 3 classes (``normal``, ``disk hernia `` or ``spondilolysthesis``) or 2 classes (``normal`` or ``abnormal``).


- Data Set Characteristics: Multivariate
- Attribute Characteristics: Real
- Associated Tasks: Classification
- Number of Instances: 310
- Number of Attributes: 6
- Missing Values? N/A
- Area: N/A
- Date Donated: 2011-08-09

### **Source**:

Guilherme de Alencar Barreto (guilherme '@' deti.ufc.br) & Ajalmar RÃªgo da Rocha Neto (ajalmar '@' ifce.edu.br), Department of Teleinformatics Engineering, Federal University of CearÃ¡, Fortaleza, Ceará¡, Brazil.

Henrique Antonio Fonseca da Mota Filho (hdamota '@' gmail.com), Hospital Monte Klinikum, Fortaleza, Ceará¡, Brazil.

### **Data Set Information**:

Biomedical data set built by Dr. Henrique da Mota during a medical residence period in the Group of Applied Research in Orthopaedics (GARO) of the Centre MÃ©dico-Chirurgical de RÃ©adaptation des Massues, Lyon, France. The data have been organized in two different but related classification tasks. The first task consists in classifying patients as belonging to one out of three categories: Normal (100 patients), Disk Hernia (60 patients) or Spondylolisthesis (150 patients). For the second task, the categories Disk Hernia and Spondylolisthesis were merged into a single category labelled as 'abnormal'. Thus, the second task consists in classifying patients as belonging to one out of two categories: Normal (100 patients) or Abnormal (210 patients). We provide files also for use within the WEKA environment.

### **Attribute Information**:

Each patient is represented in the data set by six biomechanical attributes derived from the shape and orientation of the pelvis and lumbar spine (in this order): pelvic incidence, pelvic tilt, lumbar lordosis angle, sacral slope, pelvic radius and grade of spondylolisthesis. The following convention is used for the class labels: DH (Disk Hernia), Spondylolisthesis (SL), Normal (NO) and Abnormal (AB).

### Relevant Papers:

(1) Berthonnaud, E., Dimnet, J., Roussouly, P. & Labelle, H. (2005). 'Analysis of the sagittal balance of the spine and pelvis using shape and orientation parameters', Journal of Spinal Disorders & Techniques, 18(1):40â€“47.

(2) Rocha Neto, A. R. & Barreto, G. A. (2009). 'On the Application of Ensembles of Classifiers to the Diagnosis of Pathologies of the Vertebral Column: A Comparative Analysis', IEEE Latin America Transactions, 7(4):487-496.

(3) Rocha Neto, A. R., Sousa, R., Barreto, G. A. & Cardoso, J. S. (2011). 'Diagnostic of Pathology on the Vertebral Column with Embedded Reject Optionâ€, Proceedings of the 5th Iberian Conference on Pattern Recognition and Image Analysis (IbPRIA'2011), Gran Canaria, Spain, Lecture Notes on Computer Science, vol. 6669, p. 588-595.


",.csv,True
Video Games Rating By 'ESRB',2,video-games-rating-by-esrb,test_esrb.csv,CC0-1.0,"- This data contains the name for `1895 games` with `34 of ESRB rating content with the name and console` as features for each game.<br><br>
-  A single data point is represented as a binary value `0-1` for `Console` and a `binary vector` for the `features of ESRB content`.<br><br>
- **RP, EC, A,  rating is not provided in the current version of the data, it might be included in the next updates.**

# File descriptions:

Video\_games\_esrb\_rating.csv  - the training set
test\_esrb.csv                             - the test set

# Data dictionary

| Feature                 |   type     |                description                 |  Keys  |
|:------------------------|:----------:|:------------------------------------------|:------:|
|title                    | **string** |Name of the game.                          |  ----  |
|console                  | **int** |The console on which the game was released.|0 = PS4<br> 1 = PS4 & Xbox_one|
|Alcohol_Reference        | **int** |Reference to and/or images of alcoholic beverages.|0 = no<br>1 = yes
|Animated_Blood           | **int** |Discolored and/or unrealistic depictions of blood.|0 = no<br>1 = yes
|Blood                    | **int** |Depictions of blood.|0 = no<br>1 = yes
|Blood_and_Gore           | **int** |Depictions of blood or the mutilation of body parts.|0 = no<br>1 = yes
|Cartoon_Violence         | **int** |Violent actions involving cartoon-like situations and characters. May include violence where a character is unharmed after the action has been inflicted.|0 = no<br>1 = yes
|Crude_Humor              | **int** |Depictions or dialogue involving vulgar antics, including ""bathroom"" humor.|0 = no<br>1 = yes
|DrugRe_ference           | **int** |Reference to and/or images of illegal drugs.|0 = no<br>1 = yes
|Fantasy_Violence         | **int** |Violent actions of a fantasy nature, involving human or non-human characters in situations easily distinguishable from real life.|0 = no<br>1 = yes
|Intense_Violence         | **int** |Graphic and realistic-looking depictions of physical conflict. May involve extreme and/or realistic blood, gore, weapons, and depictions of human injury and death.|0 = no<br>1 = yes
|Language                 | **int** |Moderate use of profanity.|0 = no<br>1 = yes
|Lyrics                   | **int** |References to profanity, sexuality, violence, alcohol, or drug use in music.|0 = no<br>1 = yes
|Mature_Humor             | **int** |Depictions or dialogue involving ""adult"" humor, including sexual references.|0 = no<br>1 = yes
|Mild_Blood               | **int** |Some blood.|0 = no<br>1 = yes
|Mild_Cartoon_Violence    | **int** |Some violent actions involving cartoon.|0 = no<br>1 = yes
|Mild_Fantasy_Violence    | **int** |Some violent actions of a fantasy nature.|0 = no<br>1 = yes
|Mild_Language            | **int** |Mild to moderate use of profanity.|0 = no<br>1 = yes
|Mild_Lyrics              | **int** |Mild References to profanity, sexuality, violence, alcohol, or drug use in music.|0 = no<br>1 = yes
|Mild_Suggestive_Themes   | **int** |some provocative references or materials           |0 = no<br>1 = yes
|Mild_Violence            | **int** |Some scenes involving aggressive conflict.|0 = no<br>1 = yes
|No_Descriptors           | **int** |No content descriptors.|0 = no<br>1 = yes
|Nudity                   | **int** |Graphic or prolonged depictions of nudity.|0 = no<br>1 = yes
|Partial_Nudity           | **int** |Brief and/or mild depictions of nudity.|0 = no<br>1 = yes
|Sexual_Content           | **int** |Non-explicit depictions of sexual behavior, possibly including partial nudity.|0 = no<br>1 = yes
|Sexual_Themes            | **int** |References to sex or sexuality.|0 = no<br>1 = yes
|Simulated_Gambling       | **int** |Player can gamble without betting or wagering real cash or currency.|0 = no<br>1 = yes
|Strong_Language          | **int** |Explicit and/or frequent use of profanity.|0 = no<br>1 = yes
|Strong_Sexual_Content    | **int** |Explicit and/or frequent depictions of sexual behavior, possibly including nudity.|0 = no<br>1 = yes
|Suggestive_Themes        | **int** |Provocative references or materials.|0 = no<br>1 = yes
|Use_of_Alcohol           | **int** |The consumption of alcoholic beverages.|0 = no<br>1 = yes
|Use_of_Drugs_and_Alcohol | **int** |The consumption of alcoholic and drugs beverages.|0 = no<br>1 = yes
|Violence                 | **int** |Scenes involving aggressive conflict. May contain bloodless dismemberment.|0 = no<br>1 = yes
|ESRB_rating              | **string** |rating: RP - EC - E - E+10 - T - M - A    | RP , EC , E , ET , T , M , A|


<br><br>
**ESRB rating description:**

|ESRB_rating|Description      |
|-----------|-----------------|
|RP         | Rating Pending  |
|EC         | Early Childhood |
|E          | Everyone        |
|E 10+      | Everyone 10+    |
|T          | Teen            |
|M          | Mature          |
|A          | Adult           |",.csv,True
Video Games Rating By 'ESRB',2,video-games-rating-by-esrb,Video_games_esrb_rating.csv,CC0-1.0,"- This data contains the name for `1895 games` with `34 of ESRB rating content with the name and console` as features for each game.<br><br>
-  A single data point is represented as a binary value `0-1` for `Console` and a `binary vector` for the `features of ESRB content`.<br><br>
- **RP, EC, A,  rating is not provided in the current version of the data, it might be included in the next updates.**

# File descriptions:

Video\_games\_esrb\_rating.csv  - the training set
test\_esrb.csv                             - the test set

# Data dictionary

| Feature                 |   type     |                description                 |  Keys  |
|:------------------------|:----------:|:------------------------------------------|:------:|
|title                    | **string** |Name of the game.                          |  ----  |
|console                  | **int** |The console on which the game was released.|0 = PS4<br> 1 = PS4 & Xbox_one|
|Alcohol_Reference        | **int** |Reference to and/or images of alcoholic beverages.|0 = no<br>1 = yes
|Animated_Blood           | **int** |Discolored and/or unrealistic depictions of blood.|0 = no<br>1 = yes
|Blood                    | **int** |Depictions of blood.|0 = no<br>1 = yes
|Blood_and_Gore           | **int** |Depictions of blood or the mutilation of body parts.|0 = no<br>1 = yes
|Cartoon_Violence         | **int** |Violent actions involving cartoon-like situations and characters. May include violence where a character is unharmed after the action has been inflicted.|0 = no<br>1 = yes
|Crude_Humor              | **int** |Depictions or dialogue involving vulgar antics, including ""bathroom"" humor.|0 = no<br>1 = yes
|DrugRe_ference           | **int** |Reference to and/or images of illegal drugs.|0 = no<br>1 = yes
|Fantasy_Violence         | **int** |Violent actions of a fantasy nature, involving human or non-human characters in situations easily distinguishable from real life.|0 = no<br>1 = yes
|Intense_Violence         | **int** |Graphic and realistic-looking depictions of physical conflict. May involve extreme and/or realistic blood, gore, weapons, and depictions of human injury and death.|0 = no<br>1 = yes
|Language                 | **int** |Moderate use of profanity.|0 = no<br>1 = yes
|Lyrics                   | **int** |References to profanity, sexuality, violence, alcohol, or drug use in music.|0 = no<br>1 = yes
|Mature_Humor             | **int** |Depictions or dialogue involving ""adult"" humor, including sexual references.|0 = no<br>1 = yes
|Mild_Blood               | **int** |Some blood.|0 = no<br>1 = yes
|Mild_Cartoon_Violence    | **int** |Some violent actions involving cartoon.|0 = no<br>1 = yes
|Mild_Fantasy_Violence    | **int** |Some violent actions of a fantasy nature.|0 = no<br>1 = yes
|Mild_Language            | **int** |Mild to moderate use of profanity.|0 = no<br>1 = yes
|Mild_Lyrics              | **int** |Mild References to profanity, sexuality, violence, alcohol, or drug use in music.|0 = no<br>1 = yes
|Mild_Suggestive_Themes   | **int** |some provocative references or materials           |0 = no<br>1 = yes
|Mild_Violence            | **int** |Some scenes involving aggressive conflict.|0 = no<br>1 = yes
|No_Descriptors           | **int** |No content descriptors.|0 = no<br>1 = yes
|Nudity                   | **int** |Graphic or prolonged depictions of nudity.|0 = no<br>1 = yes
|Partial_Nudity           | **int** |Brief and/or mild depictions of nudity.|0 = no<br>1 = yes
|Sexual_Content           | **int** |Non-explicit depictions of sexual behavior, possibly including partial nudity.|0 = no<br>1 = yes
|Sexual_Themes            | **int** |References to sex or sexuality.|0 = no<br>1 = yes
|Simulated_Gambling       | **int** |Player can gamble without betting or wagering real cash or currency.|0 = no<br>1 = yes
|Strong_Language          | **int** |Explicit and/or frequent use of profanity.|0 = no<br>1 = yes
|Strong_Sexual_Content    | **int** |Explicit and/or frequent depictions of sexual behavior, possibly including nudity.|0 = no<br>1 = yes
|Suggestive_Themes        | **int** |Provocative references or materials.|0 = no<br>1 = yes
|Use_of_Alcohol           | **int** |The consumption of alcoholic beverages.|0 = no<br>1 = yes
|Use_of_Drugs_and_Alcohol | **int** |The consumption of alcoholic and drugs beverages.|0 = no<br>1 = yes
|Violence                 | **int** |Scenes involving aggressive conflict. May contain bloodless dismemberment.|0 = no<br>1 = yes
|ESRB_rating              | **string** |rating: RP - EC - E - E+10 - T - M - A    | RP , EC , E , ET , T , M , A|


<br><br>
**ESRB rating description:**

|ESRB_rating|Description      |
|-----------|-----------------|
|RP         | Rating Pending  |
|EC         | Early Childhood |
|E          | Everyone        |
|E 10+      | Everyone 10+    |
|T          | Teen            |
|M          | Mature          |
|A          | Adult           |",.csv,True
Water Quality,2,water-potability,water_potability.csv,CC0-1.0,"# Context

`Access to safe drinking-water is essential to health, a basic human right and a component of effective policy for health protection. This is important as a health and development issue at a national, regional and local level. In some regions, it has been shown that investments in water supply and sanitation can yield a net economic benefit, since the reductions in adverse health effects and health care costs outweigh the costs of undertaking the interventions.`


# Content


The water_potability.csv file contains water quality metrics for 3276 different water bodies. 
### 1. pH value:
```PH is an important parameter in evaluating the acid–base balance of water. It is also the indicator of acidic or alkaline condition of water status. WHO has recommended maximum permissible limit of pH from 6.5 to 8.5. The current investigation ranges were 6.52–6.83 which are in the range of WHO standards. ```

### 2. Hardness:
```Hardness is mainly caused by calcium and magnesium salts. These salts are dissolved from geologic deposits through which water travels. The length of time water is in contact with hardness producing material helps determine how much hardness there is in raw water.
Hardness was originally defined as the capacity of water to precipitate soap caused by Calcium and Magnesium.```

### 3. Solids (Total dissolved solids - TDS): 
```Water has the ability to dissolve a wide range of inorganic and some organic minerals or salts such as potassium, calcium, sodium, bicarbonates, chlorides, magnesium, sulfates etc. These minerals produced un-wanted taste and diluted color in appearance of water. This is the important parameter for the use of water. The water with high TDS value indicates that water is highly mineralized. Desirable limit for TDS is 500 mg/l and maximum limit is 1000 mg/l which prescribed for drinking purpose. ```

### 4. Chloramines: 
```Chlorine and chloramine are the major disinfectants used in public water systems. Chloramines are most commonly formed when ammonia is added to chlorine to treat drinking water. Chlorine levels up to 4 milligrams per liter (mg/L or 4 parts per million (ppm)) are considered safe in drinking water.```

### 5. Sulfate: 
```Sulfates are naturally occurring substances that are found in minerals, soil, and rocks. They are present in ambient air, groundwater, plants, and food. The principal commercial use of sulfate is in the chemical industry. Sulfate concentration in seawater is about 2,700 milligrams per liter (mg/L). It ranges from 3 to 30 mg/L in most freshwater supplies, although much higher concentrations (1000 mg/L) are found in some geographic locations. ```

### 6. Conductivity: 
```Pure water is not a good conductor of electric current rather’s a good insulator. Increase in ions concentration enhances the electrical conductivity of water. Generally, the amount of dissolved solids in water determines the electrical conductivity. Electrical conductivity (EC) actually measures the ionic process of a solution that enables it to transmit current. According to WHO standards, EC value should not exceeded 400 μS/cm. ```

### 7. Organic_carbon: 
 ```Total Organic Carbon (TOC) in source waters comes from decaying natural organic matter (NOM) as well as synthetic sources. TOC is a measure of the total amount of carbon in organic compounds in pure water. According to US EPA &lt; 2 mg/L as TOC in treated / drinking water, and &lt; 4 mg/Lit in source water which is use for treatment.```

### 8. Trihalomethanes: 
```THMs are chemicals which may be found in water treated with chlorine. The concentration of THMs in drinking water varies according to the level of organic material in the water, the amount of chlorine required to treat the water, and the temperature of the water that is being treated. THM levels up to 80 ppm is considered safe in drinking water.```

### 9. Turbidity: 
```The turbidity of water depends on the quantity of solid matter present in the suspended state. It is a measure of light emitting properties of water and the test is used to indicate the quality of waste discharge with respect to colloidal matter. The mean turbidity value obtained for Wondo Genet Campus (0.98 NTU) is lower than the WHO recommended value of 5.00 NTU.```

### 10. Potability: 
```Indicates if water is safe for human consumption where 1 means Potable and 0 means Not potable.```",.csv,True
Water Quality,2,water-quality,water-quality-1.csv,CC0-1.0,"**Context:**
Access to safe drinking-water is essential to health, a basic human right and a component of effective policy for health protection. This is important as a health and development issue at a national, regional and local level. In some regions, it has been shown that investments in water supply and sanitation can yield a net economic benefit, since the reductions in adverse health effects and health care costs outweigh the costs of undertaking the interventions.

Content
The water_potability.csv file contains water quality metrics for 3276 different water bodies.

**1. pH value:**
PH is an important parameter in evaluating the acid–base balance of water. It is also the indicator of acidic or alkaline condition of water status. WHO has recommended maximum permissible limit of pH from 6.5 to 8.5. The current investigation ranges were 6.52–6.83 which are in the range of WHO standards.

**2. Hardness:**
Hardness is mainly caused by calcium and magnesium salts. These salts are dissolved from geologic deposits through which water travels. The length of time water is in contact with hardness producing material helps determine how much hardness there is in raw water. Hardness was originally defined as the capacity of water to precipitate soap caused by Calcium and Magnesium.

**3. Solids (Total dissolved solids - TDS):
**Water has the ability to dissolve a wide range of inorganic and some organic minerals or salts such as potassium, calcium, sodium, bicarbonates, chlorides, magnesium, sulfates etc. These minerals produced un-wanted taste and diluted color in appearance of water. This is the important parameter for the use of water. The water with high TDS value indicates that water is highly mineralized. Desirable limit for TDS is 500 mg/l and maximum limit is 1000 mg/l which prescribed for drinking purpose.

**4. Chloramines:
**Chlorine and chloramine are the major disinfectants used in public water systems. Chloramines are most commonly formed when ammonia is added to chlorine to treat drinking water. Chlorine levels up to 4 milligrams per liter (mg/L or 4 parts per million (ppm)) are considered safe in drinking water.

**5. Sulfate:**
Sulfates are naturally occurring substances that are found in minerals, soil, and rocks. They are present in ambient air, groundwater, plants, and food. The principal commercial use of sulfate is in the chemical industry. Sulfate concentration in seawater is about 2,700 milligrams per liter (mg/L). It ranges from 3 to 30 mg/L in most freshwater supplies, although much higher concentrations (1000 mg/L) are found in some geographic locations.

**6. Conductivity:**
Pure water is not a good conductor of electric current rather’s a good insulator. Increase in ions concentration enhances the electrical conductivity of water. Generally, the amount of dissolved solids in water determines the electrical conductivity. Electrical conductivity (EC) actually measures the ionic process of a solution that enables it to transmit current. According to WHO standards, EC value should not exceeded 400 μS/cm.

**7. Organic_carbon:
**Total Organic Carbon (TOC) in source waters comes from decaying natural organic matter (NOM) as well as synthetic sources. TOC is a measure of the total amount of carbon in organic compounds in pure water. According to US EPA &lt; 2 mg/L as TOC in treated / drinking water, and &lt; 4 mg/Lit in source water which is use for treatment.

**8. Trihalomethanes:**
THMs are chemicals which may be found in water treated with chlorine. The concentration of THMs in drinking water varies according to the level of organic material in the water, the amount of chlorine required to treat the water, and the temperature of the water that is being treated. THM levels up to 80 ppm is considered safe in drinking water.

**9. Turbidity:
**The turbidity of water depends on the quantity of solid matter present in the suspended state. It is a measure of light emitting properties of water and the test is used to indicate the quality of waste discharge with respect to colloidal matter. The mean turbidity value obtained for Wondo Genet Campus (0.98 NTU) is lower than the WHO recommended value of 5.00 NTU.

**10. Potability:
**Indicates if water is safe for human consumption where 1 means Potable and 0 means Not potable.



import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))


df=pd.read_csv(""/kaggle/input/water-potability/water_potability.csv"")
df.head()",.csv,True
Wind Power Generation Data,4,wind-power-generation,50Hertz.csv,CC0-1.0,"### Context

Information about the four German Transmission System Operators (TSOs) jointly publish as well as general information about the transmission system. 


### Content

Wind power generation from four German energy companies (50 Hertz, Amprion, TenneT TSO and TransnetBW). It contains power generation data (non-normalized) with an interval of 15 minutes, totalizing 96 points a day.

Generation in THw between 23/08/2019 to 22/09/2020.

### Acknowledgements

https://www.netztransparenz.de/


",.csv,True
Wind Power Generation Data,4,wind-power-generation,Amprion.csv,CC0-1.0,"### Context

Information about the four German Transmission System Operators (TSOs) jointly publish as well as general information about the transmission system. 


### Content

Wind power generation from four German energy companies (50 Hertz, Amprion, TenneT TSO and TransnetBW). It contains power generation data (non-normalized) with an interval of 15 minutes, totalizing 96 points a day.

Generation in THw between 23/08/2019 to 22/09/2020.

### Acknowledgements

https://www.netztransparenz.de/


",.csv,True
Wind Power Generation Data,4,wind-power-generation,TransnetBW.csv,CC0-1.0,"### Context

Information about the four German Transmission System Operators (TSOs) jointly publish as well as general information about the transmission system. 


### Content

Wind power generation from four German energy companies (50 Hertz, Amprion, TenneT TSO and TransnetBW). It contains power generation data (non-normalized) with an interval of 15 minutes, totalizing 96 points a day.

Generation in THw between 23/08/2019 to 22/09/2020.

### Acknowledgements

https://www.netztransparenz.de/


",.csv,True
Wind Power Generation Data,4,wind-power-generation,TenneTTSO.csv,CC0-1.0,"### Context

Information about the four German Transmission System Operators (TSOs) jointly publish as well as general information about the transmission system. 


### Content

Wind power generation from four German energy companies (50 Hertz, Amprion, TenneT TSO and TransnetBW). It contains power generation data (non-normalized) with an interval of 15 minutes, totalizing 96 points a day.

Generation in THw between 23/08/2019 to 22/09/2020.

### Acknowledgements

https://www.netztransparenz.de/


",.csv,True
World Bank Data (1960 to 2016),3,world-bank-data-1960-to-2016,life_expectancy.csv,world-bank,"### Context

In 2006, Hans Rosling gave a TED talk titled [The best stats you've ever seen](https://www.ted.com/talks/hans_rosling_shows_the_best_stats_you_ve_ever_seen). In the beginning of the talk, he shows an animation he made to debunk some misconceptions about today's world.  
 I really enjoyed seeing this visualization and have been thinking to try to reproduce it with the tools I know (i.e python and matplotlib).   


### Content

The data was downloaded from [data.worldbank.org](https://data.worldbank.org/) on June 28th, 2018. 

- [life expentancy at birth](https://data.worldbank.org/indicator/SP.DYN.LE00.IN): number of years a newborn would live if the patterns of mortality at the time of birth remain the same throughout his life.
- [Fertility rate](https://data.worldbank.org/indicator/SP.DYN.TFRT.IN): number of children a woman would give birth to during her childbearing years.  
- [Country population](https://data.worldbank.org/indicator/SP.POP.TOTL): total number of residents regardless of legal status or citizenship (midyear estimates)


Photo by Ishan @seefromthesky on Unsplash",.csv,True
World Bank Data (1960 to 2016),3,world-bank-data-1960-to-2016,country_population.csv,world-bank,"### Context

In 2006, Hans Rosling gave a TED talk titled [The best stats you've ever seen](https://www.ted.com/talks/hans_rosling_shows_the_best_stats_you_ve_ever_seen). In the beginning of the talk, he shows an animation he made to debunk some misconceptions about today's world.  
 I really enjoyed seeing this visualization and have been thinking to try to reproduce it with the tools I know (i.e python and matplotlib).   


### Content

The data was downloaded from [data.worldbank.org](https://data.worldbank.org/) on June 28th, 2018. 

- [life expentancy at birth](https://data.worldbank.org/indicator/SP.DYN.LE00.IN): number of years a newborn would live if the patterns of mortality at the time of birth remain the same throughout his life.
- [Fertility rate](https://data.worldbank.org/indicator/SP.DYN.TFRT.IN): number of children a woman would give birth to during her childbearing years.  
- [Country population](https://data.worldbank.org/indicator/SP.POP.TOTL): total number of residents regardless of legal status or citizenship (midyear estimates)


Photo by Ishan @seefromthesky on Unsplash",.csv,True
World Bank Data (1960 to 2016),3,world-bank-data-1960-to-2016,fertility_rate.csv,world-bank,"### Context

In 2006, Hans Rosling gave a TED talk titled [The best stats you've ever seen](https://www.ted.com/talks/hans_rosling_shows_the_best_stats_you_ve_ever_seen). In the beginning of the talk, he shows an animation he made to debunk some misconceptions about today's world.  
 I really enjoyed seeing this visualization and have been thinking to try to reproduce it with the tools I know (i.e python and matplotlib).   


### Content

The data was downloaded from [data.worldbank.org](https://data.worldbank.org/) on June 28th, 2018. 

- [life expentancy at birth](https://data.worldbank.org/indicator/SP.DYN.LE00.IN): number of years a newborn would live if the patterns of mortality at the time of birth remain the same throughout his life.
- [Fertility rate](https://data.worldbank.org/indicator/SP.DYN.TFRT.IN): number of children a woman would give birth to during her childbearing years.  
- [Country population](https://data.worldbank.org/indicator/SP.POP.TOTL): total number of residents regardless of legal status or citizenship (midyear estimates)


Photo by Ishan @seefromthesky on Unsplash",.csv,True
"World GDP(GDP, GDP per capita, and annual growths)",6,world-gdpgdp-gdp-per-capita-and-annual-growths,gdp_ppp_per_capita.csv,CC0-1.0,"## **Includings**
#### 1. GDP
#### 2. GDP Growth(Annually)
#### 3. GDP per capita
#### 4. GDP per capita Growth(Annually)
#### 5. GDP PPP
#### 6. GDP PPP per capita

## **Description**
GDP data is gathered from [World Bank](https://data.worldbank.org/). Data may be used for academic research or for self-learn. More than +200 country **GDP** is used between the years **1960-2020**.

## **Possible Usage**
Data can be used for processing, analyzing, and visualizing various GDP types for various countries for a given year.",.csv,True
"World GDP(GDP, GDP per capita, and annual growths)",6,world-gdpgdp-gdp-per-capita-and-annual-growths,gdp_ppp.csv,CC0-1.0,"## **Includings**
#### 1. GDP
#### 2. GDP Growth(Annually)
#### 3. GDP per capita
#### 4. GDP per capita Growth(Annually)
#### 5. GDP PPP
#### 6. GDP PPP per capita

## **Description**
GDP data is gathered from [World Bank](https://data.worldbank.org/). Data may be used for academic research or for self-learn. More than +200 country **GDP** is used between the years **1960-2020**.

## **Possible Usage**
Data can be used for processing, analyzing, and visualizing various GDP types for various countries for a given year.",.csv,True
"World GDP(GDP, GDP per capita, and annual growths)",6,world-gdpgdp-gdp-per-capita-and-annual-growths,gdp_per_capita.csv,CC0-1.0,"## **Includings**
#### 1. GDP
#### 2. GDP Growth(Annually)
#### 3. GDP per capita
#### 4. GDP per capita Growth(Annually)
#### 5. GDP PPP
#### 6. GDP PPP per capita

## **Description**
GDP data is gathered from [World Bank](https://data.worldbank.org/). Data may be used for academic research or for self-learn. More than +200 country **GDP** is used between the years **1960-2020**.

## **Possible Usage**
Data can be used for processing, analyzing, and visualizing various GDP types for various countries for a given year.",.csv,True
"World GDP(GDP, GDP per capita, and annual growths)",6,world-gdpgdp-gdp-per-capita-and-annual-growths,gdp_per_capita_growth.csv,CC0-1.0,"## **Includings**
#### 1. GDP
#### 2. GDP Growth(Annually)
#### 3. GDP per capita
#### 4. GDP per capita Growth(Annually)
#### 5. GDP PPP
#### 6. GDP PPP per capita

## **Description**
GDP data is gathered from [World Bank](https://data.worldbank.org/). Data may be used for academic research or for self-learn. More than +200 country **GDP** is used between the years **1960-2020**.

## **Possible Usage**
Data can be used for processing, analyzing, and visualizing various GDP types for various countries for a given year.",.csv,True
"World GDP(GDP, GDP per capita, and annual growths)",6,world-gdpgdp-gdp-per-capita-and-annual-growths,gdp.csv,CC0-1.0,"## **Includings**
#### 1. GDP
#### 2. GDP Growth(Annually)
#### 3. GDP per capita
#### 4. GDP per capita Growth(Annually)
#### 5. GDP PPP
#### 6. GDP PPP per capita

## **Description**
GDP data is gathered from [World Bank](https://data.worldbank.org/). Data may be used for academic research or for self-learn. More than +200 country **GDP** is used between the years **1960-2020**.

## **Possible Usage**
Data can be used for processing, analyzing, and visualizing various GDP types for various countries for a given year.",.csv,True
"World GDP(GDP, GDP per capita, and annual growths)",6,world-gdpgdp-gdp-per-capita-and-annual-growths,gdp_growth.csv,CC0-1.0,"## **Includings**
#### 1. GDP
#### 2. GDP Growth(Annually)
#### 3. GDP per capita
#### 4. GDP per capita Growth(Annually)
#### 5. GDP PPP
#### 6. GDP PPP per capita

## **Description**
GDP data is gathered from [World Bank](https://data.worldbank.org/). Data may be used for academic research or for self-learn. More than +200 country **GDP** is used between the years **1960-2020**.

## **Possible Usage**
Data can be used for processing, analyzing, and visualizing various GDP types for various countries for a given year.",.csv,True
World Happiness Report up to 2023,9,global-happiness-scores-and-factors,WHR_2015.csv,CC0-1.0,"### Context

The World Happiness Report Up to 2023 dataset offers a comprehensive and up-to-date examination of happiness metrics and the factors influencing well-being on a global scale. This dataset is designed to provide valuable insights for policymakers, researchers, and individuals interested in understanding the dynamics of happiness and well-being worldwide.

### Content

There are 9 CSVs, each listing the same items. These datasets include key metrics related to global happiness and well-being, such as country names, regions, happiness scores, GDP per capita, social support, healthy life expectancy, freedom to make life choices, generosity, and perceptions of corruption. These metrics offer insights into the happiness and socio-economic conditions of various countries and regions, making it a valuable resource for analyzing and understanding well-being on a global scale.


### Dataset
These datasets comprise various key indicators related to happiness, covering from 2015 up to 2023. It includes the following columns:

| Column                           | Description                              |
|----------------------------------|------------------------------------------|
| `country`                          | The name of the country.       |
| `region`                           | The geographic region or continent.      |
| `happiness_score`                  | A measure reflecting overall happiness.  |
| `gdp_per_capita`                   | A measure of Gross Domestic Product per capita.       |
| `social_support`                   | A metric measuring social support.       |
| `healthy_life_expectancy`          | A measure of years of healthy life expectancy.|
| `freedom_to_make_life_choices`     | A measure of freedom in life choices.    |
| `generosity`                       | A metric reflecting generosity.           |
| `perceptions_of_corruption`        | A measure of perception of corruption within a country.|


### Acknowledgment

The primary dataset was retrieved from the [World Happiness Report](https://worldhappiness.report/).
I extend my sincere gratitude to the original authors and editors of the ""World Happiness Report 2023 (11th ed.)"" for providing the main dataset used in this compilation. 

Editors: John Helliwell, Richard Layard, Jeffrey D. Sachs, Jan-Emmanuel De Neve, Lara B. Aknin, Shun Wang; and Sharon Paculor, Production Editor

©️ Citation: Helliwell, J. F., Layard, R., Sachs, J. D., Aknin, L. B., De Neve, J.-E., & Wang, S. (Eds.). (2023). World Happiness Report 2023 (11th ed.). Sustainable Development Solutions Network.

Image credit: [Getty; The Atlantic](https://cdn.theatlantic.com/thumbor/sdRdXMCLjpMANrHTL3NeHCm2nyc=/0x0:2000x1125/1952x1098/media/img/mt/2021/06/HappiestCountriesFinal/original.jpg)",.csv,True
World Happiness Report up to 2023,9,global-happiness-scores-and-factors,WHR_2016.csv,CC0-1.0,"### Context

The World Happiness Report Up to 2023 dataset offers a comprehensive and up-to-date examination of happiness metrics and the factors influencing well-being on a global scale. This dataset is designed to provide valuable insights for policymakers, researchers, and individuals interested in understanding the dynamics of happiness and well-being worldwide.

### Content

There are 9 CSVs, each listing the same items. These datasets include key metrics related to global happiness and well-being, such as country names, regions, happiness scores, GDP per capita, social support, healthy life expectancy, freedom to make life choices, generosity, and perceptions of corruption. These metrics offer insights into the happiness and socio-economic conditions of various countries and regions, making it a valuable resource for analyzing and understanding well-being on a global scale.


### Dataset
These datasets comprise various key indicators related to happiness, covering from 2015 up to 2023. It includes the following columns:

| Column                           | Description                              |
|----------------------------------|------------------------------------------|
| `country`                          | The name of the country.       |
| `region`                           | The geographic region or continent.      |
| `happiness_score`                  | A measure reflecting overall happiness.  |
| `gdp_per_capita`                   | A measure of Gross Domestic Product per capita.       |
| `social_support`                   | A metric measuring social support.       |
| `healthy_life_expectancy`          | A measure of years of healthy life expectancy.|
| `freedom_to_make_life_choices`     | A measure of freedom in life choices.    |
| `generosity`                       | A metric reflecting generosity.           |
| `perceptions_of_corruption`        | A measure of perception of corruption within a country.|


### Acknowledgment

The primary dataset was retrieved from the [World Happiness Report](https://worldhappiness.report/).
I extend my sincere gratitude to the original authors and editors of the ""World Happiness Report 2023 (11th ed.)"" for providing the main dataset used in this compilation. 

Editors: John Helliwell, Richard Layard, Jeffrey D. Sachs, Jan-Emmanuel De Neve, Lara B. Aknin, Shun Wang; and Sharon Paculor, Production Editor

©️ Citation: Helliwell, J. F., Layard, R., Sachs, J. D., Aknin, L. B., De Neve, J.-E., & Wang, S. (Eds.). (2023). World Happiness Report 2023 (11th ed.). Sustainable Development Solutions Network.

Image credit: [Getty; The Atlantic](https://cdn.theatlantic.com/thumbor/sdRdXMCLjpMANrHTL3NeHCm2nyc=/0x0:2000x1125/1952x1098/media/img/mt/2021/06/HappiestCountriesFinal/original.jpg)",.csv,True
World Happiness Report up to 2023,9,global-happiness-scores-and-factors,WHR_2017.csv,CC0-1.0,"### Context

The World Happiness Report Up to 2023 dataset offers a comprehensive and up-to-date examination of happiness metrics and the factors influencing well-being on a global scale. This dataset is designed to provide valuable insights for policymakers, researchers, and individuals interested in understanding the dynamics of happiness and well-being worldwide.

### Content

There are 9 CSVs, each listing the same items. These datasets include key metrics related to global happiness and well-being, such as country names, regions, happiness scores, GDP per capita, social support, healthy life expectancy, freedom to make life choices, generosity, and perceptions of corruption. These metrics offer insights into the happiness and socio-economic conditions of various countries and regions, making it a valuable resource for analyzing and understanding well-being on a global scale.


### Dataset
These datasets comprise various key indicators related to happiness, covering from 2015 up to 2023. It includes the following columns:

| Column                           | Description                              |
|----------------------------------|------------------------------------------|
| `country`                          | The name of the country.       |
| `region`                           | The geographic region or continent.      |
| `happiness_score`                  | A measure reflecting overall happiness.  |
| `gdp_per_capita`                   | A measure of Gross Domestic Product per capita.       |
| `social_support`                   | A metric measuring social support.       |
| `healthy_life_expectancy`          | A measure of years of healthy life expectancy.|
| `freedom_to_make_life_choices`     | A measure of freedom in life choices.    |
| `generosity`                       | A metric reflecting generosity.           |
| `perceptions_of_corruption`        | A measure of perception of corruption within a country.|


### Acknowledgment

The primary dataset was retrieved from the [World Happiness Report](https://worldhappiness.report/).
I extend my sincere gratitude to the original authors and editors of the ""World Happiness Report 2023 (11th ed.)"" for providing the main dataset used in this compilation. 

Editors: John Helliwell, Richard Layard, Jeffrey D. Sachs, Jan-Emmanuel De Neve, Lara B. Aknin, Shun Wang; and Sharon Paculor, Production Editor

©️ Citation: Helliwell, J. F., Layard, R., Sachs, J. D., Aknin, L. B., De Neve, J.-E., & Wang, S. (Eds.). (2023). World Happiness Report 2023 (11th ed.). Sustainable Development Solutions Network.

Image credit: [Getty; The Atlantic](https://cdn.theatlantic.com/thumbor/sdRdXMCLjpMANrHTL3NeHCm2nyc=/0x0:2000x1125/1952x1098/media/img/mt/2021/06/HappiestCountriesFinal/original.jpg)",.csv,True
World Happiness Report up to 2023,9,global-happiness-scores-and-factors,WHR_2019.csv,CC0-1.0,"### Context

The World Happiness Report Up to 2023 dataset offers a comprehensive and up-to-date examination of happiness metrics and the factors influencing well-being on a global scale. This dataset is designed to provide valuable insights for policymakers, researchers, and individuals interested in understanding the dynamics of happiness and well-being worldwide.

### Content

There are 9 CSVs, each listing the same items. These datasets include key metrics related to global happiness and well-being, such as country names, regions, happiness scores, GDP per capita, social support, healthy life expectancy, freedom to make life choices, generosity, and perceptions of corruption. These metrics offer insights into the happiness and socio-economic conditions of various countries and regions, making it a valuable resource for analyzing and understanding well-being on a global scale.


### Dataset
These datasets comprise various key indicators related to happiness, covering from 2015 up to 2023. It includes the following columns:

| Column                           | Description                              |
|----------------------------------|------------------------------------------|
| `country`                          | The name of the country.       |
| `region`                           | The geographic region or continent.      |
| `happiness_score`                  | A measure reflecting overall happiness.  |
| `gdp_per_capita`                   | A measure of Gross Domestic Product per capita.       |
| `social_support`                   | A metric measuring social support.       |
| `healthy_life_expectancy`          | A measure of years of healthy life expectancy.|
| `freedom_to_make_life_choices`     | A measure of freedom in life choices.    |
| `generosity`                       | A metric reflecting generosity.           |
| `perceptions_of_corruption`        | A measure of perception of corruption within a country.|


### Acknowledgment

The primary dataset was retrieved from the [World Happiness Report](https://worldhappiness.report/).
I extend my sincere gratitude to the original authors and editors of the ""World Happiness Report 2023 (11th ed.)"" for providing the main dataset used in this compilation. 

Editors: John Helliwell, Richard Layard, Jeffrey D. Sachs, Jan-Emmanuel De Neve, Lara B. Aknin, Shun Wang; and Sharon Paculor, Production Editor

©️ Citation: Helliwell, J. F., Layard, R., Sachs, J. D., Aknin, L. B., De Neve, J.-E., & Wang, S. (Eds.). (2023). World Happiness Report 2023 (11th ed.). Sustainable Development Solutions Network.

Image credit: [Getty; The Atlantic](https://cdn.theatlantic.com/thumbor/sdRdXMCLjpMANrHTL3NeHCm2nyc=/0x0:2000x1125/1952x1098/media/img/mt/2021/06/HappiestCountriesFinal/original.jpg)",.csv,True
World Happiness Report up to 2023,9,global-happiness-scores-and-factors,WHR_2018.csv,CC0-1.0,"### Context

The World Happiness Report Up to 2023 dataset offers a comprehensive and up-to-date examination of happiness metrics and the factors influencing well-being on a global scale. This dataset is designed to provide valuable insights for policymakers, researchers, and individuals interested in understanding the dynamics of happiness and well-being worldwide.

### Content

There are 9 CSVs, each listing the same items. These datasets include key metrics related to global happiness and well-being, such as country names, regions, happiness scores, GDP per capita, social support, healthy life expectancy, freedom to make life choices, generosity, and perceptions of corruption. These metrics offer insights into the happiness and socio-economic conditions of various countries and regions, making it a valuable resource for analyzing and understanding well-being on a global scale.


### Dataset
These datasets comprise various key indicators related to happiness, covering from 2015 up to 2023. It includes the following columns:

| Column                           | Description                              |
|----------------------------------|------------------------------------------|
| `country`                          | The name of the country.       |
| `region`                           | The geographic region or continent.      |
| `happiness_score`                  | A measure reflecting overall happiness.  |
| `gdp_per_capita`                   | A measure of Gross Domestic Product per capita.       |
| `social_support`                   | A metric measuring social support.       |
| `healthy_life_expectancy`          | A measure of years of healthy life expectancy.|
| `freedom_to_make_life_choices`     | A measure of freedom in life choices.    |
| `generosity`                       | A metric reflecting generosity.           |
| `perceptions_of_corruption`        | A measure of perception of corruption within a country.|


### Acknowledgment

The primary dataset was retrieved from the [World Happiness Report](https://worldhappiness.report/).
I extend my sincere gratitude to the original authors and editors of the ""World Happiness Report 2023 (11th ed.)"" for providing the main dataset used in this compilation. 

Editors: John Helliwell, Richard Layard, Jeffrey D. Sachs, Jan-Emmanuel De Neve, Lara B. Aknin, Shun Wang; and Sharon Paculor, Production Editor

©️ Citation: Helliwell, J. F., Layard, R., Sachs, J. D., Aknin, L. B., De Neve, J.-E., & Wang, S. (Eds.). (2023). World Happiness Report 2023 (11th ed.). Sustainable Development Solutions Network.

Image credit: [Getty; The Atlantic](https://cdn.theatlantic.com/thumbor/sdRdXMCLjpMANrHTL3NeHCm2nyc=/0x0:2000x1125/1952x1098/media/img/mt/2021/06/HappiestCountriesFinal/original.jpg)",.csv,True
World Happiness Report up to 2023,9,global-happiness-scores-and-factors,WHR_2020.csv,CC0-1.0,"### Context

The World Happiness Report Up to 2023 dataset offers a comprehensive and up-to-date examination of happiness metrics and the factors influencing well-being on a global scale. This dataset is designed to provide valuable insights for policymakers, researchers, and individuals interested in understanding the dynamics of happiness and well-being worldwide.

### Content

There are 9 CSVs, each listing the same items. These datasets include key metrics related to global happiness and well-being, such as country names, regions, happiness scores, GDP per capita, social support, healthy life expectancy, freedom to make life choices, generosity, and perceptions of corruption. These metrics offer insights into the happiness and socio-economic conditions of various countries and regions, making it a valuable resource for analyzing and understanding well-being on a global scale.


### Dataset
These datasets comprise various key indicators related to happiness, covering from 2015 up to 2023. It includes the following columns:

| Column                           | Description                              |
|----------------------------------|------------------------------------------|
| `country`                          | The name of the country.       |
| `region`                           | The geographic region or continent.      |
| `happiness_score`                  | A measure reflecting overall happiness.  |
| `gdp_per_capita`                   | A measure of Gross Domestic Product per capita.       |
| `social_support`                   | A metric measuring social support.       |
| `healthy_life_expectancy`          | A measure of years of healthy life expectancy.|
| `freedom_to_make_life_choices`     | A measure of freedom in life choices.    |
| `generosity`                       | A metric reflecting generosity.           |
| `perceptions_of_corruption`        | A measure of perception of corruption within a country.|


### Acknowledgment

The primary dataset was retrieved from the [World Happiness Report](https://worldhappiness.report/).
I extend my sincere gratitude to the original authors and editors of the ""World Happiness Report 2023 (11th ed.)"" for providing the main dataset used in this compilation. 

Editors: John Helliwell, Richard Layard, Jeffrey D. Sachs, Jan-Emmanuel De Neve, Lara B. Aknin, Shun Wang; and Sharon Paculor, Production Editor

©️ Citation: Helliwell, J. F., Layard, R., Sachs, J. D., Aknin, L. B., De Neve, J.-E., & Wang, S. (Eds.). (2023). World Happiness Report 2023 (11th ed.). Sustainable Development Solutions Network.

Image credit: [Getty; The Atlantic](https://cdn.theatlantic.com/thumbor/sdRdXMCLjpMANrHTL3NeHCm2nyc=/0x0:2000x1125/1952x1098/media/img/mt/2021/06/HappiestCountriesFinal/original.jpg)",.csv,True
World Happiness Report up to 2023,9,global-happiness-scores-and-factors,WHR_2021.csv,CC0-1.0,"### Context

The World Happiness Report Up to 2023 dataset offers a comprehensive and up-to-date examination of happiness metrics and the factors influencing well-being on a global scale. This dataset is designed to provide valuable insights for policymakers, researchers, and individuals interested in understanding the dynamics of happiness and well-being worldwide.

### Content

There are 9 CSVs, each listing the same items. These datasets include key metrics related to global happiness and well-being, such as country names, regions, happiness scores, GDP per capita, social support, healthy life expectancy, freedom to make life choices, generosity, and perceptions of corruption. These metrics offer insights into the happiness and socio-economic conditions of various countries and regions, making it a valuable resource for analyzing and understanding well-being on a global scale.


### Dataset
These datasets comprise various key indicators related to happiness, covering from 2015 up to 2023. It includes the following columns:

| Column                           | Description                              |
|----------------------------------|------------------------------------------|
| `country`                          | The name of the country.       |
| `region`                           | The geographic region or continent.      |
| `happiness_score`                  | A measure reflecting overall happiness.  |
| `gdp_per_capita`                   | A measure of Gross Domestic Product per capita.       |
| `social_support`                   | A metric measuring social support.       |
| `healthy_life_expectancy`          | A measure of years of healthy life expectancy.|
| `freedom_to_make_life_choices`     | A measure of freedom in life choices.    |
| `generosity`                       | A metric reflecting generosity.           |
| `perceptions_of_corruption`        | A measure of perception of corruption within a country.|


### Acknowledgment

The primary dataset was retrieved from the [World Happiness Report](https://worldhappiness.report/).
I extend my sincere gratitude to the original authors and editors of the ""World Happiness Report 2023 (11th ed.)"" for providing the main dataset used in this compilation. 

Editors: John Helliwell, Richard Layard, Jeffrey D. Sachs, Jan-Emmanuel De Neve, Lara B. Aknin, Shun Wang; and Sharon Paculor, Production Editor

©️ Citation: Helliwell, J. F., Layard, R., Sachs, J. D., Aknin, L. B., De Neve, J.-E., & Wang, S. (Eds.). (2023). World Happiness Report 2023 (11th ed.). Sustainable Development Solutions Network.

Image credit: [Getty; The Atlantic](https://cdn.theatlantic.com/thumbor/sdRdXMCLjpMANrHTL3NeHCm2nyc=/0x0:2000x1125/1952x1098/media/img/mt/2021/06/HappiestCountriesFinal/original.jpg)",.csv,True
World Happiness Report up to 2023,9,global-happiness-scores-and-factors,WHR_2023.csv,CC0-1.0,"### Context

The World Happiness Report Up to 2023 dataset offers a comprehensive and up-to-date examination of happiness metrics and the factors influencing well-being on a global scale. This dataset is designed to provide valuable insights for policymakers, researchers, and individuals interested in understanding the dynamics of happiness and well-being worldwide.

### Content

There are 9 CSVs, each listing the same items. These datasets include key metrics related to global happiness and well-being, such as country names, regions, happiness scores, GDP per capita, social support, healthy life expectancy, freedom to make life choices, generosity, and perceptions of corruption. These metrics offer insights into the happiness and socio-economic conditions of various countries and regions, making it a valuable resource for analyzing and understanding well-being on a global scale.


### Dataset
These datasets comprise various key indicators related to happiness, covering from 2015 up to 2023. It includes the following columns:

| Column                           | Description                              |
|----------------------------------|------------------------------------------|
| `country`                          | The name of the country.       |
| `region`                           | The geographic region or continent.      |
| `happiness_score`                  | A measure reflecting overall happiness.  |
| `gdp_per_capita`                   | A measure of Gross Domestic Product per capita.       |
| `social_support`                   | A metric measuring social support.       |
| `healthy_life_expectancy`          | A measure of years of healthy life expectancy.|
| `freedom_to_make_life_choices`     | A measure of freedom in life choices.    |
| `generosity`                       | A metric reflecting generosity.           |
| `perceptions_of_corruption`        | A measure of perception of corruption within a country.|


### Acknowledgment

The primary dataset was retrieved from the [World Happiness Report](https://worldhappiness.report/).
I extend my sincere gratitude to the original authors and editors of the ""World Happiness Report 2023 (11th ed.)"" for providing the main dataset used in this compilation. 

Editors: John Helliwell, Richard Layard, Jeffrey D. Sachs, Jan-Emmanuel De Neve, Lara B. Aknin, Shun Wang; and Sharon Paculor, Production Editor

©️ Citation: Helliwell, J. F., Layard, R., Sachs, J. D., Aknin, L. B., De Neve, J.-E., & Wang, S. (Eds.). (2023). World Happiness Report 2023 (11th ed.). Sustainable Development Solutions Network.

Image credit: [Getty; The Atlantic](https://cdn.theatlantic.com/thumbor/sdRdXMCLjpMANrHTL3NeHCm2nyc=/0x0:2000x1125/1952x1098/media/img/mt/2021/06/HappiestCountriesFinal/original.jpg)",.csv,True
World Happiness Report up to 2023,9,global-happiness-scores-and-factors,WHR_2022.csv,CC0-1.0,"### Context

The World Happiness Report Up to 2023 dataset offers a comprehensive and up-to-date examination of happiness metrics and the factors influencing well-being on a global scale. This dataset is designed to provide valuable insights for policymakers, researchers, and individuals interested in understanding the dynamics of happiness and well-being worldwide.

### Content

There are 9 CSVs, each listing the same items. These datasets include key metrics related to global happiness and well-being, such as country names, regions, happiness scores, GDP per capita, social support, healthy life expectancy, freedom to make life choices, generosity, and perceptions of corruption. These metrics offer insights into the happiness and socio-economic conditions of various countries and regions, making it a valuable resource for analyzing and understanding well-being on a global scale.


### Dataset
These datasets comprise various key indicators related to happiness, covering from 2015 up to 2023. It includes the following columns:

| Column                           | Description                              |
|----------------------------------|------------------------------------------|
| `country`                          | The name of the country.       |
| `region`                           | The geographic region or continent.      |
| `happiness_score`                  | A measure reflecting overall happiness.  |
| `gdp_per_capita`                   | A measure of Gross Domestic Product per capita.       |
| `social_support`                   | A metric measuring social support.       |
| `healthy_life_expectancy`          | A measure of years of healthy life expectancy.|
| `freedom_to_make_life_choices`     | A measure of freedom in life choices.    |
| `generosity`                       | A metric reflecting generosity.           |
| `perceptions_of_corruption`        | A measure of perception of corruption within a country.|


### Acknowledgment

The primary dataset was retrieved from the [World Happiness Report](https://worldhappiness.report/).
I extend my sincere gratitude to the original authors and editors of the ""World Happiness Report 2023 (11th ed.)"" for providing the main dataset used in this compilation. 

Editors: John Helliwell, Richard Layard, Jeffrey D. Sachs, Jan-Emmanuel De Neve, Lara B. Aknin, Shun Wang; and Sharon Paculor, Production Editor

©️ Citation: Helliwell, J. F., Layard, R., Sachs, J. D., Aknin, L. B., De Neve, J.-E., & Wang, S. (Eds.). (2023). World Happiness Report 2023 (11th ed.). Sustainable Development Solutions Network.

Image credit: [Getty; The Atlantic](https://cdn.theatlantic.com/thumbor/sdRdXMCLjpMANrHTL3NeHCm2nyc=/0x0:2000x1125/1952x1098/media/img/mt/2021/06/HappiestCountriesFinal/original.jpg)",.csv,True
Y Combinator Directory,2,y-combinator-directory,2023-07-13-yc-companies.csv,CC0-1.0,"# Y Combinator Directory Scraper
I put together a dataset of all the companies in the Y Combinator directory as of July, 13th 2023. You can search for companies by industry, region, company size, and more in this dataset. 

This dataset was scraped using [YC Scraper](https://github.com/corralm/yc-scraper).

## About Y Combinator
Y Combinator is a startup accelerator that has invested in over 4,000 companies that have a combined valuation of over $600B. The overall goal of Y Combinator is to help startups really take off.

## Attributes
|  Attribute           |  Description | Data Type  |
|-----------------------|---|---|
| company_id            | Company id provided by YC  | int  |
| company_name          | Company name  | string  |
| short_description     | One-line description of the company  | string  |
| long_description      | Long description of the company  | string  |
| batch                 | Batch name provided by YC  | string  |
| status                | Company status  | string  |
| tags                  | Industry tags  | list  |
| location              | Company location | string  |
| country               | Company country  | string  |
| year_founded          | Year the company was founded  | int  |
| num_founders          | Number of founders  | int  |
| founders_names        | Full names of the founders  | list  |
| team_size             | Number of employees  | int  |
| website               | Company website   | string  |
| cb_url                | Company Crunchbase url  | string  |
| linkedin_url          | Company LinkedIn url  | string  |

## Meta
Author: Miguel Corral Jr.  
Email: corraljrmiguel@gmail.com  
LinkedIn: https://www.linkedin.com/in/imiguel  
GitHub: https://github.com/corralm",.csv,True
Y Combinator Directory,2,y-combinator-directory,2023-02-27-yc-companies.csv,CC0-1.0,"# Y Combinator Directory Scraper
I put together a dataset of all the companies in the Y Combinator directory as of July, 13th 2023. You can search for companies by industry, region, company size, and more in this dataset. 

This dataset was scraped using [YC Scraper](https://github.com/corralm/yc-scraper).

## About Y Combinator
Y Combinator is a startup accelerator that has invested in over 4,000 companies that have a combined valuation of over $600B. The overall goal of Y Combinator is to help startups really take off.

## Attributes
|  Attribute           |  Description | Data Type  |
|-----------------------|---|---|
| company_id            | Company id provided by YC  | int  |
| company_name          | Company name  | string  |
| short_description     | One-line description of the company  | string  |
| long_description      | Long description of the company  | string  |
| batch                 | Batch name provided by YC  | string  |
| status                | Company status  | string  |
| tags                  | Industry tags  | list  |
| location              | Company location | string  |
| country               | Company country  | string  |
| year_founded          | Year the company was founded  | int  |
| num_founders          | Number of founders  | int  |
| founders_names        | Full names of the founders  | list  |
| team_size             | Number of employees  | int  |
| website               | Company website   | string  |
| cb_url                | Company Crunchbase url  | string  |
| linkedin_url          | Company LinkedIn url  | string  |

## Meta
Author: Miguel Corral Jr.  
Email: corraljrmiguel@gmail.com  
LinkedIn: https://www.linkedin.com/in/imiguel  
GitHub: https://github.com/corralm",.csv,True
Zoo Animals Extended Dataset,2,zoo-animals-extended-dataset,zoo3.csv,CC0-1.0,"### Context

The <a href=""https://www.kaggle.com/uciml/zoo-animal-classification"">Zoo Animal Classification Dataset</a> originally consists of **101 animals in a zoo** and **16 variables with several features that describe them** (the *attributes*), besides the **class to which each animal belongs** (the *target*).

That original dataset is often used in Machine Learning, as it is a complete and yet simple example to practice **classification problems with multi-label classes**. However, as it provides only a hundred rows, some ML algorithms might not perform well. That is exactly where this **extended dataset** fits in.


### Content

As an addition to the original Zoo Animal Classification Dataset, this given dataset provides:

- **43 animals** from several classes except *Mammals* and *Birds* (as these latter classes are very frequent in the original dataset);
- **70 animals** from species maintained by <a href=""http://www.zoologico.com.br/nossos-animais/"">São Paulo Zoo</a>, being primarily animals of the Brazilian fauna in danger of extinction.
",.csv,True
Zoo Animals Extended Dataset,2,zoo-animals-extended-dataset,zoo2.csv,CC0-1.0,"### Context

The <a href=""https://www.kaggle.com/uciml/zoo-animal-classification"">Zoo Animal Classification Dataset</a> originally consists of **101 animals in a zoo** and **16 variables with several features that describe them** (the *attributes*), besides the **class to which each animal belongs** (the *target*).

That original dataset is often used in Machine Learning, as it is a complete and yet simple example to practice **classification problems with multi-label classes**. However, as it provides only a hundred rows, some ML algorithms might not perform well. That is exactly where this **extended dataset** fits in.


### Content

As an addition to the original Zoo Animal Classification Dataset, this given dataset provides:

- **43 animals** from several classes except *Mammals* and *Birds* (as these latter classes are very frequent in the original dataset);
- **70 animals** from species maintained by <a href=""http://www.zoologico.com.br/nossos-animais/"">São Paulo Zoo</a>, being primarily animals of the Brazilian fauna in danger of extinction.
",.csv,True
ebay_product_Xbox,3,ebay-product-xbox,Xbox 7-day auctions.csv,Community Data License Agreement - Sharing - Version 1.0,"File Format
All files are available in comma separated format (CSV).

Data Field Description
auctionid - unique identifier of an auction

bid - the proxy bid placed by a bidder

bidtime - the time (in days) that the bid was placed, from the start of the auction

bidder - eBay username of the bidder

bidderrate - eBay feedback rating of the bidder

openbid - the opening bid set by the seller

price - the closing price that the item sold for (equivalent to the second highest bid + an increment)",.csv,True
ebay_product_Xbox,3,ebay-product-xbox,Xbox 3-day auctions.csv,Community Data License Agreement - Sharing - Version 1.0,"File Format
All files are available in comma separated format (CSV).

Data Field Description
auctionid - unique identifier of an auction

bid - the proxy bid placed by a bidder

bidtime - the time (in days) that the bid was placed, from the start of the auction

bidder - eBay username of the bidder

bidderrate - eBay feedback rating of the bidder

openbid - the opening bid set by the seller

price - the closing price that the item sold for (equivalent to the second highest bid + an increment)",.csv,True
ebay_product_Xbox,3,ebay-product-xbox,Xbox 5-day auctions.csv,Community Data License Agreement - Sharing - Version 1.0,"File Format
All files are available in comma separated format (CSV).

Data Field Description
auctionid - unique identifier of an auction

bid - the proxy bid placed by a bidder

bidtime - the time (in days) that the bid was placed, from the start of the auction

bidder - eBay username of the bidder

bidderrate - eBay feedback rating of the bidder

openbid - the opening bid set by the seller

price - the closing price that the item sold for (equivalent to the second highest bid + an increment)",.csv,True
fake-and-real-news-dataset,2,fake-and-real-news-dataset,Fake.csv,CC-BY-NC-SA-4.0,"# **Fake News detection dataset**
## 
Dataset separated in two files:
1. Fake.csv (23502 fake news article)
2. True.csv (21417 true news article)

Dataset columns:
1. Title: title of news article
2. Text: body text of news article
3. Subject: subject of news article
4. Date: publish date of news article",.csv,True
fake-and-real-news-dataset,2,fake-and-real-news-dataset,True.csv,CC-BY-NC-SA-4.0,"# **Fake News detection dataset**
## 
Dataset separated in two files:
1. Fake.csv (23502 fake news article)
2. True.csv (21417 true news article)

Dataset columns:
1. Title: title of news article
2. Text: body text of news article
3. Subject: subject of news article
4. Date: publish date of news article",.csv,True
wine quality selection,2,wine-quality-selection,winequality-red.csv,DbCL-1.0,"# Context 

There are two datasets with different details. Depending on these details, the quality of the wine is found

# Content

The datasets are uploaded from http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/


# Acknowledgements

We wouldn't be here without the help of others. If you owe any attributions or thanks, include them here along with any citations of past research.


# Inspiration

Your data will be in front of the world's largest data science community. What questions do you want to see answered?",.csv,True
wine quality selection,2,wine-quality-selection,winequality-white.csv,DbCL-1.0,"# Context 

There are two datasets with different details. Depending on these details, the quality of the wine is found

# Content

The datasets are uploaded from http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/


# Acknowledgements

We wouldn't be here without the help of others. If you owe any attributions or thanks, include them here along with any citations of past research.


# Inspiration

Your data will be in front of the world's largest data science community. What questions do you want to see answered?",.csv,True
👛🤑💰 Bitcoin & Ethereum prices (2014-2024),4,bitcoin-and-ethereum-prices-from-start-to-2023,ETH-USD (01-05.2024).csv,CC0-1.0,"**Bitcoin** (abbreviation: BTC) is a protocol which implements a highly available, public, permanent, and decentralized ledger. In order to add to the ledger, a user must prove they control an entry in the ledger. The protocol specifies that the entry indicates an amount of a token, bitcoin with a minuscule b. The user can update the ledger, assigning some of their bitcoin to another entry in the ledger. Because the token has characteristics of money, it can be thought of as a digital currency.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F1d369ac7b6a859b12b355e82e8e6d3b9%2Fbitcoin1-2000-7912c2175848490f99c66fb1a93a77ba-sixteen_nine.avif?generation=1681021547784975&alt=media)

**Ethereum** is a decentralized blockchain with smart contract functionality. Ether (Abbreviation: ETH) is the native cryptocurrency of the platform. Among cryptocurrencies, ether is second only to bitcoin in market capitalization. It is open-source software.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F5356509a535b3203b29df60339c5960c%2Fethereum_tutorial.avif?generation=1681021661033520&alt=media)

Ethereum was conceived in 2013 by programmer Vitalik Buterin.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2Fa100795bc3bd277c498a0a648cedda98%2Fvitalik_buterin_predskazal_defi_i_sovershenno_upustil_iz_vidu_nft.jpg?generation=1681021783757764&alt=media)",.csv,True
👛🤑💰 Bitcoin & Ethereum prices (2014-2024),4,bitcoin-and-ethereum-prices-from-start-to-2023,BTC-USD (2014-2024).csv,CC0-1.0,"**Bitcoin** (abbreviation: BTC) is a protocol which implements a highly available, public, permanent, and decentralized ledger. In order to add to the ledger, a user must prove they control an entry in the ledger. The protocol specifies that the entry indicates an amount of a token, bitcoin with a minuscule b. The user can update the ledger, assigning some of their bitcoin to another entry in the ledger. Because the token has characteristics of money, it can be thought of as a digital currency.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F1d369ac7b6a859b12b355e82e8e6d3b9%2Fbitcoin1-2000-7912c2175848490f99c66fb1a93a77ba-sixteen_nine.avif?generation=1681021547784975&alt=media)

**Ethereum** is a decentralized blockchain with smart contract functionality. Ether (Abbreviation: ETH) is the native cryptocurrency of the platform. Among cryptocurrencies, ether is second only to bitcoin in market capitalization. It is open-source software.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F5356509a535b3203b29df60339c5960c%2Fethereum_tutorial.avif?generation=1681021661033520&alt=media)

Ethereum was conceived in 2013 by programmer Vitalik Buterin.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2Fa100795bc3bd277c498a0a648cedda98%2Fvitalik_buterin_predskazal_defi_i_sovershenno_upustil_iz_vidu_nft.jpg?generation=1681021783757764&alt=media)",.csv,True
👛🤑💰 Bitcoin & Ethereum prices (2014-2024),4,bitcoin-and-ethereum-prices-from-start-to-2023,Bitcoin USD (01-05.2024).csv,CC0-1.0,"**Bitcoin** (abbreviation: BTC) is a protocol which implements a highly available, public, permanent, and decentralized ledger. In order to add to the ledger, a user must prove they control an entry in the ledger. The protocol specifies that the entry indicates an amount of a token, bitcoin with a minuscule b. The user can update the ledger, assigning some of their bitcoin to another entry in the ledger. Because the token has characteristics of money, it can be thought of as a digital currency.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F1d369ac7b6a859b12b355e82e8e6d3b9%2Fbitcoin1-2000-7912c2175848490f99c66fb1a93a77ba-sixteen_nine.avif?generation=1681021547784975&alt=media)

**Ethereum** is a decentralized blockchain with smart contract functionality. Ether (Abbreviation: ETH) is the native cryptocurrency of the platform. Among cryptocurrencies, ether is second only to bitcoin in market capitalization. It is open-source software.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F5356509a535b3203b29df60339c5960c%2Fethereum_tutorial.avif?generation=1681021661033520&alt=media)

Ethereum was conceived in 2013 by programmer Vitalik Buterin.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2Fa100795bc3bd277c498a0a648cedda98%2Fvitalik_buterin_predskazal_defi_i_sovershenno_upustil_iz_vidu_nft.jpg?generation=1681021783757764&alt=media)",.csv,True
👛🤑💰 Bitcoin & Ethereum prices (2014-2024),4,bitcoin-and-ethereum-prices-from-start-to-2023,ETH-USD (2017-2024).csv,CC0-1.0,"**Bitcoin** (abbreviation: BTC) is a protocol which implements a highly available, public, permanent, and decentralized ledger. In order to add to the ledger, a user must prove they control an entry in the ledger. The protocol specifies that the entry indicates an amount of a token, bitcoin with a minuscule b. The user can update the ledger, assigning some of their bitcoin to another entry in the ledger. Because the token has characteristics of money, it can be thought of as a digital currency.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F1d369ac7b6a859b12b355e82e8e6d3b9%2Fbitcoin1-2000-7912c2175848490f99c66fb1a93a77ba-sixteen_nine.avif?generation=1681021547784975&alt=media)

**Ethereum** is a decentralized blockchain with smart contract functionality. Ether (Abbreviation: ETH) is the native cryptocurrency of the platform. Among cryptocurrencies, ether is second only to bitcoin in market capitalization. It is open-source software.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F5356509a535b3203b29df60339c5960c%2Fethereum_tutorial.avif?generation=1681021661033520&alt=media)

Ethereum was conceived in 2013 by programmer Vitalik Buterin.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2Fa100795bc3bd277c498a0a648cedda98%2Fvitalik_buterin_predskazal_defi_i_sovershenno_upustil_iz_vidu_nft.jpg?generation=1681021783757764&alt=media)",.csv,True
💤Quality of Sleep😴,3,japanquality-of-sleep,wake-up time.csv,other,"Quality of Sleep in Japan

This survey will give you an idea of the quality of sleep and other information. Please take a look at how much Japanese people are sleeping. We will try to analyze the data so that we can make use of it for something.


",.csv,True
💤Quality of Sleep😴,3,japanquality-of-sleep,bedtime.csv,other,"Quality of Sleep in Japan

This survey will give you an idea of the quality of sleep and other information. Please take a look at how much Japanese people are sleeping. We will try to analyze the data so that we can make use of it for something.


",.csv,True
💤Quality of Sleep😴,3,japanquality-of-sleep,sleepingtime.csv,other,"Quality of Sleep in Japan

This survey will give you an idea of the quality of sleep and other information. Please take a look at how much Japanese people are sleeping. We will try to analyze the data so that we can make use of it for something.


",.csv,True
"💵📈 HP, Lenovo, Acer, Asus and Samsung prices",7,hp-lenovo-acer-asus-samsung-companies-share-prices,Lenovo share prices (2000-2023).csv,other,"# 💰 Share prices of the largest laptop manufacturers in the world (from 2000 to 2024, and HP since 1962)
## 🏭 HP
The Hewlett-Packard Company, commonly shortened to Hewlett-Packard or HP, was an American multinational information technology company headquartered in Palo Alto, California. HP developed and provided a wide variety of hardware components, as well as software and related services to consumers, small and medium-sized businesses (SMBs), and large enterprises, including customers in the government, health, and education sectors. The company was founded in a one-car garage in Palo Alto by Bill Hewlett and David Packard in 1939, and initially produced a line of electronic test and measurement equipment. The HP Garage at 367 Addison Avenue is now designated an official California Historical Landmark, and is marked with a plaque calling it the ""Birthplace of 'Silicon Valley'"".
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F079d29a4e1cfa58ac77220b0bb59d21d%2Fxawulg8upg208ks9tl3fvmptbq38qc1k.jpg?generation=1682086016286249&alt=media)

## 🏭Lenovo

Lenovo Group Limited, often shortened to Lenovo. American-Chinese multinational technology company specializing in designing, manufacturing, and marketing consumer electronics, personal computers, software, business solutions, and related services. Products manufactured by the company include desktop computers, laptops, tablet computers, smartphones, workstations, servers, supercomputers, electronic storage devices, IT management software, and smart televisions. Its best-known brands include its ThinkPad business line of laptop computers (acquired from IBM), the IdeaPad, Yoga, and Legion consumer lines of laptop computers, and the IdeaCentre and ThinkCentre lines of desktop computers. As of 2021, Lenovo is the world's largest personal computer vendor by unit sales.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2Fb0175f114ee003162f0fc24d32ce530d%2F1200px-Lenovo_western_headquarters_(20170707113944).jpg?generation=1682086088894750&alt=media)

## 🏭 Acer 

Acer Inc. is a Taiwanese multinational hardware and electronics corporation specializing in advanced electronics technology, headquartered in Xizhi, New Taipei City. Its products include desktop PCs, laptop PCs (clamshells, 2-in-1s, convertibles and Chromebooks), tablets, servers, storage devices, virtual reality devices, displays, smartphones and peripherals, as well as gaming PCs and accessories under its Predator brand. Acer is the world's 5th-largest PC vendor by unit sales as of September 2022.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F99622a2edafb0ca9421304e08d9758a4%2FAcer-21.jpg?generation=1682086137537313&alt=media)

## 🏭 Asus

ASUSTek Computer Inc. is a Taiwanese multinational computer and phone hardware and electronics company headquartered in Beitou District, Taipei, Taiwan. Its products include desktop computers, laptops, netbooks, mobile phones, networking equipment, monitors, wi-fi routers, projectors, motherboards, graphics cards, optical storage, multimedia products, peripherals, wearables, servers, workstations, and tablet PCs. 
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2Fa732a6925f193663517ae4a504d5a3c5%2F1497084536_asus.jpg?generation=1682086192841220&alt=media)

## 🏭Samsung

Samsung Group, or simply Samsung , is a South Korean multinational manufacturing conglomerate headquartered in Samsung Town, Seoul, South Korea. It comprises numerous affiliated businesses, most of them united under the Samsung brand, and is the largest South Korean chaebol (business conglomerate). As of 2020, Samsung has the eighth highest global brand value.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F2d457aaaade7edcb588d6bcee97b6e8d%2FSamsung-Headquarters_large.jpg?generation=1682086262461742&alt=media)",.csv,True
"💵📈 HP, Lenovo, Acer, Asus and Samsung prices",7,hp-lenovo-acer-asus-samsung-companies-share-prices,Acer (2000-2024).csv,other,"# 💰 Share prices of the largest laptop manufacturers in the world (from 2000 to 2024, and HP since 1962)
## 🏭 HP
The Hewlett-Packard Company, commonly shortened to Hewlett-Packard or HP, was an American multinational information technology company headquartered in Palo Alto, California. HP developed and provided a wide variety of hardware components, as well as software and related services to consumers, small and medium-sized businesses (SMBs), and large enterprises, including customers in the government, health, and education sectors. The company was founded in a one-car garage in Palo Alto by Bill Hewlett and David Packard in 1939, and initially produced a line of electronic test and measurement equipment. The HP Garage at 367 Addison Avenue is now designated an official California Historical Landmark, and is marked with a plaque calling it the ""Birthplace of 'Silicon Valley'"".
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F079d29a4e1cfa58ac77220b0bb59d21d%2Fxawulg8upg208ks9tl3fvmptbq38qc1k.jpg?generation=1682086016286249&alt=media)

## 🏭Lenovo

Lenovo Group Limited, often shortened to Lenovo. American-Chinese multinational technology company specializing in designing, manufacturing, and marketing consumer electronics, personal computers, software, business solutions, and related services. Products manufactured by the company include desktop computers, laptops, tablet computers, smartphones, workstations, servers, supercomputers, electronic storage devices, IT management software, and smart televisions. Its best-known brands include its ThinkPad business line of laptop computers (acquired from IBM), the IdeaPad, Yoga, and Legion consumer lines of laptop computers, and the IdeaCentre and ThinkCentre lines of desktop computers. As of 2021, Lenovo is the world's largest personal computer vendor by unit sales.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2Fb0175f114ee003162f0fc24d32ce530d%2F1200px-Lenovo_western_headquarters_(20170707113944).jpg?generation=1682086088894750&alt=media)

## 🏭 Acer 

Acer Inc. is a Taiwanese multinational hardware and electronics corporation specializing in advanced electronics technology, headquartered in Xizhi, New Taipei City. Its products include desktop PCs, laptop PCs (clamshells, 2-in-1s, convertibles and Chromebooks), tablets, servers, storage devices, virtual reality devices, displays, smartphones and peripherals, as well as gaming PCs and accessories under its Predator brand. Acer is the world's 5th-largest PC vendor by unit sales as of September 2022.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F99622a2edafb0ca9421304e08d9758a4%2FAcer-21.jpg?generation=1682086137537313&alt=media)

## 🏭 Asus

ASUSTek Computer Inc. is a Taiwanese multinational computer and phone hardware and electronics company headquartered in Beitou District, Taipei, Taiwan. Its products include desktop computers, laptops, netbooks, mobile phones, networking equipment, monitors, wi-fi routers, projectors, motherboards, graphics cards, optical storage, multimedia products, peripherals, wearables, servers, workstations, and tablet PCs. 
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2Fa732a6925f193663517ae4a504d5a3c5%2F1497084536_asus.jpg?generation=1682086192841220&alt=media)

## 🏭Samsung

Samsung Group, or simply Samsung , is a South Korean multinational manufacturing conglomerate headquartered in Samsung Town, Seoul, South Korea. It comprises numerous affiliated businesses, most of them united under the Samsung brand, and is the largest South Korean chaebol (business conglomerate). As of 2020, Samsung has the eighth highest global brand value.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F2d457aaaade7edcb588d6bcee97b6e8d%2FSamsung-Headquarters_large.jpg?generation=1682086262461742&alt=media)",.csv,True
"💵📈 HP, Lenovo, Acer, Asus and Samsung prices",7,hp-lenovo-acer-asus-samsung-companies-share-prices,Hewlett Packard Enterprise Company (2015-2024).csv,other,"# 💰 Share prices of the largest laptop manufacturers in the world (from 2000 to 2024, and HP since 1962)
## 🏭 HP
The Hewlett-Packard Company, commonly shortened to Hewlett-Packard or HP, was an American multinational information technology company headquartered in Palo Alto, California. HP developed and provided a wide variety of hardware components, as well as software and related services to consumers, small and medium-sized businesses (SMBs), and large enterprises, including customers in the government, health, and education sectors. The company was founded in a one-car garage in Palo Alto by Bill Hewlett and David Packard in 1939, and initially produced a line of electronic test and measurement equipment. The HP Garage at 367 Addison Avenue is now designated an official California Historical Landmark, and is marked with a plaque calling it the ""Birthplace of 'Silicon Valley'"".
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F079d29a4e1cfa58ac77220b0bb59d21d%2Fxawulg8upg208ks9tl3fvmptbq38qc1k.jpg?generation=1682086016286249&alt=media)

## 🏭Lenovo

Lenovo Group Limited, often shortened to Lenovo. American-Chinese multinational technology company specializing in designing, manufacturing, and marketing consumer electronics, personal computers, software, business solutions, and related services. Products manufactured by the company include desktop computers, laptops, tablet computers, smartphones, workstations, servers, supercomputers, electronic storage devices, IT management software, and smart televisions. Its best-known brands include its ThinkPad business line of laptop computers (acquired from IBM), the IdeaPad, Yoga, and Legion consumer lines of laptop computers, and the IdeaCentre and ThinkCentre lines of desktop computers. As of 2021, Lenovo is the world's largest personal computer vendor by unit sales.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2Fb0175f114ee003162f0fc24d32ce530d%2F1200px-Lenovo_western_headquarters_(20170707113944).jpg?generation=1682086088894750&alt=media)

## 🏭 Acer 

Acer Inc. is a Taiwanese multinational hardware and electronics corporation specializing in advanced electronics technology, headquartered in Xizhi, New Taipei City. Its products include desktop PCs, laptop PCs (clamshells, 2-in-1s, convertibles and Chromebooks), tablets, servers, storage devices, virtual reality devices, displays, smartphones and peripherals, as well as gaming PCs and accessories under its Predator brand. Acer is the world's 5th-largest PC vendor by unit sales as of September 2022.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F99622a2edafb0ca9421304e08d9758a4%2FAcer-21.jpg?generation=1682086137537313&alt=media)

## 🏭 Asus

ASUSTek Computer Inc. is a Taiwanese multinational computer and phone hardware and electronics company headquartered in Beitou District, Taipei, Taiwan. Its products include desktop computers, laptops, netbooks, mobile phones, networking equipment, monitors, wi-fi routers, projectors, motherboards, graphics cards, optical storage, multimedia products, peripherals, wearables, servers, workstations, and tablet PCs. 
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2Fa732a6925f193663517ae4a504d5a3c5%2F1497084536_asus.jpg?generation=1682086192841220&alt=media)

## 🏭Samsung

Samsung Group, or simply Samsung , is a South Korean multinational manufacturing conglomerate headquartered in Samsung Town, Seoul, South Korea. It comprises numerous affiliated businesses, most of them united under the Samsung brand, and is the largest South Korean chaebol (business conglomerate). As of 2020, Samsung has the eighth highest global brand value.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F2d457aaaade7edcb588d6bcee97b6e8d%2FSamsung-Headquarters_large.jpg?generation=1682086262461742&alt=media)",.csv,True
"💵📈 HP, Lenovo, Acer, Asus and Samsung prices",7,hp-lenovo-acer-asus-samsung-companies-share-prices,Lenovo Group Limited (2000-2024).csv,other,"# 💰 Share prices of the largest laptop manufacturers in the world (from 2000 to 2024, and HP since 1962)
## 🏭 HP
The Hewlett-Packard Company, commonly shortened to Hewlett-Packard or HP, was an American multinational information technology company headquartered in Palo Alto, California. HP developed and provided a wide variety of hardware components, as well as software and related services to consumers, small and medium-sized businesses (SMBs), and large enterprises, including customers in the government, health, and education sectors. The company was founded in a one-car garage in Palo Alto by Bill Hewlett and David Packard in 1939, and initially produced a line of electronic test and measurement equipment. The HP Garage at 367 Addison Avenue is now designated an official California Historical Landmark, and is marked with a plaque calling it the ""Birthplace of 'Silicon Valley'"".
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F079d29a4e1cfa58ac77220b0bb59d21d%2Fxawulg8upg208ks9tl3fvmptbq38qc1k.jpg?generation=1682086016286249&alt=media)

## 🏭Lenovo

Lenovo Group Limited, often shortened to Lenovo. American-Chinese multinational technology company specializing in designing, manufacturing, and marketing consumer electronics, personal computers, software, business solutions, and related services. Products manufactured by the company include desktop computers, laptops, tablet computers, smartphones, workstations, servers, supercomputers, electronic storage devices, IT management software, and smart televisions. Its best-known brands include its ThinkPad business line of laptop computers (acquired from IBM), the IdeaPad, Yoga, and Legion consumer lines of laptop computers, and the IdeaCentre and ThinkCentre lines of desktop computers. As of 2021, Lenovo is the world's largest personal computer vendor by unit sales.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2Fb0175f114ee003162f0fc24d32ce530d%2F1200px-Lenovo_western_headquarters_(20170707113944).jpg?generation=1682086088894750&alt=media)

## 🏭 Acer 

Acer Inc. is a Taiwanese multinational hardware and electronics corporation specializing in advanced electronics technology, headquartered in Xizhi, New Taipei City. Its products include desktop PCs, laptop PCs (clamshells, 2-in-1s, convertibles and Chromebooks), tablets, servers, storage devices, virtual reality devices, displays, smartphones and peripherals, as well as gaming PCs and accessories under its Predator brand. Acer is the world's 5th-largest PC vendor by unit sales as of September 2022.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F99622a2edafb0ca9421304e08d9758a4%2FAcer-21.jpg?generation=1682086137537313&alt=media)

## 🏭 Asus

ASUSTek Computer Inc. is a Taiwanese multinational computer and phone hardware and electronics company headquartered in Beitou District, Taipei, Taiwan. Its products include desktop computers, laptops, netbooks, mobile phones, networking equipment, monitors, wi-fi routers, projectors, motherboards, graphics cards, optical storage, multimedia products, peripherals, wearables, servers, workstations, and tablet PCs. 
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2Fa732a6925f193663517ae4a504d5a3c5%2F1497084536_asus.jpg?generation=1682086192841220&alt=media)

## 🏭Samsung

Samsung Group, or simply Samsung , is a South Korean multinational manufacturing conglomerate headquartered in Samsung Town, Seoul, South Korea. It comprises numerous affiliated businesses, most of them united under the Samsung brand, and is the largest South Korean chaebol (business conglomerate). As of 2020, Samsung has the eighth highest global brand value.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F2d457aaaade7edcb588d6bcee97b6e8d%2FSamsung-Headquarters_large.jpg?generation=1682086262461742&alt=media)",.csv,True
"💵📈 HP, Lenovo, Acer, Asus and Samsung prices",7,hp-lenovo-acer-asus-samsung-companies-share-prices,LG Electronics (2023-24).csv,other,"# 💰 Share prices of the largest laptop manufacturers in the world (from 2000 to 2024, and HP since 1962)
## 🏭 HP
The Hewlett-Packard Company, commonly shortened to Hewlett-Packard or HP, was an American multinational information technology company headquartered in Palo Alto, California. HP developed and provided a wide variety of hardware components, as well as software and related services to consumers, small and medium-sized businesses (SMBs), and large enterprises, including customers in the government, health, and education sectors. The company was founded in a one-car garage in Palo Alto by Bill Hewlett and David Packard in 1939, and initially produced a line of electronic test and measurement equipment. The HP Garage at 367 Addison Avenue is now designated an official California Historical Landmark, and is marked with a plaque calling it the ""Birthplace of 'Silicon Valley'"".
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F079d29a4e1cfa58ac77220b0bb59d21d%2Fxawulg8upg208ks9tl3fvmptbq38qc1k.jpg?generation=1682086016286249&alt=media)

## 🏭Lenovo

Lenovo Group Limited, often shortened to Lenovo. American-Chinese multinational technology company specializing in designing, manufacturing, and marketing consumer electronics, personal computers, software, business solutions, and related services. Products manufactured by the company include desktop computers, laptops, tablet computers, smartphones, workstations, servers, supercomputers, electronic storage devices, IT management software, and smart televisions. Its best-known brands include its ThinkPad business line of laptop computers (acquired from IBM), the IdeaPad, Yoga, and Legion consumer lines of laptop computers, and the IdeaCentre and ThinkCentre lines of desktop computers. As of 2021, Lenovo is the world's largest personal computer vendor by unit sales.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2Fb0175f114ee003162f0fc24d32ce530d%2F1200px-Lenovo_western_headquarters_(20170707113944).jpg?generation=1682086088894750&alt=media)

## 🏭 Acer 

Acer Inc. is a Taiwanese multinational hardware and electronics corporation specializing in advanced electronics technology, headquartered in Xizhi, New Taipei City. Its products include desktop PCs, laptop PCs (clamshells, 2-in-1s, convertibles and Chromebooks), tablets, servers, storage devices, virtual reality devices, displays, smartphones and peripherals, as well as gaming PCs and accessories under its Predator brand. Acer is the world's 5th-largest PC vendor by unit sales as of September 2022.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F99622a2edafb0ca9421304e08d9758a4%2FAcer-21.jpg?generation=1682086137537313&alt=media)

## 🏭 Asus

ASUSTek Computer Inc. is a Taiwanese multinational computer and phone hardware and electronics company headquartered in Beitou District, Taipei, Taiwan. Its products include desktop computers, laptops, netbooks, mobile phones, networking equipment, monitors, wi-fi routers, projectors, motherboards, graphics cards, optical storage, multimedia products, peripherals, wearables, servers, workstations, and tablet PCs. 
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2Fa732a6925f193663517ae4a504d5a3c5%2F1497084536_asus.jpg?generation=1682086192841220&alt=media)

## 🏭Samsung

Samsung Group, or simply Samsung , is a South Korean multinational manufacturing conglomerate headquartered in Samsung Town, Seoul, South Korea. It comprises numerous affiliated businesses, most of them united under the Samsung brand, and is the largest South Korean chaebol (business conglomerate). As of 2020, Samsung has the eighth highest global brand value.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F2d457aaaade7edcb588d6bcee97b6e8d%2FSamsung-Headquarters_large.jpg?generation=1682086262461742&alt=media)",.csv,True
"💵📈 HP, Lenovo, Acer, Asus and Samsung prices",7,hp-lenovo-acer-asus-samsung-companies-share-prices,ASUSTeK Computer (2000-2024).csv,other,"# 💰 Share prices of the largest laptop manufacturers in the world (from 2000 to 2024, and HP since 1962)
## 🏭 HP
The Hewlett-Packard Company, commonly shortened to Hewlett-Packard or HP, was an American multinational information technology company headquartered in Palo Alto, California. HP developed and provided a wide variety of hardware components, as well as software and related services to consumers, small and medium-sized businesses (SMBs), and large enterprises, including customers in the government, health, and education sectors. The company was founded in a one-car garage in Palo Alto by Bill Hewlett and David Packard in 1939, and initially produced a line of electronic test and measurement equipment. The HP Garage at 367 Addison Avenue is now designated an official California Historical Landmark, and is marked with a plaque calling it the ""Birthplace of 'Silicon Valley'"".
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F079d29a4e1cfa58ac77220b0bb59d21d%2Fxawulg8upg208ks9tl3fvmptbq38qc1k.jpg?generation=1682086016286249&alt=media)

## 🏭Lenovo

Lenovo Group Limited, often shortened to Lenovo. American-Chinese multinational technology company specializing in designing, manufacturing, and marketing consumer electronics, personal computers, software, business solutions, and related services. Products manufactured by the company include desktop computers, laptops, tablet computers, smartphones, workstations, servers, supercomputers, electronic storage devices, IT management software, and smart televisions. Its best-known brands include its ThinkPad business line of laptop computers (acquired from IBM), the IdeaPad, Yoga, and Legion consumer lines of laptop computers, and the IdeaCentre and ThinkCentre lines of desktop computers. As of 2021, Lenovo is the world's largest personal computer vendor by unit sales.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2Fb0175f114ee003162f0fc24d32ce530d%2F1200px-Lenovo_western_headquarters_(20170707113944).jpg?generation=1682086088894750&alt=media)

## 🏭 Acer 

Acer Inc. is a Taiwanese multinational hardware and electronics corporation specializing in advanced electronics technology, headquartered in Xizhi, New Taipei City. Its products include desktop PCs, laptop PCs (clamshells, 2-in-1s, convertibles and Chromebooks), tablets, servers, storage devices, virtual reality devices, displays, smartphones and peripherals, as well as gaming PCs and accessories under its Predator brand. Acer is the world's 5th-largest PC vendor by unit sales as of September 2022.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F99622a2edafb0ca9421304e08d9758a4%2FAcer-21.jpg?generation=1682086137537313&alt=media)

## 🏭 Asus

ASUSTek Computer Inc. is a Taiwanese multinational computer and phone hardware and electronics company headquartered in Beitou District, Taipei, Taiwan. Its products include desktop computers, laptops, netbooks, mobile phones, networking equipment, monitors, wi-fi routers, projectors, motherboards, graphics cards, optical storage, multimedia products, peripherals, wearables, servers, workstations, and tablet PCs. 
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2Fa732a6925f193663517ae4a504d5a3c5%2F1497084536_asus.jpg?generation=1682086192841220&alt=media)

## 🏭Samsung

Samsung Group, or simply Samsung , is a South Korean multinational manufacturing conglomerate headquartered in Samsung Town, Seoul, South Korea. It comprises numerous affiliated businesses, most of them united under the Samsung brand, and is the largest South Korean chaebol (business conglomerate). As of 2020, Samsung has the eighth highest global brand value.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F2d457aaaade7edcb588d6bcee97b6e8d%2FSamsung-Headquarters_large.jpg?generation=1682086262461742&alt=media)",.csv,True
"💵📈 HP, Lenovo, Acer, Asus and Samsung prices",7,hp-lenovo-acer-asus-samsung-companies-share-prices,HP share prices (1962-2023).csv,other,"# 💰 Share prices of the largest laptop manufacturers in the world (from 2000 to 2024, and HP since 1962)
## 🏭 HP
The Hewlett-Packard Company, commonly shortened to Hewlett-Packard or HP, was an American multinational information technology company headquartered in Palo Alto, California. HP developed and provided a wide variety of hardware components, as well as software and related services to consumers, small and medium-sized businesses (SMBs), and large enterprises, including customers in the government, health, and education sectors. The company was founded in a one-car garage in Palo Alto by Bill Hewlett and David Packard in 1939, and initially produced a line of electronic test and measurement equipment. The HP Garage at 367 Addison Avenue is now designated an official California Historical Landmark, and is marked with a plaque calling it the ""Birthplace of 'Silicon Valley'"".
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F079d29a4e1cfa58ac77220b0bb59d21d%2Fxawulg8upg208ks9tl3fvmptbq38qc1k.jpg?generation=1682086016286249&alt=media)

## 🏭Lenovo

Lenovo Group Limited, often shortened to Lenovo. American-Chinese multinational technology company specializing in designing, manufacturing, and marketing consumer electronics, personal computers, software, business solutions, and related services. Products manufactured by the company include desktop computers, laptops, tablet computers, smartphones, workstations, servers, supercomputers, electronic storage devices, IT management software, and smart televisions. Its best-known brands include its ThinkPad business line of laptop computers (acquired from IBM), the IdeaPad, Yoga, and Legion consumer lines of laptop computers, and the IdeaCentre and ThinkCentre lines of desktop computers. As of 2021, Lenovo is the world's largest personal computer vendor by unit sales.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2Fb0175f114ee003162f0fc24d32ce530d%2F1200px-Lenovo_western_headquarters_(20170707113944).jpg?generation=1682086088894750&alt=media)

## 🏭 Acer 

Acer Inc. is a Taiwanese multinational hardware and electronics corporation specializing in advanced electronics technology, headquartered in Xizhi, New Taipei City. Its products include desktop PCs, laptop PCs (clamshells, 2-in-1s, convertibles and Chromebooks), tablets, servers, storage devices, virtual reality devices, displays, smartphones and peripherals, as well as gaming PCs and accessories under its Predator brand. Acer is the world's 5th-largest PC vendor by unit sales as of September 2022.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F99622a2edafb0ca9421304e08d9758a4%2FAcer-21.jpg?generation=1682086137537313&alt=media)

## 🏭 Asus

ASUSTek Computer Inc. is a Taiwanese multinational computer and phone hardware and electronics company headquartered in Beitou District, Taipei, Taiwan. Its products include desktop computers, laptops, netbooks, mobile phones, networking equipment, monitors, wi-fi routers, projectors, motherboards, graphics cards, optical storage, multimedia products, peripherals, wearables, servers, workstations, and tablet PCs. 
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2Fa732a6925f193663517ae4a504d5a3c5%2F1497084536_asus.jpg?generation=1682086192841220&alt=media)

## 🏭Samsung

Samsung Group, or simply Samsung , is a South Korean multinational manufacturing conglomerate headquartered in Samsung Town, Seoul, South Korea. It comprises numerous affiliated businesses, most of them united under the Samsung brand, and is the largest South Korean chaebol (business conglomerate). As of 2020, Samsung has the eighth highest global brand value.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F2d457aaaade7edcb588d6bcee97b6e8d%2FSamsung-Headquarters_large.jpg?generation=1682086262461742&alt=media)",.csv,True
💻👩🏻‍💻 NVIDIA AMD Intel MSI share prices,9,nvidia-amd-intel-asus-msi-share-prices,INTEL (1980 - 11.07.2023).csv,other,"# Share prices of the top 5 GPU companies:
**NVIDIA** (1999-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F509e854bb7acf621bc041da87161573f%2F1.jpg?generation=1689079494217974&alt=media)

**AMD** (1980-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F5b60d4e38e6c66290409a2cd2742842d%2F2.jpg?generation=1689079507273482&alt=media)

**Intel** (1980-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F6f011aeeab2323d570845d78656abbc6%2F3.jpg?generation=1689079524479899&alt=media)

**ASUS** (2000-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F402cb3f4bc4afa3c5c7cfcab04ba15cf%2F4.jpg?generation=1689079550889434&alt=media)

**Micro-Star International** (2000-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2Faa44d2170a1f119c74cba82ec2802e75%2F5.jpg?generation=1689079562633209&alt=media)",.csv,True
💻👩🏻‍💻 NVIDIA AMD Intel MSI share prices,9,nvidia-amd-intel-asus-msi-share-prices,AMD (2023 - 08.04.2024).csv,other,"# Share prices of the top 5 GPU companies:
**NVIDIA** (1999-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F509e854bb7acf621bc041da87161573f%2F1.jpg?generation=1689079494217974&alt=media)

**AMD** (1980-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F5b60d4e38e6c66290409a2cd2742842d%2F2.jpg?generation=1689079507273482&alt=media)

**Intel** (1980-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F6f011aeeab2323d570845d78656abbc6%2F3.jpg?generation=1689079524479899&alt=media)

**ASUS** (2000-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F402cb3f4bc4afa3c5c7cfcab04ba15cf%2F4.jpg?generation=1689079550889434&alt=media)

**Micro-Star International** (2000-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2Faa44d2170a1f119c74cba82ec2802e75%2F5.jpg?generation=1689079562633209&alt=media)",.csv,True
💻👩🏻‍💻 NVIDIA AMD Intel MSI share prices,9,nvidia-amd-intel-asus-msi-share-prices,NVIDIA (1999 -11.07.2023).csv,other,"# Share prices of the top 5 GPU companies:
**NVIDIA** (1999-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F509e854bb7acf621bc041da87161573f%2F1.jpg?generation=1689079494217974&alt=media)

**AMD** (1980-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F5b60d4e38e6c66290409a2cd2742842d%2F2.jpg?generation=1689079507273482&alt=media)

**Intel** (1980-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F6f011aeeab2323d570845d78656abbc6%2F3.jpg?generation=1689079524479899&alt=media)

**ASUS** (2000-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F402cb3f4bc4afa3c5c7cfcab04ba15cf%2F4.jpg?generation=1689079550889434&alt=media)

**Micro-Star International** (2000-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2Faa44d2170a1f119c74cba82ec2802e75%2F5.jpg?generation=1689079562633209&alt=media)",.csv,True
💻👩🏻‍💻 NVIDIA AMD Intel MSI share prices,9,nvidia-amd-intel-asus-msi-share-prices,Nvidia (2023 - 08.04.2024).csv,other,"# Share prices of the top 5 GPU companies:
**NVIDIA** (1999-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F509e854bb7acf621bc041da87161573f%2F1.jpg?generation=1689079494217974&alt=media)

**AMD** (1980-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F5b60d4e38e6c66290409a2cd2742842d%2F2.jpg?generation=1689079507273482&alt=media)

**Intel** (1980-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F6f011aeeab2323d570845d78656abbc6%2F3.jpg?generation=1689079524479899&alt=media)

**ASUS** (2000-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F402cb3f4bc4afa3c5c7cfcab04ba15cf%2F4.jpg?generation=1689079550889434&alt=media)

**Micro-Star International** (2000-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2Faa44d2170a1f119c74cba82ec2802e75%2F5.jpg?generation=1689079562633209&alt=media)",.csv,True
💻👩🏻‍💻 NVIDIA AMD Intel MSI share prices,9,nvidia-amd-intel-asus-msi-share-prices,Intel (2023 - 08.04.2024).csv,other,"# Share prices of the top 5 GPU companies:
**NVIDIA** (1999-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F509e854bb7acf621bc041da87161573f%2F1.jpg?generation=1689079494217974&alt=media)

**AMD** (1980-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F5b60d4e38e6c66290409a2cd2742842d%2F2.jpg?generation=1689079507273482&alt=media)

**Intel** (1980-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F6f011aeeab2323d570845d78656abbc6%2F3.jpg?generation=1689079524479899&alt=media)

**ASUS** (2000-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F402cb3f4bc4afa3c5c7cfcab04ba15cf%2F4.jpg?generation=1689079550889434&alt=media)

**Micro-Star International** (2000-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2Faa44d2170a1f119c74cba82ec2802e75%2F5.jpg?generation=1689079562633209&alt=media)",.csv,True
💻👩🏻‍💻 NVIDIA AMD Intel MSI share prices,9,nvidia-amd-intel-asus-msi-share-prices,AMD (1980 -11.07.2023).csv,other,"# Share prices of the top 5 GPU companies:
**NVIDIA** (1999-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F509e854bb7acf621bc041da87161573f%2F1.jpg?generation=1689079494217974&alt=media)

**AMD** (1980-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F5b60d4e38e6c66290409a2cd2742842d%2F2.jpg?generation=1689079507273482&alt=media)

**Intel** (1980-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F6f011aeeab2323d570845d78656abbc6%2F3.jpg?generation=1689079524479899&alt=media)

**ASUS** (2000-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F402cb3f4bc4afa3c5c7cfcab04ba15cf%2F4.jpg?generation=1689079550889434&alt=media)

**Micro-Star International** (2000-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2Faa44d2170a1f119c74cba82ec2802e75%2F5.jpg?generation=1689079562633209&alt=media)",.csv,True
💻👩🏻‍💻 NVIDIA AMD Intel MSI share prices,9,nvidia-amd-intel-asus-msi-share-prices,ASUS (2000 - 11.07.2023).csv,other,"# Share prices of the top 5 GPU companies:
**NVIDIA** (1999-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F509e854bb7acf621bc041da87161573f%2F1.jpg?generation=1689079494217974&alt=media)

**AMD** (1980-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F5b60d4e38e6c66290409a2cd2742842d%2F2.jpg?generation=1689079507273482&alt=media)

**Intel** (1980-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F6f011aeeab2323d570845d78656abbc6%2F3.jpg?generation=1689079524479899&alt=media)

**ASUS** (2000-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F402cb3f4bc4afa3c5c7cfcab04ba15cf%2F4.jpg?generation=1689079550889434&alt=media)

**Micro-Star International** (2000-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2Faa44d2170a1f119c74cba82ec2802e75%2F5.jpg?generation=1689079562633209&alt=media)",.csv,True
💻👩🏻‍💻 NVIDIA AMD Intel MSI share prices,9,nvidia-amd-intel-asus-msi-share-prices,MSI (2023 - 08.04.2024).csv,other,"# Share prices of the top 5 GPU companies:
**NVIDIA** (1999-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F509e854bb7acf621bc041da87161573f%2F1.jpg?generation=1689079494217974&alt=media)

**AMD** (1980-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F5b60d4e38e6c66290409a2cd2742842d%2F2.jpg?generation=1689079507273482&alt=media)

**Intel** (1980-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F6f011aeeab2323d570845d78656abbc6%2F3.jpg?generation=1689079524479899&alt=media)

**ASUS** (2000-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F402cb3f4bc4afa3c5c7cfcab04ba15cf%2F4.jpg?generation=1689079550889434&alt=media)

**Micro-Star International** (2000-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2Faa44d2170a1f119c74cba82ec2802e75%2F5.jpg?generation=1689079562633209&alt=media)",.csv,True
💻👩🏻‍💻 NVIDIA AMD Intel MSI share prices,9,nvidia-amd-intel-asus-msi-share-prices,ASUS (2023 - 08.04.2024).csv,other,"# Share prices of the top 5 GPU companies:
**NVIDIA** (1999-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F509e854bb7acf621bc041da87161573f%2F1.jpg?generation=1689079494217974&alt=media)

**AMD** (1980-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F5b60d4e38e6c66290409a2cd2742842d%2F2.jpg?generation=1689079507273482&alt=media)

**Intel** (1980-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F6f011aeeab2323d570845d78656abbc6%2F3.jpg?generation=1689079524479899&alt=media)

**ASUS** (2000-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F402cb3f4bc4afa3c5c7cfcab04ba15cf%2F4.jpg?generation=1689079550889434&alt=media)

**Micro-Star International** (2000-2024 share prices)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2Faa44d2170a1f119c74cba82ec2802e75%2F5.jpg?generation=1689079562633209&alt=media)",.csv,True
📈💸 MAANG share prices till May 2024 😎🧑‍💻,10,maang-share-prices-till-february-2024,Amazon.com Inc. (AMZN) (1998-02.2024).csv,CC0-1.0,"# 🏦 Share prices of technological giants: Meta, Apple, Amazon, Netflix and Google till February 2024

## Meta (share prices since 2013 - 02.2024)
Meta Platforms, Inc., doing business as Meta, and formerly named Facebook, Inc., and The Facebook, Inc., is an American multinational technology conglomerate based in Menlo Park, California. The company owns and operates Facebook, Instagram, Threads, and WhatsApp, among other products and services. Meta ranks among the largest American information technology companies, alongside other Big Five corporations Alphabet (Google), Amazon, Apple, and Microsoft. The company was ranked #31 on the Forbes Global 2000 ranking in 2023.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F0092cfb5e21b4649fead60c2b969b799%2Fmeta.webp?generation=1708923032286895&alt=media)

## Apple (share prices since 1981 - 02.2024)
Apple Inc. (formerly Apple Computer, Inc.) is an American multinational technology company headquartered in Cupertino, California, in Silicon Valley. It designs, develops, and sells consumer electronics, computer software, and online services. Devices include the iPhone, iPad, Mac, Apple Watch, and Apple TV; operating systems include iOS, iPadOS, and macOS; and software applications and services include iTunes, iCloud, and Apple Music.

As of March 2023, Apple was the world's largest company by market capitalization, but it lost this position to Microsoft in January 2024. In 2022, it was the largest technology company by revenue, with US$394.3 billion. As of June 2022, Apple was the fourth-largest personal computer vendor by unit sales, the largest manufacturing company by revenue, and the second-largest manufacturer of mobile phones in the world. It is one of the Big Five American information technology companies, alongside Alphabet (the parent company of Google), Amazon, Meta (the parent company of Facebook), and Microsoft.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F355fd858e8cf894c85d34012937de7cb%2Fmaxresdefault.jpg?generation=1708925753123441&alt=media)

## Amazon (share prices since 1998 - 02.2024)
Amazon.com, Inc., doing business as Amazon, is an American multinational technology company focusing on e-commerce, cloud computing, online advertising, digital streaming, and artificial intelligence. It is considered one of the Big Five Am![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F8c7eaaa939f4afa87230e4cfc7a73965%2F02.webp?generation=1708925895528644&alt=media)erican technology companies; the other four are Alphabet (parent company of Google), Apple, Meta (parent company of Facebook), and Microsoft.

## Netflix (share prices since 2003 - 02.2024)
Netflix is an American subscription video on-demand over-the-top streaming service. The service primarily distributes original and acquired films and television shows from various genres, and it is available internationally in multiple languages.

Launched on January 16, 2007, nearly a decade after Netflix, Inc. began its pioneering DVD‑by‑mail movie rental service, Netflix is the most-subscribed video on demand streaming media service, with 260.28 million paid memberships in more than 190 countries as of January 2024. By 2022, ""Netflix Original"" productions accounted for half of its library in the United States and the namesake company had ventured into other categories, such as video game publishing of mobile games via its flagship service. As of October 2023, Netflix is the 24th most-visited website in the world with 23.66% of its traffic coming from the United States, followed by the United Kingdom at 5.84% and Brazil at 5.64%.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F98710ac371805da8047b14bbd5f73b2e%2Fhppsunsetbronsonicon_1200xx4905-2759-184-0.jpg?generation=1708926012776496&alt=media)

## Google (share prices since 2005 - 02.2024)
Google LLC (Alphabet Inc.) is an American multinational technology company focusing on artificial intelligence, online advertising, search engine technology, cloud computing, computer software, quantum computing, e-commerce, and consumer electronics. It has been referred to as ""the most powerful company in the world"" and as one of the world's most valuable brands due to its market dominance, data collection, and technological advantages in the field of artificial intelligence. Google's parent company Alphabet Inc. is one of the five Big Tech companies, alongside Amazon, Apple, Meta, and Microsoft.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F86a517c27caafb1d081b4facc0752a9d%2FGoogle%20HQ.jpg?generation=1708926639236016&alt=media)",.csv,True
📈💸 MAANG share prices till May 2024 😎🧑‍💻,10,maang-share-prices-till-february-2024,Meta Platforms Inc. (META) (2013-02.2024).csv,CC0-1.0,"# 🏦 Share prices of technological giants: Meta, Apple, Amazon, Netflix and Google till February 2024

## Meta (share prices since 2013 - 02.2024)
Meta Platforms, Inc., doing business as Meta, and formerly named Facebook, Inc., and The Facebook, Inc., is an American multinational technology conglomerate based in Menlo Park, California. The company owns and operates Facebook, Instagram, Threads, and WhatsApp, among other products and services. Meta ranks among the largest American information technology companies, alongside other Big Five corporations Alphabet (Google), Amazon, Apple, and Microsoft. The company was ranked #31 on the Forbes Global 2000 ranking in 2023.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F0092cfb5e21b4649fead60c2b969b799%2Fmeta.webp?generation=1708923032286895&alt=media)

## Apple (share prices since 1981 - 02.2024)
Apple Inc. (formerly Apple Computer, Inc.) is an American multinational technology company headquartered in Cupertino, California, in Silicon Valley. It designs, develops, and sells consumer electronics, computer software, and online services. Devices include the iPhone, iPad, Mac, Apple Watch, and Apple TV; operating systems include iOS, iPadOS, and macOS; and software applications and services include iTunes, iCloud, and Apple Music.

As of March 2023, Apple was the world's largest company by market capitalization, but it lost this position to Microsoft in January 2024. In 2022, it was the largest technology company by revenue, with US$394.3 billion. As of June 2022, Apple was the fourth-largest personal computer vendor by unit sales, the largest manufacturing company by revenue, and the second-largest manufacturer of mobile phones in the world. It is one of the Big Five American information technology companies, alongside Alphabet (the parent company of Google), Amazon, Meta (the parent company of Facebook), and Microsoft.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F355fd858e8cf894c85d34012937de7cb%2Fmaxresdefault.jpg?generation=1708925753123441&alt=media)

## Amazon (share prices since 1998 - 02.2024)
Amazon.com, Inc., doing business as Amazon, is an American multinational technology company focusing on e-commerce, cloud computing, online advertising, digital streaming, and artificial intelligence. It is considered one of the Big Five Am![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F8c7eaaa939f4afa87230e4cfc7a73965%2F02.webp?generation=1708925895528644&alt=media)erican technology companies; the other four are Alphabet (parent company of Google), Apple, Meta (parent company of Facebook), and Microsoft.

## Netflix (share prices since 2003 - 02.2024)
Netflix is an American subscription video on-demand over-the-top streaming service. The service primarily distributes original and acquired films and television shows from various genres, and it is available internationally in multiple languages.

Launched on January 16, 2007, nearly a decade after Netflix, Inc. began its pioneering DVD‑by‑mail movie rental service, Netflix is the most-subscribed video on demand streaming media service, with 260.28 million paid memberships in more than 190 countries as of January 2024. By 2022, ""Netflix Original"" productions accounted for half of its library in the United States and the namesake company had ventured into other categories, such as video game publishing of mobile games via its flagship service. As of October 2023, Netflix is the 24th most-visited website in the world with 23.66% of its traffic coming from the United States, followed by the United Kingdom at 5.84% and Brazil at 5.64%.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F98710ac371805da8047b14bbd5f73b2e%2Fhppsunsetbronsonicon_1200xx4905-2759-184-0.jpg?generation=1708926012776496&alt=media)

## Google (share prices since 2005 - 02.2024)
Google LLC (Alphabet Inc.) is an American multinational technology company focusing on artificial intelligence, online advertising, search engine technology, cloud computing, computer software, quantum computing, e-commerce, and consumer electronics. It has been referred to as ""the most powerful company in the world"" and as one of the world's most valuable brands due to its market dominance, data collection, and technological advantages in the field of artificial intelligence. Google's parent company Alphabet Inc. is one of the five Big Tech companies, alongside Amazon, Apple, Meta, and Microsoft.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F86a517c27caafb1d081b4facc0752a9d%2FGoogle%20HQ.jpg?generation=1708926639236016&alt=media)",.csv,True
📈💸 MAANG share prices till May 2024 😎🧑‍💻,10,maang-share-prices-till-february-2024,Alphabet Inc. (GOOG) (2005-02.2024).csv,CC0-1.0,"# 🏦 Share prices of technological giants: Meta, Apple, Amazon, Netflix and Google till February 2024

## Meta (share prices since 2013 - 02.2024)
Meta Platforms, Inc., doing business as Meta, and formerly named Facebook, Inc., and The Facebook, Inc., is an American multinational technology conglomerate based in Menlo Park, California. The company owns and operates Facebook, Instagram, Threads, and WhatsApp, among other products and services. Meta ranks among the largest American information technology companies, alongside other Big Five corporations Alphabet (Google), Amazon, Apple, and Microsoft. The company was ranked #31 on the Forbes Global 2000 ranking in 2023.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F0092cfb5e21b4649fead60c2b969b799%2Fmeta.webp?generation=1708923032286895&alt=media)

## Apple (share prices since 1981 - 02.2024)
Apple Inc. (formerly Apple Computer, Inc.) is an American multinational technology company headquartered in Cupertino, California, in Silicon Valley. It designs, develops, and sells consumer electronics, computer software, and online services. Devices include the iPhone, iPad, Mac, Apple Watch, and Apple TV; operating systems include iOS, iPadOS, and macOS; and software applications and services include iTunes, iCloud, and Apple Music.

As of March 2023, Apple was the world's largest company by market capitalization, but it lost this position to Microsoft in January 2024. In 2022, it was the largest technology company by revenue, with US$394.3 billion. As of June 2022, Apple was the fourth-largest personal computer vendor by unit sales, the largest manufacturing company by revenue, and the second-largest manufacturer of mobile phones in the world. It is one of the Big Five American information technology companies, alongside Alphabet (the parent company of Google), Amazon, Meta (the parent company of Facebook), and Microsoft.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F355fd858e8cf894c85d34012937de7cb%2Fmaxresdefault.jpg?generation=1708925753123441&alt=media)

## Amazon (share prices since 1998 - 02.2024)
Amazon.com, Inc., doing business as Amazon, is an American multinational technology company focusing on e-commerce, cloud computing, online advertising, digital streaming, and artificial intelligence. It is considered one of the Big Five Am![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F8c7eaaa939f4afa87230e4cfc7a73965%2F02.webp?generation=1708925895528644&alt=media)erican technology companies; the other four are Alphabet (parent company of Google), Apple, Meta (parent company of Facebook), and Microsoft.

## Netflix (share prices since 2003 - 02.2024)
Netflix is an American subscription video on-demand over-the-top streaming service. The service primarily distributes original and acquired films and television shows from various genres, and it is available internationally in multiple languages.

Launched on January 16, 2007, nearly a decade after Netflix, Inc. began its pioneering DVD‑by‑mail movie rental service, Netflix is the most-subscribed video on demand streaming media service, with 260.28 million paid memberships in more than 190 countries as of January 2024. By 2022, ""Netflix Original"" productions accounted for half of its library in the United States and the namesake company had ventured into other categories, such as video game publishing of mobile games via its flagship service. As of October 2023, Netflix is the 24th most-visited website in the world with 23.66% of its traffic coming from the United States, followed by the United Kingdom at 5.84% and Brazil at 5.64%.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F98710ac371805da8047b14bbd5f73b2e%2Fhppsunsetbronsonicon_1200xx4905-2759-184-0.jpg?generation=1708926012776496&alt=media)

## Google (share prices since 2005 - 02.2024)
Google LLC (Alphabet Inc.) is an American multinational technology company focusing on artificial intelligence, online advertising, search engine technology, cloud computing, computer software, quantum computing, e-commerce, and consumer electronics. It has been referred to as ""the most powerful company in the world"" and as one of the world's most valuable brands due to its market dominance, data collection, and technological advantages in the field of artificial intelligence. Google's parent company Alphabet Inc. is one of the five Big Tech companies, alongside Amazon, Apple, Meta, and Microsoft.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F86a517c27caafb1d081b4facc0752a9d%2FGoogle%20HQ.jpg?generation=1708926639236016&alt=media)",.csv,True
📈💸 MAANG share prices till May 2024 😎🧑‍💻,10,maang-share-prices-till-february-2024,Netflix Inc. (24.02.2024-02.05.2024).csv,CC0-1.0,"# 🏦 Share prices of technological giants: Meta, Apple, Amazon, Netflix and Google till February 2024

## Meta (share prices since 2013 - 02.2024)
Meta Platforms, Inc., doing business as Meta, and formerly named Facebook, Inc., and The Facebook, Inc., is an American multinational technology conglomerate based in Menlo Park, California. The company owns and operates Facebook, Instagram, Threads, and WhatsApp, among other products and services. Meta ranks among the largest American information technology companies, alongside other Big Five corporations Alphabet (Google), Amazon, Apple, and Microsoft. The company was ranked #31 on the Forbes Global 2000 ranking in 2023.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F0092cfb5e21b4649fead60c2b969b799%2Fmeta.webp?generation=1708923032286895&alt=media)

## Apple (share prices since 1981 - 02.2024)
Apple Inc. (formerly Apple Computer, Inc.) is an American multinational technology company headquartered in Cupertino, California, in Silicon Valley. It designs, develops, and sells consumer electronics, computer software, and online services. Devices include the iPhone, iPad, Mac, Apple Watch, and Apple TV; operating systems include iOS, iPadOS, and macOS; and software applications and services include iTunes, iCloud, and Apple Music.

As of March 2023, Apple was the world's largest company by market capitalization, but it lost this position to Microsoft in January 2024. In 2022, it was the largest technology company by revenue, with US$394.3 billion. As of June 2022, Apple was the fourth-largest personal computer vendor by unit sales, the largest manufacturing company by revenue, and the second-largest manufacturer of mobile phones in the world. It is one of the Big Five American information technology companies, alongside Alphabet (the parent company of Google), Amazon, Meta (the parent company of Facebook), and Microsoft.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F355fd858e8cf894c85d34012937de7cb%2Fmaxresdefault.jpg?generation=1708925753123441&alt=media)

## Amazon (share prices since 1998 - 02.2024)
Amazon.com, Inc., doing business as Amazon, is an American multinational technology company focusing on e-commerce, cloud computing, online advertising, digital streaming, and artificial intelligence. It is considered one of the Big Five Am![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F8c7eaaa939f4afa87230e4cfc7a73965%2F02.webp?generation=1708925895528644&alt=media)erican technology companies; the other four are Alphabet (parent company of Google), Apple, Meta (parent company of Facebook), and Microsoft.

## Netflix (share prices since 2003 - 02.2024)
Netflix is an American subscription video on-demand over-the-top streaming service. The service primarily distributes original and acquired films and television shows from various genres, and it is available internationally in multiple languages.

Launched on January 16, 2007, nearly a decade after Netflix, Inc. began its pioneering DVD‑by‑mail movie rental service, Netflix is the most-subscribed video on demand streaming media service, with 260.28 million paid memberships in more than 190 countries as of January 2024. By 2022, ""Netflix Original"" productions accounted for half of its library in the United States and the namesake company had ventured into other categories, such as video game publishing of mobile games via its flagship service. As of October 2023, Netflix is the 24th most-visited website in the world with 23.66% of its traffic coming from the United States, followed by the United Kingdom at 5.84% and Brazil at 5.64%.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F98710ac371805da8047b14bbd5f73b2e%2Fhppsunsetbronsonicon_1200xx4905-2759-184-0.jpg?generation=1708926012776496&alt=media)

## Google (share prices since 2005 - 02.2024)
Google LLC (Alphabet Inc.) is an American multinational technology company focusing on artificial intelligence, online advertising, search engine technology, cloud computing, computer software, quantum computing, e-commerce, and consumer electronics. It has been referred to as ""the most powerful company in the world"" and as one of the world's most valuable brands due to its market dominance, data collection, and technological advantages in the field of artificial intelligence. Google's parent company Alphabet Inc. is one of the five Big Tech companies, alongside Amazon, Apple, Meta, and Microsoft.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F86a517c27caafb1d081b4facc0752a9d%2FGoogle%20HQ.jpg?generation=1708926639236016&alt=media)",.csv,True
📈💸 MAANG share prices till May 2024 😎🧑‍💻,10,maang-share-prices-till-february-2024,Amazon.com Inc. (24.02.2024-02.05.2024).csv,CC0-1.0,"# 🏦 Share prices of technological giants: Meta, Apple, Amazon, Netflix and Google till February 2024

## Meta (share prices since 2013 - 02.2024)
Meta Platforms, Inc., doing business as Meta, and formerly named Facebook, Inc., and The Facebook, Inc., is an American multinational technology conglomerate based in Menlo Park, California. The company owns and operates Facebook, Instagram, Threads, and WhatsApp, among other products and services. Meta ranks among the largest American information technology companies, alongside other Big Five corporations Alphabet (Google), Amazon, Apple, and Microsoft. The company was ranked #31 on the Forbes Global 2000 ranking in 2023.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F0092cfb5e21b4649fead60c2b969b799%2Fmeta.webp?generation=1708923032286895&alt=media)

## Apple (share prices since 1981 - 02.2024)
Apple Inc. (formerly Apple Computer, Inc.) is an American multinational technology company headquartered in Cupertino, California, in Silicon Valley. It designs, develops, and sells consumer electronics, computer software, and online services. Devices include the iPhone, iPad, Mac, Apple Watch, and Apple TV; operating systems include iOS, iPadOS, and macOS; and software applications and services include iTunes, iCloud, and Apple Music.

As of March 2023, Apple was the world's largest company by market capitalization, but it lost this position to Microsoft in January 2024. In 2022, it was the largest technology company by revenue, with US$394.3 billion. As of June 2022, Apple was the fourth-largest personal computer vendor by unit sales, the largest manufacturing company by revenue, and the second-largest manufacturer of mobile phones in the world. It is one of the Big Five American information technology companies, alongside Alphabet (the parent company of Google), Amazon, Meta (the parent company of Facebook), and Microsoft.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F355fd858e8cf894c85d34012937de7cb%2Fmaxresdefault.jpg?generation=1708925753123441&alt=media)

## Amazon (share prices since 1998 - 02.2024)
Amazon.com, Inc., doing business as Amazon, is an American multinational technology company focusing on e-commerce, cloud computing, online advertising, digital streaming, and artificial intelligence. It is considered one of the Big Five Am![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F8c7eaaa939f4afa87230e4cfc7a73965%2F02.webp?generation=1708925895528644&alt=media)erican technology companies; the other four are Alphabet (parent company of Google), Apple, Meta (parent company of Facebook), and Microsoft.

## Netflix (share prices since 2003 - 02.2024)
Netflix is an American subscription video on-demand over-the-top streaming service. The service primarily distributes original and acquired films and television shows from various genres, and it is available internationally in multiple languages.

Launched on January 16, 2007, nearly a decade after Netflix, Inc. began its pioneering DVD‑by‑mail movie rental service, Netflix is the most-subscribed video on demand streaming media service, with 260.28 million paid memberships in more than 190 countries as of January 2024. By 2022, ""Netflix Original"" productions accounted for half of its library in the United States and the namesake company had ventured into other categories, such as video game publishing of mobile games via its flagship service. As of October 2023, Netflix is the 24th most-visited website in the world with 23.66% of its traffic coming from the United States, followed by the United Kingdom at 5.84% and Brazil at 5.64%.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F98710ac371805da8047b14bbd5f73b2e%2Fhppsunsetbronsonicon_1200xx4905-2759-184-0.jpg?generation=1708926012776496&alt=media)

## Google (share prices since 2005 - 02.2024)
Google LLC (Alphabet Inc.) is an American multinational technology company focusing on artificial intelligence, online advertising, search engine technology, cloud computing, computer software, quantum computing, e-commerce, and consumer electronics. It has been referred to as ""the most powerful company in the world"" and as one of the world's most valuable brands due to its market dominance, data collection, and technological advantages in the field of artificial intelligence. Google's parent company Alphabet Inc. is one of the five Big Tech companies, alongside Amazon, Apple, Meta, and Microsoft.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F86a517c27caafb1d081b4facc0752a9d%2FGoogle%20HQ.jpg?generation=1708926639236016&alt=media)",.csv,True
📈💸 MAANG share prices till May 2024 😎🧑‍💻,10,maang-share-prices-till-february-2024,Alphabet Inc. (24.02.2024-02.05.2024).csv,CC0-1.0,"# 🏦 Share prices of technological giants: Meta, Apple, Amazon, Netflix and Google till February 2024

## Meta (share prices since 2013 - 02.2024)
Meta Platforms, Inc., doing business as Meta, and formerly named Facebook, Inc., and The Facebook, Inc., is an American multinational technology conglomerate based in Menlo Park, California. The company owns and operates Facebook, Instagram, Threads, and WhatsApp, among other products and services. Meta ranks among the largest American information technology companies, alongside other Big Five corporations Alphabet (Google), Amazon, Apple, and Microsoft. The company was ranked #31 on the Forbes Global 2000 ranking in 2023.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F0092cfb5e21b4649fead60c2b969b799%2Fmeta.webp?generation=1708923032286895&alt=media)

## Apple (share prices since 1981 - 02.2024)
Apple Inc. (formerly Apple Computer, Inc.) is an American multinational technology company headquartered in Cupertino, California, in Silicon Valley. It designs, develops, and sells consumer electronics, computer software, and online services. Devices include the iPhone, iPad, Mac, Apple Watch, and Apple TV; operating systems include iOS, iPadOS, and macOS; and software applications and services include iTunes, iCloud, and Apple Music.

As of March 2023, Apple was the world's largest company by market capitalization, but it lost this position to Microsoft in January 2024. In 2022, it was the largest technology company by revenue, with US$394.3 billion. As of June 2022, Apple was the fourth-largest personal computer vendor by unit sales, the largest manufacturing company by revenue, and the second-largest manufacturer of mobile phones in the world. It is one of the Big Five American information technology companies, alongside Alphabet (the parent company of Google), Amazon, Meta (the parent company of Facebook), and Microsoft.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F355fd858e8cf894c85d34012937de7cb%2Fmaxresdefault.jpg?generation=1708925753123441&alt=media)

## Amazon (share prices since 1998 - 02.2024)
Amazon.com, Inc., doing business as Amazon, is an American multinational technology company focusing on e-commerce, cloud computing, online advertising, digital streaming, and artificial intelligence. It is considered one of the Big Five Am![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F8c7eaaa939f4afa87230e4cfc7a73965%2F02.webp?generation=1708925895528644&alt=media)erican technology companies; the other four are Alphabet (parent company of Google), Apple, Meta (parent company of Facebook), and Microsoft.

## Netflix (share prices since 2003 - 02.2024)
Netflix is an American subscription video on-demand over-the-top streaming service. The service primarily distributes original and acquired films and television shows from various genres, and it is available internationally in multiple languages.

Launched on January 16, 2007, nearly a decade after Netflix, Inc. began its pioneering DVD‑by‑mail movie rental service, Netflix is the most-subscribed video on demand streaming media service, with 260.28 million paid memberships in more than 190 countries as of January 2024. By 2022, ""Netflix Original"" productions accounted for half of its library in the United States and the namesake company had ventured into other categories, such as video game publishing of mobile games via its flagship service. As of October 2023, Netflix is the 24th most-visited website in the world with 23.66% of its traffic coming from the United States, followed by the United Kingdom at 5.84% and Brazil at 5.64%.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F98710ac371805da8047b14bbd5f73b2e%2Fhppsunsetbronsonicon_1200xx4905-2759-184-0.jpg?generation=1708926012776496&alt=media)

## Google (share prices since 2005 - 02.2024)
Google LLC (Alphabet Inc.) is an American multinational technology company focusing on artificial intelligence, online advertising, search engine technology, cloud computing, computer software, quantum computing, e-commerce, and consumer electronics. It has been referred to as ""the most powerful company in the world"" and as one of the world's most valuable brands due to its market dominance, data collection, and technological advantages in the field of artificial intelligence. Google's parent company Alphabet Inc. is one of the five Big Tech companies, alongside Amazon, Apple, Meta, and Microsoft.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F86a517c27caafb1d081b4facc0752a9d%2FGoogle%20HQ.jpg?generation=1708926639236016&alt=media)",.csv,True
📈💸 MAANG share prices till May 2024 😎🧑‍💻,10,maang-share-prices-till-february-2024,Apple Inc. (AAPL) (1981-02.2024).csv,CC0-1.0,"# 🏦 Share prices of technological giants: Meta, Apple, Amazon, Netflix and Google till February 2024

## Meta (share prices since 2013 - 02.2024)
Meta Platforms, Inc., doing business as Meta, and formerly named Facebook, Inc., and The Facebook, Inc., is an American multinational technology conglomerate based in Menlo Park, California. The company owns and operates Facebook, Instagram, Threads, and WhatsApp, among other products and services. Meta ranks among the largest American information technology companies, alongside other Big Five corporations Alphabet (Google), Amazon, Apple, and Microsoft. The company was ranked #31 on the Forbes Global 2000 ranking in 2023.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F0092cfb5e21b4649fead60c2b969b799%2Fmeta.webp?generation=1708923032286895&alt=media)

## Apple (share prices since 1981 - 02.2024)
Apple Inc. (formerly Apple Computer, Inc.) is an American multinational technology company headquartered in Cupertino, California, in Silicon Valley. It designs, develops, and sells consumer electronics, computer software, and online services. Devices include the iPhone, iPad, Mac, Apple Watch, and Apple TV; operating systems include iOS, iPadOS, and macOS; and software applications and services include iTunes, iCloud, and Apple Music.

As of March 2023, Apple was the world's largest company by market capitalization, but it lost this position to Microsoft in January 2024. In 2022, it was the largest technology company by revenue, with US$394.3 billion. As of June 2022, Apple was the fourth-largest personal computer vendor by unit sales, the largest manufacturing company by revenue, and the second-largest manufacturer of mobile phones in the world. It is one of the Big Five American information technology companies, alongside Alphabet (the parent company of Google), Amazon, Meta (the parent company of Facebook), and Microsoft.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F355fd858e8cf894c85d34012937de7cb%2Fmaxresdefault.jpg?generation=1708925753123441&alt=media)

## Amazon (share prices since 1998 - 02.2024)
Amazon.com, Inc., doing business as Amazon, is an American multinational technology company focusing on e-commerce, cloud computing, online advertising, digital streaming, and artificial intelligence. It is considered one of the Big Five Am![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F8c7eaaa939f4afa87230e4cfc7a73965%2F02.webp?generation=1708925895528644&alt=media)erican technology companies; the other four are Alphabet (parent company of Google), Apple, Meta (parent company of Facebook), and Microsoft.

## Netflix (share prices since 2003 - 02.2024)
Netflix is an American subscription video on-demand over-the-top streaming service. The service primarily distributes original and acquired films and television shows from various genres, and it is available internationally in multiple languages.

Launched on January 16, 2007, nearly a decade after Netflix, Inc. began its pioneering DVD‑by‑mail movie rental service, Netflix is the most-subscribed video on demand streaming media service, with 260.28 million paid memberships in more than 190 countries as of January 2024. By 2022, ""Netflix Original"" productions accounted for half of its library in the United States and the namesake company had ventured into other categories, such as video game publishing of mobile games via its flagship service. As of October 2023, Netflix is the 24th most-visited website in the world with 23.66% of its traffic coming from the United States, followed by the United Kingdom at 5.84% and Brazil at 5.64%.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F98710ac371805da8047b14bbd5f73b2e%2Fhppsunsetbronsonicon_1200xx4905-2759-184-0.jpg?generation=1708926012776496&alt=media)

## Google (share prices since 2005 - 02.2024)
Google LLC (Alphabet Inc.) is an American multinational technology company focusing on artificial intelligence, online advertising, search engine technology, cloud computing, computer software, quantum computing, e-commerce, and consumer electronics. It has been referred to as ""the most powerful company in the world"" and as one of the world's most valuable brands due to its market dominance, data collection, and technological advantages in the field of artificial intelligence. Google's parent company Alphabet Inc. is one of the five Big Tech companies, alongside Amazon, Apple, Meta, and Microsoft.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F86a517c27caafb1d081b4facc0752a9d%2FGoogle%20HQ.jpg?generation=1708926639236016&alt=media)",.csv,True
📈💸 MAANG share prices till May 2024 😎🧑‍💻,10,maang-share-prices-till-february-2024,Netflix Inc. (NFLX) (2003-02.2024).csv,CC0-1.0,"# 🏦 Share prices of technological giants: Meta, Apple, Amazon, Netflix and Google till February 2024

## Meta (share prices since 2013 - 02.2024)
Meta Platforms, Inc., doing business as Meta, and formerly named Facebook, Inc., and The Facebook, Inc., is an American multinational technology conglomerate based in Menlo Park, California. The company owns and operates Facebook, Instagram, Threads, and WhatsApp, among other products and services. Meta ranks among the largest American information technology companies, alongside other Big Five corporations Alphabet (Google), Amazon, Apple, and Microsoft. The company was ranked #31 on the Forbes Global 2000 ranking in 2023.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F0092cfb5e21b4649fead60c2b969b799%2Fmeta.webp?generation=1708923032286895&alt=media)

## Apple (share prices since 1981 - 02.2024)
Apple Inc. (formerly Apple Computer, Inc.) is an American multinational technology company headquartered in Cupertino, California, in Silicon Valley. It designs, develops, and sells consumer electronics, computer software, and online services. Devices include the iPhone, iPad, Mac, Apple Watch, and Apple TV; operating systems include iOS, iPadOS, and macOS; and software applications and services include iTunes, iCloud, and Apple Music.

As of March 2023, Apple was the world's largest company by market capitalization, but it lost this position to Microsoft in January 2024. In 2022, it was the largest technology company by revenue, with US$394.3 billion. As of June 2022, Apple was the fourth-largest personal computer vendor by unit sales, the largest manufacturing company by revenue, and the second-largest manufacturer of mobile phones in the world. It is one of the Big Five American information technology companies, alongside Alphabet (the parent company of Google), Amazon, Meta (the parent company of Facebook), and Microsoft.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F355fd858e8cf894c85d34012937de7cb%2Fmaxresdefault.jpg?generation=1708925753123441&alt=media)

## Amazon (share prices since 1998 - 02.2024)
Amazon.com, Inc., doing business as Amazon, is an American multinational technology company focusing on e-commerce, cloud computing, online advertising, digital streaming, and artificial intelligence. It is considered one of the Big Five Am![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F8c7eaaa939f4afa87230e4cfc7a73965%2F02.webp?generation=1708925895528644&alt=media)erican technology companies; the other four are Alphabet (parent company of Google), Apple, Meta (parent company of Facebook), and Microsoft.

## Netflix (share prices since 2003 - 02.2024)
Netflix is an American subscription video on-demand over-the-top streaming service. The service primarily distributes original and acquired films and television shows from various genres, and it is available internationally in multiple languages.

Launched on January 16, 2007, nearly a decade after Netflix, Inc. began its pioneering DVD‑by‑mail movie rental service, Netflix is the most-subscribed video on demand streaming media service, with 260.28 million paid memberships in more than 190 countries as of January 2024. By 2022, ""Netflix Original"" productions accounted for half of its library in the United States and the namesake company had ventured into other categories, such as video game publishing of mobile games via its flagship service. As of October 2023, Netflix is the 24th most-visited website in the world with 23.66% of its traffic coming from the United States, followed by the United Kingdom at 5.84% and Brazil at 5.64%.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F98710ac371805da8047b14bbd5f73b2e%2Fhppsunsetbronsonicon_1200xx4905-2759-184-0.jpg?generation=1708926012776496&alt=media)

## Google (share prices since 2005 - 02.2024)
Google LLC (Alphabet Inc.) is an American multinational technology company focusing on artificial intelligence, online advertising, search engine technology, cloud computing, computer software, quantum computing, e-commerce, and consumer electronics. It has been referred to as ""the most powerful company in the world"" and as one of the world's most valuable brands due to its market dominance, data collection, and technological advantages in the field of artificial intelligence. Google's parent company Alphabet Inc. is one of the five Big Tech companies, alongside Amazon, Apple, Meta, and Microsoft.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F86a517c27caafb1d081b4facc0752a9d%2FGoogle%20HQ.jpg?generation=1708926639236016&alt=media)",.csv,True
📈💸 MAANG share prices till May 2024 😎🧑‍💻,10,maang-share-prices-till-february-2024,Apple Inc. (24.02.2024-02.05.2024).csv,CC0-1.0,"# 🏦 Share prices of technological giants: Meta, Apple, Amazon, Netflix and Google till February 2024

## Meta (share prices since 2013 - 02.2024)
Meta Platforms, Inc., doing business as Meta, and formerly named Facebook, Inc., and The Facebook, Inc., is an American multinational technology conglomerate based in Menlo Park, California. The company owns and operates Facebook, Instagram, Threads, and WhatsApp, among other products and services. Meta ranks among the largest American information technology companies, alongside other Big Five corporations Alphabet (Google), Amazon, Apple, and Microsoft. The company was ranked #31 on the Forbes Global 2000 ranking in 2023.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F0092cfb5e21b4649fead60c2b969b799%2Fmeta.webp?generation=1708923032286895&alt=media)

## Apple (share prices since 1981 - 02.2024)
Apple Inc. (formerly Apple Computer, Inc.) is an American multinational technology company headquartered in Cupertino, California, in Silicon Valley. It designs, develops, and sells consumer electronics, computer software, and online services. Devices include the iPhone, iPad, Mac, Apple Watch, and Apple TV; operating systems include iOS, iPadOS, and macOS; and software applications and services include iTunes, iCloud, and Apple Music.

As of March 2023, Apple was the world's largest company by market capitalization, but it lost this position to Microsoft in January 2024. In 2022, it was the largest technology company by revenue, with US$394.3 billion. As of June 2022, Apple was the fourth-largest personal computer vendor by unit sales, the largest manufacturing company by revenue, and the second-largest manufacturer of mobile phones in the world. It is one of the Big Five American information technology companies, alongside Alphabet (the parent company of Google), Amazon, Meta (the parent company of Facebook), and Microsoft.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F355fd858e8cf894c85d34012937de7cb%2Fmaxresdefault.jpg?generation=1708925753123441&alt=media)

## Amazon (share prices since 1998 - 02.2024)
Amazon.com, Inc., doing business as Amazon, is an American multinational technology company focusing on e-commerce, cloud computing, online advertising, digital streaming, and artificial intelligence. It is considered one of the Big Five Am![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F8c7eaaa939f4afa87230e4cfc7a73965%2F02.webp?generation=1708925895528644&alt=media)erican technology companies; the other four are Alphabet (parent company of Google), Apple, Meta (parent company of Facebook), and Microsoft.

## Netflix (share prices since 2003 - 02.2024)
Netflix is an American subscription video on-demand over-the-top streaming service. The service primarily distributes original and acquired films and television shows from various genres, and it is available internationally in multiple languages.

Launched on January 16, 2007, nearly a decade after Netflix, Inc. began its pioneering DVD‑by‑mail movie rental service, Netflix is the most-subscribed video on demand streaming media service, with 260.28 million paid memberships in more than 190 countries as of January 2024. By 2022, ""Netflix Original"" productions accounted for half of its library in the United States and the namesake company had ventured into other categories, such as video game publishing of mobile games via its flagship service. As of October 2023, Netflix is the 24th most-visited website in the world with 23.66% of its traffic coming from the United States, followed by the United Kingdom at 5.84% and Brazil at 5.64%.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F98710ac371805da8047b14bbd5f73b2e%2Fhppsunsetbronsonicon_1200xx4905-2759-184-0.jpg?generation=1708926012776496&alt=media)

## Google (share prices since 2005 - 02.2024)
Google LLC (Alphabet Inc.) is an American multinational technology company focusing on artificial intelligence, online advertising, search engine technology, cloud computing, computer software, quantum computing, e-commerce, and consumer electronics. It has been referred to as ""the most powerful company in the world"" and as one of the world's most valuable brands due to its market dominance, data collection, and technological advantages in the field of artificial intelligence. Google's parent company Alphabet Inc. is one of the five Big Tech companies, alongside Amazon, Apple, Meta, and Microsoft.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F86a517c27caafb1d081b4facc0752a9d%2FGoogle%20HQ.jpg?generation=1708926639236016&alt=media)",.csv,True
📈💸 MAANG share prices till May 2024 😎🧑‍💻,10,maang-share-prices-till-february-2024,Meta Platforms Inc. (24.02.2024-02.05.2024).csv,CC0-1.0,"# 🏦 Share prices of technological giants: Meta, Apple, Amazon, Netflix and Google till February 2024

## Meta (share prices since 2013 - 02.2024)
Meta Platforms, Inc., doing business as Meta, and formerly named Facebook, Inc., and The Facebook, Inc., is an American multinational technology conglomerate based in Menlo Park, California. The company owns and operates Facebook, Instagram, Threads, and WhatsApp, among other products and services. Meta ranks among the largest American information technology companies, alongside other Big Five corporations Alphabet (Google), Amazon, Apple, and Microsoft. The company was ranked #31 on the Forbes Global 2000 ranking in 2023.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F0092cfb5e21b4649fead60c2b969b799%2Fmeta.webp?generation=1708923032286895&alt=media)

## Apple (share prices since 1981 - 02.2024)
Apple Inc. (formerly Apple Computer, Inc.) is an American multinational technology company headquartered in Cupertino, California, in Silicon Valley. It designs, develops, and sells consumer electronics, computer software, and online services. Devices include the iPhone, iPad, Mac, Apple Watch, and Apple TV; operating systems include iOS, iPadOS, and macOS; and software applications and services include iTunes, iCloud, and Apple Music.

As of March 2023, Apple was the world's largest company by market capitalization, but it lost this position to Microsoft in January 2024. In 2022, it was the largest technology company by revenue, with US$394.3 billion. As of June 2022, Apple was the fourth-largest personal computer vendor by unit sales, the largest manufacturing company by revenue, and the second-largest manufacturer of mobile phones in the world. It is one of the Big Five American information technology companies, alongside Alphabet (the parent company of Google), Amazon, Meta (the parent company of Facebook), and Microsoft.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F355fd858e8cf894c85d34012937de7cb%2Fmaxresdefault.jpg?generation=1708925753123441&alt=media)

## Amazon (share prices since 1998 - 02.2024)
Amazon.com, Inc., doing business as Amazon, is an American multinational technology company focusing on e-commerce, cloud computing, online advertising, digital streaming, and artificial intelligence. It is considered one of the Big Five Am![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F8c7eaaa939f4afa87230e4cfc7a73965%2F02.webp?generation=1708925895528644&alt=media)erican technology companies; the other four are Alphabet (parent company of Google), Apple, Meta (parent company of Facebook), and Microsoft.

## Netflix (share prices since 2003 - 02.2024)
Netflix is an American subscription video on-demand over-the-top streaming service. The service primarily distributes original and acquired films and television shows from various genres, and it is available internationally in multiple languages.

Launched on January 16, 2007, nearly a decade after Netflix, Inc. began its pioneering DVD‑by‑mail movie rental service, Netflix is the most-subscribed video on demand streaming media service, with 260.28 million paid memberships in more than 190 countries as of January 2024. By 2022, ""Netflix Original"" productions accounted for half of its library in the United States and the namesake company had ventured into other categories, such as video game publishing of mobile games via its flagship service. As of October 2023, Netflix is the 24th most-visited website in the world with 23.66% of its traffic coming from the United States, followed by the United Kingdom at 5.84% and Brazil at 5.64%.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F98710ac371805da8047b14bbd5f73b2e%2Fhppsunsetbronsonicon_1200xx4905-2759-184-0.jpg?generation=1708926012776496&alt=media)

## Google (share prices since 2005 - 02.2024)
Google LLC (Alphabet Inc.) is an American multinational technology company focusing on artificial intelligence, online advertising, search engine technology, cloud computing, computer software, quantum computing, e-commerce, and consumer electronics. It has been referred to as ""the most powerful company in the world"" and as one of the world's most valuable brands due to its market dominance, data collection, and technological advantages in the field of artificial intelligence. Google's parent company Alphabet Inc. is one of the five Big Tech companies, alongside Amazon, Apple, Meta, and Microsoft.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F86a517c27caafb1d081b4facc0752a9d%2FGoogle%20HQ.jpg?generation=1708926639236016&alt=media)",.csv,True
🚤 Boat Price Prediction,2,boat-price-prediction,Boats_No_Price_dataset.csv,other,"This project involves analysis of pricing data for boats listed on BoatTrader.com. Various features of the boats were considered when making this analysis with the aim of building a comprehensive model to explain the variation in boat prices.

# Acknowlegement

Foto von <a href=""https://unsplash.com/de/@rag0zin?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Ivan Ragozin</a> auf <a href=""https://unsplash.com/de/fotos/mann-fahrt-tagsuber-auf-weissem-und-rotem-boot-auf-see-o9oQaOGpLz0?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  
",.csv,True
🚤 Boat Price Prediction,2,boat-price-prediction,Boats_Cleaned_dataset.csv,other,"This project involves analysis of pricing data for boats listed on BoatTrader.com. Various features of the boats were considered when making this analysis with the aim of building a comprehensive model to explain the variation in boat prices.

# Acknowlegement

Foto von <a href=""https://unsplash.com/de/@rag0zin?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Ivan Ragozin</a> auf <a href=""https://unsplash.com/de/fotos/mann-fahrt-tagsuber-auf-weissem-und-rotem-boot-auf-see-o9oQaOGpLz0?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  
",.csv,True
🚨 Fraudulent E-Commerce Transactions 💳,2,fraudulent-e-commerce-transactions,Fraudulent_E-Commerce_Transaction_Data.csv,MIT,"### Description

This synthetic dataset, ""Fraudulent E-Commerce Transactions,"" is designed to simulate transaction data from an e-commerce platform with a focus on fraud detection. It contains a variety of features commonly found in transactional data, with additional attributes specifically engineered to support the development and testing of fraud detection algorithms.

#### Dataset Overview

- **Number of Transactions in Version 1**: 1,472,952
- **Number of Transactions in Version 2**: 23,634
- **Features**: 16
- **Fraudulent Transactions**: Approximately 5%

#### Feature Details

1. **Transaction ID**: A unique identifier for each transaction.
2. **Customer ID**: A unique identifier for each customer.
3. **Transaction Amount**: The total amount of money exchanged in the transaction.
4. **Transaction Date**: The date and time when the transaction took place.
5. **Payment Method**: The method used to complete the transaction (e.g., credit card, PayPal, etc.).
6. **Product Category**: The category of the product involved in the transaction.
7. **Quantity**: The number of products involved in the transaction.
8. **Customer Age**: The age of the customer making the transaction.
9. **Customer Location**: The geographical location of the customer.
10. **Device Used**: The type of device used to make the transaction (e.g., mobile, desktop).
11. **IP Address**: The IP address of the device used for the transaction.
12. **Shipping Address**: The address where the product was shipped.
13. **Billing Address**: The address associated with the payment method.
14. **Is Fraudulent**: A binary indicator of whether the transaction is fraudulent (1 for fraudulent, 0 for legitimate).
15. **Account Age Days**: The age of the customer's account in days at the time of the transaction.
16. **Transaction Hour**: The hour of the day when the transaction occurred.

#### Purpose

The dataset is intended for use in developing and testing machine learning models for fraud detection in e-commerce transactions. It can also be used for exploratory data analysis, feature engineering, and benchmarking fraud detection algorithms.

#### Generation Method

The data is entirely synthetic, generated using Python's `Faker` library and custom logic to simulate realistic transaction patterns and fraudulent scenarios. The dataset is not based on real individuals or transactions and is created for educational and research purposes.

#### Usage

Feel free to use this dataset for data analysis, machine learning projects, or as a benchmark for fraud detection algorithms. If you use this dataset in your research or projects, please provide proper attribution.
",.csv,True
🚨 Fraudulent E-Commerce Transactions 💳,2,fraudulent-e-commerce-transactions,Fraudulent_E-Commerce_Transaction_Data_2.csv,MIT,"### Description

This synthetic dataset, ""Fraudulent E-Commerce Transactions,"" is designed to simulate transaction data from an e-commerce platform with a focus on fraud detection. It contains a variety of features commonly found in transactional data, with additional attributes specifically engineered to support the development and testing of fraud detection algorithms.

#### Dataset Overview

- **Number of Transactions in Version 1**: 1,472,952
- **Number of Transactions in Version 2**: 23,634
- **Features**: 16
- **Fraudulent Transactions**: Approximately 5%

#### Feature Details

1. **Transaction ID**: A unique identifier for each transaction.
2. **Customer ID**: A unique identifier for each customer.
3. **Transaction Amount**: The total amount of money exchanged in the transaction.
4. **Transaction Date**: The date and time when the transaction took place.
5. **Payment Method**: The method used to complete the transaction (e.g., credit card, PayPal, etc.).
6. **Product Category**: The category of the product involved in the transaction.
7. **Quantity**: The number of products involved in the transaction.
8. **Customer Age**: The age of the customer making the transaction.
9. **Customer Location**: The geographical location of the customer.
10. **Device Used**: The type of device used to make the transaction (e.g., mobile, desktop).
11. **IP Address**: The IP address of the device used for the transaction.
12. **Shipping Address**: The address where the product was shipped.
13. **Billing Address**: The address associated with the payment method.
14. **Is Fraudulent**: A binary indicator of whether the transaction is fraudulent (1 for fraudulent, 0 for legitimate).
15. **Account Age Days**: The age of the customer's account in days at the time of the transaction.
16. **Transaction Hour**: The hour of the day when the transaction occurred.

#### Purpose

The dataset is intended for use in developing and testing machine learning models for fraud detection in e-commerce transactions. It can also be used for exploratory data analysis, feature engineering, and benchmarking fraud detection algorithms.

#### Generation Method

The data is entirely synthetic, generated using Python's `Faker` library and custom logic to simulate realistic transaction patterns and fraudulent scenarios. The dataset is not based on real individuals or transactions and is created for educational and research purposes.

#### Usage

Feel free to use this dataset for data analysis, machine learning projects, or as a benchmark for fraud detection algorithms. If you use this dataset in your research or projects, please provide proper attribution.
",.csv,True
🤔 OpenTriviaQA Database,22,opentriviaqa-database,category_entertainment.csv,CC-BY-SA-4.0,"A creative commons dataset of trivia, multiple choice questions and answers.

[Original Data](https://github.com/uberspot/OpenTriviaQA)

# Acknowlegement

Foto von <a href=""https://unsplash.com/de/@simonesecci?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Simone Secci</a> auf <a href=""https://unsplash.com/de/fotos/rote-buchstaben-neonlicht-49uySSA678U?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv,True
🤔 OpenTriviaQA Database,22,opentriviaqa-database,category_humanities.csv,CC-BY-SA-4.0,"A creative commons dataset of trivia, multiple choice questions and answers.

[Original Data](https://github.com/uberspot/OpenTriviaQA)

# Acknowlegement

Foto von <a href=""https://unsplash.com/de/@simonesecci?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Simone Secci</a> auf <a href=""https://unsplash.com/de/fotos/rote-buchstaben-neonlicht-49uySSA678U?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv,True
🤔 OpenTriviaQA Database,22,opentriviaqa-database,category_history.csv,CC-BY-SA-4.0,"A creative commons dataset of trivia, multiple choice questions and answers.

[Original Data](https://github.com/uberspot/OpenTriviaQA)

# Acknowlegement

Foto von <a href=""https://unsplash.com/de/@simonesecci?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Simone Secci</a> auf <a href=""https://unsplash.com/de/fotos/rote-buchstaben-neonlicht-49uySSA678U?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv,True
🤔 OpenTriviaQA Database,22,opentriviaqa-database,category_religion-faith.csv,CC-BY-SA-4.0,"A creative commons dataset of trivia, multiple choice questions and answers.

[Original Data](https://github.com/uberspot/OpenTriviaQA)

# Acknowlegement

Foto von <a href=""https://unsplash.com/de/@simonesecci?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Simone Secci</a> auf <a href=""https://unsplash.com/de/fotos/rote-buchstaben-neonlicht-49uySSA678U?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv,True
🤔 OpenTriviaQA Database,22,opentriviaqa-database,category_people.csv,CC-BY-SA-4.0,"A creative commons dataset of trivia, multiple choice questions and answers.

[Original Data](https://github.com/uberspot/OpenTriviaQA)

# Acknowlegement

Foto von <a href=""https://unsplash.com/de/@simonesecci?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Simone Secci</a> auf <a href=""https://unsplash.com/de/fotos/rote-buchstaben-neonlicht-49uySSA678U?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv,True
🤔 OpenTriviaQA Database,22,opentriviaqa-database,category_world.csv,CC-BY-SA-4.0,"A creative commons dataset of trivia, multiple choice questions and answers.

[Original Data](https://github.com/uberspot/OpenTriviaQA)

# Acknowlegement

Foto von <a href=""https://unsplash.com/de/@simonesecci?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Simone Secci</a> auf <a href=""https://unsplash.com/de/fotos/rote-buchstaben-neonlicht-49uySSA678U?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv,True
🤔 OpenTriviaQA Database,22,opentriviaqa-database,category_general.csv,CC-BY-SA-4.0,"A creative commons dataset of trivia, multiple choice questions and answers.

[Original Data](https://github.com/uberspot/OpenTriviaQA)

# Acknowlegement

Foto von <a href=""https://unsplash.com/de/@simonesecci?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Simone Secci</a> auf <a href=""https://unsplash.com/de/fotos/rote-buchstaben-neonlicht-49uySSA678U?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv,True
🤔 OpenTriviaQA Database,22,opentriviaqa-database,category_celebrities.csv,CC-BY-SA-4.0,"A creative commons dataset of trivia, multiple choice questions and answers.

[Original Data](https://github.com/uberspot/OpenTriviaQA)

# Acknowlegement

Foto von <a href=""https://unsplash.com/de/@simonesecci?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Simone Secci</a> auf <a href=""https://unsplash.com/de/fotos/rote-buchstaben-neonlicht-49uySSA678U?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv,True
🤔 OpenTriviaQA Database,22,opentriviaqa-database,category_rated.csv,CC-BY-SA-4.0,"A creative commons dataset of trivia, multiple choice questions and answers.

[Original Data](https://github.com/uberspot/OpenTriviaQA)

# Acknowlegement

Foto von <a href=""https://unsplash.com/de/@simonesecci?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Simone Secci</a> auf <a href=""https://unsplash.com/de/fotos/rote-buchstaben-neonlicht-49uySSA678U?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv,True
🤔 OpenTriviaQA Database,22,opentriviaqa-database,category_music.csv,CC-BY-SA-4.0,"A creative commons dataset of trivia, multiple choice questions and answers.

[Original Data](https://github.com/uberspot/OpenTriviaQA)

# Acknowlegement

Foto von <a href=""https://unsplash.com/de/@simonesecci?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Simone Secci</a> auf <a href=""https://unsplash.com/de/fotos/rote-buchstaben-neonlicht-49uySSA678U?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv,True
🤔 OpenTriviaQA Database,22,opentriviaqa-database,category_literature.csv,CC-BY-SA-4.0,"A creative commons dataset of trivia, multiple choice questions and answers.

[Original Data](https://github.com/uberspot/OpenTriviaQA)

# Acknowlegement

Foto von <a href=""https://unsplash.com/de/@simonesecci?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Simone Secci</a> auf <a href=""https://unsplash.com/de/fotos/rote-buchstaben-neonlicht-49uySSA678U?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv,True
🤔 OpenTriviaQA Database,22,opentriviaqa-database,category_brain-teasers.csv,CC-BY-SA-4.0,"A creative commons dataset of trivia, multiple choice questions and answers.

[Original Data](https://github.com/uberspot/OpenTriviaQA)

# Acknowlegement

Foto von <a href=""https://unsplash.com/de/@simonesecci?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Simone Secci</a> auf <a href=""https://unsplash.com/de/fotos/rote-buchstaben-neonlicht-49uySSA678U?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv,True
🤔 OpenTriviaQA Database,22,opentriviaqa-database,category_television.csv,CC-BY-SA-4.0,"A creative commons dataset of trivia, multiple choice questions and answers.

[Original Data](https://github.com/uberspot/OpenTriviaQA)

# Acknowlegement

Foto von <a href=""https://unsplash.com/de/@simonesecci?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Simone Secci</a> auf <a href=""https://unsplash.com/de/fotos/rote-buchstaben-neonlicht-49uySSA678U?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv,True
🤔 OpenTriviaQA Database,22,opentriviaqa-database,category_newest.csv,CC-BY-SA-4.0,"A creative commons dataset of trivia, multiple choice questions and answers.

[Original Data](https://github.com/uberspot/OpenTriviaQA)

# Acknowlegement

Foto von <a href=""https://unsplash.com/de/@simonesecci?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Simone Secci</a> auf <a href=""https://unsplash.com/de/fotos/rote-buchstaben-neonlicht-49uySSA678U?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv,True
🤔 OpenTriviaQA Database,22,opentriviaqa-database,category_sports.csv,CC-BY-SA-4.0,"A creative commons dataset of trivia, multiple choice questions and answers.

[Original Data](https://github.com/uberspot/OpenTriviaQA)

# Acknowlegement

Foto von <a href=""https://unsplash.com/de/@simonesecci?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Simone Secci</a> auf <a href=""https://unsplash.com/de/fotos/rote-buchstaben-neonlicht-49uySSA678U?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv,True
🤔 OpenTriviaQA Database,22,opentriviaqa-database,category_animals.csv,CC-BY-SA-4.0,"A creative commons dataset of trivia, multiple choice questions and answers.

[Original Data](https://github.com/uberspot/OpenTriviaQA)

# Acknowlegement

Foto von <a href=""https://unsplash.com/de/@simonesecci?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Simone Secci</a> auf <a href=""https://unsplash.com/de/fotos/rote-buchstaben-neonlicht-49uySSA678U?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv,True
🤔 OpenTriviaQA Database,22,opentriviaqa-database,category_science-technology.csv,CC-BY-SA-4.0,"A creative commons dataset of trivia, multiple choice questions and answers.

[Original Data](https://github.com/uberspot/OpenTriviaQA)

# Acknowlegement

Foto von <a href=""https://unsplash.com/de/@simonesecci?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Simone Secci</a> auf <a href=""https://unsplash.com/de/fotos/rote-buchstaben-neonlicht-49uySSA678U?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv,True
🤔 OpenTriviaQA Database,22,opentriviaqa-database,category_video-games.csv,CC-BY-SA-4.0,"A creative commons dataset of trivia, multiple choice questions and answers.

[Original Data](https://github.com/uberspot/OpenTriviaQA)

# Acknowlegement

Foto von <a href=""https://unsplash.com/de/@simonesecci?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Simone Secci</a> auf <a href=""https://unsplash.com/de/fotos/rote-buchstaben-neonlicht-49uySSA678U?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv,True
🤔 OpenTriviaQA Database,22,opentriviaqa-database,category_hobbies.csv,CC-BY-SA-4.0,"A creative commons dataset of trivia, multiple choice questions and answers.

[Original Data](https://github.com/uberspot/OpenTriviaQA)

# Acknowlegement

Foto von <a href=""https://unsplash.com/de/@simonesecci?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Simone Secci</a> auf <a href=""https://unsplash.com/de/fotos/rote-buchstaben-neonlicht-49uySSA678U?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv,True
🤔 OpenTriviaQA Database,22,opentriviaqa-database,category_for-kids.csv,CC-BY-SA-4.0,"A creative commons dataset of trivia, multiple choice questions and answers.

[Original Data](https://github.com/uberspot/OpenTriviaQA)

# Acknowlegement

Foto von <a href=""https://unsplash.com/de/@simonesecci?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Simone Secci</a> auf <a href=""https://unsplash.com/de/fotos/rote-buchstaben-neonlicht-49uySSA678U?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv,True
🤔 OpenTriviaQA Database,22,opentriviaqa-database,category_geography.csv,CC-BY-SA-4.0,"A creative commons dataset of trivia, multiple choice questions and answers.

[Original Data](https://github.com/uberspot/OpenTriviaQA)

# Acknowlegement

Foto von <a href=""https://unsplash.com/de/@simonesecci?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Simone Secci</a> auf <a href=""https://unsplash.com/de/fotos/rote-buchstaben-neonlicht-49uySSA678U?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv,True
🤔 OpenTriviaQA Database,22,opentriviaqa-database,category_movies.csv,CC-BY-SA-4.0,"A creative commons dataset of trivia, multiple choice questions and answers.

[Original Data](https://github.com/uberspot/OpenTriviaQA)

# Acknowlegement

Foto von <a href=""https://unsplash.com/de/@simonesecci?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Simone Secci</a> auf <a href=""https://unsplash.com/de/fotos/rote-buchstaben-neonlicht-49uySSA678U?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv,True
🤖 LLM Generated Essays for the Detect AI Comp!,2,llm-generated-essays,ai_generated_train_essays.csv,CC0-1.0,"This dataset contains 700 LLM generated essays in total.

I generated 500 of these essays with `gpt-3.5-turbo` and 200 with `gpt-4`, a total of 300 for prompt_id 0 and 300 for prompt id 1).

Hope you find it useful! 🙂 Happy Kaggling!

**PS. Would appreciate if you could please help me and upvote the dataset! Thank you 🙏**",.csv,True
🤖 LLM Generated Essays for the Detect AI Comp!,2,llm-generated-essays,ai_generated_train_essays_gpt-4.csv,CC0-1.0,"This dataset contains 700 LLM generated essays in total.

I generated 500 of these essays with `gpt-3.5-turbo` and 200 with `gpt-4`, a total of 300 for prompt_id 0 and 300 for prompt id 1).

Hope you find it useful! 🙂 Happy Kaggling!

**PS. Would appreciate if you could please help me and upvote the dataset! Thank you 🙏**",.csv,True
🥇 SEMI BLENDING 2024,4,semi-blending-2023,serie3.csv,DbCL-1.0,"Predict New Medicines with BELKA
https://www.kaggle.com/competitions/leash-BELKA

Predict small molecule-protein interactions using the Big Encoded Library for Chemical Assessment (BELKA)
",.csv,True
🥇 SEMI BLENDING 2024,4,semi-blending-2023,serie2.csv,DbCL-1.0,"Predict New Medicines with BELKA
https://www.kaggle.com/competitions/leash-BELKA

Predict small molecule-protein interactions using the Big Encoded Library for Chemical Assessment (BELKA)
",.csv,True
🥇 SEMI BLENDING 2024,4,semi-blending-2023,serie5.csv,DbCL-1.0,"Predict New Medicines with BELKA
https://www.kaggle.com/competitions/leash-BELKA

Predict small molecule-protein interactions using the Big Encoded Library for Chemical Assessment (BELKA)
",.csv,True
🥇 SEMI BLENDING 2024,4,semi-blending-2023,serie4.csv,DbCL-1.0,"Predict New Medicines with BELKA
https://www.kaggle.com/competitions/leash-BELKA

Predict small molecule-protein interactions using the Big Encoded Library for Chemical Assessment (BELKA)
",.csv,True
🥇🥈 Gold and Silver prices (2013-2024),2,gold-and-silver-prices-2013-2023,gold prices.csv,CC0-1.0,"# 💵 Daily prices for gold and silver from 2013 till  May 2024

###  The prices in USD for one ounce (1 ounce = 28.3495 grams) 
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F302de72b47a7ecbad1398187be0eeb63%2F4.png?generation=1692385928734951&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2Fcc249a4901564b9a23dfd7049db8c2c6%2F1.jpg?generation=1692385938810592&alt=media)![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2Fdbc36c83ee9de1faac84816704b79a82%2F5.png?generation=1692385952707647&alt=media)
",.csv,True
🥇🥈 Gold and Silver prices (2013-2024),2,gold-and-silver-prices-2013-2023,silver prices.csv,CC0-1.0,"# 💵 Daily prices for gold and silver from 2013 till  May 2024

###  The prices in USD for one ounce (1 ounce = 28.3495 grams) 
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F302de72b47a7ecbad1398187be0eeb63%2F4.png?generation=1692385928734951&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2Fcc249a4901564b9a23dfd7049db8c2c6%2F1.jpg?generation=1692385938810592&alt=media)![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2Fdbc36c83ee9de1faac84816704b79a82%2F5.png?generation=1692385952707647&alt=media)
",.csv,True
