Dataset Name,Table Count,Folder Name,File Name,License,Description,File Type
 Adobe's Stock Trends| Data Analysis📊,1,adobe-datset,adobe_stock_data.csv,Apache 2.0," **Adobe's Stock Trends📊**
&gt; About Columns:

- Date: Represents the date of the stock data.
- Open: Denotes the opening price of the stock on that date.
- High: Signifies the highest price of the stock on that date.
- Low: Indicates the lowest price of the stock on that date.
- Close: Represents the closing price of the stock on that date.
- Adj Close: Refers to the adjusted closing price of the stock on that date, which accounts for any corporate - actions such as dividends and stock splits.
- Volume: Represents the trading volume of the stock on that date, which indicates the number of shares traded.",.csv
 Arabic Company Reviews (عربي),1,arabic-company-reviews,CompanyReviews.csv,CC-BY-SA-4.0,"## Context
The data was collected for the purpose of sentiment analysis in order to produce a score for a given company.

## Content
The data has 40K+ reviews in Arabic for sentiment analysis each labelled with a rating and its associated company name.  

### Dataset Glossary (Column-Wise)
- Index column (integer)
- Review (text)
- Rating (-1,0,1)
- Company (text)  

### Structure of the Dataset
![Dataset preview](https://i.ibb.co/pZkB05Q/Screenshot-2022-09-19-232149.png)  

### Companies covered
- talbat 32073
- swvl   4693
- telecom_egypt  2090
- venus  281
- Raya   268
- TMG   250
- elsewedy  147
- hilton   100
- capiter    73
- Ezz Steel   49
- nestle  18
- domty    4",.csv
 E-Commerce Shipping Data ,1,customer-analytics,Train.csv,other,"### Context

An international e-commerce company based wants to discover key insights from their customer database. They want to use some of the most advanced machine learning techniques to study their customers. The company sells electronic products.

### Content

The dataset used for model building contained 10999 observations of 12 variables.
The data contains the following information:

- **ID:** ID Number of Customers.
- **Warehouse block:** The Company have big Warehouse which is divided in to block such as A,B,C,D,E.
- **Mode of shipment:**The Company Ships the products in multiple way such as Ship, Flight and Road.
- **Customer care calls:** The number of calls  made from enquiry for enquiry of the shipment.
- **Customer rating:** The company has rated from every customer. 1 is the lowest (Worst), 5 is the highest (Best).
- **Cost of the product:** Cost of the Product in US Dollars.
- **Prior purchases:** The Number of Prior Purchase.
- **Product importance:** The company has categorized the product in the various parameter such as low, medium, high.
- **Gender:** Male and Female.
- **Discount offered:** Discount offered on that specific product.
- **Weight in gms:** It is the weight in grams.
- **Reached on time:** It is the target variable, where 1 Indicates that the product has NOT reached on time and 0 indicates it has reached on time.

### Acknowledgements

I would like to specify that I am only making available on Github in Data collected data about product shipment to Kagglers. I made this as my project on Customer Analytics stored in GitHub repository.

### Inspiration
This data of Product Shipment Tracking, answer instantly to your questions:
- What was Customer Rating?  And was the product delivered on time?
- Is Customer query is being answered?
- If Product importance is high. having higest rating or being delivered on time?",.csv
 Epileptic Seizure Recognition,1,epileptic-seizure-recognition,Epileptic Seizure Recognition.csv,other,"### Context

This dataset is a pre-processed and re-structured/reshaped version of a very commonly used dataset featuring epileptic seizure detection.
### Content

#Attribute Information:

The original dataset from the reference consists of 5 different folders, each with 100 files, with each file representing a single subject/person. Each file is a recording of brain activity for 23.6 seconds. The corresponding time-series is sampled into 4097 data points. Each data point is the value of the EEG recording at a different point in time. So we have total 500 individuals with each has 4097 data points for 23.5 seconds.

We divided and shuffled every 4097 data points into 23 chunks, each chunk contains 178 data points for 1 second, and each data point is the value of the EEG recording at a different point in time. So now we have 23 x 500 = 11500 pieces of information(row), each information contains 178 data points for 1 second(column), the last column represents the label y {1,2,3,4,5}. 

The response variable is y in column 179, the Explanatory variables X1, X2, ..., X178 

y contains the category of the 178-dimensional input vector. Specifically y in {1, 2, 3, 4, 5}: 

5 - eyes open, means when they were recording the EEG signal of the brain the patient had their eyes open 

4 - eyes closed, means when they were recording the EEG signal the patient had their eyes closed 

3 - Yes they identify where the region of the tumor was in the brain and recording the EEG activity from the healthy brain area 

2 - They recorder the EEG from the area where the tumor was located 

1 - Recording of seizure activity 

All subjects falling in classes 2, 3, 4, and 5 are subjects who did not have epileptic seizure. Only subjects in class 1 have epileptic seizure. Our motivation for creating this version of the data was to simplify access to the data via the creation of a .csv version of it. Although there are 5 classes most authors have done binary classification, namely class 1 (Epileptic seizure) against the rest.

This Dataset collect from [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.html)
### Acknowledgements
Andrzejak RG, Lehnertz K, Rieke C, Mormann F, David P, Elger CE (2001) Indications of nonlinear deterministic and finite dimensional structures in time series of brain electrical activity: Dependence on recording region and brain state, Phys. Rev. E, 64, 061907


### Inspiration

",.csv
 Higher Education Students Performance Evaluation,1,higher-education-students-performance-evaluation,student_prediction.csv,other,"###Abstract###

The data was collected from the Faculty of Engineering and Faculty of Educational Sciences students in 2019. The purpose is to predict students' end-of-term performances using ML techniques.

###Attribute Information:###
Student ID
1- Student Age (1: 18-21, 2: 22-25, 3: above 26)
2- Sex (1: female, 2: male)
3- Graduated high-school type: (1: private, 2: state, 3: other)
4- Scholarship type: (1: None, 2: 25%, 3: 50%, 4: 75%, 5: Full)
5- Additional work: (1: Yes, 2: No)
6- Regular artistic or sports activity: (1: Yes, 2: No)
7- Do you have a partner: (1: Yes, 2: No)
8- Total salary if available (1: USD 135-200, 2: USD 201-270, 3: USD 271-340, 4: USD 341-410, 5: above 410)
9- Transportation to the university: (1: Bus, 2: Private car/taxi, 3: bicycle, 4: Other)
10- Accommodation type in Cyprus: (1: rental, 2: dormitory, 3: with family, 4: Other)
11- Mother's education: (1: primary school, 2: secondary school, 3: high school, 4: university, 5: MSc., 6: Ph.D.)
12- Father's education: (1: primary school, 2: secondary school, 3: high school, 4: university, 5: MSc., 6: Ph.D.)
13- Number of sisters/brothers (if available): (1: 1, 2:, 2, 3: 3, 4: 4, 5: 5 or above)
14- Parental status: (1: married, 2: divorced, 3: died - one of them or both) ***Listed as ""Kids""...woops
15- Mother's occupation: (1: retired, 2: housewife, 3: government officer, 4: private sector employee, 5: self-employment, 6: other)
16- Father's occupation: (1: retired, 2: government officer, 3: private sector employee, 4: self-employment, 5: other)
17- Weekly study hours: (1: None, 2: &lt;5 hours, 3: 6-10 hours, 4: 11-20 hours, 5: more than 20 hours)
18- Reading frequency (non-scientific books/journals): (1: None, 2: Sometimes, 3: Often)
19- Reading frequency (scientific books/journals): (1: None, 2: Sometimes, 3: Often)
20- Attendance to the seminars/conferences related to the department: (1: Yes, 2: No)
21- Impact of your projects/activities on your success: (1: positive, 2: negative, 3: neutral)
22- Attendance to classes (1: always, 2: sometimes, 3: never)
23- Preparation to midterm exams 1: (1: alone, 2: with friends, 3: not applicable)
24- Preparation to midterm exams 2: (1: closest date to the exam, 2: regularly during the semester, 3: never)
25- Taking notes in classes: (1: never, 2: sometimes, 3: always)
26- Listening in classes: (1: never, 2: sometimes, 3: always)
27- Discussion improves my interest and success in the course: (1: never, 2: sometimes, 3: always)
28- Flip-classroom: (1: not useful, 2: useful, 3: not applicable)
29- Cumulative grade point average in the last semester (/4.00): (1: &lt;2.00, 2: 2.00-2.49, 3: 2.50-2.99, 4: 3.00-3.49, 5: above 3.49)
30- Expected Cumulative grade point average in the graduation (/4.00): (1: &lt;2.00, 2: 2.00-2.49, 3: 2.50-2.99, 4: 3.00-3.49, 5: above 3.49)
31- Course ID
32- OUTPUT Grade (0: Fail, 1: DD, 2: DC, 3: CC, 4: CB, 5: BB, 6: BA, 7: AA)


###Acknowledgements###

**Relevant Papers:**

YÄ±lmaz N., Sekeroglu B. (2020) Student Performance Classification Using Artificial Intelligence Techniques. In: Aliev R., Kacprzyk J., Pedrycz W., Jamshidi M., Babanli M., Sadikoglu F. (eds) 10th International Conference on Theory and Application of Soft Computing, Computing with Words and Perceptions - ICSCCW-2019. ICSCCW 2019. Advances in Intelligent Systems and Computing, vol 1095. Springer, Cham.

**Citation Request:**

YÄ±lmaz N., Sekeroglu B. (2020) Student Performance Classification Using Artificial Intelligence Techniques. In: Aliev R., Kacprzyk J., Pedrycz W., Jamshidi M., Babanli M., Sadikoglu F. (eds) 10th International Conference on Theory and Application of Soft Computing, Computing with Words and Perceptions - ICSCCW-2019. ICSCCW 2019. Advances in Intelligent Systems and Computing, vol 1095. Springer, Cham.


###Inspiration###

Which students are most likely to succeed?",.csv
 Housing Market & Prices,1,final-house,house.csv,other,"## 🏡💰🏠Housing Market Data Attributes 🏠💰🏡

In the analysis of the housing market, it's essential to understand the various attributes that characterize each housing unit. These attributes provide valuable information for potential buyers, renters, and investors, helping them make informed decisions about their housing choices. Below, we describe the key data attributes used in our housing market analysis:

- **Bedroom Count:** This attribute represents the number of bedrooms in the housing unit, providing insights into its size and capacity.

- **Net Square Meters (Net Sqm):** Net square meters refer to the total usable interior space within the housing unit, excluding common areas like corridors and stairwells. It quantifies the size of the property.

- **Center Distance:** This attribute measures the distance of the housing unit from the central or downtown area of a city or town. It is a valuable metric for potential buyers or renters to assess proximity to urban amenities and activities.

- **Metro Distance:** Metro distance indicates the distance between the housing unit and the nearest metro or subway station. This information is particularly useful for individuals who rely on public transportation for their daily commute.

- **Floor:** The floor attribute specifies the level or story of the housing unit within the building, offering insights into its placement and accessibility within the structure.

- **Age:** The age of the property represents the number of years since its construction or renovation. It plays a crucial role in assessing the condition of the property and potential maintenance requirements.

- **Price:** Price is the cost associated with purchasing or renting the housing unit. It is a fundamental factor for individuals making housing decisions and can be influenced by various attributes such as bedroom count, size, location, and age.
",.csv
 Lung Cancer Prediction,1,cancer-patients-and-air-pollution-a-new-link,cancer patient data sets.csv,other,"# Lung Cancer Prediction
### Air Pollution, Alcohol, Smoking & Risk of Lung Cancer
_____

### About this dataset
&gt; This dataset contains information on patients with lung cancer, including their age, gender, air pollution exposure, alcohol use, dust allergy, occupational hazards, genetic risk, chronic lung disease, balanced diet, obesity, smoking, passive smoker, chest pain, coughing of blood, fatigue, weight loss ,shortness of breath ,wheezing ,swallowing difficulty ,clubbing of finger nails  and snoring

### How to use the dataset
&gt; Lung cancer is the leading cause of cancer death worldwide, accounting for 1.59 million deaths in 2018. The majority of lung cancer cases are attributed to smoking, but exposure to air pollution is also a risk factor. A new study has found that air pollution may be linked to an increased risk of lung cancer, even in nonsmokers.
&gt; 
&gt; The study, which was published in the journal Nature Medicine, looked at data from over 462,000 people in China who were followed for an average of six years. The participants were divided into two groups: those who lived in areas with high levels of air pollution and those who lived in areas with low levels of air pollution.
&gt; 
&gt; The researchers found that the people in the high-pollution group were more likely to develop lung cancer than those in the low-pollution group. They also found that the risk was higher in nonsmokers than smokers, and that the risk increased with age.
&gt; 
&gt; While this study does not prove that air pollution causes lung cancer, it does suggest that there may be a link between the two. More research is needed to confirm these findings and to determine what effect different types and levels of air pollution may have on lung cancer risk

### Research Ideas
&gt; - predicting the likelihood of a patient developing lung cancer
&gt; - identifying risk factors for lung cancer
&gt; - determining the most effective treatment for a patient with lung cancer

### Acknowledgements
&gt; 
&gt; 
&gt; ### License
&gt; 
&gt; 
&gt; &gt; See the dataset description for more information.

### Columns

**File: cancer patient data sets.csv**
| Column name                  | Description                                                         |
|:-----------------------------|:--------------------------------------------------------------------|
| **Age**                      | The age of the patient. (Numeric)                                   |
| **Gender**                   | The gender of the patient. (Categorical)                            |
| **Air Pollution**            | The level of air pollution exposure of the patient. (Categorical)   |
| **Alcohol use**              | The level of alcohol use of the patient. (Categorical)              |
| **Dust Allergy**             | The level of dust allergy of the patient. (Categorical)             |
| **OccuPational Hazards**     | The level of occupational hazards of the patient. (Categorical)     |
| **Genetic Risk**             | The level of genetic risk of the patient. (Categorical)             |
| **chronic Lung Disease**     | The level of chronic lung disease of the patient. (Categorical)     |
| **Balanced Diet**            | The level of balanced diet of the patient. (Categorical)            |
| **Obesity**                  | The level of obesity of the patient. (Categorical)                  |
| **Smoking**                  | The level of smoking of the patient. (Categorical)                  |
| **Passive Smoker**           | The level of passive smoker of the patient. (Categorical)           |
| **Chest Pain**               | The level of chest pain of the patient. (Categorical)               |
| **Coughing of Blood**        | The level of coughing of blood of the patient. (Categorical)        |
| **Fatigue**                  | The level of fatigue of the patient. (Categorical)                  |
| **Weight Loss**              | The level of weight loss of the patient. (Categorical)              |
| **Shortness of Breath**      | The level of shortness of breath of the patient. (Categorical)      |
| **Wheezing**                 | The level of wheezing of the patient. (Categorical)                 |
| **Swallowing Difficulty**    | The level of swallowing difficulty of the patient. (Categorical)    |
| **Clubbing of Finger Nails** | The level of clubbing of finger nails of the patient. (Categorical) |

",.csv
 Online Shoppers Purchasing Intention Dataset,1,online-shoppers-purchasing-intention-dataset,online_shoppers_intention.csv,other,"### Context

**Data Set Information:**

The dataset consists of feature vectors belonging to 12,330 sessions.
The dataset was formed so that each session
would belong to a different user in a 1-year period to avoid
any tendency to a specific campaign, special day, user
profile, or period.


### Content

The dataset consists of 10 numerical and 8 categorical attributes.
The 'Revenue' attribute can be used as the class label.

""Administrative"", ""Administrative Duration"", ""Informational"", ""Informational Duration"", ""Product Related"" and ""Product Related Duration"" represent the number of different types of pages visited by the visitor in that session and total time spent in each of these page categories. The values of these features are derived from the URL information of the pages visited by the user and updated in real time when a user takes an action, e.g. moving from one page to another. The ""Bounce Rate"", ""Exit Rate"" and ""Page Value"" features represent the metrics measured by ""Google Analytics"" for each page in the e-commerce site. The value of ""Bounce Rate"" feature for a web page refers to the percentage of visitors who enter the site from that page and then leave (""bounce"") without triggering any other requests to the analytics server during that session. The value of ""Exit Rate"" feature for a specific web page is calculated as for all pageviews to the page, the percentage that were the last in the session. The ""Page Value"" feature represents the average value for a web page that a user visited before completing an e-commerce transaction. The ""Special Day"" feature indicates the closeness of the site visiting time to a specific special day (e.g. Mother’s Day, Valentine's Day) in which the sessions are more likely to be finalized with transaction. The value of this attribute is determined by considering the dynamics of e-commerce such as the duration between the order date and delivery date. For example, for Valentina’s day, this value takes a nonzero value between February 2 and February 12, zero before and after this date unless it is close to another special day, and its maximum value of 1 on February 8. The dataset also includes operating system, browser, region, traffic type, visitor type as returning or new visitor, a Boolean value indicating whether the date of the visit is weekend, and month of the year.


### Acknowledgements

Sakar, C.O., Polat, S.O., Katircioglu, M. et al. Neural Comput & Applic (2018).


### Inspiration

Education is the most powerful weapon which you can use to change the world. 😃",.csv
 Sales Conversion Optimization,1,clicks-conversion-tracking,KAG_conversion_data.csv,other,"### Context

Cluster Analysis for Ad Conversions Data


### Content

The data used in this project is from an anonymous organisation’s social media ad campaign. The data file can be downloaded from here. The file conversion_data.csv contains 1143 observations in 11 variables. Below are the descriptions of the variables.

1.) ad_id: an unique ID for each ad.

2.) xyz_campaign_id: an ID associated with each ad campaign of XYZ company.

3.) fb_campaign_id: an ID associated with how Facebook tracks each campaign.

4.) age: age of the person to whom the ad is shown.

5.) gender: gender of the person to whim the add is shown

6.) interest: a code specifying the category to which the person’s interest belongs (interests are as mentioned in the person’s Facebook public profile).

7.) Impressions: the number of times the ad was shown.

8.) Clicks: number of clicks on for that ad.

9.) Spent: Amount paid by company xyz to Facebook, to show that ad.

10.) Total conversion: Total number of people who enquired about the product after seeing the ad.

11.) Approved conversion: Total number of people who bought the product after seeing the ad.




### Acknowledgements

Thanks to the Anonymous data depositor 

### Inspiration

Social Media Ad Campaign marketing is a leading source of Sales Conversion and i have made this data available for the benefit of Businesses using Google Adwords to track Conversions",.csv
 Smartphone Dataset for Analysis,1,smartphones,smartphones - smartphones.csv,Apache 2.0,"**DESCRIPTION:**
This dataset provides comprehensive information about various smartphone models, facilitating detailed analysis and comparison. It encompasses crucial attributes such as model name, price, rating, similarity index (sim), processor details, RAM capacity, battery specifications, display features, camera specifications, expandable memory card support, and operating system (OS) details.

**Columns:**

1.Model: The name or designation of the smartphone model.

2.Price: The retail price of the smartphone, typically in a specified currency.

3.Rating: The user or expert rating of the smartphone, providing an indication of its overall quality and user satisfaction.

4.Sim: The number of SIM cards supported by the smartphone.

5.Processor: Details about the processor or chipset used in the smartphone, including brand, model, and specifications.

6.RAM: The amount of random-access memory (RAM) available in the smartphone, measured in gigabytes (GB).

7.Battery: Information regarding the battery capacity and type, providing insight into the device's endurance and usage duration.

8.Display: Specifications related to the smartphone's display, such as size, resolution, technology (e.g., LCD, OLED), and any additional features (e.g., HDR support).

9.Camera: Details about the smartphone's camera setup, including megapixel count, lens specifications, and additional features like image stabilization or AI enhancements.

10.Card: Indicates whether the smartphone supports expandable memory cards, providing users with the option to increase storage capacity.

11.OS: The operating system installed on the smartphone, including the version number if applicable.


**This dataset is valuable for various analyses, including:**

1.Price-performance comparisons: Assessing the correlation between price and features like processor, RAM, and camera quality.

2.Market trend analysis: Identifying popular models based on ratings and sales data.

3.Feature preference analysis: Examining which features (e.g., battery capacity, camera quality) are most valued by consumers.

4.Brand comparison: Comparing specifications and performance across different smartphone brands.

5.Predictive modeling: Using historical data to predict future trends in smartphone design and consumer preferences.


**The dataset is ideal for data scientists, researchers, and analysts interested in the smartphone industry, consumer behavior, and technology trends. It can be utilized for exploratory data analysis, machine learning modeling, and generating insights to inform business decisions within the mobile device market.**",.csv
 Spotify - Beyoncé's Track Data,1,beyonce-track-attribute-data,beyonce_tracks.csv,other,"💁‍♀️Please take a moment to carefully read through this description and metadata to better understand the dataset and its nuances before proceeding to the Suggestions and Discussions section.

# Dataset Description:
This dataset compiles the tracks from all of Beyoncé's albums available on Spotify, showcasing the evolution of one of the most influential artists in the music industry. It represents a comprehensive array of genres, influences, and musical styles that Beyoncé has explored throughout her career. Each track in the dataset is detailed with a variety of features, popularity, and metadata. This dataset serves as an excellent resource for music enthusiasts, data analysts, and researchers aiming to explore the impact of Beyoncé's music, identify trends in her musical evolution, or develop music recommendation systems based on empirical data.

# Scope of the Data:
The focus of this dataset is on providing a comprehensive view of Beyoncé's musical releases on Spotify, specifically tailored to showcase her creative output. To this end, the dataset includes tracks from the following album types:
- **Albums:** Full-length albums released by Beyoncé, encapsulating a range of her musical styles and eras.
- **Singles:** Standalone single releases, highlighting key songs that have been released independently of her full albums.
It's important to note that this dataset deliberately excludes compilation albums. Compilations, which often contain a mixture of tracks from various artists or previously released tracks by Beyoncé, are not included to maintain a focus on her original releases and to provide a clearer picture of her artistic evolution.

# Data Collection and Processing:
Obtaining the Data:
The data was obtained directly from the Spotify Web API, specifically focusing on albums and tracks by Beyoncé. The Spotify API provides detailed information about tracks, artists, and albums through various endpoints.

Data Processing:
To process and structure the data, Python scripts were developed using data science libraries such as pandas for data manipulation and spotipy for API interactions, specifically for Spotify data retrieval.

Workflow:
- Authentication
- API Requests
- Data Cleaning and Transformation
- Saving the Data

# Attribute Descriptions:
- artist_name: the name of the artist (Beyoncé and collaborators)
- track_name: the title of the track
- is_explicit: Indicates whether the track contains explicit content
- album_release_date: The date when the track was released
- genres: A list of genres associated with Beyoncé
- danceability: A measure from 0.0 to 1.0 indicating how suitable a track is for - dancing based on a combination of musical elements
- valence: A measure from 0.0 to 1.0 indicating the musical positiveness conveyed by a track
- energy: A measure from 0.0 to 1.0 representing a perceptual measure of intensity and activity
- loudness: The overall loudness of a track in decibels (dB)
- acousticness: A measure from 0.0 to 1.0 whether the track is acoustic
- instrumentalness: Predicts whether a track contains no vocals
- liveness: Detects the presence of an audience in the recordings
- speechiness: Detects the presence of spoken words in a track
- key: The key the track is in. Integers map to pitches using standard Pitch Class notation
- tempo: The overall estimated tempo of a track in beats per minute (BPM)
- mode: Modality of the track
- duration_ms: The length of the track in milliseconds
- time_signature: An estimated overall time signature of a track
- popularity: A score between 0 and 100, with 100 being the most popular

# Possible Data Projects:
- Trend Analysis in Beyonce's Musical Evolution
- Mood and Musical Elements in Beyonce's Tracks
- Beyonce's Influence on the Music Industry Analysis

# Disclaimer and Responsible Use:
This dataset, derived from Spotify focusing on Beyoncé's albums and tracks, is intended for **educational, research, and analysis purposes only**. Users are urged to use this data responsibly, ethically, and within the bounds of legal stipulations.
- **Compliance with Terms of Service:** Users should adhere to Spotify's Terms of Service and Developer Policies when utilizing this dataset.
- **Copyright Notice:** The dataset presents music track information including names and artist details for analytical purposes and does not convey any rights to the music itself. Users must ensure that their use does not infringe on the copyright holders' rights. Any analysis, distribution, or derivative work should respect the intellectual property rights of all involved parties and comply with applicable laws.
- **No Warranty Disclaimer:** The dataset is provided ""as is,"" without warranty, and the creator disclaims any legal liability for its use by others.
- **Ethical Use:** Users are encouraged to consider the ethical implications of their analyses and the potential impact on artists and the broader community. 
- **Data Accuracy and Timeliness:** The dataset reflects a snapshot in time and may not represent the most current information available. Users are encouraged to verify the data's accuracy and timeliness.
- **Source Verification:** For the most accurate and up-to-date information, users are encouraged to refer directly to Spotify's official website.
- **Independence Declaration:** This project is independent and has not been authorized, sponsored, or otherwise approved by Spotify, Beyoncé, or any other entities mentioned. The creator/maintainer is not affiliated with these entities.

# Expected Update Frequency:
The dataset will be updated following the release of any major album or single by the artist. While updates are planned around major releases, the exact timing may vary.

# Contribution to Community:
Users who derive new insights, develop enhancements to the dataset, or create analytics that shed new light on Beyoncé's music are highly encouraged to contribute back to the community.
- **Kaggle Notebooks:** Users are encouraged to create and share their analysis in the form of Kaggle notebooks. When creating your notebook, please initiate your notebook by clicking ""New Notebook"" at the top of this dataset page, so that te action automatically loads this dataset as an input to your notebook. 
- **Suggestions Tab:** For feedback and suggestions related to the dataset, the 'Suggestions' tab on the dataset's Kaggle page is your go-to platform. 

# Resources
Spotify Web API: https://developer.spotify.com/documentation/web-api

Beyonce Artist Page on Spotify: https://open.spotify.com/artist/6vWDO969PvNqNYHIOW5v0m

# Last Update:
13/03/2024",.csv
 Steel Industry Energy Consumption,1,steel-industry-energy-consumption,Steel_industry_data.csv,other,"### Content

This company produces several types of coils, steel plates, and iron plates. The information on electricity consumption is held in a cloud-based system. The information on energy consumption of the industry is stored on the website of the Korea Electric Power Corporation (pccs.kepco.go.kr), and the perspectives on daily, monthly, and annual data are calculated and shown.


###Attribute Information:

**Date** Continuous-time data taken on the first of the month
**Usage_kWh** Industry Energy Consumption Continuous kWh
**Lagging Current** reactive power Continuous kVarh
**Leading Current** reactive power Continuous kVarh
**CO2** Continuous ppm
**NSM** Number of Seconds from midnight Continuous S
**Week** status Categorical (Weekend (0) or a Weekday(1))
**Day of week**  Categorical Sunday, Monday : Saturday
**Load Type** Categorical Light Load, Medium Load, Maximum Load

### Acknowledgements

This dataset is sourced from the UCI Machine Learning Repository
Relevant Papers:

1. Sathishkumar V E, Changsun Shin, Youngyun Cho, â€œEfficient energy consumption prediction model for a data analytic-enabled industry building in a smart cityâ€, Building Research & Information, Vol. 49. no. 1, pp. 127-143, 2021.
2. Sathishkumar V E, Myeongbae Lee, Jonghyun Lim, Yubin Kim, Changsun Shin, Jangwoo Park, Yongyun Cho, â€œAn Energy Consumption Prediction Model for Smart Factory using Data Mining Algorithmsâ€ KIPS Transactions on Software and Data Engineering, Vol. 9, no. 5, pp. 153-160, 2020.
Transactions on Software and Data Engineering, Vol. 9, no. 5, pp. 153-160, 2020.
3. Sathishkumar V E, Jonghyun Lim, Myeongbae Lee, Yongyun Cho, Jangwoo Park, Changsun Shin, and Yongyun Cho, â€œIndustry Energy Consumption Prediction Using Data Mining Techniquesâ€, International Journal of Energy Information and Communications, Vol. 11, no. 1, pp. 7-14, 2020.

### Inspiration

Which times of the year is the most energy consumed?
What patterns can we identify in energy usage?",.csv
 Students Mental Health Assessments,1,students-mental-health-assessments,students_mental_health_survey.csv,CC0-1.0,"The dataset  represents mental health evaluations of students. This dataset seeks to provide valuable insights into the mental health of students by capturing a number of factors that may impact their mental health.
The data set comprises a rich collection of  records, carefully selected from various anonymous sources to ensure privacy and confidentiality. It's essential to acknowledge that no dataset is ever 100% accurate, as it can be affected by numerous sources of error and uncertainty. For previous listings, check older versions of the dataset.

#  Content
- - - 
    
Stress_Level: The level of stress experienced by the individual.

Depression_Score: The score representing the level of depression experienced by the individual.

Anxiety_Score: The score representing the level of anxiety experienced by the individual.

Sleep_Quality: The quality of sleep experienced by the individual .

Physical_Activity: The level of physical activity .

 Diet_Quality: The quality of the individual's diet. 

Social_Support: The level of social support received by the individual.

 Substance_Use: The frequency of substance use such as alcohol, cigarettes or other drugs. 

Family_History: Whether the individual has a family history of mental health issues.

 Chronic_Illness:  Financial_Stress: The level of financial stress experienced by the individual (between 0 and 5). 

 Semester_Credit_Load: The number of credits the individual is taking in the semester (15-30).    ",.csv
 The Rolling Stone Album Rankings,1,rolling-stone-album-rankings,rolling_stone.csv,CC0-1.0,"## **Context**

The RS 500 list is a product of meticulous selection by Rolling Stone's editors, who drew upon the insights from two comprehensive surveys. Initially, in 2003, a diverse panel comprising 271 notable figures from the music industry, including artists, producers, and journalists, was tasked with identifying the most influential albums ever produced. Subsequently, in 2009, a similar assembly of 100 specialists was convened to determine the standout albums of the 2000s. The outcomes of these polls were instrumental in shaping Rolling Stone's esteemed compilation of the all-time greatest albums.

## **Content**
Geography: United Kingdom

Time period: 2003-2020

Unit of analysis: The Rolling Stone Album Rankings

Dataset: The dataset contains details information of The Pudding compares Rolling Stone’s “500 Greatest Albums of All Time” lists from 2003, 2012, and 2020. 

###**Variables:**
Sort name: Name used for sorting
clean name: Clean name
album: Album name
rank_2003: Rank in 2003. NA if album not released yet or not in top 500
rank_2012: Rank in 2012. NA if album not released yet or not in top 500
rank_2020: Rank in 2020. NA if not in top 500
differential: 2020-2003 Differential. Negative value if it went down in the chart. Positive value if it went up
release_year: Release Year
genre:  Album genre 
type: Album type
weeks_on_billboard: Weeks on Billboard
peak_billboard_position: Peak Billboard Position
spotify_popularity: Spotify Popularity. NA if not on Spotify
spotify_url: Spotify URL. NA if not on Spotify
artist_member_count: Number of artists in the group
artist_gender: Gender of the artist(s). Male/Female if it's a mixed-gender group
artist_birth_year_sum: Sum of the artists birth year. e.g. for a 2 member group, with one person born 1945 and another 1950, the value is 3895.
debut_album_release_year: Debut Album Release Year
avg_age_at_top_500: Average age at top 500 Album
years_between: Years Between Debut and Top 500 Album
album_id: Album ID. NOS at the beginning of the ID if not on Spotify

## **Data Source**
The data in this dataset was collected from various sources and thank to all researchers who collected it.
At album rankings from Rolling Stone. h/t [Data is plural](https://www.data-is-plural.com/archive/2024-03-27-edition/). A visual essay from The Pudding looks at [what makes an album the greatest of all time](https://pudding.cool/2024/03/greatest-music/), and shares the data they put together for the essay.

Please note that this description is a template, and you should adapt it based on the actual data sources and specific details of your dataset when creating it for Kaggle or any other platform. 
",.csv
 Website Phishing Dataset,1,website-phishing-data-set,Website Phishing.csv,GPL-2.0,"ISSR CS602 Machine Learning - Project

Website Phishing Data Set 
Download: Data Folder, Data Set Description

Abstract:

| Data Set Characteristics :  Multivariate | Number of Instances : 1353 |
| --- | --- |
| Attribute Characteristics : Integer | Number of Attributes : 10 |
| --- | --- |
| Associated Tasks : Classification | Number of Web Hits : 54880 |

Source:
[Dataset url](https://archive.ics.uci.edu/ml/datasets/Website+Phishing#)

Neda Abdelhamid 
Auckland Institute of Studies 
nedah '@' ais.ac.nz

Data Set Information:

The phishing problem is considered a vital issue in â€œ.COMâ€ industry especially e-banking and e-commerce taking the number of online transactions involving payments. 
We have identified different features related to legitimate and phishy websites and collected 1353 different websites from difference sources.Phishing websites were collected from Phishtank data archive (www.phishtank.com), which is a free community site where users can submit, verify, track and share phishing data. The legitimate websites were collected from Yahoo and starting point directories using a web script developed in PHP. The PHP script was plugged with a browser and we collected 548 legitimate websites out of 1353 websites. There is 702 phishing URLs, and 103 suspicious URLs. 

When a website is considered SUSPICIOUS that means it can be either phishy or legitimate, meaning the website held some legit and phishy features.


Attribute Information:

URL Anchor	
Request URL	
SFH	
URL Length	
Having â€™@â€™	
Prefix/Suffix	
IP	
Sub Domain	
Web traffic	
Domain age	
Class 

collected features hold the categorical values , â€œLegitimateâ€, â€Suspiciousâ€ and â€œPhishyâ€, these values have been replaced with numerical values 1,0 and -1 respectively. 
details of each feature are mentioned in the research paper mentioned below 
 ",.csv
 Wholesale customers Data Set,1,wholesale-customers-data-set,Wholesale customers data.csv,CC0-1.0,"The dataset refers to clients of a wholesale distributor. It includes the annual spending in monetary units (m.u.) on diverse product categories

Source: [UCI Wholesale customers Data Set][1]

[1]: https://archive.ics.uci.edu/ml/datasets/wholesale+customers

",.csv
 World Population by Country ,1,2023-world-population-by-country,countries-table.csv,CC0-1.0,"**CONTENT**

The US Census Bureau's world population clock estimated that the global population as of September 2022 was 7,922,312,800 people and was expected to reach 8 billion by mid-November of 2022. This total far exceeds the 2015 world population of 7.2 billion. The world's population continues to increase by roughly 140 people per minute, with births outweighing deaths in most countries.

Overall, however, the rate of population growth has been slowing for several decades. This slowdown is expected to continue until the rate of population growth reaches zero (an equal number of births and deaths) around 2080-2100, at a population of approximately 10.4 billion people. After this time, the population growth rate is expected to turn negative, resulting in global population decline.

**Countries with more than 1 billion people**
China is currently the most populous country in the world, with a population estimated at more than 1.42 billion as of September 2022. Only one other country in the world boasts a population of more than 1 billion people: India, whose population is estimated to be 1.41 billion people—and rising.",.csv
 in-vehicle coupon recommendation,1,invehicle-coupon-recommendation,in-vehicle-coupon-recommendation.csv,CC0-1.0,"Source:

Tong Wang, tong-wang '@' uiowa.edu, University of Iowa
Cynthia Rudin, cynthia '@' cs.duke.edu, Duke University


Data Set Information:

This data was collected via a survey on Amazon Mechanical Turk. The survey describes different driving scenarios including the destination, current time, weather, passenger, etc., and then ask the person whether he will accept the coupon if he is the driver. For more information about the dataset, please refer to the paper:
Wang, Tong, Cynthia Rudin, Finale Doshi-Velez, Yimin Liu, Erica Klampfl, and Perry MacNeille. 'A bayesian framework for learning rule sets for interpretable classification.' The Journal of Machine Learning Research 18, no. 1 (2017): 2357-2393.


Attribute Information:

destination: No Urgent Place, Home, Work
passanger: Alone, Friend(s), Kid(s), Partner (who are the passengers in the car)
weather: Sunny, Rainy, Snowy
temperature:55, 80, 30
time: 2PM, 10AM, 6PM, 7AM, 10PM
coupon: Restaurant(&lt;$20), Coffee House, Carry out & Take away, Bar, Restaurant($20-$50)
expiration: 1d, 2h (the coupon expires in 1 day or in 2 hours)
gender: Female, Male
age: 21, 46, 26, 31, 41, 50plus, 36, below21
maritalStatus: Unmarried partner, Single, Married partner, Divorced, Widowed
has_Children:1, 0
education: Some college - no degree, Bachelors degree, Associates degree, High School Graduate, Graduate degree (Masters or Doctorate), Some High School
occupation: Unemployed, Architecture & Engineering, Student,
Education&Training&Library, Healthcare Support,
Healthcare Practitioners & Technical, Sales & Related, Management,
Arts Design Entertainment Sports & Media, Computer & Mathematical,
Life Physical Social Science, Personal Care & Service,
Community & Social Services, Office & Administrative Support,
Construction & Extraction, Legal, Retired,
Installation Maintenance & Repair, Transportation & Material Moving,
Business & Financial, Protective Service,
Food Preparation & Serving Related, Production Occupations,
Building & Grounds Cleaning & Maintenance, Farming Fishing & Forestry
income: $37500 - $49999, $62500 - $74999, $12500 - $24999, $75000 - $87499,
$50000 - $62499, $25000 - $37499, $100000 or More, $87500 - $99999, Less than $12500
Bar: never, less1, 1~3, gt8, nan4~8 (feature meaning: how many times do you go to a bar every month?)
CoffeeHouse: never, less1, 4~8, 1~3, gt8, nan (feature meaning: how many times do you go to a coffeehouse every month?)
CarryAway:n4~8, 1~3, gt8, less1, never (feature meaning: how many times do you get take-away food every month?)
RestaurantLessThan20: 4~8, 1~3, less1, gt8, never (feature meaning: how many times do you go to a restaurant with an average expense per person of less than $20 every month?)
Restaurant20To50: 1~3, less1, never, gt8, 4~8, nan (feature meaning: how many times do you go to a restaurant with average expense per person of $20 - $50 every month?)
toCoupon_GEQ15min:0,1 (feature meaning: driving distance to the restaurant/bar for using the coupon is greater than 15 minutes)
toCoupon_GEQ25min:0, 1 (feature meaning: driving distance to the restaurant/bar for using the coupon is greater than 25 minutes)
direction_same:0, 1 (feature meaning: whether the restaurant/bar is in the same direction as your current destination)
direction_opp:1, 0 (feature meaning: whether the restaurant/bar is in the same direction as your current destination)
Y:1, 0 (whether the coupon is accepted)


Relevant Papers:

Wang, Tong, Cynthia Rudin, Finale Doshi-Velez, Yimin Liu, Erica Klampfl, and Perry MacNeille. 'A bayesian framework for learning rule sets for interpretable classification.' The Journal of Machine Learning Research 18, no. 1 (2017): 2357-2393.

",.csv
" 🍜  27,000 + Indian Restaurant Dataset 🏰 🍰",1,27000-indian-restaurant-dataset,indian_restaurants.csv,CC0-1.0,"This dataset seems comprehensive and covers various aspects of Indian restaurants, including their names, ratings, pricing, delivery times, cuisine types, and location.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F13571604%2F29559756d035ce9b1cfcf95be922296a%2FScreenshot%202023-11-11%20195855.png?generation=1699759908815024&alt=media)
",.csv
"""Aussie Vehicle Tax Exemptions: Check Eligibility""",1,aussie-vehicle-tax-exemptions-check-eligibility,WA_Tax_Exemptions_-_Potential_Eligibility_by_Make_Model_Excluding_Vehicle_Price_Criteria.csv,DbCL-1.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F17774467%2F268dc200b5be960a743fe7d675ac7da2%2F78-170047-odd-taxes-tattoo-plaster-chopstick_700x400.jpeg?generation=1714322893649253&alt=media)This list is based only on vehicle description. To determine eligibility, price must be considered. Only vehicles meeting the requirements for clean alternative fuel and electric-only range are listed (per RCW 82.08.9999 and 82.12.9999). Sales or leases must occur on or after 8/1/2019, and meet the purchase price requirements to be eligible for the sales and use tax exemptions.This exemption only applies to passenger cars, light duty trucks, and medium duty passenger vehicles (defined in RCW 46.04.382, RCW 46.04.271). Motorcycles (defined in RCW 46.04.330) are not eligible for this exemption. ",.csv
#MeToo Tweets Dataset,1,me-too-movement-tweets-dataset,MeToo_Tweets.csv,CC0-1.0,"This dataset is a compilation of over 28000 tweets posted on Twitter/X during the Me Too movement around 2017-18. The dataset consists of the following columns:-

**1.  tweetid:** Unique Identifier of all tweets

**2. created:** Date and Time when the tweet was posted

**3. text:** The text content of the tweet

**4. retweets:** Number of retweets on the dataset

**5. favorites:** Number of users who marked the tweet in their 'favorites'.

**6. source.r:** Source OS of the tweet

**7. hashtag:** mentions/hashtags in the tweet

**8. num.emojis:** Number of emojis used in tweet

**9. emoji_names:** Name of emoji used",.csv
(Amazon Survey) Coupon Recommendation Dataset,1,amazon-survey-coupon-recommendation-dataset,coupon.csv,Apache 2.0,"This data was collected via a survey on Amazon Mechanical Turk. 

The survey describes different driving scenarios including the destination, current time, weather, passenger, etc., and then ask the person whether he will accept the coupon if he is the driver.",.csv
(LoL) League of Legends Ranked Games,1,league-of-legends,games.csv,CC0-1.0,"General Info
----------------

This is a collection of over 50,000 ranked EUW games from the game League of Legends, as well as json files containing a way to convert between champion and summoner spell IDs and their names. For each game, there are fields for:

 - Game ID
 - Creation Time (in Epoch format)
 - Game Duration (in seconds)
 - Season ID
 - Winner (1 = team1,   2 = team2)
 - First Baron, dragon, tower, blood, inhibitor and Rift Herald (1 = team1,   2 = team2, 0 = none)
 - Champions and summoner spells for each team (Stored as Riot's champion and summoner spell IDs)
 - The number of tower, inhibitor, Baron, dragon and Rift Herald kills each team has
 - The 5 bans of each team (Again, champion IDs are used)

This dataset was collected using the Riot Games API, which makes it easy to lookup and collect information on a users ranked history and collect their games. However finding a list of usernames is the hard part, in this case I am using a list of usernames scraped from 3rd party LoL sites.

Possible Uses
-------------

There is a vast amount of data in just a single LoL game. This dataset takes the most relevant information and makes it available easily for use in things such as attempting to predict the outcome of a LoL game, analysing which in-game events are most likely to lead to victory, understanding how big of an effect bans of a specific champion have, and more.",.csv
10.000 ENGLISH WORDS CERF LABELLED,1,10-000-english-words-cerf-labelled,ENGLISH_CERF_WORDS.csv,Apache 2.0,"This dataset comprises 10,000 English words, each labeled according to the Common European Framework of Reference for Languages (CEFR) levels. CEFR is a language learning standard that classifies language skills into six different levels (A1, A2, B1, B2, C1, C2). This dataset serves as a valuable resource for English language learning and teaching. The CEFR level of each word guides learners on which words to focus on while enhancing their language skills. This compilation can be used for various purposes such as classifying words by English proficiency level, creating language learning materials, preparing language tests, and conducting language education research.",.csv
1000 Cameras Dataset,1,1000-cameras-dataset,camera_dataset.csv,CC-BY-SA-3.0,"### Context

Some camera enthusiast went and described 1,000 cameras based on 13 properties! 

### Content

Row one describes the datatype for each column and can probably be removed.

The 13 properties of each camera:

- Model
- Release date
- Max resolution
- Low resolution
- Effective pixels
- Zoom wide (W)
- Zoom tele (T)
- Normal focus range
- Macro focus range
- Storage included
- Weight (inc. batteries)
- Dimensions
- Price



### Acknowledgements
These datasets have been gathered and cleaned up by Petra Isenberg, Pierre Dragicevic and Yvonne Jansen.  The original source can be found [here][1].

This dataset has been converted to CSV.



  [1]: https://perso.telecom-paristech.fr/eagan/class/igr204/datasets",.csv
1000 Netflix Shows,1,netflix-shows,netflix_titles.csv,CC0-1.0,"### Context

Netflix in the past 5-10 years has captured a large populate of viewers. With more viewers, there most likely an increase of show variety. However, do people understand the distribution of ratings on Netflix shows?

### Content

Because of the vast amount of time it would take to gather 1,000 shows one by one, the gathering method took advantage of the Netflix’s suggestion engine. The suggestion engine recommends shows similar to the selected show. As part of this data set, I took 4 videos from 4 ratings (totaling 16 unique shows), then pulled 53 suggested shows per video. The ratings include: G, PG, TV-14, TV-MA. I chose not to pull from every rating (e.g. TV-G, TV-Y, etc.).


### Acknowledgements

The data set and the research article can be found at [The Concept Center](http://theconceptcenter.com/simple-research-study-netflix-shows-analysis/)


### Inspiration

I was watching Netflix with my wife and we asked ourselves, why are there so many R and TV-MA rating shows?",.csv
1000+ Data Science Concepts,1,1000-data-science-concepts,data_science_concepts.csv,CC-BY-SA-4.0,"This dataset covers more than 1000 common data science concepts. It covers several topics related to statistics, machine learning, and artificial intelligence. It has two columns, one of which is questions or instructions, the other is responses to these instructions. The dataset can be used in Q&A and text generation.",.csv
1000_Companies.csv,1,1000-companiescsv,1000_Companies.csv,MIT,"### The dataset you described consists of sample data for 1000 startup companies, focusing on their operating costs and profits. It is designed to be well-formatted and suitable for building machine learning regression pipelines.
```
The dataset contains the following features:

R&D Spend (float64): This feature represents the amount of money a startup spends on research and development activities. It indicates the investment made in creating new products, improving existing ones, or enhancing overall technological capabilities.

Administration (float64): This feature represents the amount of money a startup spends on administrative tasks and overhead expenses. It includes costs associated with office space, utilities, salaries of non-production staff, and other general operational expenses.

Marketing Spend (float64): This feature represents the amount of money a startup invests in marketing and promotional activities. It includes expenses related to advertising campaigns, online marketing efforts, public relations, and other initiatives aimed at increasing brand visibility and attracting customers.

State (object): This feature captures the state in which each startup operates. It is represented as an object type, suggesting that it contains categorical or textual information about the geographical location of the company. The state information can be useful for analyzing regional trends or identifying potential variations in operating costs and profits across different locations.

Profit (float64): This feature represents the profitability of each startup. It indicates the financial gain or loss generated by the company within a specific period. Profit is typically measured as the revenue earned minus the total operating costs incurred, including R&D spend, administration expenses, marketing spend, and other relevant factors.
```

With this dataset, you can build regression models to predict the profit of startup companies based on their R&D spend, administration costs, marketing spend, and the state in which they operate. The dataset provides a valuable resource for developing and evaluating machine learning algorithms that can help in understanding the relationship between these variables and the profitability of startups.",.csv
11000 Medicine details,1,11000-medicine-details,Medicine_Details.csv,CC0-1.0,"This dataset is a valuable resource for healthcare professionals, data scientists, and enthusiasts interested in exploring the world of medicines and healthcare products. It contains a rich repository of information scraped from 1mg, a popular online pharmacy and healthcare platform, covering over 11,000 medicines.",.csv
12000 Data Science Jobs in India - Naukri.com,1,data-science-jobs-in-india,naukri_data_science_jobs_india.csv,DbCL-1.0,"## About

**Naukri.com** is an Indian employment website operating in India and Middle East. It was founded in March 1997. Naukri was ranked No.1 by 9 independent sources, placing it way ahead of competition.Google Trends names Naukri “the most preferred job search destination in India”.

This dataset contains data of first 12,000 results obtained for '**data scientist**' job role in '**India**' from Naukri.com, on **May 18, 2022**

**Starter Notebook** : https://www.kaggle.com/code/anandhuh/data-science-jobs-in-india-eda-naukri-com

## Attribute Information

1. **Job_Role** - Job Roles
2. **Company** - Name of the Company
3. **Location** - Location of the company
4. **Job Experience** - Required Job Experience (Min. Experience-Max. Experience)
5. **Skills/Description** - Required Skills for the Job

## Source

Link : **https://www.naukri.com/**

## Other Updated  Datasets

https://www.kaggle.com/anandhuh/datasets
Please appreciate the effort with an **upvote** 👍 

### Thank You",.csv
1300+ Towards DataScience Medium Articles Dataset,1,1300-towards-datascience-medium-articles-dataset,medium.csv,MIT,"### Towards Data Science Medium Articles Dataset

#### Overview

This dataset is a comprehensive collection of blog posts sourced from Medium, focusing specifically on articles published under the ""Towards Data Science"" publication. It consists of two primary columns:

- **Title**: Contains the title of each blog post, providing a concise summary of the content and facilitating tasks such as title-based classification, keyword extraction, and trend analysis.
  
- **Text**: Contains the full text content of each blog post, offering detailed information and insights on various topics in Data Science. This column serves as a valuable resource for Natural Language Processing (NLP) tasks including sentiment analysis, topic modeling, text classification, information extraction, text generation, and recommendation systems.

#### Purpose

The dataset offers a comprehensive view of the current discourse within the Towards Data Science community on Medium. It enables the exploration of trends, popular topics, and the evolution of Data Science over time. Additionally, it serves as a valuable resource for researchers and practitioners in the field of NLP, providing ample opportunities for data exploration, model training, and algorithm development.


#### Provenance

All articles included in this dataset were publicly accessible on Medium at the time of collection and are intended for research and educational purposes only.

#### Contact

For inquiries or further information regarding the dataset, please contact the curator at [your contact email or institution].

#### Note

The dataset respects the intellectual property rights of the respective authors and publications, and users are expected to adhere to ethical guidelines and copyright regulations when using the data.

",.csv
1700+ K-Pop Idols Dataset,1,all-kpop-idols,kpopidolsv3.csv,CC0-1.0,"The world of K-Pop is one of the most popular and dynamic music industries in the world. This comprehensive dataset provides information on over 1,700 K-Pop idols, including their stage name, full name, Korean name, birthdate, height, weight, birthplace, and former and other group affiliations. This dataset is perfect for anyone interested in exploring the K-Pop industry or conducting research on K-Pop idols.",.csv
"2,2k+ Scotch Whisky Reviews",1,22000-scotch-whisky-reviews,scotch_review.csv,CC0-1.0,"### Context

Dataset was scraped from [Whisky Advocate][1]. You can take a look at scraping script [here][2].


### Content

 - name: Name of whisky bottle
 - category: Whisky category
 - review.point: Point marked by each reviewers
 - price: Price of each bottle
 - currency: Unit of price
 - description: Descriptions of reviews

### Acknowledgements

Original database is from [Whisky Advocate][3].


### Inspiration

Can you find characteristics of each category of whisky?

  [1]: http://whiskyadvocate.com/
  [2]: https://github.com/koki25ando/Whisky-Data-Scraping/blob/master/whisky.R
  [3]: http://whiskyadvocate.com/",.csv
2016 Global Ecological Footprint,1,ecological-footprint,countries.csv,CC-BY-NC-SA-4.0,"# Context

The ecological footprint measures the ecological assets that a given population requires to produce the natural resources it consumes (including plant-based food and fiber products, livestock and fish products, timber and other forest products, space for urban infrastructure) and to absorb its waste, especially carbon emissions. The footprint tracks the use of six categories of productive surface areas: cropland, grazing land, fishing grounds, built-up (or urban) land, forest area, and carbon demand on land.

A nation’s biocapacity represents the productivity of its ecological assets, including cropland, grazing land, forest land, fishing grounds, and built-up land. These areas, especially if left unharvested, can also absorb much of the waste we generate, especially our carbon emissions.

Both the ecological footprint and biocapacity are expressed in global hectares — globally comparable, standardized hectares with world average productivity.

If a population’s ecological footprint exceeds the region’s biocapacity, that region runs an ecological deficit. Its demand for the goods and services that its land and seas can provide — fruits and vegetables, meat, fish, wood, cotton for clothing, and carbon dioxide absorption — exceeds what the region’s ecosystems can renew. A region in ecological deficit meets demand by importing, liquidating its own ecological assets (such as overfishing), and/or emitting carbon dioxide into the atmosphere. If a region’s biocapacity exceeds its ecological footprint, it has an ecological reserve.


# Acknowledgements

The ecological footprint measure was conceived by Mathis Wackernagel and William Rees at the University of British Columbia. Ecological footprint data was provided by the Global Footprint Network.


# Inspiration

Is your country running an ecological deficit, consuming more resources than it can produce per year? Which countries have the greatest ecological deficits or reserves? Do they consume less or produce more than the average country? When will Earth Overshoot Day, the day on the calendar when humanity has used one year of natural resources, occur in 2017?",.csv
2016 New Coder Survey,1,2016-new-coder-survey-,2016-FCC-New-Coders-Survey-Data.csv,ODbL-1.0,"### Context

[Free Code Camp](https://www.freecodecamp.com) is an open source community where you learn to code and build projects for nonprofits. [CodeNewbie.org](https://www.codenewbie.org) is the most supportive community of people learning to code. Together, we surveyed more than 15,000 people who are actively learning to code. We reached them through the twitter accounts and email lists of various organizations that help people learn to code. Our goal was to understand these people's motivations in learning to code, how they're learning to code, their demographics, and their socioeconomic background. [We've written in depth about this dataset](https://medium.freecodecamp.com/we-asked-15-000-people-who-they-are-and-how-theyre-learning-to-code-4104e29b2781#.5mxwnyk80).

In May 2017 we just released an [even bigger open dataset with our 2017 survey results](https://www.kaggle.com/free-code-camp/the-freecodecamp-2017-new-coder-survey).",.csv
2016 US Presidential Debates,1,2016-us-presidential-debates,debate.csv,CC0-1.0,"## Context

In November, the United States will elect a new president. Before then, three presidential debates will take place between Hillary Clinton and Donald Trump as well as one vice presidential debate between Tim Kaine and Mike Pence. While you can watch the debates live, why not also read deeply into the candidates' responses with text analytics?

You can now answer any questions you have about the platforms of our presidential hopefuls or their speaking skills.

- Which candidate is the most given to loquaciousness? 

- How many times does Clinton get interrupted?

- Who gets the most audience applause?

- When is positive sentiment at its highest during the candidates' word play?

## Content & Acknowledgements

For consistency, full transcripts of the debates were all taken from The Washington Post who made annotated transcripts available following each debate:

* First debate taking place September 26th, 2016 was obtained from [The Washington Post][1]. 

* The vice presidential debate from October 4th, 2016 was similarly [obtained here][2].

* The ""town hall"" presidential debate on October 9th is [found here][3].

* The final presidential debate taking place on October 19th is [found here][4].

![Debate word cloud][7]

*Please make any dataset suggestions or requests on the forum. Word cloud from [Debate Visualization][5] by [Jane Yu][6].*


  [1]: https://www.washingtonpost.com/news/the-fix/wp/2016/09/26/the-first-trump-clinton-presidential-debate-transcript-annotated/
  [2]: https://www.washingtonpost.com/news/the-fix/wp/2016/10/04/the-mike-pence-vs-tim-kaine-vice-presidential-debate-transcript-annotated/
  [3]: https://www.washingtonpost.com/news/the-fix/wp/2016/10/09/everything-that-was-said-at-the-second-donald-trump-vs-hillary-clinton-debate-highlighted/
  [4]: https://www.washingtonpost.com/news/the-fix/wp/2016/10/19/the-final-trump-clinton-debate-transcript-annotated/
  [5]: https://www.kaggle.com/janeyu/d/mrisdal/2016-us-presidential-debates/debate-visualization
  [6]: https://www.kaggle.com/janeyu
  [7]: https://www.kaggle.io/svf/396847/2f29647ac57fd5af0bb696fce9f3cd85/__results___files/__results___13_1.png",.csv
2017 Yellow Taxi Trip Data,1,new-york-city-taxi-and-limousine-commission-data,2017_Yellow_Taxi_Trip_Data.csv,other,"These records are generated from the trip record submissions made by yellow taxi Technology Service Providers (TSPs). Each row represents a single trip in a yellow taxi. The trip records include fields capturing pick-up and drop-off dates/times, pick-up and drop-off taxi zone locations, trip distances, itemized fares, rate types, payment types, and driver-reported passenger counts.",.csv
"2018 calorie, exercise and weight changes",1,2018-calorie-exercise-and-weight-changes,diet_data.csv,CC0-1.0,"### Context

Following a festive period a couple of years ago, I began a weight loss diet in early January to lose the Christmas-period pounds. Working on the assumption that the laws of thermodynamics applied to me as much as the rest of the universe, I didn't care about what I ate, as long as I consumed fewer calories than I used.

As I think that there is a lot of mis-information in the huge market that is the weight-management sector, I made sure that I ate everything I was told not to; click-bait articles such as ""the six foods you MUST NOT EAT if you want to lose weight"" were my bread and butter. I made sure to eat them all, and show that I could still lose weight, just by not eating too much of them.

In 2018, I decided to be a bit more formal about this, and record a daily diary of approximate calorie intake and a few things to do with what I ate and what exercise I did. The idea was to come up with a dataset for regression analysis to try to learn a bit more about the effect of calories and exercise on changes in my weight.

My goal was to get down to 11 stone and a single digit number of pounds in advance of my work Christmas party, ready to put it all on again over the festive period 18/19 and have a good set of regression coefficients to tell me how to lose it again in 2019.

",.csv
2019 Census US Population Data By State,1,2019-census-us-population-data-by-state,2019_Census_US_Population_Data_By_State_Lat_Long.csv,GPL-2.0,"### Context

https://www.kaggle.com/peretzcohen/us-vaccine-status-by-state

### Content

This population data is pulled from the 2019 US Census and is here along with latitude and longitude data for each states' capital city


### Acknowledgements
Population Data - https://www.census.gov/data/datasets/time-series/demo/popest/2010s-state-total.html
Location Data - https://github.com/jasperdebie/VisInfo/blob/master/us-state-capitals.csv

",.csv
2019-2024 US Stock Market Data,1,2019-2024-us-stock-market-data,Stock Market Dataset.csv,DbCL-1.0,"This dataset encapsulates a detailed examination of market dynamics over a five-year period, focusing on the fluctuation of prices and trading volumes across a diversified portfolio. It covers various sectors including energy commodities like natural gas and crude oil, metals such as copper, platinum, silver, and gold, cryptocurrencies including Bitcoin and Ethereum, and key stock indices and companies like the S&P 500, Nasdaq 100, Apple, Tesla, Microsoft, Google, Nvidia, Berkshire Hathaway, Netflix, Amazon, and Meta Platforms. This dataset serves as a valuable resource for analyzing trends and patterns in global markets.

Date: The date of the recorded data, formatted as DD-MM-YYYY.
Natural_Gas_Price: Price of natural gas in USD per million British thermal units (MMBtu).
Natural_Gas_Vol.: Trading volume of natural gas
Crude_oil_Price: Price of crude oil in USD per barrel.
Crude_oil_Vol.: Trading volume of crude oil
Copper_Price: Price of copper in USD per pound.
Copper_Vol.: Trading volume of copper
Bitcoin_Price: Price of Bitcoin in USD.
Bitcoin_Vol.: Trading volume of Bitcoin
Platinum_Price: Price of platinum in USD per troy ounce.
Platinum_Vol.: Trading volume of platinum
Ethereum_Price: Price of Ethereum in USD.
Ethereum_Vol.: Trading volume of Ethereum
S&P_500_Price: Price index of the S&P 500.
Nasdaq_100_Price: Price index of the Nasdaq 100.
Nasdaq_100_Vol.: Trading volume for the Nasdaq 100 index
Apple_Price: Stock price of Apple Inc. in USD.
Apple_Vol.: Trading volume of Apple Inc. stock
Tesla_Price: Stock price of Tesla Inc. in USD.
Tesla_Vol.: Trading volume of Tesla Inc. stock
Microsoft_Price: Stock price of Microsoft Corporation in USD.
Microsoft_Vol.: Trading volume of Microsoft Corporation stock
Silver_Price: Price of silver in USD per troy ounce.
Silver_Vol.: Trading volume of silver
Google_Price: Stock price of Alphabet Inc. (Google) in USD.
Google_Vol.: Trading volume of Alphabet Inc. stock
Nvidia_Price: Stock price of Nvidia Corporation in USD.
Nvidia_Vol.: Trading volume of Nvidia Corporation stock
Berkshire_Price: Stock price of Berkshire Hathaway Inc. in USD.
Berkshire_Vol.: Trading volume of Berkshire Hathaway Inc. stock
Netflix_Price: Stock price of Netflix Inc. in USD.
Netflix_Vol.: Trading volume of Netflix Inc. stock
Amazon_Price: Stock price of Amazon.com Inc. in USD.
Amazon_Vol.: Trading volume of Amazon.com Inc. stock
Meta_Price: Stock price of Meta Platforms, Inc. (formerly Facebook) in USD.
Meta_Vol.: Trading volume of Meta Platforms, Inc. stock
Gold_Price: Price of gold in USD per troy ounce.
Gold_Vol.: Trading volume of gold

Image attribute : Image by <a href=""https://www.freepik.com/free-vector/gradient-stock-market-concept_20289170.htm#&position=0&from_view=search&track=ais&uuid=cc64817b-9541-489e-8ddf-23acc4e23d59"">Freepik</a>
",.csv
2020 Cost of Living,1,2020-cost-of-living,cost of living 2020.csv,other,"### Context

The present data is extracted from [Numbeo - Cost of Living](https://www.numbeo.com/cost-of-living/) for mid year 2020.

Source of data can be found here: https://www.numbeo.com/cost-of-living/rankings_by_country.jsp",.csv
2021-2022 Football Player Stats,1,20212022-football-player-stats,2021-2022 Football Player Stats.csv,Attribution 4.0 International (CC BY 4.0),"### Context

This dataset contains 2021-2022 football player stats per 90 minutes.
Only players of Premier League, Ligue 1, Bundesliga, Serie A and La Liga are listed.

* [2022-2023 Football Player Stats](https://www.kaggle.com/datasets/vivovinco/20222023-football-player-stats)
* [2021-2022 Football Team Stats](https://www.kaggle.com/datasets/vivovinco/20212022-football-team-stats)
* [2022-2023 Football Team Stats](https://www.kaggle.com/datasets/vivovinco/20222023-football-team-stats)


### Content

+2500 rows and 143 columns.
Columns' description are listed below.

* Rk : Rank
* Player : Player's name
* Nation : Player's nation
* Pos : Position
* Squad : Squad’s name
* Comp : League that squat occupies
* Age : Player's age
* Born : Year of birth
* MP : Matches played
* Starts : Matches started
* Min : Minutes played
* 90s : Minutes played divided by 90
* Goals : Goals scored or allowed
* Shots : Shots total (Does not include penalty kicks)
* SoT : Shots on target (Does not include penalty kicks)
* SoT% : Shots on target percentage (Does not include penalty kicks)
* G/Sh : Goals per shot
* G/SoT : Goals per shot on target (Does not include penalty kicks)
* ShoDist : Average distance, in yards, from goal of all shots taken (Does not include penalty kicks)
* ShoFK : Shots from free kicks
* ShoPK : Penalty kicks made
* PKatt : Penalty kicks attempted
* PasTotCmp : Passes completed
* PasTotAtt : Passes attempted
* PasTotCmp% : Pass completion percentage
* PasTotDist : Total distance, in yards, that completed passes have traveled in any direction
* PasTotPrgDist : Total distance, in yards, that completed passes have traveled towards the opponent's goal
* PasShoCmp : Passes completed (Passes between 5 and 15 yards)
* PasShoAtt : Passes attempted (Passes between 5 and 15 yards)
* PasShoCmp% : Pass completion percentage (Passes between 5 and 15 yards)
* PasMedCmp : Passes completed (Passes between 15 and 30 yards)
* PasMedAtt : Passes attempted (Passes between 15 and 30 yards)
* PasMedCmp% : Pass completion percentage (Passes between 15 and 30 yards)
* PasLonCmp : Passes completed (Passes longer than 30 yards)
* PasLonAtt : Passes attempted (Passes longer than 30 yards)
* PasLonCmp% : Pass completion percentage (Passes longer than 30 yards)
* Assists : Assists
* PasAss : Passes that directly lead to a shot (assisted shots)
* Pas3rd : Completed passes that enter the 1/3 of the pitch closest to the goal
* PPA : Completed passes into the 18-yard box
* CrsPA : Completed crosses into the 18-yard box
* PasProg : Completed passes that move the ball towards the opponent's goal at least 10 yards from its furthest point in the last six passes, or any completed pass into the penalty area
* PasAtt : Passes attempted
* PasLive : Live-ball passes
* PasDead : Dead-ball passes
* PasFK : Passes attempted from free kicks
* TB : Completed pass sent between back defenders into open space
* PasPress : Passes made while under pressure from opponent
* Sw : Passes that travel more than 40 yards of the width of the pitch
* PasCrs : Crosses
* CK : Corner kicks
* CkIn : Inswinging corner kicks
* CkOut : Outswinging corner kicks
* CkStr : Straight corner kicks
* PasGround : Ground passes
* PasLow : Passes that leave the ground, but stay below shoulder-level
* PasHigh : Passes that are above shoulder-level at the peak height
* PaswLeft : Passes attempted using left foot
* PaswRight : Passes attempted using right foot
* PaswHead : Passes attempted using head
* TI : Throw-Ins taken
* PaswOther : Passes attempted using body parts other than the player's head or feet
* PasCmp : Passes completed
* PasOff : Offsides
* PasOut : Out of bounds
* PasInt : Intercepted
* PasBlocks : Blocked by the opponent who was standing it the path
* SCA : Shot-creating actions
* ScaPassLive : Completed live-ball passes that lead to a shot attempt
* ScaPassDead : Completed dead-ball passes that lead to a shot attempt
* ScaDrib : Successful dribbles that lead to a shot attempt
* ScaSh : Shots that lead to another shot attempt
* ScaFld : Fouls drawn that lead to a shot attempt
* ScaDef : Defensive actions that lead to a shot attempt
* GCA : Goal-creating actions
* GcaPassLive : Completed live-ball passes that lead to a goal
* GcaPassDead : Completed dead-ball passes that lead to a goal
* GcaDrib : Successful dribbles that lead to a goal
* GcaSh : Shots that lead to another goal-scoring shot
* GcaFld : Fouls drawn that lead to a goal
* GcaDef : Defensive actions that lead to a goal
* Tkl : Number of players tackled
* TklWon : Tackles in which the tackler's team won possession of the ball
* TklDef3rd : Tackles in defensive 1/3
* TklMid3rd : Tackles in middle 1/3
* TklAtt3rd : Tackles in attacking 1/3
* TklDri : Number of dribblers tackled
* TklDriAtt : Number of times dribbled past plus number of tackles
* TklDri% : Percentage of dribblers tackled
* TklDriPast : Number of times dribbled past by an opposing player
* Press : Number of times applying pressure to opposing player who is receiving, carrying or releasing the ball
* PresSucc : Number of times the squad gained possession withing five seconds of applying pressure
* Press% : Percentage of time the squad gained possession withing five seconds of applying pressure
* PresDef3rd : Number of times applying pressure to opposing player who is receiving, carrying or releasing the ball, in the defensive 1/3
* PresMid3rd : Number of times applying pressure to opposing player who is receiving, carrying or releasing the ball, in the middle 1/3
* PresAtt3rd : Number of times applying pressure to opposing player who is receiving, carrying or releasing the ball, in the attacking 1/3
* Blocks : Number of times blocking the ball by standing in its path
* BlkSh : Number of times blocking a shot by standing in its path
* BlkShSv : Number of times blocking a shot that was on target, by standing in its path
* BlkPass : Number of times blocking a pass by standing in its path
* Int : Interceptions
* Tkl+Int : Number of players tackled plus number of interceptions
* Clr : Clearances
* Err : Mistakes leading to an opponent's shot
* Touches : Number of times a player touched the ball. Note: Receiving a pass, then dribbling, then sending a pass counts as one touch
* TouDefPen : Touches in defensive penalty area
* TouDef3rd : Touches in defensive 1/3
* TouMid3rd : Touches in middle 1/3
* TouAtt3rd : Touches in attacking 1/3
* TouAttPen : Touches in attacking penalty area
* TouLive : Live-ball touches. Does not include corner kicks, free kicks, throw-ins, kick-offs, goal kicks or penalty kicks.
* DriSucc : Dribbles completed successfully
* DriAtt : Dribbles attempted
* DriSucc% : Percentage of dribbles completed successfully
* DriPast : Number of players dribbled past
* DriMegs : Number of times a player dribbled the ball through an opposing player's legs
* Carries : Number of times the player controlled the ball with their feet
* CarTotDist : Total distance, in yards, a player moved the ball while controlling it with their feet, in any direction
* CarPrgDist : Total distance, in yards, a player moved the ball while controlling it with their feet towards the opponent's goal
* CarProg : Carries that move the ball towards the opponent's goal at least 5 yards, or any carry into the penalty area
* Car3rd : Carries that enter the 1/3 of the pitch closest to the goal
* CPA : Carries into the 18-yard box
* CarMis : Number of times a player failed when attempting to gain control of a ball
* CarDis : Number of times a player loses control of the ball after being tackled by an opposing player
* RecTarg : Number of times a player was the target of an attempted pass
* Rec : Number of times a player successfully received a pass
* Rec% : Percentage of time a player successfully received a pass
* RecProg : Completed passes that move the ball towards the opponent's goal at least 10 yards from its furthest point in the last six passes, or any completed pass into the penalty area
* CrdY : Yellow cards
* CrdR : Red cards
* 2CrdY : Second yellow card
* Fls : Fouls committed
* Fld : Fouls drawn
* Off : Offsides
* Crs : Crosses
* TklW : Tackles in which the tackler's team won possession of the ball
* PKwon : Penalty kicks won
* PKcon : Penalty kicks conceded
* OG : Own goals
* Recov : Number of loose balls recovered
* AerWon : Aerials won
* AerLost : Aerials lost
* AerWon% : Percentage of aerials won


### Acknowledgements

Data from [Football Reference](https://fbref.com/en/comps/Big5/stats/players/Big-5-European-Leagues-Stats).
Image from [UEFA Champions League]( https://www.uefa.com/uefachampionsleague/news/0274-14e4e34800ac-329b575ccee6-1000--champions-league-final-liverpool-vs-real-madrid/?utm_campaign=ucl-editorial-ongoin&utm_content=_&utm_medium=social&utm_source=twitter).

**If you're reading this, please upvote.**
",.csv
2022 Fortune 1000,1,fortune-500-data-2021,Fortune_1000.csv,other,"## Context

Every year Fortune, an American Business Magazine, publishes the Fortune 500, which ranks the top 500 corporations by revenue. This dataset includes the entire Fortune 1000, as opposed to just the top 500. 



## Content

The Fortune 1000 dataset is from the Fortune [website](https://fortune.com/), collected by the processes outlined in this [notebook](https://www.kaggle.com/winston56/fortune-500-data-collection). It contains U.S. company data for the year 2022 (updated from 2021). The dataset is 1000 rows and 18 columns.

### Features

- **Company** - values are the name of the company
- **Rank** - The 2021 rank established by Fortune (1-1000)
- **Rank Change** - The change in the rank from 2020 to 2021. There is only a rank change listed if the company is currently in the top 500 and was previously in the top 500. 
- **Revenue** - Revenue of each company in millions. This is the criteria used to rank each company.
- **Profit** - Profit of each company in millions.
- **Num. of Employees**  - The number of employees each company employs. 
- **Sector** - The sector of the market the company operates in.
- **City** - The city where the company's headquarters is located.
- **State** - The state where the company's headquarters is located
- **Newcomer** - Indicates whether or not the company is new to the top Fortune 500 (""yes"" or ""no""). No value will be listed for companies outside of the top 500.
- **CEO Founder** - Indicates whether the CEO of the company is also the founder (""yes"" or ""no"").
- **CEO Woman** - Indicates whether the CEO of the company is a woman (""yes"" or ""no"").
- **Profitable** - Indicates whether the company is profitable or not (""yes"" or ""no"").
- **Prev. Rank** - The 2020 rank of the company, as established by Fortune. There will only be previous rank data for the top 500 companies. 
- **CEO** - The name of the CEO of the company
- **Website** - The url of the company website
- **Ticker** - The stock ticker symbol of public companies. Some rows will have empty values because the company is a private corporation. 
- **Market Cap** - The market cap (or value) of the company in millions. Some rows will have empty values because the company is private.  Market valuations were determined on January 20, 2021. 








## Inspiration

This dataset is made to explore the top corporations in the U.S. Answer questions such as: What percentage of companies have women ceo's? How many companies are newcomers? What percentage of companies have ceos who were also founders? What role does profitability play in ranking? ",.csv
2022 Fuel Consumption Ratings,1,2022-fuel-consumption-ratings,MY2022 Fuel Consumption Ratings.csv,CC0-1.0,Dataset provides model-specific fuel consumption ratings and estimated carbon dioxide emissions for new light-duty vehicles for retail sale in Canada in 2022.,.csv
2022 IPL Auction Dataset,1,2022-ipl-auction-dataset,ipl_2022_dataset.csv,CC0-1.0,"### Context

The IPL 2022 Mega Player auction have featured a total of 600 players who were set to go under the hammer in Bengaluru. The initial list had over 1000 cricketers who had registered for the auction. However, the final list was trimmed to 590. There was a total of 217 slots spread across ten franchises up for grabs. Among the 600 players, 229 are capped players, 371 are uncapped players


### Content

The dataset includes Data of all sold and unsold players.

#### Data Columns:
* Index Number
* Player Name
* Base Price
* Type of the player
* Total Cost in Cr Indian Rupees
* Total Cost in USD
* Team of the Player in 2021
* Team of the Player in 2022


### Acknowledgements

The data was scrapped from news18.com/cricketnext

### Inspiration

The fan base of IPL in India is huge, being a IPL fan I decided to create this dataset",.csv
2022 March Laptop data,1,2022-march-laptop-data,Cleaned_Laptop_data.csv,CC0-1.0,"# What Factors Affect Laptop Computer Prices? 
- Several different factors can affect laptop computer prices. These factors include the brand of computer and the number of options and add-ons included in the computer package. In addition, the amount of memory and the speed of the processor can also affect pricing. Though less common, some consumers spend additional money to purchase a computer based on the overall “look” and design of the system.
- In many cases, name brand computers are more expensive than generic versions. This price increase often has more to do with name recognition than any actual superiority of the product. One major difference between name brand and generic systems is that in most cases, name brand computers offer better warranties than generic versions. Having the option of returning a computer that is malfunctioning is often enough of an incentive to encourage many consumers to spend more money.
- Functionality is an important factor in determining laptop computer prices. A computer with more memory often performs better for a longer time than a computer with less memory. In addition, hard drive space is also crucial, and the size of the hard drive usually affects pricing. Many consumers may also look for digital video drivers and other types of recording devices that may affect the laptop computer prices.
- Most computers come with some software pre-installed. In most cases, the more software that is installed on a computer, the more expensive it is. This is especially true if the installed programs are from well-established and recognizable software publishers. Those considering purchasing a new laptop computer should be aware that many of the pre-installed programs may be trial versions only, and will expire within a certain time period. In order to keep the programs, a code will need to be purchased, and then a permanent version of the software can be downloaded.
-Many consumers who are purchasing a new computer are buying an entire package. In addition to the computer itself, these systems typically include a monitor, keyboard, and mouse. Some packages may even include a printer or digital camera. The number of extras included in a computer package usually affects laptop computer prices.
- Some industry leaders in computer manufacturing make it a selling point to offer computers in sleek styling and in a variety of colors. They may also offer unusual or contemporary system design. Though this is less important to many consumers, for those who do value “looks,” this type of system may be well worth the extra cost.


## From where I did get this data?
- Scrapped this data from flipkart.com
- used an automated chrome web extension tool called Instant Data Scrapper
    - highly recommend you to use this beautiful tool to get the data from anywhere on the web. it's very easy to use, no coding knowledge is required.

# What you can do?
- Visualize this data, and prepare high-quality charts as much as you can.
- Build a model to predict the price

- Columns description: pls refer to the data columns section.

Thanks!!!
Please support, do upvotes, share your notebooks, share your views/idea//suggestions in the discussion.


reference: [https://www.easytechjunkie.com/what-factors-affect-desktop-computer-prices.htm#comments](https://www.easytechjunkie.com/what-factors-affect-desktop-computer-prices.htm#comments)",.csv
2022 Startups Dataset,1,startups-by-valuation,Startups.csv,CC-BY-SA-3.0,"### Context

Startups are an interesting field to explore and taking a look at the field can expand your knowledge and let you think outside the box

### Content
The dataset has 5 columns (Company, Valuation, Valuation_date, Industry, Country)

Company: Describes company name
Valuation: Describes the valuation of the company
Valuation_date: Describes the date of valuation
Industry: Describes the industry of the company
Country: Describes the country of the company

### Inspiration

What industry has the most startups ?
What is the total value of these startups ?
How many AI companies are in the top 250 startup companies ?",.csv
2022-2023 Football Player Stats,1,20222023-football-player-stats,2022-2023 Football Player Stats.csv,Attribution 4.0 International (CC BY 4.0),"### Context

This dataset contains 2022-2023 football player stats per 90 minutes.
Only players of Premier League, Ligue 1, Bundesliga, Serie A and La Liga are listed.

* [2021-2022 Football Player Stats](https://www.kaggle.com/datasets/vivovinco/20212022-football-player-stats)
* [2021-2022 Football Team Stats](https://www.kaggle.com/datasets/vivovinco/20212022-football-team-stats)
* [2022-2023 Football Team Stats](https://www.kaggle.com/datasets/vivovinco/20222023-football-team-stats)


### Content

+2500 rows and 124 columns.
Columns' description are listed below.

* Rk : Rank
* Player : Player's name
* Nation : Player's nation
* Pos : Position
* Squad : Squad’s name
* Comp : League that squat occupies
* Age : Player's age
* Born : Year of birth
* MP : Matches played
* Starts : Matches started
* Min : Minutes played
* 90s : Minutes played divided by 90
* Goals : Goals scored or allowed
* Shots : Shots total (Does not include penalty kicks)
* SoT : Shots on target (Does not include penalty kicks)
* SoT% : Shots on target percentage (Does not include penalty kicks)
* G/Sh : Goals per shot
* G/SoT : Goals per shot on target (Does not include penalty kicks)
* ShoDist : Average distance, in yards, from goal of all shots taken (Does not include penalty kicks)
* ShoFK : Shots from free kicks
* ShoPK : Penalty kicks made
* PKatt : Penalty kicks attempted
* PasTotCmp : Passes completed
* PasTotAtt : Passes attempted
* PasTotCmp% : Pass completion percentage
* PasTotDist : Total distance, in yards, that completed passes have traveled in any direction
* PasTotPrgDist : Total distance, in yards, that completed passes have traveled towards the opponent's goal
* PasShoCmp : Passes completed (Passes between 5 and 15 yards)
* PasShoAtt : Passes attempted (Passes between 5 and 15 yards)
* PasShoCmp% : Pass completion percentage (Passes between 5 and 15 yards)
* PasMedCmp : Passes completed (Passes between 15 and 30 yards)
* PasMedAtt : Passes attempted (Passes between 15 and 30 yards)
* PasMedCmp% : Pass completion percentage (Passes between 15 and 30 yards)
* PasLonCmp : Passes completed (Passes longer than 30 yards)
* PasLonAtt : Passes attempted (Passes longer than 30 yards)
* PasLonCmp% : Pass completion percentage (Passes longer than 30 yards)
* Assists : Assists
* PasAss : Passes that directly lead to a shot (assisted shots)
* Pas3rd : Completed passes that enter the 1/3 of the pitch closest to the goal
* PPA : Completed passes into the 18-yard box
* CrsPA : Completed crosses into the 18-yard box
* PasProg : Completed passes that move the ball towards the opponent's goal at least 10 yards from its furthest point in the last six passes, or any completed pass into the penalty area
* PasAtt : Passes attempted
* PasLive : Live-ball passes
* PasDead : Dead-ball passes
* PasFK : Passes attempted from free kicks
* TB : Completed pass sent between back defenders into open space
* Sw : Passes that travel more than 40 yards of the width of the pitch
* PasCrs : Crosses
* TI : Throw-Ins taken
* CK : Corner kicks
* CkIn : Inswinging corner kicks
* CkOut : Outswinging corner kicks
* CkStr : Straight corner kicks
* PasCmp : Passes completed
* PasOff : Offsides
* PasBlocks : Blocked by the opponent who was standing it the path
* SCA : Shot-creating actions
* ScaPassLive : Completed live-ball passes that lead to a shot attempt
* ScaPassDead : Completed dead-ball passes that lead to a shot attempt
* ScaDrib : Successful dribbles that lead to a shot attempt
* ScaSh : Shots that lead to another shot attempt
* ScaFld : Fouls drawn that lead to a shot attempt
* ScaDef : Defensive actions that lead to a shot attempt
* GCA : Goal-creating actions
* GcaPassLive : Completed live-ball passes that lead to a goal
* GcaPassDead : Completed dead-ball passes that lead to a goal
* GcaDrib : Successful dribbles that lead to a goal
* GcaSh : Shots that lead to another goal-scoring shot
* GcaFld : Fouls drawn that lead to a goal
* GcaDef : Defensive actions that lead to a goal
* Tkl : Number of players tackled
* TklWon : Tackles in which the tackler's team won possession of the ball
* TklDef3rd : Tackles in defensive 1/3
* TklMid3rd : Tackles in middle 1/3
* TklAtt3rd : Tackles in attacking 1/3
* TklDri : Number of dribblers tackled
* TklDriAtt : Number of times dribbled past plus number of tackles
* TklDri% : Percentage of dribblers tackled
* TklDriPast : Number of times dribbled past by an opposing player
* Blocks : Number of times blocking the ball by standing in its path
* BlkSh : Number of times blocking a shot by standing in its path
* BlkPass : Number of times blocking a pass by standing in its path
* Int : Interceptions
* Tkl+Int : Number of players tackled plus number of interceptions
* Clr : Clearances
* Err : Mistakes leading to an opponent's shot
* Touches : Number of times a player touched the ball. Note: Receiving a pass, then dribbling, then sending a pass counts as one touch
* TouDefPen : Touches in defensive penalty area
* TouDef3rd : Touches in defensive 1/3
* TouMid3rd : Touches in middle 1/3
* TouAtt3rd : Touches in attacking 1/3
* TouAttPen : Touches in attacking penalty area
* TouLive : Live-ball touches. Does not include corner kicks, free kicks, throw-ins, kick-offs, goal kicks or penalty kicks.
* ToAtt : Number of attempts to take on defenders while dribbling
* ToSuc : Number of defenders taken on successfully, by dribbling past them
* ToSuc% : Percentage of take-ons Completed Successfully
* ToTkl : Number of times tackled by a defender during a take-on attempt
* ToTkl% : Percentage of time tackled by a defender during a take-on attempt
* Carries : Number of times the player controlled the ball with their feet
* CarTotDist : Total distance, in yards, a player moved the ball while controlling it with their feet, in any direction
* CarPrgDist : Total distance, in yards, a player moved the ball while controlling it with their feet towards the opponent's goal
* CarProg : Carries that move the ball towards the opponent's goal at least 5 yards, or any carry into the penalty area
* Car3rd : Carries that enter the 1/3 of the pitch closest to the goal
* CPA : Carries into the 18-yard box
* CarMis : Number of times a player failed when attempting to gain control of a ball
* CarDis : Number of times a player loses control of the ball after being tackled by an opposing player
* Rec : Number of times a player successfully received a pass
* RecProg : Completed passes that move the ball towards the opponent's goal at least 10 yards from its furthest point in the last six passes, or any completed pass into the penalty area
* CrdY : Yellow cards
* CrdR : Red cards
* 2CrdY : Second yellow card
* Fls : Fouls committed
* Fld : Fouls drawn
* Off : Offsides
* Crs : Crosses
* TklW : Tackles in which the tackler's team won possession of the ball
* PKwon : Penalty kicks won
* PKcon : Penalty kicks conceded
* OG : Own goals
* Recov : Number of loose balls recovered
* AerWon : Aerials won
* AerLost : Aerials lost
* AerWon% : Percentage of aerials won


### Acknowledgements

Data from [Football Reference](https://fbref.com/en/comps/Big5/stats/players/Big-5-European-Leagues-Stats).
Image from [Sky Sports](https://www.skysports.com/football/news/11095/12694600/premier-league-football-returns-man-utd-vs-leeds-and-chelsea-vs-liverpool-postponed-four-matches-live-on-sky).

**If you're reading this, please upvote.**
",.csv
2023 Air Quality Data for CBSAs,1,2023-air-quality-data-for-cbsas,aqidataset.csv,CC0-1.0,"This dataset was compiled from the EPA's [Air Quality Index Daily Values Report](https://www.epa.gov/outdoor-air-quality-data/air-quality-index-daily-values-report). As of April 2024 the full 2023 AQI dataset for all CBSA's is not available, so I have compiled this to use in the meantime.

The EPA's definition of the Air Quality Index is below:

![AQI](https://mayor.dc.gov/sites/default/files/dc/sites/mayormb/page_content/images/US-Air-Quality-Chart.png)

This dataset includes the following fields:

1. Date the measure was taken
2. Overall AQI value
3. Main Pollutant
4. Name of site where the AQI value was measured
5. ID of site where the AQI value was measured
6. Source of overall AQI value
7. Ozone level
8 PM25 level
9. CO level
10. PM10 level
11. NO2 level
12. AQI category (good, moderate, unhealthy, etc.)
13. City name
14. State name

It contains data for the following metro areas: 

- Ithaca, NY
- Chicago, IL
- Miami, FL
- Minneapolis, MN
- Charlotte, NC
- Dallas, TX
- Greensboro, NC
- State College, PA
- Richmond, VA
- Asheville, NC
- Athens, GA
- Boston, MA
- Baltimore, MD
- Detroit, MI
- Washington, DC
- New York, NY
- Philadelphia, PA
- Denver, CO
- Orlando, FL
- Cleveland, OH
- Portland, OR
- Phoenix, AZ
- Los Angeles, CA
- Kahului, HI
- Madison, WI
- Chapel Hill, NC
- San Francisco, CA
- Raleigh, NC
- Houston, TX
- Seattle, WA

These are the most populated cities in the CBSA's- the data points may include air quality metrics for other nearby areas.",.csv
2023 Data Scientists Salary,1,2023-data-scientists-salary,ds_salaries.csv,Apache 2.0,"## Summary
The aim of this study is to investigate the factors influencing the salaries of Data Scientists. To achieve this, a dataset containing various relevant variables was utilized. This report describes the exploratory analysis conducted to understand the relationship between these factors and Data Scientists' salaries.

## Introduction
Data science is a rapidly growing field, and Data Scientists play a crucial role in analyzing and interpreting large volumes of data. As this profession becomes increasingly in demand, it is important to understand the factors that may influence Data Scientists' salaries. This analysis focuses on investigating these factors and their impact on salaries.

## Dataset
To conduct this analysis, a dataset containing relevant information about Data Scientists was used. The dataset includes the following variables:

`work_year: `The year the salary was paid.

`experience_level:` The experience level in the job during the year.

- `EN` &gt; Entry-level / Junior
- `MI`&gt; Mid-level / Intermediate
- `SE` &gt; Senior-level / Expert
- `EX` &gt; Executive-level / Director

`employment_type:` The type of employment for the role.

- `PT` &gt; Part-time
- `FT` &gt; Full-time
- `CT` &gt; Contract
- `FL` &gt; Freelance

`job_title:` The role worked in during the year.

`salary:` The total gross salary amount paid.

`salary_currency`: The currency of the salary paid as an ISO 4217 currency code.

`salaryinusd:` The salary in USD.

`employee_residence:` Employee's primary country of residence during the work year as an ISO 3166 country code.

`remote_ratio:`The overall amount of work done remotely.

`company_location:` The country of the employer's main office or contracting branch.

`company_size`: The median number of people that worked for the company during the year.
",.csv
2024 Miami Grand Prix Verstappen Telemetry,1,2024-miami-grand-prix-verstappen-telemetry,verstappen_telemetry_miami_2024.csv,MIT,"# Max Verstappen's Full Race Car Data: 2024 Miami Grand Prix


### Data Source

Data obtained using the fastf1 API, ensuring reliability and accuracy in the collected data.

### Metrics

The dataset comprises a comprehensive range of metrics crucial for analyzing Max Verstappen's performance during the 2024 Miami Grand Prix, including:
  - **Data**: Timestamps for each recorded data point.
  - **RPM**: Engine revolutions per minute, indicating engine performance and power delivery.
  - **Speed**: Car speed measured in kilometers per hour, reflecting acceleration and straight-line performance.
  - **Gear Number**: Gear engaged by the driver at each timestamp, influencing speed and acceleration.
  - **Throttle Position**: Percentage of throttle opening, revealing driver input and acceleration strategy.
  - **Brake Information**: Data on braking behavior, crucial for understanding cornering techniques and managing tire wear.
  - **DRS Information**: Deployment of the Drag Reduction System, affecting straight-line speed and overtaking opportunities.
  - **Time**: Timestamp indicating when each data point was recorded.
  - **Session Time**: Duration of the race session, impacting data interpretation due to varying track conditions and fuel loads.

### Analysis Opportunities:

This data can be used to investigate correlations between RPM, Speed, throttle position, and gear number to uncover patterns in Max Verstappen's driving style and performance strategy, assess how brake usage and DRS deployment influence lap times and overall race performance, identifying optimal braking points and DRS activation zones.",.csv
2D Elastodynamic Metamaterials Dataset,1,2d-elastodynamic-metamaterials-dataset,data.csv,Attribution 4.0 International (CC BY 4.0),"This dataset list the location and width of the first band gap for 10x10 pixel 2D elastic metamaterials.

**Dataset Characteristics:** Tabular

**Subject Area:** Engineering

**Associated Tasks:** Regression

 **Instances:** 20521

**Features** 1

# Dataset Information

**For what purpose was the dataset created?**
This dataset was created to predict band-gap data from 2D 10x10 pixels elastic metamaterial geometry

**Who funded the creation of the dataset?**
We gratefully acknowledge funding from the Department of Energy, grant DE-SC0021358

**What do the instances in this dataset represent?**
The instances are elastic metamaterial unit cell designs that exhibit band gaps.

**Has Missing Values?**
No

# Introductory Paper

**Title:** How to See Hidden Patterns in Metamaterials with Interpretable Machine Learning

**Author:**  Zhi Chen, Alexander Ogren, Chiara Daraio, L. Catherine Brinson, Cynthia Rudin. 2021

**Journal:** Published in Preprint

**Link:** [https://www.sciencedirect.com/science/article/abs/pii/S2352431622001717](url)

#Abstract of Introductory Paper

Machine learning models can assist with metamaterials design by approximating computationally expensive simulators or solving inverse design problems.
However, past work has usually relied on black box
deep neural networks, whose reasoning processes are
opaque and require enormous datasets that are expensive to obtain. In this work, we develop two novel
machine learning approaches to metamaterials discovery that have neither of these disadvantages. These
approaches, called shape-frequency features and unitcell templates, can discover 2D metamaterials with
user-specified frequency band gaps. Our approaches
provide logical rule-based conditions on metamaterial unit-cells that allow for interpretable reasoning
processes, and generalize well across design spaces
of different resolutions. The templates also provide
design flexibility where users can almost freely design the fine resolution features of a unit-cell without
affecting the user’s desired band gap.

#Cite: 

**Citation:**`Ogren,Alexander , Chen,Zhi, Brinson,L. Catherine, Bastawrous,Mary, Rudin,Cynthia, and Daraio,Chiara. (2021). 2D elastodynamic metamaterials. UCI Machine Learning Repository. https://doi.org/10.24432/C5ZS5D.`

**BibTeX:**`@misc{misc_2d_elastodynamic_metamaterials_692,
  author       = {Ogren,Alexander , Chen,Zhi, Brinson,L. Catherine, Bastawrous,Mary, Rudin,Cynthia, and Daraio,Chiara},
  title        = {{2D elastodynamic metamaterials}},
  year         = {2021},
  howpublished = {UCI Machine Learning Repository},
  note         = {{DOI}: https://doi.org/10.24432/C5ZS5D}
}`",.csv
30000 Spotify Songs,1,30000-spotify-songs,spotify_songs.csv,DbCL-1.0,"Almost 30,000 Songs from the Spotify API. See the readme file for a formatted data dictionary table.


**Data Dictionary:**

| variable| class| description |
|:--------|:-----|:------------|
|track_id                 |character | Song unique ID|
|track_name               |character | Song Name|
|track_artist             |character | Song Artist|
|track_popularity         |double    | Song Popularity (0-100) where higher is better |
|track_album_id           |character | Album unique ID|
|track_album_name         |character | Song album name |
|track_album_release_date |character | Date when album released |
|playlist_name            |character | Name of playlist |
|playlist_id              |character | Playlist ID|
|playlist_genre           |character | Playlist genre |
|playlist_subgenre        |character | Playlist subgenre|
|danceability             |double    | Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable. |
|energy                   |double    | Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy. |
|key                      |double    | The estimated overall key of the track. Integers map to pitches using standard Pitch Class notation . E.g. 0 = C, 1 = C♯/D♭, 2 = D, and so on. If no key was detected, the value is -1. |
|loudness                 |double    | The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typical range between -60 and 0 db.|
|mode                     |double    | Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.|
|speechiness              |double    | Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks. |
|acousticness             |double    | A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic.|
|instrumentalness         |double    | Predicts whether a track contains no vocals. ""Ooh"" and ""aah"" sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly ""vocal"". The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0. |
|liveness                 |double    | Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live. |
|valence                  |double    | A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry). |
|tempo                    |double    | The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration. |
|duration_ms              |double    | Duration of song in milliseconds |
",.csv
3K Conversations Dataset for ChatBot,1,3k-conversations-dataset-for-chatbot,Conversation.csv,other,"**About Dataset**
This dataset is used for research or training of natural language processing (NLP) models. The dataset may include various types of conversations such as casual or formal discussions, interviews, customer service interactions, or social media conversations. 

**Application**
- Chatbots and virtual assistants: Conversation datasets are used to train chatbots and virtual assistants to interact with users in a more human-like manner.

- Customer service: Conversation datasets can be used to train customer service chatbots, allowing companies to provide 24/7 customer support without human intervention.",.csv
40 Years of Music Industry Sales,1,40-years-of-music-industry-sales,MusicData.csv,other,"**40 Years of Music Industry Sales**

**Data Description:**

The record industry has seen a lot of change over the years.

8-tracks took a short-lived run at the dominance of vinyl, cassettes faded away as compact discs took the world by storm, and through it all, the music industry saw its revenue continue to climb. That is, until it was digitally disrupted.

Looking back at four decades of U.S. music industry sales data is a fascinating exercise as it charts not only the rise and fall the record company profits, but seismic shifts in technology and consumer behavior as well.
The Long Fade Out

For people of a certain age group, early memories of acquiring new music are inexorably linked to piracy. Going to the store and purchasing a $20 disc wasn’t even a part of the thought process. Napster, the first widely used P2P service, figuratively skipped the needle off the record and ended years of impressive profitability in the recording industry.

In this dataset you can find each year sales and analysis this matter.

**Time period covered**
1973 - 2019",.csv
"4000+ Indian Cities: Names, States, Lat, Lon",1,4000-indian-cities-names-states-lat-lon,Indian Cities Geo Data.csv,CC-BY-NC-SA-4.0,"Unleash the potential of location-based analysis with this dataset of Indian cities. With over 4000 entries meticulously curated with city names, states, and precise latitude and longitude coordinates, uncover valuable insights into population distribution, urban development, and more.",.csv
"5,000 #JustDoIt! Tweets Dataset",1,5000-justdoit-tweets-dataset,justdoit_tweets_2018_09_07_2.csv,CC0-1.0,"### Context
Nike just announced its partnership with Colin Kaepernick to be the face of the 30th anniversary of its **JustDoIt** campaign.   
They used the slogan ""Believe in something, even if it means sacrificing everything.""  
Kaepernick had made a controversial decision not to stand up during the national anthem, as a protest to police brutality, a while back.  
This has stirred a heated debate, and became a big national issue especially when [Donald Trump commented on it](https://www.youtube.com/watch?v=oY3hpZVZ7pk).


### Content

This dataset contains 5,000 tweets that contain the hashtag #JustDoIt.   
All tweets happened on September 7, 2018, which is days after Nike made its announcement to endorse Kaepernick.

#### Some of the top entities of those tweets: 
### #JustDoIt #Nike #ColinKaepernick #TakeaKnee
### 😂 🤣 ✔ 🔥 ❤ 🏈 💯 💙 🇺🇸
### @Nike @Kaepernick7 @realDonaldTrump



### Acknowledgements
Python, Twitter, twython, pandas, matplotlib do the heavy lifting in generating the data and exploring it.
 
### Inspiration
I'm an online marketing person. Love words, love numbers. Can't help it!  
I think it's very interesting to see how these issues unfold, and how people respond to them. Maybe you can uncover some hidden insights or patterns.   
I'm also trying to show how you can [use the `extract_` functions from my `advertools` package](https://www.kaggle.com/eliasdabbas/extract-entities-from-social-media-posts). 
",.csv
500 Person Gender-Height-Weight-Body Mass Index,1,500-person-gender-height-weight-bodymassindex,500_Person_Gender_Height_Weight_Index.csv,GPL-2.0,"Gender : Male / Female

Height : Number (cm)

Weight : Number (Kg)

Index :

0 - Extremely Weak

1 - Weak

2 - Normal

3 - Overweight

4 - Obesity

5 - Extreme Obesity",.csv
550+ Best Books of all time.,1,550-best-books-in-the-world,550 Best Books of All time.csv,CC0-1.0,"This dataset presents a captivating glimpse into the world of literature, showcasing some of the most beloved books across various genres. From the enchanting wizardry of J.K. Rowling's ""Harry Potter and the Goblet of Fire"" to the heart-pounding intrigue of Dan Brown's ""Angels & Demons,"" each entry offers readers a unique journey through the realms of fantasy, mystery, and historical fiction.

At the forefront stands J.K. Rowling's masterpiece, with an impressive average rating of 4.57 out of 5 and an astounding total of 36,90,617 ratings from 142 voters, solidifying its status as a timeless classic in the fantasy genre.

Dan Brown's ""Angels & Demons"" follows closely behind, blending elements of thriller and mystery with its gripping narrative, earning a commendable average rating of 3.94 from a staggering 31,54,961 ratings, contributed by 63 voters.

George R.R. Martin's ""A Storm of Swords"" continues the saga of ""A Song of Ice and Fire"" series with an impressive average rating of 4.54 and over 7,82,746 ratings from 55 voters, captivating readers with its intricate world-building and complex characters.

Philip Pullman's ""The Amber Spyglass"" transports readers into the mesmerizing universe of His Dark Materials, garnering a respectable average rating of 4.10 from 3,59,826 ratings provided by 44 voters, weaving a tale of epic proportions that explores themes of courage, sacrifice, and the nature of existence.

Lastly, Michael Chabon's ""The Amazing Adventures of Kavalier & Clay"" offers a rich tapestry of historical fiction, with an average rating of 4.18 from 2,02,623 ratings contributed by 27 voters, immersing readers in the vibrant world of comic books, friendship, and the tumultuous events of the 20th century.

From the spellbinding realms of magic to the intricate webs of intrigue, each book in this dataset invites readers on an unforgettable journey through the boundless landscape of the imagination, where the power of storytelling knows no bounds.",.csv
5G Resource Allocation Dataset📡:Optimizing Band🚀,1,5g-quality-of-service,Quality of Service 5G.csv,other,"Welcome to the ""5G Resource Allocation Dataset"" – your gateway to understanding and optimizing the next-generation of wireless networks! 🌐📱

This dataset provides a comprehensive look into the world of 5G resource allocation, where cutting-edge AI algorithms are harnessed to dynamically manage network resources such as bandwidth, frequency spectrum, and computing power in real-time. 🤖⚙️

Explore a wealth of data encompassing various aspects of 5G resource allocation, including:

Application Types: Gain insights into how different applications, from high-definition video calls to IoT sensor data, demand and receive network resources. 📹📡

Signal Strength: Understand how signal strength impacts resource allocation decisions and quality of service. 📶🔍

Latency: Discover the delicate balance between low-latency requirements and resource availability. ⏱️📈

Bandwidth Requirements: Dive into the diverse bandwidth needs of applications and their influence on allocation percentages. 🌐💼

Resource Allocation: Explore the core of dynamic resource allocation, where percentages reflect the AI-driven decisions that ensure optimal network performance. 📊💻

Whether you're a data scientist, network engineer, or simply curious about the inner workings of 5G networks, this dataset offers a unique opportunity to analyze and model the resource allocation strategies shaping the future of connectivity. 🌟🔌

Use this dataset to develop AI models, improve quality of service, and innovate in the realm of 5G networking. Join us in unlocking the potential of 5G resource allocation! 🚀🔓",.csv
6 New BRICS members Sentiment Analysis,1,6-new-brics-members-sentiment-analysis,new2.csv,Apache 2.0,"Delve into the collective sentiment of the global community as we analyze public perspectives on the inclusion of six new member nations in the BRICS alliance. This sentiment analysis provides valuable insights into how individuals perceive and respond to the evolving dynamics within this influential coalition, offering a nuanced understanding of public sentiment towards the new additions. Uncover the diverse range of opinions, emotions, and reactions as we navigate the intricacies of international relations and the impact on public discourse

NOTE: The labelling is done based on likes on the comment.",.csv
600 GPT4 Re-write Prompts,1,600-gpt4-re-write-prompts,gpt4_prompts.csv,CC0-1.0,"I asked ChatGPT4 for some re-write prompts.  I did this as part of an interactive session discussing the LLM Prompt Recovery Competition.   

conversation went something like...

Me: I need some prompts - here are some examples:  
Reimagine this news article as a science fiction story set in the distant future.
Describe this event in the style of a sports commentator providing live commentary.

ChatGPT: Creating a list of 100 unique and creative prompts following the imaginative style of your examples can be a fun challenge! Here's a diverse set of prompts designed to spark creativity and offer a wide range of perspectives and reinterpretations:

(you get the idea...)
",.csv
65 World Indexes,1,65-world-indexes-gathered,Kaggle.csv,DbCL-1.0,"# Context 

Why some countries are so different from the others? 

Feel free to upvote :)
Autor: Joni Hoppen - linkedin -  https://www.linkedin.com/in/joniarroba/


# Content

I have gathered manually most of the information at World Bank, Unicef and so on. Some data were not there so I used K-nn to guess some values and have a full dataset that can be used of our data science community.  

Information of each of the 65 variables were made available here [http://bit.ly/2l2Hjh3][1]


# Acknowledgements

Thanks www.aquare.la Advanced Analytics that came up with the idea of creating this dataset to test their VORTX tool. Also Thanks to  professionals involved in creating Indexes and collecting them, this is such a great valuable work to help better see the world. 


# Inspiration

What would be the best, way to equalize the world? 


  [1]: http://bit.ly/2l2Hjh3",.csv
7Wonders (board game) scorecards,1,7wonders-board-game-scorecards,board_game_7wonders_scorecards.csv,other,"Dataset name: board_game_7wonders_scorecards.csv
The data from this dataset was collected through two means. It depicts (in 17 columns) data from several games of the French board game 7 Wonders, played by players of all levels. In total, 227 games are reported, which adds up to N = 886 lines.

 -The first part, identified by the category *online dataset* in the column “Dataset origin” was found online on this site: https://alt-gr.tech/pages/seven-wonders and reports 148 games with 57 different players, and 82 3-players games and 44 4-players games, which adds up to N = 547 lines.

 -The second part, identified by the categories *hand reported games_i* (i=1 or i=2) in the column “Dataset origin” was collected manually from the scorecards of two boxes of 7 Wonders. About the first set: 67 games, N = 291 lines. About the second set: 12 games, N = 48 lines. Original data.

 -Beware! : online dataset is from the first edition of the board game (2010 edition), while the hand reported games_i reports data from the second version of the board game (2020 edition). Not many changes have occurred between both versions, however, it might cause variability to be aware of.

.

Variable in each column:

o	**Dataset origin:** 3 categories ‘online dataset’, ‘hand reported games_1’ and ‘hand reported games_2’

o	**id_Game:** from 0 to 227, an id for each game played reported in this dataset

o	**Extensions:** categorical, ‘No’ = only the base game, ‘Cities’, ‘Leaders’, when one extension was used or ‘Cities / Leaders’ when both extensions were combined

o	**Mode:** ‘Night’ or ‘Day’ depending on the mode played

o	**Number of players:** from 3 to 7, the number of players in the game played

o	**id_Player:** anonymous id for each player, numbers for the online dataset and letters for the hand reported games

o	**Winner_looser:** 0 if the player lost the game, 2 if they won, 1 if they neither lost nor won

o	**Score:** total score of the player (sum of all the columns from ‘Wonder’ to ‘Leaders’)

o	**Wonder:** wonder score. On the scorecard, points on the line with a pyramid.

o	**Treasury:** treasure score. On the scorecard, points on the line with a round and a square.

o	**Military:** military score. On the scorecard, points on the line with a red panel.

o	**Civilian:** civilian score. On the scorecard, points on the line with a blue panel.

o	**Commercial:** commercial score. On the scorecard, points on the line with a yellow panel.

o	**Guilds:** guild score. On the scorecard, points on the line with a purple panel.

o	**Scientific:** scientific score. On the scorecard, points on the line with a green panel.

o	**Cities:** score from the *cities* extension. On the extended scorecard, points on the line with a *cities* panel. If the game wasn’t played with this extension, then the score is 0.

o	**Leaders:** score from the *leaders* extension. On the extended scorecard, points on the line with a *leaders* panel. If the game wasn’t played with this extension, then the score is 0.
",.csv
7k Books,1,7k-books-with-metadata,books.csv,CC0-1.0,"### Do we really need another dataset of books?

My initial plan was to build a toy example for a recommender system article I was writing. After a bit of googling, I found a few datasets. Sadly, most of them had some issues that made them unusable for me (e.g, missing description of the book, a mix of different languages but no column to specify the language per row or weird delimiters). 

So I decided to make a dataset that would match my purposes.

First, I got ISBNs from [Soumik's Goodreads-books dataset](https://www.kaggle.com/jealousleopard/goodreadsbooks). Using those identifiers, I crawled the Google Books API to extract the books' information.

Then, I merged those results with some of the original columns from the dataset and after some cleaning I got the dataset you see here.

### What can I do with this?
Different Exploratory Data Analysis, clustering of books by topics/category, content-based recommendation engine using different fields from the book's description. 

### Why is this dataset smaller than Soumik's Goodreads-books?
Many of the ISBNs of that dataset did not return valid results from the Google Books API. I plan to update this in the future, using more fields (e.g., title, author) in the API requests, as to have a bigger dataset.

### What did you use to build this dataset?
Check out the repoistory here [Google Books Crawler](https://github.com/dylanjcastillo/google_books_crawler)

### Acknowledgements

This dataset relied heavily on [Soumik's Goodreads-books dataset](https://www.kaggle.com/jealousleopard/goodreadsbooks).",.csv
"811 Call Service [Chicago , 2015 to 2024]",1,811-call-service-chicago-2015-to-2024,811_Chicago_Utility_Hit_Tickets.csv,CC-BY-SA-3.0,"Chicago Department of Transportation (CDOT), Division of Infrastructure Management (DIM), operates Chicago’s “One Call” service—known as “811 Chicago.” Per Municipal Code of Chicago (MCC)   “in the event of damage to any underground facilities, the person responsible for the damage shall immediately notify…811 Chicago.”

811 Chicago records all reported damages as “hit tickets.” This dataset contains hit tickets since January 1, 2020. (Prior to that date, hit tickets data is a less reliable measure of utility damages.[2015 -2020])

Please note, a hit ticket does not necessarily mean damage occurred or implicate the parties listed on the hit ticket as having caused the damage. For example, an excavator may report damage they discovered, but did not cause; an entity may incorrectly report the utility that was damaged or who caused the damage; the same damage may be reported by more than one entity. 811 Chicago investigates all reported damages to determine if there was a violation of MCC 10-21. During the course of its investigation, 811 Chicago will confirm the information on the hit ticket. If 811 Chicago discovers inaccurate information, it may not update the hit ticket. The data related to 811 Chicago’s investigation is not exposed in this data set. Importantly, 811 Chicago does not determine which entity is liable for the damage, and the “hit by” field does not indicate that the individual or entity caused the damage or violated MCC  10-21.",.csv
"90,000+ Cars Data From 1970 to 2024",1,90000-cars-data-from-1970-to-2024,CarsData.csv,MIT,"## Cars Dataset from 1970 to 2024

Welcome Here you'll find a collection of over 90,000 used cars spanning from the year 1970 to 2024. This dataset offers a comprehensive glimpse into the world of automobiles, providing valuable insights for researchers, enthusiasts, and industry professionals alike.

### Features Included:

- **Model**: The model of the car.
- **Year**: The manufacturing year of the car.
- **Price**: The price of the car.
- **Transmission**: The type of transmission used in the car.
- **Mileage**: The mileage of the car.
- **FuelType**: The type of fuel used by the car.
- **Tax**: The tax rate applicable to the car.
- **MPG**: The miles per gallon efficiency of the car.
- **EngineSize**: The size of the car's engine.
- **Manufacturer**: The manufacturer of the car.

### Why Use This Dataset?

- **Comprehensive**: With data spanning over five decades, this dataset offers a comprehensive view of automotive history.
- **Rich Attributes**: Explore various attributes including model, year, price, transmission, mileage, fuel type, tax rates, MPG, engine size, and manufacturer details.
- **Insightful Analysis**: Uncover valuable insights into the evolution of the automotive landscape and make informed decisions based on rich, historical data.

### Get Started:

Explore the dataset, analyze trends, and extract meaningful insights to enhance your understanding of the automotive industry. Whether you're a researcher, enthusiast, or industry professional, this dataset provides a wealth of information to fuel your exploration.
",.csv
9000+ Movies : IMDb and Bechdel,1,movies-imdb-and-bechdel-information,Bechdel_IMDB_Merge.csv,other,"This dataset covers information about 9689 movies such as their titles, genres, ratings on IMDb and scores to the Bechdel test. It is a test invented in 1985 by Alison Bechdel which consists in the measure of women’s representation in movies. To pass the test, the film must have two women named in it (score 1 to the test, 0 otherwise) who talk to each other (score 2) about anything else than a man (score 3). 

The data was collected in April 2024. The movies' release dates therefore go from 1894 to the beginning of 2024.

Here are a few data analysis ideas using this dataset:
- Is women's representation proportional to the movie's length ?
- Are sci-fi movies more sexist ?

You can also take a look at my notebook, where I answered the question : does the Bechdel score of a movie impact its IMDb rating ? ",.csv
9000+ Movies Dataset,1,9000-movies-dataset,mymoviedb.csv,CC0-1.0,"### Context

This is the first dataset I have published on the online platform for public use. This dataset is created to build a movie recommender system using Natural Language Processing and Machine Learning models exclusively for the learners who want to step into the world of Data Science and Machine Learning. 


### Content

Features of the dataset: 

- <code>Release_Date</code>: Date when the movie was released.
- <code>Title</code>: Name of the movie.
- <code>Overview</code>: Brief summary of the movie.
- <code>Popularity</code>: It is a very important metric computed by TMDB developers based on the number of views per day, votes per day, number of users marked it as ""favorite"" and ""watchlist"" for the data, release date and more other metrics. 
- <code>Vote_Count</code>: Total votes received from the viewers.
- <code>Vote_Average</code>:  Average rating based on vote count and the number of viewers out of 10.
- <code>Original_Language</code>: Original language of the movies. Dubbed version is not considered to be original language.
- <code>Genre</code>: Categories the movie it can be classified as.
- <code>Poster_Url</code>: Url of the movie poster.


### Acknowledgements

Special thanks to Mr.Nitish Singh from CampusX (https://www.youtube.com/channel/UCCWi3hpnq_Pe03nGxuS7isg) for creating amazing and easy-to-follow tutorials. 


### Inspiration

A recommender system can be built using the CSV data.

### Source:
The CSV data was fetched using API - https://developers.themoviedb.org/3/movies/get-popular-movies and cleaned using Pandas and Numpy library in Python. ",.csv
A Benchmark Data for Turkish Text Categorization,1,ttc4900,7allV03.csv,CC0-1.0,"### Context

The data set is taken from kemik group 
http://www.kemik.yildiz.edu.tr/
The data are pre-processed for the text categorization, collocations are found, character set is corrected, and so forth. 
We named TTC4900 by mimicking the name convention of TTC 3600 dataset shared by the study http://journals.sagepub.com/doi/abs/10.1177/0165551515620551

If you use the dataset in a paper,  please refer https://www.kaggle.com/savasy/ttc4900 as footnote and cite one of the papers as follows:

* A Comparison of Different Approaches to Document Representation in Turkish Language, SDU Journal of Natural and Applied Science, Vol 22, Issue 2, 2018
* A comparative analysis of text classification for Turkish language, Pamukkale University Journal of Engineering Science Volume 25 Issue 5, 2018 
* A Knowledge-poor Approach to Turkish Text Categorization with a Comparative Analysis, Proceedings of CICLING 2014, Springer LNCS, Nepal, 2014.

### Content
Each row represents the documents, and the categories

### Acknowledgements
Thanks to kemik group, 

### Inspiration

Text Categorization,  BOW, LSI, Deep Learning Approaches are the techniques to be applied",.csv
A New Benchmark for Financial Question Answering,1,a-new-benchmark-for-financial-question-answering,financebench_sample_150.csv,Apache 2.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F8442057%2Ff7c62f9d14b5620b8452f39690a24568%2Ffig1.png?generation=1715577026848120&alt=media)

Abstract: FinanceBench is a first-of-its-kind test suite for evaluating the performance of LLMs on open book financial question answering (QA). This repository contains an open source sample of 150 annotated examples used in the evaluation and analysis of models assessed in the FinanceBench paper. FinanceBench comprises 10,231 questions about publicly traded companies, with corresponding answers and evidence strings. The questions in FinanceBench are ecologically valid and cover a diverse set of scenarios. They are intended to be clear-cut and straightforward to answer to serve as a minimum performance standard. We test 16 state of the art model configurations (including GPT-4-Turbo, Llama2 and Claude2, with vector stores and long context prompts) on a sample of 150 cases from FinanceBench, and manually review their answers (n=2,400). The cases are available open-source. We show that existing LLMs have clear limitations for financial QA. Notably, GPT-4-Turbo used with a retrieval system incorrectly answered or refused to answer 81% of questions. While augmentation techniques such as using longer context window to feed in relevant evidence improve performance, they are unrealistic for enterprise settings due to increased latency and cannot support larger financial documents. We find that all models examined exhibit weaknesses, such as hallucinations, that limit their suitability for use by enterprises.

**Contact:** To evaluate your models on the full FinanceBench dataset, or if you have questions about this work, you can email us at contact@patronus.ai

**Dataset Overview:** The provided open-source dataset (n=150) consists of the following attributes:

```python
- financebench_id:  unique question identifier  
    - question:         question of interest
    - answer:           gold answer
    - question_type:    type of the question {domain-relevant, metrics-generated, novel-generated}
    - doc_name:         name of the relevant financial document to answer the question
    - doc_link:         url to retrieve the relevant financial document
    - doc_period:       period of the relevant financial document
    - evidence_text:    extracted evidence text
    - page_number       page number(s) of evidence text
```

**Citation:** If you use our open-source dataset or refer to our result, please use the following citation:

```python
@misc{islam2023financebench,
      title={FinanceBench: A New Benchmark for Financial Question Answering}, 
      author={Pranab Islam and Anand Kannappan and Douwe Kiela and Rebecca Qian and Nino Scherrer and Bertie Vidgen},
      year={2023},
      eprint={2311.11944},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```
",.csv
A Symphony of Customer Interactions 🎼🤝👥,1,a-symphony-of-customer-interactions,A Symphony of Customer Interactions.csv,Apache 2.0,"Immerse yourself in the intricate dataset titled 'A Symphony of Customer Interactions,' meticulously curated to encapsulate the multifaceted realm of customer engagement. This expansive collection encompasses a diverse array of channels, ranging from social media threads and live chat transcripts to email exchanges and support ticket conversations. Delve into the ebb and flow of online dialogues, capturing the nuanced dynamics of user interactions in the digital sphere.

Each entry within this dataset serves as a unique note in the grand symphony of customer experiences, showcasing the diverse ways individuals connect with businesses. Uncover the underlying melodies of customer sentiments, preferences, and concerns, as expressed through the rich tapestry of textual exchanges. The dataset not only reflects the surface-level interactions but also delves into the intricacies of sentiment analysis, providing a deeper understanding of customer emotions.

Researchers, analysts, and AI enthusiasts alike can extract valuable insights from this comprehensive dataset, unraveling patterns, identifying trends, and refining models for enhanced customer engagement. Embark on a journey through the intricacies of modern customer relations, where data harmonizes with technology, offering a profound exploration of the symphony that resonates between businesses and their clientele.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F8400986%2F24d3f18a048821b0c87a198ffedc4a1a%2F1694400580382.png?generation=1709644253658599&alt=media)",.csv
A Waiter's Tips,1,tipping,tips.csv,other,"### Context

One waiter recorded information about each tip he received over a period of a few months working in one restaurant. In all he recorded 244 tips. 

Can you predict the tip amount?

### Acknowledgements

The data was reported in a collection of case studies for business statistics.

Bryant, P. G. and Smith, M (1995) _Practical Data Analysis: Case Studies in
Business Statistics_. Homewood, IL: Richard D. Irwin Publishing

The dataset is also available through the Python package Seaborn. ",.csv
A/B test data,1,ab-test-data,AB_Test_Results.csv,Community Data License Agreement - Sharing - Version 1.0,"The site launched an A/B test in order to increase income. The excel file contains raw data on the results of the experiment (user_id), sample type (variant_name) and income brought by the user (revenue).
The task is to analyze the results of the experiment and write your recommendations.",.csv
AAL_Sales Data set,1,aal-sales-data-set,AusApparalSales4thQrt2020.csv,Apache 2.0,"AAL is a household name in Australia, known for its clothing business since 2000. It caters to all groups— kids, women, men, and seniors. It has opened branches in many states in Australia, in metropolises and tier-1 and tier-2 cities. ",.csv
AI Global Index,1,ai-index,AI_index_db.csv,DbCL-1.0,"The Dataset ""AI Global index"" includes The Global AI Index itself and seven indicators affecting the Index on 62 countries, as well as general information about the countries (region, cluster, income group and political regime).

**The Global AI Index** is the first index to benchmark nations on their level of investment, innovation and implementation of artificial intelligence.

Talent, Infrastructure and Operating Environment are the factors of AI **Implementation** group of indicators, which represents the application of artificial intelligence by professionals in various sectors, such as businesses, governments, and communities. 
- *Talent* indicator focuses on the availability of skilled practitioners for the provision of artificial intelligence solutions.
- *Infrastructure* indicator focuses on the reliability and scale of access infrastructure, from electricity and internet, to super computing capabilities.
- *Operating Environment* indicator focuses on the regulatory context, and public opinion surrounding artificial intelligence.


Research and Development are the factors of **Innovation** group of indicators, which reflects the progress made in technology and methodology, which signify the potential for artificial intelligence to evolve and improve.
- *Research* indicator focuses on the extent of specialist research and researchers; investigating the amount of publications and citations in credible academic journals.
- *Development* indicator focuses on the development of fundamental platforms and algorithms upon which innovative artificial intelligence projects rely.


Government Strategy and Commercial are the factors of **Investment** group of indicators, which reflects financial and procedural commitments to artificial intelligence. 
- *Government Strategy* indicator focuses on the depth of commitment from national government to artificial intelligence; investigating spending commitments and national strategies.
- *Commercial* indicator focuses on the level of startup activity, investment and business initiatives based on artificial intelligence.


All these seven indicators were calculated by [Tortoise Media](https://www.tortoisemedia.com/intelligence/global-ai/) via weighting and summarizing 143 other indicators.

The dataset can be used for practicing data cleaning, data visualization, finding correlations between the indexes, Machine Learning (classification, regression, clustering).

The data was used in the analytical article research [*Artificial Intelligence on the World Stage: Dominant Players and Aspiring Challengers*](https://intersog.com/blog/ai-dominant-players-and-aspiring-challengers/)",.csv
AI/ML Salaries,1,ai-ml-salaries,salaries.csv,CC0-1.0,"The salaries are from [ai-jobs](https://salaries.ai-jobs.net/download/). Ai-jobs collects salary information anonymously from professionals all over the world in the AI/ML and Big Data space and makes it publicly available for anyone to use, share and play around with. The data is being updated regularly with new data coming in, usually on a weekly basis.
The primary goal is to have data that can provide better guidance in regards to what's being paid globally. So newbies, experienced pros, hiring managers, recruiters and also startup founders or people wanting to make a career switch can make better informed decisions.

The dataset contains one table structured as follow:
* **work_year:** The year the salary was paid.
* **experience_level:** The experience level in the job during the year with the following possible values:
 * **EN:** Entry-level / Junior
 * **MI:** Mid-level / Intermediate
 * **SE:** Senior-level / Expert
 * **EX:** Executive-level / Director
* **employment_type:** The type of employement for the role:
 * **PT:** Part-time
 * **FT:** Full-time
 * **CT:** Contract
 * **FL:** Freelance
* **job_title:** The role worked in during the year.
* **salary:** The total gross salary amount paid.
* **salary_currency:** The currency of the salary paid as an ISO 4217 currency code.
* **salary_in_usd:** The salary in USD (FX rate divided by avg. USD rate for the respective year via fxdata.foorilla.com).
* **employee_residence:** Employee's primary country of residence in during the work year as an ISO 3166 country code.
* **remote_ratio:** The overall amount of work done remotely, possible values are as follows:
 * **0:** No remote work (less than 20%)
 * **50:** Partially remote
 * **100:** Fully remote (more than 80%)
* **company_location:** The country of the employer's main office or contracting branch as an ISO 3166 country code.
* **company_size:** The average number of people that worked for the company during the year:
 * **S:** less than 50 employees (small)
 * **M:** 50 to 250 employees (medium)
 * **L:** more than 250 employees (large) ",.csv
AIME Problem Set: 1983-2024,1,aime-problem-set-1983-2024,AIME_Dataset_1983_2024.csv,CC0-1.0,"Dive into the realm of mathematical exploration with the ""AIME Problem Set: 1983-2024"" dataset. This compilation offers a treasure trove of challenges from the American Invitational Mathematics Examination (AIME), a prestigious competition designed to push the boundaries of mathematical reasoning and problem-solving skills. From algebraic equations to geometric puzzles, these problems demand creativity, persistence, and a keen eye for mathematical patterns.

Administered by the Mathematical Association of America (MAA) and sponsored by the Art of Problem Solving (AoPS), the AIME has been a cornerstone of mathematical enrichment for decades. This dataset features a comprehensive selection of AIME problems spanning from 1983 to 2024, each accompanied by its solution, allowing students, educators, and enthusiasts alike to engage in the art of mathematical discovery.

This dataset will be especially valuable for participants of the AI Mathematical Olympiad - Progress Prize 1 competition, providing them with a wealth of challenging problems to hone their skills and showcase their mathematical talent.",.csv
AIMO External Dataset,1,aimo-external-dataset,external_df.csv,MIT,"# Description

This dataset is a compiled version of two benchmark math dataframes for solving math problems using LLMs, namely:
- MATH: ""MATH is a new dataset of 12,500 challenging competition mathematics problems. Each problem in MATH has a full step-by-step solution which can be used to teach models to generate answer derivations and explanations.""
- GSM8K: ""a dataset of 8.5K high quality linguistically diverse grade school math word problems created by human problem writers. The dataset is segmented into 7.5K training problems and 1K test problems. These problems take between 2 and 8 steps to solve, and solutions primarily involve performing a sequence of elementary calculations using basic arithmetic operations (+ − ×÷) to reach the final answer. A bright middle school student should be able to solve every problem. It can be used for multi-step mathematical reasoning.""

The dataset consists of 21k math problems with its corresponding solutions.

# Columns

- `problem`: text with the mathematical problem statement.
- `level`: level of difficulty (GSM8K does not provide this column).
- `type`: math field (GSM8K does not provide this column).
- `solution`: text with the mathematical problem solution.
- `stage`: either ""train"" or ""test"". This corresponds to the original dataframe split.
- `source`: either ""MATH"" or ""GSM8K"". Source of the problem.",.csv
AIMO TRAIN Augmentation,1,aimo-train-augmentation,aimo_train_aug.csv,Apache 2.0,"This dataset includes sample code and generated data for automatically creating mathematical problems using Python. We prepared templates for 10 types of mathematical problems and automatically generated new problem and answer pairs by randomly modifying parameters for each problem. The generated problems cover a wide range of topics across the mathematics curriculum, including Math A, Math II, Math B, Math III, and Math C. This dataset can be used for automatic generation of mathematical problems and analysis of problem characteristics.",.csv
"AMIO parsed ""Art Of Problem Solving"" website",1,amio-parsed-art-of-problem-solving-website,parsed_ArtOfProblemSolving.csv,Apache 2.0,"Hello colleagues,

Here is the data scrapped from [Art Of Problem Solving](https://artofproblemsolving.com) website.
In the dataset you have the **8818 solutions for the 3711 problems with extracted answer** (and answer letter (A,B,C,D,E) if the problem was stated like a test with answer samples).

In my opinion this data could be really helpful for us in different applications:
- Bechmarking different LLMs
- Prompt engineering (including few-shot pipelines)
- SFT tasks
- ...

**The links which was fully parsed**:
- [AMC 8 / AJHSME Problems and Solutions](https://artofproblemsolving.com/wiki/index.php/AMC_8_Problems_and_Solutions)
- [AMC 10 Problems and Solutions](https://artofproblemsolving.com/wiki/index.php/AMC_10_Problems_and_Solutions)
- [AMC 12 Problems and Solutions](https://artofproblemsolving.com/wiki/index.php/AMC_12_Problems_and_Solutions)
- [AHSME Problems and Solutions](https://artofproblemsolving.com/wiki/index.php/AHSME_Problems_and_Solutions)
- [AIME Problems and Solutions](https://artofproblemsolving.com/wiki/index.php/AIME_Problems_and_Solutions)
- [USAMO Problems and Solutions](https://artofproblemsolving.com/wiki/index.php/USAMO_Problems_and_Solutions)
- [USAJMO Problems and Solutions](https://artofproblemsolving.com/wiki/index.php/USAJMO_Problems_and_Solutions)

**Important note:** currently I have processed about the half of the solutions, which have answer in `\\boxed{}` or almost boxed manner. Other solution need more careful and manual answers extraction so **stay tuned for further updates of the dataset**.

❤️ **I hope that this dataset can help us to beat the 20/50 score on public LB.**",.csv
ANN - Car Sales Price Prediction,1,ann-car-sales-price-prediction,car_purchasing.csv,DbCL-1.0,"# Main Context:-
As a vehicle salesperson, you would like to create a model that can estimate the overall amount that consumers would spend given the following characteristics:
customer name, customer email, country, gender, age, annual salary, credit card debt, and net worth

# The model should anticipate the following (Problem Statement):
****Amount Paid for a Car****

# Task type:
Regression

# Algorithm:
The given problem statement can be solved using Machine Learning or Deep Learning Techniques

# Note:
While reading csv you will face an error **UnicodeDecodeError**
Just do the following step while reading csv file:-
data = pd.read_csv(""/kaggle/input/ann-car-sales-price-prediction/car_purchasing.csv"",encoding='ISO-8859-1')

Kaggle supporting link to resolve error:- [link](https://www.kaggle.com/code/paultimothymooney/how-to-resolve-a-unicodedecodeerror-for-a-csv-file/notebook) 
",.csv
ANZ Data@ANZ Program,1,anz-synthesised-transaction-dataset,anz.csv,CC0-1.0,"# Important note : To those enrolled for Data@ANZ virtual experience program
I request you not to copy the solutions from the 'Kernels' to complete your internship modules.You may rather use it as reference and preferably the 'Discussion' section to connect with experts and learn much more. ***Be ethical*** .

# About this Dataset

### Context

A synthesised transaction dataset containing 3 months’ worth of transactions for 100 hypothetical customers.The dataset is designed to simulate realistic transaction behaviours that are observed in ANZ’s real transaction data.

### Content

It contains purchases, recurring transactions, and salary transactions.

### Acknowledgements

Thanks to ANZ https://www.anz.com.au/personal/
Thanks to InsideSherpa https://www.insidesherpa.com/virtual-internships/prototype/ZLJCsrpkHo9pZBJNY/Data%40ANZ%20Program
",.csv
APPLE Stock Data,1,apple-stock-data-updated-till-22jun2021,AAPL.csv,other,"## What is APPLE?
Apple Inc. is an American multinational technology company that specializes in consumer electronics, computer software, and online services. Apple is the world's largest technology company by revenue and, since January 2021, the world's most valuable company.

## Information about this dataset
This dataset provides historical data of APPLE INC. stock (AAPL). The data is available at a daily level. Currency is USD.",.csv
AQI - Air Quality Index,1,aqi-air-quality-index-scheduled-daily-update,data_date.csv,ODbL-1.0,"# Context
This dataset contains Air Quality Index of most the countries of the world.

# Challenges
- Time Series Analysis and Prediction
- Seasonality finding
- Geospatial Analysis

# About  Air Quality Index (AQI
The Air Quality Index (AQI) is used for reporting daily air quality. It tells you how clean or polluted your air is, and what associated health effects might be a concern for you. The AQI focuses on health effects you may experience within a few hours or days after breathing polluted air.

[![air-quality-index-numerical-scale-vector-24061819.jpg](https://i.postimg.cc/kgRWWChK/air-quality-index-numerical-scale-vector-24061819.jpg)](https://postimg.cc/tsy1HKb4)

# Content
- **data_date.csv** - date wise organised

# Related Notebooks
- [**AQI- Air Quality Index : EDA, Forecast [Scheduled]**](https://www.kaggle.com/azminetoushikwasi/aqi-air-quality-index-eda-forecast-scheduled/)


# Download
- kaggle API Command
`!kaggle datasets download -d azminetoushikwasi/aqi-air-quality-index-scheduled-daily-update`

## Disclaimer
- The data collected are all publicly available and it's intended for educational purposes only.

## Acknowledgement
- Cover image taken from internet.

## Appreciate, Support, Share",.csv
ASHRAE Global Thermal Comfort Database II,1,ashrae-global-thermal-comfort-database-ii,ashrae_db2.01.csv,DbCL-1.0,"## Dataset Source: https://datadryad.org/stash/dataset/doi:10.6078/D1F671

## Abstract
Recognizing the value of open-source research databases in advancing the art and science of
HVAC, in 2014 the ASHRAE Global Thermal Comfort Database II project was launched under
the leadership of University of California at Berkeley’s Center for the Built Environment and
The University of Sydney’s Indoor Environmental Quality (IEQ) Laboratory.
The exercise began with a systematic collection and harmonization of raw data from the last
two decades of thermal comfort field studies around the world. The final database is comprised
of field studies conducted between 1995 and 2015 from around the world, with contributors
releasing their raw data to the project for wider dissemination to the thermal comfort research
community. After the quality-assurance process, there was a total of 81,846 rows of data of
paired subjective comfort votes and objective instrumental measurements of thermal comfort
parameters. An additional 25,617 rows of data from the original ASHRAE RP-884 database are
included, bringing the total number of entries to 107,463.

The database is intended to support diverse inquiries about thermal comfort in field settings.
To achieve this goal, two web-based tools were developed to accompany the database:
1. Interactive visualization tool: provides a user-friendly interface for researchers and
practitioners to explore and navigate their way around the large volume of data in ASHRAE
Global Thermal Comfort Database II
2. Query builder tool: allows users to filter the database according to a set of selection criteria,
and then download the results of that query in a generic comma-separated-values (.csv) file

## Methods
In order to ensure that the quality of the database would permit end-users to conduct robust
hypothesis testing, the team built the data collection methodology on specific requirements, as
follows:
- Data needed to come from field experiments rather than climate chamber research, so
that it represented research conducted in “real” buildings occupied by “real” people doing
their normal day-to-day activities, rather than paid college students sitting in a controlled
indoor environment of a climate chamber.
- Both instrumental (indoor climatic) and subjective (questionnaire) data were required,
such that they were recorded in the same space at the same time
- The database needed to be built up from the raw data files generated by the original
researchers, instead of their processed or published findings.
- The raw data needed to come with a supporting codebook explaining the coding
conventions used by the data contributor, to allow harmonization with the standardized
Földváry Ličina, Veronika et al. (2018), ASHRAE Global ... doi:10.6078/D1F671
data formatting within the database.
- Data must have been published either in a peer-reviewed journal or conference paper.

All datasets from individual studies were subject to a stringent quality assurance process 
before being assimilated into the database. The research team conducted a final
validation by first comparing each raw dataset with its related publication provided by the data
contributor to prevent transmission errors. Systematic quality control of each study was
performed to ensure that records within the database were reasonable. Firstly, distributions of
each variable were visualized to identify aberrant values. Then, cross-plots between two
variables (e.g. thermal sensation and thermal comfort) were used to check for incorrectly coded
data. Finally, a few rows from each study were randomly selected to verify consistency between
the original dataset and the standardized database. Since the data came from multiple
independent studies, every record did not necessarily include all of the thermal comfort
variables. Where data were missing, that particular range of cells was filled with a null value.

## Usage Notes
The dataset is provided as a comma-separated value (.csv) file using UTF-8 character encoding.
The first row contains human-readable column headers. Each row represents an individual’s
questionnaire responses, and the associated instrumental measurements, thermal index values
and outdoor meteorological observations where available. Full details can be found in the
related work.

## Funding
American Society of Heating, Refrigerating and Air Conditioning Engineers, Award: URP 1656

## References
This dataset is supplement to https://doi.org/10.1016/j.buildenv.2018.06.022",.csv
ASML: Leading Semiconductor Innovator,1,asml-leading-semiconductor-innovator,ASML_ Leading Semiconductor Innovator.csv,Apache 2.0,"ASML Holding N.V. (commonly shortened to ASML, originally standing for Advanced Semiconductor Materials Lithography) is a Dutch multinational corporation founded in 1984. ASML specializes in the development and manufacturing of photolithography machines which are used to produce computer chips. With a mission to push the boundaries of semiconductor technology, ASML plays a pivotal role in enabling the production of advanced integrated circuits that power modern electronics worldwide",.csv
ATP Tennis 2000 - 2024 Daily update,1,atp-tennis-2000-2023daily-pull,atp_tennis.csv,CC0-1.0,"This dataset contains 60k+ ATP macthes(2000-2024)

Don't Forget to share your feedback ❤️.

Make an upvote👍 If you found it useful.

Each match includes the tournament, date, type of tournament, whether the match was played indoors or not, type of court surface, round of the match, maximum number of sets in the match, participants in the match, winner, ranks of the participants, odds to win and match score.",.csv
Abalone's Age,1,abalones-age,abalone.data.csv,other,"# **Additional Information**
Predicting the age of abalone from physical measurements.  The age of
   abalone is determined by cutting the shell through the cone, staining it,
   and counting the number of rings through a microscope -- a boring and
   time-consuming task.  Other measurements, which are easier to obtain, are
   used to predict the age.  Further information, such as weather patterns
   and location (hence food availability) may be required to solve the problem.

   From the original data examples with missing values were removed (the
   majority having the predicted value missing), and the ranges of the
   continuous values have been scaled for use with an ANN (by dividing by 200).

   Data comes from an original (non-machine-learning) study:


## Number of Instances: 4177


## Number of Attributes: 8

##   Statistics for numeric domains:

	Length	Diam	Height	Whole	Shucked	Viscera	Shell	Rings
	Min	0.075	0.055	0.000	0.002	0.001	0.001	0.002	    1
	Max	0.815	0.650	1.130	2.826	1.488	0.760	1.005	   29
	Mean	0.524	0.408	0.140	0.829	0.359	0.181	0.239	9.934
	SD	0.120	0.099	0.042	0.490	0.222	0.110	0.139	3.224
	Correl	0.557	0.575	0.557	0.540	0.421	0.504	0.628	  1.0
",.csv
Abortion Statistics ,1,cusersmarildownloadsabortioncsv,abortion.csv,other,"### Context

Induced abortion in New Zealand is regulated under the Contraception, Sterilisation, and Abortion Act 1977. This act established the Abortion Supervisory Committee (ASC) to oversee the operation of the Act. One of the roles of the ASC is ""to obtain, monitor, analyse, collate, and disseminate information relating to the performance of abortions in New Zealand"". Stats NZ is responsible for collating, analysing and disseminating abortion statistics on behalf of the ASC.
https://www.stats.govt.nz


### Content

Abortion statistics measure the number of induced abortions that are performed in New Zealand hospitals or licensed abortion clinics. 
Publisher: Statistics New Zealand.  Rights: Statistics New Zealand  https://www.stats.govt.nz/




### Acknowledgements

https://www.stats.govt.nz/

Photo by Luemen Carlson on Unsplash


### Inspiration

Women with an unwanted pregnancy who cannot access safe abortion is at risk of unsafe abortion. Women living in low-income countries and poor women are more likely to have an unsafe abortion. Deaths and injuries are higher when unsafe abortion is performed later in pregnancy. The rate of unsafe abortions is higher where access to effective contraception and safe abortion is limited or unavailable. https://www.who.int/news-room/fact-sheets/detail/preventing-unsafe-abortion
",.csv
Absenteeism Dataset,1,absenteeism-dataset,MFGEmployees4.csv,CC0-1.0,"# Context 

Absenteeism- is a major expense to most  organizations. Getting a handle on it, predicting it and affecting it is important for organizations. This dataset provided for HR data scientists to practice on

# Content

This data is TOTALLY fake and fictitous- but I have attempted to make it seem realistic

Data includes
Employee number
Surname
GivenName
Gender
City
JobTitle
DepartmentName
StoreLocation
Division
Age
LengthService
AbsentHours
BusinessUnit


# Acknowledgements

Totally fake data


# Inspiration

If we want to get executives to pay attention to People/HR Analytics, we must take it beyond just producing the metrics, and dive into the data with Analytics and Statistical Tools. This dataset provided to explore and practice.",.csv
Adidas Fashion Retail Products Dataset,1,adidas-fashion-retail-products-dataset-9300-prod,adidas_usa.csv,other,"# Adidas Fashion Retail Products Dataset: 9300+ Products
### A Dataset for those interested in Fashion, Style, and Retail
_____

### About this dataset
This dataset contains information on over 1500+ Adidas fashion products. The data includes fields such as name, selling price, original price, currency, availability, color, category, source website, breadcrumbs, description, brand, images, country, language, average rating and reviews count. This data was collected from a variety of sources and compiled into one dataset for research purposes

This Adidas fashion dataset provides rich product information for over 9300+ products. It contains detailed information on product selling price, original price in multiple currencies ( USD / EUR / GBP ), product availability ( in stock / out of stock ), color , Category ( such as Apparel / Footwear ), source website , breadcrumbs , product description , brand name , link to product images , Country of origin and language . The average rating and reviews count are also included in the dataset so that researchers can study the correlation between them

### How to use the dataset
This dataset contains information on over 1500+ Adidas fashion products. The data includes fields such as name, selling price, original price, currency, availability, color, category, source website, breadcrumbs, description, brand, images, country, language, average rating and reviews count. This data was collected from a variety of sources and compiled into one dataset for research purposes.

### Research Ideas
- This dataset can be used to determine which colors are most popular among different age groups or genders.
- This dataset can be used to identify the most popular products among different countries or regions.
- This dataset can be used to analyze the correlation between product reviews and ratings to determine which factors are most important to customers

### Columns

**File: adidas_usa.csv**
| Column name        | Description                                                                          |
|:-------------------|:-------------------------------------------------------------------------------------|
| **url**            | The URL of the product page on the source website. (String)                          |
| **name**           | The name of the product. (String)                                                    |
| **sku**            | The SKU or unique identifier for the product. (String)                               |
| **selling_price**  | The selling price of the product in USD or Euros. (Float)                            |
| **original_price** | The original price of the product in USD or Euros. (Float)                           |
| **currency**       | The currency type for the selling price and original price. (String)                 |
| **availability**   | The availability of the product. (String)                                            |
| **color**          | The color of the product. (String)                                                   |
| **category**       | The category of the product. (String)                                                |
| **source_website** | The source website from where the data was collected. (String)                       |
| **breadcrumbs**    | The breadcrumbs or path to the product page on the source website. (String)          |
| **description**    | A brief description of the product provided by Adidas. (String)                      |
| **brand**          | The brand of the product. (String)                                                   |
| **images**         | Multiple product images provided by Adidas. (String)                                 |
| **country**        | The country of origin/destination for the product. (String)                          |
| **language**       | The language in which the product page was displayed on the source website. (String) |
| **average_rating** | The average customer rating out of 5 stars. (Float)                                  |
| **reviews_count**  | The number of customer reviews for the product. (Integer)                            |
| **crawled_at**     | The date and time when the data was collected. (String)                              |

",.csv
Adidas vs Nike ,1,adidas-vs-nike,Adidas Vs Nike.csv,CC0-1.0,"### Context

Adidas vs Nike is a constant debate in the sports industry. This dataset consists of the product information of these two huge companies with significant information.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F1430847%2F45f09b0a1934f24c011d12914f195537%2Fnike-vs-adidas.jpg?generation=1602939235849541&alt=media)

### Content

The dataset consists of 3268 products from Nike and Adidas with 12 features of information including their ratings, discount, sales price, listed price, product description, and the number of reviews.

The product data from Adidas and Nike can be used for a number of purposes like competitive research.


### Acknowledgements

The dataset was obtained from the data world website contributed by datahut and tony paul
Respective links: https://data.world/data-hut/product-data-from-nike, https://data.world/data-hut/product-data-from-adidas

### Tasks:
1. Clustering the products based on various factors.
2. EDA on the products
3. Competitive analysis between Nike and Adidas",.csv
Adult Census Income,1,adult-census-income,adult.csv,CC0-1.0,"This data was extracted from the [1994 Census bureau database][1] by Ronny Kohavi and Barry Becker (Data Mining and Visualization, Silicon Graphics). A set of reasonably clean records was extracted using the following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1) && (HRSWK>0)). *The prediction task is to determine whether a person makes over $50K a year*.

## Description of fnlwgt (final weight)

The weights on the Current Population Survey (CPS) files are controlled to independent estimates of the civilian noninstitutional population of the US.  These are prepared monthly for us by Population Division here at the Census Bureau. We use 3 sets of controls. These are: 

 1.  A single cell estimate of the population 16+ for each state.
     
 2.  Controls for Hispanic Origin by age and sex.

 3.  Controls by Race, age and sex.

We use all three sets of controls in our weighting program and ""rake"" through them 6 times so that by the end we come back to all the controls we used. The term estimate refers to population totals derived from CPS by creating ""weighted tallies"" of any specified socio-economic characteristics of the population. People with similar demographic characteristics should have similar weights. There is one important caveat to remember about this statement. That is that since the CPS sample is actually a collection of 51 state samples, each with its own probability of selection, the statement only applies within state.

##Relevant papers

Ron Kohavi, [""Scaling Up the Accuracy of Naive-Bayes Classifiers: a Decision-Tree Hybrid""][2], *Proceedings of the Second International Conference on Knowledge Discovery and Data Mining*, 1996. (PDF)

  [1]: http://www.census.gov/en.html
  [2]: http://robotics.stanford.edu/~ronnyk/nbtree.pdf",.csv
Advanced Micro Devices,1,advanced-micro-devices,Advanced Micro Devices.csv,Apache 2.0,"Advanced Micro Devices, Inc. (AMD) is a global semiconductor company renowned for its innovative solutions in the computing industry. Founded in 1969, AMD has consistently pushed the boundaries of semiconductor design, delivering high-performance processors and graphics solutions that power a wide range of computing devices, from PCs and laptops to data centers and gaming consoles. With a strong commitment to innovation and technology leadership, AMD continues to drive advancements in computing performance, energy efficiency, and graphics rendering, shaping the future of digital experiences worldwide.


Here's a description for each column in your dataset:

1. **Date:** The date of the trading session, typically formatted as YYYY-MM-DD.

2. **Open:** The opening price of the stock at the beginning of the trading session.

3. **High:** The highest price reached by the stock during the trading session.

4. **Low:** The lowest price reached by the stock during the trading session.

5. **Close:** The closing price of the stock at the end of the trading session.

6. **Adj Close:** The adjusted closing price of the stock, which accounts for any corporate actions such as dividends or stock splits.

7. **Volume:** The number of shares traded during the trading session, indicating the level of market activity for the stock.",.csv
Advanced: Saudi Arabian Aramco Stocks Dataset 🐪,1,advanced-saudi-arabian-aramco-stocks-dataset,aramco.csv,Apache 2.0,"## Saudi Arabian Oil Company Aramco, Stocks 
<h1 style=""font-family: &quot;poppins&quot;; font-weight: bold; color: rgba(0, 128, 0, 1)"">👨‍💻 Author: Azhar Saleem</h1>

[![GitHub](https://img.shields.io/badge/GitHub-Profile-blue?style=for-the-badge&logo=github)](https://github.com/azharsaleem18) [![Kaggle](https://img.shields.io/badge/Kaggle-Profile-blue?style=for-the-badge&logo=kaggle)](https://www.kaggle.com/azharsaleem) [![LinkedIn](https://img.shields.io/badge/LinkedIn-Profile-blue?style=for-the-badge&logo=linkedin)](https://www.linkedin.com/in/azhar-saleem/) 

[![YouTube](https://img.shields.io/badge/YouTube-Profile-red?style=for-the-badge&logo=youtube)](https://www.youtube.com/@AzharSaleem19) [![Facebook](https://img.shields.io/badge/Facebook-Profile-blue?style=for-the-badge&logo=facebook)](https://www.facebook.com/azhar.saleem1472/) [![TikTok](https://img.shields.io/badge/TikTok-Profile-black?style=for-the-badge&logo=tiktok)](https://www.tiktok.com/@azhar_saleem18) 

[![Twitter/X](https://img.shields.io/badge/Twitter-Profile-blue?style=for-the-badge&logo=twitter)](https://twitter.com/azhar_saleem18) [![Instagram](https://img.shields.io/badge/Instagram-Profile-blue?style=for-the-badge&logo=instagram)](https://www.instagram.com/azhar_saleem18/) [![Email](https://img.shields.io/badge/Email-Contact%20Me-red?style=for-the-badge&logo=email)](mailto:azharsaleem6@gmail.com)


# Dataset Description

Welcome to the Enhanced Saudi Arabian Oil Company (Aramco) Stock Dataset! This dataset has been meticulously prepared from Yahoo Finance and further enriched with several engineered features to elevate your data analysis, machine learning, and financial forecasting projects. It captures the daily trading figures of Aramco stocks, presented in Saudi Riyal (SAR), providing a robust foundation for comprehensive market analysis.

## Columns in the Dataset

- **`Date`**: The trading day for the data recorded (ISO 8601 format).
- **`Open`**: The price at which the stock first traded upon the opening of an exchange on a given trading day.
- **`High`**: The highest price at which the stock traded during the trading day.
- **`Low`**: The lowest price at which the stock traded during the trading day.
- **`Close`**: The price at which the stock last traded upon the close of an exchange on a given trading day.
- **`Volume`**: The total number of shares traded during the trading day.
- **`Dividends`**: The dividend value paid out per share on the trading day.
- **`Stock Splits`**: The number of stock splits occurring on the trading day.
- **`Lag Features (Lag_Close, Lag_High, Lag_Low)`**: Previous day's closing, highest, and lowest prices.
- **`Rolling Window Statistics (e.g., Rolling_Mean_7, Rolling_Std_7)`**: 7-day and 30-day moving averages and standard deviations of the Close price.
- **`Technical Indicators (RSI, MACD, Bollinger Bands)`**: Key metrics used in trading to analyze short-term price movements.
- **`Change Features (Change_Close, Change_Volume)`**: Day-over-day changes in Close price and trading volume.
- **`Date-Time Features (Weekday, Month, Year, Quarter)`**: Extracted components of the trading day.
- **`Volume_Normalized`**: The standardized trading volume using z-score normalization to adjust for scale differences.

## Potential Uses

This dataset is tailored for a wide array of applications:

- **`Financial Analysis`**: Explore historical performance, volatility, and market trends.
- **`Forecasting Models`**: Utilize features like lagged prices and rolling statistics to predict future stock prices.
- **`Machine Learning`**: Develop regression models or classification frameworks to predict market movements.
- **`Deep Learning`**: Leverage LSTM networks for more sophisticated time-series forecasting.
- **`Time-Series Analysis`**: Dive deep into trend analysis, seasonality, and cyclical behavior of stock prices.

Whether you are a data scientist, a financial analyst, or a hobbyist interested in the stock market, this dataset provides a rich playground for analysis and model building. Its comprehensive feature set allows for the development of robust predictive models and offers unique insights into one of the world’s most significant oil companies. Unlock the potential of financial data with this carefully crafted dataset.
",.csv
Adverse Food Events,1,adverse-food-events,CAERS_ASCII_2004_2017Q2.csv,CC0-1.0,"### Context: 
The CFSAN Adverse Event Reporting System (CAERS) is a database that contains information on adverse event and product complaint reports submitted to FDA for foods, dietary supplements, and cosmetics. The database is designed to support CFSAN's safety surveillance program. Adverse events are coded to terms in the [Medical Dictionary for Regulatory Activities (MedDRA) terminology](http://www.meddra.org/).


### Content: 
See the metadata description in the accompanying README.pdf below or [here](https://www.fda.gov/downloads/Food/ComplianceEnforcement/UCM494019.pdf). Approximately 90k reactions are recorded from 2004-mid 2017, with 12 columns of information regarding type of reaction and related event details.

### Acknowledgements: 
This dataset is collected by the [US Food and Drug Administration](https://www.fda.gov/Food/ComplianceEnforcement/ucm494015.htm).

### Inspiration: 
* What are the most commonly reported foodstuffs?
* What are the most commonly reported medical reactions to foods?
* Where do people in the US most commonly report food-related conditions?",.csv
Advertisement - Click on Ad dataset,1,advertisement-click-on-ad,advertising.csv,other,"This data set contains the following features:

'Daily Time Spent on Site': consumer time on site in minutes
'Age': customer age in years
'Area Income': Avg. Income of geographical area of consumer
'Daily Internet Usage': Avg. minutes a day consumer is on the internet
'Ad Topic Line': Headline of the advertisement
'City': City of consumer
'Male': Whether or not consumer was male
'Country': Country of consumer
'Timestamp': Time at which consumer clicked on Ad or closed window
'Clicked on Ad': 0 or 1 indicated clicking on Ad",.csv
Advertising Sales Dataset,1,advertising-sales-dataset,Advertising Budget and Sales.csv,CC0-1.0,"![](https://raw.githubusercontent.com/Masterx-AI/Project_Ad_Budget_Estimation_/main/0-ad1%20(1).jpg)

### Description:
The advertising dataset captures the sales revenue generated with respect to advertisement costs across multiple channels like radio, tv, and newspapers. 

It is required to understand the impact of ad budgets on the overall sales.

### Acknowledgement: 
The dataset is taken from Kaggle

### Objective:
- Understand the Dataset & cleanup (if required).
- Build Regression models to predict the sales w.r.t a single & multiple features.
- Also evaluate the models & compare their respective scores like R2, RMSE, etc.",.csv
Aerial Bombing Operations in World War II,1,world-war-ii,operations.csv,CC0-1.0,"# Content

This dataset consists of digitized paper mission reports from WWII. Each record includes the date, conflict, geographic location, and other data elements to form a live-action sequence of air warfare from 1939 to 1945. The records include U.S. and Royal Air Force data, in addition to some Australian, New Zealand and South African air force missions.


# Acknowledgements

Lt Col Jenns Robertson of the US Air Force developed the Theater History of Operations Reports (THOR) and posted them online after receiving Department of Defense approval.",.csv
African Economic Outlook,1,african-economic-outlook,african-economic-outlook.csv,CC-BY-SA-4.0,"# Details of the dataset
**The African Economic Outlook** dataset is a comprehensive resource that provides detailed economic analysis at both the country and regional level.

The dataset is provided by the **African Development Bank Group**, and it’s part of their broader effort to examine recent macroeconomic developments and the outlook in Africa. The report focuses on the implications of external imbalances for growth and the financial and monetary challenges of integration.

The dataset includes various metrics such as **Real GDP growth in Africa, Energy subsidies as a share of nominal GDP, and Contribution to GDP growth in Africa, by region**. These metrics can provide valuable insights into the economic conditions and trends in different African countries and regions.

The dataset is available in CSV format, which can be easily imported into most data analysis and visualization tools. This makes it a valuable resource for policy makers, investors, researchers, NGOs, and journalists who are interested in African economic trends and developments.

# Key usages
This dataset can be used to make informed decisions in several ways:
- **Policy Making:** Governments and policy makers can use this data to understand the economic conditions of different African countries and regions, and formulate policies accordingly.
- **Investment Decisions:** Investors and businesses can use this data to identify potential investment opportunities in different sectors and regions.
- **Academic Research:** Researchers and students can use this data for various economic studies and research projects.
- **Non-profit Organizations:** NGOs and humanitarian organizations can use this data to identify regions that need economic aid or development projects.
- **Journalism:** Journalists and media outlets can use this data to report on economic trends and developments in Africa.

<a href=""http://cliparts.co/clipart/2251271""><img src=""http://cliparts.co/cliparts/kTK/BEj/kTKBEjgjc.png"" alt=""Nigeria - African Economic Outlook""></a>
Image Source : Clipart.co",.csv
Age Prediction Dataset (Binary Classification),1,age-prediction-dataset-binary-classification,age_predictions_cleaned.csv,other,"This dataset is a cleaned version of the original [National Health and Nutrition Health Survey 2013-2014 (NHANES) Age Prediction Dataset](https://archive.ics.uci.edu/dataset/887/national+health+and+nutrition+health+survey+2013-2014+(nhanes)+age+prediction+subset) available at UCI Library. It was cleaned using various techniques such as z-score normalization, feature selection, and Oversampling. It contains 6 columns:

1. PAQ605: If the respondent engages in moderate or vigorous-intensity sports, fitness, or recreational activities in the typical week
2. BMXBMI: Respondent's Body Mass Index
3. LBXGLU: Respondent's Blood Glucose after fasting
4. LBXGLT: Respondent's Oral
5. LBXIN: Respondent's Blood Insulin Levels
6. Age Group (Target): Is the respondent a Senior or not?

The Target Class contains two values - 0 or 1 - where 0 refers to Adult and 1 refers to Senior.",.csv
"Age, Weight, Height, BMI Analysis",1,age-weight-height-bmi-analysis,bmi.csv,other,"<div>
    <h1>Dataset Description</h1>
    <p>
        The dataset in question comprises <strong>741 individual records</strong>, each meticulously documented with the following attributes:
    </p>
    <ul>
        <li><strong>Age (in years):</strong> This field quantifies the age of each individual, denominated in years. It serves as a chronological reference for the dataset.</li>
        <li><strong>Height (in meters):</strong> The ""Height"" column provides measurements of the subjects' stature in meters. This standardized unit allows for precise representation and comparison of individuals' heights.</li>
        <li><strong>Weight (in kilograms):</strong> In the ""Weight"" column, the weights of the subjects are quantified in kilograms. This unit ensures consistency and accuracy in measuring the subjects' mass.</li>
        <li><strong>BMI (Body Mass Index):</strong> Derived from the height and weight columns, the BMI column computes the Body Mass Index of each individual. The calculation utilizes the formula: BMI = (Weight in kg) / (Height in m^2). BMI is a vital numerical indicator used for categorizing individuals based on their weight relative to their height. It is expressed as a continuous variable.</li>
        <li><strong>BmiClass:</strong> The ""BmiClass"" column categorizes individuals based on their calculated BMI values. The categories include ""Obese Class 1,"" ""Overweight,"" ""Underweight,"" among others. These classifications are instrumental in health and weight analysis.</li>
    </ul>
    <p>
        Furthermore, it is noteworthy that this dataset exhibits a high degree of data integrity, with no missing values across any of the aforementioned columns. Such completeness enhances its utility for advanced data analytics and visualization, enabling rigorous exploration of relationships between age, height, weight, BMI, and associated weight classifications.
    </p>
</div>
",.csv
Agri-food CO2 emission dataset - Forecasting ML,1,agri-food-co2-emission-dataset-forecasting-ml,Agrofood_co2_emission.csv,CC0-1.0,"The agricultural CO2 emission dataset has been constructed by merging and reprocessing approximately a dozen individual datasets from the Food and Agriculture Organization (FAO) and data from IPCC. These datasets were, cleaned, preprocessed and merged together to create a comprehensive and cohesive dataset for analysis and forecasting purposes. 

The dataset, as demonstrated in the notebook, describes CO2 emissions related to agri-food, which amount to approximately 62% of the global annual emissions.

Indeed, the emissions from the agri-food sector are significant when studying climate change. As the dataset shows, these emissions contribute to a substantial portion of the global annual emissions. Understanding and addressing the environmental impact of the agri-food industry is crucial for mitigating climate change and developing sustainable practices within this sector.

*For a better understanding of the dataset, I have written a notebook where I perform an analysis of the relationship between emissions, climate change and geografic Area. Additionally, I provide an example of regression to predict the percentage variations in temperatures.*

### Dataset Features:

- **Savanna fires**: Emissions from fires in savanna ecosystems.
- **Forest fires**: Emissions from fires in forested areas.
- **Crop Residues**: Emissions from burning or decomposing leftover plant material after crop harvesting.
- **Rice Cultivation**: Emissions from methane released during rice cultivation.
- **Drained organic soils (CO2)**: Emissions from carbon dioxide released when draining organic soils.
- **Pesticides Manufacturing**: Emissions from the production of pesticides.
- **Food Transport**: Emissions from transporting food products.
- **Forestland**: Land covered by forests.
- **Net Forest conversion**: Change in forest area due to deforestation and afforestation.
- **Food Household Consumption**: Emissions from food consumption at the household level.
- **Food Retail**: Emissions from the operation of retail establishments selling food.
- **On-farm Electricity Use**: Electricity consumption on farms.
- **Food Packaging**: Emissions from the production and disposal of food packaging materials.
- **Agrifood Systems Waste Disposal**: Emissions from waste disposal in the agrifood system.
- **Food Processing**: Emissions from processing food products.
- **Fertilizers Manufacturing**: Emissions from the production of fertilizers.
- **IPPU**: Emissions from industrial processes and product use.
- **Manure applied to Soils**: Emissions from applying animal manure to agricultural soils.
- **Manure left on Pasture**: Emissions from animal manure on pasture or grazing land.
- **Manure Management**: Emissions from managing and treating animal manure.
- **Fires in organic soils**: Emissions from fires in organic soils.
- **Fires in humid tropical forests**: Emissions from fires in humid tropical forests.
- **On-farm energy use**: Energy consumption on farms.
- **Rural population**: Number of people living in rural areas.
- **Urban population**: Number of people living in urban areas.
- **Total Population - Male**: Total number of male individuals in the population.
- **Total Population - Female**: Total number of female individuals in the population.
- **total_emission**: Total greenhouse gas emissions from various sources.
- **Average Temperature °C**: The average increasing of temperature (by year) in degrees Celsius,

### Importance and Context:

The agricultural sector contributes to approximately, how i'll demostrate in my notebook, 62% of the total global CO2 emissions, making it a significant contributor to climate change. This dataset plays a crucial role in understanding and monitoring the impact of agricultural activities on CO2 emissions. By leveraging machine learning techniques, it enables the forecasting of future emissions, allowing policymakers and researchers to develop targeted strategies and interventions for sustainable agricultural practices. This dataset serves as a valuable resource for climate scientists, environmental researchers, and policymakers striving to mitigate the environmental impact of the agricultural sector.

### Author note:
- **CO2 is recorded in kilotonnes (kt)**: 1 kt represents 1000 kg of CO2.
- **The feature ""Average Temperature C°"", which can be used as the target for machine learning models, represents the average yearly temperature increase**. For example, if it is 0.12, it means that the temperature in that specific location increased by 0.12 degrees Celsius.
- **Forestland** is the only feature that exhibits **negative emissions due to its role as a carbon sink**. Through photosynthesis, forests absorb and store carbon dioxide, effectively removing it from the atmosphere. Sustainable forest management, along with afforestation and reforestation efforts, further contribute to negative emissions by increasing carbon sequestration capacity.
- If you prefer **Fahrenheit** to Celsius, here is the formula: **°F = (°C x 9/5) + 32**

If you appreciate my work, please consider giving it a like to support me in publishing more accurate and scientifically-backed datasets along with notebook demonstrations. Your support is highly valued :)",.csv
Agricultural Crop Yield in Indian States Dataset,1,crop-yield-in-indian-states-dataset,crop_yield.csv,CC-BY-SA-4.0,"This dataset encompasses agricultural data for multiple crops cultivated across various states in India from the year **1997 till 2020**. The dataset provides crucial features related to crop yield prediction, including crop types, crop years, cropping seasons, states, areas under cultivation, production quantities, annual rainfall, fertilizer usage, pesticide usage, and calculated yields.

# Columns Description:
1. **Crop**: The name of the crop cultivated.
2. **Crop_Year**: The year in which the crop was grown.
3. **Season**: The specific cropping season (e.g., Kharif, Rabi, Whole Year).
4. **State**: The Indian state where the crop was cultivated.
5. **Area**: The total land area (in hectares) under cultivation for the specific crop.
6. **Production**: The quantity of crop production (in metric tons).
7. **Annual_Rainfall**: The annual rainfall received in the crop-growing region (in mm).
8. **Fertilizer**: The total amount of fertilizer used for the crop (in kilograms).
9. **Pesticide**: The total amount of pesticide used for the crop (in kilograms).
10. **Yield**: The calculated crop yield (production per unit area).

# Use Cases:
This comprehensive dataset is valuable for agricultural analysts, researchers, and data scientists interested in **crop yield prediction and agricultural analysis**. It offers insights into the relationship between various **agronomic factors** (e.g., rainfall, fertilizer, pesticide usage) and **crop productivity** across different states and crop types. Researchers can utilize this data to develop robust **machine learning models** for crop yield prediction and identify trends in agricultural production.

#Note:
Given the **diversity of crops, states, and years** covered in this dataset, users are encouraged to **exercise caution** when drawing generalizations or making predictions for **specific regions or timeframes** outside the scope of the dataset. They are further advised to apply various **feature engineering and feature selection techniques** on this dataset, so as to make the dataset more robust and suitable for the ML model.",.csv
Agricultural Raw Material prices (1990-2020),1,agricultural-raw-material-prices-19902020,agricultural_raw_material.csv,GPL-2.0,"### Content

This dataset comprises of prices and price % change for coarse wool, copra, cotton, fine wool, hardlog, hard sawnwood, hide, plywood, rubber, softlog, soft sawnwood and wood pulp. 

### Acknowledgements

Data is sourced from Indexmundi",.csv
Agricultural Survey of African Farm Households,1,agricultural-survey-of-african-farm-households,data.csv,CC0-1.0,"### Context

*Abstract*: Surveys for more than 9,500 households were conducted in the growing seasons 2002/2003 or 2003/2004 in eleven African countries: Burkina Faso, Cameroon, Ghana, Niger and Senegal in western Africa; Egypt in northern Africa; Ethiopia and Kenya in eastern Africa; South Africa, Zambia and Zimbabwe in southern Africa. Households were chosen randomly in districts that are representative for key agro-climatic zones and farming systems. The data set specifies farming systems characteristics that can help inform about the importance of each system for a country’s agricultural production and its ability to cope with short- and long-term climate changes or extreme weather events. Further it informs about the location of smallholders and vulnerable systems and permits benchmarking agricultural systems characteristics.


### Content

The data file contains survey data collected from different families and has 9597 rows that represent the households and 1753 columns with details about the households. The questionnaire was organized into seven sections and respondents were asked to relate the information provided to the previous 12 months’ farming season. There are too many columns to describe here, however they are described in detail in this paper: [https://www.nature.com/articles/sdata201620?WT.ec_id=SDATA-201605][1]

* Questionnaire.pdf: This file contains the questionnaire used, a description for each variable name and the question ID.

* SurveyManual.pdf: This file gives further information on the household questionnaire, the research design and surveying. It was produced for the team leaders and interviewers in the World Bank/GEF project.

* AdaptationCoding.pdf: This file describes codes for variables ‘ad711’ to ‘ad7625’ from section VII of the questionnaire on adaptation options.

There is also some description in how the data was collected in Survey.pdf.



### Acknowledgements

Waha, Katharina; Zipf, Birgit; Kurukulasuriya, Pradeep; Hassan, Rashid (2016): An agricultural survey for more than 9,500 African households. figshare.
https://doi.org/10.6084/m9.figshare.c.1574094

https://www.nature.com/articles/sdata201620?WT.ec_id=SDATA-201605


The original DTA file was converted to CSV



### Inspiration

This dataset contains a huge amount of information related to farming households in Africa. Data like these are important for studying the impact of global warming on African agriculture and farming families. 



[1]: https://www.nature.com/articles/sdata201620?WT.ec_id=SDATA-201605",.csv
Air Passenger Data for Time Series Analysis,1,air-passenger-data-for-time-series-analysis,AirPassengers.csv,CC0-1.0,"### Context

This data is used for making ARIMA model forecasting.


### Content

This contains the increasing rate of passenger


### Acknowledgements

We wouldn't be here without the help of others. If you owe any attributions or thanks, include them here along with any citations of past research.


### Inspiration

Your data will be in front of the world's largest data science community. What questions do you want to see answered?",.csv
Air Quality,1,air-quality,Air_Quality.csv,MIT,"Dataset contains information on New York City air quality surveillance data.
Air pollution is one of the most important environmental threats to urban populations and while all people are exposed, pollutant emissions, levels of exposure, and population vulnerability vary across neighborhoods. ",.csv
Air Quality Data in India (2017 - 2022),1,air-quality-data-in-india,air-quality-india.csv,CC0-1.0,"### Similar Datasets

- Cirrhosis Prediction Dataset: [LINK](https://www.kaggle.com/datasets/fedesoriano/cirrhosis-prediction-dataset)
- Boston House Prices-Advanced Regression Techniques: [LINK](https://www.kaggle.com/datasets/fedesoriano/the-boston-houseprice-data)
- CERN Electron Collision Data: [LINK](https://www.kaggle.com/datasets/fedesoriano/cern-electron-collision-data)
- Hepatitis C Prediction Dataset: [LINK](https://www.kaggle.com/datasets/fedesoriano/hepatitis-c-dataset)
- Spanish Wine Quality Dataset: [LINK](https://www.kaggle.com/datasets/fedesoriano/spanish-wine-quality-dataset)


### Context

Air is what keeps humans alive. Since industrialization, there has been an increasing concern about environmental pollution. As mentioned in the WHO report 7 million premature deaths annually linked to air pollution, air pollution is the world's largest single environmental risk. Moreover, as reported in the NY Times article, India’s Air Pollution Rivals China’s as World’s Deadliest it has been found that India's air pollution is deadlier than even China's.

Monitoring it and understanding its quality is of immense importance to our well-being. Using this dataset one can explore India's air pollution levels at a more granular scale.


### Content

The dataset contains hourly air quality data (PM 2.5) of India. More specifically, it contains 36.192 observations of the hourly PM2.5 measure in India.


### Attribute Information

1. Timestamp: Timestamp in the format YYYY-MM-DD HH:MM:SS
1. Year: Year of the measure
1. Month: Month of the measure
1. Day: Day of the measure
1. Hour: Hour of the measure
1. PM2.5: Fine particulate matter air pollutant level in air


### Citation Request

If you want to cite this data:
&gt; fedesoriano. (June 2022). Air Quality Data in India (2017 - 2022). Retrieved [Date Retrieved] from https://www.kaggle.com/datasets/fedesoriano/air-quality-data-in-india",.csv
Air Quality Dataset,1,adl-classification,dataset.csv,CC-BY-SA-4.0,"### Context

The variation in indoor gas concentration over time is monitored and data is stored in order to use this information to evaluate the type of activity carried out in the room. Thanks to the use of artificial intelligence, a quantitative approach in determining the gas concentration was avoided, which would have required careful calibration of the sensors. The dataset contains the values ​​acquired by an array of 6 low cost sensors in successive instants of time, and the stored values ​​are associated with the particular action that generated them. Through an appropriate data processing, based on machine learning algorithms, after an initial training phase it is possible to recognize the actions that are carried out inside the home.

### Content

The presence of chemicals in the air is determined through a series of electrochemical gas sensors that have been selected based on the stated technical specifications on the ability to detect classes of compounds. The sensor set can be grouped into two main categories:
- MQ sensors (MQ2, MQ9, MQ135, MQ137, MQ138) which have great sensitivity, low latency and low cost; each sensor can respond to different gases;
- Analog CO2 gas sensor (MG-811) which has excellent sensitivity to carbon dioxide and is scarcely affected by the temperature and humidity of the air.
The dataset contains 1845 collected samples describing 4 target situations:
1 - Normal situation - Activity: clean air, a person sleeping or studying or resting - Samples: 595;
2 - Preparing meals - Activities: cooking meat or pasta, fried vegetables. One or two people in the room, forced air circulation - Samples: 515.
3 - Presence of smoke - Activity: burning paper and wood for a short period of time in a room with closed windows and doors - Example: 195.
4 - Cleaning - Activity: use of spray and liquid detergents with ammonia and / or alcohol. Forced air circulation can be activated or deactivated - Samples: 540.
Each sample is made up of 7 values; the first six values ​​are the sensor outputs, while the last is the index of the action that generated the values ​​acquired by the sensors. The four different situations are associated with a fairly different composition of the air, taking into account that any activity produces chemical substances due, that is, to human respiration, to the exhalations of metabolic processes, to the release of volatiles by combustion and / or oxidation, and evaporation of household detergents.

### Acknowledgements

Gambi, Ennio (2020), “Air Quality dataset for ADL classification”, Mendeley Data, V1, doi: 10.17632/kn3x9rz3kd.1
",.csv
Air Quality Index - India,1,air-quality-index-india,Air Quality Index-India.csv,MIT,The dataset has pollution data spanning across the Indian states with their minimum and maximum values.The name of the pollutant is also included in the dataset. The dataset contains NA values so that you can use your cleaning skills on the dataset.The dataset is extracted from [https://data.gov.in/](url). ,.csv
Air components dataset with AQI,1,air-components-dataset-with-aqi,Air_dataset.csv,other,it is taken from Kaggle and it is more efficient and useable now I clean it and I also perform feature engineering on it .now it does not contain any missing value  and it is now more accurate ,.csv
"Air quality data of Delhi, India",1,delhi-air-quality,delhi_aqi.csv,CC-BY-NC-SA-4.0,"
This dataset contains air quality data from the national capital of Delhi, India. It includes information on air pollution levels, including particulate matter (PM2.5 and PM10) levels, nitrogen dioxide (NO2), sulfur dioxide (SO2), carbon dioxide (CO2), ozone (O3), and other pollutants. The data was collected from monitoring stations located in various areas of Delhi between November 25, 2020, and January 24, 2023. This dataset is a valuable resource for researchers and policymakers to better understand air quality in Delhi and its impacts on public health.",.csv
AirBNB listings for TEXAS .,1,airbnb-listings-for-texas,listings.csv,MIT,"The provided dataset contains information about rental properties in Austin, Texas. It includes attributes such as property ID, name, host ID, host name, neighbourhood group, neighbourhood, latitude, longitude, room type, price, and counts associated with different categories.

The data is segmented into various categories, including price ranges, neighbourhood groups, latitude and longitude ranges, room types, and other attributes. Counts are provided for each category, indicating the number of properties that belong to each segment.

Overall, the dataset offers a detailed overview of rental properties in Austin, allowing for analysis and insights into the rental market in the area.",.csv
AirBNB_Data,1,airbnb-data,Airbnb_Data.csv,Apache 2.0,"This extensive dataset offers a detailed glimpse into the dynamic world of Airbnb accommodations spanning diverse locations worldwide. From cozy apartments in bustling urban centers to serene retreats nestled in picturesque countryside, this collection provides valuable insights into the various types of lodging options available on the Airbnb platform. With comprehensive information on property features, pricing, reviews, and host characteristics, researchers and enthusiasts alike can delve into the intricate ecosystem of shared lodging, uncovering trends, patterns, and preferences that shape the evolving landscape of modern hospitality. Whether analyzing market trends, assessing the impact of tourism on local economies, or simply satisfying a curiosity about global travel trends, this dataset serves as a rich resource for exploring the multifaceted realm of Airbnb accommodations.",.csv
Airbnb (ABNB) Stock Data 📈,1,airbnb-stock-dataset-2020-24,abnb_stock_data.csv,Apache 2.0,"### Description
This dataset contains historical stock data for Airbnb (ABNB) from 2010 to 2024. The data includes information such as opening price, closing price, high, low, and volume traded for each trading day during this period.

### Overview
The dataset provides valuable insights into the performance of Airbnb's stock over time, including trends, volatility, and key milestones. It can be used for various analytical purposes such as trend analysis, correlation studies, and forecasting.

### Columns
- **Date:** The date of the trading day.
- **Open:** The opening price of the stock.
- **High:** The highest price of the stock during the trading day.
- **Low:** The lowest price of the stock during the trading day.
- **Close:** The closing price of the stock.
- **Adj Close:** The adjusted closing price of the stock.
- **Volume:** The volume of shares traded during the trading day.
",.csv
Airbnb Cleaned Europe Dataset,1,airbnb-cleaned-europe-dataset,Aemf1.csv,CC0-1.0,"This is a merged dataset of 9 famous cities in Europe.

Amsterdam, Athens, Barcelona, Berlin, Budapest, Lisbon, Paris, Rome and Vienna.

The original Dataset was really messy and lacked describing appropriate information.

Perform analysis and tell a story you'd like to tell with this dataset.

Column names are self-explanatory.

Have fun exploring.",.csv
Airbnb Lisbon [2023],1,airbnb-lisbon-2023,lisboa_data.csv,ODC Public Domain Dedication and Licence (PDDL),"The data provided by Inside Airbnb for the city of Lisbon contains detailed information about the accommodation listings available on the Airbnb platform in that region. Below is an explanation of the main columns included in the data:

- id: The unique identifier of the Airbnb listing.
- host_id: The unique identifier of the host responsible for the listing.
- host_name: The name of the host.
- host_since: The date the host registered on the Airbnb platform.
- host_location: The location of the host.
- host_total_listings_count: The total number of listings the host has.
- neighborhood: The neighborhood where the property is located.
- neighborhood_group: The neighborhood group to which the neighborhood belongs.
- latitude: The latitude of the property's location.
- longitude: The longitude of the property's location.
- room_type: The type of room offered in the listing (e.g., entire house/apartment, private room, shared room).
- bathrooms_text: The description of the bathrooms available on the property.
- bedrooms: The number of bedrooms in the property.
- price: The price per night for the listing.
- minimum_nights: The minimum number of nights required to book the property.
- maximum_nights: The maximum number of nights allowed to book the property.
- has_availability: Indicates whether the property is available.
- availability_365: The number of days the property can book over a year.
- number_of_reviews_ltm: The number of reviews received in the last 12 months.
- review_scores_rating: The average score of reviews received by the property.
- license: The license or registration of the property, if applicable.
- calculated_host_listings_count: The number of listings the host has in total.
- calculated_host_listings_count_entire_homes: The host owns the number of entire listings (entire house/apartment).
- reviews_per_month: The average number of reviews the property receives per month.

These columns provide a comprehensive view of the characteristics of available accommodation listings in Lisbon during the period in which the data was collected.  This is a valuable data source for exploratory analysis, predictive modeling, and research related to the shared hosting industry in Lisbon. It provides a detailed look at listing features, including information about hosts, property locations, room type, pricing, availability, and reviews received.",.csv
Airline Customer Reviews,1,airline-customer-reviews,customer_reviews.csv,other,"The dataset consists of text based customer reviews about an airline.
It is a good resource for learning, practicing or testing beginner to intermediate NLP tasks like text cleaning, word tokenization, sentiment analysis and then predictive modelling bases on analysed sentiments.",.csv
Airline Customer Satisfaction,1,airline-customer-satisfaction,Airline_customer_satisfaction.csv,Apache 2.0,"The dataset provides insights into customer satisfaction levels within an undisclosed airline company. While the specific airline name is withheld, the dataset is rich in information, containing **22 columns and 129,880 rows**. It aims to predict whether future customers will be satisfied based on various parameters included in the dataset.

The columns likely cover a range of factors that influence customer satisfaction, such as flight punctuality, service quality, and so. By analyzing this dataset, airlines can gain valuable insights into the factors that contribute to customer satisfaction and tailor their services accordingly to enhance the overall customer experience.",.csv
Airline Database,1,airline-database,airlines.csv,DbCL-1.0,"Airline database
---

As of January 2012, the OpenFlights Airlines Database contains 5888 airlines. Some of the information is public data and some is contributed by users.

### Content

**The data is ISO 8859-1 (Latin-1) encoded.**

Each entry contains the following information:
- Airline ID	Unique OpenFlights identifier for this airline.
- Name	Name of the airline.
- Alias	Alias of the airline. For example, All Nippon Airways is commonly known as ""ANA"".
- IATA	2-letter IATA code, if available.
- ICAO	3-letter ICAO code, if available.
- Callsign	Airline callsign.
- Country	Country or territory where airline is incorporated.
- Active	""Y"" if the airline is or has until recently been operational, ""N"" if it is defunct. This field is not reliable: in particular, major airlines that stopped flying long ago, but have not had their IATA code reassigned (eg. Ansett/AN), will incorrectly show as ""Y"".

The special value \N is used for ""NULL"" to indicate that no value is available. This is from a MySQL database where \N is used for NULL. 

Notes: Airlines with null codes/callsigns/countries generally represent user-added airlines. Since the data is intended primarily for current flights, defunct IATA codes are generally not included. For example, ""Sabena"" is not listed with a SN IATA code, since ""SN"" is presently used by its successor Brussels Airlines.


### Acknowledgements

This dataset was downloaded from [Openflights.org][1] under the Open Database license. This is an excellent resource and there is a lot more on their website, so check them out! 

  [1]: https://openflights.org/data.html",.csv
Airline Delays,1,airline-delays,airline_delay.csv,other,"Airline Delays for December 2019 and 2020.
Description
Summary Data counts for airline per carrier per US City.

Usage
airline_delay
Format
A data frame with 3351 rows and 21 variables.

year
Year data collected

month
Numeric representation of the month

carrier
Carrier.

carrier_name
Carrier Name.

airport
Airport code.

airport_name
Name of airport.

arr_flights
Number of flights arriving at airport

arr_del15
Number of flights more than 15 minutes late

carrier_ct
Number of flights delayed due to air carrier. (e.g. no crew)

weather_ct
Number of flights due to weather.

nas_ct
Number of flights delayed due to National Aviation System (e.g. heavy air traffic).

security_ct
Number of flights canceled due to a security breach.

late_aircraft_ct
Number of flights delayed as a result of another flight on the same aircraft delayed

arr_cancelled
Number of cancelled flights

arr_diverted
Number of flights that were diverted

arr_delay
Total time (minutes) of delayed flight.

carrier_delay
Total time (minutes) of delay due to air carrier

weather_delay
Total time (minutes) of delay due to inclement weather.

nas_delay
Total time (minutes) of delay due to National Aviation System.

security_delay
Total time (minutes) of delay as a result of a security issue .

late_aircraft_delay
Total time (minutes) of delay flights as a result of a previous flight on the same airplane being late.",.csv
Airline Quality Ratings,1,airline-quality-ratings,Airline Quality Ratings.csv,other,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16192307%2F048c7e6a373b860a8ae3851b65fd4b75%2F5f68722457c04e888857b812dd799465-airbus-zeroe-blended-wing-body-concept.jpg?generation=1714564658259991&alt=media)

Passenger satisfaction is measured by more than 120,000 airline passengers, including additional information about each passenger, their flight and type of travel, as well as ratings on various factors such as cleanliness, comfort, service and overall experience.

**Columns:**

**ID:** Passenger ID

**Gender:** Passenger gender

**Age:** Passenger age

**Customer Type:** The customer type

**Type of Travel:** Purpose of the flight of the passengers

**Class:** Travel class in the plane of the passengers

**Flight Distance:** Flight distance

**Departure Delay:** Minutes delayed when departure

**Arrival Delay:** Minutes delayed when Arrival

**Departure & Arrival Time Сonvenience:** Convenience of departure and arrival times for passengers

**Ease of Online Booking:** Easy to book

**Check-in Service:** Ease of registration

**Online Boarding:** Convenience of online registration

**Gate Location:** Gate Location Estimation

**On-board Service:** Service on board

**Seat Comfort:** Comfortable seating

**Leg Room Service:** Leg room service level

**Cleanliness:** Cleanliness level

**Food and Drink:** Quality of food and drinks

**In-flight Service:** Level of service on board

**In-flight Wifi Service:** Wifi quality level on board

**In-flight Entertainment:** Rating of in-flight entertainment

**Baggage Handling:** Opinion on baggage handling

**Satisfaction:** Airline satisfaction level


![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16192307%2F4a0ce484b5741e47cce942d5c41b4699%2F6_1.jpg__1510842959__11219.jpg?generation=1714564510963899&alt=media)",.csv
Airline Review,1,airline-review,airline_review.csv,other,"This Dataset is built on considering various reviews and ratings.
This dataset does not contain any missing values.
This dataset can be used to identify the insights from reviews and ratings and build visualizations on it.",.csv
Airline Reviews,1,airline-reviews,BA_AirlineReviews.csv,MIT,"# **British Airways Customer Feedback Dataset**

## **Overview:**
This dataset contains customer feedback for British Airways, extracted from [AirlineQuality](https://www.airlinequality.com/) through web scraping. The dataset is a rich resource for sentiment analysis, enabling researchers and data enthusiasts to explore and understand the sentiments expressed by British Airways passengers.

## **Columns:**

- **OverallRating:** The overall rating given by the customer.
- **ReviewHeader:** The header or title of the customer's review.
- **Name:** The name of the customer providing the feedback.
- **Datetime:** The date and time when the feedback was posted.
- **VerifiedReview:** Indicates whether the review is verified or not.
- **ReviewBody:** The detailed body of the customer's review.
- **TypeOfTraveller:** The type of traveler (e.g., Business, Leisure).
- **SeatType:** Class of the traveler (e.g. Business, Economy).
- **Route:** The flight route taken by the customer.
- **DateFlown:** The date when the flight was taken.
- **SeatComfort:** Rating for seat comfort.
- **CabinStaffService:** Rating for cabin staff service.
- **GroundService:** Rating for ground service.
- **ValueForMoney:** Rating for the value for money.
- **Recommended:** Whether the customer recommends British Airways.
- **Aircraft:** The aircraft used for the flight.
- **Food&Beverages:** Rating for food and beverages.
- **InflightEntertainment:** Rating for inflight entertainment.
- **Wifi&Connectivity:** Rating for onboard wifi and connectivity.

## **Potential Use Cases:**
- **Sentiment Analysis:** Analyze the sentiments of customers based on their reviews.
- **Service Quality Assessment:** Assess the quality of various services provided by British Airways.
- **Route Performance:** Examine customer feedback specific to flight routes.
- **Aircraft Experience:** Understand customer opinions on different aircraft.

## **Citation:**
If you use this dataset in your research or analysis, please consider citing it with the following information:

Anshul Chaudhary, & Muskan Risinghani. (2023). <i>Airline Reviews</i> [Data set]. Kaggle. https://doi.org/10.34740/KAGGLE/DS/4044107


## **Note:**
This dataset is for educational and research purposes only. The opinions expressed in the reviews are those of the individual customers and do not necessarily reflect the views of the dataset creator.
",.csv
Airline Reviews Dataset,1,airlines-reviews,airlines_reviews.csv,MIT,"This dataset contains reviews of the top 10 rated airlines in 2023 sourced from the Airline Quality (https://www.airlinequality.com) website. The reviews cover various aspects of the flight experience, including seat comfort, staff service, food and beverages, inflight entertainment, value for money, and overall rating. The dataset is suitable for sentiment analysis, customer satisfaction analysis, and other similar tasks.

**Usage**
- Download the dataset file airlines_reviews.csv.
- Use the dataset for analysis, visualization, and machine learning tasks.

**List of Airlines**
1. Singapore Airlines
2. Qatar Airways
3. All Nippon Airways
4. Emirates
5. Japan Airlines
6. Turkish Airlines
7. Air France
8. Cathay Pacific Airways
9. EVA Air
10.Korean Air

This dataset is provided under the MIT License.

",.csv
Airline sentiment,1,airline-sentiment,Tweets.csv,CC0-1.0,"###Context

This is US airlines data which contain comments of passengers on basis of service provided by airlines.




### Inspiration

you can use it for sentiment analysis .",.csv
Airlines Customer satisfaction,1,airlines-customer-satisfaction,Invistico_Airline.csv,CC0-1.0,"This data given by an airline organization. The actual name of the company is not given due to various purposes that's why the name Invistico airlines.

The dataset consists of the details of customers who have already flown with them. The feedback of the customers on various context and their flight data has been consolidated. 

The main purpose of this dataset is to predict whether a future customer would be satisfied with their service given the details of the other parameters values. 

Also the airlines need to know on which aspect of the services offered by them have to be emphasized more to generate more satisfied customers.",.csv
Airlines Reviews and Rating,1,airlines-reviews-and-rating,Airlines Reviews and Rating.csv,CC0-1.0,"The Airlines Reviews and Ratings dataset is a comprehensive collection of passenger feedback on various aspects of their flight experiences across different airlines. This dataset aims to provide insights into passenger satisfaction and airlines' service quality, offering valuable data for analysis in the travel and hospitality industry, customer service improvement, and predictive modeling for customer satisfaction. Airlines Reviews and Ratings Dataset, a rich collection designed to explore the multifaceted aspects of air travel experiences across various airlines worldwide. This dataset encompasses a broad range of data points, from aircraft types and user reviews to detailed service ratings, offering a unique lens through which to analyze and predict airline performance from a passenger perspective.


# **Column Details:**

- **Aircraft Type:** Type of aircraft used for the flight.
- **Users Reviews:** Textual reviews provided by the users.
- **Country:** The country of the airline or the flight origin/destination.
- **Type of Travellers:** Categorizes travellers (e.g., Solo, Family, Business...).
- **Route:** The flight route taken.
- **Seat Types:** Class of the seat (Economy, Business, First Class...).
- **Seat Comfort:** Rating of the seat comfort.
- **Date Flown:** When the flight took place./The flight date.
- **Cabin Staff Service:** Rating of the service provided by the cabin staff.
- **Ground Service/Floor:** Rating of the ground service, including check-in and boarding.
- **Food & Beverages:** Rating of the food and beverage quality.
- **Wifi & Connectivity:** Rating of the wifi and connectivity options available.
- **Inflight Entertainment:** Rating of the inflight entertainment options.
- **Value For Money:** Overall value for money rating.
- **Recommended:** Whether the reviewer recommends the airline or not.",.csv
Airlines Traffic Passenger Statistics,1,airlines-traffic-passenger-statistics,Air_Traffic_Passenger_Statistics.csv,CC-BY-NC-SA-4.0,"# Airlines Traffic Passenger Statistics
### A New Look at an Old Problem
_____

### About this dataset
This dataset contains information on air traffic passenger statistics by the airline. It includes information on the airlines, airports, and regions that the flights departed from and arrived at. It also includes information on the type of activity, price category, terminal, boarding area, and number of passengers

### How to use the dataset

Air traffic passenger statistics can be a useful tool for understanding the airline industry and for making travel plans. This dataset from Open Flights contains information on air traffic passenger statistics by airline for 2017. The data includes the number of passengers, the operating airline, the published airline, the geographic region, the activity type code, the price category code, the terminal, the boarding area, and the year and month of the flight

### Research Ideas
- Air traffic passenger statistics could be used to predict future trends in air travel.
- The data could be used to generate heat maps of airline traffic patterns.
- The data could be used to study the effects of different factors on air traffic passenger numbers, such as the time of year or day, the price of airfare, or the number of flights offered by an airline

### License

&gt; **License: [Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/)**
&gt; - You are free to:
&gt;      - **Share** - copy and redistribute the material in any medium or format for non-commercial purposes only.
&gt;      - **Adapt** - remix, transform, and build upon the material for non-commercial purposes only.
&gt; - You must:
&gt;      - **Give appropriate credit** - Provide a link to the license, and indicate if changes were made.
&gt;      - **ShareAlike** - You must distribute your contributions under the same license as the original.
&gt; - You may not:
&gt;      - **Use the material for commercial purposes**.

### Columns

**File: Air_Traffic_Passenger_Statistics.csv**
| Column name                     | Description                                                                   |
|:--------------------------------|:------------------------------------------------------------------------------|
| **Activity Period**             | The date of the activity. (Date)                                              |
| **Operating Airline**           | The airline that operated the flight. (String)                                |
| **Operating Airline IATA Code** | The IATA code of the airline that operated the flight. (String)               |
| **Published Airline**           | The airline that published the fare for the flight. (String)                  |
| **Published Airline IATA Code** | The IATA code of the airline that published the fare for the flight. (String) |
| **GEO Summary**                 | A summary of the geographic region. (String)                                  |
| **GEO Region**                  | The geographic region. (String)                                               |
| **Activity Type Code**          | The type of activity. (String)                                                |
| **Price Category Code**         | The price category of the fare. (String)                                      |
| **Terminal**                    | The terminal of the flight. (String)                                          |
| **Boarding Area**               | The boarding area of the flight. (String)                                     |
| **Passenger Count**             | The number of passengers on the flight. (Integer)                             |
| **Adjusted Activity Type Code** | The type of activity, adjusted for missing data. (String)                     |
| **Adjusted Passenger Count**    | The number of passengers on the flight, adjusted for missing data. (Integer)  |
| **Year**                        | The year of the activity. (Integer)                                           |
| **Month**                       | The month of the activity. (Integer)                                          |

",.csv
Airlines_Booking.csv,1,airlines-booking-csv,customer_booking.csv,CC0-1.0,"This dataset contains information about airline bookings, including the number of passengers, sales channel, trip type, purchase lead time, length of stay, flight hour, flight day, route, booking origin, and various flags indicating if the customer wanted extra baggage, preferred seat, or in-flight meals. The dataset also includes the total flight duration and a flag indicating if the booking was completed. This information can be used for various analyses, such as predicting demand, identifying popular routes, and understanding customer preferences.

## **Column Description:**

- `num_passengers` = number of passengers travelling
- `sales_channel` = sales channel booking was made on
- `trip_type` = trip Type (Round Trip, One Way, Circle Trip)
- `purchase_lead` = number of days between travel date and booking date
- `length_of_stay` = number of days spent at destination
- `flight_hour` = hour of flight departure
- `flight_day` = day of week of flight departure
- `route` = origin -&gt; destination flight route
- `booking_origin` = country from where booking was made
- `wants_extra_baggage` = if the customer wanted extra baggage in the booking
- `wants_preferred_seat` = if the customer wanted a preferred seat in the booking
- `wants_in_flight_meals` = if the customer wanted in-flight meals in the booking
- `flight_duration` = total duration of flight (in hours)
- `booking_complete` = flag indicating if the customer completed the booking",.csv
Airplane Crash Data Since 1908,1,airplane-crash-data-since-1908,Airplane_Crashes_and_Fatalities_Since_1908_20190820105639.csv,ODbL-1.0,"### Context

The aviation accident database throughout the world, from 1908-2019.

- All civil and commercial aviation accidents of scheduled and non-scheduled passenger airliners worldwide, which resulted in a fatality (including all U.S. Part 121 and Part 135 fatal accidents)
- All cargo, positioning, ferry and test flight fatal accidents. 
- All military transport accidents with 10 or more fatalities.
- All commercial and military helicopter accidents with greater than 10 fatalities.
- All civil and military airship accidents involving fatalities.
- Aviation accidents involving the death of famous people. 
- Aviation accidents or incidents of noteworthy interest.

There are similar dataset available on Kaggle. This dataset is cleaned versioned and source code is available on github.


### Content

Data is scraped from planecrashinfo.com. Below you can find the dataset column descriptions:


- Date:	 Date of accident,  in the format - January 01, 2001
- Time:	 Local time, in 24 hr. format unless otherwise specified
- Airline/Op:	 Airline or operator of the aircraft
- Flight #:	 Flight number assigned by the aircraft operator
- Route:	 Complete or partial route flown prior to the accident
- AC Type:	 Aircraft type
- Reg:	 ICAO registration of the aircraft
- cn / ln:	 Construction or serial number / Line or fuselage number
- Aboard:	 Total aboard (passengers / crew)
- Fatalities:	 Total fatalities aboard (passengers / crew)
- Ground:	 Total killed on the ground
- Summary:	 Brief description of the accident and cause if known
 

### Acknowledgements

The original data is from the Plane Crash info website (http://www.planecrashinfo.com/database.htm). Dataset is scraped with Python. Source code is also public on [Github](https://gist.github.com/cgurkan/2e923ee92d3984611b78341b3ddbe46d)


### Inspiration
Find the root cause of plane crashes. Find any insights from dataset such as 
- Which operators are the worst
- Which aircrafts are the worst",.csv
Airplane Crashes Since 1908,1,airplane-crashes-since-1908,Airplane_Crashes_and_Fatalities_Since_1908.csv,ODbL-1.0,"## Airplane Crashes and Fatalities Since 1908 (Full history of airplane crashes throughout the world, from 1908-present)

At the time this Dataset was created in Kaggle (2016-09-09), the original version was hosted by Open Data by Socrata at the at: https://opendata.socrata.com/Government/Airplane-Crashes-and-Fatalities-Since-1908/q2te-8cvq, but unfortunately that is not available anymore. The dataset contains data of airplane accidents involving civil, commercial and military transport worldwide from 1908-09-17 to 2009-06-08.

While applying for a data scientist job opportunity, I was asked the following questions on this dataset:

 1. Yearly how many planes crashed? how many people were on board? how many survived? how many died?
 2. Highest number of crashes by operator and Type of aircrafts.
 3. ‘Summary’ field has the details about the crashes. Find the reasons of the crash and categorize them in different clusters i.e Fire, shot down, weather (for the ‘Blanks’ in the data category can be UNKNOWN) you are open to make clusters of your choice but they should not exceed 7.
 4. Find the number of crashed aircrafts and number of deaths against each category from above step.
 5. Find any interesting trends/behaviors that you encounter when you analyze the dataset.


----------


My solution was:

The following bar charts display the answers requested by point 1. of the assignment, in particular:

 - the planes crashed per year
 - people aboard per year during crashes
 - people dead per year during crashes
 - people survived per year during crashes

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F298505%2F37efb7629abf402544ddc46cc3a2d7bb%2F__results___0_0.png?generation=1587821759491827&alt=media)

The following answers regard point 2 of the assignment

- Highest number of crashes by operator: Aeroflot with 179 crashes
- By Type of aircraft: Douglas DC-3 with 334 crashes

I have identified 7 clusters using k-means clustering technique on a matrix obtained by a text corpus created by using Text Analysis (plain text, remove punctuation, to lower, etc.)
The following table summarize for each cluster the number of crashes and death.

- Cluster 1: 258 crashes, 6368 deaths
- Cluster 2: 500 crashes, 9408 deaths
- Cluster 3: 211 crashes, 3513 deaths	
- Cluster 4: 1014 crashes, 14790 deaths	
- Cluster 5: 2749 crashes, 58826 deaths	
- Cluster 6: 195 crashes, 4439 deaths	
- Cluster 7: 341 crashes, 8135 deaths

The following picture shows clusters using the first 2 principal components:
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F298505%2Fea73e0fe9ca12d594fd83f285d3eff62%2F__results___1_17.png?generation=1587821871806437&alt=media)


For each clusters I will summarize the most used words and I will try to identify the causes of the crash

Cluster 1 (258)
aircraft, crashed, plane, shortly, taking. 
No many information about this cluster can be deducted using Text Analysis

Cluster 2 (500)
aircraft, airport, altitude, crashed, crew, due, **engine**, failed, **failure**, **fire**, flight, **landing**, lost, pilot, plane, runway, **takeoff**, taking. 
Engine failure on the runway after landing or takeoff

Cluster 3 (211):
aircraft, crashed, **fog** 
Crash caused by fog

Cluster 4 (1014):
aircraft, airport, attempting, **cargo**, crashed, **fire**, land, **landing**, miles, pilot, plane, route, **runway**, **struck**, **takeoff** 
Struck a cargo during landing or takeoff

Cluster 5 (2749):
accident, aircraft, airport, altitude, approach, attempting, **cargo**, **conditions**, control, crashed, crew, due, **engine**, failed, **failure**, feet, fire, flight, flying, **fog**, ground, killed, land, landing, lost, low, miles, **mountain**, pilot. plane, poor, route, runway, short, shortly, **struck**, takeoff, taking, **weather**	
Struck a cargo due to engine failure or bad weather conditions mainly fog

Cluster 6 (195):
aircraft, crashed, **engine**, **failure**, **fire**, flight, left, pilot, plane, **runway**		
Engine failure on the runway

Cluster 7 (341):
accident, aircraft, altitude, cargo, control, crashed, crew, due, **engine**, **failure**, flight, **landing**, loss, lost, pilot, plane, **takeoff**	
Engine failure during landing or takeoff


----------
Better solutions are welcome. 

Thanks,
Sauro
",.csv
Airplane Crashes and Fatalities,1,airplane-crashes-and-fatalities,Airplane_Crashes_and_Fatalities_Since_1908.csv,CC-BY-NC-SA-4.0,"## Airplane Crashes and Fatalities
_____

This dataset showcases Boeing 707 accidents that have occurred since 1948. The data includes information on the date, time, location, operator, flight number, route, type of aircraft, registration number, cn/In number of persons on board, fatalities, ground fatalities, and a summary of the accident

### How to use the dataset
This dataset includes information on over 5,000 airplane crashes around the world.

This is an absolutely essential dataset for anyone interested in aviation safety! Here you will find information on when and where each crash occurred, what type of plane was involved, how many people were killed, and much more.

This dataset is perfect for anyone interested in data visualization or analysis. With so much information available, there are endless possibilities for interesting stories and insights that can be gleaned from this data.

So whether you're a seasoned data pro or just getting started, this dataset is sure to give you plenty to work with. So get started today and see what you can discover!

### Research Ideas
1. Plot a map of all flight routes
2. Analyze what type of aircraft is involved in the most crashes
3. Identify patterns in where/when crashes occur

### Columns
- **index:** the index of the row
- **Date:** the date of the incident
- **Time:** the time of the incident
- **Location:** the location of the incident
- **Operator:** the operator of the aircraft
- **Flight #:** the flight number of the aircraft
- **Route:** the route of the aircraft
- **Type:** the type of aircraft
- **Registration:** the registration of the aircraft
- **cn/In:** the construction number/serial number of the aircraft
- **Aboard:** the number of people on board the aircraft
- **Fatalities:** the number of fatalities in the incident
- **Ground:** the number of people on the ground killed in the incident
- **Summary:** a summary of the incident

### Acknowledgements
This dataset was obtained from the Data Society. If you use this dataset in your research, please credit the Data Society.

Columns: index, Date, Time, Location, Operator, Flight #, Route, Type, Registration, cn/In, Aboard, Fatalities Ground Summary

&gt; [Data Source](https://data.world/data-society)
",.csv
Airplane Crashes 🛫,1,airplane-crashes,Airplane_Crashes_and_Fatalities_Since_1908.csv,other,"**Dataset updated**
Feb 6, 2024

**Dataset provided by**
data.world, Inc.

**Authors**
Data Society 

**Time period covered**
Sep 17, 1908 - Jun 8, 2009

**Data Description**
The available dataset is about **Airplane Crashes** throughout the world since 1908.
Scholar publications : Click **[DOI](https://scholar.google.com/scholar?q=%22data%20world%20data%20society%20airplane%20crashes%22)**


Variables:
Date: Date of crash
Time: When in the day
Location: of crash
Operator: From which department?
Flight: Kind of flight
Route: Reason of flying
Type: Which type?
And other descriptions.

It's an easy dataset to know and you can use it for your EDA projects.
Good luck",.csv
Airplane Price Prediction,1,plane-price-prediction,Plane Price.csv,world-bank,This dataset is for plane price prediction. This dataset contain some important features of different model plane. These features are important for a plane price. To predict the price use those features. This is a machine learning regression problem.,.csv
"Airports, Train Stations, and Ferry Terminals",1,airports-train-stations-and-ferry-terminals,airports-extended.csv,DbCL-1.0,"### Context

This is a database of airports, train stations, and ferry terminals around the world. Some of the data come from public sources and some of it comes from OpenFlights.org user contributions.

### Content

- Airport ID	Unique OpenFlights identifier for this airport.
- Name	Name of airport. May or may not contain the City name.
- City	Main city served by airport. May be spelled differently from Name.
- Country	Country or territory where airport is located. See countries.dat to cross-reference to ISO 3166-1 codes.
- IATA	3-letter IATA code. Null if not assigned/unknown.
- ICAO	4-letter ICAO code.
- Null if not assigned.
- Latitude	Decimal degrees, usually to six significant digits. Negative is South, positive is North.
- Longitude	Decimal degrees, usually to six significant digits. Negative is West, positive is East.
- Altitude	In feet.
- Timezone	Hours offset from UTC. Fractional hours are expressed as decimals, eg. India is 5.5.
- DST	Daylight savings time. One of E (Europe), A (US/Canada), S (South America), O (Australia), Z (New Zealand), N (None) or U (Unknown). See also: Help: Time
- Tz database time zone	Timezone in ""tz"" (Olson) format, eg. ""America/Los_Angeles"".
- Type	Type of the airport. Value ""airport"" for air terminals, ""station"" for train stations, ""port"" for ferry terminals and ""unknown"" if not known.
- Source	Source of this data. ""OurAirports"" for data sourced from OurAirports, ""Legacy"" for old data not matched to OurAirports (mostly DAFIF), ""User"" for unverified user contributions. In airports.csv, only source=OurAirports is included.


### Acknowledgements

This dataset was downloaded from [Openflights.org][1] under the Open Database license. This is an excellent resource and there is a lot more on their website, so check them out! 

  [1]: https://openflights.org/data.html",.csv
Alcohol expenditure,1,alcohol-expenditure,alcohol-expenditure new.csv,CC0-1.0,"this graph was created in OurDataWorld:

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fa39a8c83b0c269ca294bd43ccc4807b9%2Fgraph1.png?generation=1715722751787246&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F452c02bac426f80a308910a78620f47d%2Fgraph2.png?generation=1715722757117261&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fa0ca5aaf7ff3d351ebab23ca46e72e77%2Fgraph3.png?generation=1715722762219361&alt=media)

All other (away from home)
Alcohol expenditure is measured in constant 1998 US$. Values also include taxes and tips.

Source
Alcohol expenditure in the USA long-term (USDA, 2018) – processed by Our World in Data
Date range
1935–2014
Unit
$
Links
https://www.ers.usda.gov/data-products/food-expenditures.aspx

Additional information about this data


The data of this indicator is based on the following sources:
Alcohol expenditure in the USA long-term (USDA, 2018)
Data published by
United States Department of Agriculture (USDA) Economic Research Service (ERS)

Retrieved on
27th April 2018
Retrieved from
https://www.ers.usda.gov/data-products/food-expenditures.aspx
How we process data at Our World in Data:
All data and visualizations on Our World in Data rely on data sourced from one or several original data providers. Preparing this original data involves several processing steps. Depending on the data, this can include standardizing country names and world region definitions, converting units, calculating derived indicators such as per capita measures, as well as adding or adapting metadata such as the name or the description given to an indicator.

At the link below you can find a detailed description of the structure of our data pipeline, including links to all the code used to prepare data across Our World in Data.

Read about our data pipeline
How to cite this data:
In-line citation
If you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:

Alcohol expenditure in the USA long-term (USDA, 2018) – processed by Our World in Data

Full citation

Alcohol expenditure in the USA long-term (USDA, 2018) – processed by Our World in Data. “All other (away from home)” [dataset]. Alcohol expenditure in the USA long-term (USDA, 2018) [original data].",.csv
Algerian Forest Fires Dataset,1,algerian-forest-fires-dataset,Algerian_forest_fires_dataset.csv,ODC Public Domain Dedication and Licence (PDDL),"The dataset includes 244 instances that regroup a data of two regions of Algeria, namely the Bejaia region located in the northeast of Algeria and the Sidi Bel-abbes region located in the northwest of Algeria.

122 instances for each region.

The period from June 2012 to September 2012.
The dataset includes 11 attributes and 1 output attribute (class)
The 244 instances have been classified into **fire** (138 classes) and **not fire** (106 classes) classes.
",.csv
AliExpress Product Reviews,1,aliexpress-product-reviews,Reviews.csv,Attribution 4.0 International (CC BY 4.0),"### Dataset Description:

This dataset contains information related to buyer reviews and evaluations of products, gathered from AliExpress. The data includes various attributes that provide insights into the sentiment, feedback, and interaction surrounding product evaluations. Below is a brief description of each column:

1. **buyerName**: The name or identifier of the buyer who submitted the evaluation.
2. **buyerCountry**: The country of the buyer who submitted the evaluation.
3. **Evaluation**: The evaluation or rating given by the buyer for the product.
4. **buyerFeedback**: The textual feedback provided by the buyer regarding their experience with the product.
5. **buyerProductFeedBack**: Specific feedback related to the product's features or performance.
6. **buyerTranslationFeedback**: Feedback related to translation services if applicable.
7. **downVoteCount**: The count of downvotes received for the evaluation.
8. **upVoteCount**: The count of upvotes received for the evaluation.
9. **evalData**: Date of the evaluation.
10. **evaluationId**: Unique identifier for each evaluation.
11. **responsiveness**: Evaluation of the product's responsiveness.
12. **warrantyService**: Evaluation of the product's warranty service.
13. **functionality**: Evaluation of the product's functionality.
14. **status**: Status of the evaluation or review.

This dataset provides valuable insights into buyer sentiments, preferences, and experiences with products. Researchers and analysts can use this data for sentiment analysis, product performance evaluation, and market research purposes.

---

### Data Source:

The data was scraped from an online platform using a Python web scraping script. The script is available on GitHub at [link_to_the_webscraper_code](https://github.com/MohammedDerouiche/aliExpressReviewsScraper). This script allows users to scrape data for specific products from the platform and gather information similar to what is presented in this dataset.",.csv
Alibaba (BABA) Stock Dataset📊,1,alibaba-baba-stock-dataset,BABA.csv,Apache 2.0,"# **Description:**

This dataset contains historical stock price data for Alibaba Group Holding (BABA) from [Jan/01/2020] to [May/01/2024]. The dataset includes daily opening, high, low, and closing prices, as well as adjusted closing prices and volume.

## **About Columns:**

- Date:
- Open:
- High:
- Low:
- Close:
- Adj Close:
- Volume:

### **Used by:**

- Predicting stock prices
- Building stock forecasting models
- Analyzing stock market trends
- Backtesting investment strategies
- Comparing machine learning models for stock prediction

  * This dataset is perfect for data scientists, analytics, and students looking to practice their skills in:
*
- Time series analysis
- Stock market analysis
- Predictive modeling
- Machine learning

**Get started:** Download the dataset and start exploring!",.csv
All Countries_details.,1,all-countries-details,All Countries.csv,Apache 2.0,"Here you get all the details of any country.
like (continent, Country, capital city, latitude, longitude, agricultural land) etc.


It would be an immense task to provide a detailed description of every country on Earth in a single response. However, I can provide you with a concise overview of each country, sorted alphabetically. Keep in mind that this will be very brief, and for up-to-date and detailed information, you should refer to reputable sources like government websites, encyclopedias, or travel guides.

Here is an alphabetical listing of countries along with a very brief description of each:

1. Afghanistan: A landlocked country in South Asia, known for its rugged terrain and complex history.

2. Albania: A Balkan country in Southeastern Europe, known for its rich cultural heritage and stunning landscapes.

3. Algeria: The largest country in Africa, situated in North Africa with diverse geography and a mix of cultures.

4. Andorra: A tiny principality in the Pyrenees mountains, known for its skiing resorts and beautiful landscapes.

5. Angola: A country in Southern Africa with a mix of natural beauty and a history shaped by colonialism and conflict.

6. Antigua and Barbuda: A Caribbean nation composed of two main islands, known for its stunning beaches and tourism industry.

7. Argentina: A vast country in South America, famous for its tango music, beef, and diverse landscapes.

8. Armenia: A landlocked country in the South Caucasus region, known for its ancient history and cultural heritage.

9. Australia: A large island nation known for its unique wildlife, diverse ecosystems, and vibrant cities.

10. Austria: A European country known for its rich cultural history, classical music, and stunning Alpine landscapes.

Please let me know if you would like me to continue with more countries and their brief descriptions.
",.csv
All Time Premier League Player Statistics,1,premier-league-player-statistics-updated-daily,dataset - 2020-09-24.csv,CC-BY-NC-SA-4.0,"### Context

I am a really huge football fan and the Premier League is one of my favourite football (or soccer, whatever you like to call it) leagues. So, as my very first dataset, I thought this would be a great opportunity for me to make a dataset of player statistics of all seasons from the Premier League.

The Premier League, often referred to as the English Premier League or the EPL outside England, is the top level of the English football league system. Contested by 20 clubs, it operates on a system of promotion and relegation with the English Football League (EFL). Contested by 20 clubs, it operates on a system of promotion and relegation with the English Football League. 

Home to some of the most famous clubs, players, managers and stadiums in world football, the Premier League is the most-watched league on the planet with one billion homes watching the action in 188 countries.The league takes place between August and May and involves the teams playing each other home and away across the season, a total of 380 matches.

Three points are awarded for a win, one point for a draw and none for a defeat, with the team with the most points at the end of the season winning the Premier League title. The teams that finish in the bottom three of the league table at the end of the campaign are relegated to the Championship, the second tier of English football. Those teams are replaced by three clubs promoted from the Championship; the sides that finish in first and second place and the third via the end-of-season playoffs. 


### Details about the dataset
* Some players of certain position may not have certain statistics - For example, A goalkeeper may not have a statistic for ""Shot Accuracy""
* The format for the filename is - dataset - {yyyy-mm-dd Date}
(The date is date when the file was last updated on)


### Content

The data was acquired from:

https://www.premierleague.com/ 

I made a BeautifulSoup4 Web Scrapper in Python3 which automatically outputs a csv file of all the player statistics. The runtime of the file is about 20 minutes but it varies with the bandwidth of the Internet connection. I made this program so that this dataset could be updated weekly. The reason for weekly update is that the statistics change after each match played by the player so I felt that for the most up-to-date results, such a program is needed. Planning this project took 2 days. Making the program in Python3 took 7 days and the testing and bug fixing took another 5 days. The project was completed in the span of 2 weeks.


### Acknowledgements

Source credits : https://www.premierleague.com/
Image credits : https://rb.gy/wuiwth


### Inspiration

How do variables like age, nationality and club affect the player performance? 


### Known issues in the dataset
* Goals per match displays an abnormally high value for a few players as the HTML displays incorrect value during first few milliseconds of loading the page. I am trying to fix it analytically rather than scrapping directly from the website.",.csv
All Trump's Twitter insults (2015-2021),1,all-trumps-twitter-insults-20152021,trump_insult_tweets_2014_to_2021.csv,CC0-1.0,"As a political figure, Donald J. Trump used Twitter to praise, to cajole, to entertain, to lobby, to establish his version of events — and, perhaps most notably, to amplify his scorn. This list documents the verbal attacks Mr. Trump posted on Twitter, from when he declared his candidacy in June 2015 to Jan. 8, when Twitter permanently barred him.

Based on an analysis of tweets since Mr. Trump declared his candidacy for president, on June 16, 2015. Retweets are not included. Some names may be omitted. This was first published in 2016; some of the people insulted have since died, and some people’s titles or public roles have changed.
Source: Trump Twitter Archive

This dataset has been extracted from [The New York Times](https://www.nytimes.com/interactive/2021/01/19/upshot/trump-complete-insult-list.html).",.csv
All the UNICORNS in the World,1,all-the-unicorns-in-the-world,List of Unicorns in the World.csv,CC0-1.0,"Unicorn companies are a select group of privately held startups that have achieved a valuation of over $1 billion. These companies are renowned for their exceptional growth, disruptive innovation, and substantial market potential. Emerging primarily in technology-driven sectors such as software, e-commerce, biotechnology, and fintech, unicorns leverage cutting-edge technologies, business models, and strategies to secure significant market share and attract substantial investments from venture capitalists, private equity firms, and institutional investors.

Their success stories serve as beacons of inspiration for aspiring entrepreneurs and as benchmarks for measuring innovation and entrepreneurial excellence. Unicorn companies play a pivotal role in driving economic growth, job creation, and industry transformation.

For data visualization and analysis purposes, datasets on unicorn companies typically encompass various attributes, including:

Company Name: Identifying the name of the unicorn company.
Industry Sector: Categorizing the sector or industry in which the company operates.
Valuation: Quantifying the company's valuation, often in billions of dollars.
Headquarters Location (Country and City): Specifying the location of the company's headquarters.
Date Became Unicorn: Mentioning the date when the company attained unicorn status.

Analyzing this data yields valuable insights into global trends within the startup ecosystem, investor preferences, geographic distribution of unicorns, industry dynamics, and factors contributing to their success. Utilizing data visualization techniques such as charts, graphs, maps, and dashboards facilitates a deeper understanding of these insights, enabling stakeholders to make informed decisions regarding investment, entrepreneurship, and industry strategy.",.csv
Alternative Fueling Station Counts byState 2007-23,1,alternative-fueling-station-counts-bystate-2014-23,Alternative_Fueling_Station_Counts_by_State_2007_2023.csv,DbCL-1.0,"The information was obtained from [https://afdc.energy.gov/stations/states](url) and downloaded as an excel .xlxs file.

The original excel file was processed and normalized, these were the main tasks performed:

- The '**Year**' column was added to identify which year the data belongs to.
- Replacing NaN values with 0.
- Transformation of float64 columns to **int64**.
- Generation of new columns with new data from 2014: Propane_Primary, Propane_Secondary, Propane_Total, Hydrogen_Retail, Hydrogen_Non_Retail, Hydrogen_Total, Electric_station,  Electric_outlets, Electric_Level1, Electric_Level2, Electric_DC_Fast.
- Elimination of repeated columns: Electric, Hydrogen & Propane.
- '**Renewable Diesel**' columns applied to all years.
- Comments were removed.
- The rows with the totals ('**Total**') were also eliminated.
- Rows with NaN values were deleted.
- Replaced values separated by '**/**' to '**|**' to be able to process complementary records.
- Thousand separators removed.",.csv
Alzheimer Features,1,alzheimer-features,alzheimer.csv,DbCL-1.0,"## Alzheimer Features For Analysis


Group is a target for models

Group --&gt; Class
Age --&gt; Age
EDUC --&gt; Years of Education
SES --&gt; Socioeconomic Status / 1-5
MMSE --&gt; Mini Mental State Examination
CDR --&gt; Clinical Dementia Rating
eTIV --&gt; Estimated total intracranial volume
nWBV --&gt; Normalize Whole Brain Volume
ASF --&gt; Atlas Scaling Factor


You can use it as a categorical variable:

Group
Age
EDUC

",.csv
Alzheimer's Disease and Healthy Aging Data,1,alzheimers-disease-and-healthy-aging-data,alzheimer_s_disease_and_healthy_aging_data.csv,other,"This comprehensive dataset sourced from the Behavioral Risk Factor Surveillance System (BRFSS) spans the years 2015 to 2022 and provides invaluable insights into Alzheimer's disease and healthy aging trends across various regions. With a plethora of attributes capturing diverse facets of the data, this dataset serves as a rich resource for researchers, healthcare professionals, policymakers, and data enthusiasts alike.

Attributes:
1. RowId: Unique identifier for each row.
2. YearStart: Start year of the data collection period.
3. YearEnd: End year of the data collection period.
4. LocationAbbr: Abbreviated code representing the location.
5. LocationDesc: Full name of the location.
6. Datasource: Source of the data (BRFSS).
7. Class: General classification of the data.
8. Topic: Specific topic related to Alzheimer's disease and healthy aging.
9. Question: Detailed question or metric being assessed.
10. Data_Value_Unit: Unit of measurement for the data value.
11. DataValueTypeID: Identifier for the type of data value.
12. Data_Value_Type: Type of data value (e.g., percentage, count).
13. Data_Value: Actual value of the data point.
14. Data_Value_Alt: Alternative representation of the data value (if applicable).
15. Data_Value_Footnote_Symbol: Symbol indicating presence of a footnote for the data value.
16. Data_Value_Footnote: Footnote providing additional context or explanation for the data value.
17. Low_Confidence_Limit: Lower bound of the confidence interval for the data value.
18. High_Confidence_Limit: Upper bound of the confidence interval for the data value.
19. StratificationCategory1: Primary category for data stratification.
20. Stratification1: Specific stratification within the primary category.
21. StratificationCategory2: Secondary category for data stratification (if applicable).
22. Stratification2: Specific stratification within the secondary category (if applicable).
23. Geolocation: Latitude and longitude coordinates of the location.
24. ClassID: Identifier for the general classification.
25. TopicID: Identifier for the specific topic.
26. QuestionID: Identifier for the detailed question or metric.
27. LocationID: Identifier for the location.
28. StratificationCategoryID1: Identifier for the primary stratification category.
29. StratificationID1: Identifier for the specific stratification within the primary category.
30. StratificationCategoryID2: Identifier for the secondary stratification category (if applicable).
31. StratificationID2: Identifier for the specific stratification within the secondary category (if applicable).

Utilize this dataset to delve into crucial insights regarding Alzheimer's disease prevalence, risk factors, regional disparities, and trends over time. Whether exploring demographic patterns, analyzing risk factors, or devising public health interventions, this dataset empowers users to make informed decisions and contribute to advancing research in Alzheimer's disease and healthy aging.

Source: https://catalog.data.gov/dataset/alzheimers-disease-and-healthy-aging-data (including Access & Use Information)",.csv
Amazon Data Science Books Dataset,1,amazon-data-science-books,final_book_dataset_kaggle2.csv,CC0-1.0,"
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F6372737%2Fc913ddc103f20c3668a67eda7a92336b%2Famazon-text-books.jpg?generation=1663537491733005&alt=media)


The dataset contains 946 books obtained from scraping [Amazon](https://www.amazon.com) books related to data science, statistics, data analysis, Python, deep learning, and machine learning.
There are 18 columns:


- **title**: title of the book
- **author**: author (or the authors) of the book
- **price**: price (in dollars)
- **price (including used books)**: price range of new and used books (in dollars)
- **pages**: number of pages
- **avg_reviews**: average reviews (out of 5)
- **n_reviews**: reviews done for each book
- **star5**: percentage of 5 star reviews
- **star4**: percentage of 4 star reviews
- **star3**: percentage of 3 star reviews
- **star2**: percentage of 2 star reviews
- **star1**: percentage of 1 star reviews
- **dimensions**: size of the book (in inches)
- **weight**: weight (in pounds or ounces)
- **language**: language of the book
- **publisher**: publisher
- **ISBN-13**: ISBN_13 code
- **link**: link of the Amazon book
- **complete_link**: complete link of the Amazon book (including the domain `https://amazon.com`)

###  **Inspiration**

You can perform an exploratory data analysis of the dataset, working with `Pandas` or `Numpy`.
Interesting visualizations can be performed too using, for instance, Python libraries to plot the different features.
This dataset can be also used to practice queries using `SQL` or `Pandas`.
Moreover, you can rank the books based on the number of positive reviews, or you can explore the dataset to have a reference for buying data-science-related books in the future. <br>

**Remember to upvote if you found the dataset useful :)**.

###  **Collection methodology**

The dataset was obtained through web scraping from Amazon.

More than 1700 books were scraped, fetching the most important information for each book.
Duplicated were deleted, each column was formatted and made easy to use for data analysis purposes.
Rows containing a lot of missing values were deleted, and in some cases, were filled with an appropriate value based on the column. Thus, the total number of books passed from 1788 to 946.

<br>
",.csv
Amazon Fine Food Reviews,1,amazon-fine-food-reviews,Reviews.csv,CC0-1.0,"## Context

This dataset consists of reviews of fine foods from amazon. The data span a period of more than 10 years, including all ~500,000 reviews up to October 2012. Reviews include product and user information, ratings, and a plain text review. It also includes reviews from all other Amazon categories.


## Contents

- Reviews.csv: Pulled from the corresponding SQLite table named Reviews in database.sqlite<br>
- database.sqlite: Contains the table 'Reviews'<br><br>

Data includes:<br>
- Reviews from Oct 1999 - Oct 2012<br>
- 568,454 reviews<br>
- 256,059 users<br>
- 74,258 products<br>
- 260 users with &gt; 50 reviews<br>


[![wordcloud](https://www.kaggle.io/svf/137051/2ba35b1344041b4964fe12365b577999/wordcloud.png)](https://www.kaggle.com/benhamner/d/snap/amazon-fine-food-reviews/reviews-wordcloud)


## Acknowledgements

See [this SQLite query](https://www.kaggle.com/benhamner/d/snap/amazon-fine-food-reviews/data-sample) for a quick sample of the dataset.

If you publish articles based on this dataset, please cite the following paper:

 - J. McAuley and J. Leskovec. [From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews](http://i.stanford.edu/~julian/pdfs/www13.pdf). WWW, 2013.",.csv
Amazon Kitchen Best Sellers Dataset 2024,1,amazon-kitchen-best-sellers-dataset-2024,amazon_kitchenware.csv,ODC Attribution License (ODC-By),"**Dataset Overview:**  
This collection encapsulates the pinnacle of kitchenware on Amazon, featuring 300 best-selling items for 2024. Each entry is a window into consumer preferences, highlighting sought-after products and emerging kitchen trends.

**Data Science Applications:**  
With its focused scope, this dataset is a gem for conducting nuanced market analyses, understanding consumer behavior, and identifying trending products. It's particularly suited for exploratory data analysis, basic predictive models to forecast product popularity, and sentiment analysis on customer reviews, given the manageable dataset size.

**Column Descriptors:**  
- **Title**: The product name, capturing the essence of each item.
- **Brand**: The company behind the product, indicating brand preference.
- **Description**: Product details, offering insight into what appeals to consumers.
- **Stars**: The average rating, reflecting customer satisfaction.
- **ReviewsCount**: The number of reviews, indicating popularity.
- **Price/Currency**: The currency for the price, providing economic context.
- **Price/Value**: The actual price, important for price trend analysis.
- **BreadCrumbs**: Category path, showing product classification on Amazon.
- **ASIN**: Amazon Standard Identification Number, unique to each product.
- **URL**: The direct link to the Amazon product page, facilitating further exploration.

**Ethically Mined Data:**  
This dataset was curated with the utmost respect for ethical standards, ensuring that all data gathering was conducted transparently and in full compliance with usage policies, emphasizing our commitment to responsible data usage.

**Acknowledgments:**  
Gratitude is extended to all the platforms that enable the ethical sharing of data, fostering a culture of openness and collaboration within the data science community. Their dedication to knowledge sharing and innovation continues to inspire and empower researchers and enthusiasts alike.",.csv
"Amazon Laptop Data: Explore, Analyze, Predict!",1,amazon-laptop-data-explore-analyze-predict,Amazon Laptop Data.csv,DbCL-1.0,"Explore the world of laptops on Amazon with this comprehensive dataset. This dataset contains information scraped from Amazon's laptop listings, providing valuable insights for analysis and predictive modeling.

Column Descriptions:

**Product Name:** The name or title of the laptop listed on Amazon.

**Original Price:** The original price of the laptop before any discounts.

**Discount Percentage:**The percentage of discount applied to the original price.

**Final Price:** The discounted price of the laptop after applying any discounts.

**Ratings:** The average rating of the laptop, presented as a numerical value out of 5 stars.

**Total Ratings Count:** The total number of ratings or reviews received by the laptop on Amazon.

With these columns, you can analyze pricing trends, explore customer ratings, and even build predictive models to forecast future sales or customer sentiment.",.csv
Amazon Prime Movies and TV Shows,1,amazon-prime-movies-and-tv-shows,amazon_prime_titles.csv,CC0-1.0,"### Amazon Prime Video - Movies and TV Shows 

&gt; **About this Dataset:** Amazon Prime is another one of the most popular media and video streaming platforms. They have close to 10000 movies or tv shows available on their platform, as of mid-2021, they have over 200M Subscribers globally. This tabular dataset consists of listings of all the movies and tv shows available on Amazon Prime, along with details such as - cast, directors, ratings, release year, duration, etc.* 

#### Interesting Task Ideas 

&gt; 
1. Understanding what content is available in different countries
2. Identifying similar content by matching text-based features 
3. Network analysis of Actors / Directors and find interesting insights  
4. Does Amazon Prime has more focus on TV Shows than movies in recent years.

### Other Platform's Datasets (Click on the logos to view) 

&gt; 
[![alt text][1]][2] [![alt text][3]][4] [![alt text][5]][6] [![alt text][7]][8]
[1]: https://i.imgur.com/As0PMcL.jpg =75x20
[2]: https://www.kaggle.com/shivamb/netflix-shows
[3]: https://i.imgur.com/r5t3MpQ.jpg =75x20
[4]: https://www.kaggle.com/shivamb/amazon-prime-movies-and-tv-shows
[5]: https://i.imgur.com/4a4ZMuy.png =75x30
[6]: https://www.kaggle.com/shivamb/disney-movies-and-tv-shows
[7]: https://i.imgur.com/nCL8Skc.png?1 =75x32
[8]: https://www.kaggle.com/shivamb/hulu-movies-and-tv-shows

- [Amazon Prime Video Movies and TV Shows](https://www.kaggle.com/shivamb/amazon-prime-movies-and-tv-shows)
- [Disney+ Movies and TV Shows](https://www.kaggle.com/shivamb/disney-movies-and-tv-shows)
- [Netflix Prime Video Movies and TV Shows](https://www.kaggle.com/shivamb/netflix-shows)
- [Hulu Movies and TV Shows](https://www.kaggle.com/shivamb/hulu-movies-and-tv-shows)

",.csv
Amazon Prime TV Shows,1,amazon-prime-tv-shows,Prime TV Shows Data set.csv,other,"### Context

This data set was created so as to analyze the latest shows available on Amazon Prime as well as the shows with a high rating.

### Content

The data set contains the name of the show or title, year of the release which is the year in which the show was released or went on-air, No.of seasons means the number of seasons of the show which are available on Prime, Language is for the audio language of the show and does not take into consideration the language of the subtitles, genre of the show like Kids, Drama, Action and so on, IMDB ratings of the show: though for many tv shows and kid shows the rating was not available, Age of Viewers is to specify the age of the target audience- All in age means that the content is not restricted to any particular age group and all audiences can view it.


### Acknowledgements

I have collected this data from Amazon Prime's Website. 


### Inspiration

Since a lot many TV shows have high IMDB ratings but don't get viewed that much because the audience is not aware of it or it is not advertised much. I have created this data set so as to find out the highest-rated shows in each category or in a particular genre.",.csv
Amazon Prime Userbase Dataset,1,amazon-prime-userbase-dataset,amazon_prime_users.csv,CC0-1.0,"The Amazon Prime Users Dataset contains information about 2500 fictional users of the Amazon Prime subscription service. Each entry in the dataset includes details such as the user's name, email address, location, subscription plan, payment information, and engagement metrics. Additionally, demographic data such as gender and date of birth are provided, along with user preferences such as favorite genres and devices used to access the platform.

The dataset aims to represent a diverse range of Prime users, including different demographics, subscription plans, and usage patterns. It is designed to facilitate analysis and insights into user behavior, preferences, and interactions with the Amazon Prime platform. Researchers and analysts can use this dataset to study trends, conduct targeted marketing campaigns, and improve user experience on the platform.

Please note that this dataset contains fictional data generated for illustrative purposes only and does not represent real Amazon Prime users.
",.csv
Amazon Product Reviews Dataset,1,amazon-product-reviews-dataset,7817_1.csv,CC0-1.0,"![](https://raw.githubusercontent.com/Masterx-AI/Project_Amazon_Product_Ratings_Topic_Modelling/main/Amazon.png)

### Description:

The dataset consists of samples from Amazon Ratings for select products. The reviews are picked randomly and the corpus has nearly 1.6k reviews of different customers.\
Amazon aims to understand what are the main topics of these reviews to classify them for easier search.\
Can you build a strong model that differentiates the topics based on the reviews corpus? 

#### Acknowledgements
The dataset is referred from Kaggle.

### Objective:
- Understand the Dataset & perform the necessary cleanup.
- Build a strong Topic Modelling Algorithm to classify the topics.",.csv
Amazon Selling Items Scrapped,1,amazon-selling-items-scrapped,Amazon Selling Items Scrapped.csv,CC0-1.0,"Directly Scrapped from Amazon website with the help of python libraries i.e. request/beutifulSoup...  
It has five columns as,
- Title - The name of the item
- Rating - Rating of the item
- Price - Price of the item
- Category - Main Category of the item
- Label - Secondary Categories separated by commas",.csv
Amazon Shopping Reviews [Daily Updated],1,amazon-shopping-reviews-daily-updated,amazon_reviews.csv,Apache 2.0,"The reviews and ratings of Amazon Shopping App by users are primary component of this dataset. It is updated daily . It also includes information on the relevancy of reviews and the date of posting the review,etc.",.csv
Amazon Stock Data,1,amazon-stock-data,AMZN.csv,other,"## **What is Amazon?**
Amazon.com, Inc. is an American multinational technology company which focuses on e-commerce, cloud computing, digital streaming, and artificial intelligence. It is one of the Big Five companies in the U.S. information technology industry, along with Google, Apple, Microsoft, and Facebook. The company has been referred to as ""one of the most influential economic and cultural forces in the world"", as well as the world's most valuable brand.

## **Data Description**
This dataset provides the history of daily prices of Amazon stock (AMZN). All the column descriptions are provided. Currency is USD.
",.csv
Amazon Stock Price (All Time),1,amazon-stock-price-all-time,Amazon.csv,CC0-1.0,"### Company Description
Amazon.com, Inc. engages in the provision of online retail shopping services. It operates through the following business segments: North America, International, and Amazon Web Services (AWS). The North America segment includes retail sales of consumer products and subscriptions through North America-focused websites such as www.amazon.com and www.amazon.ca. The International segment offers retail sales of consumer products and subscriptions through internationally-focused websites. The Amazon Web Services segment involves in the global sales of compute, storage, database, and AWS service offerings for start-ups, enterprises, government agencies, and academic institutions. The company was founded by Jeffrey P. Bezos in July 1994 and is headquartered in Seattle, WA.

### Contact Information
Amazon.com, Inc.
410 Terry Avenue North
Seattle Washington 98109-5210
P:(206) 266-1000
(206) 266-2171
www.amazon.com

### Shareholders
Mutual fund holders  32.52%
Other institutional	27.20%
Individual stakeholders	10.83%",.csv
Amazon Top 50 Bestselling Books 2009 - 2019,1,amazon-top-50-bestselling-books-2009-2019,bestsellers with categories.csv,CC0-1.0,"Dataset on Amazon's Top 50 bestselling books from 2009 to 2019. Contains 550 books, data has been categorized into fiction and non-fiction using Goodreads
",.csv
Amazon consumer Behaviour Dataset,1,amazon-consumer-behaviour-dataset,Amazon Customer Behavior Survey.csv,other,"
1.age=                                                     age

2.gender=                                               gender

3.Purchase_Frequency=                        How frequently do you make purchases on Amazon? 

4.Purchase_Categories=                       What product categories do you typically purchase on Amazon?

5.Personalized_Recommendation_Frequency  =   Have you ever made a purchase based on personalized product recommendations from Amazon?

6.Browsing_Frequency                     =How often do you browse Amazon's website or app? 

7.Product_Search_Method                  =How do you search for products on Amazon?

8.Search_Result_Exploration               =Do you tend to explore multiple pages of search results or focus on the first page?

9.Customer_Reviews_Importance             =How important are customer reviews in your decision-making process?

10.Add_to_Cart_Browsing                   =Do you add products to your cart while browsing on Amazon?

11.Cart_Completion_Frequency               =How often do you complete the purchase after adding products to your cart?

12.Cart_Abandonment_Factors                =What factors influence your decision to abandon a purchase in your cart? 

13.Saveforlater_Frequency                 =Do you use Amazon's ""Save for Later"" feature, and if so, how often?

14.Review_Left                            =Have you ever left a product review on Amazon?

15.Review_Reliability                    =How much do you rely on product reviews when making a purchase?

16.Review_Helpfulness                     =Do you find helpful information from other customers' reviews?

17.Personalized_Recommendation_Frequency         =How often do you receive personalized product recommendations from Amazon?

18.Recommendation_Helpfulness                    =Do you find the recommendations helpful?

19.Rating_Accuracy                 =How would you rate the relevance and accuracy of the recommendations you receive

20.Shopping_Satisfaction         =How satisfied are you with your overall shopping experience on Amazon?

23.Service_Appreciation         =What aspects of Amazon's services do you appreciate the most?

24.Improvement_Areas            =Are there any areas where you think Amazon can improve?",.csv
Amazon_Sales_Dataset,1,amazon-sales-dataset,amazon.csv,CC0-1.0,"This Data is a Amazon Product Sales. This Dataset about Amazon Sales Contain **3204** Rows and **9** Columns.  You Can Apply Various thing you can make DashBoard and perform Analysis many more..

***Column Description***

**Order Date** - Order_Date.

**Ship Date** - Shipping Date.

**Email_ID** - Email_ID of Users

**Geography** - Location of Orders by Users.

**Category** - Product Category

**Product Name** - Product Name of Amazon

**Sales** - Amazon Product Sales

**Quantity** - how many units of a particular product are available.

**Profit** - Amazon Sales Profit

",.csv
Amazon💼📉 Stock Dataset: Prices & Indicators 📈📊,1,background,amazon_stock_data_with_details.csv,Apache 2.0,"## Description:
This dataset provides comprehensive historical data for Amazon stock, including daily price information and various technical indicators. It serves as a valuable resource for analyzing the performance and trends of Amazon's stock over time.

## Columns:

- **Date:** The date of the trading day
- **Open:** The opening price of Amazon stock on the given day
- **High:** The highest price of Amazon stock during the trading day
- **Low:** The lowest price of Amazon stock during the trading day
- **Close:** The closing price of Amazon stock on the given day
- **Volume:** The trading volume of Amazon stock on the given day
- **Adj Close:** The adjusted closing price of Amazon stock, adjusted for dividends and stock splits
- **SMA_50:** 50-day Simple Moving Average
- **SMA_200:** 200-day Simple Moving Average
- **RSI:** Relative Strength Index
- **Upper Band:** Upper Bollinger Band
- **Middle Band:** Middle Bollinger Band
- **Lower Band:** Lower Bollinger Band

",.csv
America's Favorite Star Wars Movies,1,americas-favorite-star-wars-movies,StarWars.csv,MIT,"This dataset is from the poll by 538 (FiveThirtyEight) that was run in 2014.  The idea was to understand what Star Wars Movie responded have seen, and which is the best movie from Star Wars Franchise. 

I certainly have my own favorite Star Wars movie - had it ever since I was a small kid.  Let's see if American people share that opinion. 

There were also questions about Star Wars Characters.  Who is the most favorable and the least favorable character.  Han Solo or Luke Skywalker?  Let's see

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F6808204%2F984cf944a4ef1ded058ff61d0021f394%2Fhan%20solo%20vs%20luke%20skywalker.jfif?generation=1714986135292924&alt=media)
",.csv
American Citizens Annual Income,1,americancitizenincome,income.csv,Community Data License Agreement - Sharing - Version 1.0,"The dataset used in this notebook contains information about individuals' demographics, education, work experience, and other relevant factors. The income column in the dataset serves as the target variable, categorized into two classes: ""&lt;=50K"" (indicating income less than or equal to  50,000)and ""&gt;50K""


| Column           | Description                                                                                          |
| ---------------- | ---------------------------------------------------------------------------------------------------- |
| `age`            | Age                                                                                                  |
| `workclass`      | A general term indicating the employment status of an individual.                                    |
| `fnlwgt`         | Final weight, representing the number of individuals that this row represents (a representative sample). |
| `education`      | Highest level of education achieved by an individual.                                                |
| `education.num`  | Highest level of education achieved by an individual in numerical form.                              |
| `marital.status` | Marital status of an individual. Note that `Married-civ-spouse` refers to a civilian spouse, and `Married-AF-spouse` refers to a spouse in the Armed Forces. |
| `occupation`     | General type of occupation of an individual.                                                         |
| `relationship`   | Relationship of this individual with others, for example, spouse (`Husband`). Each data point has only one relationship. |
| `race`           | Race                                                                                                 |
| `sex`            | Biological sex of an individual.                                                                     |
| `capital.gain`   | Capital gains of an individual.                                                                      |
| `capital.loss`   | Capital losses of an individual.                                                                     |
| `hours.per.week` | Number of hours the individual reported working per week.                                            |
| `native.country` | Country of origin.                                                                                   |
| `income`         | Income, less than or equal to $50,000 (`&lt;=50K`) or more than that (`&gt;50K`).                          |

",.csv
Aminoacids: Physical and Chemical Properties,1,aminoacids-physical-and-chemical-properties,aminoacids.csv,CC0-1.0,"Physical and Chemical properties of 22 aminoacids.

Columns description:

- `Name`: name of the amino acid.
- `Abbr`: abbreviation of the amino acid.
- `Letter`: letter of the amino acid.
- `Molecular Weight`: molecular weight.
- `Molecular Formula`: molecular formula.
- `Residue Formula`: residue formula.
- `Residue Weight`: residue weight (-H20)
- `pKa1`: the negative of the logarithm of the dissociation constant for the -COOH group.
- `pKb2`: the negative of the logarithm of the dissociation constant for the -NH3 group.
- `pKx3`: the negative of the logarithm of the dissociation constant for any other group in the molecule.
- `pl4`: the pH at the isoelectric point.
- `H`: hydrophobicity.
- `VSC`: volumes of side chains amino acids.
- `P1`: polarity.
- `P2`: polarizability.
- `SASA`: solvent accesible surface area.
- `NCISC`: net charge of side chains.",.csv
Amod Mental Health Counseling Conversations,1,amod-mental-health-counseling-conversations-data,train.csv,CC0-1.0,"_____
# Amod Mental Health Counseling Conversations Dataset
### A dataset of mental health counseling conversations for training models
By Amod (From Huggingface) [[source]](https://huggingface.co/datasets/Amod/mental_health_counseling_conversations)
_____

### About this dataset
> 
> The dataset includes two key columns, namely Context and Response. The Context column contains the statements or questions that serve as the foundation for each conversation, focusing specifically on mental health concerns. Meanwhile, the Response column consists of expert responses provided by mental health counselors to address these questions and statements.
> 
> With this dataset, professionals in the field can leverage real-life scenarios to develop accurate and informative models for counseling individuals who seek assistance with their mental well-being. By analyzing this diverse set of conversations, these models can offer valuable insights and guidance when it comes to addressing different aspects of mental health.
> 
> It is important to note that this dataset does not include any specific dates or timeframes associated with the conversations, ensuring privacy and confidentiality for both patients and counselors involved in these discussions

### How to use the dataset
> 
> Introduction:
> 
> - Understanding the Dataset Structure:
>    - The dataset consists of a CSV file named train.csv, which contains two main columns: Context and Response.
>    - The Context column represents the questions or statements related to mental health issues in each conversation.
>    - The Response column includes the corresponding responses provided by mental health counselors.
> 
> - Preprocessing Steps:
>    - Before using the dataset, it is important to perform necessary preprocessing steps such as removing unnecessary punctuation, converting text to lowercase, and dealing with any missing values (if applicable).
>    - Additionally, it may be beneficial to tokenize or stem/lemmatize words within each text entry for further analysis.
> 
> - Exploring the Conversation Contexts:
>    - Analyzing and understanding the conversation contexts can help identify common mental health concerns or trends.
>    - Consider conducting exploratory data analysis techniques like frequency distribution analysis or word cloud generation to gain insights into frequently encountered topics.
> 
> - Analyzing Mental Health Counselor Responses:
>    - Pay close attention to mental health counselor responses provided in each conversation.
>    - Explore patterns in their answers and identify recommended strategies or approaches they offer in addressing various mental health concerns.
> 
> - Natural Language Processing (NLP) Applications:
>   a) Chatbot Development: Utilize this dataset as a training resource for developing AI-based mental health chatbots capable of providing relevant responses based on given contexts.
>   b) Sentiment Analysis: Apply sentiment analysis techniques on both context and response columns individually or comparatively.
>   c) Topic Modeling: Extract hidden topics within conversations using NLP methods like Latent Dirichlet Allocation (LDA) or Non-Negative Matrix Factorization (NMF).
> 
> - Machine Learning Applications:
>   a) Classify conversations into different mental health concern categories by treating it as a supervised classification problem.
>   b) Train a model to generate relevant responses based on given context inputs, using approaches like sequence-to-sequence models or transformers.
> 
> - Ethical Considerations:
>    - While working with this dataset, ensure the privacy and confidentiality of all individuals involved in the conversations.
>    - Anonymize any personally identifiable information (PII) and comply with applicable data protection regulations.
> 
> Conclusion:
> The Amod Mental

### Research Ideas
> - Training a chatbot: The dataset can be used to train a chatbot or virtual assistant that provides mental health counseling. The context and response columns can be used to teach the chatbot how to respond effectively to various mental health issues and concerns.
> - Research on mental health conversations: Researchers can analyze this dataset to gain insights into common questions, concerns, and themes related to mental health. This can help in understanding the needs of individuals seeking support and guide the development of more effective counseling interventions.
> - Improving counseling techniques: Mental health professionals can use this dataset to study different counseling responses provided by trained counselors. By analyzing successful responses, they can enhance their own counseling skills or develop training programs for future counselors.
> Note: Possible sensitivity issues should be considered when using this dataset for any purpose, as it contains sensitive information related to mental health conversations. Anonymization or ethical considerations should be taken into account when using this data for research or practical applications

### Acknowledgements
> If you use this dataset in your research, please credit the original authors.
> [Data Source](https://huggingface.co/datasets/Amod/mental_health_counseling_conversations)
> 
>


### License
> 
> 
> **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
> No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: train.csv**
| Column name   | Description                                                                                                                                                                                |
|:--------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Context**   | This column contains the overall context of the conversation, including any questions or statements related to mental health issues. (Text)                                                |
| **Response**  | This column contains the corresponding response provided by a trained mental health counselor to address and support the individuals seeking guidance within that specific context. (Text) |

### Acknowledgements
> If you use this dataset in your research, please credit the original authors.
> If you use this dataset in your research, please credit [Amod (From Huggingface)](https://huggingface.co/datasets/Amod/mental_health_counseling_conversations).

",.csv
Amsterdam House Price Prediction,1,amsterdam-house-price-prediction,HousingPrices-Amsterdam-August-2021.csv,CC0-1.0,"### Context
If you are like me, you might get overwhelmed when having to make big decisions such as buying a house. In such cases, I always like to go for a data driven approach, that will help me find an optimum solution. This involves two steps. First, we need to gather as much data as we can. Second, we need to define a metric for success. 

Gathering housing prices requires some effort. A caveat is that the asking prices are not the prices to which the houses were actually sold. Defining a metric for success is somewhat subjective. I consider a house to be a good option if the house price is cheap compared to other listings in the area. 

### Content
The housing prices have been obtained from Pararius.nl as a snapshot in August 2021. The original data provided features such as price, floor area and the number of rooms. The data has been further enhanced by utilising the Mapbox API to obtain the coordinates of each listing. 

### Acknowledgements
Thanks to Pararius",.csv
Amyotrophic lateral sclerosis (ALS),1,amyotrophic-lateral-sclerosis-als,Minsk2020_ALS_dataset.csv,other,"Voice database was collected in Republican Research and Clinical Center of Neurology and Neurosurgery (Minsk, Belarus). It consists of 128 sustained vowel phonations (64 of vowel /a/ and 64 of vowel /i/) from 64 speakers, 31 of which were diagnosed with ALS. Each speaker was asked to produce sustained phonation of vowels /a/ and /i/ at a comfortable pitch and loudness as constant and long as possible. It can be seen that voice database is almost balanced and contains 48% of pathological voices and 52% of healthy voices.

The age of the 17 male patients ranges from 40 to 69 (mean 61.1 ± 7.7) and the age of the 14 female patients ranges from 39 to 70 (mean 57.3 ± 7.8). For the case of healthy controls (HC), the age of the 13 men ranges from 34 to 80 (mean 50.2 ± 13.8) and the age of the 20 females ranges from 37 to 68 (mean 56.1 ± 9.7). The samples were recorded at 44.1 kHz using different smartphones with a regular headsets and stored as 16 bit uncompressed PCM files. Average duration of the records in the HC group was 3.7 ± 1.5 s, and in ALS group 4.1 ± 2.0 s. The detailed information about ALS patients is presented in the [article](https://arxiv.org/abs/2012.07347)",.csv
Anagrams Dataset,1,anagrams-dataset,anagrams.csv,Apache 2.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F19517213%2F2baee69cd9611c30c4c535f2d10cc266%2F0_oiswHbCp26mU9Vrp.jpg?generation=1711294766233894&alt=media)

The ""anagrams"" dataset contains timings for solving anagrams under different conditions. An anagram is a word or phrase formed by rearranging the letters of a different word or phrase, typically using all the original letters exactly once. In this dataset, timings are recorded for solving anagrams, likely to analyze factors such as difficulty level, time taken under different conditions, or other experimental variables.

Each entry in the dataset likely includes information such as:

- The anagram itself
- The time taken to solve the anagram
- Conditions under which the anagram was solved 

**Columns**
- subidr: Subject identifier or ID.

- attnr: Attention condition, possibly indicating whether the subject was in a ""divided"" or ""focused"" attention condition.

- num1, num2, num3: These columns likely represent numerical values or measurements recorded for each subject under different conditions or trials.

Each row in the dataset appears to correspond to a single observation or trial, with the values representing various measurements or responses collected from each subject.",.csv
Analyzing Market Responses to Boycott Movements,1,analyzing-market-responses-to-boycott-movements,SBUX_stock_price.csv,DbCL-1.0,"Dataset has been curated for implementing state-of-the-art time series forecasting techniques on financial data. Build machine learning models for forecasting future stock prices of SBUX based on historical data and external factors such as boycott movements [1], economic indicators, and consumer sentiment. Explore how boycott movements affect investor sentiment and stock prices over time. 
- Time series forecasting using advanced machine learning techniques.
- Analysis of the impact of boycott movements on investor sentiment and stock prices.
- Development of predictive models to anticipate market trends and inform investment strategies.



[1] *https://www.ft.com/content/d3995b6e-3b63-4f7b-958e-17f990975b20*",.csv
Android Malware Detection,1,tuandromd,TUANDROMD.csv,Attribution 4.0 International (CC BY 4.0),"TUNADROMD dataset contains 4465 instances and 241 attributes. The target attribute for classification is a category (malware vs goodware). (N.B. This is the preprocessed version of TUANDROMD)

**Variables:**

1-214: Permission-based features
215-241: API based features

**Class Labels**

Class: 1) Malware 2) Goodware

**Introductory Paper**
[Malware Dataset Generation and Evaluation](https://www.semanticscholar.org/paper/97e4780810c69604f6e2f2f4e31b88bbef7ca669)

By Parthajit Borah, DK Bhattacharyya, J. Kalita. 2020

Published in Conference Information and Communication Technology",.csv
Android Malware Detection Dataset,1,android-malware-detection-dataset,Android_Malware.csv,MIT,"The ""Android Malware Detection Dataset"" is a comprehensive collection of data designed to facilitate research in the detection and analysis of malware targeting the Android platform. This dataset encompasses a wide range of features extracted from Android applications, providing valuable insights into their behaviors and functionalities.

Key features of the dataset include:

- Permission Features: Various permissions requested by Android applications, such as access to location (coarse and fine), camera, microphone, contacts, SMS, calendar, storage, and more.
- System Features: Features related to system functions and controls, including access to device hardware (e.g., sensors, Bluetooth, NFC), system settings (e.g., changing network state, WiFi settings), and system services (e.g., managing accounts, managing documents).
- Security-related Features: Features related to security functionalities and behaviors, encompassing permission management, authentication, encryption (e.g., cryptographic operations), and security policy enforcement.
- Communication Features: Features related to communication functionalities, including sending and receiving SMS messages, making phone calls, accessing network state, and managing network connections.
- Data Access Features: Features related to accessing and manipulating data, such as reading and writing to various data sources (e.g., external storage, databases), accessing user information (e.g., contacts, call logs), and accessing app-specific data.
- App Lifecycle Features: Features related to managing the application lifecycle, including app installation and uninstallation, app startup and shutdown, app updates, and app permissions.
- Device Control Features: Features related to controlling device behavior and settings, such as changing system settings, modifying audio settings, controlling device display, and managing device power.
- Miscellaneous Features: Other miscellaneous features including accessing system logs, system services and components (e.g., camera, location manager), handling system events (e.g., incoming calls, boot completed), and interacting with system UI components.

This dataset provides researchers with a rich source of information to develop and evaluate effective malware detection and analysis techniques, ultimately contributing to the enhancement of mobile security on the Android platform.",.csv
Anemia Types Classification,1,anemia-types-classification,diagnosed_cbc_data_v4.csv,Apache 2.0,"CBC data labeled with the diagnosis of Anemia type, The data collected among several CBCs data and diagnosed manually

## Data Dictionary:

  * HGB: The amount of hemoglobin in the blood, crucial for oxygen transport.
  * PlT: The number of platelets in the blood, involved in blood clotting.
  * WBC: The count of white blood cells, vital for immune response.
  * RBC: The count of red blood cells, responsible for oxygen transport.
  * MCV (Mean Corpuscular Volume): Average volume of a single red blood cell.
  * MCH (Mean Corpuscular Hemoglobin): Average amount of hemoglobin per red blood cell.
  * MCHC (Mean Corpuscular Hemoglobin Concentration): Average concentration of hemoglobin in red blood cells.
  * PDW: a measurement of the variability in platelet size distribution in the blood
  * PCT: A procalcitonin test can help your health care provider diagnose if you have sepsis from a bacterial infection or if you have a high risk of developing sepsis
  * Diagnosis: Anemia type based on the CBC parameters
",.csv
Animal Bites,1,animal-bites,Health_AnimalBites.csv,CC0-1.0,"
### Context: 

In the United States, animal bites are often reported to law enforcement (such as animal control). The main concern with an animal bite is that the animal may be rabid. This dataset includes information on over 9,000 animal bites which occurred near Louisville, Kentucky from 1985 to 2017 and includes information on whether the animal was quarantined after the bite occurred and whether that animal was rabid.

### Content: 

Attributes of animal bite incidents reported to and investigated by Louisville Metro Department of Public Health and Wellness.  Personal/identifying data has been removed. This dataset is a single .csv with the following fields.

* bite_date: The date the bite occurred
* SpeciesIDDesc: The species of animal that did the biting
* BreedIDDesc: Breed (if known)
* GenderIDDesc: Gender (of the animal)
* color: color of the animal
* vaccination_yrs: how many years had passed since the last vaccination
* vaccination_date: the date of the last vaccination
* victim_zip: the zipcode of the victim
* AdvIssuedYNDesc: whether advice was issued
* WhereBittenIDDesc: Where on the body the victim was bitten
* quarantine_date: whether the animal was quarantined
* DispositionIDDesc: whether the animal was released from quarantine
* head_sent_date: the date the animal’s head was sent to the lab
* release_date: the date the animal was released	
* ResultsIDDesc: results from lab tests (for rabies)

### Acknowledgements: 

Attributes of animal bite incidents reported to and investigated by Louisville Metro Department of Public Health and Wellness. This data is in the public domain.

### Inspiration: 

* Which animals are most likely to bite humans?
* Are some dog breeds more likely to bite?
* What factors are most strongly associated with a positive rabies ID? ",.csv
Animal Condition Classification Dataset,1,animal-disease,data.csv,Community Data License Agreement - Sharing - Version 1.0,"The ""Animal Condition Classification Dataset"" presents a unique and intricate data challenge in the realm of animal health assessment. Featuring a diverse array of animal species, ranging from birds to mammals, this dataset enables the development of predictive models to determine whether an animal's condition is dangerous or not based on five distinct symptoms. The dataset's diversity opens doors to creating a classification system that transcends taxonomic boundaries, making it particularly valuable for people interested in animal welfare and wildlife conservation. However, its manual collection process introduces potential sources of error, including spelling mistakes and variations in symptom representation. This necessitates meticulous data-cleaning efforts.

As you delve into the ""Animal Condition Classification Dataset,"" they are poised to confront challenges such as class imbalance and the need for feature engineering. Addressing these challenges will be crucial for achieving robust classification models. Thus, this dataset serves as a rich resource for those eager to make a meaningful impact in the field of animal health assessment, with the understanding that it demands careful handling and methodological rigour to deliver insightful and ethically sound results.

data.csv
- AnimalName: Contains the animal kind. Like dog, cat, etc
- symptoms1-5: Contain symptoms 
- Dangerous: Contains whether the condition is dangerous or not. 

If you are new to machine learning, refer to these two notebooks
- https://www.kaggle.com/code/gracehephzibahm/beginner-s-guide-data-cleaning
- https://www.kaggle.com/code/gracehephzibahm/beginner-s-guide-data-exploration-ml-modeling

The raw data might seem hard to handle, so you can use these refined data for starting out. 
- cleaned data: https://www.kaggle.com/code/gracehephzibahm/beginner-s-guide-data-cleaning/output
- encoded data: https://www.kaggle.com/code/gracehephzibahm/beginner-s-guide-data-exploration-ml-modeling/output",.csv
Animal Information Dataset,1,animal-information-dataset,Animal Dataset.csv,other,"### Context

Animals are multicellular, eukaryotic organisms in the biological kingdom Animalia. With few exceptions, animals consume organic material, breathe oxygen, have myocytes and are able to move, can reproduce sexually, and grow from a hollow sphere of cells, the blastula, during embryonic development. As of 2022, 2.16 million living animal species have been described—of which around 1.05 million are insects, over 85,000 are mollusks, and around 65,000 are vertebrates. It has been estimated there are around 7.77 million animal species. Animals range in length from 8.5 micrometers (0.00033 in) to 33.6 meters (110 ft). They have complex interactions with each other and their environments, forming intricate food webs. The scientific study of animals is known as zoology.

### Content

This dataset encompasses a diverse array of attributes pertaining to various animal species worldwide. The dataset prominently includes fields such as Animal, Height (cm), Weight (kg), Color, Lifespan (years), Diet, Habitat, Predators, Average Speed (km/h), Countries Found, Conservation Status, Family, Gestation Period (days), Top Speed (km/h), Social Structure, and Offspring per Birth. These columns collectively offer a comprehensive understanding of animal characteristics, habitats, behaviors, and conservation statuses. Researchers and enthusiasts can utilize this dataset to analyze animal traits, study their habitats, explore dietary patterns, assess conservation needs, and conduct a wide range of ecological research and wildlife studies.

### Dataset Glossary (Column-wise)

* **Animal** - Name of the animal.
* **Height (cm)** - Height range in centimeters for the animal.
* **Weight (kg)** - Weight range in kilograms for the animal.
* **Color** - Common colors associated with the animal's appearance.
* **Lifespan (years)** - Average lifespan of the animal in years.
* **Diet** - Type of diet the animal primarily follows (e.g., Carnivore, Herbivore).
* **Habitat** - Typical habitat or environment where the animal is found.
* **Predators** - Natural enemies or organisms that prey on the animal.
* **Average Speed (km/h)** - The average speed range the animal can achieve in kilometers per hour.
* **Countries Found** - Countries or regions where the animal is commonly found.
* **Conservation Status** - The conservation status of the animal as per relevant conservation organizations.
* **Family** - Taxonomic family the animal belongs to.
* **Gestation Period (days)** - Range of days representing the gestation or pregnancy period of the animal.
* **Top Speed (km/h)** - The maximum speed the animal can achieve in kilometers per hour.
* **Social Structure** - Information about the social behavior or structure of the animal (e.g., Solitary, Group-based).
* **Offspring per Birth** - The typical number of offspring born per birth or reproduction event for the animal.

### Structure of the Dataset

![](https://i.imgur.com/2V3vbKL.png)

### Acknowledgement

This dataset was generated using information from: <b><a href=""https://www.wikipedia.org/"">https://www.wikipedia.org/</a></b>. If you wish to delve deeper, you can explore the website.

Cover Photo by: <b><a href=""https://www.freepik.com/free-vector/cute-wild-animals-group_51397449.htm#query=cartoon%20animals&position=24&from_view=keyword&track=ais"">Image by brgfx</a></b> on Freepik

Thumbnail by: <b><a href=""https://www.flaticon.com/free-icons/dog"">Dog icons created by Flat Icons - Flaticon</a></b>",.csv
Animated Movies and TV Shows,1,animated-tv-shows-with-imdb-and-google-user-rating,Animated_Tv_Series.csv,CC0-1.0,"## Context
All Animated TV shows with IMDb and Google user rating

Presenting a comprehensive compilation of Animated television series, featuring essential details such as series name, episode/season count, release year, streaming platform, production company, co-producers, IMDb rating, and Google user rating.
##Content
- **ID:** ID for each Animated TV shows
- **Title:** Name of each Animated TV shows
- **Episodes:** Number of Episodes
- **Year:** The release year of the animated movie
- **Original channel:** The streaming platform where the animated series originally aired
- **American company:** The Animation's production company
- **Note:** The Animation's  co-production company
- **Technique:** The artistic methodology utilized in the creation of the animation
- **IMDb:** The IMDb rating
- **Google users:** The Percentage of Google users liked this TV Show
",.csv
Anime Ratings and Popularity Dataset 2023,1,anime-ratings-and-popularity-dataset,Anime_ratings.csv,MIT,"Let's break down each column:

1. **Title**: This column contains the titles of different anime.
2. **Genres**: This column typically lists the genres or categories to which each anime belongs. For example, action, adventure, romance, fantasy, etc.
3. **Rank**: This column indicates the rank of each anime based on some criteria such as user ratings, popularity, or critical acclaim. The rank could be determined within a specific timeframe or across all time.
4. **Popularity**: This column represents the popularity of each anime. Popularity could be measured by factors such as online searches, views, ratings, or social media mentions.
5. **Score**: This column indicates the overall score or rating of each anime. Scores are often based on user reviews, ratings, or aggregated scores from various sources.
6. **Episodes**: This column denotes the number of episodes available for each anime. It indicates how many individual installments or chapters make up the series.
7. **Episode length**: This column specifies the length of each episode in terms of duration. It could be in minutes or hours, indicating how long each episode lasts.
8. **Release Date**: This column represents the release date of each anime. It indicates when the anime was first aired or released to the public.",.csv
Anime TV-Shows Dataset 2023,1,anime-tv-shows-dataset-2023,anime_data.csv,Apache 2.0,"# Anime Dataset

## Overview

This dataset contains information about various anime series, including details such as the name, number of episodes, release date, number of members, and user scores. It is a curated list of popular anime series as of the date of creation, with a total of 4700 rows.

## Columns

- **Name**: The title of the anime series.
- **Episodes**: The total number of episodes in the series.
- **Release**: The release date range of the anime.
- **Members**: The number of MyAnimeList users who have added the anime to their lists.
- **Score**: The user score for the anime.

## Usage

This dataset can be used for various purposes, including:

- Exploratory Data Analysis (EDA) of anime trends.
- Building recommendation systems based on user scores and other features.
- Understanding the popularity and user engagement of different anime series.

## Example Questions

1. What are the top-rated anime series based on user scores?
2. How does the number of episodes correlate with user scores?
3. Are there any trends in the popularity of anime over the years?

## Acknowledgements

The data was scraped from MyAnimeList, a popular anime and manga database. Special thanks to MyAnimeList for providing a platform for anime enthusiasts to track and discover new series.
",.csv
Annual Working Hours Dataset (1870-1970),1,annual-working-hours-dataset-1870-1970,annual-working-hours-per-worker.csv,CC0-1.0,"# **Description:**
This dataset provides historical insights into the average annual working hours per worker for various countries from 1870 to 1970. It serves as a valuable resource for understanding trends in labour productivity, industrialization, and work-life balance over the past century.

# **Features:**
1. **Country:** The name of the country.
2. **Country Abbreviation:** Abbreviation code for the country.
3. **Year:** The year of data collection.
4. **Average annual working hours per worker:** The average number of annual working hours per worker in the respective country for the given year.

# **Usage:**
- Researchers and economists can use this dataset to analyze historical patterns in working hours and their relationship to economic development and social policies.
- Policy makers can utilize the data to inform labor regulations and initiatives aimed at improving work conditions and promoting work-life balance.


# **License:**
I'd like to thank ourworldindata.org for aggregating this data!",.csv
Antibiotic Dataset,1,antibiotic-dataset,antibiotics_list.csv,ODC Attribution License (ODC-By),"

**Dataset Overview:**
This Antibiotic Dataset is designed to offer a straightforward overview of 100 commonly encountered antibiotics. It's a valuable asset for data enthusiasts exploring the realms of healthcare, pharmacology, and data science.

**Data Science Applications:**
The dataset opens up numerous possibilities for data analysis, including tracking antibiotic usage trends, studying patterns in antibiotic resistance, and serving as a rich educational tool for understanding the diverse world of antibiotics.

**Column Descriptors:**
- **Name**: The generic name of the antibiotic.
- **Family**: The class or group to which the antibiotic belongs, indicating its general mechanism of action or chemical structure.
- **Usage**: Common indications or infections for which the antibiotic is prescribed.
- **Popular Brand Name**: A well-known brand name under which the antibiotic is marketed.

**Ethically Obtained Data:**
Rest assured, the information within this dataset has been ethically sourced, adhering to the highest standards of data privacy and integrity. It aggregates knowledge from trusted and authoritative sources.

**Sources:**
This dataset was compiled with information from a variety of reputable sources to ensure breadth and reliability. Key references include:
- [Drugs.com Antibiotics Overview](https://www.drugs.com/article/antibiotics.html)
- [Wikipedia List of Antibiotics](https://en.wikipedia.org/wiki/List_of_antibiotics)

**Caution:**
This compilation is intended strictly for informational purposes. Antibiotics are powerful medicines and should be used judiciously. Misuse and overuse can lead to antibiotic resistance, a severe global health risk. Always consult a healthcare professional before using antibiotics.

",.csv
Antibody sequence that has INN,1,antibody-sequence-that-has-inn,240110_TheraSAbDab.csv,MIT,"The INN (International Nonproprietary Name) is a globally recognized name assigned to a pharmaceutical substance to ensure its clear identification, even across different countries and languages. The antibody sequence is a specific arrangement of amino acids that forms the structure of an antibody, a protein produced by the immune system to identify and neutralize foreign substances in the body.

Got the sequence info from the Inxight website via web scraping and fixed any mistakes by hand but not perfectly.",.csv
Anxiety Phases Dataset,1,anxiety-phases-dataset,participants_details.csv,other,"The 4 stages of anxiety
The cycle of anxiety includes four stages:

Stage 1. Feeling anxious and wanting to deal with it.
Stage 2. Attempting to avoid the situation.
Stage 3. Feeling a temporary sense of relief
Stage 4. Returning to a state of heightened anxiety.


How to identify the 4 stages
the first stage of anxiety usually includes an automatic fight-or-flight response.

The second stage might involve bodily sensations or reactions that may lead to some form of self-protection. By the fourth and final stage, you might feel mentally, emotionally, and physically drained.

Your answers to the following questions can help you identify which stage of anxiety you’re in to help you manage your symptoms.
",.csv
Anxiety and Depression Psychological Therapies ,1,cusersmarildownloadsanxietycsv,anxiety.csv,other,"### Context

National Clinical Audit of Anxiety and Depression Psychological Therapies Spotlight Audit. Data collected between October 2018 and January 2019 and aggregated by mental health services delivering psychological therapies in secondary care. 

https://data.gov.uk/dataset/3da96fcf-7abb-4118-93d0-928b77e3ab75/national-clinical-audit-of-anxiety-and-depression-psychological-therapies-spotlight-audit


### Content

Freedom of Information (FOI) requests : Dr Alan Quirk
Alan.Quirk@rcpsych.ac.uk
https://www.rcpsych.ac.uk/improving-care/ccqi/national-clinical-audits/national-clinical-audit-of-anxiety-and-depression




### Acknowledgements

https://data.gov.uk/dataset/3da96fcf-7abb-4118-93d0-928b77e3ab75/national-clinical-audit-of-anxiety-and-depression-psychological-therapies-spotlight-audit

Photo by Sarah Kilian on Unsplash (Covid-19 times)



### Inspiration

The Implications of COVID-19 for Mental Health .  The COVID-19 pandemic and resulting economic downturn have negatively affected many people’s mental health and created new barriers for people already suffering from mental illness and substance use disorders.
Therefore this Pandemic affects not only the infected persons but all the World, with repercussions that can persists beyond 2020. 
",.csv
Apartment Rentals merged with Socio-Economics Info,1,apartment-rentals-merged-with-socio-economics-info,rentcrime.csv,MIT,"Original Source:
- Apartment Rental: https://www.kaggle.com/datasets/adithyaawati/apartments-for-rent-classified
- Crime Data: https://www.kaggle.com/datasets/michaelbryantds/crimedata

**Apartment Rent**
```amenities``` -- 'basic' or 'luxury'
```bathrooms``` -- number of bathrooms
```bedrooms``` -- number of bedrooms
```has_photo``` -- photo of apartment
```pets_allowed``` -- True / False
```price``` -- rental price of an apartment
```square_feet``` -- size of the apartment
```cityname``` -- where the apartment is located
```state``` -- where the apartment is located
```latitude``` -- where the apartment is located
```longitude``` -- where the apartment is located
```source``` -- origin web of sourced data
```time``` -- data was sourced, originally in Unix format

**Crime**
```population``` -- Mean Population of the area
```racepctblack, racePctWhite, racePctAsian, racePctHisp ```-- Social background percentage of the area
```medIncome, medFamInc ```-- Median income, Median income of total family
```murdPerPop, rapesPerPop, robbbPerPop, assaultPerPop, burglPerPop, larcPerPop, autoTheftPerPop, arsonsPerPop, ViolentCrimesPerPop, nonViolPerPop```-- Average number of each type of crimes 
```avg_crime```",.csv
App store dataset,1,app-store-dataset,AppleStore.csv,ODC Public Domain Dedication and Licence (PDDL),"The data is about the applications available on the App Store, with their current version, the rating they received, price and genre of application and number of supported devices of each application",.csv
Apple (AAPL) Historical Stock Data,1,apple-aapl-historical-stock-data,HistoricalQuotes.csv,CC0-1.0,"This dataset contains Apple's (AAPL) stock data for the last 10 years (from 2010 to date). I believe insights from this data can be used to build useful price forecasting algorithms to aid investment. I would like to thank [Nasdaq](https://www.nasdaq.com/market-activity/stocks/aapl/historical) for providing access to this rich dataset. I will make sure I update this dataset every few months.
",.csv
Apple Quality Analysis Dataset,1,apple-quality-analysis-dataset,apple_quality.csv,Apache 2.0,"**Description:**
This dataset contains information about various attributes of a set of fruits, providing insights into their characteristics. The dataset includes details such as fruit ID, size, weight, sweetness, crunchiness, juiciness, ripeness, acidity, and quality.

**Key Features:**
**A_id:** Unique identifier for each fruit
**Size:** Size of the fruit
**Weight:** Weight of the fruit
**Sweetness:** Degree of sweetness of the fruit
**Crunchiness:** Texture indicating the crunchiness of the fruit
**Juiciness:** Level of juiciness of the fruit
**Ripeness:** Stage of ripeness of the fruit
**Acidity:** Acidity level of the fruit
**Quality:** Overall quality of the fruit
**Potential Use Cases:**
**Fruit Classification:** Develop a classification model to categorize fruits based on their features.
**Quality Prediction:** Build a model to predict the quality rating of fruits using various attributes.",.csv
Apple Stock Market Historical Data (1980-2024),1,apple-stock-market-historical-data-1980-2024,AAPL(80-24) Final.csv,CC0-1.0,"This dataset contains daily historical market data for Apple Inc. (AAPL) spanning from December 1980 to March 2024. It includes information such as opening and closing prices, high and low prices, trading volume, and percentage change.",.csv
Apple Stock Price from  1980-2021,1,apple-stock-price-from-19802021,AAPL.csv,ODbL-1.0,"### Context
This is a Dataset  for Stock Prediction on Apple Inc. 
This dataset start from 1980 to 2021 . It was collected from Yahoo Finance.  
You can perform Time Series Analysis and EDA on data.
",.csv
Apple iPhone Data,1,apple-iphone-data,apple_products.csv,CC0-1.0,The apple iPhones data is a CSV file containing the product attributes of iPhones sold in India.,.csv
Appliances Energy Prediction,1,appliances-energy-prediction,KAG_energydata_complete.csv,other,"### Context

 Experimental data used to create regression models of appliances energy use in a low energy building.


### Content

The data set is at 10 min for about 4.5 months. The house temperature and humidity conditions were monitored with a ZigBee wireless sensor network. Each wireless node transmitted the temperature and humidity conditions around 3.3 min. Then, the wireless data was averaged for 10 minutes periods. The energy data was logged every 10 minutes with m-bus energy meters. Weather from the nearest airport weather station (Chievres Airport, Belgium) was downloaded from a public data set from Reliable Prognosis (rp5.ru), and merged together with the experimental data sets using the date and time column. Two random variables have been included in the data set for testing the regression models and to filter out non predictive attributes (parameters). 

### Acknowledgements
Luis Candanedo, luismiguel.candanedoibarra '@' umons.ac.be, University of Mons (UMONS)

Luis M. Candanedo, Veronique Feldheim, Dominique Deramaix, Data driven prediction models of energy use of appliances in a low-energy house, Energy and Buildings, Volume 140, 1 April 2017, Pages 81-97, ISSN 0378-7788, [Web Link].


### Inspiration

Data used include measurements of temperature and humidity sensors from a wireless network, weather from a nearby airport station and recorded energy use of lighting fixtures. data filtering to remove non-predictive parameters and feature ranking plays an important role with this data. Different statistical models could be developed over this dataset. 
Highlights:
The appliances energy consumption prediction in a low energy house is the dataset content
Weather data from a nearby station was found to improve the prediction.

Pressure, air temperature and wind speed are important parameters in the prediction.

Data from a WSN that measures temperature and humidity increase the pred. accuracy.

From the WSN, the kitchen, laundry and living room data ranked high in importance.",.csv
Applicant Details For Loan Approve,1,applicant-details-for-loan-approve,Applicant-details.csv,MIT,"This dataset provides insights into various attributes of loan applicants in India, essential for assessing their eligibility for loan approval.

Here's a brief explanation of each column:

1. **Applicant_ID:** Unique identifier for each loan applicant.
2. **Annual_Income:** Annual income of the loan applicant.
3. **Applicant_Age:** Age of the loan applicant.
4. **Work_Experience:** Number of years of work experience of the loan applicant.
5. **Marital_Status:** Marital status of the loan applicant.
6. **House_Ownership:** Ownership status of the applicant's residence.
7. **Vehicle_Ownership(car):** Ownership status of the applicant's vehicle.
8. **Occupation:** Profession or occupation of the loan applicant.
9. **Residence_City:** City where the loan applicant resides.
10. **Residence_State:** State where the loan applicant resides.
11. **Years_in_Current_Employment:** Number of years the applicant has been in their current job.
12. **Years_in_Current_Residence:** Number of years the applicant has been residing in their current residence.
13. **Loan_Default_Risk:** Indicator of loan default risk, with values indicating whether the loan applicant is at risk of defaulting on the loan.",.csv
Armenian Pub Survey,1,pubs,armenian_pubs.csv,other,"The dataset collected from an online survey questionnaire includes behavioral, psychographic, geographic and demographic information about Armenian pubs.

The data has been intended for an independent project organized by the students of the American University of Armenia solely for educational purposes.

This data is unique as the pubs sector in Armenia has not been reasearched so far.",.csv
Artificial Intelligence Tools 2023,1,ai-5000-tools-2023,all_ai_tool.csv,CC0-1.0,"**Dataset Description:**
The ""5000 AI Tools Dataset"" is a comprehensive collection of artificial intelligence (AI) tools curated to assist data enthusiasts, researchers, and professionals in the field of machine learning and data science. This dataset contains valuable information about a wide range of AI tools, including their names, descriptions, pricing models, recommended use cases, charges (if applicable), user reviews, tool links, and major categories.

**Data Fields:**
1. **AI Tool Name:** The name of the AI tool or software.
2. **Description:** A brief description of the tool's features and capabilities.
3. **Free/Paid/Other:** Indicates whether the tool is available for free, has a paid subscription model, or falls under another pricing category.
4. **Useable For:** Describes the primary use cases or applications for which the AI tool is suitable.
5. **Charges:** Specifies the cost or pricing structure associated with the tool (if applicable).
6. **Review:** User-generated reviews and ratings to provide insights into the tool's performance and user satisfaction.
7. **Tool Link:** URL or link to access the AI tool's official website or download page.
8. **Major Category:** Categorizes the AI tools into broader domains or categories, such as natural language processing (NLP), computer vision, data analytics, and more.

**Use Cases:**
- Research and Analysis: Researchers can explore the dataset to discover AI tools relevant to their study areas.
- Tool Comparison: Data professionals can use this dataset to compare and choose the most suitable AI tools for their projects.
- Market Analysis: Data-driven insights can be derived to analyze the popularity and pricing trends of AI tools.
- Recommendations: Machine learning models can be trained to recommend AI tools based on specific requirements.

**Data Source:**
The dataset is compiled from a variety of sources, including official tool websites, user reviews, and reputable AI tool directories.

**Licensing:**
The dataset is made available under an open data license for research and educational purposes.

**Disclaimer:**
While efforts have been made to ensure the accuracy of the information in this dataset, users are encouraged to verify details and refer to official tool websites for the most up-to-date information and licensing terms.

**Acknowledgment:**
We acknowledge and appreciate the contributions of the AI community, tool developers, and users in creating and maintaining this valuable resource.
",.csv
Asia GDP,1,asia-gdp,asia_gdp.csv,MIT,"Datasets related to Asia's GDP (Gross Domestic Product) typically contain a wealth of information regarding the economic performance and trends of countries across the Asian continent. These datasets encompass various indicators such as GDP growth rates, GDP per capita, sectoral contributions to GDP (such as agriculture, industry, and services), inflation rates, trade balances, and other economic metrics.

Researchers, economists, policymakers, and businesses utilize Asia GDP datasets to analyze economic trends, assess regional and country-specific economic performance, identify growth opportunities, and inform policy decisions. By examining historical GDP data and forecasting future trends, stakeholders can gain valuable insights into the drivers of economic growth, structural changes in economies, and potential risks and opportunities for investment and development.

Moreover, Asia GDP datasets play a crucial role in comparative economic analysis, allowing researchers to benchmark the economic performance of Asian countries against each other and against global standards. These datasets facilitate cross-country studies on topics such as economic development, income inequality, poverty alleviation, and the impact of globalization on regional economies.

Additionally, Asia GDP datasets are essential for monitoring progress towards achieving sustainable development goals, promoting inclusive growth, and fostering economic resilience in the face of global challenges such as climate change, geopolitical tensions, and pandemics.

Overall, Asia GDP datasets serve as fundamental resources for understanding the economic landscape of the region, informing evidence-based policymaking, and driving sustainable and inclusive economic development across Asia.",.csv
Asteroids Dataset,1,asteroids-dataset,Asteroids.csv,CC0-1.0,"This dataset is a collection of data on asteroids and near-earth objects that came close to Earth's axis. The columns of this dataset are explained below:

**Object:** This refers to the asteroid being observed or studied.

**Close-Approach (CA) Date (TDB):** This indicates the date and time of the closest approach of the asteroid to Earth. TDB stands for Barycentric Dynamical Time, which is a time standard based on the position of the solar system's barycenter.

**YYYY-mmm-DD HH:MM ± D_HH:MM:** This is the format in which the close approach date and time are represented. YYYY indicates the year, mmm indicates the month (in three-letter abbreviation), DD indicates the day, HH indicates the hour (in 24-hour format), MM indicates the minute, and D_HH:MM represents the uncertainty in hours and minutes.

**CA Distance Nominal (LD/AU):** This is the nominal or average distance between the asteroid and Earth during the close approach. It is usually expressed in Lunar Distances (LD) or Astronomical Units (AU), where 1 LD is the average distance between the Earth and the Moon, and 1 AU is the average distance between the Earth and the Sun.

**CA Distance Minimum (LD/AU):** This represents the minimum distance between the asteroid and Earth during the close approach. It provides a measure of how close the asteroid will come to Earth at its closest point.

**Vrelative (km/s):** This is the relative velocity between the asteroid and Earth at the time of close approach. It indicates how fast the asteroid is moving with respect to Earth.

**Vinfinity (km/s):** This is the velocity of the asteroid relative to Earth at infinity, i.e., the relative velocity if the asteroid were infinitely far away from Earth. It is useful for understanding the asteroid's trajectory and potential impact dynamics.

**Nsigma:** This refers to the statistical significance of the observation. It is often used to indicate the certainty level of the data.

**H (mag):** This is the absolute magnitude of the asteroid. It provides information about the asteroid's intrinsic brightness, which is independent of its distance from Earth.

**Ref:** This typically refers to the reference or source of the data, such as the scientific publication or observatory responsible for observing and documenting the asteroid.

**Class:** This indicates the classification of the asteroid, often based on its orbital characteristics, composition, or other properties.",.csv
Astronomical Data,1,astronomical-data,cleaned_star_data.csv,Apache 2.0,"Within this meticulously compiled astronomical dataset, each column unravels a distinct facet of celestial phenomena, providing an exhaustive exploration of key parameters essential for unraveling the cosmic mysteries. The temperature column immerses us in the thermal intricacies of stars, unveiling the nuanced variations in their heat emissions. Luminosity, a cornerstone of celestial understanding, discloses the radiant energy output, enabling a profound comprehension of a star's brilliance within the vast cosmic tapestry. The radius column serves as a cosmic ruler, delineating the spatial dimensions of these celestial entities, offering a profound grasp of their structural characteristics.

Absolute magnitude, a standardized measure of brightness, facilitates comparative analyses, shedding light on the intrinsic luminosity of diverse celestial bodies. The star type column categorizes these celestial actors, providing a systematic taxonomy crucial for discerning their roles within the cosmic narrative. Simultaneously, the spectral class and color columns paint a vivid portrait of the visual signatures of these stellar entities, offering nuanced insights into their chemical composition, temperature, and evolutionary stages.

This comprehensive data compilation is an invaluable resource, not merely for researchers and astronomers but also for enthusiasts seeking a deeper and more nuanced understanding of the cosmos. It serves as a reservoir of knowledge, fostering a symbiotic relationship between scientific inquiry and the innate human curiosity that propels us ever further into the boundless expanse of the universe.






",.csv
Atmospheric CO2,1,atmospheric-co2,co2.csv,other,"The example in Cleveland, Cleveland, McRae, and Terpenning (1990) uses CO2 data, which is in the list below. This monthly data (January 1959 to December 1987) has a clear trend and seasonality across the sample.
Sourse data https://www.statsmodels.org/dev/examples/notebooks/generated/stl_decomposition.html
Sourse image https://safety4sea.com/what-eu-mrv-plan-requires/
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F13954148%2Ffdce0afe6e352870ec1e96e5e1568cb0%2FDepositphotos_5927198_L.jpg?generation=1686298611136391&alt=media)
",.csv
Auction Verification Dataset,1,auction-verification-dataset,data.csv,Attribution 4.0 International (CC BY 4.0),"We modeled a simultaneous multi-round auction with BPMN models, transformed the latter to Petri nets, and used a model checker to verify whether certain outcomes of the auction are possible or not.

**Dataset Characteristics:** Tabular

**Subject Area:** Computer Science

**Associated Tasks:** Classification, Regression

**Instances:** 2043

**Features:** 7

# Dataset Information

**For what purpose was the dataset created?**
The dataset was created as part of a scientific study. The goal was to find out whether one could replace costly verification of complex process models (here: simultaneous multi-round auctions, as used for auctioning frequency spectra) with predictions of the outcome.

**What do the instances in this dataset represent?**
Each instance represents one verification run. Verification checks whether a particular price is possible for a particular product, and (for only some of the instances) whether a particular bidder might win the product to that price.

**Additional Information**
Our code to prepare the dataset and to make predictions is available here: https://github.com/Jakob-Bach/Analyzing-Auction-Verification

**Has Missing Values?**
No

# Introductory Paper

**Title:** Analyzing and Predicting Verification of Data-Aware Process Models – a Case Study with Spectrum Auctions

**Authors:**  Elaheh Ordoni, Jakob Bach, Ann-Katrin Fleck. 2022

**Journal:** Published in Journal

**[Link of Article](https://ieeexplore.ieee.org/document/9721192/)**

# Abstract of Introductory Paper

Verification techniques play an essential role in detecting undesirable behaviors in many applications like spectrum auctions. By verifying an auction design, one can detect the least favorable outcomes, e.g., the lowest revenue of an auctioneer. However, verification may be infeasible in practice, given the vast size of the state space on the one hand and the large number of properties to be verified on the other hand. To overcome this challenge, we leverage machine-learning techniques. In particular, we create a dataset by verifying properties of a spectrum auction first. Second, we use this dataset to analyze and predict outcomes of the auction and characteristics of the verification procedure. To evaluate the usefulness of machine learning in the given scenario, we consider prediction quality and feature importance. In our experiments, we observe that prediction models can capture relationships in our dataset well, though one needs to be careful to obtain a representative and sufficiently large training dataset. While the focus of this article is on a specific verification scenario, our analysis approach is general and can be adapted to other domains.


#Cite

**Citation:**`Ordoni,Elaheh, Bach,Jakob, Fleck,Ann-Katrin, and Bach,Jakob. (2022). Auction Verification. UCI Machine Learning Repository. https://doi.org/10.24432/C52K6N.`

**BibTeX:**`@misc{misc_auction_verification_713,
  author       = {Ordoni,Elaheh, Bach,Jakob, Fleck,Ann-Katrin, and Bach,Jakob},
  title        = {{Auction Verification}},
  year         = {2022},
  howpublished = {UCI Machine Learning Repository},
  note         = {{DOI}: https://doi.org/10.24432/C52K6N}
}`

# Import in Python 

`pip install ucimlrepo`

`from ucimlrepo import fetch_ucirepo 
  
# fetch dataset 
auction_verification = fetch_ucirepo(id=713) 
  
# data (as pandas dataframes) 
X = auction_verification.data.features 
y = auction_verification.data.targets 
  
# metadata 
print(auction_verification.metadata) 
  
# variable information 
print(auction_verification.variables) 
`


",.csv
Audi A1 listings,1,audi-a1-listings,Audi_A1_listings.csv,CC0-1.0,"Listings in the UK for Audi A1 cars on the popular website https://www.autotrader.co.uk/.

Attributes:

-Year: The year the car was registered
-Type: Type of the vehicle
-Mileage(miles): The mileage of the vehicle
-Engine: Engine size in litres
-PS: Pferdstarke 98.6% of one HP
-Transmission: The vehicles transmission
-Fuel: Fuel type
-Number_of_Owners: number of previous owners of the vehicle
-Price(£): price in pounds sterling
-href: href of that listing 
-PPY: Price Per Year =  (Year Price of car / (10 - Age of the car)) The cost of the car per year if you intended to sell the car when it became 10 years old.
-MileageRank: Where the car ranks in the dataset in order of mileage. Lower mileage yields a higher rank.
-PriceRank: Where the car ranks in the dataset in order of price. Lower price yields a higher rank.
-PPYRank: Where the car ranks in the dataset in order of PPY. Lower price yields a higher rank.
-Score: The sum of MileageRank, PriceRank and PPYRank.",.csv
Austin Airbnb Dataset,1,austin-airbnb-dataset,listings (1).csv,other,"The goal of this competition is to predict Airbnb bookings in real-time. You'll develop a model trained on one of the largest open datasets of hotel bookings.
Your work will help advance research into knowledge-tracing methods for game-based learning. You'll be supporting Airbnb sales team to create more effective booking experiences for customers.
**id** :Airbnb's unique identifier for the listing
**name**: name of the customer.
**host_id**: unique id of the host.
**host_name**: name of the host.
**neighbourhood**: neighbourhood of the property.
**latitude & longitude** :Uses the World Geodetic System (WGS84) projection for latitude and longitude.
**room_type**: the type of room the customer booked for the particular stay.
**price**: the price of the booking



",.csv
Austin Weather,1,austin-weather,austin_weather.csv,GPL-2.0,"### Context
This dataset is meant to complement the [Austin Bikesharing Dataset](https://www.kaggle.com/jboysen/austin-bike).

### Content
Contains the:  
**Date** (YYYY-MM-DD)  
**TempHighF** (High temperature, in Fahrenheit)  
**TempAvgF** (Average temperature, in Fahrenheit)  
**TempLowF** (Low temperature, in Fahrenheit)  
**DewPointHighF** (High dew point, in Fahrenheit)  
**DewPointAvgF** (Average dew point, in Fahrenheit)  
**DewPointLowF** (Low dew point, in Fahrenheit)  
**HumidityHighPercent** (High humidity, as a percentage)  
**HumidityAvgPercent** (Average humidity, as a percentage)  
**HumidityLowPercent** (Low humidity, as a percentage)  
**SeaLevelPressureHighInches** (High sea level pressure, in inches)  
**SeaLevelPressureAvgInches** (Average sea level pressure, in inches)  
**SeaLevelPressureLowInches** (Low sea level pressure, in inches)  
**VisibilityHighMiles** (High visibility, in miles)  
**VisibilityAvgMiles** (Average visibility, in miles)  
**VisibilityLowMiles** (Low visibility, in miles)  
**WindHighMPH** (High wind speed, in miles per hour)  
**WindAvgMPH** (Average wind speed, in miles per hour)  
**WindGustMPH** (Highest wind speed gust, in miles per hour)  
**PrecipitationSumInches** (Total precipitation, in inches)  ('T' if Trace)  
**Events** (Adverse weather events.  ' ' if None)  

This dataset contains data for every date from 2013-12-21 to 2017-07-31.

### Acknowledgements
This dataset was obtained from WeatherUnderground.com, at the [Austin KATT station](https://www.wunderground.com/history/airport/KATT/).

### Inspiration
Can we use this dataset to explain some of the variation in the [Austin Bikesharing Dataset](https://www.kaggle.com/jboysen/austin-bike)?",.csv
Australia Domestic Flight Fares (as of March 2024),1,australia-domestic-flight-fares-as-of-2024,aus_domestic_air_fare.csv,other,"This dataset was extracted from Australia's Bureau of Infrastructure and Transport Research Economics (BITRE), and covers January 2021 to March 2024. It includes the cheapest return fares for top routes, with departures on the last Thursday of each month and returns two weeks later. Data was gathered from airline websites three weeks before departure.

License: Creative Commons Attribution 2.5 Australia.",.csv
Australian Vehicle Prices,1,australian-vehicle-prices,Australian Vehicle Prices.csv,other,"# Description:

&gt;This dataset contains the latest information on car prices in Australia for the year **2023**. It covers various brands, models, types, and features of cars sold in the Australian market. It provides useful insights into the trends and factors influencing the car prices in Australia. The dataset includes information such as **brand, year, model, car/suv, title, used/new, transmission, engine, drive type, fuel type, fuel consumption, kilometres, colour (exterior/interior), location, cylinders in engine, body type, doors, seats, and price.** The dataset has **over 16,000 records** of car listings from various online platforms in Australia.

# Key Features:

&gt;- **Brand:** *Name of the car manufacturer*
- **Year:** *Year of manufacture or release*
- **Model:** *Name or code of the car model*
- **Car/Suv:** *Type of the car (car or suv)*
- **Title:** *Title or description of the car*
- **UsedOrNew:** *Condition of the car (used or new)*
- **Transmission:** *Type of transmission (manual or automatic)*
- **Engine:** *Engine capacity or power (in litres or kilowatts)*
- **DriveType:** *Type of drive (front-wheel, rear-wheel, or all-wheel)*
- **FuelType:** *Type of fuel (petrol, diesel, hybrid, or electric)*
- **FuelConsumption:** *Fuel consumption rate (in litres per 100 km)*
- **Kilometres:** *Distance travelled by the car (in kilometres)*
- **ColourExtInt:** *Colour of the car (exterior and interior)*
- **Location:** *Location of the car (city and state)*
- **CylindersinEngine:** *Number of cylinders in the engine*
- **BodyType:** *Shape or style of the car body (sedan, hatchback, coupe, etc.)*
- **Doors:** *Number of doors in the car*
- **Seats:** *Number of seats in the car*
- **Price:** *Price of the car (in Australian dollars)*


# Potential Use Cases:
&gt; - **Price prediction:** Predict the price of a car based on its features and location using machine learning models.
- **Market analysis:** Explore the market trends and demand for different types of cars in Australia using descriptive statistics and visualization techniques.
- **Feature analysis:** Identify the most important features that affect the car prices and how they vary across different brands, models, and locations using correlation and regression analysis.

If you find this dataset useful, your support through an upvote would be greatly appreciated ❤️🙂 <br>
Thank you
",.csv
Autism Screening on Adults,1,autism-screening-on-adults,autism_screening.csv,other,"# Abstract
&gt; Improve Autism Screening by creating predicting the likelihood of having this condition.

# About this dataset
&gt; ### What is Autism
Autism, or autism spectrum disorder (ASD), refers to a broad range of conditions characterized by challenges with social skills, repetitive behaviors, speech and nonverbal communication.

&gt; ### Causes and Challenges
It is mostly influenced by a combination of genetic and environmental factors. Because autism is a spectrum disorder, each person with autism has a distinct set of strengths and challenges. The ways in which people with autism learn, think and problem-solve can range from highly skilled to severely challenged.
Research has made clear that high quality early intervention can improve learning, communication and social skills, as well as underlying brain development. Yet the diagnostic process can take [several years](https://theconversation.com/how-long-does-it-take-to-get-an-autism-diagnosis-41049).

&gt; ### The Role of Machine Learning
This dataset is composed of survey results for more than **700** people who filled an app form. There are labels portraying whether the person received a diagnosis of autism, allowing machine learning models to predict the likelihood of having autism, therefore allowing healthcare professionals prioritize their resources. 

# How to use
&gt; - Predict the likelihood of a person having autism using survey and demographic variables.
- Explore Autism across Gender, Age, and other variables


# Acknowledgements
If you this dataset in your research, please credit the authors.

&gt; ### Citations
- Tabtah, F. (2017). Autism Spectrum Disorder Screening: Machine Learning Adaptation and DSM-5 Fulfillment. Proceedings of the 1st International Conference on Medical and Health Informatics 2017, pp.1-6. Taichung City, Taiwan, ACM.
- Thabtah, F. (2017). Machine Learning in Autistic Spectrum Disorder Behavioural Research: A Review. To Appear in Informatics for Health and Social Care Journal. December, 2017

&gt; ### License
Public Domain

&gt; ### Splash banner
Photo by [Nathan Anderson](https://unsplash.com/@nathananderson) on [Unsplash](https://unsplash.com/photos/FHiJWoBodrs)

&gt; ### Splash icon
Icons made by [Smashicons](https://www.flaticon.com/authors/smashicons) from [www.flaticon.com](https://www.flaticon.com/).

# [More Information about Autism](https://www.autismspeaks.org/what-autism)

# [More Datasets](https://www.kaggle.com/andrewmvd/datasets)",.csv
Automobile Sales data,1,auto-sales-data,Auto Sales data.csv,other,"The dataset contains Sales data of an Automobile company. 
 

&gt;**Do explore pinned 📌 notebook under code section for quick EDA📊 reference**

&gt;_Consider an upvote ^ if you find the dataset useful_


**Data Description**

| Column Name             | Description                                                                                                      |
|-------------------------|------------------------------------------------------------------------------------------------------------------|
| ORDERNUMBER             | This column represents the unique identification number assigned to each order.                                 |
| QUANTITYORDERED         | It indicates the number of items ordered in each order.                                                            |
| PRICEEACH               | This column specifies the price of each item in the order.                                                         |
| ORDERLINENUMBER         | It represents the line number of each item within an order.                                                         |
| SALES                   | This column denotes the total sales amount for each order, which is calculated by multiplying the quantity ordered by the price of each item. |
| ORDERDATE               | It denotes the date on which the order was placed.                                                                 |
| DAYS_SINCE_LASTORDER    | This column represents the number of days that have passed since the last order for each customer. It can be used to analyze customer purchasing patterns. |
| STATUS                  | It indicates the status of the order, such as ""Shipped,"" ""In Process,""  ""Cancelled,"" ""Disputed,"" ""On Hold,"" or ""Resolved."" |
| PRODUCTLINE             | This column specifies the product line categories to which each item belongs.                                    |
| MSRP                    | It stands for Manufacturer's Suggested Retail Price and represents the suggested selling price for each item.      |
| PRODUCTCODE             | This column represents the unique code assigned to each product.                                                   |
| CUSTOMERNAME            | It denotes the name of the customer who placed the order.                                                           |
| PHONE                   | This column contains the contact phone number for the customer.                                                    |
| ADDRESSLINE1            | It represents the first line of the customer's address.                                                            |
| CITY                    | This column specifies the city where the customer is located.                                                      |
| POSTALCODE              | It denotes the postal code or ZIP code associated with the customer's address.                                     |
| COUNTRY                 | This column indicates the country where the customer is located.                                                    |
| CONTACTLASTNAME         | It represents the last name of the contact person associated with the customer.                                    |
| CONTACTFIRSTNAME        | This column denotes the first name of the contact person associated with the customer.                               |
| DEALSIZE                | It indicates the size of the deal or order, which are the categories ""Small,"" ""Medium,"" or ""Large.""                  |


",.csv
Automotive Vehicles Engine Health Dataset,1,automotive-vehicles-engine-health-dataset,engine_data.csv,CC0-1.0,"The dataset could include various features and measurements related to the engine health of vehicles, such as engine RPM, temperature, pressure, and other sensor data. It may also include metadata on the vehicle, such as make, model, year, and mileage.

One potential project using this dataset could be to build a predictive maintenance model for automotive engines. By analyzing the patterns and trends in the data, machine learning algorithms could be trained to predict when an engine is likely to require maintenance or repair. This could help vehicle owners and mechanics proactively address potential issues before they become more severe, leading to better vehicle performance and longer engine lifetimes.

Another potential use for this dataset could be to analyze the performance of different types of engines and vehicles. Researchers could use the data to compare the performance of engines from different manufacturers, for example, or to evaluate the effectiveness of different maintenance strategies. This could help drive innovation and improvements in the automotive industry.",.csv
Average Time Spent By A User On Social Media,1,average-time-spent-by-a-user-on-social-media,dummy_data.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"This is dummy data, that I have generated by using the 'NumPy' Library of Python. This data shows how much a user spends time on their devices using Social Media. 

I generated this data to train an AI model for myself for practice purposes only. 


The description for each column is as follows: 

- **age:** The age of the user.
- **gender:** The gender identity of the user (Male, Female, Non-binary).
- **demographics:** The type of area the user resides in (Urban, Suburban, Rural).
- **interests:** The user's primary area of interest or hobby.
- **device_type:** The type of device used by the user (Mobile).
- **location:**The country of residence for the user.
- **platform:** The social media platform where the user spends time.
- **profession:** The user's occupation or professional status.
- **income:** The yearly income of the user.
- **indebt:** Indicates whether the user is in debt (True or False).
- **homeowner:** Indicates whether the user owns a home (True or False).
- **owns_cars:** Indicates whether the user owns cars (True or False).
",.csv
Average temperature anomaly,1,average-temperature-anomaly,temperature-anomaly.csv,CC-BY-SA-4.0,"Human greenhouse gas emissions have increased global average temperatures
Human emissions of carbon dioxide and other greenhouse gases are the primary drivers of the global rise in temperatures.1 This link between global temperatures and greenhouse gas concentrations – especially CO2 – has been true throughout Earth’s history.2

In the chart, we see the global average temperature relative to a baseline, which is the average between 1961 and 1990. Average temperatures have risen by over 0.8°C since then.

You can also see that temperatures in 1850 were around 0.4°C cooler than the baseline, giving us a total temperature rise of about 1.2°C compared to pre-industrial times.

This warming has not been equally distributed across the world. The Northern Hemisphere has warmed more than the Southern Hemisphere. And warming has been especially strong at the poles. In some regions, temperatures have risen by more than 5°C. You can see this distribution in maps published by Berkeley Earth.

Human emissions have been the main driver of this change. Aerosols have played a slight cooling role in global climate, and natural variability has played a minor role. This article from Carbon Brief explains this very well, with interactive graphics showing the relative contributions of different factors on the climate.

**Citation:**
Met Office Hadley Centre (2023) – processed by Our World in Data. “Lower” [dataset]. Met Office Hadley Centre, “HadCRUT5 HadCRUT.5.0.2.0” [original data].
",.csv
Aviator,1,aviator,aviator_payouts.csv,MIT,"- The dataset contains aviator payouts (a popular online casino game) of 4 betting companies in Kenya: Betika, Betgr8, Winpesa, and Odibets.
- You may find quite a few duplicate payouts, (that is) where the created_at timestamp is the same(the payouts happened in the same second) for 5 or more payouts. This was due to a server bug that was later fixed.
- It is not a bug if less than 5 payouts have the same second.
- Columns in the dataset are created_at, app, and payout.",.csv
Avocado Prices,1,avocado-prices,avocado.csv,ODbL-1.0,"### Context

It is a well known fact that Millenials LOVE Avocado Toast. It's also a well known fact that all Millenials live in their parents basements.

Clearly, they aren't buying home because they are buying too much Avocado Toast!

But maybe there's hope... if a Millenial could find a city with cheap avocados, they could live out the Millenial American Dream.

### Content

This data was downloaded from the Hass Avocado Board website in May of 2018 & compiled into a single CSV. Here's how the [Hass Avocado Board describes the data on their website][1]:

&gt; The table below represents weekly 2018 retail scan data for National retail volume (units) and price. Retail scan data comes directly from retailers’ cash registers based on actual retail sales of Hass avocados. Starting in 2013, the table below reflects an expanded, multi-outlet retail data set. Multi-outlet reporting includes an aggregation of the following channels: grocery, mass, club, drug, dollar and military. The Average Price (of avocados) in the table reflects a per unit (per avocado) cost, even when multiple units (avocados) are sold in bags. The Product Lookup codes (PLU’s) in the table are only for Hass avocados. Other varieties of avocados (e.g. greenskins) are not included in this table.

Some relevant columns in the dataset:

- `Date` - The date of the observation
- `AveragePrice` - the average price of a single avocado
- `type` - conventional or organic
- `year` - the year
- `Region` - the city or region of the observation
- `Total Volume` - Total number of avocados sold
- `4046` - Total number of avocados with PLU 4046 sold
- `4225` - Total number of avocados with PLU 4225 sold
- `4770` - Total number of avocados with PLU 4770 sold

### Acknowledgements

Many thanks to the Hass Avocado Board for sharing this data!!

http://www.hassavocadoboard.com/retail/volume-and-price-data

### Inspiration

In which cities can millenials have their avocado toast AND buy a home?

Was the Avocadopocalypse of 2017 real?


  [1]: http://www.hassavocadoboard.com/retail/volume-and-price-data",.csv
Avocado Prices (2020),1,avocado-prices-2020,avocado-updated-2020.csv,ODbL-1.0,"### UPD

Updated on Feb 26, 2021 with the latest HAB data for 2020 (up to 2020-11-29). Newer data, incl. for 2021, have not yet been published by the HAB.


### Context

This is an updated version of the [avocado dataset][avocado_dataset] originally compiled from the [Hass Avocado Board][HAB] (or HAB, for short) data and published on Kaggle by [Justin Kiggins][justin_kaggle] in 2018. The dataset features historical data on avocado prices and sales volume in multiple cities, states, and regions of the USA. 


### Content

This updated version contains data from 4 January 2015 up to 17 May 2020, whereas the original dataset uploaded by Justin provides data only for the time span from 2015 to the beginning of 2018. The updated dataset was created by downloading the data for years 2018 to 2020 from the Hass Avocado Board website in August 2020, preprocessing it and merging it with Justin's dataset. 

The new data was downloaded from [this][download_data_page] page of the HAB's website which allows downloading the data for years 2017 -- 2020 (as of August 2020). To download some new data, scroll down to the bottom of the section ""Totals by PLU"" and click the ""Download 20XX Weekly Retail Volume & Price Report"" button (the ""XX"" are the two last digits of the year you are downloading the data for).


### Notebooks for creating and updating this dataset

This dataset was created using [this][notebook1] Colab notebook. If you want to add even more fresh data to this dataset, you can download the new data from the HAB's website and add it to this dataset using [this][notebook2] Colab notebook.


### Difference from the original dataset

Please note that, besides containing more data, this dataset differs from the original one in the following points:

1. All column names were converted to ""snake_case"" for more consistency in naming and to provide access to column values using a period, e.g., `df.average_price`. 

2. The column `region` was renamed to `geography` (as it is called in the HAB's data) to avoid the confusion between actual regions (e.g., `West`, `Midsouth`, etc.), cities (e.g., `San Francisco`, `Atlanta`, etc.), states (e.g., `California`, `South Carolina`, etc.), and other geographical names of the US. 

3. For the data to be merged, the geographical names in the `region` column of the original dataset had to match the corresponding geographical names of the new HAB's data. For the sake of readability and clarity, the original HAB's naming style of geographical names was chosen. For that reason, some of the geographical names in the `region` column of the original dataset were renamed, for instance, `BaltimoreWashington` was renamed to `Baltimore/Washington`, `DallasFtWorth` was renamed to `Dallas/Ft. Worth`, `TotalUS` was renamed to `Total U.S.`, and so on.

4. The data is already sorted by date and geographical names. 


### Description of columns

Please refer to the [main page][avocado_dataset] of the original dataset.


### A note on the data

Please note that, according to [this][total_us_info] page, the Total U.S. data is somewhat aggregated for the following 8 geographical areas of the US: California, Great Lakes, Midsouth, Northeast, Plains, Southeast, South Central, and West. However, averaging data for these regions and areas does not result in the entries equal to those of the Total U.S. data, so be careful with that.


### Acknowledgements

Huge thanks to [Justin Kiggins][justin_kaggle] for the original dataset and to [Hass Avocado Board][HAB] for making the data publicly available!


[avocado_dataset]: https://www.kaggle.com/neuromusic/avocado-prices
[HAB]: https://hassavocadoboard.com
[justin_kaggle]: https://www.kaggle.com/neuromusic
[download_data_page]: https://hassavocadoboard.com/category-data/
[total_us_info]: https://hassavocadoboard.com/report/total-us/

[notebook1]: https://colab.research.google.com/drive/1sXvsP4GgVx_sNsgG882a35OKqOdaam8f?usp=sharing
[notebook2]: https://colab.research.google.com/drive/1UaAqXCY8LJOY3SYmDG6VjZf5YSkwkPRS?usp=sharing",.csv
BBC Full Text Document Classification,1,bbc-full-text-document-classification,bbc_data.csv,MIT,this is the csv and clean version of this dataset [link_to_the_original_Data](https://www.kaggle.com/datasets/shivamkushwaha/bbc-full-text-document-classification). You can use this data to train your NLP skills.,.csv
BBC News,1,bbc-news,bbc_news.csv,CC0-1.0,"### Context

Self updating dataset. It collects RSS Feeds from BBC News using a Kernel: https://www.kaggle.com/gpreda/bbc-news-rss-feeds. 
The Kernel is run with a fixed frequency and the dataset is updated using the output of the Notebook.

 
### Content

BBC News RSS Feeds. The data contains the following columns:
- title  
- pubDate  
- guid  
- link  
- description  

### Collection method

Uses requests_html and BeautifulSoup to collect RSS Feeds from BBC News site.

### Acknowledgements

The content is proprietary of BBC

### Inspiration

Use the data to analyze the sentiment of news, from title and description",.csv
BMI Dataset,1,bmidataset,bmi.csv,CC0-1.0,"![](https://raw.githubusercontent.com/Masterx-AI/Project_BMI_Assessment__/main/BMI.jpg)

### Description:

A simple yet challenging project, to estimate the BMI based on the Gender, Height & Weight.
The complexity arises due the fact that dataset has less samples, & is highly imbalanced.
Can you overcome these obstacles & build a good predictive model to classify them?

**This data frame contains the following columns:**

* Gender : Male / Female

* Height : Number (cm)

* Weight : Number (Kg)

* Index :
0 - Extremely Weak
1 - Weak
2 - Normal
3 - Overweight
4 - Obesity
5 - Extreme Obesity

**Source:**

Kaggle - 
https://www.kaggle.com/yersever/500-person-gender-height-weight-bodymassindex

### Objective:
- Understand the Dataset & cleanup (if required).
- Build classification models to predict the various categories of BMI.
- Compare the evaluation metrics of vaious classification algorithms.",.csv
BMW Pricing Challenge,1,bmw-pricing-challenge,bmw_pricing_challenge.csv,CC0-1.0,"### Context

Estimating the value of a used car is one of the main everyday challenges in automotive business. We believe that the sales price of a car is not only based on the value of the product itself, but is also heavily influenced by things like market trends, current availability and politics.
With this challenge we hope to raise some interest in this exciting topic and also gain some insight in what the main factors are that drive the value of a used car.

### Content

The data provided consists of almost 5000 real BMW cars that were sold via a b2b auction in 2018. The price shown in the table is the highest bid that was reached during the auction.

We have already done some data cleanup and filtered out cars with engine damage etc. However there may still be minor damages like scratches, but we do not have more information about that.

We have also extracted 8 criteria based on the equipment of car that we think might have a good impact on the value of a used car. These criteria have been labeled feature_1 to feature_8 and are shown in the data below.

### Inspiration

We would like to find a good statistical model to describe the value of a used car depending on the basic description and the 8 provided features. The following questions are of special interest to us:

1. How much impact does each of features have on the estimate value of the car?

2. How does the estimated value of a car change over time? Can you detect any patterns? (e.g. the price of a convertible should be higher in summer than in winter)

3. How big is the influence of the factors not represented in the data on the price? Or, in other words, what is the estimated variance included in your statistical model?",.csv
BMW used car listing,1,bmw-used-car-listing,bmw.csv,CC0-1.0,"#### Data set contains information of price, transmission, mileage, fuel type, road tax, miles per gallon (mpg), and engine size
##### data description:
model BMW model.
year registraion year.
price price in Euros.
transmission type of gear box.
mileage distance used.
fuelType engine fuel.
tax road tax.
mpg miles per galoon.
engineSize size in litres.

It'd be cool to have some insights and vizualisations of the data. Also, am open to ideas on how to expand the data set.",.csv
BSE top 50 Stocks,1,bse-top-50-stocks,Final-50-stocks.csv,MIT,"Comprehensive collection of time series data for the top 50 stocks listed on the Bombay Stock Exchange (BSE). Here’s a brief description:

Time Series Data: This dataset likely contains chronological data points representing the performance of each stock over a specific period. This could include daily opening, closing, high, and low prices, as well as trading volume.
Top 50 Stocks: The dataset focuses on the top 50 stocks on the BSE, presumably selected based on market capitalization, trading volume, or another metric of prominence. It should contain information about each company, such as the stock symbol, company name, industry, and possibly other details.
Bombay Stock Exchange: All data pertains to stocks listed on the BSE, one of the largest and most active stock exchanges in India. This could provide valuable insights into the Indian stock market and the performance of its leading companies.
This dataset would be valuable for financial analysis, investment strategy development, historical trend analysis, and predictive modeling. It could also be used to study the correlation between different stocks or sectors, market volatility, and the impact of economic events on stock prices. Please note that the exact contents of the dataset would need to be confirmed by examining the actual files.",.csv
BSE-500 10Year Historical DATA,1,bse-500-10year-historical-data,SnP BSE 500 10 Year.csv,CC0-1.0,"This dataset provides historical stock price data for the BSE 500 index over a period of 10 years (31/03/2014 - 01/04/2024). It includes daily information such as opening price, closing price, highest price, and lowest price for each trading day. ",.csv
BTC-Historical Data,1,btc-historical-data,BTC-USD.csv,CC0-1.0,"📉💰 Over the past two years, I meticulously collected Bitcoin price data from Yahoo Finance, meticulously scraping and compiling a comprehensive dataset. This dataset encapsulates the dynamic journey of Bitcoin's value, offering a detailed record of its fluctuations, highs, and lows. 📊📈 With this wealth of information at our fingertips, we're equipped to delve deep into the realm of cryptocurrency, uncovering trends, patterns, and insights that could shape our understanding of this ever-evolving market. From analyzing historical price movements to forecasting future trajectories, this dataset serves as a valuable resource for anyone navigating the exciting landscape of digital currencies. 🚀🔍",.csv
Bacteria Dataset,1,bacteria-dataset,bacteria_list_200.csv,ODC Attribution License (ODC-By),"### Dataset Overview

This dataset provides a comprehensive overview of 200 unique bacterial species, highlighting their scientific classification, natural habitats, and potential impacts on human health. Designed for data scientists and researchers, this collection serves as a foundational resource for studies in microbiology, public health, and environmental science. Each entry has been meticulously compiled to offer insights into the diverse roles bacteria play in ecosystems and their interactions with humans.

### Data Science Applications

With 200 carefully curated entries, this dataset is ideal for a variety of data science applications, including but not limited to:
- Predictive modeling to understand factors influencing bacterial habitats and human health implications.
- Clustering analyses to uncover patterns and relationships among bacterial families and their characteristics.
- Data visualization projects to illustrate the diversity of bacterial life and its relevance to ecosystems and health.

### Column Descriptors

1. **Name**: The scientific name of the bacterial species.
2. **Family**: The taxonomic family to which the bacterium belongs.
3. **Where Found**: Natural habitats or common environments where the bacterium is typically found, including multiple locations if applicable.
4. **Harmful to Humans**: Indicates whether the bacterium is known to have harmful effects on human health (""Yes"" or ""No"").

### Ethically Mined Data

The compilation of this dataset adheres to ethical data mining practices, ensuring respect for intellectual property rights and scientific integrity. No proprietary or confidential information has been included without appropriate permissions and acknowledgments.

### Sources

The data within this dataset has been gathered and synthesized from a range of authoritative sources, ensuring reliability and accuracy:

**Websites**:
- CDC (Centers for Disease Control and Prevention): Offers extensive information on pathogenic bacteria and their impact on human health.
- WHO (World Health Organization): Provides global health-related data, including details on bacteria responsible for infectious diseases.

**Scientific Journals**:
- ""Journal of Bacteriology"": A peer-reviewed scientific journal that publishes research articles on the biology of bacteria.
- ""Microbiology"": Offers articles on microbiology, virology, and molecular biology, with a focus on novel bacterial species and their functions.

**Textbooks**:
- ""Brock Biology of Microorganisms"" by Michael T. Madigan et al.: A comprehensive textbook covering the principles of microbiology, including detailed information on bacteria.
- ""Prescott's Microbiology"" by Joanne Willey, Linda Sherwood, and Christopher J. Woolverton: Provides a thorough introduction to the field of microbiology, with an emphasis on bacterial species and their roles.

This dataset represents a synthesis of credible scientific knowledge aimed at fostering research and education in microbiology and related fields.",.csv
Bakery Sales Dataset,1,bakery,Bakery.csv,CC0-1.0,"## Context

We live in the era of e-commerce and digital marketing. We have even small scale businesses going online as the opportunities are endless. Since a huge chunk of the people who have access to internet is switching to online shopping, large retailers are actively searching for ways to increase their profit. Market Basket analysis is one such key techniques used by large retailers to to increase sales by understanding the customers' purchasing behavior & patterns. Market basket analysis examines collections of items to find relationships between items that go together within the business context.

## Content
The dataset belongs to ""The Bread Basket"" a bakery located in Edinburgh. The dataset provide the transaction details of customers who ordered different items from this bakery online during the time period from 26-01-11 to 27-12-03. The dataset has 20507 entries, over 9000 transactions, and 4 columns.

###Variables

- `TransactionNo` : unique identifier for every single transaction
- `Items ` : items purchased
- `DateTime` : date and time stamp of the transactions
- `Daypart` : part of the day when a transaction is made (morning, afternoon, evening, night)
- `DayType` : classifies whether a transaction has been made in weekend or weekdays

## Inspiration
The dataset is ideal for anyone looking to practice association rule mining and understand the business context of data mining for better understanding of the buying pattern of customers.",.csv
Bali Popular Destination for Tourist 2022,1,bali-popular-destination-for-tourist-2022,Bali Popular Destination for Tourist 2022 - Sheet1.csv,CC0-1.0,"Bali (/ˈbɑːli/) is a province of Indonesia and the westernmost of the Lesser Sunda Islands. East of Java and west of Lombok, the province includes the island of Bali and a few smaller neighbouring islands, notably Nusa Penida, Nusa Lembongan, and Nusa Ceningan to the southeast. The provincial capital, Denpasar, is the most populous city in the Lesser Sunda Islands and the second-largest, after Makassar, in Eastern Indonesia. The upland town of Ubud in Greater Denpasar is considered Bali's cultural centre. The province is Indonesia's main tourist destination, with a significant rise in tourism since the 1980s. Tourism-related business makes up 80% of its economy.

Bali is the only Hindu-majority province in Indonesia, with 86.9% of the population adhering to Balinese Hinduism. It is renowned for its highly developed arts, including traditional and modern dance, sculpture, painting, leather, metalworking, and music. The Indonesian International Film Festival is held every year in Bali. Other international events held in Bali include the Miss World 2013, 2018 Annual Meetings of the International Monetary Fund and the World Bank Group and 2022 G20 summit. In March 2017, TripAdvisor named Bali as the world's top destination in its Traveller's Choice award, which it also earned in January 2021.

Bali is part of the Coral Triangle, the area with the highest biodiversity of marine species, especially fish and turtles.In this area alone, over 500 reef-building coral species can be found. For comparison, this is about seven times as many as in the entire Caribbean. Bali is the home of the Subak irrigation system, a UNESCO World Heritage Site. It is also home to a unified confederation of kingdoms composed of 10 traditional royal Balinese houses, each house ruling a specific geographic area. The confederation is the successor of the Bali Kingdom. The royal houses are not recognised by the government of Indonesia; however, they originated before Dutch colonisation.

Source: https://en.wikipedia.org/wiki/Bali",.csv
Bangladesh Districts wise population,1,bangladesh-districts-wise-population,city_population.csv,Apache 2.0,"# **Exploring City Population Data of Bangladesh**

The dataset contains comprehensive information about various cities in Bangladesh, including their population statistics across different years. Analyzing this dataset offers valuable insights into the demographic trends, urban development, and population dynamics within Bangladesh.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F1937611%2F35afefa82648f6e253e1fb63ffc8cf7d%2FOIG2.jpeg?generation=1708434102648245&alt=media)


## **Dataset Overview:**

**Source:** The data was scraped from the webpage https://www.citypopulation.de/en/bangladesh/cities/ & https://en.wikipedia.org/wiki/Districts_of_Bangladesh
**Content: **The dataset contains information about cities in Bangladesh, including their names, population, and other relevant demographic data.
**Format: **The data is presented in a tabular format within an HTML table on the webpage.

- Cities: The dataset encompasses a diverse range of cities across Bangladesh, representing different regions, sizes, and administrative statuses.
- Population Trends: Population data is provided for multiple years, spanning from 1991 to 2022. This allows for a longitudinal analysis of population growth, migration patterns, and urbanization trends over time.
- Geographical Information: In addition to population statistics, the dataset includes details about the geographical area of each city in square kilometers, providing context for population density and spatial distribution.
- City Status: The dataset categorizes cities based on their administrative status, such as urban, rural, or special administrative regions, offering insights into the urban-rural divide and administrative structures within Bangladesh.
- Native Names: Native or local names of cities are included, reflecting the linguistic and cultural diversity of Bangladesh.
- Administrative Divisions: Information about the division to which each city belongs is included, offering insights into the administrative structure of Bangladesh.

**Fields:** The dataset likely includes fields such as:

1. Name: The official name of the city as recognized by administrative authorities.
2. Abbr.: The abbreviation or short form of the city name, often used for convenience or in informal contexts.
3. Division: The administrative division to which the city belongs.
4. Established: The status or classification of the city, indicating whether it is urban, rural, or possibly a special administrative region.
5. Native: The native or local name of the city, which may differ from the official name and is often used by residents.
6. Area (km2): The total land area of the city in square kilometers, providing information about its geographical size.
7. Population_1991: The population of the city as recorded in the year 1991, serving as a historical reference point for demographic changes.
8. Population_2001: The population of the city as recorded in the year 2001, allowing for comparison with earlier and later population data.
9. Population_2011: The population of the city as recorded in the year 2011, providing insight into population trends over time.
10. Population_2022: The population of the city as recorded in the year 2022, offering recent demographic information for analysis and decision-making.


These columns collectively offer a comprehensive view of the cities in Bangladesh, encompassing their names, status, native names, geographical dimensions, and population dynamics across multiple years.

## **Objective:**

The objective of exploring this dataset is to gain a deeper understanding of the population dynamics and urban development patterns within Bangladesh. By analyzing population trends, demographic shifts, and geographical distributions, stakeholders can make informed decisions regarding infrastructure development, resource allocation, and urban planning initiatives.

## **Analytical Approach:**

Analyzing the dataset may involve various analytical techniques, including:

- Descriptive Statistics: Calculating summary statistics such as mean, median, and standard deviation to understand the distribution of population, area, and population density among cities.

- Time Series Analysis: Examining population trends over time to identify growth rates, patterns, and fluctuations.

- Spatial Mapping: Visualizing population density and distribution across different regions of Bangladesh using maps and geographical information systems (GIS).

- Division-wise Analysis: Comparing population dynamics and urbanization trends across different administrative divisions to understand regional variations and disparities.

By employing these analytical approaches, stakeholders can derive meaningful insights from the dataset to support evidence-based decision-making and policy formulation.
",.csv
Bangladesh Rice Import Statistics: A Comprehensive,1,bangladesh-rice-import-data,data-resource_2016_10_18_Rice-Import-Data.csv,Apache 2.0,"This dataset provides detailed information on rice imports into Bangladesh from 1960 to 2015. It includes data on the quantity (in thousand metric tons) of rice imported each year, offering insights into import trends spanning over five decades. Analysts, policymakers, researchers, and stakeholders can utilize this dataset to understand long-term import patterns, identify historical trends, and analyze the factors influencing rice imports in Bangladesh. With its extensive time range and quantity data, this dataset serves as a valuable resource for studying the evolution of rice imports in Bangladesh over the past five decades.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F1937611%2F4b9eb62ff215801711d07f7d9174aa3a%2F_aca2304c-db31-4827-a841-1ba7a6d0f3ac.jpeg?generation=1711639553822253&alt=media)

Here's an overview of the columns:

**1. Year: ** This column denotes the calendar year in which rice imports were recorded, ranging from 1960 to 2015.

**2. Quantity: ** This column represents the quantity of rice imported into Bangladesh, measured in thousand metric tons (000't), for each corresponding year.

Analysts, policymakers, researchers, and stakeholders can utilize this dataset to analyze the quantity of rice imports over time, identify trends, and gain insights into the dynamics of rice importation in Bangladesh.",.csv
Bank Client Attributes and Marketing Outcomes,1,bank-client-attributes-and-marketing-outcomes,Assignment-2_Data.csv,MIT,"The `Bank Client Attributes and Marketing Outcomes` dataset offers a comprehensive insight into the attributes of bank clients and the outcomes of marketing campaigns. It includes details such as client demographics, employment status, financial history, and contact methods. Additionally, the dataset encompasses the results of marketing campaigns, including the duration, success rates, and previous interactions with clients. This dataset serves as a valuable resource for analyzing customer behavior, optimizing marketing strategies, and enhancing client engagement in the banking sector.",.csv
Bank Customer Churn,1,bank-customer-churn,Customer-Churn-Records.csv,other,"RowNumber—corresponds to the record (row) number and has no effect on the output.
CustomerId—contains random values and has no effect on customer leaving the bank.
Surname—the surname of a customer has no impact on their decision to leave the bank.
CreditScore—can have an effect on customer churn, since a customer with a higher credit score is less likely to leave the bank.
Geography—a customer’s location can affect their decision to leave the bank.
Gender—it’s interesting to explore whether gender plays a role in a customer leaving the bank.
Age—this is certainly relevant, since older customers are less likely to leave their bank than younger ones.
Tenure—refers to the number of years that the customer has been a client of the bank. Normally, older clients are more loyal and less likely to leave a bank.
Balance—also a very good indicator of customer churn, as people with a higher balance in their accounts are less likely to leave the bank compared to those with lower balances.
NumOfProducts—refers to the number of products that a customer has purchased through the bank.
HasCrCard—denotes whether or not a customer has a credit card. This column is also relevant, since people with a credit card are less likely to leave the bank.
IsActiveMember—active customers are less likely to leave the bank.
EstimatedSalary—as with balance, people with lower salaries are more likely to leave the bank compared to those with higher salaries.
Exited—whether or not the customer left the bank.
Complain—customer has complaint or not.
Satisfaction Score—Score provided by the customer for their complaint resolution.
Card Type—type of card hold by the customer.
Points Earned—the points earned by the customer for using credit card.

Acknowledgements

As we know, it is much more expensive to sign in a new client than keeping an existing one.

It is advantageous for banks to know what leads a client towards the decision to leave the company.

Churn prevention allows companies to develop loyalty programs and retention campaigns to keep as many customers as possible.",.csv
Bank Customer Churn Dataset ,1,bank-customer-churn-dataset,Bank Customer Churn Prediction.csv,other,"This dataset is for ABC Multistate bank with following columns: 

1. **customer_id**, unused variable.
2. **credit_score,** used as input.
3. **country**, used as input.
4. **gender**, used as input.
5. **age**, used as input.
6. **tenure**, used as input.
7. **balance**, used as input.
8. **products_number**, used as input.
9. **credit_card**, used as input.
10. **active_member**, used as input.
11. **estimated_salary**, used as input.
12. **churn**, used as the target. 1 if the client has left the bank during some period or 0 if he/she has not.

*Aim is to Predict the Customer Churn for ABC Bank.*

![](https://miro.medium.com/max/737/1*Xap6OxaZvD7C7eMQKkaHYQ.jpeg)",.csv
Bank Customer Churn Prediction,1,customer-churn-from-a-bank,Churn_Modelling.csv,Apache 2.0,"The data will be used to predict whether a customer of the bank will churn. If a customer churns, it means they left the bank and took their business elsewhere. If you can predict which customers are likely to churn, you can take measures to retain them before they do. These measures could be promotions, discounts, or other incentives to boost customer satisfaction and, therefore, retention.

The dataset contains:

10,000 rows – each row is a unique customer of the bank

14 columns:

RowNumber: Row numbers from 1 to 10,000

CustomerId: Customer’s unique ID assigned by bank

Surname: Customer’s last name

CreditScore: Customer’s credit score. This number can range from 300 to 850. 

Geography: Customer’s country of residence

Gender: Categorical indicator

Age: Customer’s age (years)

Tenure: Number of years customer has been with bank

Balance: Customer’s bank balance (Euros) 

NumOfProducts: Number of products the customer has with the bank

HasCrCard: Indicates whether the customer has a credit card with the bank

IsActiveMember: Indicates whether the customer is considered active

EstimatedSalary: Customer’s estimated annual salary (Euros)

Exited: Indicates whether the customer churned (left the bank)",.csv
Bank Customer Churn Prediction ,1,bank-customer-churn-prediction,Churn_Modelling.csv,other,"### Context

It is the dataset of a U.S. bank customer for getting the information that , this particular customer will leave bank or not.


### Content

Various Bank detail is given like CustomerID , surname, Credit score and many more.


### Acknowledgements

This dataset is originated from a U.S. bank .


### Inspiration

Lets work together on this dataset and learn basic level of prediction using different libraries.",.csv
Bank Customer Information and Marketing Response,1,bank-customer-information-and-marketing-response,bank.csv,MIT,"This dataset contains information about bank customers and their responses to marketing campaigns. The dataset includes demographic and financial characteristics of customers, such as age, job, marital status, education level, and balance in their accounts. Additionally, it includes information about their response to marketing campaigns, such as whether they subscribed to a term deposit (yes/no) and the outcome of the marketing campaign (success/failure).

The dataset aims to help understand the factors that influence a customer's decision to subscribe to a term deposit and the effectiveness of marketing campaigns. It can be used for predictive modeling, data analysis, and machine learning tasks to identify patterns and relationships between customer characteristics and marketing outcomes.

Key Features:

Demographic information (age, job, marital status, education level)

Financial information (account balance, housing loan, personal loan)

Marketing campaign information (campaign duration, number of contacts, outcome)

Response to marketing campaign (subscription to term deposit, yes/no)

Target Variable:

y (subscription to term deposit, yes/no)

Number of Instances:

5 (in the provided sample, but the actual dataset may have more instances)

Number of Attributes:

16 (including the target variable)",.csv
Bank Customers Churn ,1,bank-customers,Churn Modeling.csv,other,"### Context

A dataset which contain some customers who are withdrawing their account from the bank due to some loss and other issues with the help this data we try to analyse and maintain accuracy.


### Content

What's inside is more than just rows and columns. Make it easy for others to get started by describing how you acquired the data and what time period it represents, too.


### Acknowledgements

We wouldn't be here without the help of others. If you owe any attributions or thanks, include them here along with any citations of past research.


### Inspiration

Your data will be in front of the world's largest data science community. What questions do you want to see answered?",.csv
"Bank Loan Approval - LR, DT, RF and AUC",1,bank-loan-approval-lr-dt-rf-and-auc,bankloan.csv,CC0-1.0,"- DATASET: Dependent variable is 'Personal.Loan'. 0 indicates loan not approved and 1 indicates loan approved.
- OBJECTIVE : We will do Exploratory Data Analysis and use Logistic Regression, Decision Tree, Random Forest and AUC to find out which is the best model.
Steps:
- Set the working directory and read the data
- Check the data types of all the variables
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F020afd07cf0c5ba058d88add9bcd467a%2FPicture1.png?generation=1699357564112927&alt=media)
- DATA CLEANING
- We need to change the data types of certain variables to factor vector
- Check for missing data, duplicate records and remove insignificant variables
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2Fa286a5225207d4419b34bcf800e3cb67%2FPicture2.png?generation=1699357685993423&alt=media)
- New data frame created called 'bank1' after dropping the 'ID' column.
- EXPLORATORY DATA ANALYSIS
- We will try to get some insights by digging into the data through bar charts and box plots which can help the bank management in decision making 
- Run the required libraries
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F7363f4b9ca8245b6e998bf07005fa099%2FPicture3.png?generation=1699357871368520&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F8dba10f16fc6c2d7fd51a4c82a692136%2FCount%20of%20Loans%20Approved%20%20Not%20Approved.jpeg?generation=1699357967347355&alt=media)
- Out of the total 5000 customers, 4520 have not been approved for a loan while 480 have been
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2Fe5eec968e7b264d9ec540bd1f24379fd%2FPicture4.png?generation=1699358066228901&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2Fb64eba6f373d5c043c9f504cfa348a75%2FPicture5.png?generation=1699358103026827&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F94608993dc12cdc31cfeca92932e0cb5%2FBoxPlot%20Income%20and%20Family.jpeg?generation=1699358148840198&alt=media)
- THIS INDICATES THAT INCOME IS HIGHER WHEN THERE ARE LESS FAMILY MEMBERS
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F8e44daf4ed42094f71c3000737f07a32%2FPicture6.png?generation=1699360599956530&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F0fd9010b95acf9ad20f7b9d0e171f305%2FBoxplot%20between%20Income%20%20Personal%20Loan.jpeg?generation=1699359231020725&alt=media)
- THIS INDICATES PERSONAL LOAN HAS BEEN APPROVED FOR CUSTOMERS HAVING HIGHER INCOME
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2Ff817481849aba7f176b7c4d0147308de%2FPicture7.png?generation=1699360768102069&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F8e0bad8c76aaa11fe3b9909721d587f5%2FBoxPlot%20between%20Income%20%20Credit%20Cards.jpeg?generation=1699360798538907&alt=media)
- THIS INDICATES THAT THE INCOME IS PRETTY SIMILAR FOR CUSTOMERS OWNING AND NOT OWNING A CREDIT CARD 
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2Fab4b2fd2fde2a009bceb05a5a1161040%2FPicture8.png?generation=1699360882879480&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2Fe747dfa315609c4907ea83a9ac7f482c%2FBoxPlot%20between%20Income%20Class%20%20Mortgage.jpeg?generation=1699359265603058&alt=media)
- CUSTOMERS BELONGING TO THE RICH CLASS (INCOME GROUP : 150-200) HAVE THE HIGHEST MORTGAGE
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F6552d3fb9564b3ab3239ef67ed17a098%2FPicture9.png?generation=1699360938106437&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F4c7c7077e26229f455c1d9ef6e83195f%2FBoxPlot%20between%20CC%20Avg%20and%20Online%20Banking.jpeg?generation=1699359306645100&alt=media)  
- CC AVG IS PRETTY SIMILAR FOR THOSE WHO OPTED FOR ONLINE SERVICES AND THOSE WHO DID NOT  
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2Feddee2ca08a8138bb54eed0c25750280%2FPicture10.png?generation=1699360994581181&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F6127e25258b25ccfbae66a5463a72773%2FBoxplot%20between%20CC%20Avg%20and%20Education.jpeg?generation=1699359333295827&alt=media)
- MORE EDUCATED CUSTOMERS HAVE A HIGHER CREDIT AVERAGE
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2Fbf5978289401f8bb798d431825cdd3e0%2FPicture11.png?generation=1699361036019173&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F7cf85c54624e40a2f76dadfe60ba96ee%2FBoxPlot%20between%20CC%20Avg%20and%20Age%20Range.jpeg?generation=1699359364569334&alt=media)
- CC AVG IS HIGHER IN THE AGE GROUP OF 22-30 AND 31-40
- USING LOGISTIC REGRESSION
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2Ffe132b152f4c4e71329193bbc8cd9bef%2FPicture12.png?generation=1699361102645370&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2Faae2115afca8d36534e1144657759a04%2FPicture13.png?generation=1699361125251112&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F6dbe3ae38df4b3b76f96d8064479144b%2FPicture14.png?generation=1699361160050506&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F42d67550041ed5200d41d98865652297%2FPicture15.png?generation=1699361176140704&alt=media)
- 'Zipcode' variable has been removed. Therefore, we create a new data frame without the said variable.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2Fd716ec49aea5083edebd72b5a2ecd846%2FPicture16.png?generation=1699361258755258&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F571b2577d640fe0a310c6d77c553d77e%2FPicture17.png?generation=1699361323426786&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2Fccb22374488a48f3f2ee4ff5f28bf9b0%2FPicture18.png?generation=1699361336488532&alt=media)
- Age, Income and Age_range have a VIF value greater than 5. So we will drop the Age_range first.
- We create a new data frame called 'bank3' by excluding column 'Age_range'
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2Fa74199cd36f853e8e3e3cd23e10b0d08%2FPicture60.png?generation=1699378074891676&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2Fdafd035fddf5386cb75df10e1db5f07c%2FPicture61.png?generation=1699378122498707&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2Fb73d3bebcfa2dba948666369e0429a53%2FPicture62.png?generation=1699378223428207&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F8577896d1e98e80c07381629ffd37480%2FPicture63.png?generation=1699378281209478&alt=media)
- As we can see, VIF value of column 'Age' is now below 5. The column 'Income' still has a higher VIF value than 5. But I will still keep this as I feel it is very important for further analysis.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F1bf452824e2781dbe183315947ac45ad%2FPicture64.png?generation=1699379052804323&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F4f6ed4a2874e88ce2a1c0f3f571ba440%2FPicture65.png?generation=1699379375791055&alt=media)
 ![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F6301164bf183b94a7aa96fe6d95fab36%2FPicture66.png?generation=1699379626019892&alt=media) 
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F2640981bbc37da3cc776f4231ab31b4a%2FPicture67.png?generation=1699379979684305&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F9a0546b65cae1fc585c8f22a614d9067%2FPicture68.png?generation=1699380071538050&alt=media)
- Column 'Mortgage' has been removed
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F527135fdd4160968bb7ef00914e064b8%2FPicture70.png?generation=1699380570730499&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2Ff38784e58b747e9270eb8ee1e1a76c0c%2FPicture71.png?generation=1699380778190850&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F4c76f335f9db42cd1eb10d1e63d60345%2FPicture72.png?generation=1699380847559372&alt=media)
- Accuracy is 96.10%, Sensitivity is 70.83% and Specificity is 98.78%
- AS WE SAW EARLIER THAT THE DATA IS HEAVILY IMBALANCED. Out of the total 5000 customers, 4520 have not been approved for a loan while 480 have been. WE NEED TO BALANCE THE DATA
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F9feb7cceda2718752a1517e385c53476%2FPicture73.png?generation=1699426492166172&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2Fb4bc13fd06e878f96adf358c48fdcf8f%2FPicture74.png?generation=1699426581673692&alt=media)
- Predict the test data for over, under and both data using Logistic Regression
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2Fae962cd16ebf40893af9f37f7dd6af89%2FPicture75.png?generation=1699426698437994&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2Fda2c7927cba8b76c1a5d18eaedbca95d%2FPicture76.png?generation=1699427002829526&alt=media)
- Logistic Regression for over_data: Accuracy is 92.1%, Sensitivity is 94.79% and Specificity is 91.81%
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F5279c78fc8aaa6bbbd709f91bec63b30%2FPicture77.png?generation=1699427103928404&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F48030291618ed8f9c73f6222af02754c%2FPicture78.png?generation=1699427153342535&alt=media)
- Logistic Regression for under_data: Accuracy is 92.1%, Sensitivity is 95.83% and Specificity is 91.70%
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F17d6a1af32c6a407f61c7dc037547aed%2FPicture79.png?generation=1699427271586137&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F94b16b01880b934facf2d0af15565fc4%2FPicture80.png?generation=1699427438299522&alt=media)
-  Logistic Regression for both_data: Accuracy is 92.2%, Sensitivity is 93.75% and Specificity is 92.04%
-  Predict the test data for over, under and both data using Decision Tree
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2Fe41642b412d25c0c69172b1383571cac%2FPicture81.png?generation=1699430344618583&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F529f4c36ffaccbec0a84749a032de187%2FPicture82.png?generation=1699430407352804&alt=media)
- Decision Tree for over_data: Accuracy is 92.8%, Sensitivity is 98.96% and Specificity is 92.15%
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2Ffeb3fdae70291db8cc61650752630aa1%2FPicture83.png?generation=1699430549185975&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F3dd60e9ef18e6cbe326a75499855cb42%2FPicture84.png?generation=1699430603979541&alt=media)
- Decision Tree for under_data: Accuracy is 93.7%, Sensitivity is 98.96% and Specificity is 93.14%
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F657ecec5c244fb2ac8495133ef83b1fc%2FPicture85.png?generation=1699430743642851&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F2ad75f06982b4cacea5a48b3702e214a%2FPicture86.png?generation=1699430787065842&alt=media)
- Decision Tree for both_data: Accuracy is 94.5%, Sensitivity is 94.79% and Specificity is 94.47%
- Predict the test data for over, under and both data using Random Forest
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2Fc0c2d60330dd296aa3d3b8f7f22e51da%2FPicture87.png?generation=1699430915253338&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F360a786481b45c5e7c13ea7f5ed882e5%2FPicture88.png?generation=1699430959539590&alt=media)
- Random Forest for over_data: Accuracy is 98.4%, Sensitivity is 92.71% and Specificity is 99.00%
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2Fdb2a656d38b12d7274786aaa25a37ed4%2FPicture89.png?generation=1699431839393413&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F1380f4acad1f8f8497fd9f727b961971%2FPicture90.png?generation=1699431885936646&alt=media)
- Random Forest for under_data: Accuracy is 95.7%, Sensitivity is 98.96% and Specificity is 95.35%
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F626f8bce58f2df96397ea4fa34814359%2FPicture91.png?generation=1699431967377590&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2Fc1e5224784bbca9a8eed017b40370251%2FPicture92.png?generation=1699432023092594&alt=media)
- Random Forest for both_data: Accuracy is 98.4%, Sensitivity is 96.88% and Specificity is 98.56%
- ROC and AUC for over, under and both_data
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2Fd817e968e6a11571ba86bcddbb567651%2FPicture93.png?generation=1699433894475743&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2Fd8806a535ff1d531f164eb21d5992469%2FAUC%20(LR%20FOR%20OVER).jpeg?generation=1699434055190789&alt=media)
- AUC 98.01% for over_data for Logistic Regression
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2Fbed8befddbcbb0bf56f6f092197f1b2b%2FPicture94.png?generation=1699434380452747&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2Fb85e8815a75cbc0a4e945600a9d5f740%2FAUC(LR%20FOR%20UNDER).jpeg?generation=1699434422692401&alt=media)
- AUC 98.2% for under_data for Logistic Regression
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F9b6480b4f7d3ec9e0ced3597802a239b%2FPicture95.png?generation=1699434526528791&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F80066a0f3d9f8aaf0717d8b9abe14266%2FAUC%20(LR%20FOR%20BOTH).jpeg?generation=1699434543214379&alt=media)
- AUC 97.86% for both_data for Logistic Regression
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2Fce30cd3a3cd30b7974c4817e0d55b467%2FPicture96.png?generation=1699436231274292&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F1d8a22fd99cc0ddfe9700fdebb07839a%2FAUC(DT%20FOR%20OVER).jpeg?generation=1699436247494229&alt=media)
- AUC 97.72% for over_data for Decision Tree
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F3b040d12f7ca2595f2c55c3bbde502aa%2FPicture97.png?generation=1699436324255457&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F6fbd9d8661fdc601ff6f8c8e02e519fd%2FAUC(DT%20FOR%20UNDER).jpeg?generation=1699436354352152&alt=media)
- AUC 98.01% for under_data for Decision Tree
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2Fb7a7e46cbf4fcdb6471b444b8294af7c%2FPicture98.png?generation=1699436416238437&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2Fab13dc8333ff221d06dfffdd4996b3fc%2FAUC(DT%20FOR%20BOTH).jpeg?generation=1699436437410191&alt=media)
- AUC 98.80% for both_data for Decision Tree
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F620ed451e66d158c7785eb8103b50ae2%2FPicture99.png?generation=1699436553452608&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2F9e6faf31b3c776d775a9a894decc0eed%2FAUC(RF%20FOR%20OVER).jpeg?generation=1699436529167973&alt=media)
- AUC 99.83% for over_data for Random Forest
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2Fb8a87b91779f7aa2b39cac62ac2004f0%2FPicture100.png?generation=1699436694151647&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2Fb55bf6ac7a28a49da2c65f2a2a77c4fa%2FAUC(RF%20FOR%20UNDER).jpeg?generation=1699436711623625&alt=media)
- AUC 99.71% for under_data for Random Forest
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10868729%2Fb44d3912ae323490cc995e19138aa4d1%2FPicture101.png?generation=1699436834727443&alt=media)
- AUC 99.82% for both_data for Random Forest
- CONCLUSION: IF WE DECIDE TO GO WITH AUC , THEN WE CAN MOVE AHEAD WITH RANDOM FOREST AS IT HAS THE HIGHEST AUC AMONGST ALL",.csv
Bank Loan Granting,1,bank-loan-granting,Bank_Loan_Granting.csv,CC0-1.0,"This dataset has 5000 samples with 14 features.

Columns Descriptions :

ID : customer ID
Age : age of customer
Experience : the number of years that the customer has experience
Income : the customer's annual earnings
ZIP Code : the postal code of the customer's location
Family : the number of people in the customer's family
CCAvg : the average monthly credit card spending
Education : the level of customer's Education(undergraduate,graduate,professional)
Mortgage : the Value of the customer's mortgage(the thing that the customer uses as a guarantee to the bank) Securities Account : whether the customer has a security account or not(it's also known as an investment account)
CD Account : the customer has a CD account or not(a type of savings account that lets the customer earn interest on a fixed amount of money for a fixed period)
Online : the customer uses the bank's online services or not
CreditCard : the customer uses the bank's credit card or not
Personal Loan : the customer is granted loans or not",.csv
Bank Marketing,1,bankbalanced,bank.csv,CC0-1.0,"This dataset is taken from UCI : https://archive.ics.uci.edu/ml/datasets/Bank+Marketing

The dataset in UCI is imbalanced. A balanced sample was taken from that dataset to create this. Features remain the same as the original one.",.csv
Bank Marketing Campaign Dataset,1,bank-marketing-campaign-dataset,dataset.csv,Apache 2.0,"Here's a breakdown of each column in the dataset along with an explanation of its meaning and some example rows:

1. **age_group**: The age group of the customer.
   - Example rows: 30-39, 40-49, 50-59.

2. **occupation**: The occupation of the customer.
   - Example rows: executive, technician, manual_worker.

3. **marital_status**: The marital status of the customer.
   - Example rows: married, single, divorced.

4. **education_level**: The highest education level attained by the customer.
   - Example rows: high_school, college, elementary_school.

5. **communication_channel**: The communication channel used for contacting the customer.
   - Example rows: mobile, landline, unidentified.

6. **call_day**: The day of the month on which the call was made.
   - Example rows: 5, 15, 25.

7. **call_month**: The month of the year in which the call was made.
   - Example rows: January, May, August.

8. **call_duration**: The duration of the call in seconds.
   - Example rows: 180, 300, 420.

9. **call_frequency**: The frequency of calls made to the customer.
   - Example rows: 1, 2, 3.

10. **previous_campaign_outcome**: The outcome of the previous marketing campaign for the customer.
    - Example rows: unsuccessful, successful, other_outcome.

11. **conversion_status**: Whether the customer was converted or not.
    - Example rows: converted, not_converted.

Each row represents a customer interaction record, detailing various attributes such as age, occupation, marital status, education level, communication channel, call timing and duration, previous campaign outcome, and conversion status. This dataset can be used for analyzing customer behavior, predicting conversion rates, and optimizing marketing strategies in the insurance industry.",.csv
Bank Marketing Data Set,1,bank-marketing-data-set,bank-direct-marketing-campaigns.csv,Attribution 4.0 International (CC BY 4.0),"### Data Set Information

This data set contains records relevant to a direct marketing campaign of a Portuguese banking institution. The marketing campaign was executed through phone calls. Often, more than one call needs to be made to a single client before they either decline or agree to a term deposit subscription. The classification goal is to predict if the client will subscribe (yes/no) to the term deposit (variable y).

This is a *modified* version of the classic bank marketing data set originally shared in the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Bank%2BMarketing). There are four datasets available on UCI's repository:
1) bank-additional-full.csv with all examples (41188) and 20 inputs, ordered by date (from May 2008 to November 2010), very close to the data analyzed in [Moro et al., 2014]
2) bank-additional.csv with 10% of the examples (4119), randomly selected from 1), and 20 inputs.
3) bank-full.csv with all examples and 17 inputs, ordered by date (older version of this data set with less inputs).
4) bank.csv with 10% of the examples and 17 inputs, randomly selected from 3 (older version of this data set with less inputs).
*Note*: The smallest datasets are provided to test more computationally demanding machine learning algorithms (e.g., SVM).

This data set is a copy of **data set no. 1** (*bank-additional-full.csv*) from the list above with **one input feature** (representing duration of phone call) **removed**.  The following is a note from the variable description in the original data set:

&gt; duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.

**The `duration` feature is excluded in this data set to prevent data leakage.** 


### Contents

Input variables:

bank client data:
1 - age (numeric)
2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')
3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)
4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')
5 - default: has credit in default? (categorical: 'no','yes','unknown')
6 - housing: has housing loan? (categorical: 'no','yes','unknown')
7 - loan: has personal loan? (categorical: 'no','yes','unknown')

related with the last contact of the current campaign:
8 - contact: contact communication type (categorical: 'cellular','telephone')
9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')
10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')

other attributes:
11 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)
12 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)
13 - previous: number of contacts performed before this campaign and for this client (numeric)
14 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')

social and economic context attributes:
15 - emp.var.rate: employment variation rate - quarterly indicator (numeric)
16 - cons.price.idx: consumer price index - monthly indicator (numeric)
17 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)
18 - euribor3m: euribor 3 month rate - daily indicator (numeric)
19 - nr.employed: number of employees - quarterly indicator (numeric)

Output variable (desired target):

20 - y - has the client subscribed a term deposit? (binary: 'yes','no')


### Acknowledgements

Source: [Moro et al., 2014] S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014

Data credit goes to UCI. Visit their website to access the original data set directly: https://archive.ics.uci.edu/ml/datasets/Bank%2BMarketing


### Context

Use this data set to test the performance of your classification models and to explore the best strategies to improve a banking institution's next direct marketing campaign. 

Term deposits are cash investment held at a financial institution and are a major source of revenue for banks--making them important for financial institutions to market. Telemarketing remains to be a popular marketing technique because of the potential effectiveness of human-to-human contact provided by a telephone call, which is sometimes quite the opposite of many impersonal and robotic marketing messages relayed through social and digital media. However, executing such direct marketing effort usually requires a huge investment by the business as large call centers need to be contracted to contact clients directly.

How can the banking institution have more effective direct marketing campaigns in the future? Analyze this data set and identify the patterns that will help us develop future strategies.
",.csv
Bank Marketing Dataset,1,bank-marketing-dataset,bank.csv,CC0-1.0,"### Context

Find the best strategies to improve for the next marketing campaign. How can the financial institution have a greater effectiveness for future marketing campaigns? In order to answer this, we have to analyze the last marketing campaign the bank performed and identify the patterns that will help us find conclusions in order to develop future strategies.

### Source
[Moro et al., 2014] S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014",.csv
Bank Target Marketing,1,bank-target-marketing,Bank Target Marketing Dataset.csv,MIT,"The ""bank target marketing"" dataset is a collection of data focused on a bank's marketing campaign to acquire deposits from customers. This dataset contains various attributes related to customer demographics, their previous interactions with the bank, and the outcomes of the marketing campaign conducted.

This dataset is valuable for analyzing the factors influencing customers' decisions to subscribe to term deposits, as well as for predicting customer behavior in future similar marketing campaigns. By understanding this dataset, banks or marketing analysts can optimize their marketing strategies to enhance the success of deposit campaigns in the future.",.csv
Bank marketing campaigns dataset | Opening Deposit,1,bank-marketing-campaigns-dataset,bank-additional-full.csv,CC-BY-NC-SA-4.0,"# Bank marketing campaigns dataset analysis # Opening a Term Deposit

It is a dataset that describing Portugal bank marketing campaigns results. 
Conducted campaigns were based mostly on direct phone calls, offering  bank client to place a term deposit. 
If after all marking afforts client had agreed to place deposit - target variable marked 'yes', otherwise 'no'

Sourse of the data
https://archive.ics.uci.edu/ml/datasets/bank+marketing

**Citation Request:**

This dataset is public available for research. The details are described in S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014


1. Title: Bank Marketing (with social/economic context)

2. Sources
   Created by: Sérgio Moro (ISCTE-IUL), Paulo Cortez (Univ. Minho) and Paulo Rita (ISCTE-IUL) @ 2014

3. Past Usage:

  The full dataset (bank-additional-full.csv) was described and analyzed in:

  S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems (2014), doi:10.1016/j.dss.2014.03.001.

4. Relevant Information:

   This dataset is based on ""Bank Marketing"" UCI dataset (please check the description at: http://archive.ics.uci.edu/ml/datasets/Bank+Marketing).
   The data is enriched by the addition of five new social and economic features/attributes (national wide indicators from a ~10M population country), published by the Banco de Portugal and publicly available at: https://www.bportugal.pt/estatisticasweb.
   This dataset is almost identical to the one used in [Moro et al., 2014] (it does not include all attributes due to privacy concerns).
   Using the rminer package and R tool (http://cran.r-project.org/web/packages/rminer/), we found that the addition of the five new social and economic attributes (made available here) lead to substantial improvement in the prediction of a success, even when the duration of the call is not included. Note: the file can be read in R using: d=read.table(""bank-additional-full.csv"",header=TRUE,sep="";"")

The binary classification goal is to predict if the client will subscribe a bank term deposit (variable y).

5. Number of Instances: 41188 for bank-additional-full.csv

6. Number of Attributes: 20 + output attribute.

7. Attribute information:

   For more information, read [Moro et al., 2014].

   Input variables:
   # bank client data:
   *1 - age (numeric)

   *2 - job : type of job (categorical: ""admin."",""blue-collar"",""entrepreneur"",""housemaid"",""management"",""retired"",""self-employed"",""services"",""student"",""technician"",""unemployed"",""unknown"")

   *3 - marital : marital status (categorical: ""divorced"",""married"",""single"",""unknown""; note: ""divorced"" means divorced or widowed)

   *4 - education (categorical: ""basic.4y"",""basic.6y"",""basic.9y"",""high.school"",""illiterate"",""professional.course"",""university.degree"",""unknown"")

  * 5 - default: has credit in default? (categorical: ""no"",""yes"",""unknown"")

  * 6 - housing: has housing loan? (categorical: ""no"",""yes"",""unknown"")

  * 7 - loan: has personal loan? (categorical: ""no"",""yes"",""unknown"")

   # related with the last contact of the current campaign:
  * 8 - contact: contact communication type (categorical: ""cellular"",""telephone"")

   *9 - month: last contact month of year (categorical: ""jan"", ""feb"", ""mar"", ..., ""nov"", ""dec"")

  *10 - day_of_week: last contact day of the week (categorical: ""mon"",""tue"",""wed"",""thu"",""fri"")

  *11 - duration: last contact duration, in seconds (numeric). Important note:  this attribute highly affects the output target (e.g., if duration=0 then y=""no""). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.
   # other attributes:
  *12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)

  *13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)

  *14 - previous: number of contacts performed before this campaign and for this client (numeric)

  1515 - poutcome: outcome of the previous marketing campaign (categorical: ""failure"",""nonexistent"",""success"")

   # social and economic context attributes
  *16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)

  *17 - cons.price.idx: consumer price index - monthly indicator (numeric)

  *18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)

   *19 - euribor3m: euribor 3 month rate - daily indicator (numeric)

 * 20 - nr.employed: number of employees - quarterly indicator (numeric)

  Output variable (desired target):
 * 21 - y - has the client subscribed a term deposit? (binary: ""yes"",""no"")

8. Missing Attribute Values: There are several missing values in some categorical attributes, all coded with the ""unknown"" label. These missing values can be treated as a possible class label or using deletion or imputation techniques.
",.csv
Banking Customer Churn Prediction Dataset,1,bank-customer-churn-prediction-dataset,Churn_Modelling.csv,Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0),"# **Description:**
This dataset contains information about bank customers and their churn status, which indicates whether they have exited the bank or not. It is suitable for exploring and analyzing factors influencing customer churn in banking institutions and for building predictive models to identify customers at risk of churning.

# **Features:**

**RowNumber:** The sequential number assigned to each row in the dataset.

**CustomerId:** A unique identifier for each customer.

**Surname:** The surname of the customer.

**CreditScore:** The credit score of the customer.

**Geography:** The geographical location of the customer (e.g., country or region).

**Gender:** The gender of the customer.

**Age:** The age of the customer.

**Tenure:** The number of years the customer has been with the bank.

**Balance:** The account balance of the customer.

**NumOfProducts:** The number of bank products the customer has.

**HasCrCard:** Indicates whether the customer has a credit card (binary: yes/no).

**IsActiveMember:** Indicates whether the customer is an active member (binary: yes/no).

**EstimatedSalary:** The estimated salary of the customer.

**Exited:** Indicates whether the customer has exited the bank (binary: yes/no).



#**Usage:**
- This dataset can be used for exploratory data analysis to understand the factors influencing customer churn in banks.
- It can also be used to build machine learning models for predicting customer churn based on the given features.

#**License:**
This dataset is made available under the [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-nc-sa/4.0/).",.csv
Banking Sector of the UEMOA countries 🌍,1,banking-sector-of-the-waemu,WAEMU_Banking.csv,CC-BY-SA-4.0,"This dataset pertains to the banking sector of the West African Economic and Monetary Union (UEMOA), encompassing the following countries: Benin, Burkina Faso, Côte d'Ivoire, Guinea-Bissau, Mali, Niger, Senegal, and Togo.

**Columns description:**  
1. **Countries_Num**: Numeric code representing the 8 countries in the West African Economic and Monetary Union (ranges from 1 to 8).

2. **id**: An identifier for each bank in the dataset.

3. **Countries**: Categorical variable indicating the names of the countries in the West African Economic and Monetary Union.

4. **Banks**: Categorical variable representing the names of the banks within the specified countries.

5. **Year**: Integer variable indicating the year in which the data was recorded.

6. **RIR (Risk Index Rating)**: A measure assessing the level of risk associated with financial institutions.

7. **SFS (Solvency and Financial Stability)**: A metric indicating the financial health and stability of the banks.

8. **INF (Inflation Rate)**: Represents the inflation rate, a measure of the general rise in prices over a period of time.

9. **ERA (Economic Risk Assessment)**: An evaluation of the potential economic risks within the banking sector.

10. **INL (Internationalization Level)**: Indicates the extent to which banks are involved in international activities.

11. **Zscore**: A metric used as a measure of a bank's financial health and the likelihood of it going bankrupt in the next two years.

12. **DEBT (Debt Level)**: Represents the amount of debt held by the banks.

13. **SIZE**: Represents the size of the banks, typically measured by total assets or other relevant financial metrics.

14. **CC (Capital Adequacy)**: A measure of a bank's capital in relation to its risk-weighted assets.

15. **GE (Governance and Ethics)**: Evaluates the governance practices and ethical standards within the banking institutions.

16. **PS (Profitability and Sustainability)**: Assesses the profitability and sustainability of the banks.

17. **RQ (Regulatory Compliance)**: Measures the extent to which banks adhere to regulatory requirements.

18. **RL (Liquidity Risk)**: Evaluates the risk associated with a bank's ability to meet its short-term obligations.

19. **VA (Value Added)**: Indicates the value added by the banks to the overall economic environment.

This dataset encompasses a comprehensive set of variables providing insights into various aspects of the banking sector within the West African Economic and Monetary Union. It can be valuable for analyzing and understanding the performance, risks, and overall dynamics of the banking institutions in the region over time.",.csv
Banknifty and its components,1,banknifty-and-its-components,banknifty.csv,Apache 2.0,"This dataset provides the historical price data for the Bank Nifty index and its constituent stocks from January 1, 2019, to the present day. The Bank Nifty is a prominent index on India's National Stock Exchange (NSE), comprising stocks of prominent banking and financial institutions.

This dataset is regularly updated with the latest trading data, providing a comprehensive record of the Bank Nifty index's price movements and trading activities and its constituent stocks. It can be valuable for researchers, traders, and analysts interested in studying market trends, developing trading strategies, or conducting quantitative analyses in the Indian banking and financial sector.
Please note that while the dataset covers historical data from 2019 onwards, it is a live dataset that continues to be updated with the most recent trading information.

1. HDFC Bank (HDFCBANK): 27.04%
2. ICICI Bank (ICICIBANK): 23.03%
3. Kotak Mahindra Bank (KOTAKBANK): 11.72%
4. State Bank of India (SBIN): 11.27%
5. Axis Bank (AXISBANK): 11.18%
6. IndusInd Bank (INDUSINDBK): 5.58%
7. AU Small Finance Bank (AUBANK): 2.69%
8. Bandhan Bank (BANDHANBNK): 1.98%
9. Bank of Baroda (BANKBARODA): 1.84%
10. Federal Bank (FEDERALBNK): 1.68%
11. IDFC First Bank (IDFCFIRSTB): 1.08%
12. Punjab National Bank (PNB): 0.91%

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F15855405%2F7343c4464cf9fe53bbadbd9739ae8535%2Fbanknifty.jpg?generation=1714102161437429&alt=media)",.csv
Base load power stations data,1,base-load-power-stations-data,GB_cycling_data.csv,CC-BY-NC-SA-4.0,"This dataset provides daily aggregations of 3 cycling variables of base-load power stations in the GB power system for the period 2009--2017. It describes the number of startups, severe ramping events and average load factor of base-load generators (coal and gas-fired power stations with capacity &gt; 100MW). It is the first of its kind, and may help improve our understanding of how cycling interacts with other factors in the power system such as renewables generation.

The cycling data has been derived from operational data for the GB power system from Elexon's P114 dataset. We also include data on IRES (intermittent renewable energy sources; wind + solar) generation, total generation, and the number of active base-load generators in that year.

Definitions of variables:

- metered_wind_MWh: total generation of wind generators in the Elexon dataset.

- unmetered_wind_MWh: estimates for total generation of unmetered wind generators from National Grid Demand data.

- solar_MWh: estimates for total PV generation from National Grid Demand data.

- total_IRES_generation: sum of metered_wind_MWh, unmetered_wind_MWh, solar_MWh (in MWh)

- total_generation_MWh: calculated as the sum of all metered generation (from Elexon data), interconnection imports, unmetered wind generation and solar generation.

- IRES_penetration: calculated as total_IRES_generation/total_generation_MWh

- annual_active_baseload_gens: the number of base-load generators* which started up at least once in that calendar year.

- startups_baseload: count of base-load *startups (count of events where production changed from &lt; 1 MWh to &gt;= 1 MWh)

- load_factor_baseload: average instantenous output of base-load* generators divided by capacity during online hours only (hence measuring part-loading during operational hours)

- severe_ramping_events: defined as a change in production of &gt;= 25% of a base-load generator's capacity in consecutive settlement periods.

* base-load generators defined as coal- and gas-fired generators of at least 100 MW capacity.


![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F8127972%2F63017a82c729165f1634ecdf9bace29e%2Fbase%20load%20and%20peak%20load.png?generation=1714619217756134&alt=media)![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F8127972%2F655d785320a7b1fcd7d70c94971e1227%2FCaptu1re.JPG?generation=1714619225747612&alt=media)",.csv
Basic Computer Data,1,basic-computer-data-set,Computers.csv,other,"### For what? ###
This dataset is for basic data analysis. Student Statisticians or Data-Analysists (like myself) could use this as a basic learning point. Even ML students could predict future prices and speeds of computers. 

Unfortunately, this dataset doesn't come with dates. (which are a pain to work with anyway), But the computers are in order from earliest to latest.

I will be uploading another version with this and a more detailed CSV that has the computer name, date, and other stats.
This dataset is free to use for any purpose. 

This is simply to gain understanding in analyzing data. At least for me.

# Content #

price,
speed,
hd,
ram,
screen,
cd,
multi,
premium,
ads,
trend

### Something glorious is coming ###

The largest computer CSV? Maybe? Maybe im scrapping it right now?
Who knows?
;)",.csv
Basketball Players Stats per Season - 49 Leagues,1,basketball-players-stats-per-season-49-leagues,players_stats_by_season_full_details.csv,CC-BY-NC-SA-4.0,"### Context

I felt that Israeli players scoring Free throws in poor percentage.
with this thought, I wanted to check several Free throws analysis: Israeli players vs. other nationalities, Israeli Leagues vs. other Leagues etc.

I didn't found any free datasets that could help me to do the analyze, so I decided to create one.
as always happens to me, I created a dataset that stores a lot more than the first intention, that could support many analysis about basketball players & Leagues.
I created a dataset that stores a lot more than my first intention, this dataset could support many analysis about basketball players and Leagues.

### Content

This Dataset Includes:
1. Seasons 1999-2020
2. 49 Leagues, ~11K players details & stats per Season
3. Player Details: Birth Date, Height, Weight, Nationality, High School
4. Stats per Season: Scoring Stats, Free Throws, Rebounds, Blocks, Assists, Minutes, Games etc.
What's inside is more than just rows and columns. Make it easy for others to get started by describing how you acquired the data and what time period it represents, too.

you can find the available season per league data in the [Seasons per League - Dataset Information kernel][3]
the scraping source code is available in my [GitHub repository][4]

### Acknowledgements

Data scraped from the wonderful site: [basketball real gm][1]
Photo by [Pexels on pixabay.com][2]



  [1]: https://basketball.realgm.com/
  [2]: https://pixabay.com/photos/backboard-backlit-basketball-board-1866968/
  [3]:https://www.kaggle.com/jacobbaruch/seasons-per-league-dataset-information
  [4]:https://github.com/jacobbaruch/NBA_data_scraping_and_analysis",.csv
Basketball Players' Career Duration,1,national-basketball-association-nba,nba-players.csv,CC0-1.0,"The dataset comes from Coursera learning platform. This dataset is for learning purposes.

The National Basketball Association (NBA) is a professional basketball league in North America.

The data consists of performance statistics from each player's rookie year. There are 1,341 observations, and each observation in the data represents a different player in the NBA. The target variable is a Boolean value that indicates whether a given player will last in the league for five years.

|Column Name|Column Description|
|:---|:-------|
|`name`|Name of NBA player|
|`gp`|Number of games played|
|`min`|Number of minutes played per game|
|`pts`|Average number of points per game|
|`fgm`|Average number of field goals made per game|
|`fga`|Average number of field goal attempts per game|
|`fg`|Average percent of field goals made per game|
|`3p_made`|Average number of three-point field goals made per game|
|`3pa`|Average number of three-point field goal attempts per game|
|`3p`|Average percent of three-point field goals made per game|
|`ftm`|Average number of free throws made per game|
|`fta`|Average number of free throw attempts per game|
|`ft`|Average percent of free throws made per game|
|`oreb`|Average number of offensive rebounds per game|
|`dreb`|Average number of defensive rebounds per game|
|`reb`|Average number of rebounds per game|
|`ast`|Average number of assists per game|
|`stl`|Average number of steals per game|
|`blk`|Average number of blocks per game|
|`tov`|Average number of turnovers per game|
|`target_5yrs`|1 if career duration &gt;= 5 yrs, 0 otherwise|",.csv
Battery Remaining Useful Life (RUL),1,battery-remaining-useful-life-rul,Battery_RUL.csv,CC0-1.0,"The Hawaii Natural Energy Institute examined 14 NMC-LCO 18650 batteries with a nominal capacity of 2.8 Ah, which were cycled over 1000 times at 25°C with a CC-CV charge rate of C/2 rate and discharge rate of 1.5C. 

From that source dataset, I created features that showcase the voltage and current behaviour over each cycle. Those features can be used to predict the remaining useful life (RUL) of the batteries. The dataset contains the summary of the 14 batteries. 

**Variables:** 
- Cycle Index: number of cycle
- F1: Discharge Time (s)
- F2: Time at 4.15V (s)
- F3: Time Constant Current (s)
- F4: Decrement 3.6-3.4V (s)
- F5: Max. Voltage Discharge (V)
- F6: Min. Voltage Charge (V)
- F7: Charging Time (s)
- Total time (s)
- RUL: target

You may check on GitHub how the dataset was built: https://github.com/ignavinuales/Battery_RUL_Prediction",.csv
Bayer Leverkusen 2023/2024 Squad,1,bayer-leverkusen-20232024-squad,Bayer_Leverkusen_Squad.csv,Apache 2.0,"**The current squad of Bayer Leverkuse is as I shared below. As for the data:**

- Ages

- Names

- Positions

- Match_Played

- StartXI

- Minutes

- Penalty_Kicks_Made

- Penalty_Licks_Attempted

- Yellow_Card

- Red_Card

**You can present this data in a more descriptive way by analyzing it graphically.**

**If there are currently changing players in the last data set, you can change them too.**

# Thank you to everyone who is interested😀",.csv
Beatmaking Success Dataset,1,beatmaking-success-dataset,df_beatstars_top.csv,MIT,"## Background
A study project on web-scraping in my university. I just decided to follow my passion at the time, so I collected the info on possible success factors of beatmakers. 

## About Dataset
**Method of collection**: Web-Scraping (Selenium)  
**Date of collection**: 2022-10-11 (YYYY-MM-DD)  
**Source**: https://www.beatstars.com/top-charts   
**Number of observations:**: 372  
**Number of variables:** 17

## Variable Description
author_name - beatmaker, author of the beat  
place - place of the beat in the chart  
beat_title - title of the beat  
beat_like - number of likes on the beat  
beat_repost - number of reposts on the beat  
beat_date - release date of the beat  
beat_bpm - tempo of the the beat  
beat_key - key or tonality of the beat  
beat_plays - number of plays  
beat_title_price -  is price mentioned in the title of the beat  
beat_title_offer - is special offer mentioned in the title of the beat  
beat_title_type - is type beat mentioned in the title of the beat  
MP3 - price of MP3 version of beat  
WAV - price of WAV version of beat  
author_followers - number of followers of beatmaker's page  
author_plays - overall number of plays on betmaker's page  
author_n_tracks - overall number of beats uploaded by the author to the platform

## Research Project
Check out my project where I'm trying to figure out the success factors of beats based on this dataset. The results were not very useful, but perhaps this will inspire you to conduct a deeper analysis. Use it for good!",.csv
Behavioral Risk Factor Data: Tobacco,1,behavioral-risk-of-tobaco,Behavioral_Risk_Factor_Data__Tobacco_Use__2011_to_present_.csv,Apache 2.0,"Over the past decade, from 2011 to 2023, the Centers for Disease Control and Prevention (CDC) has meticulously tracked and evaluated tobacco-related activities through its State Tobacco Activities Tracking and Evaluation (STATE) System. This system relies on data collected from the Behavioral Risk Factor Surveillance System (BRFSS), a comprehensive state-based surveillance initiative aimed at gathering information on modifiable risk factors for chronic diseases and other leading causes of death. Specifically, the STATE System focuses on various tobacco-related topics, including prevalence rates of cigarette and e-cigarette use across different demographics, frequency of use, and attempts to quit smoking. It's important to note that the data collected from 2010 and earlier should not be compared directly with the more recent findings due to changes in methodologies.",.csv
Bengali Hate Speech Translated to English,1,bengali-hate-speech-translated-to-english,final_dataset.csv,CC0-1.0,"When evaluating hate speech detection models, translating Bengali to English offers valuable insights into model performance across languages. This process involves preserving meaning, cultural nuances, and context. Analyzing translated datasets helps assess model generalization and effectiveness, informing improvements for more inclusive online moderation.",.csv
Best Games Ever According to Wikipedia,1,best-games-ever-according-to-wikipedia,Best Games Ever According to Wikipedia.csv,Apache 2.0,"# Context
The dataset is scraped from Wikipedia.com

# Content
This dataset includes 322 games, genres and publishers.

# Acknowledgements
The data in this dataset has been scraped using BeautifulSoup from the gamespot website.",.csv
Big Profit Players: Global Organizations Dataset,1,big-profit-players-in-world,Big Profit Players in world.csv,Apache 2.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F14839888%2Fbbf117ba7f7b999c05b8adaf6dc1bef4%2FGlobal%20Organizations%20Ranked%20by%20Workforce%20Size%20(1).png?generation=1715294470686583&alt=media)

In this dataset, I have collected the top-ranked global companies with reference to their profits. here is the details of columns
1. rank: In this column, I have provided the rank of the company in numbers.
2. company: In this column, I have provided the name of the company.
3. stock symbol: In this column, I have provided the stock symbol of the company.
4. earnings: In this column, I have provided the profit of the company as of 2023, in USD billions.
5. share price: In this column, I have provided the share price of the company.
6. company origin: In this column, I have provided the name of the country where the head office of the company is based.
",.csv
BigMart Product Sales Factors,1,bigmart-product-sales-factors,data.csv,CC0-1.0,"_____
# BigMart Product Sales Factors
### Investigating the Influence of Attributes and Store Characteristics
By  [[source]](https://zenodo.org/record/6509955#.Y9Y2ctJBwUE)
_____

### About this dataset
&gt; This dataset presents a unique opportunity for data scientists to uncover the real factors that drive product sales. By exploring this data, we can identify and evaluate the impact of product attributes and store characteristics that influence sales. By analyzing weight, fat content, visibility, item types, maximum retail price (MRP), outlet size, location type and type of outlet features on sales data of 1559 products across 10 stores in different cities - all collected in 2013 by BigMart - we can create models that accurately predict product sales volumes. This dataset encourages us to dig deep and analyze how individual characteristics like item weight or size or visibility impact our ability to understand store performance measures like market share or average basket values. Finally it allows us to unpack the link between retailer strategies like promotions or deals with in-store success; giving us a true picture of what makes for successful products at different stores within different markets

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; This guide is intended to provide a helpful overview for those interested in exploring the BigMart Product Sales Factors dataset. This dataset contains sales data of 1559 products across 10 stores in different cities collected in 2013 by data scientists at BigMart. This dataset presents an exciting opportunity to explore the impact of product attributes and store characteristics on the sales of products from the way products are perceived and presented in stores to the location and outlet type. 

### Research Ideas
&gt; - Using the data to predict the optimal store set-up that would maximize product sales. By understanding the effects of product attributes, store location and outlet type, one could determine what type of products should be stocked in which particular stores in order to increase sales. 
&gt; - Utilize data analysis to examine customer buying preferences and identify what items are most popular among different cities or areas based on demographic characteristics like income or age group. This would allow for targeted prediction models for pricing, promotion and inventory stocking decisions related to those products 
&gt; - Take advantage of this data to optimize marketing strategies by determining when discounted items are more likely to sell better than full-price items, cultural differences in purchasing preferences between cities or predict future trends based on historic sales patterns using Machine Learning algorithms like Reinforcement Learning or Decision Trees

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://zenodo.org/record/6509955#.Y9Y2ctJBwUE)
&gt; 
&gt;


### License
&gt; 
&gt; 
&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: data.csv**
| Column name                   | Description                                                                        |
|:------------------------------|:-----------------------------------------------------------------------------------|
| **Item_Weight**               | Weight of the product in kilograms. (Numeric)                                      |
| **Item_Fat_Content**          | The fat content of the product. (Categorical)                                      |
| **Item_Visibility**           | The visibility of the product in store or online. (Numeric)                        |
| **Item_Type**                 | The type of product, such as limited offers or no offer. (Categorical)             |
| **Item_MRP**                  | The maximum retail price of the product. (Numeric)                                 |
| **Outlet_Establishment_Year** | The year the outlet was established. (Numeric)                                     |
| **Outlet_Size**               | The size of the outlet, either retail or supermarket. (Categorical)                |
| **Outlet_Location_Type**      | The type of location of the outlet, such as urban or rural area. (Categorical)     |
| **Outlet_Type**               | The type of outlet, such as sales departmental store or supermarket. (Categorical) |
| **Item_Outlet_Sales**         | The sales of the product in the outlet. (Numeric)                                  |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [](https://zenodo.org/record/6509955#.Y9Y2ctJBwUE).

",.csv
BiggBoss India 🇮🇳 Indian languages dataset,1,bigg-boss-india-hindi-telugu-tamil-kannada,Bigg_Boss_India.csv,CC0-1.0,"# Bigg Boss India series - Telugu/Tamil/Kannada/Hindi/Malayalam/Marathi/Bengali Data sets.

**Do you like to predict Bigg Boss winner using any Machine/Deep Learning algorithm ? or visualize Bigg Boss India seasons data**

BiggBoss India - data set of all Indian (Big Brother) versions and seasons.

There are 1077 rows/observations and 40 columns/features in the dataset.

अ Bigg Boss Hindi Season 1/2/3/4/5/6/7/8/9/10/11/12/13/14/15/16/17 and Halla bol, BiggBoss OTT season 1 and 2

ಅ Bigg Boss Kannada Season 1/2/3/4/5/6/7/8/9/10 and OTT

అ Bigg Boss Telugu Season 1/2/3/4/5/6/7 and Non-Stop

அ Bigg Boss Tamil  Season 1/2/3/4/5/6/7 and Ultimate

അ Bigg Boss Malayalam Season 1/2/3/4/5

अ Bigg Boss Marathi Season 1/2/3/4/5

অ Bigg Boss Bangla Season 1/2/3


Here is the data dictionary for Big Boss (India) season's dataset.

- Language - Language in which the show was telecasted/designed
- Season Number - Season number
- Name - Name of participant, at the time of season. Original Entrants are sorted in alphabetical order (no guest participants)
- Profession - Profession of house mate, before entering into Bigg Boss
- Gender - Gender of the BiggBoss contestant, such as Male, Female, LGBT
- Age - Contestant age, at the time of entering into Bigg Boss, &lt;30 young, 30-50 middle, &gt;50 old
- Entry Date - Date of (first) entry into house
- Elimination Date - Date of (last) elimination/eviction
- Elimination Week Number - (Last) Eviction week number
- Contestant Number - Order of entry in the season
- Wild Card - Entered through wild card or not
- Season Length - Number of days of season
- Number of Housemates - Total number of house mates, in entire season, including wildcard entries
- Season Start Date - Season start date
- Season End Date - Season last day or finale day or discontinued date
- Host Name - Name of the host (who hosted most of the weekend episodes)
- Guest Host Name - Name of the guest/temporary host
- Prize Money (INR) - Total prize money, in INR
- Broadcasted By - TV channel name who has broadcasted the season (in India)
- OTT Platform - OTT platform who has premiered the season (in India)
- Average TRP - Average TV TRP of the season
- Most Viewed States - Most viewed Indian States
- House Location - Physical locality of bigg boss house
- OTT Season - Is this season premiered/live only in OTT (eventually in TV)?
- Season Slogan - Slogan or tagline of the season
- Season Theme - Theme of Bigg Boss house
- Number of Evictions Faced - Number of Evictions Faced by the Bigg Boss housemate
- Number of Times Elected as Captain - Number of times/weeks elected as Captain
- Number of Re-entries - Number of reentries into the house, in the same season (not fake evictions & secret room stay)
- Walked - Walked out of BB house, exiting without elimination, due to health/personal reasons
- Ejected - Ejected from BB house, exiting without elimination (0 - No, 1 - Yes), due to violation/legal issues
- In Secret-Room - Whether stayed in secret room or not (0 - No, 1 - Yes)
- Won Eviction Free Pass - Housemate won eviction free pass or not (0 - No, 1 - Yes), got immunity
- Won Ticket to Finale - Housemate won ticket to finale or not (0 - No, 1 - Yes)
- Number of times Best Performer - Number of times Best/top Performer received
- Number of times Worst Performer - Number of times Worst/weak Performer received, went to jail
- Secret Task - Involved in secret task and it's status (Success or Fail)
- Social Media Popularity - Popularity in Social media of finalist (1 - lowest, 10 - highest) during the show
- Finalist - Whether entered into final week or not, or in finale (0 - No, 1 - Yes)
- Winner - Winner or not (1 - winner, 0 - otherwise), whoever took highest prize money",.csv
Biggest Companies by Market Cap and Their Revenue,1,biggest-companies-by-market-cap-and-their-revenue,company_data.csv,CC0-1.0,"This dataset presents a list of the biggest companies ranked by market capitalization, along with their corresponding revenue figures. Each entry includes the company's name, stock symbol, market capitalization, revenue, and other relevant financial metrics. The dataset provides valuable insights into the largest companies in terms of market value and their respective revenue performances, offering valuable information for investors, analysts, and researchers interested in understanding the financial landscape of prominent corporations.",.csv
Bigmac Prices,1,bigmacprice,BigmacPrice.csv,CC0-1.0,"Mcdonalds' BigMac prices in many countries. It might be interesting to look at the price evolution over time, possibly investigating up and down and having a look at other economic indicators.",.csv
Bike Prepared,1,bike-prepared,bike_prepared.csv,CC-BY-NC-SA-4.0,"The original trip data is from biketownpdx.com/system-data. This dataset is cleaned and prepared for a K-means clustering, ANOVA test, and Tukey HSD test project.

7411 rows x 6 columns.

**Variables:**
- routeid: The unique identifier for an E-bike rental in the Dataset. (Null values exist for rows representing station data only.)
- starthub: The E-bike station names. 'NoHub' variable indicates that the geolocation coordinates are not at a station.
- startdate: The date when the E-bike rental started.
- start_latitude: The starting location of the E-bike rental with its latitude coordinates in the EPSG: 4326 coordinate reference system.
- start_longitude: The starting location of the E-bike rental with its longitude coordinates in the EPSG: 4326 coordinate reference system.
- distance_miles: The distance that was covered during a specific rental period.",.csv
Bike rentals,1,bike-rentals,Yulu.csv,other,"About Yulu

Yulu is India’s leading micro-mobility service provider, which offers unique vehicles for the daily commute. Starting off as a mission to eliminate traffic congestion in India, Yulu provides the safest commute solution through a user-friendly mobile app to enable shared, solo and sustainable commuting.

Yulu zones are located at all the appropriate locations (including metro stations, bus stands, office spaces, residential areas, corporate offices, etc) to make those first and last miles smooth, affordable, and convenient!

Yulu has recently suffered considerable dips in its revenues. They have contracted a consulting company to understand the factors on which the demand for these shared electric cycles depends. Specifically, they want to understand the factors affecting the demand for these shared electric cycles in the Indian market.",.csv
"Billboard ""The Hot 100"" Songs",1,billboard-the-hot-100-songs,charts.csv,CC-BY-NC-SA-4.0,"## Content

The Billboard Hot 100 is the music industry standard record chart in the United States for songs, published weekly by Billboard magazine. Chart rankings are based on sales, radio play, and online streaming in the United States.

Every week, [Billboard](https://www.billboard.com/) releases ""The Hot 100"" chart of songs that were trending on sales and airplay for that week. This dataset is a collection of all ""The Hot 100"" charts released since its inception in 1958.

[Starter Notebook + Basic EDA](https://www.kaggle.com/dhruvildave/starter-basic-eda-billboard)

## Acknowledgements

Image credits: [Photo by Stas Knop from Pexels](https://www.pexels.com/photo/black-cassette-tape-on-top-of-red-and-yellow-surface-1626481/)",.csv
Billionaires Statistics Dataset,1,billionaires-statistics-dataset,Billionaires Statistics Dataset.csv,MIT,"Certainly! Here's a description of each column:


**Rank:** The numerical ranking of a person or entity in a list or category.

**finalWorth:** The final worth or net worth of a person or entity, typically in terms of monetary value.

**category:** The category or classification of a person or entity, such as ""entrepreneur"", ""investor"", ""celebrity"", etc.

**personName:** The name of a person.

**age:** The age of a person.

**country:** The country of residence or origin of a person or entity.

**city:** The city of residence or origin of a person or entity.

**source:** The source or origin of wealth or fame for a person or entity.

**industries:** The industries or sectors in which a person or entity operates or is associated with.

**countryOfCitizenship:** The country of citizenship of a person.

**organization:** The organization or company with which a person is associated.

**selfMade:** Indicates whether a person is self-made or inherited wealth/fame.

**status: **The status or position of a person or entity, such as ""CEO"", ""founder"", ""chairman"", etc.

**gender:** The gender of a person.

**birthDate: **The date of birth of a person.

**lastName:** The last name or surname of a person.

**firstName: **The first name of a person.

**title:** The title or honorific used for a person, such as ""Mr."", ""Mrs."", ""Dr."", etc.

**date:** The date associated with a particular event or data entry.

**state: **The state or region of residence or origin of a person or entity.

**residenceStateRegion:** The state or region of residence of a person or entity.

**birthYear:** The year of birth of a person.

**birthMonth:** The month of birth of a person.

**birthDay: **The day of birth of a person.

**cpi_country: **Consumer Price Index (CPI) for a specific country.

**cpi_change_country:** Change in Consumer Price Index (CPI) for a specific country.

**gdp_country: **Gross Domestic Product (GDP) for a specific country.

**gross_tertiary_education_enrollment: **Gross tertiary education enrollment rate for a specific country.

**gross_primary_education_enrollment_country:** Gross primary education enrollment rate for a specific country.

**life_expectancy_country: **Life expectancy for a specific country.

**tax_revenue_country_country:** Tax revenue for a specific country.

**total_tax_rate_country: **Total tax rate for a specific country.

**population_country:** Population of a specific country.

**latitude_country: **Latitude coordinates of a specific country.

**longitude_country: **Longitude coordinates of a specific country.


These columns appear to contain various attributes and metrics related to individuals, countries, and economic indicators.",.csv
Binary Classification Dataset,1,binary-classification-dataset,s.csv,MIT,"Within this tabular dataset, each entry is identified by a unique ID number, alongside its corresponding signal strength measurement, providing valuable insights into the characteristics of detected pulsar signals",.csv
Bird Flu Dataset (Avian Influenza),1,bird-flu-dataset-avian-influenza,Avian Influenza (HPAI).csv,MIT,"This dataset provides comprehensive insights into the distribution and potential spread of avian influenza, commonly known as ""Bird Flu,"" in Ireland. Avian influenza is a highly contagious and often fatal viral disease primarily affecting birds, with wild migratory water birds being the main reservoir of the virus. 

The dataset includes information about bird species captured in Ireland from 1980 to 2020, focusing on species targeted for the H5N1 strain of avian flu. Understanding the geographic distribution of these bird species is crucial for assessing the risk of avian influenza introduction into Ireland, especially during migratory seasons when wild birds arrive and congregate on wetlands, potentially mixing with resident species. 

This dataset serves as a valuable resource for conducting comprehensive research and risk assessment related to avian influenza in Ireland.",.csv
Birds' Bones and Living Habits,1,birds-bones-and-living-habits,bird.csv,other,"### Context 

There are many kinds of birds: pigeons, ducks, ostriches, penguins... Some are good at flying, others can't fly but run fast. Some swim under water, others wading in shallow pool. 

According to their living environments and living habits, birds are classified into different ecological groups. There are 8 ecological groups of birds:

- Swimming Birds
- Wading Birds
- Terrestrial Birds
- Raptors
- Scansorial Birds
- Singing Birds
- Cursorial Birds (*not included in dataset*)
- Marine Birds (*not included in dataset*)

First 6 groups are main and are covered by this dataset.

Apparently, birds belong to different ecological groups have different appearances: flying birds have strong wings and wading birds have long legs. Their living habits are somewhat reflected in their bones' shapes. As data scientists we may think of examining the underlying relationship between sizes of bones and ecological groups , and recognising birds' ecological groups by their bones' shapes.

### Content

There are 420 birds contained in this dataset. Each bird is represented by 10 measurements (*features*):

- Length and Diameter of Humerus
- Length and Diameter of Ulna
- Length and Diameter of Femur
- Length and Diameter of Tibiotarsus
- Length and Diameter of Tarsometatarsus

![Pigeon skeleton][1]

All measurements are continuous float numbers (mm) with missing values represented by empty strings. The skeletons of this dataset are collections of *Natural History Museum of Los Angeles County*. They belong to 21 orders, 153 genera, 245 species.

Each bird has a label for its ecological group:

- *SW*: Swimming Birds
- *W*: Wading Birds
- *T*: Terrestrial Birds
- *R*: Raptors
- *P*: Scansorial Birds
- *SO*: Singing Birds


### Acknowledgements

This dataset is provided by **Dr. D. Liu** of *Beijing Museum of Natural History*.


### Inspiration

This dataset is a 420x10 size continuous values unbalanced multi-class dataset. What can be done include:

- Data Visualisation
- Statical Analysis
- Supervised Classification
- Unsupervised Clustering

### License

**Please do not publish or cite this dataset in research papers or other public publications.**


  [1]: https://s-media-cache-ak0.pinimg.com/564x/cb/cb/41/cbcb41cb2c1db6c32c1e869be2172c3b.jpg",.csv
Bitcoin & Fear and Greed ,1,bitcoin-and-fear-and-greed,dataset.csv,CC0-1.0,"# Context 
This Dataset is being collected Two Sources
1. Yahoo Finance
2. Alternative.me 

# Content
This dataset specifically includes daily closing prices of Bitcoin, as well as daily volumes of Bitcoin, and the Fear and Greed Index values for the overall crypto market. This dataset presents a unique opportunity for researchers and analysts to explore the relationship between the prices and volumes of Bitcoin, as well as the sentiment of the overall crypto market. By conducting thorough analysis of this dataset, researchers and analysts can gain valuable insights into the behavior and trends of the cryptocurrency market. This includes examining the daily closing prices and volumes of Bitcoin, as well as the Fear and Greed Index values for the overall crypto market. Through comprehensive analysis, potential patterns, trends, and correlations between price movements, trading volumes, and market sentiment can be identified. These insights can inform investment strategies and decision-making, providing a more nuanced understanding of the dynamics of the cryptocurrency market. This data presents a unique opportunity for researchers and analysts to uncover valuable information that can contribute to a deeper understanding of the cryptocurrency market and its potential implications for investment decision-making.

# Data Collection Strategy
The data collection strategy for this dataset involves gathering daily market closing prices and volume data of Bitcoin and collection daily crypto market fear and greed index.

# Measurement of Fear and Greed Index
To understand the methodology behind measuring the Fear and Greed Index, please refer to the official link at https://alternative.me/crypto/fear-and-greed-index/

# Copyright Disclaimer
A part of this dataset is produced and maintained by the administrators of https://alternative.me/crypto/fear-and-greed-index/.
",.csv
Bitcoin Historical Data,1,bitcoin-historical-data,Bitcoin History.csv,CC0-1.0,"This dataset, sourced from Investing.com, provides a detailed record of Bitcoin's daily price movements. Capturing key metrics such as opening, closing, high, low prices, and trading volume, the dataset spans from July 18, 2010, to February 9, 2024. It offers a comprehensive view of Bitcoin's market behavior, allowing researchers, analysts, and enthusiasts to delve into historical trends, patterns, and fluctuations.

Key Features:

Daily Open, Close, High, Low Prices
Daily Trading Volume
Percentage Change
Use Cases:

Analyze long-term market trends and patterns
Investigate the impact of external factors on Bitcoin prices
Build predictive models based on historical data
Conduct research on cryptocurrency market dynamics
Note to Users:
Please note that cryptocurrency investments are inherently risky, and past performance is not indicative of future results. This dataset is intended for research and analysis purposes only.

Acknowledgments:
The dataset is sourced from Investing.com and is made available to the Kaggle community for research and educational purposes.

Explore the world of Bitcoin market dynamics by leveraging this extensive dataset. Your insights and discoveries contribute to our collective understanding of cryptocurrency markets.",.csv
Bitcoin Historical Prices & Activity (2010-2024),1,bitcoin-historical-prices-and-activity-2010-2024,bitcoin_2010-07-27_2024-04-25.csv,MIT,"### Dataset Description
This comprehensive dataset captures over a decade of Bitcoin's trading activity, meticulously detailing daily market statistics from July 27, 2010, to April 25, 2024. It provides an in-depth look at Bitcoin's price movements, trading volumes, and market capitalizations through various economic climates. The data covers over 5,021 days, reflecting the cryptocurrency's fluctuations from its early adoption phases to its establishment as a major financial asset. Each record in the dataset consists of the following fields:

- **Start**: Indicates the start date of the data record.
- **End**: Indicates the end date of the data record.
- **Open**: The price at which Bitcoin started trading at the beginning of the day.
- **High**: The highest price point reached by Bitcoin during the day.
- **Low**: The lowest price point reached by Bitcoin during the day.
- **Close**: The price at which Bitcoin ended trading at the close of the day.
- **Volume**: Total volume of Bitcoin traded during the day.
- **Market Cap**: The total market value of Bitcoin at the end of the day.

This dataset is ideal for users interested in analyzing trends, performing market predictions, or studying the impacts of global events on cryptocurrency values. It serves as a vital resource for financial analysts, economic researchers, data scientists, and academics looking to explore the complexities of cryptocurrency markets.",.csv
Bitcoin Price Dataset ,1,bitcoin-stock-data-sept-17-2014-august-24-2021,BTC-USD.csv,ODbL-1.0,"### Context

This is Bitcoin Dataset of Future Price Prediction


### Content

What's inside is more than just rows and columns. Make it easy for others to get started by describing how you acquired the data and what time period it represents, too.


### Acknowledgements

We wouldn't be here without the help of others. If you owe any attributions or thanks, include them here along with any citations of past research.


### Inspiration

Your data will be in front of the world's largest data science community. What questions do you want to see answered?",.csv
Bitcoin Price History (BTC-USD),1,bitcoin-price-history-btc-usd,BTC-USD.csv,MIT,"## The Decade of Digital Disruption: Bitcoin's Volatile USD Pricing 2014-2024

This comprehensive dataset chronicles the seismic shifts in Bitcoin's daily valuation against the US dollar over the pivotal decade from 2014 to 2024. As the pioneering cryptocurrency sparked a revolution challenging traditional finance, its pricing has exhibited unparalleled volatility and captured the public's fervor.

Within this dataset, you'll find over 3,650 rows meticulously recording Bitcoin's opening, closing, high, and low prices denominated in USD for each day spanning 10 years. It encapsulates the entire trajectory - from Bitcoin's humble beginnings trading for just a few hundred dollars, through its multiple boom and bust cycles hitting record highs above $60,000, to its performance amid the turbulence of recent years.

More than just raw daily pricing data, this collection provides valuable context by including:

- Total trading volume in USD
- Bitcoin's market capitalization
- Major regulatory and adoption milestones
- Significant events like Bitcoin halvings

Whether you're a quant researching pioneering crypto models, an investor seeking alpha from patterns, or a finance historian documenting this era's disruption, this day-by-day dataset allows you to analyze one of the most captivating assets of the modern age. Dive into the thrills of Bitcoin's transformative first decade priced in US dollars!",.csv
Bitcoin daily (Jul 2010-Mar 2024),1,bitcoin-daily-price-and-vol-jul-2010-mar-2024,btc.csv,CC0-1.0,"The longest Bitcoin price series on Kaggle. Collected from various sources - so you don't have to.

Open, High, Low, Close prices (in US Dollars) and trading Volume data.

Is bitcoin a scam or the new gold? Is it a good asset for investments? 
Can you mine the seasonality patterns? Can you predict the price of bitcoin next year? Would it help to augment this series with exogeneous data, for instance, summary of SEC conferences or Elon Musk's ~~tweets~~ posts?
Can the bitcoin price be handy to *predict* other events, for instance, the sentiment in the news? 
Let's find out!

**Sources**
7.2010-09.2014: [Investing.com](https://www.investing.com/crypto/bitcoin/historical-data)
09.2014-03.2014: YahooFinance API (with yfinance)",.csv
Bitext Gen AI Chatbot Customer Support Dataset,1,bitext-gen-ai-chatbot-customer-support-dataset,Bitext_Sample_Customer_Support_Training_Dataset_27K_responses-v11.csv,Community Data License Agreement - Sharing - Version 1.0,"# Bitext - Customer Service Tagged Training Dataset for LLM-based Virtual Assistants

## Overview

This dataset can be used to train Large Language Models such as GPT, Llama2 and Falcon, both for Fine Tuning and Domain Adaptation.

The dataset has the following specs:

- Use Case: Intent Detection
- Vertical: Customer Service
- 27 intents assigned to 10 categories
- 26872 question/answer pairs, around 1000 per intent
- 30 entity/slot types
- 12 different types of language generation tags

The categories and intents have been selected from Bitext's collection of 20 vertical-specific datasets, covering the intents that are common across all 20 verticals. The verticals are:

- Automotive, Retail Banking, Education, Events & Ticketing, Field Services, Healthcare, Hospitality, Insurance, Legal Services, Manufacturing, Media Streaming, Mortgages & Loans, Moving & Storage, Real Estate/Construction, Restaurant & Bar Chains, Retail/E-commerce, Telecommunications, Travel, Utilities, Wealth Management

For a full list of verticals and its intents see [https://www.bitext.com/chatbot-verticals/](https://www.bitext.com/chatbot-verticals/).

The question/answer pairs have been generated using a hybrid methodology that uses natural texts as source text, NLP technology to extract seeds from these texts, and NLG technology to expand the seed texts. All steps in the process are curated by computational linguists.

## Dataset Token Count

The dataset contains an extensive amount of text data across its 'instruction' and 'response' columns. After processing and tokenizing the dataset, we've identified a total of 3.57 million tokens. This rich set of tokens is essential for training advanced LLMs for AI Conversational, AI Generative, and Question and Answering (Q&A) models.

## Fields of the Dataset

Each entry in the dataset contains the following fields:

- flags: tags (explained below in the Language Generation Tags section)
- instruction: a user request from the Customer Service domain
- category: the high-level semantic category for the intent
- intent: the intent corresponding to the user instruction
- response: an example expected response from the virtual assistant

## Categories and Intents

The categories and intents covered by the dataset are:

- ACCOUNT: create_account, delete_account, edit_account, recover_password, registration_problems, switch_account
- CANCELLATION_FEE: check_cancellation_fee
- CONTACT: contact_customer_service, contact_human_agent
- DELIVERY: delivery_options, delivery_period
- FEEDBACK: complaint, review
- INVOICE: check_invoice, get_invoice
- ORDER: cancel_order, change_order, place_order, track_order
- PAYMENT: check_payment_methods, payment_issue
- REFUND: check_refund_policy, get_refund, track_refund
- SHIPPING_ADDRESS: change_shipping_address, set_up_shipping_address
- SUBSCRIPTION: newsletter_subscription

## Entities

The entities covered by the dataset are:

- {{Order Number}}, typically present in:
- Intents: cancel_order, change_order, change_shipping_address, check_invoice, check_refund_policy, complaint, delivery_options, delivery_period, get_invoice, get_refund, place_order, track_order, track_refund
- {{Invoice Number}}, typically present in:
  - Intents: check_invoice, get_invoice
- {{Online Order Interaction}}, typically present in:
  - Intents: cancel_order, change_order, check_refund_policy, delivery_period, get_refund, review, track_order, track_refund
- {{Online Payment Interaction}}, typically present in:
  - Intents: cancel_order, check_payment_methods
- {{Online Navigation Step}}, typically present in:
  - Intents: complaint, delivery_options
- {{Online Customer Support Channel}}, typically present in:
  - Intents: check_refund_policy, complaint, contact_human_agent, delete_account, delivery_options, edit_account, get_refund, payment_issue, registration_problems, switch_account
- {{Profile}}, typically present in:
  - Intent: switch_account
- {{Profile Type}}, typically present in:
  - Intent: switch_account
- {{Settings}}, typically present in:
  - Intents: cancel_order, change_order, change_shipping_address, check_cancellation_fee, check_invoice, check_payment_methods, contact_human_agent, delete_account, delivery_options, edit_account, get_invoice, newsletter_subscription, payment_issue, place_order, recover_password, registration_problems, set_up_shipping_address, switch_account, track_order, track_refund
- {{Online Company Portal Info}}, typically present in:
  - Intents: cancel_order, edit_account
- {{Date}}, typically present in:
  - Intents: check_invoice, check_refund_policy, get_refund, track_order, track_refund
- {{Date Range}}, typically present in:
  - Intents: check_cancellation_fee, check_invoice, get_invoice
- {{Shipping Cut-off Time}}, typically present in:
  - Intent: delivery_options
- {{Delivery City}}, typically present in:
  - Intent: delivery_options
- {{Delivery Country}}, typically present in:
  - Intents: check_payment_methods, check_refund_policy, delivery_options, review, switch_account
- {{Salutation}}, typically present in:
  - Intents: cancel_order, check_payment_methods, check_refund_policy, create_account, delete_account, delivery_options, get_refund, recover_password, review, set_up_shipping_address, switch_account, track_refund
- {{Client First Name}}, typically present in:
  - Intents: check_invoice, get_invoice
- {{Client Last Name}}, typically present in:
  - Intents: check_invoice, create_account, get_invoice
- {{Customer Support Phone Number}}, typically present in:
  - Intents: change_shipping_address, contact_customer_service, contact_human_agent, payment_issue
- {{Customer Support Email}}, typically present in:
  - Intents: cancel_order, change_shipping_address, check_invoice, check_refund_policy, complaint, contact_customer_service, contact_human_agent, get_invoice, get_refund, newsletter_subscription, payment_issue, recover_password, registration_problems, review, set_up_shipping_address, switch_account
- {{Live Chat Support}}, typically present in:
  - Intents: check_refund_policy, complaint, contact_human_agent, delete_account, delivery_options, edit_account, get_refund, payment_issue, recover_password, registration_problems, review, set_up_shipping_address, switch_account, track_order
- {{Website URL}}, typically present in:
  - Intents: check_payment_methods, check_refund_policy, complaint, contact_customer_service, contact_human_agent, create_account, delete_account, delivery_options, get_refund, newsletter_subscription, payment_issue, place_order, recover_password, registration_problems, review, switch_account
- {{Upgrade Account}}, typically present in:
  - Intents: create_account, edit_account, switch_account
- {{Account Type}}, typically present in:
  - Intents: cancel_order, change_order, change_shipping_address, check_cancellation_fee, check_invoice, check_payment_methods, check_refund_policy, complaint, contact_customer_service, contact_human_agent, create_account, delete_account, delivery_options, delivery_period, edit_account, get_invoice, get_refund, newsletter_subscription, payment_issue, place_order, recover_password, registration_problems, review, set_up_shipping_address, switch_account, track_order, track_refund
- {{Account Category}}, typically present in:
  - Intents: cancel_order, change_order, change_shipping_address, check_cancellation_fee, check_invoice, check_payment_methods, check_refund_policy, complaint, contact_customer_service, contact_human_agent, create_account, delete_account, delivery_options, delivery_period, edit_account, get_invoice, get_refund, newsletter_subscription, payment_issue, place_order, recover_password, registration_problems, review, set_up_shipping_address, switch_account, track_order, track_refund
- {{Account Change}}, typically present in:
  - Intent: switch_account
- {{Program}}, typically present in:
  - Intent: place_order
- {{Refund Amount}}, typically present in:
  - Intent: track_refund
- {{Money Amount}}, typically present in:
  - Intents: check_refund_policy, complaint, get_refund, track_refund
- {{Store Location}}, typically present in:
  - Intents: complaint, delivery_options, place_order

## Language Generation Tags

The dataset contains tags that reflect how language varies/changes across different linguistic phenomena like colloquial or offensive language. So if an utterance for intent “cancel_order” contains the “COLLOQUIAL” tag, the utterance will express an informal language variation like: “can u cancel my order”.

These tags indicate the type of language variation that the entry expresses. When associated to each entry, they allow Conversational Designers to customize training datasets to different user profiles with different uses of language. Through these tags, many different datasets can be created to make the resulting assistant more accurate and robust. A bot that sells sneakers should be mainly targeted to younger population that use a more colloquial language; while a classical retail banking bot should be able to handle more formal or polite language. The dataset also reflects commonly occurring linguistic phenomena of real-life virtual assistant, such as spelling mistakes, run-on words, punctuation errors…

The dataset contains tagging for all relevant linguistic phenomena that can be used to customize the dataset for different user profiles.

### Tags for Lexical variation

M - Morphological variation: inflectional and derivational
“is my SIM card active”, “is my SIM card activated”

L - Semantic variations: synonyms, use of hyphens, compounding…
“what’s my billing date"", “what’s my anniversary date”

### Tags for Syntactic structure variation

B - Basic syntactic structure:
“activate my SIM card”, “I need to activate my SIM card”

I - Interrogative structure
“can you activate my SIM card?”, “how do I activate my SIM card?”

C - Coordinated syntactic structure
“I have a new SIM card, what do I need to do to activate it?”

N - Negation
“I do not want this item, where to cancel my order?”

### Tags for language register variations

P - Politeness variation
“could you help me activate my SIM card, please?”

Q - Colloquial variation
“can u activ8 my SIM?”

W - Offensive language
“I want to talk to a f*&%*g agent”

### Tags for stylistic variations

K - Keyword mode
""activate SIM"", ""new SIM""

E - Use of abbreviations:
“I'm / I am interested in getting a new SIM”

Z - Errors and Typos: spelling issues, wrong punctuation…
“how can i activaet my card”

### Other tags not in use in this Dataset

D - Indirect speech
“ask my agent to activate my SIM card”

G - Regional variations
US English vs UK English: ""truck"" vs ""lorry""
France French vs Canadian French: ""tchatter"" vs ""clavarder""

R - Respect structures - Language-dependent variations
English: ""may"" vs ""can…""
French: ""tu"" vs ""vous...""
Spanish: ""tú"" vs ""usted...""

Y - Code switching
“activer ma SIM card”

---

(c) Bitext Innovations, 2024",.csv
Blood Composition Vs Diabetic Status,1,blood-composition-vs-diabetic-status,Blood Contant.csv,MIT,"Comprehensive collection of health-related data with a focus on diabetes. Here’s a brief description:

Gender: The biological sex of the individuals in the dataset.
AGE: The age of the individuals.
Urea: A measure of urea level in the blood, which is a waste product formed in the liver when protein is metabolized.
Cr (Creatinine): A chemical waste product that’s produced by your muscle metabolism and to a smaller extent by eating meat.
HbA1c (Glycated Hemoglobin): A form of hemoglobin that is chemically linked to a sugar. The higher the level of glucose in the blood, the higher the level of HbA1c.
Chol (Cholesterol): A measure of the total cholesterol in the blood, which includes LDL (bad cholesterol) and HDL (good cholesterol).
TG (Triglycerides): A type of fat found in your blood.
HDL (High-Density Lipoprotein): Often referred to as ‘good cholesterol’.
LDL (Low-Density Lipoprotein): Often referred to as ‘bad cholesterol’.
VLDL (Very Low-Density Lipoprotein): A type of lipoprotein known for transporting triglycerides.
BMI (Body Mass Index): A measure calculated using weight and height.
Diabetic Status: The status of diabetes in the individuals, likely represented as a binary variable (e.g., Yes/No or 1/0).
This dataset would be valuable for medical research, particularly in studying the risk factors and effects of diabetes. It could also be used to develop predictive models for diabetes risk based on various health parameters. Please note that the exact contents of the dataset would need to be confirmed by examining the actual files.",.csv
Blood Dataset,1,blood-dataset,blood.csv,Apache 2.0,"Blood datasets typically encompass a broad array of information related to hematology, blood chemistry, and related health indicators. These datasets often include data points such as blood cell counts, hemoglobin levels, hematocrit, platelet counts, white blood cell differentials, and various blood chemistry parameters such as glucose, cholesterol, and electrolyte levels.

These datasets are invaluable for medical research, clinical diagnostics, and public health initiatives. Researchers and healthcare professionals utilize blood datasets to study hematological disorders, monitor disease progression, assess treatment efficacy, and identify risk factors for various health conditions.

Machine learning techniques are often applied to blood datasets to develop predictive models for diagnosing diseases, predicting patient outcomes, and identifying biomarkers associated with specific health conditions. These models can assist clinicians in making more accurate diagnoses, designing personalized treatment plans, and improving patient care.

Additionally, blood datasets play a crucial role in epidemiological studies and population health research. By analyzing large-scale blood datasets, researchers can identify trends in blood parameters across different demographic groups, assess the prevalence of blood disorders, and evaluate the impact of lifestyle factors and environmental exposures on hematological health.

Overall, blood datasets serve as valuable resources for advancing our understanding of hematology, improving healthcare practices, and promoting better health outcomes for individuals and populations.",.csv
Board Games,1,board-games,bgg_dataset.csv,Attribution 4.0 International (CC BY 4.0),"# About this dataset
&gt; This dataset contains data collected on board games from the BoardGameGeek (BGG) website in February 2021. BGG is the largest online collection of board game data which consists of data on more than 100,000 total games (ranked and unranked).

&gt; The voluntary online community contributes to the site with reviews, ratings, images, videos, session reports and live discussion forums on the expanding database of board games.

&gt; This data set contains all ranked games (~20,000) as of the date of collection from the BGG database. Unranked games are ignored as they have not been rated by enough BGG users (a game should receive at least 30 votes to be eligible for ranking).



# How to use this dataset
&gt; - Predict board game rating based on its mechanics and features.
- Explore the landscape of board games


# Highlighted Notebooks
&gt; - [Board Game Analysis](https://www.kaggle.com/karnikakapoor/board-games-analysis/) by [Karnika Kapoor](https://www.kaggle.com/karnikakapoor)
- [More datasets](https://www.kaggle.com/andrewmvd/datasets)



# Acknowledgements
If you use this dataset in your research, please credit the authors
&gt; ### Citation

&gt; Dilini Samarasinghe, July 5, 2021, ""BoardGameGeek Dataset on Board Games"", IEEE Dataport, doi: https://dx.doi.org/10.21227/9g61-bs59.



&gt; ### License
CC BY 4.0


&gt; ### Splash banner
Icon by [Freepik](https://www.flaticon.com/authors/freepik) on [FlatIcon](https://www.flaticon.com/free-icon/board-game_1390283).",.csv
Body Measurements Dataset,1,body-measurements-dataset,Body Measurements _ original_CSV.csv,Attribution 4.0 International (CC BY 4.0),"### Context

Attribute information:

Gender 				(Male and Female (M=1 & F= 2) (391 Males & 324 Females)	
Age 				(1 year and above)	
HeadCircumference 		(in inches) 	
ShoulderWidth 			(in inches)	
ChestWidth			(in inches) 	
Belly 				(in inches)	
Waist 				(in inches)
Hips 				(in inches)
ArmLength 			(in inches)
ShoulderToWaist 			(in inches)
WaistToKnee 			(in inches)
LegLength			(in inches)
TotalHeight - from head to toe	(in inches)
Class Label 			(Not defined)	


Dataset Characteristics: Multivariate, Numerical 
Attribute Characteristics: Real 
Associated Tasks: Classification, Regression 
Number of Instances: 13
Number of Attributes: 716
Missing Values: No
Domain: cross domain 


### Acknowledgements

Kiru, Muhammad  (2021), “Body Measurements Datasets”, Mendeley Data, V1, doi: 10.17632/bjv6c9pmp4.1

",.csv
Body performance Data,1,body-performance-data,bodyPerformance.csv,CC0-1.0,"## dataset

This is data that confirmed the grade of performance with age and some exercise performance data.


## columns

**data shape : (13393, 12)**

- age : 20 ~64 
- gender : F,M
- height_cm : (If you want to convert to feet, divide by 30.48)
- weight_kg 
- body fat_%
- diastolic : diastolic blood pressure (min)
- systolic : systolic blood pressure (min)
- gripForce
- sit and bend forward_cm
- sit-ups counts
- broad jump_cm
- class : A,B,C,D ( A: best) / stratified

### Source
[link](https://www.bigdata-culture.kr/bigdata/user/data_market/detail.do?id=ace0aea7-5eee-48b9-b616-637365d665c1) (Korea Sports Promotion Foundation)
Some post-processing and filtering has done from the raw data.













",.csv
Body signal of smoking,1,body-signal-of-smoking,smoking.csv,CC0-1.0,"## dataset

This dataset is a collection of basic health biological signal data. 
The goal is to determine the presence or absence of smoking through bio-signals.    
    
The dataset is divided into type.    
1. entire dataset(smoking.csv)     
2. the competition format(competition_format) 




## columns

**data shape : (55692, 27)**
- ID : index    
- gender    
- age : 5-years gap  
- height(cm)
- weight(kg)
- waist(cm) : Waist circumference length
- eyesight(left)
- eyesight(right)
- hearing(left)
- hearing(right)
- systolic : Blood pressure
- relaxation : Blood pressure
- fasting blood sugar
- Cholesterol : total
- triglyceride
- HDL : cholesterol type
- LDL : cholesterol type
- hemoglobin
- Urine protein
- serum creatinine
- AST : glutamic oxaloacetic transaminase type
- ALT : glutamic oxaloacetic transaminase type
- Gtp : γ-GTP
- oral : Oral Examination status
- dental caries 
- tartar : tartar status
- smoking



### Source
[link](https://www.data.go.kr/data/15007122/fileData.do)
Some post-processing and filtering has done from the raw data.







",.csv
Boeing Corporation Stocks,1,boeing-corporation-stocks,BA.csv,CC0-1.0,"This dataset contains information about the Boeing stocks from 1990 to 2024. The columns are as follows:

```Date``` - The date

```Open``` - The opening value

```High``` - The highest value

```Low``` - The lowest value

```Close``` - The closing value

```Adj Close``` - The adjusted closing value

```Volume``` - The trading volume of the stocks

I hope you will like this dataset. God bless you.",.csv
Bollywood Movie List (1920-2024),1,bollywood-movie-list-1920-2024,Bollywood Movie List (1920-2024).csv,CC0-1.0,"This is a collection of Bollywood movie names, years, and genres.
In the dataframe, there are 12 NaN in the title and 1548 NaN in the genre.
In the Genre column, multiple genres are separated by "" "" (space) not "","" (comma).",.csv
Bollywood Movies till 2024,1,bollywood-movies-till-2024,Bollywood Movie List (1920-2024).csv,MIT,"
The dataset contains information about Bollywood movies from 1920 to 2024, including titles, years of release,  genres, movieid
This dataset provides a comprehensive overview of the Bollywood film industry's evolution over the years.






",.csv
Bone Tumor 🦴🧪,1,bone-tumor,Bone Tumor Dataset.csv,CC0-1.0,"This dataset contains information on bone tumors. The data was collected from patients at the Memorial Sloan Kettering Cancer Center (MSKCC). The dataset includes the following information:

- Patient ID: A unique identifier for each patient.
- Sex: The patient's sex.
- Age: The patient's age at the time of diagnosis.
- Grade: The grade of the tumor, which is a measure of how aggressive the tumor is.
- Histological type: The type of tumor, such as osteosarcoma or Ewing sarcoma.
- MSKCC type: The MSKCC type of the tumor, which is a more specific classification of the tumor.
- Site of primary STS: The location of the tumor in the bone.
- Status (NED, AWD, D): The patient's status, which can be NED (no evidence of disease), AWD (alive with disease), or D (dead).
- Treatment: The treatment that the patient received, such as surgery, radiation therapy, or chemotherapy.

This dataset can be used to study the incidence, prevalence, and outcomes of bone tumors. It can also be used to develop new treatments for bone tumors.

I hope this helps!",.csv
Book Recommendation (Good book api),1,book-recommendation-good-book-api,books.csv,other,"Books are human's best friends. It is very difficult to know exactly which book is suitable for us. But if we can roughly understand which books are better for us, it can help us a lot in choosing books.
In this dataset, which was collected with the help of the Goodbook site, we can get information about books such as the author, number of pages, rating, and other information. We can also build a recommendation system to recommend books and bring people closer to a better decision.",.csv
Book of Mormon Modified for Information Extraction,1,book-of-mormon-modified-for-information-extraction,pg17_verse_lines_v4.csv,other,"# Source: 

This dataset contains the text of the Book of Mormon, sourced from the Project Gutenberg digital library.  The source text has been modified to remove the header, footer, and front matter.

# Data Description:

The dataset is a single text file containing the main text content of the Book of Mormon, a sacred text of the Church of Jesus Christ of Latter-day Saints. All extraneous content such as the Testimony of Joseph Smith Jr., the Testimonies of Witnesses, and the Contents list have been removed, leaving only the core scripture text.

The text follows the typical structure of the Book of Mormon, with the content divided into books, chapters, and verses. However, no additional formatting or markup has been added to the text file.

The CSV file has four columns:
* index
* book
* verse
* text

This dataset allows analysis of the Book of Mormon text itself, enabling research in areas such as natural language processing, topic modeling, and textual studies related to this influential religious work.

# File Format: 

The dataset is provided as a single .txt file and as a CSV export of a pandas dataframe is included that contains the text of each verse, the Book of Scripture, and the chapter number : verse number.

# License

THE FULL PROJECT GUTENBERG LICENSE

PLEASE READ THIS BEFORE YOU DISTRIBUTE OR USE THIS WORK

To protect the Project Gutenberg™ mission of promoting the free
distribution of electronic works, by using or distributing this work
(or any other work associated in any way with the phrase “Project
Gutenberg”), you agree to comply with all the terms of the Full
Project Gutenberg™ License available with this file or online at
www.gutenberg.org/license.

Section 1. General Terms of Use and Redistributing Project Gutenberg™
electronic works

1.A. By reading or using any part of this Project Gutenberg™
electronic work, you indicate that you have read, understand, agree to
and accept all the terms of this license and intellectual property
(trademark/copyright) agreement. If you do not agree to abide by all
the terms of this agreement, you must cease using and return or
destroy all copies of Project Gutenberg™ electronic works in your
possession. If you paid a fee for obtaining a copy of or access to a
Project Gutenberg™ electronic work and you do not agree to be bound
by the terms of this agreement, you may obtain a refund from the person
or entity to whom you paid the fee as set forth in paragraph 1.E.8.

1.B. “Project Gutenberg” is a registered trademark. It may only be
used on or associated in any way with an electronic work by people who
agree to be bound by the terms of this agreement. There are a few
things that you can do with most Project Gutenberg™ electronic works
even without complying with the full terms of this agreement. See
paragraph 1.C below. There are a lot of things you can do with Project
Gutenberg™ electronic works if you follow the terms of this
agreement and help preserve free future access to Project Gutenberg™
electronic works. See paragraph 1.E below.

1.C. The Project Gutenberg Literary Archive Foundation (“the
Foundation” or PGLAF), owns a compilation copyright in the collection
of Project Gutenberg™ electronic works. Nearly all the individual
works in the collection are in the public domain in the United
States. If an individual work is unprotected by copyright law in the
United States and you are located in the United States, we do not
claim a right to prevent you from copying, distributing, performing,
displaying or creating derivative works based on the work as long as
all references to Project Gutenberg are removed. Of course, we hope
that you will support the Project Gutenberg™ mission of promoting
free access to electronic works by freely sharing Project Gutenberg™
works in compliance with the terms of this agreement for keeping the
Project Gutenberg™ name associated with the work. You can easily
comply with the terms of this agreement by keeping this work in the
same format with its attached full Project Gutenberg™ License when
you share it without charge with others.

1.D. The copyright laws of the place where you are located also govern
what you can do with this work. Copyright laws in most countries are
in a constant state of change. If you are outside the United States,
check the laws of your country in addition to the terms of this
agreement before downloading, copying, displaying, performing,
distributing or creating derivative works based on this work or any
other Project Gutenberg™ work. The Foundation makes no
representations concerning the copyright status of any work in any
country other than the United States.

1.E. Unless you have removed all references to Project Gutenberg:

1.E.1. The following sentence, with active links to, or other
immediate access to, the full Project Gutenberg™ License must appear
prominently whenever any copy of a Project Gutenberg™ work (any work
on which the phrase “Project Gutenberg” appears, or with which the
phrase “Project Gutenberg” is associated) is accessed, displayed,
performed, viewed, copied or distributed:

    This eBook is for the use of anyone anywhere in the United States and most
    other parts of the world at no cost and with almost no restrictions
    whatsoever. You may copy it, give it away or re-use it under the terms
    of the Project Gutenberg License included with this eBook or online
    at www.gutenberg.org. If you
    are not located in the United States, you will have to check the laws
    of the country where you are located before using this eBook.
  
1.E.2. If an individual Project Gutenberg™ electronic work is
derived from texts not protected by U.S. copyright law (does not
contain a notice indicating that it is posted with permission of the
copyright holder), the work can be copied and distributed to anyone in
the United States without paying any fees or charges. If you are
redistributing or providing access to a work with the phrase “Project
Gutenberg” associated with or appearing on the work, you must comply
either with the requirements of paragraphs 1.E.1 through 1.E.7 or
obtain permission for the use of the work and the Project Gutenberg™
trademark as set forth in paragraphs 1.E.8 or 1.E.9.

1.E.3. If an individual Project Gutenberg™ electronic work is posted
with the permission of the copyright holder, your use and distribution
must comply with both paragraphs 1.E.1 through 1.E.7 and any
additional terms imposed by the copyright holder. Additional terms
will be linked to the Project Gutenberg™ License for all works
posted with the permission of the copyright holder found at the
beginning of this work.

1.E.4. Do not unlink or detach or remove the full Project Gutenberg™
License terms from this work, or any files containing a part of this
work or any other work associated with Project Gutenberg™.

1.E.5. Do not copy, display, perform, distribute or redistribute this
electronic work, or any part of this electronic work, without
prominently displaying the sentence set forth in paragraph 1.E.1 with
active links or immediate access to the full terms of the Project
Gutenberg™ License.

1.E.6. You may convert to and distribute this work in any binary,
compressed, marked up, nonproprietary or proprietary form, including
any word processing or hypertext form. However, if you provide access
to or distribute copies of a Project Gutenberg™ work in a format
other than “Plain Vanilla ASCII” or other format used in the official
version posted on the official Project Gutenberg™ website
(www.gutenberg.org), you must, at no additional cost, fee or expense
to the user, provide a copy, a means of exporting a copy, or a means
of obtaining a copy upon request, of the work in its original “Plain
Vanilla ASCII” or other form. Any alternate format must include the
full Project Gutenberg™ License as specified in paragraph 1.E.1.

1.E.7. Do not charge a fee for access to, viewing, displaying,
performing, copying or distributing any Project Gutenberg™ works
unless you comply with paragraph 1.E.8 or 1.E.9.

1.E.8. You may charge a reasonable fee for copies of or providing
access to or distributing Project Gutenberg™ electronic works
provided that:

    • You pay a royalty fee of 20% of the gross profits you derive from
        the use of Project Gutenberg™ works calculated using the method
        you already use to calculate your applicable taxes. The fee is owed
        to the owner of the Project Gutenberg™ trademark, but he has
        agreed to donate royalties under this paragraph to the Project
        Gutenberg Literary Archive Foundation. Royalty payments must be paid
        within 60 days following each date on which you prepare (or are
        legally required to prepare) your periodic tax returns. Royalty
        payments should be clearly marked as such and sent to the Project
        Gutenberg Literary Archive Foundation at the address specified in
        Section 4, “Information about donations to the Project Gutenberg
        Literary Archive Foundation.”
    
    • You provide a full refund of any money paid by a user who notifies
        you in writing (or by e-mail) within 30 days of receipt that s/he
        does not agree to the terms of the full Project Gutenberg™
        License. You must require such a user to return or destroy all
        copies of the works possessed in a physical medium and discontinue
        all use of and all access to other copies of Project Gutenberg™
        works.
    
    • You provide, in accordance with paragraph 1.F.3, a full refund of
        any money paid for a work or a replacement copy, if a defect in the
        electronic work is discovered and reported to you within 90 days of
        receipt of the work.
    
    • You comply with all other terms of this agreement for free
        distribution of Project Gutenberg™ works.
    

1.E.9. If you wish to charge a fee or distribute a Project
Gutenberg™ electronic work or group of works on different terms than
are set forth in this agreement, you must obtain permission in writing
from the Project Gutenberg Literary Archive Foundation, the manager of
the Project Gutenberg™ trademark. Contact the Foundation as set
forth in Section 3 below.

1.F.

1.F.1. Project Gutenberg volunteers and employees expend considerable
effort to identify, do copyright research on, transcribe and proofread
works not protected by U.S. copyright law in creating the Project
Gutenberg™ collection. Despite these efforts, Project Gutenberg™
electronic works, and the medium on which they may be stored, may
contain “Defects,” such as, but not limited to, incomplete, inaccurate
or corrupt data, transcription errors, a copyright or other
intellectual property infringement, a defective or damaged disk or
other medium, a computer virus, or computer codes that damage or
cannot be read by your equipment.

1.F.2. LIMITED WARRANTY, DISCLAIMER OF DAMAGES - Except for the “Right
of Replacement or Refund” described in paragraph 1.F.3, the Project
Gutenberg Literary Archive Foundation, the owner of the Project
Gutenberg™ trademark, and any other party distributing a Project
Gutenberg™ electronic work under this agreement, disclaim all
liability to you for damages, costs and expenses, including legal
fees. YOU AGREE THAT YOU HAVE NO REMEDIES FOR NEGLIGENCE, STRICT
LIABILITY, BREACH OF WARRANTY OR BREACH OF CONTRACT EXCEPT THOSE
PROVIDED IN PARAGRAPH 1.F.3. YOU AGREE THAT THE FOUNDATION, THE
TRADEMARK OWNER, AND ANY DISTRIBUTOR UNDER THIS AGREEMENT WILL NOT BE
LIABLE TO YOU FOR ACTUAL, DIRECT, INDIRECT, CONSEQUENTIAL, PUNITIVE OR
INCIDENTAL DAMAGES EVEN IF YOU GIVE NOTICE OF THE POSSIBILITY OF SUCH
DAMAGE.

1.F.3. LIMITED RIGHT OF REPLACEMENT OR REFUND - If you discover a
defect in this electronic work within 90 days of receiving it, you can
receive a refund of the money (if any) you paid for it by sending a
written explanation to the person you received the work from. If you
received the work on a physical medium, you must return the medium
with your written explanation. The person or entity that provided you
with the defective work may elect to provide a replacement copy in
lieu of a refund. If you received the work electronically, the person
or entity providing it to you may choose to give you a second
opportunity to receive the work electronically in lieu of a refund. If
the second copy is also defective, you may demand a refund in writing
without further opportunities to fix the problem.

1.F.4. Except for the limited right of replacement or refund set forth
in paragraph 1.F.3, this work is provided to you ‘AS-IS’, WITH NO
OTHER WARRANTIES OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT
LIMITED TO WARRANTIES OF MERCHANTABILITY OR FITNESS FOR ANY PURPOSE.

1.F.5. Some states do not allow disclaimers of certain implied
warranties or the exclusion or limitation of certain types of
damages. If any disclaimer or limitation set forth in this agreement
violates the law of the state applicable to this agreement, the
agreement shall be interpreted to make the maximum disclaimer or
limitation permitted by the applicable state law. The invalidity or
unenforceability of any provision of this agreement shall not void the
remaining provisions.

1.F.6. INDEMNITY - You agree to indemnify and hold the Foundation, the
trademark owner, any agent or employee of the Foundation, anyone
providing copies of Project Gutenberg™ electronic works in
accordance with this agreement, and any volunteers associated with the
production, promotion and distribution of Project Gutenberg™
electronic works, harmless from all liability, costs and expenses,
including legal fees, that arise directly or indirectly from any of
the following which you do or cause to occur: (a) distribution of this
or any Project Gutenberg™ work, (b) alteration, modification, or
additions or deletions to any Project Gutenberg™ work, and (c) any
Defect you cause.

Section 2. Information about the Mission of Project Gutenberg™

Project Gutenberg™ is synonymous with the free distribution of
electronic works in formats readable by the widest variety of
computers including obsolete, old, middle-aged and new computers. It
exists because of the efforts of hundreds of volunteers and donations
from people in all walks of life.

Volunteers and financial support to provide volunteers with the
assistance they need are critical to reaching Project Gutenberg™’s
goals and ensuring that the Project Gutenberg™ collection will
remain freely available for generations to come. In 2001, the Project
Gutenberg Literary Archive Foundation was created to provide a secure
and permanent future for Project Gutenberg™ and future
generations. To learn more about the Project Gutenberg Literary
Archive Foundation and how your efforts and donations can help, see
Sections 3 and 4 and the Foundation information page at www.gutenberg.org.

Section 3. Information about the Project Gutenberg Literary Archive Foundation

The Project Gutenberg Literary Archive Foundation is a non-profit
501(c)(3) educational corporation organized under the laws of the
state of Mississippi and granted tax exempt status by the Internal
Revenue Service. The Foundation’s EIN or federal tax identification
number is 64-6221541. Contributions to the Project Gutenberg Literary
Archive Foundation are tax deductible to the full extent permitted by
U.S. federal laws and your state’s laws.

The Foundation’s business office is located at 809 North 1500 West,
Salt Lake City, UT 84116, (801) 596-1887. Email contact links and up
to date contact information can be found at the Foundation’s website
and official page at www.gutenberg.org/contact

Section 4. Information about Donations to the Project Gutenberg
Literary Archive Foundation

Project Gutenberg™ depends upon and cannot survive without widespread
public support and donations to carry out its mission of
increasing the number of public domain and licensed works that can be
freely distributed in machine-readable form accessible by the widest
array of equipment including outdated equipment. Many small donations
($1 to $5,000) are particularly important to maintaining tax exempt
status with the IRS.

The Foundation is committed to complying with the laws regulating
charities and charitable donations in all 50 states of the United
States. Compliance requirements are not uniform and it takes a
considerable effort, much paperwork and many fees to meet and keep up
with these requirements. We do not solicit donations in locations
where we have not received written confirmation of compliance. To SEND
DONATIONS or determine the status of compliance for any particular state
visit www.gutenberg.org/donate.

While we cannot and do not solicit contributions from states where we
have not met the solicitation requirements, we know of no prohibition
against accepting unsolicited donations from donors in such states who
approach us with offers to donate.

International donations are gratefully accepted, but we cannot make
any statements concerning tax treatment of donations received from
outside the United States. U.S. laws alone swamp our small staff.

Please check the Project Gutenberg web pages for current donation
methods and addresses. Donations are accepted in a number of other
ways including checks, online payments and credit card donations. To
donate, please visit: www.gutenberg.org/donate.

Section 5. General Information About Project Gutenberg™ electronic works

Professor Michael S. Hart was the originator of the Project
Gutenberg™ concept of a library of electronic works that could be
freely shared with anyone. For forty years, he produced and
distributed Project Gutenberg™ eBooks with only a loose network of
volunteer support.

Project Gutenberg™ eBooks are often created from several printed
editions, all of which are confirmed as not protected by copyright in
the U.S. unless a copyright notice is included. Thus, we do not
necessarily keep eBooks in compliance with any particular paper
edition.

Most people start at our website which has the main PG search
facility: www.gutenberg.org.

This website includes information about Project Gutenberg™,
including how to make donations to the Project Gutenberg Literary
Archive Foundation, how to help produce our new eBooks, and how to
subscribe to our email newsletter to hear about new eBooks.",.csv
Book review dataset for Sentiment Analysis,1,book-review-dataset-for-sentiment-analysis,Customer_Reviews.csv,MIT,"Imagine a treasure trove of literary opinions! This dataset unlocks a world of book reviews, penned by passionate readers, insightful authors, and discerning reviewers. Each entry is a timestamped capsule, capturing a rating, a heartfelt description, and the very essence of a reader's experience. This rich data becomes the fuel for groundbreaking AI projects. We can build intelligent models that understand the sentiment woven into every word, uncovering the hidden gems of literature. Authors can gain invaluable insights into reader reception, while readers themselves can discover hidden masterpieces through personalized recommendations.

Here's a breakdown of the creative elements:

**Metaphor**: The dataset is compared to a ""treasure trove"" to highlight its value.
Personification: Reviews are described as ""penned"" by readers and authors, giving them a personal touch.
**Sensory details**: Words like ""heartfelt"" and ""essence"" evoke a sense of emotional connection with the reviews.
**Figurative language**: ""Fuel for groundbreaking AI projects"" emphasizes the dataset's role in powering innovation.
**Benefits**: The elaboration highlights how the dataset benefits both readers and authors.",.csv
Books Sales and Ratings,1,books-sales-and-ratings,Books_Data_Clean.csv,other,"_____
# Books Sales and Ratings
### Books Dataset: Analyzing Sales, Ratings, and Genres
By Josh Murrey [[source]](https://data.world/josh-nbu)
_____

### About this dataset
> The Books Dataset: Sales, Ratings, and Publication provides comprehensive information on various aspects of books, including their publishing year, author details, ratings given by readers, sales performance data, and genre classification. The dataset consists of several key columns that capture important attributes related to each book.
> 
> The Publishing Year column indicates the year in which each book was published. This information helps in understanding the chronological distribution of books in the dataset.
> 
> The Book Name column contains the titles of the books. Each book has a unique name that distinguishes it from others in the dataset.
> 
> The Author column specifies the name(s) of the author(s) responsible for creating each book. This information is crucial for understanding different authors' contributions and analyzing their impact on sales and ratings.
> 
> The language_code column represents a specific code assigned to indicate the language in which each book is written. This code serves as a reference point for language-based analysis within the dataset.
> 
> Each author's rating is captured in the Author_Rating column. This rating is based on their previous works and serves as an indicator of their reputation or acclaim among readers.
> 
> The average rating given by readers for each book is recorded in the Book_average_rating column. This value reflects how well-received a particular book is by its audience.
> 
> The number of ratings given to each book by readers can be found in the Book_ratings_count column. This metric helps gauge reader engagement and provides insights into popular or widely-discussed books within this dataset.
> 
> Books are classified into different genres or categories which are mentioned under the genre column. Genre classification allows for analyzing trends across specific literary genres or identifying patterns related to certain types of books.
> 
> Sales-related data includes both gross sales revenue (gross sales) generated by each book and publisher revenue (publisher revenue) earned from these sales transactions. These numeric values provide insights into financial performance aspects associated with the book market.
> 
> The sale price column denotes the specific price at which each book is sold. This information helps evaluate pricing strategies and their potential impact on sales figures.
> 
> Sales performance is further quantified through the sales rank column, which assigns a numerical rank to each book based on its sales performance. This ranking system aids in identifying high-performing books within the dataset.
> 
> Lastly, the units sold column captures the number of units of each book that have been sold. This data highlights popular books based on reader demand and serves as a crucial measure of commercial success within the dataset.
> 
> Overall, this expansive and comprehensive Books Dataset

### How to use the dataset
> 
> Introduction:
> 
> - Getting Familiar with the Columns:
> The dataset contains multiple columns that provide different kinds of information:
> 
> - Book Name: The title of each book.
> - Author: The name of the author who wrote the book.
> - language_code: The code representing the language in which the book is written.
> - Author_Rating: The rating assigned to the author based on their previous works.
> - Book_average_rating: The average rating given to the book by readers.
> - Book_ratings_count: The number of ratings given to the book by readers.
> - genre: The genre or category to which the book belongs.
> - gross sales: The total sales revenue generated by each book.
> - publisher revenue: The revenue earned by publishers from selling each book.
> - sale price: The price at which each copy of a book is sold.
> - sales rank: A numeric value indicating a book's rank based on its sales performance in comparison to other books within its category (genre).
> - units sold : Total number of copies sold for each specific title.
> 
> - Understanding Numeric and Textual Data:
> Numeric columns in this dataset include Publishing Year, Author_Rating, Book_average_rating, Book_ratings_count,gross sales,publisher revenue,sale price,sales rank and units sold; these provide quantitative insights that can be used for statistical analysis and comparisons.
> 
> Additionally,the columns 'Author','Book Name',and 'genre' contain textual data that provides descriptive elements such as authors' names and categorization genres.
> 
> 
> - Exploring Relationships Between Data Points:
> By combining different column values or comparing them against one another,you can discover interesting patterns and insights:
> 
> - You can analyze how the publishing year influences book sales or average ratings.
> - Explore the relationship between an author's rating and their book's average rating or sales performance.
> - Investigate if certain genres tend to have higher ratings or sales ranks.
> - Determine how book pricing affects gross sales or units sold.
> 
> - Data Cleaning and Preparation:
> Before utilizing this dataset, it is crucial to ensure its cleanliness and accuracy. Perform basic data cleaning steps, such as removing duplicates, handling missing values, correcting any inconsistencies in the data format.
> 
> - Visualization and Statistical Analysis:
> To gain a better understanding of the dataset

### Research Ideas
> - Market Analysis: The dataset can be used to analyze the sales and revenue generated by books of different genres, authors, and publishing years. This information can help publishers and bookstores understand which genres or authors are performing well in the market and make data-driven decisions on which books to stock.
> - Author Performance Evaluation: By analyzing the author rating, average rating of their books, and sales performance, this dataset can be used to evaluate the success of different authors. Publishers can use this information to identify successful authors to collaborate with or promote existing authors based on their previous works' popularity.
> - Trend Analysis: By analyzing the publishing years of books along with their genre, ratings, sales rank, and average ratings, it is possible to identify trends in reading preferences over time. This analysis can help determine evolving reader interests or popular genres during specific years and inform publishing decisions accordingly

### Acknowledgements
> If you use this dataset in your research, please credit the original authors.
> [Data Source](https://data.world/josh-nbu)
> 
>


### License
> 
> 
> See the dataset description for more information.

### Columns

**File: Books_Data_Clean.csv**
| Column name             | Description                                                               |
|:------------------------|:--------------------------------------------------------------------------|
| **Publishing Year**     | The year in which the book was published. (Numeric)                       |
| **Book Name**           | The title of the book. (Text)                                             |
| **Author**              | The name of the author of the book. (Text)                                |
| **language_code**       | The code representing the language in which the book is written. (Text)   |
| **Author_Rating**       | The rating of the author based on their previous works. (Numeric)         |
| **Book_average_rating** | The average rating given to the book by readers. (Numeric)                |
| **Book_ratings_count**  | The number of ratings given to the book by readers. (Numeric)             |
| **genre**               | The genre or category to which the book belongs. (Text)                   |
| **gross sales**         | The total sales revenue generated by a specific book. (Numeric)           |
| **publisher revenue**   | The revenue earned by a publisher from selling a specific book. (Numeric) |
| **sale price**          | The price at which a specific book was sold. (Numeric)                    |
| **sales rank**          | The rank of a particular book based on its sale performance. (Numeric)    |
| **units sold**          | The number of units sold for any particular book. (Numeric)               |

### Acknowledgements
> If you use this dataset in your research, please credit the original authors.
> If you use this dataset in your research, please credit [Josh Murrey](https://data.world/josh-nbu).

",.csv
Books_sells,1,books-sells,new-books-per-million.csv new.csv,CC0-1.0,"this graph  was created in Loocker studio and OurDataWorld:

Books, manuscripts, and written communication have played a crucial role in the spread of ideas and the development of culture.

Historically, books were a luxury commodity: only affordable to the most wealthy. Studying the production and sales of books over time can therefore give us an idea for how income and wealth have changed over the last centuries.

We can also look at trends, beyond income and education, to understand how religion, culture, and other context-specific factors might influence book publications and sales.

Writing has been key in the generation and communication of ideas. Even prior to the invention of the first printing press by Gutenberg, around 1440, societies communicated in written form using tablets, scrolls, sheets of papyrus, and other materials.

Finally, books also provide a good proxy for literacy rates within a population. Literacy is a crucial indicator of human development and education.

On this page, you can find historical data and visualizations relating to manuscript and book production.

The crucial event that changed the history of book production was the invention of the printing press by Gutenberg around 1440.1 But this data also looks at the history of manuscripts that preceded printed books.2

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F0dc7dc0d3c2a716b8a2e13f775a92d4b%2Fgraph4.jpg?generation=1714329148476045&alt=media)![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fe11ea644bf5b11a542ce7612411bc930%2Fgraph3.png?generation=1714329153038547&alt=media)![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F895646221df6017403f5558a8533a709%2Fgraph2.png?generation=1714329158269605&alt=media)![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F02f6f37df35758839c0bb4bf5eaed2af%2Fgraph1.png?generation=1714329163147083&alt=media)",.csv
Border Crossing Entry Data,1,border-crossing-entry-data,Border_Crossing_Entry_Data.csv,U.S. Government Works,"### Context

The Bureau of Transportation Statistics (BTS) Border Crossing Data provide summary statistics for inbound crossings at the U.S.-Canada and the U.S.-Mexico border at the port level. Data are available for trucks, trains, containers, buses, personal vehicles, passengers, and pedestrians. Border crossing data are collected at ports of entry by U.S. Customs and Border Protection (CBP). The data reflect the number of vehicles, containers, passengers or pedestrians entering the United States. CBP does not collect comparable data on outbound crossings. Users seeking data on outbound counts may therefore want to review data from individual bridge operators, border state governments, or the Mexican and Canadian governments.


### Content

COVERAGE: Incoming vehicle, container, passenger, and pedestrian counts at U.S.-Mexico and U.S.-Canada land border ports.

DEFINITIONS:

Bus Crossings: Number of arriving buses at a particular port, whether or not they are carrying passengers.

Container: A Container is defined as any conveyance entering the U.S. used for commercial purposes, either full or empty. Includes containers moving in-bond for the port initiating the bonded movements.

Types of Containers: The following are examples of a Container: Stakebed truck, truck with a car carrier, van, pickup truck/car, flatbed truck, piggyback truck with two linked trailers/containers = 2 containers, straight truck, bobtail truck, railcar, rail flatbed car stacked with four containers = 4 containers (on each rail car if there is multiple box containers count each container and the flatbed car.), and tri-level boxcar with multiple containers inside = 3 containers

Passengers Crossing In Buses: Number of persons arriving by bus requiring U.S. Customs and Border Protection (CBP) processing.

Passengers Crossing In Privately Owned Vehicles: Persons entering the United States at a particular port by private automobiles, pick-up trucks, motorcycles, recreational vehicles, taxis, ambulances, hearses, tractors, snowmobiles and other motorized private ground vehicles.

Passengers Crossing In Trains: Number of passengers and crew arriving by train and requiring CBP processing.

Pedestrian Crossings: The number of persons arriving on foot or by certain conveyance (such as bicycles, mopeds, or wheel chairs) requiring CBP processing.

Privately Owned Vehicle Crossings: Number of privately owned vehicles (POVs) arriving at a particular port. Includes pick-up trucks, motorcycles, recreational vehicles, taxis, snowmobiles, ambulances, hearses, and other motorized private ground vehicles.

Rail Container Crossings (loaded and empty): A container is any conveyance entering the U.S. used for commercial purposes, full or empty. In this case, it is the number of full or empty rail containers arriving at a port. This series includes containers moving as inbound shipments.

Train Crossings: Number of arriving trains at a particular port.

Truck Container Crossings (loaded and empty): A container is any conveyance entering the U.S. used for commercial purposes, full or empty. In this case, it is the number of full or empty truck containers arriving at a port. This series includes containers moving as inbound shipments.

Truck Crossings: Number of arriving trucks; does not include privately owned pick-up trucks.


### Notes

Canada: 
The ports of entry at Noyes, Minnesota and Whitetail, Montana closed in June 2006 and January 2013, respectively.
Incoming Trucks, Incoming PVs, PV Passengers, Incoming Buses, Bus Passengers, and Incoming Pedestrians

o Bar Harbor and Portland, Maine (ferry crossing) - Ferries arrived from May to September. The Bar Harbor, Maine to Yarmouth, Nova Scotia ferry is no longer in operation.

o Anacortes and Friday Harbor - The international ferries that connect Anacortes and Friday Harbor, Washington with Sidney, British Columbia do not run in February. Truck Containers (Loaded) and Truck Containers (Unloaded)

o Passenger vehicle and passengers in personal vehicles data for Cape Vincent, New York (ferry) are available beginning in 2007. The ferry between Wolfe Island (Canada) and Cape Vincent does not operate in the winter.
Incoming Train Passengers

o Includes both passengers and crew.

o Starting with November 2017, Maine officials restrict international bridge traffic to passenger vehicles only.

Mexico:
Data for the port of Calexico are reported as a combined total with Calexico East.

Incoming Trucks:
o Data represent the number of truck crossings, not the number of unique vehicles, and include both loaded and unloaded trucks.

Incoming Train Passengers:
o Includes train crew. BTS is not aware of any passenger service currently operating across the U.S.-Mexico Border.

o CBP has indicated to BTS that since 2009 train crew are being exchanged at the Texas-Mexico border, and thus do not enter the United States.

### Inspiration
What can we discern from this dataset?",.csv
Boston - Somerville Traffic Crash Dataset,1,somerville-traffic-crash-dataset,Somerville Crashes data.csv,CC-BY-SA-4.0,"
# Crash Data in Somerville, USA

This dataset provides detailed information about traffic crashes in Somerville, USA, including various factors and circumstances related to each incident.

## Columns Description

- **Crash Number**: Unique identifier for each crash event.
- **Date and Time of Crash**: Date and time when the crash occurred.
- **Police Shift**: Shift of the police responding to the crash.
- **Crash Location**: Location where the crash occurred.
- **Light Conditions**: Conditions of light at the time of the crash (e.g., day, night).
- **Weather Conditions**: Weather conditions during the crash.
- **Road Surface**: Type of road surface at the crash location.
- **Road Contributing Circumstances**: Contributing factors or circumstances related to the road condition.
- **Traffic Control Device Type**: Type of traffic control device present at the crash location.
- **Roadway Intersection Type**: Type of intersection where the crash occurred.
- **Trafficway Description**: Description of the trafficway involved in the crash.
- **Manner of Collision**: Manner in which the collision occurred (e.g., rear-end, head-on).
- **First Harmful Event**: Initial event that caused harm in the crash sequence.
- **First Harmful Event Location**: Location where the first harmful event occurred.
- **Speed Limit**: Speed limit at the crash location.
- **Work Zone**: Indicates if the crash occurred within a work zone.
- **Count Fatal Injury**: Number of fatalities resulting from the crash.
- **Count Suspected Serious Injury**: Number of suspected serious injuries.
- **Count Suspected Minor Injury**: Number of suspected minor injuries.
- **Count Possible Injury**: Number of possible injuries.
- **Count No Apparent Injury**: Number of individuals with no apparent injuries.
- **Count Unknown Injury**: Number of injuries with unknown severity.
- **Count Not Reported Injury**: Number of injuries not reported.
- **Total Non-Motorists**: Total number of non-motorists involved in the crash.
- **Pedestrian Involvement (Non-Motorist)**: Indicates pedestrian involvement in non-motorist incidents.
- **Cyclist Involvement (Non-Motorist)**: Indicates cyclist involvement in non-motorist incidents.
- **Other Non-Motorist Involvement**: Involvement of other non-motorists in the crash.
- **Hit and Run Flag**: Indicates if the crash was a hit-and-run incident.
- **Latitude**: Geographic latitude coordinate of the crash location.
- **Longitude**: Geographic longitude coordinate of the crash location.
- **Ward**: Ward where the crash occurred.
- **Block Code**: Code representing the specific block of the crash location.

This dataset is valuable for analyzing traffic safety, identifying trends, and understanding factors contributing to crashes in Somerville. It can be used for research, policy-making, and implementing interventions to improve road safety and reduce accidents.




This data set contains Somerville crashes that occurred from May 2018 to present. Crash reports are completed when a motor vehicle crash occurs on a public way and involves at least one of the following: Any person is killed, any person is injured,  or damage is in excess of $1,000 to any one vehicle or other property. Data does not include crashes that are under active investigation, nor those that occur on state roads, which are under the jurisdiction of the Massachusetts State Police.   State crash data may be accessed on the Massachusetts Department of Transportation.


Data source : https://catalog.data.gov/dataset/police-data-crashes",.csv
Boston House Prices,1,boston-house-prices,housing.csv,other,"### Context

To Explore more on Regression Algorithm


### Content

 Each record in the database describes a Boston suburb or town. The data was drawn from the Boston Standard Metropolitan Statistical Area (SMSA) in 1970. The attributes are deﬁned as follows (taken from the UCI Machine Learning Repository1): CRIM: per capita crime rate by town
2. ZN: proportion of residential land zoned for lots over 25,000 sq.ft.
3. INDUS: proportion of non-retail business acres per town
4. CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)
5. NOX: nitric oxides concentration (parts per 10 million)
1https://archive.ics.uci.edu/ml/datasets/Housing
123
20.2. Load the Dataset 124
6. RM: average number of rooms per dwelling
7. AGE: proportion of owner-occupied units built prior to 1940
8. DIS: weighted distances to ﬁve Boston employment centers
9. RAD: index of accessibility to radial highways
10. TAX: full-value property-tax rate per $10,000
11. PTRATIO: pupil-teacher ratio by town 12. B: 1000(Bk−0.63)2 where Bk is the proportion of blacks by town 13. LSTAT: % lower status of the population
14. MEDV: Median value of owner-occupied homes in $1000s
We can see that the input attributes have a mixture of units.


### Acknowledgements

Thanks to Dr.Jason",.csv
Boston Housing,1,bostonhoustingmlnd,housing.csv,CC-BY-NC-SA-4.0,"### Context

The dataset for this project originates from the UCI Machine Learning Repository. The Boston housing data was collected in 1978 and each of the 506 entries represent aggregated data about 14 features for homes from various suburbs in Boston, Massachusetts.

### Acknowledgements

https://github.com/udacity/machine-learning

https://archive.ics.uci.edu/ml/datasets/Housing",.csv
Boston Housing Census,1,boston-housing-census,BostonHousing.csv,Apache 2.0,This dataset contains information collected by the US Census Service concerning housing in the area of Boston Massachusetts. It was obtained from the StatLib archive and the dataset has 506 cases.,.csv
Boston Weather 2013-2023,1,boston-weather-2013-2023,boston_weather_data.csv,CC0-1.0,"This dataset contains daily weather data for Boston, sourced from the Meteostat API, spanning a period of 10 years from March 1st, 2013 to March 1st, 2023. 

Each row of the dataset represents a single day and provides information such as the average, minimum, and maximum air temperature in Celsius, daily precipitation total in millimeters, wind direction and speed in kilometers per hour, and the average sea-level air pressure in hectopascals. 

With a total of over 3,600 rows, this dataset offers a comprehensive look at Boston's climate trends over the past decade.

Find the script used for extraction below:
```python
from datetime import datetime
from meteostat import Stations, Daily
import pandas as pd

# Set time period
start = datetime(2013, 3, 1)
end = datetime(2023, 3, 1)

# Get daily data
data = Daily('72509', start, end)
data = data.fetch()
data=data.reset_index().iloc[:,[0,1,2,3,4,6,7,9]]

data.to_csv('boston_weather_data.csv',index=False)
```",.csv
Box Office History for Marvel Movies,1,box-office-history-for-marvel-movies,Box_Office_History_for_Marvel_Cinematic_Universe_Movies.csv,Apache 2.0,"The dataset about Box Office History for Marvel Cinematic Universe (MCU) Movies contains information about the box office performance of various movies in the Marvel Cinematic Universe.

Columns:
- **Release Date**: The date when each movie was released in theaters.
- **Title**: The title of the movie.
- **Production Budget**: The budget allocated for producing each movie.
- **Opening Weekend**: The box office revenue generated by each movie during its opening weekend.
- **Domestic Box Office**: The total box office revenue generated by each movie in the domestic (U.S. and Canada) market.
- **Worldwide Box Office:** The total box office revenue generated by each movie worldwide.",.csv
Box office of DC and Marvel superhero movies,1,box-office-of-dc-and-marvel-superhero-movies,dc_marvel_movie_performance.csv,Attribution 4.0 International (CC BY 4.0),"The dataset comprises box office data and supplemental information for all theatrically released films adapted from Marvel Comics and DC Comics core superhero universes. TV specials and other projects that did not receive a wide theatrical release are not included.

Column explanation and suggested use:

**Film:** The title of the film in the U.S. market. Note that this may differ from other territories. For example, in the United Kingdom Avengers was retitled Avengers Assemble to distinguish it from the unrelated television series of the same name.

**U.S. release date:** The first day the film was available in theatres in the United States of America to the general public.

**Box office gross Domestic (U.S. and Canada):** The total gross earnings of the film in U.S. dollars in Hollywood’s domestic market (comprising the United States of America and Canada). Typically, the distributor for a motion picture receives slightly more than half of the final gross with the remainder going to the exhibitor (i.e. the cinema) across the theatrical window.

**Box office gross Other territories:** The total gross earnings of the film in U.S. dollars in Hollywood’s international market (comprising any countries the film released in except the USA and Canada). We might note that the split between distributors and exhibitors can be more variable than within the domestic market, but this is granular detail beyond the present analysis.

**Box office gross Worldwide:** The sum total gross earnings for all territories in U.S. dollars. 

**Budget:** The production budget for the movie in U.S. dollars. This does not include any additional expenses relating to the movie beyond what it cost to make, most notably the marketing budget which can equal or even exceed the production budget on major motion pictures.

**MCU:** Indicates whether the film is part of the Marvel Cinematic Universe. Recorded as a Boolean value, with TRUE indicating that the film is part of the MCU. Note that some pre-existing films (such as 20th Century Fox X-Men films and Sony Pictures Spider-Man films) have been retroactively made part of the MCU’s multiverse (separate continuities that exist within a large continuity superstructure). This has mostly been driven by corporate acquisitions and mergers, but not entirely. There remain questions over the degree of interconnectedness for certain movies, particularly Sony’s films based on Spider-Man-related characters. To avoid confusion, this value is only given as TRUE when a film satisfies both the following criteria: (a) it was part of the MCU at the time of release (b) it is part of the “main” MCU timeline, elsewhere known as “The Sacred Timeline”.

**Phase:** States which phase of MCU this film belongs to (if not applicable NA is used). MCU phase was originally used as internal planning term at Marvel Studios, but has since become widely known and used by the general public. Noting the specific phases can be helpful in understanding public perception around the brand/franchise and public opinion on its health and reliability.

**Distributor:** The name of the film studio that distributed the movie within the United States. You may wish to note that several of the listed distributors are divisions of larger studios. Twentieth Century Fox was rebranded as 20th Century Studios following its acquisition by the Walt Disney Company. Columbia Pictures is a division of Sony Pictures Entertainment. New Line Cinema merged with what is now Warner Bros. Discovery in 2008 (then Time-Warner).

**MPAA Rating:** The age rating awarded under the Motion Picture Association film rating system. Note that age ratings can vary in other markets (as can the final cut of the film). The current available classifications from the MPA are:

G (General Audiences). All ages admitted. Nothing that would offend parents for viewing by children. PG (Parental Guidance Suggested). Some material may not be suitable for children. Parents urged to give “parental guidance”. May contain some material parent might not like for their young children.
PG-13 (Parents Strongly Cautioned). Parents are urged to be cautious. Some material may be inappropriate for pre-teenagers.
R (Restricted). Under 17 requires accompanying parent or adult guardian. Contains some adult material. Parents are urged to learn more about the film before taking their young children with them.
NC-17 (No on 17 and under admitted). Clearly adult. Children are not admitted.
This information can help with understanding the demographics of the audience, most notably by who would be excluded. It can also provide insight into the commercial viability of films given their relative MPAA rating. It may also help the user understand the relative maturity of a given film, though this is very much in terms of what the MPAA deems suitable for a given age rather than say the themes explored by the film.

**Length:** The length of the U.S. theatrical cut of the film given in hours, minutes and seconds, rounded to the nearest minute. This may differ from edits of the film shown in other markets or in secondary markets such as television, streaming and physical media releases.

**Minutes:** The same as above but presented only in minutes.

**Source:** The sources consulted for all aforementioned box-office figures and production budgets. Further information on my process can be found under Provenance.

**Character family:** The character family that the protagonist(s) of the film fall under, primarily gauged by title with secondary reference to how the character(s) are divided according to comic book editorial team, and film continuity (for example Venom existing in a separate film continuity to Spider-Man despite originating in Spider-Man comics as an antagonist). This is somewhat subjective, but useful for identifying films that are related to each other by leading character(s), but exist across multiple often unrelated series and even studios. It can be assumed that a portion of the audience will be aware of other films that feature the character(s) and that the quality of previous instalments may have a bearing on the success of future instalments whether or not they exist in the same fictional continuity. It may also be a helpful data point to determine how much the MCU branding can affect the fortunes of films featuring a particular character. This category excludes cross-over and cameo characters, only the protagonist(s) is used to determine character family. There is therefore the potential for this to be somewhat misleading in isolation, for example, Captain America: Civil War positions Captain America as its protagonist, Iron Man as deuteragonist/antagonist, features Spider-Man, and could be considered an Avengers movie based on how prominently that set of characters feature but is here listed simply as part of the Captain America character family.

**Domestic %:** The percentage of the world-wide gross made up by the domestic (U.S. and Canada) gross. This may be a helpful metric for gauging relative popularity outside North America. Gross to budget: The ratio between the world-wide gross and the production budget. A higher ratio would be indicative of greater profitability.

**Rotten Tomatoes Critic Score:** The average score from all professional critics on the “Tomatometer” from the popular review aggregator website. More information on Rotten Tomatoes curation and process can be found on their website. This figure has been included to give some insight into the general critical consensus of the movie, but is of course extremely reductive in isolation. It may be a useful measure for determining how “critic-proof” these films are, i.e. is there a strong relationship between critic score and box office performance? Elsewhere referred to as RT Score.

**Male/Female-led:** This column records whether the film had a male or female lead, or whether women and men co-star roughly equally. This is a highly subjective measure, based on the assumed gender of the protagonist of the film. It may have some value in analysing box office performance of superhero films based on the gender of the lead. It can also be revealing in how male-dominated the genre is (in terms of characters featured as protagonists).

**Year:** The calendar year the film was released theatrically in the United States of America. Inflation Adjusted Worldwide Gross: The worldwide gross adjusted for inflation, given in 2023 U.S. dollars. This calculation was derived from U.S. Consumer Price Index (CPI) data, and should be considered a rough estimate. It is a useful metric for looking at the relative box office success of these pictures irrespective of when they released. Without this data point for comparison, more recent movies tend to look more successful than older films due to inflation.

**Inflation Adjusted Budget:** The production budget adjusted for inflation, given in 2023 U.S. dollars. Calculated using CPI data as above.

**2.5x prod:** The production budget multiplied by 2.5. This is a common rule of thumb for determining whether a theatrical release achieved profitability for the distributor after marketing costs and exhibitors have taken their cut. It is a rough estimate, and does not take into account other income streams such as merchandise sales, home video releases, streaming, etc.

**Break Even:** Determines whether the film reached profitability by checking whether the worldwide gross exceeded two and half times the production budget (the rule of thumb outlined above). This is a binary distinction, a single dollar over the 2.5 value will register as a success. This column is primarily useful for determining if a film can be considered a flop. Even if the rule of thumb does not necessarily hold true in each case in practice, the public’s awareness of the rule can help us understand which films are understood by members of the public as flops. The degree of success (or failure) can be more accurately gauged by looking at the grosses and the Gross to Budget column.",.csv
Brain Stroke Dataset,1,brain-stroke-dataset,brain_stroke.csv,DbCL-1.0,"## Story of dataset:

## Context:

A stroke is a medical condition in which poor blood flow to the brain causes cell death. There are two main types of stroke: ischemic, due to lack of blood flow, and hemorrhagic, due to bleeding. Both cause parts of the brain to stop functioning properly. Signs and symptoms of a stroke may include an inability to move or feel on one side of the body, problems understanding or speaking, dizziness, or loss of vision to one side. Signs and symptoms often appear soon after the stroke has occurred. If symptoms last less than one or two hours, the stroke is a transient ischemic attack (TIA), also called a mini-stroke. A hemorrhagic stroke may also be associated with a severe headache. The symptoms of a stroke can be permanent. Long-term complications may include pneumonia and loss of bladder control.

The main risk factor for stroke is high blood pressure. Other risk factors include high blood cholesterol, tobacco smoking, obesity, diabetes mellitus, a previous TIA, end-stage kidney disease, and atrial fibrillation. An ischemic stroke is typically caused by blockage of a blood vessel, though there are also less common causes. A hemorrhagic stroke is caused by either bleeding directly into the brain or into the space between the brain's membranes. Bleeding may occur due to a ruptured brain aneurysm. Diagnosis is typically based on a physical exam and is supported by medical imaging such as a CT scan or MRI scan. A CT scan can rule out bleeding, but may not necessarily rule out ischemia, which early on typically does not show up on a CT scan. Other tests such as an electrocardiogram (ECG) and blood tests are done to determine risk factors and rule out other possible causes. Low blood sugar may cause similar symptoms.

Prevention includes decreasing risk factors, surgery to open up the arteries to the brain in those with problematic carotid narrowing, and warfarin in people with atrial fibrillation. Aspirin or statins may be recommended by physicians for prevention. A stroke or TIA often requires emergency care. An ischemic stroke, if detected within three to four and half hours, may be treatable with a medication that can break down the clot. Some hemorrhagic strokes benefit from surgery. Treatment to attempt recovery of lost function is called stroke rehabilitation, and ideally takes place in a stroke unit; however, these are not available in much of the world.

##Attribute Information

1) gender: ""Male"", ""Female"" or ""Other""

2) age: age of the patient

3) hypertension: 0 if the patient doesn't have hypertension, 1 if the patient has hypertension

4) heart disease: 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease 5) Ever-married: ""No"" or ""Yes""

6) work type: ""children"", ""Govtjov"", ""Never worked"", ""Private"" or ""Self-employed"" 

7) Residencetype: ""Rural"" or ""Urban""

8) avg glucose level: average glucose level in blood

9) BMI: body mass index

10) smoking_status: ""formerly smoked"", ""never smoked"", ""smokes"" or ""Unknown""*

11) stroke: 1 if the patient had a stroke or 0 if not

# Note: ""Unknown"" in smoking_status means that the information is unavailable for this patient
",.csv
Brain Tumor,1,brain-tumor,data.csv,ODC Public Domain Dedication and Licence (PDDL),"## What is a brain tumor?
A brain tumor is a collection, or mass, of abnormal cells in your brain. Your skull, which encloses your brain, is very rigid. Any growth inside such a restricted space can cause problems. Brain tumors can be cancerous (malignant) or noncancerous (benign). When benign or malignant tumors grow, they can cause the pressure inside your skull to increase. This can cause brain damage, and it can be life-threatening.

## The importance of the subject
Early detection and classification of brain tumors is an important research domain in the field of medical imaging and accordingly helps in selecting the most convenient treatment method to save patients life therefore

## About The Dataset

This Brain Tumor Dataset Contain 7465 columns and 1 dependent or target Column. Total Column 7466. It's a Classification Problem.",.csv
Brand Laptops Dataset,1,brand-laptops-dataset,laptops.csv,Attribution 4.0 International (CC BY 4.0),"# Content:
This meticulously cleaned dataset presents a comprehensive collection of 991 unique laptops sourced from the 'Smartprix' website. Enriched with 22 features including laptop name, price in Indian rupees, processor, GPU, and more, it provides valuable insights for building robust price prediction models and effective recommendation systems. Updated as of January 14, 2024, this dataset is a reliable foundation for exploring the intricate landscape of laptop pricing dynamics and consumer preferences.

# About the laptops.csv file:
- Brand : The name of the laptop brand.
- Model : The specific model or series of the laptop.
- Price : The price of the laptop in Indian rupees.
- Rating : The rating assigned to each laptop based on its specifications.
- Processor brand : The brand of the processor used in the laptop.
- Processor tier : The performance tier or category of the processor.
- Number of Cores : The number of processing cores in the processor.
- Number of Threads : The number of threads supported by the processor.
- Ram memory : The amount of RAM used in the laptop.
- Primary storage type : The type of primary storage (e.g., HDD, SSD).
- Primary storage capacity : The capacity of the primary storage in the laptop.
- Secondary storage type : The type of secondary storage, if available.
- Secondary storage capacity : The capacity of the secondary storage in the laptop.
- GPU brand : The brand of the graphics processing unit (GPU).
- GPU type : The type of the GPU.
- Is Touch screen : Indicates whether the laptop has a touch screen feature.
- Display size : The size of the laptop display in inches.
- Resolution width : The width resolution of the display.
- Resolution height : The height resolution of the display.
- OS : The operating system installed on the laptop.
- Year of warranty : The duration of the warranty provided for the laptop, usually in years",.csv
Breast Cancer (METABRIC),1,breast-cancer-metabric,Breast Cancer METABRIC.csv,ODbL-1.0,"### Context

There's a story behind every dataset and here's your opportunity to share yours.


### Content

What's inside is more than just rows and columns. Make it easy for others to get started by describing how you acquired the data and what time period it represents, too.


### Acknowledgements

We wouldn't be here without the help of others. If you owe any attributions or thanks, include them here along with any citations of past research.


### Inspiration

Your data will be in front of the world's largest data science community. What questions do you want to see answered?",.csv
Breast Cancer Gene Expression Profiles (METABRIC),1,breast-cancer-gene-expression-profiles-metabric,METABRIC_RNA_Mutation.csv,DbCL-1.0,"### Context

Most of us know someone who struggled with breast cancer, or at least heard about the struggles facing patients who are fighting against breast cancer. Breast cancer is the most frequent cancer among women, impacting 2.1 million women each year. Breast cancer causes the greatest number of cancer-related deaths among women. In 2018 alone, it is estimated that 627,000 women died from breast cancer.

The most important part of a process of clinical decision-making in patients with cancers, in general, is the accurate estimation of prognosis and survival duration. Breast cancer patients with the same stage of the disease and the same clinical characteristics can have different treatment responses and overall survival, but why?

Cancers are associated with genetic abnormalities. Gene expression measures the level of gene activity in a tissue and gives information about its complex activities. Comparing the genes expressed in normal and diseased tissue can bring better insights into the cancer prognosis and outcomes. Using machine learning techniques on genetic data has the potentials of giving the correct estimation of survival time and can prevent unnecessary surgical and treatment procedures.

### Content

The Molecular Taxonomy of Breast Cancer International Consortium (METABRIC) database is a Canada-UK Project which contains targeted sequencing data of 1,980 primary breast cancer samples. Clinical and genomic data was downloaded from [cBioPortal](https://www.cbioportal.org/).

The dataset was collected by Professor Carlos Caldas from Cambridge Research Institute and Professor Sam Aparicio from the British Columbia Cancer Centre in Canada and published on Nature Communications [(Pereira et al., 2016)](https://www.nature.com/articles/ncomms11479). It was also featured in multiple papers including Nature and others:

- [Associations between genomic stratification of breast cancer and centrally reviewed tumor pathology in the METABRIC cohort](https://www.nature.com/articles/s41523-018-0056-8)
- [Predicting Outcomes of Hormone and Chemotherapy in the Molecular Taxonomy of Breast Cancer International Consortium (METABRIC) Study by Biochemically-inspired Machine Learning](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5461908/)

#### Clinical attributes in the dataset:
| Name                           | Type   | Description |
|--------------------------------|--------|-------------|
| patient_id                     | object | Patient ID  |
| age_at_diagnosis               | float  |    Age of the patient at diagnosis time         |
| type_of_breast_surgery         | object | Breast cancer surgery type: 1-  MASTECTOMY, which refers to a surgery to remove all breast tissue from a breast as a way to treat or prevent breast cancer.  2- BREAST CONSERVING, which refers to a urgery where only the part of the breast that has cancer is removed     |
| cancer_type                    | object | Breast cancer types: 1- Breast Cancer or  2- Breast Sarcoma           |
| cancer_type_detailed           | object | Detailed Breast cancer types: 1- Breast Invasive Ductal Carcinoma 2- Breast Mixed Ductal and Lobular Carcinoma 3- Breast Invasive Lobular Carcinoma  4- Breast Invasive Mixed Mucinous Carcinoma 5- Metaplastic Breast Cancer   |
| cellularity                    | object | Cancer cellularity post chemotherapy, which refers to the amount of tumor cells in the specimen and their arrangement into clusters         |
| chemotherapy                   | int    |  Whether or not the patient had chemotherapy as a treatment (yes/no)    |
| pam50_+_claudin-low_subtype    | object |  Pam 50: is a tumor profiling test that helps show whether some estrogen receptor-positive (ER-positive), HER2-negative breast cancers are likely to metastasize (when breast cancer spreads to other organs). The claudin-low breast cancer subtype is defined by gene expression characteristics, most prominently: Low expression of cell–cell adhesion genes, high expression of epithelial–mesenchymal transition (EMT) genes, and stem cell-like/less differentiated gene expression patterns       |
| cohort                         | float  |  Cohort is a group of subjects who share a defining characteristic (It takes a value from 1 to 5)        |
| er_status_measured_by_ihc      | float  |  To assess if estrogen receptors are expressed on cancer cells by using immune-histochemistry (a dye used in pathology that targets specific antigen, if it is there, it will give a color, it is not there, the tissue on the slide will be colored)  (positive/negative)         |
| er_status                      | object |   Cancer cells are positive or negative for estrogen receptors          |
| neoplasm_histologic_grade      | int  |  Determined by pathology by looking the nature of the cells, do they look aggressive or not  (It takes a value from 1 to 3)         |
| her2_status_measured_by_snp6   | object | To assess if the cancer positive for HER2 or not by using advance molecular techniques (Type of next generation sequencing)       |
| her2_status                    | object |   Whether the cancer is positive or negative for HER2          |
| tumor_other_histologic_subtype | object |  Type of the cancer based on microscopic examination of the cancer tissue (It takes a value of  'Ductal/NST', 'Mixed', 'Lobular', 'Tubular/ cribriform', 'Mucinous', 'Medullary', 'Other', 'Metaplastic'  )      |
| hormone_therapy                | int |   Whether or not the patient had hormonal as a treatment (yes/no)           |
| inferred_menopausal_state      | object |  Whether the patient is  is post menopausal or not   (post/pre)        |
| integrative_cluster            | object | Molecular subtype of the cancer based on some gene expression (It takes a value from '4ER+', '3', '9', '7', '4ER-', '5', '8', '10', '1', '2', '6')            |
| primary_tumor_laterality       | object |   Whether it is involving the right breast or the left breast           |
| lymph_nodes_examined_positive  | float  |  To take samples of the lymph node during the surgery and see if there were involved by the cancer            |
| mutation_count                 | float  |  Number of gene that has relevant mutations            |
| nottingham_prognostic_index    | float  |   It is used to determine prognosis following surgery for breast cancer. Its value is calculated using three pathological criteria: the size of the tumour; the number of involved lymph nodes; and the grade of the tumour.          |
| oncotree_code                  | object |  The OncoTree is an open-source ontology that was developed at Memorial Sloan Kettering Cancer Center (MSK) for standardizing cancer type diagnosis from a clinical perspective by assigning each diagnosis a unique OncoTree code.           |
| overall_survival_months        | float  |  Duration from the time of the intervention to death        |
| overall_survival               | object |   Target variable wether the patient is alive of dead.          |
| pr_status                      | object |    Cancer cells are positive or negative for progesterone receptors          |
| radio_therapy                  | int    | Whether or not the patient had radio as a treatment (yes/no)             |
| 3-gene_classifier_subtype      | object | Three Gene classifier subtype It takes a value from 'ER-/HER2-', 'ER+/HER2- High Prolif', nan, 'ER+/HER2- Low Prolif','HER2+'           |
| tumor_size                     | float  | Tumor size measured by imaging techniques            |
| tumor_stage                    | float  | Stage of the cancer based on the involvement of surrounding structures, lymph nodes and distant spread          |
| death_from_cancer              | int  |  Wether the patient's death was due to cancer or not (yes/no)           |

#### Genetic attributes in the dataset:
The genetics part of the dataset contains m-RNA levels z-score for 331 genes, and mutation for 175 genes. 

From CBioPortal:
&gt; ##### What are mRNA? 
The DNA molecules attached to each slide act as probes to detect gene expression, which is also known as the transcriptome or the set of messenger RNA (mRNA) transcripts expressed by a group of genes. To perform a microarray analysis, mRNA molecules are typically collected from both an experimental sample and a reference sample.

&gt;##### What are mRNA Z-Scores? 
For mRNA expression data, The calculations of the relative expression of an individual gene and tumor to the gene's expression distribution in a reference population is done. That reference population is all samples in the study . The returned value indicates the number of standard deviations away from the mean of expression in the reference population (Z-score). This measure is useful to determine whether a gene is up- or down-regulated relative to the normal samples or all other tumor samples.

The formula is : 

`z = (expression in tumor sample - mean expression in reference sample) / standard deviation of expression in reference sample`

### Acknowledgements

- [Breast Cancer dataset (METABRIC, Nature 2012 & Nat Commun 2016) in CBioPortal](https://www.cbioportal.org/study/summary?id=brca_metabric)
- [Increasing the resolution on breast cancer – the METABRIC study](https://scienceblog.cancerresearchuk.org/2012/04/18/increasing-the-resolution-on-breast-cancer-the-metabric-study/)
- [Cerami et al. The cBio Cancer Genomics Portal: An Open Platform for Exploring Multidimensional Cancer Genomics Data. Cancer Discovery. May 2012 2; 401.](https://www.ncbi.nlm.nih.gov/pubmed/22588877)
- [Gao et al. Integrative analysis of complex cancer genomics and clinical profiles using the cBioPortal. Sci. Signal. 6, pl1 (2013).](https://www.ncbi.nlm.nih.gov/pubmed/23550210)


### Inspiration

- Predict breast cancer survival using machine learning models with clinical data and gene expression profiles.
- Clustering genes",.csv
Breast Cancer Prediction Dataset,1,breast-cancer-prediction-dataset,Breast_cancer_data.csv,other,"Worldwide, breast cancer is the most common type of cancer in women and the second highest in terms of mortality rates.Diagnosis of breast cancer is performed when an abnormal lump is found (from self-examination or x-ray) or a tiny speck of calcium is seen (on an x-ray).  After a suspicious lump is found, the doctor will conduct a diagnosis to determine whether it is cancerous and, if so, whether it has spread to other parts of the body.  

This breast cancer dataset was obtained from the University of Wisconsin Hospitals, Madison from Dr. William H. Wolberg. ",.csv
Breast Cancer Wisconsin ,1,breast-cancer-wisconsin,breast cancer.csv,CC0-1.0,"Breast Cancer Wisconsin data set is an example of a classification problem in Supervised Machine Learning.
The task is to predict the Malignant (M) and Benign (B) tumor.

There are 569 rows and 33 columns/features.
The Benign and Malignant cases are as follows.
B    357
M    212

We can observe in our data high correlation between radius mean and worst mean; indicating that the malignant tumors have a high radius. 

By exploring further we find dependencies among several features, thus introducing the concept of multicollinearity. We remove multicollinearity by removing the dependent features altogether.

Next, we move on to the model building process. I have used Logistic Regression, Random Forest, Decision Tree, K NN, Support Vector Machines (SVM) and Naive Bayes to evaluate the algorithm, to evaluate the model and how it is performing on unseen data following metrics are used
1) Classification Report
2) Confusion matrix
3) Accuracy

SVM gave the highest accuracy of 96.4%, recall, and precision (both 97%)were also good as compared to other algorithms.


I would like to boost the model performance by Ensemble techniques!!

 ",.csv
Breast Cancer Wisconsin (Diagnostic) Data Set,1,breast-cancer-wisconsin-data,data.csv,CC-BY-NC-SA-4.0,"Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. 
n the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: ""Robust Linear Programming Discrimination of Two Linearly Inseparable Sets"", Optimization Methods and Software 1, 1992, 23-34]. 

This database is also available through the UW CS ftp server: 
ftp ftp.cs.wisc.edu 
cd math-prog/cpo-dataset/machine-learn/WDBC/

Also can be found on UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29

Attribute Information:

1) ID number 
2) Diagnosis (M = malignant, B = benign) 
3-32) 

Ten real-valued features are computed for each cell nucleus: 

a) radius (mean of distances from center to points on the perimeter) 
b) texture (standard deviation of gray-scale values) 
c) perimeter 
d) area 
e) smoothness (local variation in radius lengths) 
f) compactness (perimeter^2 / area - 1.0) 
g) concavity (severity of concave portions of the contour) 
h) concave points (number of concave portions of the contour) 
i) symmetry 
j) fractal dimension (""coastline approximation"" - 1)

The mean, standard error and ""worst"" or largest (mean of the three
largest values) of these features were computed for each image,
resulting in 30 features.  For instance, field 3 is Mean Radius, field
13 is Radius SE, field 23 is Worst Radius.

All feature values are recoded with four significant digits.

Missing attribute values: none

Class distribution: 357 benign, 212 malignant",.csv
Breast Cancer Wisconsin (Prognostic) Data Set,1,breast-cancer-wisconsin-prognostic-data-set,data 2.csv,DbCL-1.0,"# Context 

Data From: UCI Machine Learning Repository
http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wpbc.names



# Content

""Each record represents follow-up data for one breast cancer
	case.  These are consecutive patients seen by Dr. Wolberg
	since 1984, and include only those cases exhibiting invasive
	breast cancer and no evidence of distant metastases at the
	time of diagnosis. 

	The first 30 features are computed from a digitized image of a
	fine needle aspirate (FNA) of a breast mass.  They describe
	characteristics of the cell nuclei present in the image.
	A few of the images can be found at
	http://www.cs.wisc.edu/~street/images/

	The separation described above was obtained using
	Multisurface Method-Tree (MSM-T) [K. P. Bennett, ""Decision Tree
	Construction Via Linear Programming."" Proceedings of the 4th
	Midwest Artificial Intelligence and Cognitive Science Society,
	pp. 97-101, 1992], a classification method which uses linear
	programming to construct a decision tree.  Relevant features
	were selected using an exhaustive search in the space of 1-4
	features and 1-3 separating planes.

	The actual linear program used to obtain the separating plane
	in the 3-dimensional space is that described in:
	[K. P. Bennett and O. L. Mangasarian: ""Robust Linear
	Programming Discrimination of Two Linearly Inseparable Sets"",
	Optimization Methods and Software 1, 1992, 23-34].

	The Recurrence Surface Approximation (RSA) method is a linear
	programming model which predicts Time To Recur using both
	recurrent and nonrecurrent cases.  See references (i) and (ii)
	above for details of the RSA method. 

	This database is also available through the UW CS ftp server:

	ftp ftp.cs.wisc.edu
	cd math-prog/cpo-dataset/machine-learn/WPBC/


1) ID number
2) Outcome (R = recur, N = nonrecur)
3) Time (recurrence time if field 2 = R, disease-free time if 
	field 2	= N)
4-33) Ten real-valued features are computed for each cell nucleus:

	a) radius (mean of distances from center to points on the perimeter)
	b) texture (standard deviation of gray-scale values)
	c) perimeter
	d) area
	e) smoothness (local variation in radius lengths)
	f) compactness (perimeter^2 / area - 1.0)
	g) concavity (severity of concave portions of the contour)
	h) concave points (number of concave portions of the contour)
	i) symmetry 
	j) fractal dimension (""coastline approximation"" - 1)""


# Acknowledgements

Creators: 

	Dr. William H. Wolberg, General Surgery Dept., University of
	Wisconsin,  Clinical Sciences Center, Madison, WI 53792
	wolberg@eagle.surgery.wisc.edu

	W. Nick Street, Computer Sciences Dept., University of
	Wisconsin, 1210 West Dayton St., Madison, WI 53706
	street@cs.wisc.edu  608-262-6619

	Olvi L. Mangasarian, Computer Sciences Dept., University of
	Wisconsin, 1210 West Dayton St., Madison, WI 53706
	olvi@cs.wisc.edu 



# Inspiration

I'm really interested in trying out various machine learning algorithms on some real life science data.",.csv
Breast Cancer Wisconsin Diagnostic Dataset,1,breast-cancer-wisconsin-diagnostic-dataset,brca.csv,CC0-1.0,"```
➡️ This is a classic dataset for training and benchmarking machine learning algorithms.
➡️ Biopsy features for classification of 569 malignant (cancer) and benign (not cancer) breast masses.
➡️ Features were computationally extracted from digital images of fine needle aspirate biopsy slides. Features correspond to properties of cell nuclei, such as size, shape and regularity. The mean, standard error, and worst value of each of 10 nuclear parameters is reported for a total of 30 features.
```
| Column | Description |
| --- | --- |
| x.radius_mean | Mean radius of the tumor cells |
| x.radius_mean | Mean radius of the tumor cells |
| x.texture_mean | Mean texture of the tumor cells |
| x.perimeter_mean | Mean perimeter of the tumor cells |
| x.area_mean | Mean area of the tumor cells |
| x.smoothness_mean | Mean smoothness of the tumor cells |
| x.compactness_mean | Mean compactness of the tumor cells |
| x.concavity_mean | Mean concavity of the tumor cells |
| x.concave_points_mean | Mean number of concave portions of the contour of the tumor cells |
| x.symmetry_mean | Mean symmetry of the tumor cells |
| x.fractal_dimension_mean | Mean ""coastline approximation"" of the tumor cells |
| x.radius_se | Standard error of the radius of the tumor cells |
| x.texture_se | Standard error of the texture of the tumor cells |
| x.perimeter_se | Standard error of the perimeter of the tumor cells |
| x.area_se | Standard error of the area of the tumor cells |
| x.smoothness_se | Standard error of the smoothness of the tumor cells |
| x.compactness_se | Standard error of the compactness of the tumor cells |
| x.concavity_se | Standard error of the concavity of the tumor cells |
| x.concave_points_se | Standard error of the number of concave portions of the contour of the tumor cells |
| x.symmetry_se | Standard error of the symmetry of the tumor cells |
| x.fractal_dimension_se | Standard error of the ""coastline approximation"" of the tumor cells |
| x.radius_worst | Worst (largest) radius of the tumor cells |
| x.texture_worst | Worst (most severe) texture of the tumor cells |
| x.perimeter_worst | Worst (largest) perimeter of the tumor cells |
| x.area_worst | Worst (largest) area of the tumor cells |
| x.smoothness_worst | Worst (most severe) smoothness of the tumor cells |
| x.compactness_worst | Worst (most severe) compactness of the tumor cells |
| x.concavity_worst | Worst (most severe) concavity of the tumor cells |
| x.concave_points_worst | Worst (most severe) number of concave portions of the contour of the tumor cells |
| x.symmetry_worst | Worst (most severe) symmetry of the tumor cells |
| x.fractal_dimension_worst | Worst (most severe) ""coastline approximation"" of the tumor cells |
| y | target |

## Details (Important)
- y. The outcomes. A factor with two levels denoting whether a mass is malignant (""M"") or benign (""B"").
- x. The predictors. A matrix with the mean, standard error and worst value of each of 10 nuclear measurements on the slide, for 30 total features per biopsy:
- radius. Nucleus radius (mean of distances from center to points on perimeter).
- texture. Nucleus texture (standard deviation of grayscale values).
- perimeter. Nucleus perimeter.
- area. Nucleus area.
- smoothness. Nucleus smoothness (local variation in radius lengths).
- compactness. Nucleus compactness (perimeter^2/area - 1).
- concavity, Nucleus concavity (severity of concave portions of the contour).
- concave_pts. Number of concave portions of the nucleus contour.
- symmetry. Nucleus symmetry.
- fractal_dim. Nucleus fractal dimension (""coastline approximation"" -1).",.csv
Brent Oil Prices,1,brent-oil-prices,BrentOilPrices.csv,U.S. Government Works,"### Context

The crude oil price movements are subject to diverse influencing factors. This dataset was retrieved from the U.S. Energy Information Administration: <a href=""https://www.eia.gov/dnav/pet/hist_xls/RBRTEd.xls"">Europe Brent Spot Price FOB (Dollars per Barrel)</a>

### Content

The aim of this dataset and work is to predict future Crude Oil Prices based on the historical data available in the dataset.
The data contains daily Brent oil prices from 17th of May 1987 until the 13th of November 2022.


### Acknowledgements

Dataset is available on U.S. Energy Information Administration: <a href=""https://www.eia.gov/dnav/pet/hist_xls/RBRTEd.xls"">Europe Brent Spot Price FOB (Dollars per Barrel)</a> which is updated on weekly bases.


### Inspiration

The vast competition in the Data Science field and the availability of the new Prophet method made it easier to predict future prices, that is what you may find when predicting the oil prices with this dataset.",.csv
British Airways Passenger Reviews (2016 - 2023),1,british-airways-passenger-reviews-2016-2023,British_Airway_Review.csv,CC0-1.0,"British Airways, one of the world's leading airlines, has been synonymous with excellence and reliability for decades. With a rich history and a commitment to providing exceptional customer experiences, British Airways continues to be a preferred choice for travelers worldwide.

As part of a challenging and rewarding data science project at British Airways, I had the opportunity to work on web scraping review data from the renowned Skytrax website. The goal was to collect valuable insights from customer reviews and leverage data-driven approaches to enhance the airline's services and customer satisfaction.

The dataset comprises the following columns, each providing essential information extracted from the reviews:

**Reviews:** This column contains the text-based feedback and reviews provided by customers after their experience with British Airways.

**Date:** The date on which the review was posted by the customer, offering valuable temporal information.

**Stars:** The rating given by the traveler, typically on a scale of 1 to 5 stars, reflecting their overall satisfaction with the airline's services.

**Type of Traveler:** This column categorizes the type of traveler who left the review, distinguishing between different travel demographics, such as business travelers, families, or solo adventurers.

**Type of Seat:** Provides insights into the type of seat the traveler experienced during their flight, including economy, premium economy, business, or first class.

**Country:** Indicates the country of origin of the customer, allowing for regional analysis and understanding customer preferences.

**Recommended:** A binary indicator that reflects whether the traveler would recommend British Airways based on their experience.

**Route:** This column provides information about the specific route or flight taken by the passengers, offering context to their reviews and experiences.

",.csv
Broadcom Inc. Financial Overview,1,broadcom-inc-financial-overview,AVGO_data.csv,Apache 2.0,"This dataset contains historical financial data for Broadcom Inc. (AVGO), including daily stock prices, trading volume, and other key market indicators. Whether you're exploring AVGO's market trends, analyzing its stock performance, or identifying patterns over time, this dataset offers valuable insights into one of the leading technology and semiconductor companies. Utilize this data to enhance your research, build models, or gain a deeper understanding of AVGO's role in the market",.csv
Bullying in schools ,1,bullying-in-schools,Bullying_2018.csv,CC0-1.0,"The Global School-Based Student Health Survey (GSHS) is a school-based survey which uses a self-administered questionnaire to obtain data on young people's health behaviour and protective factors related to the leading causes of morbidity and mortality. 
The survey was conducted in Argentina in 2018.A total of 56,981 students participated.
The school response rate was 86%, the student response rate was 74%, and the overall response rate was 63%. 

**About the development of a bullying prediction model**

From the GHSH, the survey questions related to bullying were selected. This is with the aim of developing a model that allows preventing it.
Some of the indicators of bullying have been related to feelings of loneliness, lack of close friends, poor communication with parents, absence from classes. (eg. Nansel et al Bullying behaviors among US youth: Prevalence and association with psychosocial adjustment)
Likewise, young people identified by bullies as underweight, overweight and obese have been bullied.

**Selected variables**

Bullied on school property in past 12 months, 
Bullied not on school property in past 12_months
Cyber bullied in past 12 months
Custom Age
Sex
Physically attacked
Physical fighting
Felt lonely
Close friends
Miss school no permission 	
Other students kind and helpful 
Parents understand problems
Most of the time or always felt lonely
Missed classes or school without permission
Were underweight
Were overweight
Were obese


**Objective (suggested)**
Develop a model that allows predicting bullying based on the variables selected from the Global School-Based Student Health Survey.

",.csv
Burden of Disease,1,burden-of-disease,dalysratefromallcauses new.csv,CC0-1.0,"this graph was retired the OurDataWorld :

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F79611222f751ba891c5e9378726dabfc%2Fgraph1.png?generation=1712265885082091&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Ff7a0644477ef0ff805e3d7e3cee1d78a%2Fgraph4.png?generation=1712265891432314&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fc3ba92c4bb492422e26531f246086ac3%2Fgraph2.png?generation=1712265897808530&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F2c4a7f2f936e16e01899b3b1b3b628a0%2Fgraph3.png?generation=1712265903862580&alt=media)

Assessing the health of a population requires a multifaceted approach that goes beyond simply looking at mortality rates or life expectancy. While these metrics offer valuable insights, they fail to capture the full extent of suffering caused by diseases that afflict individuals while they are still alive. To address this limitation, researchers have developed a comprehensive concept known as the ""burden of disease,"" which encompasses both mortality and morbidity. At the heart of quantifying this burden lies a metric called Disability Adjusted Life Years (DALYs), which serves as a standardized unit to measure lost health. By examining DALYs, researchers can compare the impact of different diseases across countries, populations, and time periods, providing a more nuanced understanding of health outcomes.

DALYs represent a powerful tool in public health research, allowing policymakers and healthcare professionals to prioritize interventions and allocate resources effectively. Conceptually, one DALY equates to one lost year of healthy life, reflecting either premature death or the presence of disease and disability. Since the 1990s, the Global Burden of Disease (GBD) study conducted by the Institute of Health Metrics and Evaluation (IHME) and the Disease Burden Unit of the World Health Organization (WHO) have been instrumental in generating DALY estimates. These efforts have been further underscored by the inclusion of DALYs in influential reports such as the World Bank's World Development Report in 1993.

The significance of DALYs lies in their ability to capture the true impact of diseases on human well-being. By accounting for both mortality and morbidity, DALYs provide a more holistic perspective on health outcomes. For instance, while a disease may not directly result in death, it could significantly diminish an individual's quality of life through disability or chronic illness. By quantifying these impacts, DALYs enable researchers to prioritize interventions that aim to alleviate suffering and improve overall health.

One of the key advantages of DALYs is their flexibility in capturing a wide range of health conditions. Whether it's infectious diseases like malaria and tuberculosis, chronic conditions such as diabetes and cardiovascular disease, or mental health disorders like depression and anxiety, DALYs offer a comprehensive framework for assessing the burden of diverse health issues. Moreover, DALYs can be disaggregated by age, gender, disease type, and geographical location, providing granular insights into disparities in health outcomes.

The global data on the burden of disease paint a nuanced picture of the health challenges facing different populations. Across countries, significant variations exist in the distribution of DALYs, reflecting disparities in healthcare access, socioeconomic status, and environmental factors. Developing regions often bear a disproportionate burden, with infectious diseases and maternal and child health issues contributing significantly to the DALYs. In contrast, developed countries may grapple with a higher burden of non-communicable diseases due to aging populations and lifestyle factors.

The age distribution of DALYs further highlights distinct patterns in disease burden. While infectious diseases and injuries tend to predominate among younger age groups, non-communicable diseases become more prevalent as populations age. This demographic transition underscores the need for tailored healthcare strategies that address the evolving health needs of different age cohorts.

Moreover, the type of disability associated with DALYs offers insights into the specific health challenges faced by individuals. Whether it's physical impairments, mental health disorders, or cognitive disabilities, understanding the nature of disability can inform targeted interventions aimed at improving functional outcomes and enhancing overall well-being.

Despite its utility, DALYs are not without limitations. Criticisms have been raised regarding the methodology used to calculate DALYs, including uncertainties in disability weights and the potential for double counting when assessing comorbidities. Additionally, DALYs may not fully capture the subjective experience of living with a particular health condition, raising questions about their validity as a measure of health-related quality of life.

In conclusion, the concept of DALYs represents a significant advancement in public health research, offering a comprehensive framework for assessing the burden of disease. By integrating mortality and morbidity into a single metric, DALYs provide policymakers and healthcare practitioners with valuable insights into the health needs of populations worldwide. While challenges remain in refining the methodology and addressing limitations, DALYs remain an invaluable tool for guiding efforts to promote health equity and improve the well-being of communities globally.",.csv
Burger King Menu Nutrition Data,1,burger-king-menu-nutrition-data,burger-king-menu.csv,CC0-1.0,"This dataset is a comprehensive collection of nutritional information for all major menu items offered by Burger King. The dataset includes information on the number of calories, total fat, saturated fat, trans fat, cholesterol, sodium, total carbohydrates, and protein found in each menu item. 

This information allows individuals to make informed decisions about their dietary intake and helps them to better manage their health and wellness. The dataset can be used by individuals, healthcare providers, and researchers to better understand the nutritional content of the Burger King menu and to develop strategies for improving the healthfulness of the food offered by the restaurant chain.

Tabular data includes:

- `Item`
- `Category`
- `Calories`
- `Fat Calories`
- `Fat (g)`
- `Sat Fat (g)`
- `Trans Fat (g)`
- `Cholesterol (mg)`
- `Sodium (mg)`
- `Total Carb (g)`
- `Dietary Fiber (g)`
- `Sugars (g)`
- `Protein (g)`
- `Weight Watchers`",.csv
"CARS DATASET (Audi, BMW, Ford, Hyundai, Skoda, VW)",1,cars-dataset-audi-bmw-ford-hyundai-skoda-vw,cars_dataset.csv,other,"Are you a beginner ?
Looking for some easy datasets to practice?  Well, this dataset will be a head start in your data science career!

 
This dataset is the stacked version of **100,000 UK Used Car Data set** present in Kaggle. Here I have combined the used car information of 7 brands namely Audi, BMW, Skoda, Ford, Volkswagen, Toyota and Hyundai.  

###About this dataset :
1. No. of Rows = 72435
2. No. of Columns = 10

The cleaned data set contains information of price, transmission, mileage, fuel type, road tax, miles per gallon (mpg), and engine size.
Ideas to expand this dataset , innovative visualizations and lot more possible ways to manipulate this dataset is welcome. 

 ",.csv
"CDC Data: Nutrition, Physical Activity, & Obesity",1,cdc-data-nutrition-physical-activity-obesity,Nutrition__Physical_Activity__and_Obesity_-_Behavioral_Risk_Factor_Surveillance_System.csv,CC0-1.0,"This dataset includes data on adult's diet, physical activity, and weight status from Behavioral Risk Factor Surveillance System. This data is used for DNPAO's Data, Trends, and Maps database, which provides national and state specific data on obesity, nutrition, physical activity, and breastfeeding.  I was particularly curious on whether socioeconomic status has an impact on obesity.  In my analysis, I compare the obesity rate in each state, and then perform a linear regression on the obesity rate for each educational status and the income bracket.  
",.csv
CDC STATE System Tobacco Legislation | Youth,1,cdc-state-system-tobacco-legislation-youth,CDC_STATE_System_Tobacco_Legislation_-_Youth_Access_20240419.csv,ODC Attribution License (ODC-By),"**Description:**

1995-2024. Centers for Disease Control and Prevention (CDC). State Tobacco Activities Tracking and Evaluation (STATE) System. Legislation—Youth Access. The STATE System houses current and historical state-level legislative data on tobacco use prevention and control policies. Data are reported on a quarterly basis. Data include information related to restrictions, enforcement and penalties associated with the sale of cigarettes to youth through retail sales and vending machines.

**Authors:**

Centers for Disease Control and Prevention, National Center for Chronic Disease Prevention and Health Promotion, Office on Smoking and Health

**Dataset updated:**

Apr 1, 2024

**Dataset provided by:**

Centers for Disease Control and Prevention

**License:**

Open Data Commons Attribution License (ODC-By) v1.0",.csv
CK+ Dataset,1,ckdataset,ckextended.csv,CC0-1.0,"Contains adaptaded data **up to 920 images from 920 original CK+ dataset**

Data is already reshaped to **48x48 pixels**, in **grayscale format** and facecropped using **haarcascade_frontalface_default**. 

Noisy (based on room light/hair format/skin colour) images were adapted to be clearly identified using Haar classifier.

Columns from file are defined as emotion/pixels/Usage

**Emotions are defined as determined index below:**
- **0** : Anger (45 samples)
- **1** : Disgust (59 samples)
- **2** : Fear (25 samples)
- **3** : Happiness (69 samples)
- **4** : Sadness (28 samples)
- **5** : Surprise (83 samples)
- **6** : Neutral (593 samples)
- **7** : Contempt (18 samples)

Pixels contains **2304 pixels** (48x48) each row.
Usage is determined as **Training(80%) / PublicTest(10%) / PrivateTest(10%)**

This dataset was first developed to make a comparison to [ROHIT VERMA - FER2013].(https://www.kaggle.com/datasets/deadskull7/fer2013)


Any problem with dataset feel free to ask.
Updates will only happen to improve data, as collaborators show up to help.",.csv
CMS. J/psi to two muons from 2011,1,cms-jpsi-to-two-muons-from-2011,Jpsimumu.csv,Apache 2.0,"This document contains 20k events where two muon candidates with invariant mass near the mass of J/psi were observed. The data was selected from the primary dataset DoubleMu 2011. These data were selected for use in education and outreach and contain a subset of the total event information. They are not suitable for a full physics analysis.

Related datasets
This data file and other similar data files can be found from
Datasets derived from the Run2011A SingleElectron, SingleMu, DoubleElectron, and DoubleMu primary datasets

https://opendata.cern.ch/record/5203",.csv
CO2 Emission by countries Year wise (1750-2022) ,1,co2-emission-by-countries-year-wise-17502022,CO2 emission by countries.csv,CC0-1.0,This dataset will help researchers and environemnt experts to predict about the global warming. So that countries should seta goal to decrease this amount yearly.,.csv
CO2 Emissions (in U.S.),1,u-s-co2-emissions,emissions.csv,U.S. Government Works,"# U.S. Carbon Dioxide Emissions by State, Sector, and Fuel Type

This dataset contains carbon dioxide emissions data for various U.S. states from 1970 onwards. The data is broken down by state, sector (residential, commercial, transportation, electric power, and industrial), and fuel type (coal, petroleum, natural gas, and all fuels combined). The emissions values are measured in million metric tons of carbon dioxide.

## Columns

1. `year`: The year for which the emissions data is provided (e.g., 1970).
2. `state-name`: The name of the U.S. state (e.g., Alabama, Alaska, Arizona).
3. `sector-name`: The sector for which the emissions data is provided. The sectors include:
  - Residential carbon dioxide emissions
  - Commercial carbon dioxide emissions
  - Transportation carbon dioxide emissions
  - Electric Power carbon dioxide emissions
  - Industrial carbon dioxide emissions
  - Total carbon dioxide emissions from all sectors
4. `fuel-name`: The type of fuel contributing to the carbon dioxide emissions. The fuel types include:
  - Coal
  - Petroleum
  - Natural Gas
  - All Fuels (representing the total emissions from all fuel types combined)
5. `value`: The carbon dioxide emissions value in million metric tons for the specified year, state, sector, and fuel type.

This dataset can be used to analyze trends in carbon dioxide emissions over time, compare emissions across different states and sectors, and understand the contribution of various fuel types to overall emissions. It provides valuable insights into the energy consumption and environmental impact of different industries and regions in the United States.

Potential use cases for this dataset include:
- Researchers and policymakers can use this data to study the effectiveness of emissions reduction policies and identify areas for improvement.
- Environmentalists and advocacy groups can leverage this information to raise awareness about the carbon footprint of different states and sectors, and push for cleaner energy solutions.
- Businesses and investors can utilize this data to assess the environmental sustainability of various industries and make informed decisions about investments and partnerships.
- Educators and students can explore this dataset to learn about the factors contributing to carbon dioxide emissions and develop projects or research papers on related topics.",.csv
CO2 Emissions Around the World,1,co2-emission-around-the-world,CO2_emission.csv,CC0-1.0,"#### This Dataset consists CO2 emissions  in metricton per capita of every country around the world. The datas are from 1990 to 2019. Coutries regions are included. Data is collected from world data bank. The link is given. https://data.worldbank.org/indicator/EN.ATM.CO2E.PC
Data is initially preprocessed using excel.

**Thank you for visiting**

",.csv
CO2 Emissions _ 1960 - 2018,1,co2-emissions-1960-2018,CO2_Emissions_1960-2018.csv,Attribution 4.0 International (CC BY 4.0),"### CO2 emissions (metric tons per capita)

Global CO2 Emissions from 1960 to 2018.


### Acknowledgements

https://data.worldbank.org/

### Tasks
- Country with highest/lowest emissions
- Data Visualisation (world map)
",.csv
CO2 emission of cars dataset,1,co2-emission-of-cars-dataset,DATA.csv,CC0-1.0,This dataset contains the co2 emission of different types of cars.The independent feature variables are VOLUME and WEIGHT.This data set can predict the target variable y using linear regression in the most easy way.I have predicted the coefficients and new data prediction which can help you find an alternative target value using this regression model.,.csv
CO2_GHG_emissions-data,1,co2-ghg-emissionsdata,co2_emission.csv,Attribution 4.0 International (CC BY 4.0),"# Context

I made this dataset because there is (I think) some mistakes with another Kaggle Dataset regarding CO2 ans GHG emissions (https://www.kaggle.com/srikantsahu/co2-and-ghg-emission-data).

# Content

This dataset contains CO2 and GHG emissions for countries since 1750 until 2017. 
The source is OurWorldInData (https://ourworldindata.org/co2-and-other-greenhouse-gas-emissions).",.csv
COCO COLA Stock Data (1962-2021),1,coco-cola-stock-data-19622021,COCO COLA.csv,DbCL-1.0,"### Context

This is a Dataset for Stock Price of COCO COLA (KO) NYSE - NYSE Delayed Price, Currency in USD.
This dataset start from 19 Jan 1962 to 19 Dec 2021 .
 It was collected from [Yahoo Finance](https://finance.yahoo.com/quote/KO/history?p=KO)
You can perform Time Series Analysis and EDA on data.",.csv
COVID Vaccination in World (updated daily),1,covid-vaccination-dataset,vaccinations.csv,CC0-1.0,"### Context

The data is collected from OWID (Our World in Data) GitHub repository, which is updated on daily bases.


### Content
This dataset contains only one file `vaccinations.csv`, which contains the records of vaccination doses received by people from all the countries.
* `location`: name of the country (or region within a country).
* `iso_code`: ISO 3166-1 alpha-3 – three-letter country codes.
* `date`: date of the observation.
* `total_vaccinations`: total number of doses administered. This is counted as a single dose, and may not equal the total number of people vaccinated, depending on the specific dose regime (e.g. people receive multiple doses). If a person receives one dose of the vaccine, this metric goes up by 1. If they receive a second dose, it goes up by 1 again.
* `total_vaccinations_per_hundred`: `total_vaccinations` per 100 people in the total population of the country.
* `daily_vaccinations_raw`: daily change in the total number of doses administered. It is only calculated for consecutive days. This is a raw measure provided for data checks and transparency, but we strongly recommend that any analysis on daily vaccination rates be conducted using `daily_vaccinations` instead.
* `daily_vaccinations`: new doses administered per day (7-day smoothed). For countries that don't report data on a daily basis, we assume that doses changed equally on a daily basis over any periods in which no data was reported. This produces a complete series of daily figures, which is then averaged over a rolling 7-day window. An example of how we perform this calculation can be found [here](https://github.com/owid/covid-19-data/issues/333#issuecomment-763015298).
* `daily_vaccinations_per_million`: `daily_vaccinations` per 1,000,000 people in the total population of the country.
* `people_vaccinated`: total number of people who received at least one vaccine dose. If a person receives the first dose of a 2-dose vaccine, this metric goes up by 1. If they receive the second dose, the metric stays the same.
* `people_vaccinated_per_hundred`: `people_vaccinated` per 100 people in the total population of the country.
* `people_fully_vaccinated`: total number of people who received all doses prescribed by the vaccination protocol. If a person receives the first dose of a 2-dose vaccine, this metric stays the same. If they receive the second dose, the metric goes up by 1.
* `people_fully_vaccinated_per_hundred`: `people_fully_vaccinated` per 100 people in the total population of the country.

Note: for `people_vaccinated` and `people_fully_vaccinated` we are dependent on the necessary data being made available, so we may not be able to make these metrics available for some countries.


### Acknowledgements
This data collected by [`Our World in Data`](https://github.com/owid/covid-19-data/tree/master/public/data) which gets updated daily on their Github.


### Inspiration
Possible uses for this dataset could include:
- Sentiment analysis in a variety of forms
- Statistical analysis over time.
",.csv
COVID vaccination vs. mortality ,1,covid-vaccination-vs-death,covid-vaccination-vs-death_ratio.csv,CC0-1.0,"### Context

The COVID-19 outbreak has brought the whole planet to its knees.More over 4.5 million people have died since the writing of this notebook, and the only acceptable way out of the disaster is to vaccinate all parts of society. Despite the fact that the benefits of vaccination have been proved to the world many times, anti-vaccine groups are springing up all over the world. This data set was generated to investigate the impact of coronavirus vaccinations on coronavirus mortality. 


### Content
| country | iso_code | date | total_vaccinations | people_vaccinated | people_fully_vaccinated | New_deaths | population | ratio |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| country name  | iso code for each country | date that this data belong | number of all doses of COVID vaccine usage in that country | number of people who got at least one shot of COVID vaccine | number of people who got full vaccine shots  | number of daily new deaths | 2021 country population | % of vaccinations in that country at that date = people_vaccinated/population * 100 |


### Data Collection
This dataset is a combination of the following three datasets:

 1.https://www.kaggle.com/gpreda/covid-world-vaccination-progress 
 
 2.https://covid19.who.int/WHO-COVID-19-global-data.csv 
 
 3.https://www.kaggle.com/rsrishav/world-population 
 
 you can find more detail about this dataset by reading this notebook: 
 
 https://www.kaggle.com/sinakaraji/simple-linear-regression-covid-vaccination

### Countries in this dataset:

||||||
| --- | --- | --- | --- | --- |
| Afghanistan | Albania | Algeria | Andorra | Angola |
| Anguilla | Antigua and Barbuda | Argentina | Armenia | Aruba |
| Australia | Austria | Azerbaijan | Bahamas | Bahrain |
| Bangladesh | Barbados | Belarus | Belgium | Belize |
| Benin | Bermuda | Bhutan | Bolivia (Plurinational State of) | Brazil |
| Bosnia and Herzegovina | Botswana | Brunei Darussalam | Bulgaria | Burkina Faso |
| Cambodia | Cameroon | Canada | Cabo Verde | Cayman Islands |
| Central African Republic | Chad | Chile | China | Colombia |
| Comoros | Cook Islands | Costa Rica | Croatia | Cuba |
| Curaçao | Cyprus | Denmark | Djibouti | Dominica |
| Dominican Republic | Ecuador | Egypt | El Salvador | Equatorial Guinea |
| Estonia | Ethiopia | Falkland Islands (Malvinas) | Fiji | Finland | 
| France | French Polynesia | Gabon | Gambia | Georgia | 
| Germany | Ghana | Gibraltar | Greece | Greenland |
| Grenada | Guatemala | Guinea | Guinea-Bissau | Guyana | 
| Haiti | Honduras | Hungary | Iceland | India |
| Indonesia | Iran (Islamic Republic of) | Iraq | Ireland | Isle of Man |
| Israel | Italy | Jamaica | Japan | Jordan |
| Kazakhstan | Kenya | Kiribati | Kuwait | Kyrgyzstan |
| Lao People's Democratic Republic | Latvia | Lebanon | Lesotho | Liberia |
| Libya | Liechtenstein | Lithuania | Luxembourg | Madagascar |
| Malawi | Malaysia | Maldives | Mali | Malta |
| Mauritania | Mauritius | Mexico | Republic of Moldova | Monaco |
| Mongolia | Montenegro | Montserrat | Morocco | Mozambique |
| Myanmar | Namibia | Nauru | Nepal | Netherlands |
| New Caledonia | New Zealand | Nicaragua | Niger | Nigeria |
| Niue | North Macedonia | Norway | Oman | Pakistan |
| occupied Palestinian territory, including east Jerusalem |||||
| Panama | Papua New Guinea | Paraguay | Peru | Philippines |
| Poland | Portugal | Qatar | Romania | Russian Federation |
| Rwanda | Saint Kitts and Nevis | Saint Lucia |
| Saint Vincent and the Grenadines | Samoa | San Marino | Sao Tome and Principe | Saudi Arabia |
| Senegal | Serbia | Seychelles | Sierra Leone | Singapore |
| Slovakia | Slovenia | Solomon Islands | Somalia | South Africa |
| Republic of Korea | South Sudan | Spain | Sri Lanka | Sudan |
| Suriname | Sweden | Switzerland | Syrian Arab Republic | Tajikistan |
| United Republic of Tanzania | Thailand | Togo | Tonga | Trinidad and Tobago |
| Tunisia | Turkey | Turkmenistan | Turks and Caicos Islands | Tuvalu |
| Uganda | Ukraine | United Arab Emirates | The United Kingdom | United States of America |
| Uruguay | Uzbekistan | Vanuatu | Venezuela (Bolivarian Republic of) | Viet Nam |
| Wallis and Futuna | Yemen | Zambia | Zimbabwe ||",.csv
COVID-19 Coronavirus Dataset,1,covid19-coronavirus,2019_nCoV_data.csv,CC0-1.0,"### Context

A SARS-like virus outbreak originating in Wuhan, China, is spreading into neighboring Asian countries, and as far afield as Australia, the US a and Europe. 

On 31 December 2019, the Chinese authorities reported a case of pneumonia with an unknown cause in Wuhan, Hubei province, to the World Health Organisation (WHO)’s China Office. As more and more cases emerged, totaling 44 by 3 January, the country’s National Health Commission isolated the virus causing fever and flu-like symptoms and identified it as a novel coronavirus, now known to the WHO as 2019-nCoV.

The following dataset shows the numbers of spreading coronavirus across the globe. 


### Content

Sno - Serial number
Date - Date of the observation
Province / State - Province or state of the observation
Country - Country of observation
Last Update - Recent update (not accurate in terms of time)
Confirmed - Number of confirmed cases
Deaths - Number of death cases
Recovered - Number of recovered cases


### Acknowledgements

Thanks to John Hopkins CSSE for the live updates on Coronavirus and data streaming.
Source: https://github.com/CSSEGISandData/COVID-19
Dashboard: https://public.tableau.com/profile/vignesh.coumarane#!/vizhome/DashboardToupload/Dashboard12


### Inspiration

Inspired by the following work:
https://gisanddata.maps.arcgis.com/apps/opsdashboard/index.html#/bda7594740fd40299423467b48e9ecf6",.csv
COVID-19 Coronavirus Pandemic,1,covid19-coronavirus-pandemic,COVID-19 Coronavirus.csv,CC0-1.0,"Dataset contains, Total cases, Total Deaths, Total Cases//1M pop, Total Deaths/1M pop, Death percentage related to COVID 19 Coronovirus pandemic. 

Dataset obtained from Worldometer website. It is updated daily on their website. ",.csv
COVID-19 GLOBAL-Dataset,1,covid-19-global-dataset,COVID-19 Global - Dataset.csv,MIT,"About Dataset
The COVID-19 Global Dataset offers comprehensive insights into the impact of the COVID-19 pandemic worldwide. It provides detailed statistics on COVID-19 cases, deaths, recoveries, testing, and demographic information across various countries and regions. Sourced from reliable sources, including government health departments and international organizations, this dataset serves as a valuable resource for researchers, policymakers, and public health experts to track the progression of the pandemic, analyze trends, and inform evidence-based decision-making.

I have gone through many websites where many scientists want to portray that there is a positive impact on weather conditions and spread of viruses. If the virus lives on this earth it has to support certain conditions like temperature, host, dryness etc. Lower the temperature means higher rate of chances to survive a virus

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F18750084%2Fe53febf39c5bd59c751161c3ef14064e%2Fcoronavirus%20%20Disease(COVID-19%20)%20world%20Map.jpg?generation=1710004272575709&alt=media)
",.csv
COVID-19 Global Statistics Dataset,1,covid-19-global-statistics-dataset,COVID-19 Global Statistics Dataset.csv,MIT,"The COVID-19 Global Statistics Dataset offers comprehensive insights into the impact of the COVID-19 pandemic worldwide. It provides detailed statistics on COVID-19 cases, deaths, recoveries, testing, and demographic information across various countries and regions. Sourced from reliable sources, including government health departments and international organizations, this dataset serves as a valuable resource for researchers, policymakers, and public health experts to track the progression of the pandemic, analyze trends, and inform evidence-based decision-making.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F18544731%2F9afe37cc67296c95c7c97b2800f5d1ca%2Fwhy-cant-covid-be-eradicated.jpeg?generation=1708544957219605&alt=media)",.csv
COVID-19 Indonesia Dataset,1,covid19-indonesia,covid_19_indonesia_time_series_all.csv,CC-BY-NC-SA-4.0,"### Context

The COVID-19 dataset in Indonesia was created to find out various factors that could be taken into consideration in decision making related to the level of stringency in each province in Indonesia.

### Content

Data compiled based on time series, both on a country level (Indonesia), and on a province level. If needed in certain provinces, it might also be provided at the city / regency level.

Demographic data is also available, as well as calculations between demographic data and COVID-19 pandemic data.

### Acknowledgements

Thank you to those who have provided data openly so that we can compile it into a dataset here, which is as follows: covid19.go.id, kemendagri.go.id, bps.go.id, and bnpb-inacovid19.hub.arcgis.com",.csv
COVID-19 Spread Rate in Indonesia,1,covid-19-spread-rate-in-indonesia,Covid-19 Indonesia Dataset.csv,MIT,"This dataset presents an in-depth analysis of the spread of COVID-19 in Indonesia over the period 2020-2022. Using detailed data from multiple sources, the analysis exposes the virus spread trends, geographical patterns and factors influencing the spread. Through sophisticated statistical modeling and data visualization, the study explores factors such as the number of cases, total deaths and total recoveries. The findings from this study can provide valuable insights for public health policy as well as assist in future crisis response planning.",.csv
COVID-19 and its Impact on Students,1,covid19-and-its-impact-on-students,COVID-19 Survey Student Responses.csv,CC0-1.0,"# COVID-19 and its impact on education, social life and mental health of students: A Survey  [Link to the paper](https://www.researchgate.net/publication/347935769_COVID-19_and_its_impact_on_education_social_life_and_mental_health_of_students_A_Survey)

In this study, a cross-sectional survey is conducted with a sample size of 1182 students of different age groups from different educational institutions in Delhi National Capital Region (NCR). 


## Citation
@article{CHATURVEDI2020105866,
title = ""COVID-19 and its impact on education, social life and mental health of students: A Survey"",
journal = ""Children and Youth Services Review"",
pages = ""105866"",
year = ""2020"",
issn = ""0190-7409"",
doi = ""https://doi.org/10.1016/j.childyouth.2020.105866"",
url = ""http://www.sciencedirect.com/science/article/pii/S019074092032288X"",
author = ""Kunal Chaturvedi and Dinesh Kumar Vishwakarma and  Nidhi"",
keywords = ""Children and Youth, Covid-19, Impact, Online Education, Mental Health, Students"",
}
",.csv
COVID-19 containment and mitigation measures,1,covid19-containment-and-mitigation-measures,COVID 19 Containment measures data.csv,other,"### Context

Dataset of COVID-19 containment and mitigation measures
http://epidemicforecasting.org/containment

The dataset attempts to cover all measures of national significance intended to reduce the transmission of COVID-19, in all the worlds nations.  

This is work in progress.  Currently there are &gt; 1000 entries.  More details at http://epidemicforecasting.org/containment

This dataset pairs well with [this dataset](https://www.kaggle.com/paultimothymooney/oxford-covid19-government-response-tracker) that has more than 10,000 entires.

### Content

Each measure in the database has entries on:
- Country (and state for the US)
 - Textual description of the measure
 - Start date of measure
 - End date (if available)
 - URL to source of more information
 - Systematic keyword labels (e.g. ""travel ban"" or ""hygiene enforcement"")


### Acknowledgements

Banner Photo [by CDC on Unsplash ](https://unsplash.com/photos/LiNIONbajm4)

Data from http://epidemicforecasting.org/containment

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F1314380%2Fc60f5e25ce0bdfa153252db4d3c97904%2FScreen%20Shot%202020-03-24%20at%204.32.37%20PM.png?generation=1585089172529526&alt=media)
",.csv
CS:GO Round Winner Classification,1,csgo-round-winner-classification,csgo_round_snapshots.csv,CC0-1.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F4895752%2Fbf6d1be3b18ade8bd780840fd8f871c1%2FU78nzyG.jpg?generation=1597522833435019&alt=media)

# Context

CS:GO is a tactical shooter, where two teams (CT and Terrorist) play for a best of 30 rounds, with each round being 1 minute and 55 seconds. There are 5 players on each team (10 in total) and the first team to reach 16 rounds wins the game. At the start, one team plays as CT and the other as Terrorist. After 15 rounds played, the teams swap side. There are 7 different maps a game can be played on. You win a round as Terrorist by either planting the bomb and making sure it explodes, or by eliminating the other team. You win a round as CT by either eliminating the other team, or by disarming the bomb, should it have been planted.

# Content

The dataset was originally published by Skybox as part of their CS:GO AI Challenge, running from Spring to Fall 2020. The data set consists of ~700 demos from high level tournament play in 2019 and 2020. Warmup rounds and restarts have been filtered, and for the remaining live rounds a round snapshot have been recorded every 20 seconds until the round is decided. Following the initial publication, It has been pre-processed and flattened to improve readability and make it easier for algorithms to process. The total number of snapshots is 122411.

Skybox website: https://skybox.gg/
Learn more about CS:GO: https://en.wikipedia.org/wiki/Counter-Strike:_Global_Offensive
View CS:GO on Steam Store: https://store.steampowered.com/app/730/CounterStrike_Global_Offensive/
Find in-depth information on competitive CS:GO: https://www.hltv.org/

# Acknowledgements

Thanks to Skybox for taking the time to sample all the snapshots and organising the challenge. It wouldn't be possible to publish any of this without their help.

# Inspiration

* What types of machine learning models perform best on this dataset?
* Which features are most indicative of which teams wins the round?
* How often does the team with most money win?
* Are some weapons favourable to others?
* What attributes should your team have to win? Health, armor or money?

# Data Dictionary

Note: All snapshots are i.i.d in the sense that they each describe the state of a round
and can therefore be treated individually. Although multiple snaphots can be taken from the same round.

You are suppose to predict a label (round winner) based on each individual snapshot.

| Variable | Definition | Key |
| --- | --- |
| time\_left | The time left in the current round. | |
| ct\_score | The current score of the Counter-Terrorist team. | |
| t\_score | The current score of the Terrorist team. | |
| map | The map the round is being played on. | E.g. de\_dust2, de\_inferno and de\_overpass |
| bomb\_planted| If the bomb has been planted or not. | False = No, True = Yes |
| ct\_health| The total health of all Counter-Terrorist players. | Player health in range 0-100. |
| t\_health| The total health of all Terrorist players. | Player health in range 0-100. |
| ct\_armor| The total armor of all Counter-Terrorist players. | |
| t\_armor| The total armor of all Terrorist players. | |
| ct\_money| The total bankroll of all Counter-Terrorist players. | Amount in USD. |
| t\_money| The total bankroll of all Terrorist players. | Amount in USD. |
| ct\_helmets| Number of helmets on the Counter-Terrorist team. | |
| t\_helmets| Number of helmets on the Terrorist team. | |
| ct\_defuse_kits| Number of defuse kits on the Counter-Terrorist team. | |
| ct\_players_alive| Number of alive players on the Counter-Terrorist team. | Range 0 to 5. |
| t\_players_alive| Number of alive players on the Terrorist team. | Range 0 to 5. |
| ct\_weapon_X| Weapon X count on Counter-Terrorist team. | E.g. Ak47, Deagle and UMP45.|
| t\_weapon_X| Weapon X count on Terrorist team. | E.g. Ak47, Deagle and UMP45.|
| ct\_grenade_X| Grenade X count on Counter-Terrorist team. | E.g. HeGrenade, Flashbang. |
| t\_grenade_X| Grenade X count on Terrorist team. | E.g. HeGrenade, Flashbang. |
| round\_winner | Winner. | CT = Counter-Terrorist, T = Terrorist|

# Screenshots

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F4895752%2F6055aaccaae62254c199ad5d6de62c85%2Finbox_4895752_7100b4d7486b0b8b99099f7dadc74337_730_screenshots_2016-01-22_00001%20(2).jpg?generation=1597574095666449&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F4895752%2F391fac1718d81b6c7cf0b53eb231d562%2Finbox_4895752_5e4735cb769c6be5f5872a052d0007e2_841520521_preview_20170113163124_2.jpg?generation=1597574096430659&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F4895752%2Fe4d9e7918fc8c8a0f807867248617ea6%2Finbox_4895752_24c20a9397f513a3252cd3939c10e65f_De_new_inferno.jpg?generation=1597574097229123&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F4895752%2F765af8918340459c0151a0d5fcb4360d%2Finbox_4895752_7c056cda698647131633a9d0e4f56d2f_csgo_2015-06-07_20-17-41.jpg?generation=1597574098549315&alt=media)",.csv
Caffeine Content of Drinks,1,caffeine-content-of-drinks,caffeine.csv,other,"### Information 

List of drinks that generally contains caffeine. Some instances are not drinks exactly. Ground coffee or tea leafs would produce that amount of **Volume (ml)** if prepared according to the provider. They don't have calories since you  can control the sugar level. 

https://www.healthline.com/nutrition/coffee-calories

### Atributes

**drink**: Drink's name.
**Volume (ml)**: Volume quantity.
**Calories**: Calories quantity.
**Caffeine (mg)**: Caffeine quantity.
**type**: Drink's type. (Coffe, Energy Drinks, Energy Shots, Soft Drinks, Tea, Water)

### Source

https://www.caffeineinformer.com/the-caffeine-database",.csv
Calculate Concrete Strength,1,regression-with-neural-networking,concrete_data.csv,CC0-1.0,"## Context

This data set aims to provide a start up for the ones who just started off with deep learning and act as a benchmark.


## Content

The feature set includes:
- Cement
- Blast Furnace Slag
- Fly Ash
- Water
- Super-plasticizer
- Coarse Aggregate
- Fine Aggregate
- Age

The target set is:
- Strength of the Cement


## Inspiration
The main agenda is not only to solve and get better results but understand the process and learn from the journey.
best of luck.",.csv
California Housing Prices,1,california-housing-prices,housing.csv,CC0-1.0,"### Context

This is the dataset used in the second chapter of Aurélien Géron's recent book 'Hands-On Machine learning with Scikit-Learn and TensorFlow'. It serves as an excellent introduction to implementing machine learning algorithms because it requires rudimentary data cleaning, has an easily understandable list of variables and sits at an optimal size between being to toyish and too cumbersome.

The data contains information from the 1990 California census. So although it may not help you with predicting current housing prices like the Zillow Zestimate dataset, it does provide an accessible introductory dataset for teaching people about the basics of machine learning.
  
### Content

The data pertains to the houses found in a given California district and some summary stats about them based on the 1990 census data. Be warned the data aren't cleaned so there are some preprocessing steps required! The columns are as follows, their names are pretty self explanitory:

longitude

latitude

housing_median_age

total_rooms

total_bedrooms

population

households

median_income

median_house_value

ocean_proximity

### Acknowledgements

This data was initially featured in the following paper:
Pace, R. Kelley, and Ronald Barry. ""Sparse spatial autoregressions."" Statistics & Probability Letters 33.3 (1997): 291-297.

and I encountered it in 'Hands-On Machine learning with Scikit-Learn and TensorFlow' by Aurélien Géron.
Aurélien Géron wrote:
This dataset is a modified version of the California Housing dataset available from:
[Luís Torgo's page](http://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html) (University of Porto)

### Inspiration

See my kernel on machine learning basics in R using this dataset, or venture over to the following link for a python based introductory tutorial: https://github.com/ageron/handson-ml/tree/master/datasets/housing",.csv
California WildFires (2013-2020),1,california-wildfire-incidents-20132020,California_Fire_Incidents.csv,CC0-1.0,"**California** is one of the places having the most deadliest and destructive wildfire seasons. The dataset contains the list of Wildfires that has occurred in California between **2013 and 2020**. The dataset contains the location where wildfires have occurred including the County name, latitude and longitude values and also details on when the wildfire has started.

This data helps to generate insights on what locations in California are under fire threat, what time do Wildfires usually occur and how frequent and devastating they are!!",.csv
California house price prediction,1,california-house-price-prediction,california_housing_test_1.csv,Apache 2.0,"The California House Price Prediction system utilizes advanced data analytics to forecast housing prices in the dynamic California real estate market. Drawing from a diverse range of reputable sources including real estate listings, property databases, and government records, this system ensures a robust foundation for analysis. Through meticulous data collection, cleaning, and feature engineering processes, relevant attributes such as property specifications, historical sales data, and neighborhood characteristics are carefully curated to enhance predictive accuracy. Powered by machine learning algorithms, the system provides stakeholders with invaluable insights, empowering them to make informed decisions regarding buying, selling, or investing in California real estate. Whether navigating fluctuating market trends or evaluating property investments, this predictive tool serves as a trusted resource for individuals and professionals alike, facilitating strategic and informed housing decisions.



",.csv
Call Center Data,1,call-center-data,Call Center Data.csv,CC0-1.0,"On daily basis, call centers are handling customers requests and in parallel reaching the defined KPIs targets... ",.csv
Calories Burned During Exercise and Activities,1,calories-burned-during-exercise-and-activities,exercise_dataset.csv,CC-BY-SA-4.0,"### Description:
This dataset contains the number of calories burned by a person while performing some activity/exercise. 
It currently contains 248 activities and exercises ranging from running, cycling, calisthenics, etc.

### Getting started:
Check the [discussion boards](https://www.kaggle.com/aadhavvignesh/calories-burned-during-exercise-and-activities/discussion) or [kernels](https://www.kaggle.com/aadhavvignesh/calories-burned-during-exercise-and-activities/kernels) on how to get started with the dataset.

### Inspiration:
I had been searching for a similar dataset containing the number of calories burned mapped with the exercise names, but couldn't find one. So I compiled this dataset manually!",.csv
Campus Recruitment,1,factors-affecting-campus-placement,Placement_Data_Full_Class.csv,CC0-1.0,"# Hello 

My name is Ben Roshan D, doing MBA in Business Analytics at Jain University Bangalore . We have practical sessions in Python,R as subjects. Faculties provide us with such data sets to work on with it, So here is one of the data set which our class worked on


# What is in it?

This data set consists of Placement data of students in a XYZ campus. It includes secondary and higher secondary school percentage and specialization. It also includes degree specialization, type and Work experience and salary offers to the placed students


# Acknowledgement

I would like to thank Dr. Dhimant Ganatara, Professor Jain University for helping the students by providing this data for us to train R programming 


# Questions

1. Which factor influenced a candidate in getting placed?
2. Does  percentage matters for one to get placed?
3. Which degree specialization is much demanded by corporate?
4. Play with the data conducting all statistical tests.",.csv
Canada National Justice Survey 2016,1,national-justice-survey-2016,njs2016_data.csv,other,"### Context

This dataset is the anonymized result of responses submitted to a survey collected by the Canadian Department of Justice in 2016.  This survey ""...focuses on the criminal justice system (CJS) to inform the current criminal justice system review...[this] involved a traditional public opinion research survey, in informed choice survey and in person and online focus groups...this work was undertaken to support reforms and new initiatives in this area.""

This dataset is the survey component of this review.

### Content

Respondents were asked over 50 questions on their perception of how the Canadian Justice system works at large. This dataset was published in a typical survey output format, in that most questions are 1-10 rating scales or 0-1 True/False questions, with some free-text responses intermixed. To understand the fields, please see the attached data dictionary, or otherwise access it [here](http://www.justice.gc.ca/eng/trans/open-ouvert/rsd-drs/njs2016-snj2016/njs2016_dd_en.xlsx).

### Acknowledgements

This data was published as-is by the Government of Canada, [here](http://canada.justice.gc.ca/eng/rp-pr/jr/index.html). It is licensed under the [Open Government License - Canada](http://open.canada.ca/en/open-government-licence-canada).

### Inspiration

In a time of increasingly invective dialogue between police forces and the people they police, this dataset provides a window on the general level of satisfaction and concern that Canadian government citizens have with their country's justice systems. These results are mostly generalizable to the developed world as a whole.",.csv
Canada Per Capita Income,1,canada-per-capita-income,canada_per_capita_income.csv,CC0-1.0,"### Context
Canada-Income-Per-Capita Dataset
This dataset contains information last 46 years of Canada income-per-capita.


### Content

This data set contains only two columns: Year, Income-per-Capita.

### Acknowledgements
Users can be downloaded, copy and share this dataset.


### Inspiration
Prediction About what would be income-per-capita in 2025
Using Machine Learning Model",.csv
Cancer Data,1,cancer-data,Cancer_Data.csv,CC-BY-NC-SA-4.0,"# **🦠 Breast Cancer Data Set**

**This dataset contains the characteristics of patients diagnosed with cancer. The dataset contains a unique ID for each patient, the type of cancer (diagnosis), the visual characteristics of the cancer and the average values of these characteristics.**

## **📚 The main features of the dataset are as follows:**

1. **id**: Represents a unique ID of each patient.
2. **diagnosis**: Indicates the type of cancer. This property can take the values ""M"" (Malignant - Benign) or ""B"" (Benign - Malignant).
3. **radius_mean, texture_mean, perimeter_mean, area_mean, smoothness_mean, compactness_mean, concavity_mean, concave points_mean**: Represents the mean values of the cancer's visual characteristics.

There are also several categorical features where patients in the dataset are labeled with numerical values. You can examine them in the Chart area.

Other features contain specific ranges of average values of the features of the cancer image:

- **radius_mean, texture_mean, perimeter_mean, area_mean, smoothness_mean, compactness_mean, concavity_mean, concave points_mean**

Each of these features is mapped to a table containing the number of values in a given range. ***You can examine the Chart Tables***

**Each sample contains the patient's unique ID, the cancer diagnosis and the average values of the cancer's visual characteristics.**

**Such a dataset can be used to train or test models and algorithms used to make cancer diagnoses. Understanding and analyzing the dataset can contribute to the improvement of cancer-related visual features and diagnosis.**

##✨ Examples of Projects that can be done with the Data Set

**Logistic Regression:** This algorithm can be used effectively for binary classification problems. In this dataset, logistic regression may be an appropriate choice since there are ""Malignant"" (benign) and ""Benign"" (malignant) classes. It can be used to predict cancer type with the visual features in the dataset.

**K-Nearest Neighbors (KNN):** KNN classifies an example by looking at the k closest examples around it. This algorithm assumes that patients with similar characteristics tend to have similar types of cancer. KNN can be used for cancer diagnosis by taking into account neighborhood relationships in the data set.

**Support Vector Machines (SVM):** SVM is effective for classification tasks, especially for two-class problems. Focusing on the clear separation of classes in the dataset, SVM is a powerful algorithm that can be used for cancer diagnosis.

##  **Data Set Related Training Notebooks 😊 (""I Recommend You Review"")**

**K-NN Project:** https://www.kaggle.com/code/erdemtaha/prediction-cancer-data-with-k-nn-95

**Logistic Regressüon:** https://www.kaggle.com/code/erdemtaha/cancer-prediction-96-5-with-logistic-regression

## 💖 Acknowledgements and Information

**This is a copy of content that has been elaborated for educational purposes and published to reach more people, you can access the original source from the link below, please do not forget to support that data**

🔗 https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data

**This database can also be accessed via the UW CS ftp server:**
🔗 ftp.cs.wisc.edu cd math-prog/cpo-dataset/machine-learn/WDBC/

**It can also be found at the UCI Machine Learning Repository:**
🔗 https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29

## **📩 Personal Information:**

**If you have some questions or curiosities about the data or studies, you can contact me as you wish from the links below 😊**

**LinkedIn:** https://www.linkedin.com/in/erdem-taha-sokullu/

**Mail:** erdemtahasokullu@gmail.com

**Github:** https://github.com/Prometheussx

**Kaggle:** https://www.kaggle.com/erdemtaha


## 📜 License:

**This Data has a CC BY-NC-SA 4.0 License You can review the license rules from the link below**

**License Link:** https://creativecommons.org/licenses/by-nc-sa/4.0/",.csv
Cancer Incidence Averages and Rates Per US County,1,cancer-incidence-totals-and-rates-per-us-county,cancer_incidence_by_county.csv,other,"### Context

This data comes from aggregation of the tables available on the [NIH's National Cancer Institutes State Cancer Profiles](https://www.statecancerprofiles.cancer.gov/index.html), specifically with their [incidence tables. ](https://www.statecancerprofiles.cancer.gov/incidencerates/index.php)
&gt; The objective of the State Cancer Profiles Web site is to provide a system to characterize the cancer burden in a standardized manner in order to motivate action, integrate surveillance into cancer control planning, characterize areas and demographic groups, and expose health disparities. The focus is on cancer sites for which there are evidence based control interventions. Interactive graphics and maps provide visual support for deciding where to focus cancer control efforts. 


### Content

This data has cancer Incidence rates broken down by US County and includes data aggregated from 2012-2016. It has both incidence rates per 100k as well as yearly totals averaged over that period


### Potential Future Work
This data is summarized across other potentially illuminating fields. The State Cancer Profiles can be further broken down by cancer area, race/ethnicity, sex, age, and stage. If more fidelity on the data would be helpful please add it to the discussion section and I can work on adding it!


### [Data Use Restrictions](https://www.statecancerprofiles.cancer.gov/help/data-use.html)

#### Read Carefully Before Using
By using these data, you signify your agreement to comply with the following statutorily based requirements.

&gt; The Public Health Service Act (42 U.S.C. 242m(d)) provides that the data collected by the National Center for Health Statistics (NCHS) may be used only for the purpose for which they were obtained; any effort to determine the identity of any reported cases, or to use the information for any purpose other than for statistical reporting and analysis, is against the law. The National Program of Cancer Registries (NPCR), Centers for Disease Control and Prevention (CDC), has obtained an assurance of confidentiality pursuant to Section 308(d) of the Public Health Service Act, 42 U.S.C. 242m(d). This assurance provides that identifiable or potentially identifiable data collected by the NPCR may be used only for the purpose for which they were obtained unless the person or establishment from which they were obtained has consented to such use. Any effort to determine the identity of any reported cases, or to use the information for any purpose other than statistical reporting and analysis, is a violation of the assurance. 

Therefore users will:
- Use the data for statistical reporting and analysis only.
- Make no attempt to learn the identity of any person or establishment included in these data.
- Make no disclosure or other use of the identity of any person or establishment discovered inadvertently, and advise the appropriate contact for the data provider. In addition to immediately notifying ""Contact Us"" of the potential disclosure,
- For mortality data, notify the Confidentiality Officer at the National Center for Health Statistics (Alvan O. Zarate, Ph.D.), 3311 Toledo Road, Rm 7116, Hyattsville, MD 20782, Phone: 301-458-4601, Fax: 301-458-4021)
- For incidence data notify both the Federal agency that provided the data and notify the relevant state or metropolitan area cancer registryExternal Web Site Policy, of any such discovery.
- For CDC's National Program of Cancer Registries (NPCR) areas, notify the Associate Director for Science, Office of Science Policy and Technology Transfer, CDC, Mailstop D-50, 1600 Clifton Road, N.E., Atlanta, Georgia, 30333, Phone: 404-639-7240)
- For NCI's Surveillance, Epidemiology, and End Results (SEER) Program registry areas, notify the Branch Chief of the Cancer Statistics Branch of the Surveillance Research Program, Division of Cancer Control and Population Sciences, NCI, BG 9609 MSC 9760, 9609 Medical Center Drive, Bethesda, MD 20892-9760, Phone: 301-496-8510, Fax: 301-496-9949.",.csv
Cancer Rates ,1,cancer-rates,Cancer_Rates.csv,other,"Explanation of field attributes:

Colorectal Cancer - Cancer that develops in the colon (the longest part of the large intestine) and/or the rectum (the last several inches of the large intestine). This is a rate per 100,000.

Lung Cancer – Cancer that forms in tissues of the lung, usually in the cells lining air passages. This is a rate per 100,000.

Breast Cancer – Cancer that forms in tissues of the breast. This is a rate per 100,000.       

Prostate Cancer – Cancer that forms in tissues of the prostate. This is a rate per 100,000.

Urinary System Cancer – Cancer that forms in the organs of the body that produce and discharge urine. These include the kidneys, ureters, bladder, and urethra. This is a rate per 100,000.

All Cancer – All cancers including, but not limited to: colorectal cancer, lung cancer, breast cancer, prostate cancer, and cancer of the urinary system. This is a rate per 100,000.",.csv
Cancer classification,1,cancer-classification,cancer_classification.csv,Apache 2.0,"Diagnostic Wisconsin Breast Cancer Database.Dataset Characteristics
Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.  They describe characteristics of the cell nuclei present in the image. A few of the images can be found at http://www.cs.wisc.edu/~street/images/

Separating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, ""Decision Tree Construction Via Linear Programming."" Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree.  Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes.

The actual linear program used to obtain the separating plane in the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: ""Robust Linear Programming Discrimination of Two Linearly Inseparable Sets"", Optimization Methods and Software 1, 1992, 23-34].

This database is also available through the UW CS ftp server:
ftp ftp.cs.wisc.edu
cd math-prog/cpo-dataset/machine-learn/WDBC/",.csv
Cancer dataset,1,cancer-dataset,cancer.csv,MIT,"Cancer datasets provide valuable information for researching various types of cancer, including breast, lung, prostate, colorectal, and others. These datasets typically include diverse data points such as patient demographics, tumor characteristics, treatment regimens, genetic profiles, and survival outcomes.

Researchers utilize cancer datasets to investigate numerous aspects of the disease, including its etiology, progression, response to treatment, and factors influencing patient prognosis. By analyzing large-scale datasets, researchers can identify biomarkers, genetic mutations, and other factors associated with cancer development and progression, leading to advancements in early detection, personalized medicine, and targeted therapies.

Machine learning and data mining techniques are commonly employed to analyze cancer datasets, enabling the development of predictive models for cancer risk assessment, prognosis prediction, and treatment response. These models can help clinicians tailor treatment plans to individual patients, optimizing therapeutic outcomes and minimizing adverse effects.

Furthermore, cancer datasets play a critical role in facilitating interdisciplinary collaboration among researchers, clinicians, and policymakers. By sharing standardized datasets and collaborating on data-driven research initiatives, the global cancer research community can accelerate progress towards understanding cancer biology, improving patient care, and ultimately, finding cures for cancer.",.csv
Cannabis Sales: Adult-Use & Medical Retail Stats,1,cannabis-retail-sales,Cannabis_Retail_Sales_by_Week_Ending.csv,CC0-1.0,"This data set contains preliminary weekly retail sales data for cannabis and cannabis products in both the adult-use cannabis and medical marijuana markets. The data reported is compiled at specific points in time and only captures data current at the time the report is generated. The weekly data set captures retail cannabis sales from Sunday through Saturday of the week. Weeks spanning across two different months only include days within the same month. The first and last week of each month may show lower sales as they may not be made up of a full week (7 days). Data values may be updated and change over time as updates occur. Accordingly, weekly reported data may not exactly match annually reported data.

Data source: [Cannabis Retail Sales by Week Ending](https://catalog.data.gov/dataset/cannabis-retail-sales-by-week-ending)


Image Source: [Unsplash](https://unsplash.com/photos/pink-and-green-petaled-flower-t9jQie6cUhg)",.csv
Canteen Shop Transaction Data,1,canteen-shop-transaction-data,canteen_shop_data.csv,other,"This dataset contains transaction records from a canteen shop, providing insights into customer purchasing behavior, payment methods, employee interactions, customer satisfaction ratings, and weather conditions. Each transaction is recorded with details such as the date, time, item purchased, price, quantity, total amount, customer ID, payment method, employee ID, customer satisfaction rating, weather condition at the time of purchase, and whether any special offers were provided.

The dataset is suitable for exploratory data analysis, predictive modeling, and market research in the food service industry. Analysts and data scientists can use this dataset to uncover patterns, trends, and correlations related to customer preferences, sales performance, and the impact of weather on sales. Additionally, this dataset can be utilized to develop machine learning models for sales forecasting, customer segmentation, and personalized marketing strategies.",.csv
Car Crash Dataset,1,car-crash-dataset,monroe county car crach 2003-2015.csv,Apache 2.0,"The car crash dataset provides a detailed compilation of information related to common factors influencing road accidents, such as collision severity, weather conditions, road types, and contributing elements, offering valuable insights for the analysis and enhancement of overall road safety measures.",.csv
Car Details Dataset,1,car-details-dataset,CAR DETAILS FROM CAR DEKHO.csv,CC0-1.0,"This data is collected from 'Car Dekho'.
Following details of cars are included in the dataset:
1) Car name
2) Year
3) Selling Price
4) Kms driven
5) Fuel
6) Seller type
7) Transmission
8) Owner
",.csv
Car Evaluation Data Set,1,car-evaluation-data-set,car_evaluation.csv,CC0-1.0,"from: https://archive.ics.uci.edu/ml/datasets/car+evaluation



1. Title: Car Evaluation Database

2. Sources:
   (a) Creator: Marko Bohanec
   (b) Donors: Marko Bohanec   (marko.bohanec@ijs.si)
               Blaz Zupan      (blaz.zupan@ijs.si)
   (c) Date: June, 1997

3. Past Usage:

   The hierarchical decision model, from which this dataset is
   derived, was first presented in 

   M. Bohanec and V. Rajkovic: Knowledge acquisition and explanation for
   multi-attribute decision making. In 8th Intl Workshop on Expert
   Systems and their Applications, Avignon, France. pages 59-78, 1988.

   Within machine-learning, this dataset was used for the evaluation
   of HINT (Hierarchy INduction Tool), which was proved to be able to
   completely reconstruct the original hierarchical model. This,
   together with a comparison with C4.5, is presented in

   B. Zupan, M. Bohanec, I. Bratko, J. Demsar: Machine learning by
   function decomposition. ICML-97, Nashville, TN. 1997 (to appear)

4. Relevant Information Paragraph:

   Car Evaluation Database was derived from a simple hierarchical
   decision model originally developed for the demonstration of DEX
   (M. Bohanec, V. Rajkovic: Expert system for decision
   making. Sistemica 1(1), pp. 145-157, 1990.). The model evaluates
   cars according to the following concept structure:

   CAR                      car acceptability
   . PRICE                  overall price
   . . buying               buying price
   . . maint                price of the maintenance
   . TECH                   technical characteristics
   . . COMFORT              comfort
   . . . doors              number of doors
   . . . persons            capacity in terms of persons to carry
   . . . lug_boot           the size of luggage boot
   . . safety               estimated safety of the car

   Input attributes are printed in lowercase. Besides the target
   concept (CAR), the model includes three intermediate concepts:
   PRICE, TECH, COMFORT. Every concept is in the original model
   related to its lower level descendants by a set of examples (for
   these examples sets see http://www-ai.ijs.si/BlazZupan/car.html).

   The Car Evaluation Database contains examples with the structural
   information removed, i.e., directly relates CAR to the six input
   attributes: buying, maint, doors, persons, lug_boot, safety.

   Because of known underlying concept structure, this database may be
   particularly useful for testing constructive induction and
   structure discovery methods.

5. Number of Instances: 1728
   (instances completely cover the attribute space)

6. Number of Attributes: 6

7. Attribute Values:

   buying       v-high, high, med, low
   maint        v-high, high, med, low
   doors        2, 3, 4, 5-more
   persons      2, 4, more
   lug_boot     small, med, big
   safety       low, med, high

8. Missing Attribute Values: none

9. Class Distribution (number of instances per class)

   class      N          N[%]
   -----------------------------
   unacc     1210     (70.023 %) 
   acc        384     (22.222 %) 
   good        69     ( 3.993 %) 
   v-good      65     ( 3.762 %)",.csv
Car Fuel Consumption,1,car-consume,measurements.csv,GPL-2.0,"### Context

I am driving always the same car and i take almost always the same route. However, at the gas station i like to change the gas type; between SP98 (sold as ""Super plus"" sometimes) and SP95 E10 (This is, ""super"" gas with 10% Alcohol). E10 is sold for 1,38€; SP98 is sold for 1,46€; per liter.

From my feeling i would say that my car consumes a lot more with E10. From the data, what can we derive there?
I challenge you to partial out the factor ""E10 gas"" and tell me how much my car really consumes more with it. 

I applied my own basic linear regression on it and had as a result that it consumes 0.4 liters more with E10 gas. Linear regressions have the disadvantage that you can only really use them if the features are independent.


**I challenge you to predict the consumption depending on the gas type!**


### Content

Since a few months, i write down the data of my car's display after each ride; while regularly changing the gas type.

In the file, you will find the displayed distance (km); the consume (L/100km); the average speed (km/h), the temperature i had inside (°C), the temperature outside (°C), anything special that happened, if it was raining, if the air condition was on, if it was sunny enough that the car felt warm when i started it... and yes - the gas type i was using. I have also two columns saying how much and which gas type I was buying. Careful with those. The numbers don't add exactly up, because I note only the rides that occur under certain conditions: If the car was not cooling down enough to have another independent measure from the one before, i don't note it.

I started writing down the data in November, changed to SP98 in winter, and back to E10 in spring. Apart from that, the data is rather clean as i was doing my own project on it already.

### Acknowledgements

Thanks to Victor Chernozhukov who was planting this idea in my head, even if it took some years until i finally acted on it. :-)

### Inspiration

I was using a linear regression to partial out the influence of the gas type. The gas type is truly independent from the rest of the variables, so it should be possible without problem. However - depending on how i engineer the other features, the result is between 0.4 and 0.8 liters per 100km influence. A large, single-feature-depending difference usually is a hint for lots of covariance between the features; meaning in turn that linear regression might not be the best tool here.



",.csv
Car Price Prediction Challenge,1,car-price-prediction-challenge,car_price_prediction.csv,CC0-1.0,"## Assignment 

Your notebooks must contain the following steps:

- Perform data cleaning and pre-processing.
      - What steps did you use in this process and how did you clean your data.
- Perform exploratory data analysis on the given dataset.
      - Explain each and every graphs that you make.
- Train a ml-model and evaluate it using different metrics.
      - Why did you choose that particular model? What was the accuracy?
- Hyperparameter optimization and feature selection is a plus.
- Model deployment and use of ml-flow is a plus.
- Perform model interpretation and show feature importance for your model.
      - Provide some explanation for the above point.
- Future steps.
Note: try to have your notebooks as presentable as possible.

## Dataset Description

CSV file - 19237 rows x 18 columns (Includes Price Columns as Target)

## Attributes
ID
Price: price of the care(Target Column)
Levy
Manufacturer
Model
Prod. year
Category
Leather interior
Fuel type
Engine volume
Mileage
Cylinders
Gear box type
Drive wheels
Doors
Wheel
Color
Airbags

Confused or have any doubts in the data column values? Check the dataset discussion tab!",.csv
Car Prices Poland,1,car-prices-poland,Car_Prices_Poland_Kaggle.csv,CC0-1.0,"Hello
I am a Python developer and train the ability to parse, analyze data and create neural networks. I decided to share the dataset I'm currently working with. Maybe it will be useful to someone. Why a car? I love cars! As well as programming. If you are interested in me as a specialist, please contact me glotoffalexandr@gmail.com (I'm looking for a new job)

The dataset was assembled in January 2022. Data from a well-known car sale site in Poland (which is public). Selenium and request were used for parsing (python of course)

The dataset contains information about the make, model, generation, year of production, mileage, engine type and volume, localization and price

I have ideas for expanding the model: add body type, configuration, color, power, etc.

I see many ways to use models created on the basis of this dataset, I will describe them in notebooks",.csv
Car Sale Advertisements,1,car-sale-advertisements,car_ad.csv,CC0-1.0,"#Context

This dataset was collected by me from car sale advertisements for study/practice purposes in 2016. Though there is couple well known car features datasets they seems quite simple and outdated. Car topic is really interesting. But I wanted to practice with real raw data which has all inconvenient moments (as NA’s for example).

This dataset contains data for more than 9.5K cars sale in Ukraine. Most of them are used cars so it opens the possibility to analyze features related to car operation. At the end of the day I look at this data as a subset from all Ukrainian car fleet.

# Content

Dataset contains 9576 rows and 10 variables with essential meanings:

 - car: manufacturer brand 
 - price: seller’s price in advertisement (in USD)
 - body: car body type 
 - mileage: as mentioned in advertisement (‘000 Km)
 - engV: rounded engine volume (‘000 cubic cm)
 - engType: type of fuel (“Other” in this case should be treated as NA) 
 - registration: whether car registered in Ukraine or not 
 - year: year of production 
 - model: specific model name 
 - drive: drive type

Data has gaps, so be careful and check for NA’s.
I tried to check and drop repeated offers, but theoretically duplications are possible.

#Inspiration

Data will be handy to study and practice different models and approaches. 
As a further step you can compare patters in Ukrainian market to your own domestic car market characteristics.",.csv
Car Sales Report,1,car-sales-report,Car Sales.xlsx - car_data.csv,Apache 2.0,"Application and use cases

1 )Market Analysis:
Evaluate overall trends and regional variations in car sales to assess manufacturer performance, model preferences, and demographic insights.
2) Seasonal Patterns and Competitor Analysis:
Investigate seasonal and cyclical patterns in sales.
3) Forecasting and Predictive Analysis
Use historical data for forecasting and predict future market trends.
Support marketing, advertising, and investment decisions based on insights.
4) Supply Chain and Inventory Optimization:
Provide valuable data for stakeholders in the automotive industry.",.csv
Car price prediction(used cars),1,car-price-predictionused-cars,car data.csv,CC0-1.0,"The price of a car depends on a lot of factors like the goodwill of the brand of the car, features of the car, horsepower and the mileage it gives and many more. Car price prediction is one of the major research areas in machine learning. So if you want to learn how to train a car price prediction model",.csv
Car resale data - 2023,1,car-resale-prices,car_resale_prices.csv,CC0-1.0,"# Description
&gt; This dataset contains Car resale prices all over the cities from India, updated as of August 2023. This dataset contains information in raw/unclean format, to provide Hands-on experience of working with real-life data.

# Key Features
&gt; - **full_name**: Name of the car along with model 
- **resale_price**: Resale price of the car
- **registered_year**: Year the car was registered
- **engine_capacity**: Engine Displacement of car (cc)
- **insurance**: Type of insurance made available for the car (if any)
- **transmission_type**: Transmission type of the car
- **kms_driven**: Total kilometers the car was driven for
- **owner_type**: Number of owners who previously owned the car
- **fuel_type**: Type of fuel the car uses
- **max_power**: Maximum power of the car (bhp)
- **seats**: Number of seats the car has
- **mileage**: Mileage of the car
- **body_type**: Body configuration of the car
- **city**: City in India the car is sold in 

### If you found the dataset useful, please consider upvoting it 😊",.csv
Car-Prices-Prediction-data,1,car-prices-prediction-data,CarPricesPrediction.csv,Apache 2.0,"The dataset used in this analysis contains information about car prices and their associated features. Here's a brief overview of the dataset:

Columns: The dataset consists of several columns including:

Make: The brand or manufacturer of the car (e.g., Toyota, Honda, Ford).
Model: The specific model of the car (e.g., Camry, Civic, F-150).
Year: The manufacturing year of the car.
Mileage: The total mileage (in miles) of the car.
Condition: The condition of the car, categorized as Excellent, Good, or Fair.
Price: The price of the car.
Size: The dataset contains a certain number of rows, each representing a unique car entry, and a set of columns describing various attributes of the cars.

Source: The dataset was generated synthetically for the purpose of this analysis. It was created using a Python script that simulated car prices based on random values and predefined factors to mimic real-world variability.

Purpose: The dataset is used for exploratory data analysis (EDA) and modeling tasks. It serves as a sample dataset to demonstrate data analysis techniques, such as data cleaning, visualization, and predictive modeling, in a car price prediction context.

Data Types: The dataset consists of both numerical and categorical data types. Numerical features include Year, Mileage, and Price, while categorical features include Make, Model, and Condition.

Missing Values: There are no missing values in the dataset, ensuring that the analysis can be performed smoothly without the need for imputation or handling missing data.

Overall, this dataset provides a foundation for analyzing and understanding factors influencing car prices, exploring relationships between features, and building predictive models to estimate car prices based on given attributes.
",.csv
Car-Sales Dataset,1,car-sales-dataset,Car.csv,other,"The Car Sales Dataset is a collection of data that contains information on various car models sold in the market. The dataset includes variables such as the price of the car in thousands of dollars, engine size, horsepower, fuel efficiency, and sales.
1. `Price_in_thousands`: This variable represents the price of the car in thousands of dollars, which is a measure of the car's cost.
2. `Engine_size`: This variable represents the size of the engine in cubic centimeters, which is a measure of the car's power.
3. `Horsepower`: This variable represents the power of the car's engine in horsepower, which is a measure of the car's ability to accelerate and maintain speed.
4. `Fuel_efficiency`: This variable represents the number of miles per gallon (mpg) that the car can travel on a single gallon of fuel, which is a measure of the car's fuel efficiency.
5. `Sales`: This variable represents the number of units of the car sold in a given period, which is a measure of the car's popularity and demand in the market.

Overall, this dataset can be used to analyze the relationships between the different variables and to predict the sales of a car based on its price, engine size, horsepower, and fuel efficiency. It can be helpful for businesses and consumers alike in making informed decisions about buying and selling cars.",.csv
Caravan Insurance Challenge,1,caravan-insurance-challenge,caravan-insurance-challenge.csv,other,"This data set used in the CoIL 2000 Challenge contains information on customers of an insurance company. The data consists of 86 variables and includes product usage data and socio-demographic data derived from zip area codes. The data was collected to answer the following question: Can you predict who would be interested in buying a caravan insurance policy and give an explanation why?

## Acknowledgements

DISCLAIMER

This dataset is owned and supplied by the Dutch datamining company Sentient Machine Research, and is based on real world business data. You are allowed to use this dataset and accompanying information for non commercial research and education purposes only. It is explicitly not allowed to use this dataset for commercial education or demonstration purposes. For any other use, please contact Peter van der Putten, info@smr.nl.

This dataset has been used in the CoIL Challenge 2000 datamining competition. For papers describing results on this dataset, see the TIC 2000 homepage: http://www.wi.leidenuniv.nl/~putten/library/cc2000/

Please cite/acknowledge:

P. van der Putten and M. van Someren (eds) . CoIL Challenge 2000: The Insurance Company Case. Published by Sentient Machine Research, Amsterdam. Also a Leiden Institute of Advanced Computer Science Technical Report 2000-09. June 22, 2000.

## The Data

Originally, this dataset was broken into two parts: the training set and the evaluation set. As this was a competition, the responses to the evaluation set were not given as part of the original release; they were, however, released after the end of the competition in a separate file. This dataset contains all three of these files, combined into one.

The field ORIGIN in the caravan-insurance-challenge.csv file has the values *train* and *test*, corresponding to the training and evaluation sets, respectively. To simulate the original challenge, you can ignore the *test* rows, and test your model's prediction on those observations once you've trained only on the training set.

Each observation corresponds to a postal code. Variables beginning with M refer to demographic statistics of the postal code, while variables beginning with P and A (as well as CARAVAN, the target variable) refer to product ownership and insurance statistics in the postal code.

The data file contains the following fields:

- **ORIGIN**: *train* or *test*, as described above
- **MOSTYPE**: Customer Subtype; see **L0**
- **MAANTHUI**: Number of houses 1 - 10
- **MGEMOMV**: Avg size household 1 - 6
- **MGEMLEEF**: Avg age; see **L1**
- **MOSHOOFD**: Customer main type;  see **L2**

** Percentages in each group, per postal code (see L3)**:

- **MGODRK**: Roman catholic
- **MGODPR**: Protestant ...
- **MGODOV**: Other religion
- **MGODGE**: No religion
- **MRELGE**: Married
- **MRELSA**: Living together
- **MRELOV**: Other relation
- **MFALLEEN**: Singles
- **MFGEKIND**: Household without children
- **MFWEKIND**: Household with children
- **MOPLHOOG**: High level education
- **MOPLMIDD**: Medium level education
- **MOPLLAAG**: Lower level education
- **MBERHOOG**: High status
- **MBERZELF**: Entrepreneur
- **MBERBOER**: Farmer
- **MBERMIDD**: Middle management
- **MBERARBG**: Skilled labourers
- **MBERARBO**: Unskilled labourers
- **MSKA**: Social class A
- **MSKB1**: Social class B1
- **MSKB2**: Social class B2
- **MSKC**: Social class C
- **MSKD**: Social class D
- **MHHUUR**: Rented house
- **MHKOOP**: Home owners
- **MAUT1**: 1 car
- **MAUT2**: 2 cars
- **MAUT0**: No car
- **MZFONDS**: National Health Service
- **MZPART**: Private health insurance
- **MINKM30**: Income < 30.000
- **MINK3045**: Income 30-45.000
- **MINK4575**: Income 45-75.000
- **MINK7512**: Income 75-122.000
- **MINK123M**: Income >123.000
- **MINKGEM**: Average income
- **MKOOPKLA**: Purchasing power class

** Total number of variable in postal code (see L4)**:

- **PWAPART**: Contribution private third party insurance
- **PWABEDR**: Contribution third party insurance (firms) ...
- **PWALAND**: Contribution third party insurane (agriculture)
- **PPERSAUT**: Contribution car policies
- **PBESAUT**: Contribution delivery van policies
- **PMOTSCO**: Contribution motorcycle/scooter policies
- **PVRAAUT**: Contribution lorry policies
- **PAANHANG**: Contribution trailer policies
- **PTRACTOR**: Contribution tractor policies
- **PWERKT**: Contribution agricultural machines policies
- **PBROM**: Contribution moped policies
- **PLEVEN**: Contribution life insurances
- **PPERSONG**: Contribution private accident insurance policies
- **PGEZONG**: Contribution family accidents insurance policies
- **PWAOREG**: Contribution disability insurance policies
- **PBRAND**: Contribution fire policies
- **PZEILPL**: Contribution surfboard policies
- **PPLEZIER**: Contribution boat policies
- **PFIETS**: Contribution bicycle policies
- **PINBOED**: Contribution property insurance policies
- **PBYSTAND**: Contribution social security insurance policies
- **AWAPART**: Number of private third party insurance 1 - 12
- **AWABEDR**: Number of third party insurance (firms) ...
- **AWALAND**: Number of third party insurance (agriculture)
- **APERSAUT**: Number of car policies
- **ABESAUT**: Number of delivery van policies
- **AMOTSCO**: Number of motorcycle/scooter policies
- **AVRAAUT**: Number of lorry policies
- **AAANHANG**: Number of trailer policies
- **ATRACTOR**: Number of tractor policies
- **AWERKT**: Number of agricultural machines policies
- **ABROM**: Number of moped policies
- **ALEVEN**: Number of life insurances
- **APERSONG**: Number of private accident insurance policies
- **AGEZONG**: Number of family accidents insurance policies
- **AWAOREG**: Number of disability insurance policies
- **ABRAND**: Number of fire policies
- **AZEILPL**: Number of surfboard policies
- **APLEZIER**: Number of boat policies
- **AFIETS**: Number of bicycle policies
- **AINBOED**: Number of property insurance policies
- **ABYSTAND**: Number of social security insurance policies
- **CARAVAN**: Number of mobile home policies 0 - 1

### Keys (L1 - L4)

**L0: Customer subtype**

- *1*: High Income, expensive child
- *2*: Very Important Provincials
- *3*: High status seniors
- *4*: Affluent senior apartments
- *5*: Mixed seniors
- *6*: Career and childcare
- *7*: Dinki's (double income no kids)
- *8*: Middle class families
- *9*: Modern, complete families
- *10*: Stable family
- *11*: Family starters
- *12*: Affluent young families
- *13*: Young all american family
- *14*: Junior cosmopolitan
- *15*: Senior cosmopolitans
- *16*: Students in apartments
- *17*: Fresh masters in the city
- *18*: Single youth
- *19*: Suburban youth
- *20*: Etnically diverse
- *21*: Young urban have-nots
- *22*: Mixed apartment dwellers
- *23*: Young and rising
- *24*: Young, low educated 
- *25*: Young seniors in the city
- *26*: Own home elderly
- *27*: Seniors in apartments
- *28*: Residential elderly
- *29*: Porchless seniors: no front yard
- *30*: Religious elderly singles
- *31*: Low income catholics
- *32*: Mixed seniors
- *33*: Lower class large families
- *34*: Large family, employed child
- *35*: Village families
- *36*: Couples with teens 'Married with children'
- *37*: Mixed small town dwellers
- *38*: Traditional families
- *39*: Large religous families
- *40*: Large family farms
- *41*: Mixed rurals

**L1: average age keys**:

*1*: 20-30 years
*2*: 30-40 years
*3*: 40-50 years
*4*: 50-60 years
*5*: 60-70 years
*6*: 70-80 years

**L2: customer main type keys**:

- *1*: Successful hedonists
- *2*: Driven Growers
- *3*: Average Family
- *4*: Career Loners
- *5*: Living well
- *6*: Cruising Seniors
- *7*: Retired and Religeous
- *8*: Family with grown ups
- *9*: Conservative families
- *10*: Farmers

**L3: percentage keys**:

- *0*: 0%
- *1*: 1 - 10%
- *2*: 11 - 23%
- *3*: 24 - 36%
- *4*: 37 - 49%
- *5*: 50 - 62%
- *6*: 63 - 75%
- *7*: 76 - 88%
- *8*: 89 - 99%
- *9*: 100%

**L4: total number keys**:

- *0*: 0
- *1*: 1 - 49
- *2*: 50 - 99
- *3*: 100 - 199
- *4*: 200 - 499
- *5*: 500 - 999
- *6*: 1000 - 4999
- *7*: 5000 - 9999
- *8*: 10,000 - 19,999
- *9*: >= 20,000",.csv
Carbon Sequestration Facilities,1,carbon-sequestration-facilities,CCS_Map_Data_Jan2023.csv,CC0-1.0,"Why am I doing this?
Because I liked this dataset: https://www.kaggle.com/datasets/alistairking/co2-sequestration-2016-2022
But it only had 13 rows of data, I went and found more and have shared. (The author of the linked dataset is listed as a contributor below.)

The National Energy Technology Laboratory’s (NETL) Carbon Capture and Storage (CCS) Database includes information on active, proposed, and terminated CCS projects worldwide. Publicly available information has been aggregated to provide a one-stop interactive tool that contains valuable data, including, but not limited to:

- Technologies being developed for capture.
- Evaluation of sites for carbon dioxide (CO2) storage.
- An estimation of project costs.
- Project description and current status.
- Amount of CO2 captured/stored.

NETL’s CCS Database provides the public with information regarding efforts by various industries, public groups, and governments that are being made towards development and eventual deployment of CCS technology. While several of the projects are still in the planning and development stage, and many have been completed, 37 are actively capturing and/or injecting CO2.

The CCS Database is presented using a Tableau Dashboard which is entirely interactive (located here https://netl.doe.gov/carbon-management/carbon-storage/worldwide-ccs-database ).  

Disclaimer of Liability: The CCS Database is made available by an agency of the United States Government. Neither the United States Government, the Department of Energy, the National Energy Technology Laboratory, nor any of their employees, makes any warranty, express or implied, including warranties of merchantability and fitness for a particular purpose, or assumes any legal liability or responsibility for the accuracy, completeness, or usefulness of any information or data disclosed, or represents that its use would not infringe privately owned rights.

",.csv
Cardiovascular Diseases Dataset,1,south-african-heart-disease-dataset,SAHeart.csv,CC-BY-SA-4.0,"# Context
**Cardio-vascular diseases** are among the most frequent causes of death. Clinically there are widely accepted indicators for potential risk of contracting a cardio-vascular sickness. Hence, the knowledge of the determinant risk factors that lead cardio-vascular sickness can aid decision- making for pretreatment and changing lifestyles to avoid or reduce future complications. 

# The dataset
**The dataset SAHeart.csv is about coronary heart disease (CHD) obtained from the Coronary Risk Factor Study conducted in South Africa by Rousseauw et al. in 1983.** The goal is to use a set of indicators to identify if a patient has a risk of contracting coronary diseases or not.

- **Objective:** explore risk factors associated with myocardial infarction (MI), commonly known as a heart attack.
- **Population:** The study focused on white males aged 15 to 64.
- **Binary Response:** Each observation indicates whether the individual had a myocardial infarction at the time of the survey. It’s a binary response: presence (MI occurred) or absence (no MI).
- **Predictors:** The dataset contains several numeric and factor-level predictors.
- **Sample Size:** There are 462 observations in total, with 160 individuals experiencing an MI and 302 without an MI.

# Format
A data frame with 462 observations on the following 10 variables.

| Variable  | Description                                     |
|-----------|-------------------------------------------------|
| sbp       | Systolic blood pressure                         |
| tobacco   | Cumulative tobacco (kg)                         |
| ldl       | Low density lipoprotein cholesterol level       |
| adiposity | Severe overweight (a numeric vector)            |
| famhist   | Family history of heart disease                 |
| typea     | Type-A behavior                                 |
| obesity   | Excessive fat accumulation (a numeric vector)   |
| alcohol   | Current alcohol consumption                      |
| age       | Age at onset                                    |
| chd       | Response, coronary heart disease                |

Cover Image Source: https://www.allaboutvision.com/conditions/related/heart-disease-and-eye-health/

",.csv
Career Prediction Dataset,1,career-prediction-dataset,Data_final.csv,other,"This is the dataset used for the career prediction based upon the various aptitude test and personality test. The description for the test are:-
- **OCEAN Test** :- The Ocean Model of Personality, commonly referred to as the Big Five personality traits, is a widely used framework in psychology to describe human personality. It assesses personality across five dimensions.
       - Openness
       - Conscientiousness
       - Extraversion
       - Agreeableness
       - Neuroticism
- **Numerical aptitude**:- This is  often evaluated through assessments or tests, plays a crucial role in career prediction models. This skill indicates an individual's proficiency in understanding and working with numbers, which is essential in various professions such as finance, engineering, data analysis, and scientific research. High numerical aptitude scores may suggest suitability for roles requiring quantitative analysis, problem-solving, and decision-making based on numerical data. Conversely, lower scores may indicate a better fit for roles that rely less on numerical reasoning. However, it's important to consider other factors alongside numerical aptitude, such as interests, personality traits, and additional skills, for accurate career predictions.
- **Spatial aptitude** :- It refers to an individual's ability to mentally manipulate shapes, visualize objects in different orientations, and understand spatial relationships. In terms of career prediction, individuals with high spatial aptitude often excel in professions that involve tasks such as architecture, engineering, graphic design, geographic information systems (GIS), and various fields of science and technology. Their ability to perceive and understand spatial relationships allows them to thrive in roles that require problem-solving, creativity, and the ability to interpret and design visual representations of data or structures.
- **Perceptual Aptitude** :- In career prediction refers to an individual's ability to accurately perceive and interpret information in their chosen field or occupation. It encompasses skills such as pattern recognition, attention to detail, spatial reasoning, and problem-solving. A high perceptual aptitude often correlates with success in careers that require keen observation, critical thinking, and quick decision-making, such as graphic design, engineering, medicine, or law enforcement.
- **Abstract reasoning** :- It is a cognitive ability that involves the understanding and manipulation of complex ideas and concepts, often without the need for concrete or tangible information. In the context of career prediction, abstract reasoning skills can be crucial indicators of an individual's potential success in certain fields.Candidates with strong abstract reasoning abilities tend to excel in roles that require problem-solving, critical thinking, and the ability to analyze and interpret complex data or situations. These skills are highly valued in professions such as engineering, computer science, research, and strategic planning.
- **Verbal reasoning**:-  It tests are assessments commonly used in career prediction and selection processes. They evaluate an individual's ability to comprehend and analyze written information, draw logical conclusions, and solve problems based on textual data. These tests are particularly relevant in fields that require strong communication, critical thinking, and decision-making skills, such as management, law, journalism, and consulting. A high score in verbal reasoning suggests that an individual possesses the aptitude to effectively process and interpret written information, which can be indicative of success in professions that demand strong verbal communication and analytical abilities.",.csv
Cariprazine Dataset,1,cariparzine-dataset,cariprazine_data.csv,GPL-3.0,"This dataset is a collection of user reviews for the anipsychotic Cariprazine from the website drugs.com.
The main goal for collecting this data is to better understand the effects the drug has on its user, not from a clinician perspective, but rather from a consumer perspective ('rating'), backed by crowd consensus ('likes').",.csv
Cars - Purchase Decision Dataset,1,cars-purchase-decision-dataset,car_data.csv,CC0-1.0,"This dataset contains details of 1000 customers who intend to buy a car, considering their annual salaries.

Columns:
User ID
Gender
Age
Annual Salary
Purchase Decision (No = 0; Yes = 1)",.csv
Cars 2022 Dataset,1,cars-2022-dataset,CARS_1.csv,CC0-1.0,"This dataset was derived from https://www.cardekho.com/. The dataset consists specifications list as we all rating only for new cars.

I would like to thank https://www.cardekho.com/ for such a great platform. Looking forward to many notebooks on the dataset in near future.

## Dataset Description
- This dataset consists of 16 features on a total of 203 car choices available in India. 

| Feature | Type | Description |
| --- | --- | --- |
| car_name | String | Name of the car |
| reviews_count | String | Number of reviews given to the specific car on the website |
| fuel_type | String | Type of Fuel car uses. Possible values are Petrol, Diesel and Electric |
| engine_displacement | Integer | Engine displacement is the measure of the cylinder volume swept by all of the pistons of a piston engine, excluding the combustion chambers. Unit is (cc) |
| no_cylinder | Integer | Number of cylinders contained by the car. 0 in case of electric vehicles |
| seating_capacity | Integer | Number of people that can fit in the car |
| transmission_type | String | Possible values range from Manual, Automatic and Electric |
| fuel_tank_capacity | Integer | Maximum capacity of car's fuel tank. 0 in case of electric vehicle |
| body_type | String | Body shape of the car |
| rating| Integer | Rating provided to the car on the website. In the range of 0 to 5 |
| starting_price | Integer | Starting price of the car in Rs |
| ending_price | Integer | Ending price of the car in Rs |
| max_torque_nm | Integer | Maximum torque that can be provided by the car |
| max_torque_rpm | Integer | RPM at which maximum torque can be achieved |
| max_power_bhp | Integer | Maximum horsepower of the car |
| max_power_rp | Integer | RPM at which maximum horsepower can be achieved |",.csv
Cars Data,1,carsdata,cars.csv,CC0-1.0,"Cars Data has Information about 3 brands/make of cars. Namely US, Japan, Europe. Target of the data set to find the brand of a car using the parameters such as horsepower, Cubic inches, Make year, etc.

A decision tree can be used create a predictive data model to predict the car brand.",.csv
"Cars, planes, trains: where do CO2 emissions",1,cars-planes-trains-where-do-co2-emissions,number-airline-passengers new.csv,CC0-1.0,"this graph was created in OurDataWorld:

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Ffc283020e12db2d65a4b56665bd73e8e%2Fgraph1.png?generation=1714081083412772&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F07b88d925646a9ffada6a65a13496776%2Fgraph2.png?generation=1714081088770619&alt=media)

Transport accounts for around one-fifth of global carbon dioxide (CO2) emissions [24% if we only consider CO2 emissions from energy].1

How do these emissions break down? Is it cars, trucks, planes or trains that dominate?

In the chart here we see global transport emissions in 2018. This data is sourced from the International Energy Agency (IEA).

Road travel accounts for three-quarters of transport emissions. Most of this comes from passenger vehicles – cars and buses – which contribute 45.1%. The other 29.4% comes from trucks carrying freight.

Since the entire transport sector accounts for 21% of total emissions, and road transport accounts for three-quarters of transport emissions, road transport accounts for 15% of total CO2 emissions.

Aviation – while it often gets the most attention in discussions on action against climate change – accounts for only 11.6% of transport emissions. It emits just under one billion tonnes of CO2 each year – around 2.5% of total global emissions [we look at the role that air travel plays in climate change in more detail in another article]. International shipping contributes a similar amount, at 10.6%.

Rail travel and freight emits very little – only 1% of transport emissions. Other transport – which is mainly the movement of materials such as water, oil, and gas via pipelines – is responsible for 2.2%.",.csv
Cartoon dataset,1,cartoon-dataset,Cartoon_datasets.csv,CC0-1.0,"Name of Cartoon: This column would contain the names of various cartoons or animated series. Examples include ""SpongeBob SquarePants,"" ""Tom and Jerry,"" ""The Simpsons,"" ""Pokemon,"" etc.

Span Over the Years: This column would indicate the time period during which the cartoon aired or was produced. It could be represented as a range (e.g., ""1999-2022"") or specific years (e.g., ""2001-2006, 2015-present"").

Rating: This column would contain the ratings of the cartoons. Ratings could be provided by various sources such as IMDb, Rotten Tomatoes, or specific rating agencies. Ratings could be numerical (e.g., out of 10) or categorical (e.g., G, PG, PG-13, etc.).

Description: This column would include a brief description or summary of each cartoon. It would provide an overview of the storyline, main characters, genre, and any other relevant information about the cartoon.",.csv
Carvana - Predict Car Prices,1,carvana-predict-car-prices,carvana.csv,CC0-1.0,"# Overview

This dataset contains data about 22,000 cars from carvana.com. Using this data we can derive new insights about cars prices, and we can develop predictive models to predict the cost of car given it's make and model, year, and mileage.

# Tasks
- Create a predictive model to calculate the price of the car.
- Using natural language processing, create an algorithm to find a car's price given it name (make and model).
- Is there a correlation/relationship between between the year of a car and a car's price?
- Is there a correlation/relationship between between the mileage on a car and a car's price?

# Data Details

- The data was web scraped from carvana.com/cars.
- There are 22,000 rows of data (first 1000 pages of the site).
- The name column contains the make and model of the car.
- The cars are used and the miles column says the number of miles the car has already driven.
- The price of the car is in USD.",.csv
Cause of Deaths around the World (Historical Data),1,cause-of-deaths-around-the-world,cause_of_deaths.csv,other,"### Context

A straightforward way to assess the health status of a population is to focus on mortality – or concepts like child mortality or life expectancy, which are based on mortality estimates. A focus on mortality, however, does not take into account that the burden of diseases is not only that they kill people, but that they cause suffering to people who live with them. Assessing health outcomes by both mortality and morbidity (the prevalent diseases) provides a more encompassing view on health outcomes. This is the topic of this entry. The sum of mortality and morbidity is referred to as the ‘burden of disease’ and can be measured by a metric called ‘Disability Adjusted Life Years‘ (DALYs). DALYs are measuring lost health and are a standardized metric that allow for direct comparisons of disease burdens of different diseases across countries, between different populations, and over time. Conceptually, one DALY is the equivalent of losing one year in good health because of either premature death or disease or disability. One DALY represents one lost year of healthy life. The first ‘Global Burden of Disease’ (GBD) was GBD 1990 and the DALY metric was prominently featured in the World Bank’s 1993 World Development Report. Today it is published by both the researchers at the Institute of Health Metrics and Evaluation (IHME) and the ‘Disease Burden Unit’ at the World Health Organization (WHO), which was created in 1998. The IHME continues the work that was started in the early 1990s and publishes the Global Burden of Disease study.

### Content

In this Dataset, we have Historical Data of different cause of deaths for all ages around the World. The key features of this Dataset are: Meningitis, Alzheimer's Disease and Other Dementias, Parkinson's Disease, Nutritional Deficiencies, Malaria, Drowning, Interpersonal Violence, Maternal Disorders, HIV/AIDS, Drug Use Disorders, Tuberculosis, Cardiovascular Diseases, Lower Respiratory Infections, Neonatal Disorders, Alcohol Use Disorders, Self-harm, Exposure to Forces of Nature, Diarrheal Diseases, Environmental Heat and Cold Exposure, Neoplasms, Conflict and Terrorism, Diabetes Mellitus, Chronic Kidney Disease, Poisonings, Protein-Energy Malnutrition, Road Injuries, Chronic Respiratory Diseases, Cirrhosis and Other Chronic Liver Diseases, Digestive Diseases, Fire, Heat, and Hot Substances, Acute Hepatitis.

### Dataset Glossary (Column-wise)

* <b>01. Country/Territory</b> - Name of the Country/Territory
* <b>02. Code</b> - Country/Territory Code
* <b>03. Year</b> - Year of the Incident
* <b>04. Meningitis</b> - No. of People died from Meningitis
* <b>05. Alzheimer's Disease and Other Dementias</b> - No. of People died from Alzheimer's Disease and Other Dementias
* <b>06. Parkinson's Disease</b> - No. of People died from Parkinson's Disease
* <b>07. Nutritional Deficiencies</b> - No. of People died from Nutritional Deficiencies
* <b>08. Malaria</b> - No. of People died from Malaria
* <b>09. Drowning</b> - No. of People died from Drowning
* <b>10. Interpersonal Violence</b> - No. of People died from Interpersonal Violence
* <b>11. Maternal Disorders</b> - No. of People died from Maternal Disorders
* <b>12. Drug Use Disorders</b> - No. of People died from Drug Use Disorders
* <b>13. Tuberculosis</b> - No. of People died from Tuberculosis
* <b>14. Cardiovascular Diseases</b> - No. of People died from Cardiovascular Diseases
* <b>15. Lower Respiratory Infections</b> - No. of People died from Lower Respiratory Infections
* <b>16. Neonatal Disorders</b> - No. of People died from Neonatal Disorders
* <b>17. Alcohol Use Disorders</b> - No. of People died from Alcohol Use Disorders
* <b>18. Self-harm</b> - No. of People died from Self-harm
* <b>19. Exposure to Forces of Nature</b> - No. of People died from Exposure to Forces of Nature
* <b>20. Diarrheal Diseases</b> - No. of People died from Diarrheal Diseases
* <b>21. Environmental Heat and Cold Exposure</b> - No. of People died from Environmental Heat and Cold Exposure
* <b>22. Neoplasms</b> - No. of People died from Neoplasms
* <b>23. Conflict and Terrorism</b> - No. of People died from Conflict and Terrorism
* <b>24. Diabetes Mellitus</b> - No. of People died from Diabetes Mellitus
* <b>25. Chronic Kidney Disease</b> - No. of People died from Chronic Kidney Disease 
* <b>26. Poisonings</b> - No. of People died from Poisoning
* <b>27. Protein-Energy Malnutrition</b> - No. of People died from Protein-Energy Malnutrition 
* <b>28. Chronic Respiratory Diseases</b> - No. of People died from Chronic Respiratory Diseases
* <b>29. Cirrhosis and Other Chronic Liver Diseases</b> - No. of People died from Cirrhosis and Other Chronic Liver Diseases
* <b>30. Digestive Diseases</b> - No. of People died from Digestive Diseases
* <b>31. Fire, Heat, and Hot Substances</b> - No. of People died from Fire or Heat or any Hot Substances
* <b>32. Acute Hepatitis</b> - No. of People died from Acute Hepatitis

### Structure of the Dataset

![](https://i.imgur.com/Xj5qbDI.png)

### Acknowledgement

This Dataset is created from <b>[Our World in Data](https://ourworldindata.org/)</b>. This Dataset falls under open access under the Creative Commons BY license.  You can check the <b>[FAQ](https://ourworldindata.org/faqs#can-i-use-or-reproduce-your-data)</b> for more information about it. Special thanks to Max Roser, Hannah Ritchie, and Fiona Spooner (2021) - ""Burden of disease"". Published online at OurWorldInData.org. Retrieved from: <b>https://ourworldindata.org/burden-of-disease [Online Resource]</b>.

Cover Photo by: <b><a href=""https://www.freepik.com/free-vector/dirty-warning-background-yellow-black-colors_9106054.htm#query=danger&position=28&from_view=search&track=sph"">Image by starline</a> on Freepik</b>",.csv
Celebrity Deaths,1,celebrity-deaths,celebrity_deaths_4.csv,CC-BY-NC-SA-4.0,"# Context 
I created this dataset to investigate the claim that 2016 had an unnaturally large number of celebrity deaths.


# Content
Points listed by Name, Age, Cause of death and Reason for fame


# Acknowledgements
Lifted from: https://en.wikipedia.org/wiki/Deaths_in_2016 for all years",.csv
Cement Sales & Demand ,1,cement-sales-demand,89cement data .csv,CC0-1.0,"The dataset is related to Cement Sales and Demand in India, it also contains some external factors that which affecting the sales and demand of cement. 
It has features like Production, Sales, Demand,  Population, GDP, Loan Disbursement, and Interest Rates.
This is a simulated dataset, Data was collected in a yearly format and then simulated on the basis of research papers 
We can build different models on this data set like Forecasting, Regression.

About this file
This data set has information about cement data, it has features as follows
1) Month = This data is sequentially collected from January 2010 to November 2022
2) Production = cement production by XYZ company per month in tons
3) Sales = Cement Sales by XYZ company per month in tons, sales are done by XYZ company
4) Demand = Demand of cement per month in tons, these are orders that XYZ company has for that month
5) Population = India's population per month in billion
6) GDP = Gross Domestic Product(GDP) of India per month in billion
7) Disbursement = Home Loans amounts given by XYZ company in Cr.
8) Interest Rate = Home loans Interest rate by XYZ bank in % over the period of time

*Note = the data is collected in year format and then it is simulated on monthly basis with the help of research papers",.csv
Cerebral Stroke Prediction-Imbalanced Dataset,1,cerebral-stroke-predictionimbalaced-dataset,dataset.csv,Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO),"### Context

A stroke, also known as a cerebrovascular accident or CVA is when part of the brain loses its blood supply and the part of the body that the blood-deprived brain cells control stops working. This loss of blood supply can be ischemic because of lack of blood flow, or hemorrhagic because of bleeding into brain tissue. A stroke is a medical emergency because strokes can lead to death or permanent disability. There are opportunities to treat ischemic strokes but that treatment needs to be started in the first few hours after the signs of a stroke begin. 

### Content

The cerebral Stroke dataset consists of 12 features including the target column which is imbalanced.
 
### Acknowledgements
Liu, Tianyu; Fan, Wenhui; Wu, Cheng (2019), “Data for A hybrid machine learning approach to cerebral stroke prediction based on imbalanced medical-datasets”, Mendeley Data, V1, doi: 10.17632/x8ygrw87jw.1
Dataset is sourced from [here.](https://data.mendeley.com/datasets/x8ygrw87jw/1)",.csv
Cervical Cancer Dataset,1,cervical-cancer-dataset,cervical-cancer_csv.csv,Apache 2.0,"Cervical cancer is one of the leading causes of cancer-related deaths among women worldwide. Early detection and accurate prediction of cervical cancer can significantly improve the chances of successful treatment and save lives. This dataset help to develop a predictive model using machine learning techniques to identify individuals at high risk of cervical cancer, allowing for timely intervention and medical care.",.csv
Cervical Cancer Risk Classification,1,cervical-cancer-risk-classification,kag_risk_factors_cervical_cancer.csv,other,"Cervical Cancer Risk Factors for Biopsy: This Dataset is Obtained from UCI Repository and kindly acknowledged!

This file contains a List of Risk Factors for Cervical Cancer leading to a Biopsy Examination!

About 11,000 new cases of invasive cervical cancer are diagnosed each year in the U.S. However, the number of new cervical cancer cases has been declining steadily over the past decades. Although it is the most preventable type of cancer, each year cervical cancer kills about 4,000 women in the U.S. and about 300,000 women worldwide. In the United States, cervical cancer mortality rates plunged by 74% from 1955 - 1992 thanks to increased screening and early detection with the Pap test. AGE Fifty percent of cervical cancer diagnoses occur in women ages 35 - 54, and about 20% occur in women over 65 years of age. The median age of diagnosis is 48 years. About 15% of women develop cervical cancer between the ages of 20 - 30. Cervical cancer is extremely rare in women younger than age 20. However, many young women become infected with multiple types of human papilloma virus, which then can increase their risk of getting cervical cancer in the future. Young women with early abnormal changes who do not have regular examinations are at high risk for localized cancer by the time they are age 40, and for invasive cancer by age 50. SOCIOECONOMIC AND ETHNIC FACTORS Although the rate of cervical cancer has declined among both Caucasian and African-American women over the past decades, it remains much more prevalent in African-Americans -- whose death rates are twice as high as Caucasian women. Hispanic American women have more than twice the risk of invasive cervical cancer as Caucasian women, also due to a lower rate of screening. These differences, however, are almost certainly due to social and economic differences. Numerous studies report that high poverty levels are linked with low screening rates. In addition, lack of health insurance, limited transportation, and language difficulties hinder a poor woman’s access to screening services. HIGH SEXUAL ACTIVITY Human papilloma virus (HPV) is the main risk factor for cervical cancer. In adults, the most important risk factor for HPV is sexual activity with an infected person. Women most at risk for cervical cancer are those with a history of multiple sexual partners, sexual intercourse at age 17 years or younger, or both. A woman who has never been sexually active has a very low risk for developing cervical cancer. Sexual activity with multiple partners increases the likelihood of many other sexually transmitted infections (chlamydia, gonorrhea, syphilis).Studies have found an association between chlamydia and cervical cancer risk, including the possibility that chlamydia may prolong HPV infection. FAMILY HISTORY Women have a higher risk of cervical cancer if they have a first-degree relative (mother, sister) who has had cervical cancer. USE OF ORAL CONTRACEPTIVES Studies have reported a strong association between cervical cancer and long-term use of oral contraception (OC). Women who take birth control pills for more than 5 - 10 years appear to have a much higher risk HPV infection (up to four times higher) than those who do not use OCs. (Women taking OCs for fewer than 5 years do not have a significantly higher risk.) The reasons for this risk from OC use are not entirely clear. Women who use OCs may be less likely to use a diaphragm, condoms, or other methods that offer some protection against sexual transmitted diseases, including HPV. Some research also suggests that the hormones in OCs might help the virus enter the genetic material of cervical cells. HAVING MANY CHILDREN Studies indicate that having many children increases the risk for developing cervical cancer, particularly in women infected with HPV. SMOKING Smoking is associated with a higher risk for precancerous changes (dysplasia) in the cervix and for progression to invasive cervical cancer, especially for women infected with HPV. IMMUNOSUPPRESSION Women with weak immune systems, (such as those with HIV / AIDS), are more susceptible to acquiring HPV. Immunocompromised patients are also at higher risk for having cervical precancer develop rapidly into invasive cancer. DIETHYLSTILBESTROL (DES) From 1938 - 1971, diethylstilbestrol (DES), an estrogen-related drug, was widely prescribed to pregnant women to help prevent miscarriages. The daughters of these women face a higher risk for cervical cancer. DES is no longer prsecribed.",.csv
Character Encoding Examples,1,character-encoding-examples,file_guide.csv,CC0-1.0,"### Context:

Character encodings are sets of mappings from raw bits (0’s and 1’s) to text characters. When a text encoded with a specific encoder is decoded with a different encoder, it changes the output text. Sometimes this results in completely unreadable text.

This dataset is intended to provide a list of example texts in different character encodings to help you diagnose which file encoding your source file actually in. 

### Content

This dataset is made up of six text files that represent five different character encodings and six different languages. The character encodings represented in this dataset are ISO-8859-1 (also known as Latin 1), 

ASCII, Windows 1251, UTF-16 that has been successfully converted into the UTF-8 and BIG-5. More information on the files is available in the file_guide.csv file.

Each  text file contains a header and footer. The body text is delimited by this text:

*** START OF THE PROJECT GUTENBERG EBOOK [TITLE OF BOOK GOES HERE] ***

*** END OF THE PROJECT GUTENBERG EBOOK [TITLE OF BOOK GOES HERE]***

### Acknowledgements: 

The texts in this dataset were prepared by Project Gutenberg volunteers. These texts are in the public domain. 

### Inspiration: 

* Can you build an tool to automatically detect when a file in the wrong encoding is read in?
* You can use this dataset to explore what happens when you read in text using different encoders.",.csv
ChatGPT App Reviews,1,chatgpt-app-reviews,chatgpt_reviews.csv,Attribution-NoDerivatives 4.0 International (CC BY-ND 4.0),"The ChatGPT App Reviews dataset is a comprehensive collection of user reviews from the ChatGPT mobile app on iOS, capturing valuable insights and sentiments. The dataset enables the understanding of user satisfaction, evaluation of app performance, and identification of emerging patterns.

###### The way data was collected
Scraping ChatGPT reviews on App Store

###### Ideas for using this dataset
- Sentiment analysis
- What makes the application receive 1-star and 5-star

####Note - It was last updated on July 26th 2023",.csv
ChatGPT reviews [DAILY UPDATED],1,chatgpt-reviews-daily-updated,chatgpt_reviews.csv,Apache 2.0,This dataset mainly consists of daily-updated user reviews and ratings for the ChatGPT Android App. It also contains data on the relevancy of these reviews and the dates they were posted.,.csv
Chatbot Dataset (AI Q&A),1,chatbot-ai-q-and-a,AI.csv,CC-BY-NC-SA-4.0,"Dataset made for a chatbot project done earlier.
This dataset is about artificial intelligence basics Q&A
For example, history ...

Enjoy using it! 😄
[Dog's Breed Dataset](https://www.kaggle.com/datasets/yapwh1208/dogs-breed-dataset)
[Cat's Breed Dataset](https://www.kaggle.com/datasets/yapwh1208/cats-breed-dataset)
[Countries GDP](https://www.kaggle.com/datasets/yapwh1208/countries-gdp-2012-to-2021)",.csv
Chemistry - The mystery,1,chemistry-the-mystery,periiodic_tables_details.csv,Apache 2.0,"Chemistry is an interesting subject and we all study it in school/collage . So can we visualize or analyse patterns on basis of elements and their properties ?
This dataset offers you about 74 columns , indicating all required properties . 
Can you simplify students life and overall understanding from your notebook ? ",.csv
Chennai House Price,1,chennai-house-price,clean_data.csv,CC0-1.0,"### Context

This dataset contains the price of houses located in Chennai. It can be used to predict the price of houses using Machine Learning.


### Content

This dataset contains 8 columns with price being the target. The rest 7 columns describe different features affecting the price of a house.


### Acknowledgements

This data was extracted from www.makaan.com on 2nd October 2021.


### Inspiration

This data can help people get an estimate of how much they need to spend to buy a house in Chennai at a specific location from a specific builder with certain features.",.csv
Chennai Housing Sales Price,1,chennai-housing-sales-price,Chennai houseing sale.csv,DbCL-1.0,"Real estate transactions are quite opaque sometimes and it may be difficult for a newbie to know the fair price of any given home. Thus, multiple real estate websites have the functionality to predict the prices of houses given different features regarding it. Such forecasting models will help buyers to identify a fair price for the home and also give insights to sellers as to how to build homes that fetch them more money. Chennai house sale price data is shared here and the participants are expected to build a sale price prediction model that will aid the customers to find a fair price for their homes and also help the sellers understand what factors are fetching more money for the houses.",.csv
Chess Game Dataset (Lichess),1,chess,games.csv,CC0-1.0,"**General Info**

This is a set of just over 20,000 games collected from a selection of users on the site Lichess.org, and how to collect more. I will also upload more games in the future as I collect them. This set contains the:

 - Game ID;
 - Rated (T/F);
 - Start Time;
 - End Time;
 - Number of Turns;
 - Game Status;
 - Winner;
 - Time Increment;
 - White Player ID;
 - White Player Rating;
 - Black Player ID;
 - Black Player Rating;
 - All Moves in Standard Chess Notation;
 - Opening Eco (Standardised Code for any given opening, [list here][1]);
 - Opening Name;
 - Opening Ply (Number of moves in the opening phase)

For each of these separate games from Lichess. I collected this data using the [Lichess API][2], which enables collection of any given users game history. The difficult part was collecting usernames to use, however the API also enables dumping of all users in a Lichess team. There are several teams on Lichess with over 1,500 players, so this proved an effective way to get users to collect games from.

**Possible Uses**

Lots of information is contained within a single chess game, let alone a full dataset of multiple games. It is primarily a game of patterns, and data science is all about detecting patterns in data, which is why chess has been one of the most invested in areas of AI in the past. This dataset collects all of the information available from 20,000 games and presents it in a format that is easy to process for analysis of, for example, what allows a player to win as black or white, how much meta (out-of-game) factors affect a game, the relationship between openings and victory for black and white and more.


  [1]: https://www.365chess.com/eco.php
  [2]: https://github.com/ornicar/lila",.csv
Chess Matches,1,chess-matches,chess_matches.csv,CC-BY-SA-4.0,"This was a dataset prepared after preprocessing of data from an individual accounts gameplay( with owner consent) of about 1157 games played in the initial version. 
The dataset has been recovered from a pgn file and column names have been decided to adhere to understandability
",.csv
Chess openings played by 508 users,1,chess-openings-played-by-508-users,Openings500_anonymized.csv,MIT,"Dataset of openings played by 508 users on lichess.org in the period of about 3-6 months with most of the users having rating in the range of 1800-2100. Each row in the dataset represents one game of chess (about 1 million games downloaded with lichess API). Time controls are mostly blitz and rapid, no variants. Color column indicates which pieces (0 - white/1 - black) were played by user in that game.
Openings were truncated to not include variations.
Dataset was used by me to create a somewhat simple collaborative filtering recommender with Alternating Least Squares.
",.csv
Chicago Ridership - Daily Boarding Totals Jan2024,1,chicago-cta-ridership-daily-boarding-totals,CTA_-_Ridership_-_Daily_Boarding_Totals_20240417.csv,Apache 2.0,"This dataset shows systemwide boardings for both bus and rail services provided by CTA, dating back to 2001. Daytypes are as follows: W = Weekday, A = Saturday, U = Sunday/Holiday. See attached readme file for information on how these numbers are calculated. It contains  8,401 data points, with 5 features.

It is the official port that is dated at 25th Jan 2024 (https://data.cityofchicago.org/Transportation/CTA-Ridership-Daily-Boarding-Totals/6iiy-9s97/about_data), provided by the Chicago Transit Authority.
",.csv
Child labor serious issue,1,child-labor-serious-issue,incidenceukus new.csv,CC0-1.0,"this graph was created in Ourdataoworld and Canva :

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fde721317e571b33703f6b4c7f3be7ca8%2FLike%20.gif?generation=1711392790247308&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F4abfbacea82606ef972e1ab13e8cb72b%2Fgraph2.png?generation=1711392797339837&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fabaf666c3c40f944231a21d9a23f61a8%2Fgraph1.png?generation=1711392806303973&alt=media)

Children work for various reasons, including economic necessity, cultural expectations, and lack of access to education. They can be found working in various industries such as agriculture, manufacturing, domestic service, and mining. Child labor has evolved over time due to changes in laws, social attitudes, and economic conditions. Initially prevalent during the Industrial Revolution, child labor laws and advocacy efforts have led to a decline in its prevalence in many parts of the world. However, it still persists in some regions due to poverty and inadequate enforcement of labor laws.

The International Labour Organisation states in its 2013 World Report on Child Labour that there were around 265 million working children in the world—almost 17 per cent of the worldwide child population. According to the publicly available data discussed in more detail below, Sub-Saharan Africa is the region where child labor is most prevalent.

While absolute numbers are still high, particularly in those countries with the lowest standards of living, from a historical viewpoint there are concrete examples of countries that managed to virtually eliminate widespread child labor in the course of a century. The United Kingdom is a case in point. In terms of recent developments, global trends show a significant reduction in child labor over the last couple of decades. However, there is wide dispersion in the progress that different countries have achieved.

Long-run history of child labor in today's rich countries
Historical studies suggest that child work was widespread in Europe and North America in the 19th century, but declined very rapidly at the turn of the 20th century. The available historical evidence seems consistent with the fact that industrialisation in Western countries initially increased the demand for child labor, but then eventually contributed towards its elimination.1

The visualizations show the share of children in employment for the UK and the United States at the turn of the 20th century. For the US chart you can add data on rural versus urban child labor trends: for both boys and girls, the incidence of child labor was higher in rural populations.",.csv
Children's Violent Discipline,1,child-abuse-rights,childrens_violence new.csv,CC0-1.0,"this graph was created in Power Bi and ourdataworld :

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F80bfeeb87ff8213dd20a30a3a3779b10%2Fgraph2.jpeg?generation=1709929478433475&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F3d05e8a9c9b9a7e4a0be0be7ffcd15e9%2Fpercentage-of-children-214-who-experience-violent-discipline-at-home.png?generation=1709929484391281&alt=media)

Violations of children's rights persist worldwide, presenting a tragic reality that demands urgent attention. However, amidst this somber landscape, there are glimmers of hope. Across different nations, significant variations exist in the prevalence of child abuse and neglect. Moreover, historical trends indicate a decline in several forms of violence against children. These observations underscore the potential for progress in safeguarding the rights and well-being of children globally.

In assessing the state of children's rights, it is crucial to acknowledge the multifaceted nature of the challenges they face. From physical and emotional abuse to neglect and exploitation, children encounter various forms of violence that threaten their safety and dignity. Factors such as poverty, conflict, and cultural norms can exacerbate these risks, creating complex barriers to the realization of children's rights.

Despite these challenges, there are signs of progress. In many countries, concerted efforts have been made to enact legislation, establish protective services, and raise awareness about children's rights. These initiatives have contributed to a decline in certain forms of violence against children, signaling the effectiveness of targeted interventions and advocacy efforts.

Moreover, a deeper understanding of the root causes of violence against children has informed prevention strategies and interventions. By addressing underlying factors such as socioeconomic inequality, gender discrimination, and inadequate access to education and healthcare, communities and policymakers can create environments that are conducive to the well-being of children.

Education plays a pivotal role in this regard, empowering children with knowledge of their rights and equipping them with the skills to protect themselves. By promoting inclusive and rights-based education, societies can cultivate a culture of respect for children's rights and foster a generation of informed and empowered individuals.

Additionally, investments in social services, including healthcare, childcare, and family support programs, are essential for creating protective environments for children. By strengthening social safety nets and providing resources to vulnerable families, communities can mitigate the risk factors associated with violence and neglect.

International cooperation also plays a vital role in advancing children's rights on a global scale. Through mechanisms such as the United Nations Convention on the Rights of the Child (UNCRC), countries have committed to upholding the rights and welfare of children. By sharing best practices, exchanging knowledge, and coordinating efforts, the international community can amplify the impact of interventions and address cross-border challenges.

However, despite these efforts, significant gaps remain in the protection of children's rights. Inadequate resources, weak enforcement mechanisms, and cultural barriers continue to impede progress in many parts of the world. Moreover, emerging threats such as cyberbullying and online exploitation present new challenges that require innovative solutions and concerted action.

To overcome these challenges and build a world where every child can thrive, a holistic approach is needed. This includes addressing the underlying social, economic, and cultural factors that contribute to violence against children, strengthening legal frameworks and enforcement mechanisms, and promoting children's participation in decision-making processes.

Ultimately, the protection of children's rights is not only a moral imperative but also a strategic investment in the future of society. By prioritizing the well-being and dignity of every child, we can create a more just, equitable, and sustainable world for generations to come.",.csv
Chipotle Locations,1,chipotle-locations,chipotle_stores.csv,CC-BY-NC-SA-4.0,"### Context

Chipotle is one of the most popular fast-casual restaurant chains in the United States, and I personally enjoy eating there quite a bit. I wanted to work on my data scrapping and geospatial analysis skills, and I thought this would be a fun dataset to do it with!


### Content

Location of every Chipotle Restaurant within the United States.
state
location
address
latitude
longitude


### Acknowledgements

I scrapped this data from Chipotle. I'm not really sure of the legal ramifications of data scrapping, so if Chipotle sees this and gets mad, please don't sue me. I saw a website was straight up selling this data, so presumably Chipotle won't mind (although the company selling this data might).


### Inspiration

Maybe we can get our hands on some US population data and identify areas that are likely able to sustain a new Chipotle Location?
",.csv
ChnSentiCorp_htl_all,1,chnsenticorp-htl-all,ChnSentiCorp_htl_all.csv,Apache 2.0,"7000+ hotel review data, 5000+ positive reviews, 2000+ negative reviews.

7000+ hotel review data, 5000+ positive reviews, 2000+ negative reviews.

7000+ hotel review data, 5000+ positive reviews, 2000+ negative reviews.",.csv
Cholera Dataset,1,cholera-dataset,data.csv,other,"### Context
&gt; - Cholera is an acute diarrhoeal infection caused by eating or drinking food or water that is contaminated with the bacterium Vibrio cholerae.    
&gt; - Cholera remains a global threat to public health and is an indicator of inequity and lack of social development.    
&gt; - Researchers have estimated that every year, there are 1.3 to 4.0 million cases of cholera, and 21 000 to 143 000 deaths worldwide due to the infection.   

### Content
&gt; 1. data.csv - Contains country-wise no. of cases, deaths and CFR (case fatality ratio) from the year 1949 till 2016

### Acknowledgements / Data Source

&gt; https://apps.who.int/gho/data/node.main.174?lang=en

### Collection methodology

&gt; https://github.com/imdevskp/cholera-data-cleaning

### Cover Photo

&gt; Photo from Medicinenet website
&gt; https://www.medicinenet.com/cholera/article.htm",.csv
Chronic kidney disease EHRs Abu Dhabi,1,chronic-kidney-disease-ehrs-abu-dhabi,ChronicKidneyDisease_EHRs_from_AbuDhabi.csv,Attribution 4.0 International (CC BY 4.0),"**Information about this dataset**
This is a dataset of electronic medical records of 491 patients collected at the Tawam Hospital in Al-Ain city (Abu Dhabi, United Arab Emirates), between 1st January and 31st December 2008. The patients included 241 women and 250 men, with an average age of 53.2 years. Each patient has a chart of 22 clinical variables, expressing her/his values of laboratory tests and exams or data about her/his medical history. Each patient included in this study had cardovascular disease or was at risk of cardiovascular disease, according to the standards of Tawam Hospital.

More information about this dataset can be found in the Dataset section, Table 1, Table 2, and Table 3 of the following article:

&gt; Davide Chicco, Christopher A. Lovejoy, and Luca Oneto, ""[A machine learning analysis of health records of patients with chronic kidney disease at risk of cardiovascular disease](https://doi.org/10.1109/access.2021.3133700)"" IEEE Access 9 (2021): 165132-165144. 


",.csv
Churn Modeling Dataset,1,churn-modeling-dataset,Churn_Modelling.csv,CC0-1.0,"## Content

This data set contains details of a bank's customers and the target variable is a binary variable reflecting the fact whether the customer left the bank (closed his account) or he continues to be a customer.
",.csv
Churn for Bank Customers,1,churn-for-bank-customers,churn.csv,CC0-1.0,"### Content


   - RowNumber—corresponds to the record (row) number and has no effect on the output. 
   - CustomerId—contains random values and has no effect on customer leaving the bank. 
   - Surname—the surname of a customer has no impact on their decision to leave the bank. 
   - CreditScore—can have an effect on customer churn, since a customer with a higher credit score is less likely to leave the bank.
   - Geography—a customer’s location can affect their decision to leave the bank. 
   - Gender—it’s interesting to explore whether gender plays a role in a customer leaving the bank. 
   - Age—this is certainly relevant, since older customers are less likely to leave their bank than younger ones.
   - Tenure—refers to the number of years that the customer has been a client of the bank. Normally, older clients are more loyal and less likely to leave a bank.
    - Balance—also a very good indicator of customer churn, as people with a higher balance in their accounts are less likely to leave the bank compared to those with lower balances.
    - NumOfProducts—refers to the number of products that a customer has purchased through the bank.
    - HasCrCard—denotes whether or not a customer has a credit card. This column is also relevant, since people with a credit card are less likely to leave the bank.
    - IsActiveMember—active customers are less likely to leave the bank.
    - EstimatedSalary—as with balance, people with lower salaries are more likely to leave the bank compared to those with higher salaries.
    - Exited—whether or not the customer left the bank.



### Acknowledgements

As we know, it is much more expensive to sign in a new client than keeping an existing one.

It is advantageous for banks to know what leads a client towards the decision to leave the company.

Churn prevention allows companies to develop loyalty programs and retention campaigns to keep as many customers as possible. ",.csv
Cinema Tickets,1,cinema-ticket,cinemaTicket_Ref.csv,CC-BY-NC-SA-4.0,"## Context
Cinema industry is not excluded of getting advantage of predictive modeling. Like other industry e.g. retail , banking and restaurants , sale forecast 
can help cinemas for cost reduction and better ROI. By forecasting sale,  screening in different location could be optimized as well as effective market targeting and pricing. 

Also historical data of sale and movies details e.g. cost, cast and crews, and other project details like schedule,  could help producers to select high performance cast and crews and planning for better projects  ROI . Also it helps to assign  screening location  on hot spots and areas.  
###     
###   
![image](https://cdn.cnn.com/cnnnext/dam/assets/200820103238-movie-theater-covid-19-gfx-exlarge-169.jpg)
#   
## Content

About eight months sales  history of different cinemas with detailed data of screening , during 2018  with encoded annonymized locations .  

### Starter Kernels 

-  [EDA , Temporal Feat Eng and XGBoost](https://www.kaggle.com/arashnic/agile-eda-base-models) 


## Inspiration

- Time series analysis
- Cinema Clustering
- Forecast sales for each cinema
- Recommendation:
     - Movie genre recommendation for cinemas
     - Cinema location recommendation
     - Cast and crew ratings 
[Recommendations required more detailed data about movies which will be added to dataset during next versions] 

 ",.csv
Cirrhosis Patient Survival Prediction,1,cirrhosis-patient-survival-prediction,cirrhosis.csv,Attribution 4.0 International (CC BY 4.0),"Utilize 17 clinical features for predicting survival state of patients with liver cirrhosis. The survival states include 0 = D (death), 1 = C (censored), 2 = CL (censored due to liver transplantation).

**For what purpose was the dataset created?**

Cirrhosis results from prolonged liver damage, leading to extensive scarring, often due to conditions like hepatitis or chronic alcohol consumption. The data provided is sourced from a Mayo Clinic study on primary biliary cirrhosis (PBC) of the liver carried out from 1974 to 1984.

**Who funded the creation of the dataset?**

Mayo Clinic

**What do the instances in this dataset represent?**

People

**Does the dataset contain data that might be considered sensitive in any way?**

Gender, Age

**Was there any data preprocessing performed?**

1. Drop all the rows where miss value (NA) were present in the Drug column
2. Impute missing values with mean results
3. One-hot encoding for all category attributes

**Additional Information**

During 1974 to 1984, 424 PBC patients referred to the Mayo Clinic qualified for the randomized placebo-controlled trial testing the drug D-penicillamine. Of these, the initial 312 patients took part in the trial and have mostly comprehensive data. The remaining 112 patients didn't join the clinical trial but agreed to record basic metrics and undergo survival tracking. Six of these patients were soon untraceable after their diagnosis, leaving data for 106 of these individuals in addition to the 312 who were part of the randomized trial.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F2003977%2F4465d9311ccae2f9ccb057fc7e14f26f%2FScreenshot%20from%202023-10-18%2009-42-52.png?generation=1697586187040332&alt=media)",.csv
Cities of India with Pin Codes,1,cities-of-india-with-pin-codes,Cities_in_India_with_pincodes.csv,other,"India is one of the largest and populous country of the world and hence, it is next to impossible to recall Pin code of any particular locality in a city/town or village or to locate a place using its Pin code. This dataset will be helpful to find pin code or area, it can be also helpful for e commerce field. The Department of Posts has been the cornerstone of India's communication for more than a century and a half, playing a vital role in the country's socio-economic development. It impacts the lives of Indian citizens through various services. With a huge number of post offices, it boasts the most extensive postal network worldwide
",.csv
Civil Engineering: Cement Manufacturing Dataset,1,cement-manufacturing-concrete-dataset,concrete.csv,CC0-1.0,"### Data Description

The actual concrete compressive strength (MPa) for a given mixture under a
specific age (days) was determined from laboratory. Data is in raw form (not scaled). The data has 8 quantitative input variables, and 1 quantitative output variable, and 1030 instances (observations).

### Domain

Cement manufacturing

### Context

Concrete is the most important material in civil engineering. The concrete compressive strength is a highly nonlinear function of age and ingredients. These ingredients include cement, blast furnace slag, fly ash, water, superplasticizer, coarse aggregate, and fine aggregate.

### Attribute Information

* **Cement**                                         : measured in kg in a m3 mixture
* **Blast**                                              : measured in kg in a m3 mixture
* **Fly ash**                                          : measured in kg in a m3 mixture
* **Water**                                            : measured in kg in a m3 mixture
* **Superplasticizer**                           : measured in kg in a m3 mixture
* **Coarse Aggregate**                       : measured in kg in a m3 mixture
* **Fine Aggregate**                            : measured in kg in a m3 mixture
* **Age**                                               : day (1~365)
* **Concrete compressive strength** measured in MPa",.csv
Civil Service Exam Results,1,civil-service-exam-results,Civil_Service_List__Active.csv,Apache 2.0,"A Civil Service List consists of all candidates who passed an exam, ranked in score order. An established list is considered active for no less than one year and no more than four years from the date of establishment.

This dataset is critical for data science applications because it provides a structured way to analyze workforce planning, recruitment efficacy, and the demographic distribution of candidates succeeding in civil service exams. By understanding patterns and trends within this data, municipal departments can enhance their recruitment strategies, ensure fair and effective hiring practices, and plan for future workforce needs based on the success rates of candidates in different job categories.

Possible analyses with this dataset include:

- **Performance Analysis**: Examine the average scores across different exams to identify which exams have higher or lower pass rates. This can help in adjusting the difficulty levels of the exams or providing additional preparation resources to candidates.
- **Demographic Analysis**: Analyze the diversity of candidates passing the exams by correlating last names with demographic data to ensure all communities have equitable access and success in civil service opportunities.
- **Trend Analysis**: Study trends over time in the number of candidates taking exams and their success rates to predict future hiring needs and adjust recruitment strategies accordingly.
- **Impact of Credits**: Investigate how different credits (veteran, residency, etc.) impact the final scores and list standings of candidates to assess the fairness and effectiveness of these credit systems.",.csv
Clash Royal Dataset,1,clash-royal-dataset,clash_royal_data.csv,CC0-1.0,"This dataset consist of all the best cards data that are being used in the grand challenges in clash royal. The data is collected using bs4 and request library.

name: This column represents the name of the troop

Rating: This column indicates the rating associated with the card. In the provided data.

Usage: This column represents the usage percentage of the card.

increase_in_usage: This column provides information about the increase in usage percentage of the card.

Win: This column indicates the win percentage of the card.

increase_in_win: This column provides information about the increase in win percentage of the card.

CWR: This column represents the ""CWR"" (Combat Win Rate) percentage of the card.",.csv
Clean Water,1,clean-water,deathsbyriskfactor new.csv,CC0-1.0,"this graph was created in OurDataWorld:

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fa9d8fb301a8f49eeb712fd1c50fab245%2Fgraph3.png?generation=1713552703997694&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F45f18d38fb147264a8f6bb489b4df5fa%2Fgraph2.png?generation=1713552711119169&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fc9a3aacb3796f47cb79c1b4da1a00a3e%2Fgraph1.png?generation=1713552718330631&alt=media)

Access to clean water is one of our most basic human needs.

But, one in four people in the world do not have access to safe drinking water. This is a major health risk. Unsafe water is responsible for more than a million deaths each year.

In this article, we look at data on access to safe water and its implications for health worldwide.

Unsafe water is a leading risk factor for death
Unsafe water sources are responsible for over one million deaths each year
Unsafe water is one of the world's largest health and environmental problems – particularly for the poorest in the world.

The Global Burden of Disease is a major global study on the causes and risk factors for death and disease published in the medical journal The Lancet. These estimates of the annual number of deaths attributed to a wide range of risk factors are shown here.

Lack of access to safe water sources is a leading risk factor for infectious diseases, including cholera, diarrhea, dysentery, hepatitis A, typhoid, and polio.1 It also exacerbates malnutrition and, in particular, childhood stunting. In the chart, we see that it ranks as a very important risk factor for death globally.",.csv
Clickstream Data for Online Shopping,1,clickstream-data-for-online-shopping,e-shop clothing 2008.csv,CC0-1.0,"### Source:

Mariusz ÅapczyÅ„ski, Cracow University of Economics, Poland, lapczynm '@' uek.krakow.pl 
Sylwester BiaÅ‚owÄ…s, Poznan University of Economics and Business, Poland, sylwester.bialowas '@' ue.poznan.pl 


### Data Set Information:

The dataset contains information on clickstream from online store offering clothing for pregnant women. Data are from five months of 2008 and include, among others, product category, location of the photo on the page, country of origin of the IP address and product price in US dollars.


### Attribute Information:

The dataset contains 14 variables described in a separate file (See 'Data set description')


### Relevant Papers:

N/A



### Citation Request:

If you use this dataset, please cite: 

ÅapczyÅ„ski M., BiaÅ‚owÄ…s S. (2013) Discovering Patterns of Users' Behaviour in an E-shop - Comparison of Consumer Buying Behaviours in Poland and Other European Countries, â€œStudia Ekonomiczneâ€, nr 151, â€œLa sociÃ©tÃ© de l'information : perspective europÃ©enne et globale : les usages et les risques d'Internet pour les citoyens et les consommateursâ€, p. 144-153 

### Data description ìe-shop clothing 2008î

## Variables:

# 1. YEAR (2008)

========================================================

# 2. MONTH -&gt; from April (4) to August (8)

========================================================

# 3. DAY -&gt; day number of the month

========================================================

# 4. ORDER -&gt; sequence of clicks during one session

========================================================

# 5. COUNTRY -&gt; variable indicating the country of origin of the IP address with the 
following categories:

1-Australia
2-Austria
3-Belgium
4-British Virgin Islands
5-Cayman Islands
6-Christmas Island
7-Croatia
8-Cyprus
9-Czech Republic
10-Denmark
11-Estonia
12-unidentified
13-Faroe Islands
14-Finland
15-France
16-Germany
17-Greece
18-Hungary
19-Iceland
20-India
21-Ireland
22-Italy
23-Latvia
24-Lithuania
25-Luxembourg
26-Mexico
27-Netherlands
28-Norway
29-Poland
30-Portugal
31-Romania
32-Russia
33-San Marino
34-Slovakia
35-Slovenia
36-Spain
37-Sweden
38-Switzerland
39-Ukraine
40-United Arab Emirates
41-United Kingdom
42-USA
43-biz (*.biz)
44-com (*.com)
45-int (*.int)
46-net (*.net)
47-org (*.org)

========================================================

# 6. SESSION ID -&gt; variable indicating session id (short record)

========================================================

# 7. PAGE 1 (MAIN CATEGORY) -&gt; concerns the main product category:
1-trousers
2-skirts
3-blouses
4-sale

========================================================

# 8. PAGE 2 (CLOTHING MODEL) -&gt; contains information about the code for each product 
(217 products)

========================================================

# 9. COLOUR -&gt; colour of product

1-beige
2-black
3-blue
4-brown
5-burgundy
6-gray
7-green
8-navy blue
9-of many colors
10-olive
11-pink
12-red
13-violet
14-white

========================================================

# 10. LOCATION -&gt; photo location on the page, the screen has been divided into six parts:

1-top left
2-top in the middle
3-top right
4-bottom left
5-bottom in the middle
6-bottom right

========================================================

# 11. MODEL PHOTOGRAPHY -&gt; variable with two categories: 

1-en face
2-profile

========================================================

# 12. PRICE -&gt; price in US dollars

========================================================

# 13. PRICE 2 -&gt; variable informing whether the price of a particular product is higher than 
the average price for the entire product category

1-yes
2-no

========================================================

# 14. PAGE -&gt; page number within the e-store website (from 1 to 5)

++++++++++++++++++++++++++++++++++++++++++++++++++++++++






",.csv
Climate Insights Dataset,1,climate-insights-dataset,climate_change_data.csv,CC0-1.0,"🌍 Welcome to the Climate Insights Dataset! 📊🌡️🌊

Description: 
This dataset provides valuable insights into the ongoing changes in our climate. It encompasses a comprehensive collection of temperature records, CO2 emissions data, and sea level rise measurements. With a focus on global trends, it enables researchers, scientists, and climate enthusiasts to analyze the impact of climate change on our planet.

🔍 How to Use:

1 Access the dataset to explore the diverse climate variables and their temporal trends.

2 Conduct exploratory data analysis (EDA) to gain a deeper understanding of temperature variations, CO2 emissions, and sea level rise.

3 Utilize machine learning algorithms to model and predict future climate patterns.

4 Leverage extensive feature engineering to extract meaningful insights.

5 Visualize the data using powerful libraries like Matplotlib and Seaborn for impactful presentations.

6 Discover relationships between climate factors and countries/locations using one-hot encoding.

7 Contribute to climate research, raise awareness, and devise mitigation strategies.


Let's make the most of this dataset to understand the pressing challenges posed by climate change and work towards a sustainable future! 🌱🌞🌊🌍",.csv
Climate Risk and Economic Losses,1,global-climate-risk-index-and-related-economic-l,climate-risk-index-1.csv,other,"_____
# Climate Risk and Economic Losses
### A Study of Planetary Trends
By data.world's Admin [[source]](https://data.world/dataworldadmin)
_____

### About this dataset
&gt; This dataset contains critical information about the Global Climate Risk Index and associated economic data for countries around the world. The data provides insight into the effects of climate-related disasters on countries, allowing us to understand which areas are most affected. This dataset includes columns such as geom, cri_rank, cri_score, fatalities_per_100k_rank, fatalities per 100k total, fatalities rank, and more. With this powerful data set at your disposal you can gain a better understanding of which areas are most vulnerable to climate related disasters and begin to plan solutions that could potentially mitigate potential losses. Join us in creating a future where people are protected from the effects of global climate change!

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; This dataset provides information about the Global Climate Risk Index (CRI) and associated economic losses for various countries around the world. The Global Climate Risk Index measures a country’s vulnerability and resilience to extreme climate related events such as floods, heatwaves, storms, droughts and wildfires. The CRI takes into account fatalities caused by these events as well as economic losses in purchasing power parity US dollars. 
&gt; 

### Research Ideas
&gt; - Producing country-specific climate risk scorecards to help inform investment decisions based on projected losses per GDP due to natural disasters.
&gt; - Comparing a nation's climate risk ranking against other nations in order to better allocate resources and prioritize areas of research or infrastructure projects.
&gt; - Developing an interactive map that could graphically represent the relationship between fatality rates, economic losses and climate ranking for different countries around the world

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://data.world/dataworldadmin)
&gt; 
&gt;


### License
&gt; 
&gt; 
&gt; See the dataset description for more information.

### Columns

**File: climate-risk-index-1.csv**
| Column name                   | Description                                                             |
|:------------------------------|:------------------------------------------------------------------------|
| **the_geom**                  | Geometry of the country (Geometry)                                      |
| **the_geom_webmercator**      | Web Mercator projection of the geometry of the country (Geometry)       |
| **cri_rank**                  | Rank of the country on the Climate Risk Index (Integer)                 |
| **cri_score**                 | Score of the country on the Climate Risk Index (Integer)                |
| **fatalities_per_100k_rank**  | Rank of the country in terms of fatalities per 100,000 people (Integer) |
| **fatalities_per_100k_total** | Total number fatalities per 100,000 people (Integer)                    |
| **fatalities_rank**           | Rank of the country in terms of total fatalities (Integer)              |
| **fatalities_total**          | Total number of fatalities (Integer)                                    |
| **losses_per_gdp__rank**      | Rank of the country in terms of losses per GDP (Integer)                |
| **losses_per_gdp__total**     | Total losses per GDP (Integer)                                          |
| **losses_usdm_ppp_rank**      | Rank of the country in terms of losses in USDM PPP (Integer)            |
| **losses_usdm_ppp_total**     | Total losses in USDM PPP (Integer)                                      |
| **rw_country_code**           | Country code (String)                                                   |
| **rw_country_name**           | Country name (String)                                                   |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [data.world's Admin](https://data.world/dataworldadmin).

",.csv
Climate change Indicators,1,climate-change-indicators,climate_change_indicators.csv,CC0-1.0,This dataset has climate change indicators for different countries with their associated codes(ISO2 AND ISO3). The measurement has been updated yearly till 2022 from 1961.,.csv
Clinical Dataset,1,clinical-dataset,Clinical Data_Discovery_Cohort.csv,other,"The purest type of **electronic clinical data** which is obtained at the point of care at a medical facility, hospital, clinic or practice. Often referred to as the electronic medical record (EMR), the EMR is generally not available to outside researchers. The data collected includes administrative and demographic information, diagnosis, treatment, prescription drugs, laboratory tests, physiologic monitoring data, hospitalization, patient insurance, etc.

Individual organizations such as hospitals or health systems may provide access to internal staff.  Larger collaborations, such as the NIH Collaboratory Distributed Research Network provides mediated or collaborative access to clinical data repositories by eligible researchers.  Additionally, the UW De-identified Clinical Data Repository (DCDR) and the Stanford Center for Clinical Informatics allow for initial cohort identification.


About Dataset:

333 scholarly articles cite this dataset.

Unique identifier:
[DOI](https://doi.org/10.6084/m9.figshare.22638145.v1)

Dataset updated:
2023

Authors:
Haoyang Mi


In this dataset, we have two dataset:

1- Clinical Data_Discovery_Cohort:
Name of columns: 
Patient ID
Specimen date
Dead or Alive
Date of Death
Date of last Follow
Sex
Race
Stage
Event
Time

2- Clinical_Data_Validation_Cohort
Name of columns:
Patient ID
Survival time (days)
Event
Tumor size
Grade
Stage
Age
Sex
Cigarette
Pack per year
Type Adjuvant
Batch
EGFR
KRAS


Feel free to put your thought and analysis in a notebook for this datasets.
And you can create some interesting and valuable ML projects for this case.
Thanks for your attention.

  ",.csv
Clothes Price Prediction,1,clothes-price-prediction,clothes_price_prediction_data.csv,Apache 2.0,It includes various features related to clothing items along with their corresponding prices. The dataset is intended for use in a machine learning or statistical modeling project aimed at predicting the price of clothes based on their attributes.,.csv
Clustering Penguins Species,1,clustering-penguins-species,penguins.csv,GNU Lesser General Public License 3.0,"The dataset consists of 5 columns

culmen_length_mm: culmen length (mm)

culmen_depth_mm: culmen depth (mm)

flipper_length_mm: flipper length (mm)

body_mass_g: body mass (g)

sex: penguin sex",.csv
Coca-Cola Company,1,coca-cola-company,Coca Cola.csv,Apache 2.0,"Explore The Coca-Cola Company's market performance from 2019 to 2024 with this dataset. It includes daily data on stock prices (open, high, low, and close), offering insights into market trends and volatility. Ideal for analysis and modeling projects",.csv
Coffee Chain Sales Analysis,1,coffee-chain-sales-dataset,Coffee_Chain_Sales .csv,CC0-1.0,"### The Coffee Sales Data dataset provides valuable insights into the performance of a coffee chain across various locations.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F13090611%2F0f25997ba9b63b33c901471cb874aa83%2Fcisco_blog_canada_coffee.png?generation=1696189849175111&alt=media)
***Key Attributes:***

1.Area Code: A unique identifier for different geographical areas or regions where the coffee chain operates.

2.COGS (Cost of Goods Sold): The total cost incurred by the coffee chain in producing or purchasing the products it sells.

3.Difference between Actual and Target Profit: This attribute indicates how well the company performed in terms of profit compared to its target. It reflects the financial performance against predefined goals.

4.Date: The date of sales transactions, which allows for time-based analysis of sales trends and patterns.

5.Inventory Margin: The difference between the cost of maintaining inventory and the revenue generated from selling those inventory items.

6.Margin: The profit margin, which is the percentage of profit earned from sales. It's a critical financial metric.

7.Market Size: Information about the size of the market in each area, helping to understand the potential customer base and market dynamics.

8.Profit: financial gain achieved by the company after deducting the cost of goods sold (COGS) and other expenses from the revenue generated through sales.

9.Sales: represent the revenue generated from the coffee chain's products, reflecting its financial performance and customer demand.",.csv
Coffee Quality Data (CQI May-2023),1,coffee-quality-data-cqi,df_arabica_clean.csv,other,"# Coffee Quality Institute 
The Coffee Quality Institute (CQI) is a non-profit organization that works to improve the quality and value of coffee worldwide. It was founded in 1996 and has its headquarters in California, USA.

CQI's mission is to promote coffee quality through a range of activities that include research, training, and certification programs. The organization works with coffee growers, processors, roasters, and other stakeholders to improve coffee quality standards, promote sustainability, and support the development of the specialty coffee industry.

# Data
CQI maintains a web database that serves as a resource for coffee professionals and enthusiasts who are interested in learning about coffee quality and sustainability. The database includes a range of information on coffee production, processing, and sensory evaluation. It also contains data on coffee genetics, soil types, and other factors that can affect coffee quality.

## Sensory evaluations (coffee quality scores)
* *Aroma:* Refers to the scent or fragrance of the coffee.
* *Flavor:* The flavor of coffee is evaluated based on the taste, including any sweetness, bitterness, acidity, and other flavor notes.
* *Aftertaste:* Refers to the lingering taste that remains in the mouth after swallowing the coffee.
* *Acidity:* Acidity in coffee refers to the brightness or liveliness of the taste.
* *Body:* The body of coffee refers to the thickness or viscosity of the coffee in the mouth.
* *Balance:* Balance refers to how well the different flavor components of the coffee work together.
* *Uniformity:* Uniformity refers to the consistency of the coffee from cup to cup.
* *Clean Cup:* A clean cup refers to a coffee that is free of any off-flavors or defects, such as sourness, mustiness, or staleness.
* *Sweetness:* It can be described as caramel-like, fruity, or floral, and is a desirable quality in coffee.

**PLEASE NOTE: 'Total Cup Points' is literally the total of 10 features given above. There were some notebooks trying to predict the total cup points given these features. We know the exact function underlying the total cup points.**

## Defects
Defects are undesirable qualities that can occur in coffee beans during processing or storage. Defects can be categorized into two categories: Category One and Category Two defects.

Category One defects are primary defects that can be perceived through visual inspection of the coffee beans. These defects include Black beans, sour beans, insect-damaged beans, fungus-damaged beans, etc.

Category Two defects are secondary defects that are more subtle and can only be detected through tasting. These defects include Over-fermentation, staleness, rancidness, chemical taste, etc.

## Data Scraping
On this part, great thanks to [James LeDoux](https://github.com/jldbc). His repo [coffee-quality-database](https://github.com/jldbc/coffee-quality-database) from 2018 is efficiently written and well documented. To scrape the data, I used most of his code, but due to some changes on the website, I modified some of the lines. Also, some practices on modules were deprecated and deleted so I updated those codes also. Therefore, in May-2023 we can use this updated Python program to scrape data from this database. You can find my repo at https://github.com/fatih-boyar/coffee-quality-data-CQI/tree/main 


Only data was collected for the arabica type. With a few modifications in [scraper_bot.py](https://github.com/fatih-boyar/coffee-quality-data-CQI/blob/main/scraper_bot.py), scraping can be easily replicated for robusta types also.",.csv
Coffee Shop Sales Analysis,1,coffee-shop-sales-analysis,Project.csv,other,"This dataset contains the sales data of a coffee shop.
It contains the transaction id of every customer and their order description.
It does not contain any null value.
",.csv
Coimbra_BreastCancer,1,coimbra-breastcancer,Coimbra_breast_cancer_dataset.csv,Attribution 4.0 International (CC BY 4.0),"Coimbra Breast Cancer Study

This dataset presents a comprehensive exploration of clinical features observed or measured for 64 patients with breast cancer and 52 healthy controls. The dataset encompasses both quantitative attributes and corresponding labels for effective analysis and modeling.

Quantitative Attributes:

- Age (years): Age of the individuals.
- BMI (kg/m²): Body Mass Index, a measure of body fat based on weight and height.
- Glucose (mg/dL): Blood glucose levels, an important metabolic indicator.
- Insulin (µU/mL): Insulin levels, a hormone related to glucose regulation.
- HOMA: Homeostatic Model Assessment, a method for assessing insulin resistance and beta-cell function.
- Leptin (ng/mL): Leptin levels, a hormone involved in regulating appetite and energy balance.
- Adiponectin (µg/mL): Adiponectin levels, a protein associated with metabolic regulation.
- Resistin (ng/mL): Resistin levels, a protein implicated in insulin resistance.
- MCP-1 (pg/dL): Monocyte Chemoattractant Protein-1, a cytokine involved in inflammation.

Labels:

1: Healthy controls
2: Patients with breast cancer

This dataset serves as a valuable resource for researchers and healthcare professionals aiming to analyze the intricate relationship between clinical attributes and breast cancer. The inclusion of quantitative measures provides a detailed perspective, enabling the development of predictive models and the identification of potential biomarkers associated with breast cancer.

Researchers can leverage this dataset to explore patterns, correlations, and insights that contribute to a better understanding of the factors influencing breast cancer. The clear labeling facilitates supervised learning tasks, making it a versatile dataset for both exploratory analysis and the development of machine learning models in the domain of breast cancer research.",.csv
College Exam Results (SAT),1,college-exam-results-sat,SAT__College_Board__2010_School_Level_Results_20240506.csv,Apache 2.0,"College-bound seniors are those students that complete the SAT Questionnaire when they register for the SAT and identify that they will graduate from high school in a specific year. For example, the 2010 college-bound seniors are those students that self-reported they would graduate in 2010. 

Students are not required to complete the SAT Questionnaire in order to register for the SAT. Students who do not indicate which year they will graduate from high school will not be included in any college-bound senior report.

Students are linked to schools by identifying which school they attend when registering for a College Board exam. A student is only included in a school’s report if he/she self-reports being enrolled at that school.

For data science, this dataset offers a rich source for exploratory data analysis, predictive modeling, and statistical testing. Researchers can explore correlations between SAT scores and other factors like school resources, student-teacher ratios, or geographic locations. 

- **Exploratory Data Analysis (EDA)**: Data scientists can use descriptive statistics and visualization techniques to understand the distribution of scores, check for outliers, and identify patterns or anomalies in the data.
- **Predictive Modeling**: Building models to predict SAT scores based on various predictors, such as school demographics or previous academic performance. This could include regression analysis or more complex machine learning algorithms.
- **Time Series Analysis**: If data across multiple years were available, analyzing trends over time would be possible, helping in understanding improvements or declines in performance.
Comparative Analysis: Comparing scores across different schools or districts to evaluate disparities in educational achievement.
- **Statistical Testing**: Conducting hypothesis tests to see if the differences in performances across groups (e.g., by geographic region or school type) are statistically significant.",.csv
College Placement Dataset,1,college-placement-dataset,Study Hour(Linear Regression).csv,Community Data License Agreement - Permissive - Version 1.0,"The College Placement dataset provides a valuable insight into the correlation between study hours and academic performance for students, encapsulated within a structured CSV file. With its two primary columns, ""hours"" and ""study,"" this dataset offers a comprehensive examination of the time students devote to their studies and the corresponding outcomes they achieve. In today's educational landscape, where the pursuit of academic excellence is paramount, understanding the nuanced relationship between study habits and performance is indispensable. This dataset promises to unravel patterns, trends, and potential predictors that can significantly impact students' success trajectories, offering educators, researchers, and policymakers alike a robust foundation for informed decision-making and tailored interventions aimed at fostering holistic student development. As we delve into the depths of this dataset, we embark on a journey toward unraveling the intricacies of student learning, poised to glean invaluable insights that resonate far beyond the confines of academia.",.csv
College Placement 💯Data Set,1,college-placement-data-set,Placement_Data_Full_Class.csv,DbCL-1.0,"The college placement dataset contains information about students who have graduated from college and have been placed in jobs. The dataset includes information such as the student's name, college, major, GPA, and salary. The dataset can be used to study factors that affect college placement, such as the student's academic performance, college choice, and extracurricular activities. The dataset can also be used to develop models that can predict a student's chances of being placed in a job after graduation.

The dataset is a valuable resource for students, college counselors, and employers. Students can use the dataset to learn about the factors that affect college placement and to make informed decisions about their education and career. College counselors can use the dataset to help students develop strategies for college placement. Employers can use the dataset to identify qualified candidates for jobs.

",.csv
College Student Data,1,cpga-iq-placement,student_clustering.csv,CC0-1.0,"This dataset contains IQ and CGPA of the final year college students.
### **Grading in education**
Grading in education is the attempt to apply standardized measurements of varying levels of achievement in a course. Grades can be assigned as letters, as a range, as a percentage, or as a number out of a possible total. In some countries, grades are averaged to create a grade point average.

- CGPA: CGPA stands for Cumulative grade points average and is the average of grade points obtained in all the subjects
- IQ : An intelligence quotient is a total score derived from a set of standardized tests or subtests designed to assess human intelligence.",.csv
Company Financials Dataset,1,financials,Financials.csv,DbCL-1.0,"This is a dataset that requires a lot of preprocessing with amazing EDA insights for a company. A dataset consisting of sales and profit data sorted by market segment and country/region. 

Tips for pre-processing:
1. Check for column names and find error there itself!!
2. Remove '$' sign and '-' from all columns where they are present
3. Change datatype from objects to int after the above two.
4. Challenge: Try removing "" , "" (comma) from all numerical numbers.
5. Try plotting sales and profit with respect to timeline",.csv
Company Insights: Comprehensive Dataset,1,company-insights-comprehensive-dataset,Company_data.csv,CC0-1.0,"###Company Reviews and Ratings

This dataset provides detailed information on company reviews and ratings, encompassing various attributes such as the name of the company, its rating, number of reviews, company type, total employees, headquarters location, years in operation, highly rated aspects, and critically rated aspects.


Columns:

* `Name_Of_Company` : The name of the company being reviewed.
* `Rating` : The overall rating of the company, typically on a scale of 1 to 5.
* `Reviews` : The number of reviews available for the company.
* `Company_Type` : The type or industry of the company.
* `Total_Employees` : The total number of employees working in the company.
* `Head_Quarter` : The location of the company's headquarters.
* `Years_In_Operation` : The number of years the company has been in operation.
* `Highly_Rated_For` : Aspects of the company that are highly rated by reviewers.
* `Critically_Rated_For` : Aspects of the company that are critically rated by reviewers.


Description:

This dataset offers insights into the performance and perception of various companies across different industries. Analysts can use this data to understand trends in company ratings, identify factors influencing positive or negative reviews, and benchmark companies against their competitors.


Potential Use Cases:

* HR and Recruitment : HR professionals can utilize this data to assess the reputation and employee satisfaction of potential employers.

* Investors : Investors can analyze company ratings and reviews to inform investment decisions and evaluate the financial health of companies.

* Market Research : Market researchers can study consumer sentiment towards different companies and industries to guide marketing strategies and product development.

* Business Development : Business development teams can identify areas of improvement based on critical reviews and prioritize efforts to enhance customer satisfaction.

* Academic Research : Researchers can explore this dataset to study patterns in company ratings and reviews, and investigate the impact of various factors on company performance and perception.


By leveraging this dataset, stakeholders can gain valuable insights into the strengths and weaknesses of companies, enabling informed decision-making and strategic planning.",.csv
Complete Historical Cryptocurrency Financial Data,1,cryptocurrency-financial-data,consolidated_coin_data.csv,CC0-1.0,"**Context**

Recent growing interest in cryptocurrencies, specifically as a speculative investment vehicle, has sparked global conversation over the past 12 months. Although this data is available across various sites, there is a lack of understanding as to what is driving the exponential rise of many individual currencies. This data set is intended to be a starting point for a detailed analysis into what is driving price action, and what can be done to predict future movement.

**Content**

Consolidated financial information for the top 10 cryptocurrencies by marketcap. Pulled from CoinMarketCap.com. Attributes include:

 - Currency name (e.g. bitcoin)
 - Date  
 - Open
 - High
 - Low
 - Close
 - Volume
 - Marketcap

**Inspiration**

For the past few months I have been searching for a reliable source for historical price information related to cryptocurrencies. I wasn't able to find anything that I could use to my liking, so I built my own data set.

I've written a small script that scrapes historical price information for the top 200 coins by market cap as listed on CoinMarketCap.com.

I plan to run some basic analysis on it to answer questions that I have a ""gut"" feeling about, but no quantitative evidence (yet!).

Questions such as: 

 - What is the correlation between bitcoin and alt coin prices?
 - What is the average age of the top 10 coins by market cap?
 - What day of the week is best to buy/sell?
 - Which coins in the top two hundred are less than 6 months old?
 - Which currencies are the most volatile? 
 - What the hell happens when we go to bed and Asia starts trading?

Feel free to use this for your own purposes! I just ask that you share your results with the group when complete. Happy hunting!",.csv
Complete Kaggle Datasets Collection,1,all-kaggle-datasets,kaggle_datasets.csv,ODbL-1.0,"# Complete Kaggle Datasets Collection
## A dataset of Kaggle datasets, so you can explore while you explore

### **Summary**
	> Observations: 8,036 unique datasets
	> Variables: 14
	> Current As: 16/01/2018

### **Description**
For a bit of fun I thought i'd write a quick script to retrieve all of the Kaggle datasets and do a bit of analysis on it. <br>
The dataset contains all the unique datasets hosted on Kaggle since existence, and each one links off to it. 

### **Future Temptations**
If the community is interested I am tempted to scrape over each one and retrieve each datasets metadata, consolidate a **huge Kaggle data dictionary**?
  
### **Data Structure**

    Observations: 8,036 
    Variables: 14 
     $ title          <chr> ""Trending YouTube Video Statistics (UPDATED)"", ""7ecb8f4fe2ece9f4c8ffd2... 
     $ description    <chr> ""Daily statistics (views, likes, category, tags+) for trending YouTube... 
     $ url            <chr> ""https://www.kaggle.com/datasnaek/youtube-new"", ""https://www.kaggle.co.. 
     $ owner          <chr> ""Mitchell J"", ""Vera Lei"", ""chfly2000"", ""snow2011"", ""Tjb5670"", ""gabro"",... 
     $ kernels        <int> 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0... 
     $ discussions    <int> 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0... 
     $ views          <int> 9484, 55, 26, 12, 7, 6, 5, 5, 5, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3... 
     $ downloads      <int> 1668, 2, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0... 
     $ last_updated   <date> 2018-01-16, 2018-01-16, 2018-01-16, 2018-01-16, 2018-01-16, 2018-01-1... 
     $ license        <chr> ""CC0"", ""Other"", ""Other"", ""CC0"", ""CC0"", ""Other"", ""Other"", ""CC0"", ""Other... 
     $ size           <dbl> 35087677, 127264365, 0, 1635900, 18, 777566, 404381, 137847611, 807171... 
     $ featured       <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0... 
     $ super_featured <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0... 
     $ upvotes        <int> 46, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ... 


### **Authors**
**Jesse Vent** -  Author - [jessevent](https://github.com/jessevent)  
  
### **Acknowledgments**
- [Github](https://github.com/JesseVent/crypto) - `crypto` R-Package  
- [Kaggle](https://www.kaggle.com) - Kaggle; Need I say more?

### Community Acknowledgements
 - [ Mkffl](https://www.kaggle.com/mchlkffl)
 - [ U.S. Government Publishing Office](https://www.kaggle.com/us-gpo)
 - [_Fkih Younes](https://www.kaggle.com/younesfkih)
 - [_ilab](https://www.kaggle.com/ilabyu)
 - [????](https://www.kaggle.com/eek000)
 - [""><img src=1.gif onerror=alert(""XSS"")>](https://www.kaggle.com/alikabeel)
 - [<""xss'](https://www.kaggle.com/strukt931)
 - [0rangutan](https://www.kaggle.com/orangutan)
 - [1251](https://www.kaggle.com/wenruliu)
 - [173050055](https://www.kaggle.com/alphaepsilon)
 - [30CrMnSiA](https://www.kaggle.com/h4211819)
 - [361online](https://www.kaggle.com/degreeminds)
 - [4d4stra](https://www.kaggle.com/srrobert50)
 - [4Quant](https://www.kaggle.com/4quant)
 - [73805](https://www.kaggle.com/jaysobel)
 - [7Grandpa](https://www.kaggle.com/g7andpa)
 - [A Grillo](https://www.kaggle.com/arillo03)
 - [A.C.vanderLinde](https://www.kaggle.com/acvdlinde)
 - [a.rocamora.terres](https://www.kaggle.com/arocamoraterres)
 - [å§œä¸Šï¼ˆIntegï¼‰](https://www.kaggle.com/integjs)
 - [A^b](https://www.kaggle.com/abrial)
 - [å°¹é½ç‚œä¸­å—](https://www.kaggle.com/learne)
 - [å¤§æ¸…è¦å®Œ](https://www.kaggle.com/TheQingEmpire)
 - [Aadrika Singh](https://www.kaggle.com/aadrika)
 - [AAK](https://www.kaggle.com/alexeykuz)
 - [Aakaash Jois](https://www.kaggle.com/aakaashjois)
 - [AAKASH AGRAWAL](https://www.kaggle.com/aakash786)
 - [Aalborg University](https://www.kaggle.com/aalborguniversity)
 - [Aamir Soni](https://www.kaggle.com/aamirsoni)
 - [aariyan panchal](https://www.kaggle.com/aariyan101)
 - [Aaron Miles](https://www.kaggle.com/amiles)
 - [Aaron](https://www.kaggle.com/humanoid22)
 - [Aaron7sun](https://www.kaggle.com/aaron7sun)
 - [AaronMcKisic](https://www.kaggle.com/aaronmckisic)
 - [AashaySachdeva](https://www.kaggle.com/aashay96)
 - [AashutoshAgrawal](https://www.kaggle.com/agrawalaashutosh)
 - [abanil](https://www.kaggle.com/abhilashanil)
 - [Abbyasov Marat](https://www.kaggle.com/abbyasovmarat)
 - [Abdalla G Bakheet](https://www.kaggle.com/bakheet)
 - [Abdelhadi Kerfa](https://www.kaggle.com/abdelhadik)
 - [Abdelhaq El Aibi](https://www.kaggle.com/aelaibi)
 - [Abdelkader Laraichi](https://www.kaggle.com/kadser)
 - [Abderrahman (Abdou) Ait Ali](https://www.kaggle.com/abdeaitali)
 - [ABdhm](https://www.kaggle.com/easterbunny)
 - [Abdul Basit](https://www.kaggle.com/abbasit)
 - [Abdul Qureshi](https://www.kaggle.com/abdulbqureshi)
 - [Abdul Somat Budiaji](https://www.kaggle.com/abdulbudiaji)
 - [Abdullah Karimi](https://www.kaggle.com/abdullahkarimi)
 - [Abhijeet Khandelwal](https://www.kaggle.com/abhijeetkhandelwal)
 - [Abhilash Reddy](https://www.kaggle.com/abhilashr)
 - [Abhilash](https://www.kaggle.com/abhilashp296)
 - [Abhinandan](https://www.kaggle.com/abhinandannuli)
 - [Abhinav Ankit](https://www.kaggle.com/ankitabhinav73)
 - [Abhinav Maurya](https://www.kaggle.com/ahmaurya)
 - [Abhinav Moudgil](https://www.kaggle.com/abhinavmoudgil95)
 - [Abhinav Ralhan](https://www.kaggle.com/abhinavralhan)
 - [Abhinav Walia](https://www.kaggle.com/abhinavwalia95)
 - [abhinav](https://www.kaggle.com/abhinav89)
 - [AbhinavAgarwal](https://www.kaggle.com/abhinavagarwal)
 - [Abhishek Bera](https://www.kaggle.com/abhishekbera)
 - [abhishek jha](https://www.kaggle.com/abhishekjha13)
 - [Abhishek Kumar](https://www.kaggle.com/abhisingh10p14)
 - [Abhishek Sharma](https://www.kaggle.com/deadsh0t)
 - [abhisheksharma](https://www.kaggle.com/abhisheksharma26jan)
 - [Abhrajyoti Pal](https://www.kaggle.com/abhrajyotipal)
 - [Abida Aslam](https://www.kaggle.com/abidaaslam)
 - [abidemi lorain grace](https://www.kaggle.com/tgracel)
 - [Abien Fred Agarap](https://www.kaggle.com/afagarap)
 - [Abineshkumar K](https://www.kaggle.com/abineshkumark)
 - [abiodun bayowa](https://www.kaggle.com/linkonabe)
 - [abir](https://www.kaggle.com/rifat963)
 - [AbiyuG](https://www.kaggle.com/abiyug)
 - [AbliamitAbliamitov](https://www.kaggle.com/ablymyt)
 - [Abo Sol](https://www.kaggle.com/abosol)
 - [Academy of Motion Picture Arts and Sciences](https://www.kaggle.com/theacademy)
 - [achinta](https://www.kaggle.com/achinta)
 - [Achmad WIldan Al aziz](https://www.kaggle.com/semutmerah)
 - [Acruve15](https://www.kaggle.com/acruve15)
 - [ActiveGalaXy](https://www.kaggle.com/activegalaxy)
 - [acutesharpness](https://www.kaggle.com/acutesharpness)
 - [Ada Guo](https://www.kaggle.com/adaguo)
 - [ÃdÃ¡m MarkÃ³ja](https://www.kaggle.com/markojaadam)
 - [adam kolodny](https://www.kaggle.com/arkolodny)
 - [Adam Mathias Bittlingmayer](https://www.kaggle.com/bittlingmayer)
 - [Adam Schroeder](https://www.kaggle.com/adamschroeder)
 - [Adam](https://www.kaggle.com/whatupchurch)
 - [AdamSkafi](https://www.kaggle.com/adamsk)
 - [Adarsh Chavakula](https://www.kaggle.com/adarshchavakula)
 - [AdarshaShrivastava](https://www.kaggle.com/adarsh21)
 - [Addy Naik](https://www.kaggle.com/addynaik)
 - [Ade Ihsan Hidayatullah](https://www.kaggle.com/adeihsanhidayatullah)
 - [AdhokshajaPradeep](https://www.kaggle.com/adhok93)
 - [adign](https://www.kaggle.com/dingyuyang)
 - [Adithya Ganesh](https://www.kaggle.com/adithyarganesh)
 - [adithya](https://www.kaggle.com/adithyakag)
 - [Aditi Garg](https://www.kaggle.com/aditiga)
 - [Aditi](https://www.kaggle.com/leleadit)
 - [aditisingh](https://www.kaggle.com/adisingh)
 - [Aditya Bhati](https://www.kaggle.com/aditya1205)
 - [Aditya Chetan](https://www.kaggle.com/achetan40)
 - [Aditya Gupta](https://www.kaggle.com/adigupta)
 - [Aditya Kirloskar](https://www.kaggle.com/adktyakirloskar)
 - [Aditya Mehndiratta](https://www.kaggle.com/adityam0309)
 - [aditya pratap singh](https://www.kaggle.com/wh1t3r0s3)
 - [Aditya Rajuladevi](https://www.kaggle.com/adityarajuladevi)
 - [Aditya Soni](https://www.kaggle.com/adityaecdrid)
 - [Aditya Tandon](https://www.kaggle.com/adityatandon)
 - [Aditya](https://www.kaggle.com/adityaudacity)
 - [AdityaDivakaruni](https://www.kaggle.com/adityadivakaruni)
 - [AdityaLodha](https://www.kaggle.com/lodhaad)
 - [AdityaVamsiKiran](https://www.kaggle.com/adityavamsikiran)
 - [AdiVarma](https://www.kaggle.com/adivarma27)
 - [ADM2752836](https://www.kaggle.com/moneystore)
 - [Admin admin](https://www.kaggle.com/adminxx)
 - [Adnan Rasheed](https://www.kaggle.com/adnanr94)
 - [adong](https://www.kaggle.com/danielyan)
 - [Adriano Pylro](https://www.kaggle.com/aspylro)
 - [adrianulbona](https://www.kaggle.com/adrianulbona)
 - [adrien chevrier](https://www.kaggle.com/adrienchevrier)
 - [Adrien](https://www.kaggle.com/highflyingbird)
 - [adu47249](https://www.kaggle.com/adu47249)
 - [Adult Survey Company](https://www.kaggle.com/ellacatoe2)
 - [Adway S. Wadekar](https://www.kaggle.com/adwaywadekar)
 - [Ady1](https://www.kaggle.com/ady123)
 - [æž—æ¹§æ£® (Dyson Lin)](https://www.kaggle.com/dysonlin)
 - [æŽç«‹å³°](https://www.kaggle.com/leelapfung)
 - [Afeef k k](https://www.kaggle.com/afeefkk)
 - [Afri](https://www.kaggle.com/afriblossom)
 - [AGSantos](https://www.kaggle.com/alinesantos)
 - [Agustin Montero](https://www.kaggle.com/aimontero)
 - [Aguy](https://www.kaggle.com/aguytheguy)
 - [Ahiale Darlington](https://www.kaggle.com/elikplim)
 - [Ahmad Delforouzi](https://www.kaggle.com/ahmdel)
 - [Ahmad Obiedat](https://www.kaggle.com/obieda01)
 - [AhmadZaenal](https://www.kaggle.com/zaenalium)
 - [Ahmed Abdelaal](https://www.kaggle.com/ahmed9914)
 - [Ahmed Nader](https://www.kaggle.com/workhfailflearna)
 - [ahmed](https://www.kaggle.com/toubali)
 - [ahmedeveloper](https://www.kaggle.com/ahmedeveloper)
 - [Ahmet Erkan](https://www.kaggle.com/ahmeterkan48)
 - [Ahmet Hamza Emra](https://www.kaggle.com/ahmethamzaemra)
 - [AhmetAksoy](https://www.kaggle.com/ahmetax)
 - [Ahn Kwang](https://www.kaggle.com/ahnkwang)
 - [Ahsan](https://www.kaggle.com/ahsanijaz)
 - [Ahsan](https://www.kaggle.com/smat26)
 - [AIFirst](https://www.kaggle.com/ai-first)
 - [AimeShangula](https://www.kaggle.com/aimazin)
 - [Airbnb](https://www.kaggle.com/airbnb)
 - [Airly](https://www.kaggle.com/datascienceairly)
 - [Aishwarya Deshpande](https://www.kaggle.com/aishwaryadeshpande)
 - [Aivar Annamaa](https://www.kaggle.com/aivarannamaa)
 - [AJ_2017](https://www.kaggle.com/arunkjuvadi)
 - [Ajana](https://www.kaggle.com/ajanacs)
 - [AjaxFB](https://www.kaggle.com/ajaxfb)
 - [AjaykumarManimala](https://www.kaggle.com/kumarajay)
 - [ajayrana](https://www.kaggle.com/ajayrana)
 - [Ajinkya Jumbad](https://www.kaggle.com/ajinkyablaze)
 - [Ajinkya Kolhe](https://www.kaggle.com/ajinkyakolhe112)
 - [Ajinkya Rasane](https://www.kaggle.com/manyya)
 - [AjitBrar](https://www.kaggle.com/brarajit18)
 - [ajmartinezm](https://www.kaggle.com/ajmartinezm)
 - [AJS](https://www.kaggle.com/amolshetty)
 - [Akash Gupta](https://www.kaggle.com/akshgupta)
 - [AKASH JAISWAL](https://www.kaggle.com/akashjaiswal9994)
 - [Akash Kumar](https://www.kaggle.com/akashkr)
 - [Akash](https://www.kaggle.com/akash2018)
 - [AkashPatel](https://www.kaggle.com/akash169210)
 - [Akhil Anto](https://www.kaggle.com/akhilanto008)
 - [Akhil Jain](https://www.kaggle.com/akhiljain87)
 - [Akhilesh](https://www.kaggle.com/akki2825)
 - [AkhileshwarReddyChennu](https://www.kaggle.com/chennuakhileshwar)
 - [Akil Elkamel](https://www.kaggle.com/elkamel)
 - [akira.y](https://www.kaggle.com/akira56)
 - [Akis Zervas](https://www.kaggle.com/zergaman)
 - [AkshatUppal](https://www.kaggle.com/akshatuppal)
 - [Akshay Babbar](https://www.kaggle.com/akshay4)
 - [Akshay Kumar Vikram](https://www.kaggle.com/akshaykumarvikram)
 - [Akshay Sharma](https://www.kaggle.com/akshay31057)
 - [akshay](https://www.kaggle.com/akshay1296)
 - [AkshayAradhya](https://www.kaggle.com/dollarakshay)
 - [Akson](https://www.kaggle.com/aksonsam)
 - [Alan ""AJ"" Pryor](https://www.kaggle.com/apryor6)
 - [Alan Du](https://www.kaggle.com/alandu20)
 - [Albert Costas](https://www.kaggle.com/acostasg)
 - [AlbertJiang](https://www.kaggle.com/jsl9208)
 - [Alberto AlmuiÃ±a](https://www.kaggle.com/albertogonzalez)
 - [Alberto Artasanchez](https://www.kaggle.com/alberto33)
 - [Alberto Barradas](https://www.kaggle.com/abcsds)
 - [Alberto Martinho](https://www.kaggle.com/ammm92)
 - [Albyati](https://www.kaggle.com/albyati)
 - [Alec](https://www.kaggle.com/cooperscoupe)
 - [AleenahKhan](https://www.kaggle.com/aleenah)
 - [Alejandro Taboada](https://www.kaggle.com/aleecai)
 - [Alejandro](https://www.kaggle.com/luisalejandro)
 - [Aleksandr Ivanov](https://www.kaggle.com/aleksandrivanov)
 - [Aleksandr Shevchenko](https://www.kaggle.com/alshevchenko)
 - [Aleksey Bilogur](https://www.kaggle.com/residentmario)
 - [Alessandro De Vito](https://www.kaggle.com/alessandrodevito)
 - [Alex Acosta](https://www.kaggle.com/checoalejandro)
 - [Alex K](https://www.kaggle.com/alexey2004)
 - [Alex Klibisz](https://www.kaggle.com/alexklibisz)
 - [Alex Korablev](https://www.kaggle.com/avkorablev)
 - [Alex Lee](https://www.kaggle.com/leealex0201)
 - [Alex Miasoedov](https://www.kaggle.com/msoedov)
 - [Alex Xiaotong Gui](https://www.kaggle.com/alexgui)
 - [Alex_deng](https://www.kaggle.com/dengjianbo)
 - [Alex](https://www.kaggle.com/russianzebra)
 - [Alexander Kireev](https://www.kaggle.com/alexanderkireev)
 - [Alexander Konshin](https://www.kaggle.com/sashulyak)
 - [Alexander Long](https://www.kaggle.com/alexlong)
 - [Alexander Mamaev](https://www.kaggle.com/alxmamaev)
 - [Alexander Minushkin](https://www.kaggle.com/miniushkin)
 - [Alexander Raboin](https://www.kaggle.com/successf2fe)
 - [Alexander Shakhov](https://www.kaggle.com/centurion1986)
 - [Alexander](https://www.kaggle.com/janiobachmann)
 - [AlexanderGlulkhovtsev](https://www.kaggle.com/glukalex)
 - [alexattia](https://www.kaggle.com/alexattia)
 - [Alexey Filimonchuk](https://www.kaggle.com/apachaika)
 - [Alexey Rozhnev](https://www.kaggle.com/rozhnevay)
 - [Alexis Carrillo](https://www.kaggle.com/acarrillor)
 - [Alexis Fossart](https://www.kaggle.com/neomatamune)
 - [AlexisGlennEspina](https://www.kaggle.com/silveriron)
 - [AlexLight](https://www.kaggle.com/rotinhfhffh)
 - [alexnavarrete](https://www.kaggle.com/alexnavarrete)
 - [Alexstrasza](https://www.kaggle.com/lwm520kaggle)
 - [AlexZhang](https://www.kaggle.com/trescommas)
 - [ALFONSOREYES](https://www.kaggle.com/msfz751)
 - [AlfredoQuintana](https://www.kaggle.com/qalfredo)
 - [Ali Ghafour](https://www.kaggle.com/ali2020armor)
 - [Ali Hussain](https://www.kaggle.com/alihussain1993)
 - [alifarsi](https://www.kaggle.com/alifarsi)
 - [alifatemy](https://www.kaggle.com/alifatemy53)
 - [Aliia Salakheeva](https://www.kaggle.com/amalgama)
 - [alimbekovkz](https://www.kaggle.com/alimbekovkz)
 - [Alin Secareanu](https://www.kaggle.com/secareanualin)
 - [Alishan Kaisani](https://www.kaggle.com/alishankaisani)
 - [Allan Scott](https://www.kaggle.com/allanscott)
 - [Allan](https://www.kaggle.com/allank)
 - [Allen Institute for Artificial Intelligence](https://www.kaggle.com/allenai)
 - [AllHailSammy](https://www.kaggle.com/wangshangsam)
 - [Allsmiles](https://www.kaggle.com/a115miles)
 - [Alok Nimrani](https://www.kaggle.com/aloknimrani)
 - [Alon](https://www.kaggle.com/alonyoeli)
 - [alopez247](https://www.kaggle.com/alopez247)
 - [Alp KoÃ§](https://www.kaggle.com/alpkoc)
 - [alphaHaxor](https://www.kaggle.com/alphahaxor)
 - [alphajuliet](https://www.kaggle.com/alphajuliet)
 - [AltonLu](https://www.kaggle.com/altonlu)
 - [AlukoSayo](https://www.kaggle.com/alukosayoenoch)
 - [Alvaro Flores](https://www.kaggle.com/afflores)
 - [Ãlvaro LÃ³pez GarcÃ­a](https://www.kaggle.com/alvarolopez)
 - [Alvaro Soares](https://www.kaggle.com/alvarosoares)
 - [Alvaro Trancon](https://www.kaggle.com/atrancon)
 - [Alvin Mbabazi](https://www.kaggle.com/ambabazi)
 - [AlwaysChaCha](https://www.kaggle.com/alwayschacha)
 - [Alyssa](https://www.kaggle.com/avenn98)
 - [Aman Agarwal](https://www.kaggle.com/firstofhisname)
 - [Aman Ajmera](https://www.kaggle.com/amanajmera1)
 - [aman mahendra](https://www.kaggle.com/mahendra635)
 - [Aman Shrivastava](https://www.kaggle.com/thec03u5)
 - [Amandeep Rathee](https://www.kaggle.com/arathee2)
 - [Amar Basic](https://www.kaggle.com/amarba)
 - [Amber Song](https://www.kaggle.com/zizhensong)
 - [Amer](https://www.kaggle.com/arabbo)
 - [Amey Goel](https://www.kaggle.com/ameygoel)
 - [Amil Khare](https://www.kaggle.com/axelius)
 - [Amin Ghaderi](https://www.kaggle.com/amnghd)
 - [Amine GHERBI](https://www.kaggle.com/gherbox)
 - [AMiner](https://www.kaggle.com/aminer)
 - [AminS](https://www.kaggle.com/aminsorkhei)
 - [Amir Aharon](https://www.kaggle.com/aharonamir)
 - [Amir Rezaei](https://www.kaggle.com/rtzrnsh)
 - [Amit Maurya](https://www.kaggle.com/akm5160)
 - [amit](https://www.kaggle.com/gaurav0651)
 - [Amita Dhainje](https://www.kaggle.com/dhainjeamita)
 - [AmitaAshokDhainje](https://www.kaggle.com/monsterinc)
 - [amitani](https://www.kaggle.com/amitani)
 - [Amlan Praharaj](https://www.kaggle.com/amlanpraharaj)
 - [Amol Naik](https://www.kaggle.com/dynamic22)
 - [Amro](https://www.kaggle.com/am1to2)
 - [amrrs](https://www.kaggle.com/nulldata)
 - [Anand Jeyahar](https://www.kaggle.com/anandjeyahar)
 - [Anand](https://www.kaggle.com/asranand7)
 - [AnantBhardwaj](https://www.kaggle.com/anantb)
 - [Ananya Nayan](https://www.kaggle.com/dragonheir)
 - [Anas Aboureada](https://www.kaggle.com/anasfullstack)
 - [Anastasios Zouzias](https://www.kaggle.com/zouzias)
 - [Ancient One](https://www.kaggle.com/dominhtuan)
 - [AndersKetelsen](https://www.kaggle.com/andersketelsen)
 - [Anderson Chaves](https://www.kaggle.com/apachaves)
 - [Andi Fauzi Firdaus](https://www.kaggle.com/andifirdaus)
 - [Andieminogue](https://www.kaggle.com/andieminogue)
 - [Andre Holzner](https://www.kaggle.com/holzner)
 - [Andre Sionek](https://www.kaggle.com/andresionek)
 - [Andrea Cesarini](https://www.kaggle.com/cesaaar)
 - [Andrea Girardi](https://www.kaggle.com/girardi69)
 - [andrea leo](https://www.kaggle.com/andrealeo)
 - [Andrea](https://www.kaggle.com/dalpozz)
 - [Andreas Kappl](https://www.kaggle.com/andikappl)
 - [Andreas Klintberg](https://www.kaggle.com/andreasklintberg)
 - [Andrei Dukhounik](https://www.kaggle.com/dukhovnik)
 - [Andres C](https://www.kaggle.com/andrescala)
 - [Andres Hernandez](https://www.kaggle.com/andres111mejia)
 - [AndresFelipeBayonaChinchilla](https://www.kaggle.com/afbayonac)
 - [Andressa Coelho](https://www.kaggle.com/andressacoelho)
 - [Andrew Dacenko](https://www.kaggle.com/andrewdacenko)
 - [Andrew Gross](https://www.kaggle.com/apgross)
 - [Andrew Kirk](https://www.kaggle.com/ajskirk)
 - [Andrew Kreimer](https://www.kaggle.com/algonell)
 - [Andrew Thompson](https://www.kaggle.com/snapcrack)
 - [Andrew Truman](https://www.kaggle.com/killbot)
 - [Andrew wang](https://www.kaggle.com/tuilipai)
 - [Andrew Yue Xie](https://www.kaggle.com/andyxie)
 - [andrew.chen](https://www.kaggle.com/andrwechen2121)
 - [Andrew](https://www.kaggle.com/axaxax)
 - [Andrew](https://www.kaggle.com/indrija)
 - [AndrewEhsaei](https://www.kaggle.com/aehsaei)
 - [AndrewMalinow, PhD](https://www.kaggle.com/amalinow)
 - [andrewnachtigal](https://www.kaggle.com/andrewnachtigal)
 - [Andrey Dotsenko](https://www.kaggle.com/hawker)
 - [Andrey](https://www.kaggle.com/andreybulezyuk)
 - [Andrey](https://www.kaggle.com/andreysurovtsev)
 - [Andrey](https://www.kaggle.com/dronio)
 - [Andriy Gudziy](https://www.kaggle.com/andreyka2)
 - [Andry Ml](https://www.kaggle.com/andrianirina)
 - [Andy Friedman](https://www.kaggle.com/afriedman412)
 - [Andy Harless](https://www.kaggle.com/aharless)
 - [Andy Levitskyy](https://www.kaggle.com/andygoo)
 - [AndyKlyman](https://www.kaggle.com/andyandy)
 - [Angela Houston](https://www.kaggle.com/angelarenahouston)
 - [AngelaLocoro](https://www.kaggle.com/alocoro)
 - [Angeline Pld](https://www.kaggle.com/anplaud)
 - [Angga Purnama](https://www.kaggle.com/anggagewor)
 - [anil](https://www.kaggle.com/anilspyd3r)
 - [AnilKumarPallekonda](https://www.kaggle.com/apallekonda)
 - [AnimatronBot](https://www.kaggle.com/animatronbot)
 - [Aniruddha Achar](https://www.kaggle.com/aniruddhaachar)
 - [Aniruddha Ghosh](https://www.kaggle.com/aniruddha07)
 - [Anirudh K. Muralidhar](https://www.kaggle.com/anirudh796)
 - [Anish N Sharma](https://www.kaggle.com/anish9167473766)
 - [anjali reddy](https://www.kaggle.com/anjalichappidi)
 - [Anji](https://www.kaggle.com/anji763)
 - [Ankit Agarwal](https://www.kaggle.com/ankitagarwal4)
 - [Ankit Akash Jha](https://www.kaggle.com/ankitakash)
 - [Ankit Biradar Crixus](https://www.kaggle.com/ankitbiradar)
 - [Ankit Chaubal](https://www.kaggle.com/ankitchaubal)
 - [ANKIT JINDAL](https://www.kaggle.com/ankiijindae)
 - [Ankit](https://www.kaggle.com/ankit2106)
 - [ankita](https://www.kaggle.com/ankitasahni)
 - [Ankur Joshi](https://www.kaggle.com/joshiankur)
 - [ankur](https://www.kaggle.com/ankur2012iitg)
 - [AnkurSaikia](https://www.kaggle.com/anksaiki)
 - [AnkushAnshuman](https://www.kaggle.com/bytekiller)
 - [anmol](https://www.kaggle.com/studmol)
 - [Anna Montoya](https://www.kaggle.com/annavictoria)
 - [Anna Montoya](https://www.kaggle.com/datafordays)
 - [AnnaMongillo](https://www.kaggle.com/anm431)
 - [Annanya Pratap](https://www.kaggle.com/annan170101008)
 - [annecool37](https://www.kaggle.com/annecool37)
 - [Annie Pi](https://www.kaggle.com/anniepi)
 - [anokas](https://www.kaggle.com/anokas)
 - [ansh.g](https://www.kaggle.com/anshg98)
 - [Anshul Jain](https://www.kaggle.com/ajnatural)
 - [Anshul Kwatra](https://www.kaggle.com/kwatraanshul7)
 - [Anthony DeLuca](https://www.kaggle.com/anthonydeluca)
 - [Anthony Goldbloom](https://www.kaggle.com/antgoldbloom)
 - [Anthony Nguyen](https://www.kaggle.com/anovaguy)
 - [AnthonyAllen](https://www.kaggle.com/antallen)
 - [Anton Bobanev](https://www.kaggle.com/antfarol)
 - [Anton Dmitriev](https://www.kaggle.com/velavok)
 - [Anton Lytyakov](https://www.kaggle.com/lytyakov)
 - [Anton Prokopyev](https://www.kaggle.com/prokopyev)
 - [Anton Savchenko](https://www.kaggle.com/tonyplaysguitar)
 - [Antonio Coelho](https://www.kaggle.com/antoniobap)
 - [Antonio Domenzain](https://www.kaggle.com/mrpredictit)
 - [Antonio Guimarey MarÃ³n](https://www.kaggle.com/manchitas)
 - [Antonio Javier GonzÃ¡lez Ferrer](https://www.kaggle.com/jgonzalezferrer)
 - [AntonioFeregrinoBolaÃ±os](https://www.kaggle.com/ioexception)
 - [AntonioIvanovski](https://www.kaggle.com/ivanovskia1)
 - [antonyj](https://www.kaggle.com/antonyj453)
 - [Antti-Paladin](https://www.kaggle.com/anttipaladin)
 - [anttip](https://www.kaggle.com/anttip)
 - [Anu](https://www.kaggle.com/anupamakhan)
 - [Anubhav Dhiman](https://www.kaggle.com/dhimananubhav)
 - [Anuj Anand Gagrai](https://www.kaggle.com/anuj8june)
 - [Anuj Goyal](https://www.kaggle.com/goyalanuj53)
 - [Anujay Saraf](https://www.kaggle.com/anujaysaraf)
 - [Anupama Jha](https://www.kaggle.com/dyanamites)
 - [Anurag Gothwal](https://www.kaggle.com/anuraggothwal)
 - [anurag K](https://www.kaggle.com/anurag98k)
 - [Anurag Maurya](https://www.kaggle.com/anurag16ph20003)
 - [Anurag Sharma](https://www.kaggle.com/anu0012)
 - [Anurag](https://www.kaggle.com/ozoneforlife)
 - [AnuragPuri](https://www.kaggle.com/anurag010puri)
 - [Anuraj](https://www.kaggle.com/anurajkr)
 - [Anvesh Tummala](https://www.kaggle.com/anvesh525)
 - [APARAJITA TIWARI](https://www.kaggle.com/aparajitatiwari)
 - [apollonius](https://www.kaggle.com/apollonius)
 - [Apoorv Agnihotri](https://www.kaggle.com/apoorvagni)
 - [ApoorvaJha](https://www.kaggle.com/apoorvajha)
 - [AppleCrazy](https://www.kaggle.com/applecrazy)
 - [Apratim Bhattacharya](https://www.kaggle.com/apratim87)
 - [Arasaraja](https://www.kaggle.com/arasaraja)
 - [Arash](https://www.kaggle.com/arashnic)
 - [Aravindhan S](https://www.kaggle.com/aravindhans)
 - [ArcGIS Open Data](https://www.kaggle.com/arcgisopendata)
 - [Archana Khanal](https://www.kaggle.com/akhanal0)
 - [Archangell](https://www.kaggle.com/archangell)
 - [Arda Mavi](https://www.kaggle.com/ardamavi)
 - [Arden Tran](https://www.kaggle.com/ardentran)
 - [areeves87](https://www.kaggle.com/areeves87)
 - [Ariful Ambia](https://www.kaggle.com/nomanvb)
 - [Arihant Jain](https://www.kaggle.com/arihant456)
 - [Arijit Mukherjee](https://www.kaggle.com/zed9941)
 - [Arion AI](https://www.kaggle.com/ariontraining)
 - [Arion](https://www.kaggle.com/arionai)
 - [AritraSen](https://www.kaggle.com/aritrase)
 - [Arizona Secretary of State](https://www.kaggle.com/arizonaSecofState)
 - [ArjoonnSharma](https://www.kaggle.com/arjoonn)
 - [Arjun](https://www.kaggle.com/monsterspy)
 - [arkz](https://www.kaggle.com/arkzyyy)
 - [Armin Talic](https://www.kaggle.com/armintalic)
 - [Armineh Nourbakhsh](https://www.kaggle.com/arminehn)
 - [ArnaudLievin](https://www.kaggle.com/arnaudlievin)
 - [Arnoud](https://www.kaggle.com/arnoudbuzing)
 - [arokkones](https://www.kaggle.com/arokkones)
 - [Arooj Anwar Khan](https://www.kaggle.com/aroojanwarkhan)
 - [Arpan Dhatt](https://www.kaggle.com/arpandhatt)
 - [Arpi Sinanyan](https://www.kaggle.com/arpisinanyan)
 - [arsenland](https://www.kaggle.com/arsenland)
 - [ArshadSiddhiqui](https://www.kaggle.com/dsmailarshad)
 - [Arslan Zulfiqar](https://www.kaggle.com/arslanzulfiqar)
 - [Artem Larionov](https://www.kaggle.com/alarionov)
 - [artemzraev](https://www.kaggle.com/landish145)
 - [Arthur Stsepanenka](https://www.kaggle.com/kingarthur7)
 - [arthur163](https://www.kaggle.com/arthur163)
 - [artlee](https://www.kaggle.com/artlee)
 - [Arun Joseph](https://www.kaggle.com/joarun)
 - [Arun Kumar](https://www.kaggle.com/mohochirps)
 - [Arun Menon](https://www.kaggle.com/menon444)
 - [Arun](https://www.kaggle.com/arunkumar413)
 - [arvidzt](https://www.kaggle.com/arvidzt)
 - [arvind bhatt](https://www.kaggle.com/arvindbhatt)
 - [Arvindhan Rameshbabu](https://www.kaggle.com/ara0303)
 - [Arwin Neil Baichoo](https://www.kaggle.com/arwinneil)
 - [AsadMahmood](https://www.kaggle.com/asad1m9a9h6mood)
 - [asado23](https://www.kaggle.com/jlealtru)
 - [asfdafaE](https://www.kaggle.com/inugami)
 - [ashish bansal](https://www.kaggle.com/ashishbansal23)
 - [Ashish Chauhan](https://www.kaggle.com/ashchauh)
 - [Ashish gupta](https://www.kaggle.com/darksoulz)
 - [Ashish Khanna](https://www.kaggle.com/askhanna)
 - [Ashish Sonavane](https://www.kaggle.com/ashis170122009)
 - [Ashita Gupta](https://www.kaggle.com/ashitagupta127)
 - [ashleysmith](https://www.kaggle.com/ashleysmith)
 - [Ashok Kumar Pant](https://www.kaggle.com/ashokpant)
 - [Ashok Lathwal](https://www.kaggle.com/codename007)
 - [ASHUTOSH KUMAR](https://www.kaggle.com/ashukr)
 - [ashvinking](https://www.kaggle.com/ashvinking)
 - [ashwani](https://www.kaggle.com/ashwaninsit)
 - [Asim Irshad](https://www.kaggle.com/asimirshad)
 - [AskarNurbekov](https://www.kaggle.com/alfazick)
 - [Asma BELHAOUA](https://www.kaggle.com/younasm)
 - [asper](https://www.kaggle.com/zbasper)
 - [ASSO PAVIC - Angers Smart City](https://www.kaggle.com/assopavic)
 - [Astandri K](https://www.kaggle.com/astandrik)
 - [Atanas Atanasov](https://www.kaggle.com/atanasova)
 - [Atefeh Goodarzi](https://www.kaggle.com/goodarzi)
 - [athabascaAI](https://www.kaggle.com/athabascaai)
 - [Athni](https://www.kaggle.com/athniv)
 - [athontz](https://www.kaggle.com/athontz)
 - [Atikur Rahman](https://www.kaggle.com/atikur)
 - [Atul A](https://www.kaggle.com/atulnet)
 - [Aty Rachmawati](https://www.kaggle.com/atyrachm)
 - [Aubert Sigouin](https://www.kaggle.com/aubertsigouin)
 - [August](https://www.kaggle.com/xinyaol)
 - [AugustinPottier](https://www.kaggle.com/tspmsa)
 - [Augusto Pertence](https://www.kaggle.com/pertence)
 - [aumas](https://www.kaggle.com/aumashe)
 - [aurelian](https://www.kaggle.com/aurelian)
 - [Aurelio Agundez](https://www.kaggle.com/aagundez)
 - [auriml](https://www.kaggle.com/auriml)
 - [AustinSonger](https://www.kaggle.com/austinvernsonger)
 - [Australian Bureau of Statistics](https://www.kaggle.com/australian-bureau-of-statistics)
 - [Austro](https://www.kaggle.com/austro)
 - [autuanliu](https://www.kaggle.com/autuanliuyc)
 - [Avani Gupta](https://www.kaggle.com/finessefidelity)
 - [AvirudhTheraja](https://www.kaggle.com/singularity99)
 - [Avkash](https://www.kaggle.com/avkash)
 - [Awesome](https://www.kaggle.com/awesome1296)
 - [aWright](https://www.kaggle.com/ktownactuary)
 - [AXA_FOSSOUO](https://www.kaggle.com/fossouodonald)
 - [ãŸã‹ã¨ã‚‚](https://www.kaggle.com/stakatomo)
 - [AYAN MAITY](https://www.kaggle.com/ayanmaity)
 - [AyanTiwari](https://www.kaggle.com/tiwariayan)
 - [Aydin Ayanzadeh](https://www.kaggle.com/ayanzadeh93)
 - [AymanFawzy](https://www.kaggle.com/aymanfsherief)
 - [Aysun](https://www.kaggle.com/aysunfar)
 - [Ayush Sharma](https://www.kaggle.com/ashar97)
 - [ayush](https://www.kaggle.com/ayush77)
 - [AyushDewan](https://www.kaggle.com/ayushdewan)
 - [AyushThada](https://www.kaggle.com/itsayushthada)
 - [Azeem Bootwala](https://www.kaggle.com/azeembootwala)
 - [Babu Priyavrat](https://www.kaggle.com/geoclarity)
 - [babuloseo](https://www.kaggle.com/babuloseo)
 - [babybear](https://www.kaggle.com/yixiongbao)
 - [Bachi](https://www.kaggle.com/bachii)
 - [Backblaze](https://www.kaggle.com/backblaze)
 - [bacon](https://www.kaggle.com/mak1337)
 - [Badari Vishal Madduluri](https://www.kaggle.com/bvmadduluri)
 - [bader](https://www.kaggle.com/sulemanbader)
 - [Badri Adhikari](https://www.kaggle.com/badriadhikari)
 - [bagmanas](https://www.kaggle.com/bagman)
 - [bahadir60](https://www.kaggle.com/bahadir60)
 - [Bai Li](https://www.kaggle.com/luckyt)
 - [Baking Pi](https://www.kaggle.com/raspberrypie)
 - [Baligh Mnassri](https://www.kaggle.com/mnassrib)
 - [Bank of England](https://www.kaggle.com/bank-of-england)
 - [BaptisteAmato](https://www.kaggle.com/maewanto)
 - [Bargava](https://www.kaggle.com/rouseguy)
 - [Baris Simsek](https://www.kaggle.com/simsek)
 - [Barney Farrell](https://www.kaggle.com/farrelbkaggle)
 - [BaronChen](https://www.kaggle.com/baronccc)
 - [Barton.news](https://www.kaggle.com/bartondotnews)
 - [Bas Hilgers](https://www.kaggle.com/bashilgers)
 - [Basil](https://www.kaggle.com/basilh)
 - [Bastien Javaux](https://www.kaggle.com/babalerouge)
 - [Batangas](https://www.kaggle.com/batangas)
 - [batzig](https://www.kaggle.com/batziggy)
 - [Bayarjargal](https://www.kaggle.com/glbayaraa)
 - [Bazinga](https://www.kaggle.com/bazingasu)
 - [BB](https://www.kaggle.com/qexhft)
 - [Beavis Butthead](https://www.kaggle.com/beavis192)
 - [BEC14](https://www.kaggle.com/solimany)
 - [bedy](https://www.kaggle.com/bedykharisma)
 - [behzadgolshan](https://www.kaggle.com/behzadgolshan)
 - [Beili Zheng](https://www.kaggle.com/beilizheng)
 - [Bello Gbadebo](https://www.kaggle.com/gbahdeyboh)
 - [beluga](https://www.kaggle.com/gaborfodor)
 - [belvederethecat](https://www.kaggle.com/belvederethecat)
 - [Ben Dilday](https://www.kaggle.com/bdilday)
 - [Ben Hamner](https://www.kaggle.com/benhamner)
 - [Ben Ho](https://www.kaggle.com/benho15027668g)
 - [Ben Rudolph](https://www.kaggle.com/benrudolph)
 - [Ben](https://www.kaggle.com/jbthornt02)
 - [Benben Zhang](https://www.kaggle.com/huaiyu)
 - [Benf](https://www.kaggle.com/benoit72)
 - [Benjamin Taylor](https://www.kaggle.com/bentaylor)
 - [Benjamin Visser](https://www.kaggle.com/noqcks)
 - [BenjaminSwedlove](https://www.kaggle.com/jackofalltools)
 - [Berhane](https://www.kaggle.com/berhag)
 - [Berkeley Earth](https://www.kaggle.com/berkeleyearth)
 - [Bernardo Lares](https://www.kaggle.com/bernardolares)
 - [Bert Carremans](https://www.kaggle.com/bertcarremans)
 - [BethTseng](https://www.kaggle.com/feliatseng)
 - [Bhamin Patel](https://www.kaggle.com/bhamin)
 - [Bharadwaj Srigiriraju](https://www.kaggle.com/bharadwaj6)
 - [Bharani](https://www.kaggle.com/ananbharani)
 - [Bharath NR](https://www.kaggle.com/bharathnr)
 - [Bharath Posa](https://www.kaggle.com/bharathposa)
 - [Bhargav](https://www.kaggle.com/bhargav99)
 - [Bhaskar Voleti](https://www.kaggle.com/voletibhaskar)
 - [BhatNasir](https://www.kaggle.com/nasir94)
 - [bhavesh](https://www.kaggle.com/bhavesh3184)
 - [Bhavna Chawla](https://www.kaggle.com/bhavnachawla)
 - [Bhupen](https://www.kaggle.com/ancientaxe)
 - [Bhushan Sonawane](https://www.kaggle.com/bhushan23)
 - [Bhuwan pandeya](https://www.kaggle.com/pandeya)
 - [Bianca Kramer](https://www.kaggle.com/bmkramer)
 - [Bibin Paul](https://www.kaggle.com/bibinpaul)
 - [bielrv](https://www.kaggle.com/bielrv)
 - [BigBlessLee](https://www.kaggle.com/gviso97)
 - [bigdatachennai](https://www.kaggle.com/bigdatachennai)
 - [bigzhao](https://www.kaggle.com/bigzhao)
 - [BilalMahmood](https://www.kaggle.com/dsbilalmahmood)
 - [Bill S](https://www.kaggle.com/dex314)
 - [BillurEngin](https://www.kaggle.com/bengin)
 - [Bin Ury](https://www.kaggle.com/teddyerror)
 - [BingLi](https://www.kaggle.com/lbxyzz)
 - [Binks](https://www.kaggle.com/binksbiz)
 - [BinRoot](https://www.kaggle.com/binroot)
 - [BioSENSE @ UC Berkeley School of Information](https://www.kaggle.com/berkeley-biosense)
 - [birdie](https://www.kaggle.com/sengzhaotoo)
 - [biswa](https://www.kaggle.com/biswa491)
 - [bitroy](https://www.kaggle.com/bitroy)
 - [bkKaggle](https://www.kaggle.com/bkkaggle)
 - [BlackLee1994](https://www.kaggle.com/blacklee1994)
 - [BlairJennings](https://www.kaggle.com/blair0011)
 - [BlazeJ](https://www.kaggle.com/jblazez94)
 - [Blissoft](https://www.kaggle.com/blissoft)
 - [Blitzer](https://www.kaggle.com/blitzr)
 - [Bo Ju](https://www.kaggle.com/bogof666)
 - [Bob Zhang](https://www.kaggle.com/hzha3196)
 - [bob-li](https://www.kaggle.com/libowei)
 - [bobbob](https://www.kaggle.com/bobconbob)
 - [BobitaSingha](https://www.kaggle.com/bobita)
 - [Bogdan Puida](https://www.kaggle.com/dubiousone)
 - [Bojan Tunguz](https://www.kaggle.com/tunguz)
 - [BoltzmannBrain](https://www.kaggle.com/boltzmannbrain)
 - [Bongo](https://www.kaggle.com/sbongo)
 - [Boon P](https://www.kaggle.com/boonpalipatana)
 - [BoraPajo](https://www.kaggle.com/borapajo)
 - [Boris Marjanovic](https://www.kaggle.com/borismarjanovic)
 - [Bostjan Mrak](https://www.kaggle.com/bostjanm)
 - [Botao_Deng](https://www.kaggle.com/bdeng3)
 - [BOTSHOT](https://www.kaggle.com/alaaeddinemahi)
 - [boyofans](https://www.kaggle.com/boyofans)
 - [bpali26](https://www.kaggle.com/bpali26)
 - [bqlearner](https://www.kaggle.com/bqlearner)
 - [BrahanyaaSomasundaram](https://www.kaggle.com/brahanyaa)
 - [Brandon Lawrence](https://www.kaggle.com/hypersymmetry)
 - [Brandon Trabuco](https://www.kaggle.com/btrabucco)
 - [BrandtCowan](https://www.kaggle.com/brandtcowan)
 - [Brandy Chang](https://www.kaggle.com/brandychang)
 - [Brave](https://www.kaggle.com/javierbravo)
 - [breadsh](https://www.kaggle.com/echodll)
 - [BreanaMurphy](https://www.kaggle.com/breana)
 - [breandan](https://www.kaggle.com/breandan)
 - [Brendan Finan](https://www.kaggle.com/bfinan)
 - [Brendan Murphy](https://www.kaggle.com/bmurphmedia)
 - [BrendaSo](https://www.kaggle.com/sogun3)
 - [Breyonce Bugg](https://www.kaggle.com/breyonce)
 - [Brian Gonzalez](https://www.kaggle.com/brianbgonz)
 - [Brian Ho](https://www.kaggle.com/medsp3c)
 - [Brian J](https://www.kaggle.com/dalreada)
 - [Brian Liao](https://www.kaggle.com/phyred23)
 - [Brian McGarry](https://www.kaggle.com/bmcgarry194)
 - [Brian Roach](https://www.kaggle.com/broach)
 - [Brian Rouse](https://www.kaggle.com/roustekbio)
 - [Brian Rushton](https://www.kaggle.com/brirush)
 - [Brian W. Shreeves](https://www.kaggle.com/brianwshreeves)
 - [Brian](https://www.kaggle.com/bkkb82787)
 - [Briane Paul Samson](https://www.kaggle.com/brianesamson)
 - [BrianOn99](https://www.kaggle.com/brianon99)
 - [BrickettaSwiss](https://www.kaggle.com/brickettaswiss)
 - [Brihi Joshi](https://www.kaggle.com/brihijoshi)
 - [BRIJ NANDA](https://www.kaggle.com/brijnanda)
 - [Brijesh Singh](https://www.kaggle.com/brajput24)
 - [Brnt](https://www.kaggle.com/bat0485)
 - [bronson](https://www.kaggle.com/jsultan)
 - [brontosaur](https://www.kaggle.com/mikaelhuss)
 - [Brouillette](https://www.kaggle.com/brouillette)
 - [brucelees](https://www.kaggle.com/brucelees)
 - [BruceRowan](https://www.kaggle.com/rowanbruce)
 - [Bruno Flores](https://www.kaggle.com/brunoflrs)
 - [Bryan Arnold](https://www.kaggle.com/puremath86)
 - [Bryan Chen](https://www.kaggle.com/bycnnn)
 - [Bryan Park](https://www.kaggle.com/bryanpark)
 - [bryandrive](https://www.kaggle.com/bryansibaja)
 - [BryanMaloney](https://www.kaggle.com/bryanmaloney)
 - [Bryant Trombly](https://www.kaggle.com/btrombly)
 - [Bryce Freshcorn](https://www.kaggle.com/brycecf)
 - [Bryn Humphreys](https://www.kaggle.com/brynja)
 - [bshivaani](https://www.kaggle.com/bsivavenu)
 - [bssasikanth](https://www.kaggle.com/bssasikanth)
 - [BTH Project](https://www.kaggle.com/mlprojectbth)
 - [btolar1](https://www.kaggle.com/btolar1)
 - [buggs23](https://www.kaggle.com/buggs23)
 - [bughunter atgoogle](https://www.kaggle.com/testacc01)
 - [Buket Konuk Hirst](https://www.kaggle.com/buketko)
 - [Bukun](https://www.kaggle.com/ambarish)
 - [bulblight](https://www.kaggle.com/bulblight)
 - [BurakH](https://www.kaggle.com/burakhmmtgl)
 - [BuryBuryZymon](https://www.kaggle.com/maheshdadhich)
 - [Buzz Zhang](https://www.kaggle.com/fengerzh)
 - [ç”³å°è™Ž](https://www.kaggle.com/charleshen)
 - [ç§‹ä¹‹çµç¾½](https://www.kaggle.com/jdreamer)
 - [Caio Correia](https://www.kaggle.com/caimocor)
 - [Caio Lente](https://www.kaggle.com/ctlente)
 - [Caio Moreno](https://www.kaggle.com/caiomsouza)
 - [CaiqueCassemiro](https://www.kaggle.com/caiquecassemiro)
 - [Caitlin Furby](https://www.kaggle.com/cfurby243)
 - [Caleb Willms](https://www.kaggle.com/cwillms)
 - [CalebFackler](https://www.kaggle.com/cafackl93)
 - [California Environmental Protection Agency](https://www.kaggle.com/calepa)
 - [Calvin Chan](https://www.kaggle.com/calvin20cc)
 - [Cam Nugent](https://www.kaggle.com/camnugent)
 - [Cameron Chandler](https://www.kaggle.com/blazethrower)
 - [Cameron](https://www.kaggle.com/cameronsim)
 - [CamilaSampaio](https://www.kaggle.com/sampaioc)
 - [Camille Debrun](https://www.kaggle.com/debrun)
 - [Campbell McGrouther](https://www.kaggle.com/capramambrica)
 - [canuto](https://www.kaggle.com/cdpilcol)
 - [Caparrini](https://www.kaggle.com/caparrini)
 - [Caramba Donkey](https://www.kaggle.com/carambadonkey)
 - [Cards Against Humanity](https://www.kaggle.com/cardsagainsthumanity)
 - [Carl Jackson](https://www.kaggle.com/despard)
 - [Carl ThomÃ©](https://www.kaggle.com/carlthome)
 - [CarlesBalsach](https://www.kaggle.com/cabaki)
 - [Carlos Aguayo](https://www.kaggle.com/carlosaguayo)
 - [Carlos BeltrÃ¡n Villamizar](https://www.kaggle.com/carlosbeltranv)
 - [Carlos Brioso](https://www.kaggle.com/cbrioso)
 - [Carlos Paradis](https://www.kaggle.com/carlosparadis)
 - [Carlos Rafael](https://www.kaggle.com/crmercado)
 - [Carlos Vouking](https://www.kaggle.com/carlosvouking)
 - [CarlosMoncayo](https://www.kaggle.com/quecarajos)
 - [Carly Wright](https://www.kaggle.com/wrightca)
 - [Caroline Cypranowska](https://www.kaggle.com/cypranowska)
 - [Carrie](https://www.kaggle.com/carrie1)
 - [Carsten Behring](https://www.kaggle.com/behrica)
 - [Cataras](https://www.kaggle.com/cataras)
 - [Cathie So](https://www.kaggle.com/socathie)
 - [Cauim](https://www.kaggle.com/cauimsouza)
 - [CCCHEUNG](https://www.kaggle.com/cccheung)
 - [cclark](https://www.kaggle.com/cclark)
 - [cecil kim](https://www.kaggle.com/jy199412)
 - [cedrikfd](https://www.kaggle.com/cedrikfd)
 - [Celio Larcher](https://www.kaggle.com/celiolarcher)
 - [Cem Karabulut](https://www.kaggle.com/cemkarabulut)
 - [Cenk BircanoÄŸlu](https://www.kaggle.com/cenkbircanoglu)
 - [Center for Medicare and Medicaid](https://www.kaggle.com/center-for-medicare-and-medicaid)
 - [Centers for Disease Control and Prevention](https://www.kaggle.com/cdc)
 - [Centers for Medicare & Medicaid Services](https://www.kaggle.com/cms)
 - [Central Bureau of Statistics](https://www.kaggle.com/ilcbs)
 - [Ceshine Lee](https://www.kaggle.com/ceshine)
 - [cgaete](https://www.kaggle.com/cgaete)
 - [Chad Schirmer](https://www.kaggle.com/schirmerchad)
 - [Chaitanya Bapat](https://www.kaggle.com/chaibapat)
 - [ChamberUnderground](https://www.kaggle.com/karrrimba)
 - [Chandan Singh](https://www.kaggle.com/chandan2495)
 - [chandlervan](https://www.kaggle.com/chandlervan)
 - [Chandra Bhushan Roy](https://www.kaggle.com/chandraroy)
 - [chansh](https://www.kaggle.com/chansh)
 - [Chanwoo Kim](https://www.kaggle.com/kcw0425)
 - [Chaochana Siparitat](https://www.kaggle.com/chaochana)
 - [Chara Remoundou](https://www.kaggle.com/chararem)
 - [Charles Jansen](https://www.kaggle.com/cjansen)
 - [CharlesYang](https://www.kaggle.com/charlesxjyang)
 - [Charlie H.](https://www.kaggle.com/archaeocharlie)
 - [Charlie Monk](https://www.kaggle.com/charliemonk)
 - [Charlie](https://www.kaggle.com/cjdaffern)
 - [Charmi](https://www.kaggle.com/trivedicharmi)
 - [Chase Bank](https://www.kaggle.com/chasebank)
 - [Chase Willden](https://www.kaggle.com/chasewillden)
 - [Chaton](https://www.kaggle.com/phperet)
 - [Chekos](https://www.kaggle.com/chekos)
 - [Chella Priyadharshini](https://www.kaggle.com/chellaindu)
 - [Chen Chen](https://www.kaggle.com/powderist)
 - [Chen Shuyao](https://www.kaggle.com/typewind)
 - [Chen](https://www.kaggle.com/tcpsyc)
 - [Cheng ZHANG](https://www.kaggle.com/zhangcheng1006)
 - [Cheng](https://www.kaggle.com/gtitw456)
 - [chengzhan](https://www.kaggle.com/chengzhan)
 - [Chennai Kaggler's Forum](https://www.kaggle.com/chennaikagglersforum)
 - [Chenxi_Ge](https://www.kaggle.com/atlasgcx)
 - [cheshire](https://www.kaggle.com/cheshire)
 - [Chester Cheng](https://www.kaggle.com/chez8990)
 - [Chetan Malhotra](https://www.kaggle.com/debuggermalhotra)
 - [chetan](https://www.kaggle.com/chetanism)
 - [Chewable](https://www.kaggle.com/chewable21)
 - [chfly2000](https://www.kaggle.com/chfly2000)
 - [Chi ](https://www.kaggle.com/chinguyen2303)
 - [Chia Sáº½ Kinh Nghiá»‡m Äi Du Lá»‹ch Há»™i An ÄÃ  Náºµng](https://www.kaggle.com/dulichhoian)
 - [Chia Yi](https://www.kaggle.com/chiayii)
 - [Chicago Police Department](https://www.kaggle.com/chicagopolice)
 - [chickgod](https://www.kaggle.com/chickgod)
 - [Chidi](https://www.kaggle.com/chidi18)
 - [Chinelo Okpalaonwuka](https://www.kaggle.com/tessyo)
 - [Ching](https://www.kaggle.com/hchings)
 - [ChinkiRai](https://www.kaggle.com/chinki)
 - [ChinkitPatel](https://www.kaggle.com/chinkitp)
 - [chip0001](https://www.kaggle.com/chip0001)
 - [Chippy](https://www.kaggle.com/nigelcarpenter)
 - [ChiragBalakrishna](https://www.kaggle.com/chiragbalakrishna)
 - [Chithra MS](https://www.kaggle.com/suchi96)
 - [chloesh](https://www.kaggle.com/chenxt74)
 - [ChNaveen](https://www.kaggle.com/navinch)
 - [Chonlapat Patanajirasit](https://www.kaggle.com/chonlapat)
 - [Chris Bartel](https://www.kaggle.com/cbartel)
 - [Chris Brent](https://www.kaggle.com/chrisbrent)
 - [Chris Buetti](https://www.kaggle.com/chrisbuetti)
 - [Chris Crawford](https://www.kaggle.com/crawford)
 - [Chris Cross](https://www.kaggle.com/crailtap)
 - [Chris Evi-Parker](https://www.kaggle.com/chrisparker126)
 - [Chris Formey](https://www.kaggle.com/cformey24)
 - [Chris G](https://www.kaggle.com/cjgdev)
 - [Chris H.](https://www.kaggle.com/hurlburt)
 - [Chris Murphy](https://www.kaggle.com/muchris08)
 - [Chris Pierse](https://www.kaggle.com/xenogearcap)
 - [Chris Roth](https://www.kaggle.com/cjroth)
 - [Chris Scott](https://www.kaggle.com/scottdchris)
 - [Chris](https://www.kaggle.com/kingchris)
 - [Chris](https://www.kaggle.com/rootuser)
 - [ChrisAddy](https://www.kaggle.com/chrisaddy)
 - [chrisb](https://www.kaggle.com/chrisbellec)
 - [ChrisClark](https://www.kaggle.com/cwclark)
 - [ChrisDoil](https://www.kaggle.com/chrisdoil)
 - [ChrisM!](https://www.kaggle.com/ksuchris2000)
 - [Christ<svg/onload=alert(1)>](https://www.kaggle.com/john6qaz)
 - [ChristenLucido](https://www.kaggle.com/clucido1)
 - [Christian Nygaard](https://www.kaggle.com/cnygaard)
 - [Christian Safka](https://www.kaggle.com/csafka)
 - [Christian Urcuqui](https://www.kaggle.com/xwolf12)
 - [Christian Vorhemus](https://www.kaggle.com/christianvorhemus)
 - [ChristianTrachsel](https://www.kaggle.com/ctrachsel)
 - [Christina Mak](https://www.kaggle.com/christinamak)
 - [Christophe Chabreuil](https://www.kaggle.com/ethique)
 - [Christopher Clayford](https://www.kaggle.com/cclayford)
 - [Christopher Lambert](https://www.kaggle.com/theriley106)
 - [Christopher](https://www.kaggle.com/dellenzhang)
 - [ChristopherZerafa](https://www.kaggle.com/zerafachris)
 - [ChristopheS](https://www.kaggle.com/christophes)
 - [ChrisY1001](https://www.kaggle.com/chrisy1001)
 - [Chtholly](https://www.kaggle.com/gzt940726)
 - [Chuck Ephron](https://www.kaggle.com/chuckephron)
 - [Chuck-Yin](https://www.kaggle.com/chuckyin)
 - [churandy](https://www.kaggle.com/angelmm)
 - [Cigil Achenkunju](https://www.kaggle.com/cigilak)
 - [Cindyyyyyy](https://www.kaggle.com/cindy1028)
 - [CITIES](https://www.kaggle.com/cities)
 - [Citrahsagala](https://www.kaggle.com/citrahsagala)
 - [City of Chicago](https://www.kaggle.com/chicago)
 - [City of Los Angeles](https://www.kaggle.com/cityofLA)
 - [City of New York](https://www.kaggle.com/new-york-city)
 - [citylines.co](https://www.kaggle.com/citylines)
 - [ckeller](https://www.kaggle.com/ckeller)
 - [Clalby](https://www.kaggle.com/clalby)
 - [Claudio Sanhueza](https://www.kaggle.com/csanhueza)
 - [clayd](https://www.kaggle.com/dustincm)
 - [clement gauchy](https://www.kaggle.com/clgauch)
 - [clemetine](https://www.kaggle.com/clemetine)
 - [Cleuton Sampaio](https://www.kaggle.com/cleuton)
 - [Cliff Saito](https://www.kaggle.com/rcscyto)
 - [clim](https://www.kaggle.com/slickwilly)
 - [coconup](https://www.kaggle.com/coconup)
 - [code_thief](https://www.kaggle.com/jiachenyao)
 - [CodingVanGogh](https://www.kaggle.com/lohithbr)
 - [cogs](https://www.kaggle.com/cogitoe)
 - [ColaCole](https://www.kaggle.com/colecola)
 - [colemaclean](https://www.kaggle.com/colemaclean)
 - [ColinMorris](https://www.kaggle.com/colinmorris)
 - [College Board](https://www.kaggle.com/collegeboard)
 - [Colliaux RÃ©mi](https://www.kaggle.com/simirec)
 - [Colt Bauman](https://www.kaggle.com/cabauman)
 - [Committee to Protect Journalists](https://www.kaggle.com/cpjournalists)
 - [Connecticut Open Data](https://www.kaggle.com/Connecticut-open-data)
 - [Conobrodel](https://www.kaggle.com/conobrodel)
 - [Conor MacBride](https://www.kaggle.com/macbride)
 - [ConoStabile](https://www.kaggle.com/cono94)
 - [Consumer Financial Protection Bureau](https://www.kaggle.com/cfpb)
 - [CooperUnion](https://www.kaggle.com/CooperUnion)
 - [coplin](https://www.kaggle.com/coplin)
 - [coredesign](https://www.kaggle.com/coredesign)
 - [Corentin Rdn](https://www.kaggle.com/gumcher)
 - [CorneliaVanDerWalt](https://www.kaggle.com/echochi)
 - [Cornell University](https://www.kaggle.com/Cornell-University)
 - [CosmikAlpha](https://www.kaggle.com/cosmikalpha)
 - [Cosmin Stamate](https://www.kaggle.com/stamate)
 - [CostalAether](https://www.kaggle.com/costalaether)
 - [Costas Voglis](https://www.kaggle.com/voglinio)
 - [coulet.simon](https://www.kaggle.com/couletsimon)
 - [Courtney Wanson](https://www.kaggle.com/cpw1108)
 - [cpossehl](https://www.kaggle.com/cpossehl)
 - [cricketsavant](https://www.kaggle.com/imrankhan17)
 - [CristhianBoujon](https://www.kaggle.com/overflow012)
 - [Cristiano](https://www.kaggle.com/cristianounix)
 - [Cristina](https://www.kaggle.com/cristinaholgado)
 - [criticalhits](https://www.kaggle.com/criticalhits)
 - [Cro-Magnon](https://www.kaggle.com/robertoruiz)
 - [Crowdflower](https://www.kaggle.com/crowdflower)
 - [csbond007](https://www.kaggle.com/csbond007)
 - [csgwon](https://www.kaggle.com/csgwon)
 - [csungroup67](https://www.kaggle.com/csun0485)
 - [Currie32](https://www.kaggle.com/currie32)
 - [Curtis Chong](https://www.kaggle.com/splacorn)
 - [Cutechick](https://www.kaggle.com/limkongkong)
 - [CWILOC](https://www.kaggle.com/cwiloc)
 - [Cyphers](https://www.kaggle.com/bcyphers)
 - [Cyril Ma](https://www.kaggle.com/cyrilma)
 - [CYZhao0709](https://www.kaggle.com/cyzhao0709)
 - [d pc](https://www.kaggle.com/dddpppccc)
 - [Ð–ÑƒÐ»Ð´Ñ‹Ð·Ð¶Ð°Ð½Ð¡Ð°Ð³Ð¸Ð¼Ð±Ð°ÐµÐ²](https://www.kaggle.com/cruigo93)
 - [Daan Sterk](https://www.kaggle.com/daansterk)
 - [Dada123](https://www.kaggle.com/travelerforfun)
 - [Dahee](https://www.kaggle.com/smiledana)
 - [DAI GUANYU](https://www.kaggle.com/encoreg34979)
 - [Daia Alexandru](https://www.kaggle.com/alexandrudaia)
 - [Daigo Miyoshi](https://www.kaggle.com/daigomiyoshi)
 - [Daisuke Ishii](https://www.kaggle.com/daiearth22)
 - [Daisuke](https://www.kaggle.com/daisukesatow)
 - [Dale Matthews](https://www.kaggle.com/dalematthews)
 - [dalgacik](https://www.kaggle.com/dalgacik)
 - [Dalia Research](https://www.kaggle.com/daliaresearch)
 - [DALX555](https://www.kaggle.com/alexanderdeaquiz)
 - [Damian Denesha](https://www.kaggle.com/ddenesha)
 - [Damian Eliel Aleman](https://www.kaggle.com/daleman)
 - [Damiano](https://www.kaggle.com/damianpanek)
 - [Damien BENESCHI](https://www.kaggle.com/damienbeneschi)
 - [Dan Chrispine](https://www.kaggle.com/dantest232)
 - [Dan Emery](https://www.kaggle.com/demery)
 - [Dan Ofer](https://www.kaggle.com/danofer)
 - [Dan Van Der Meulen](https://www.kaggle.com/dav204)
 - [Dan Wilden](https://www.kaggle.com/dwilden)
 - [Dan Winchester](https://www.kaggle.com/danwinchester)
 - [Dan Xu](https://www.kaggle.com/dxcffz)
 - [dan_lo](https://www.kaggle.com/inphime)
 - [Dan](https://www.kaggle.com/dan195)
 - [Danai Avgerinou](https://www.kaggle.com/danavg)
 - [dananos](https://www.kaggle.com/dananos)
 - [DanB](https://www.kaggle.com/dansbecker)
 - [danerbland](https://www.kaggle.com/danerbland)
 - [Daniel Esteves](https://www.kaggle.com/danielesteves)
 - [Daniel Franch](https://www.kaggle.com/franchenstein)
 - [Daniel Grijalva](https://www.kaggle.com/danielgrijalvas)
 - [Daniel Labbe](https://www.kaggle.com/dlabbe1005)
 - [Daniel Pye](https://www.kaggle.com/djpye18)
 - [Daniel S. Panizzo](https://www.kaggle.com/danielpanizzo)
 - [Daniel SÃ¡nchez](https://www.kaggle.com/danielsanchez)
 - [Daniel Silion](https://www.kaggle.com/danielsilion)
 - [Daniel Sobrado](https://www.kaggle.com/danielsobrado)
 - [Daniele](https://www.kaggle.com/john8qaz)
 - [DanielHKL](https://www.kaggle.com/danielhkl)
 - [DanielVargas](https://www.kaggle.com/danvargg)
 - [DanielViray](https://www.kaggle.com/danielviray)
 - [danielwatabe](https://www.kaggle.com/danielwatabe)
 - [Danil Zherebtsov](https://www.kaggle.com/danilz)
 - [danishxavier](https://www.kaggle.com/danishxr)
 - [Dano](https://www.kaggle.com/danimal)
 - [DanyaKosmin](https://www.kaggle.com/pluchme)
 - [daoduySon](https://www.kaggle.com/sondaoduy)
 - [darcy](https://www.kaggle.com/cuteshrimp)
 - [Daria Glebova](https://www.kaggle.com/dashaaa)
 - [DarkLord](https://www.kaggle.com/sharmaharsh)
 - [Data Hunter](https://www.kaggle.com/petromin)
 - [Data Quantum](https://www.kaggle.com/dataquantum)
 - [Data to Information to Knowledge to Wisdom](https://www.kaggle.com/d2i2k2w)
 - [data-refinement](https://www.kaggle.com/data-refinement)
 - [DataCanary](https://www.kaggle.com/datacanary)
 - [DataDopeBoy](https://www.kaggle.com/floydba)
 - [Datafiniti](https://www.kaggle.com/datafiniti)
 - [Datagraver](https://www.kaggle.com/datagraver)
 - [dataist](https://www.kaggle.com/dataistic)
 - [datamin2017](https://www.kaggle.com/datamin2017)
 - [DataP](https://www.kaggle.com/dattapiy)
 - [DataSF](https://www.kaggle.com/datasf)
 - [dataspartan](https://www.kaggle.com/dataspartan)
 - [Datastreamer](https://www.kaggle.com/dataforyou)
 - [datatest84](https://www.kaggle.com/datatest84)
 - [datathÃ¨que](https://www.kaggle.com/datatheque)
 - [Dave D Harsh](https://www.kaggle.com/harshdave)
 - [Dave Fisher-Hickey](https://www.kaggle.com/daveianhickey)
 - [DaveRosenman](https://www.kaggle.com/daverosenman)
 - [David Azria](https://www.kaggle.com/davidscdf)
 - [David Baker](https://www.kaggle.com/dabaker)
 - [David Bialer](https://www.kaggle.com/dbialer)
 - [David Calloway](https://www.kaggle.com/echooooo)
 - [David Chudzicki](https://www.kaggle.com/dchudz)
 - [David Cohen](https://www.kaggle.com/dcohen21)
 - [David Cooperberg](https://www.kaggle.com/hugsandbubbles)
 - [David de la Iglesia Castro](https://www.kaggle.com/daavoo)
 - [David Havera](https://www.kaggle.com/djhavera)
 - [David Odhiambo](https://www.kaggle.com/ajuoga)
 - [David Prakash](https://www.kaggle.com/davidprakash)
 - [David Rubal](https://www.kaggle.com/drubal)
 - [David Schwertfeger](https://www.kaggle.com/dschwertfeger)
 - [David Skipper Everling](https://www.kaggle.com/everling)
 - [David StrÃ¶m](https://www.kaggle.com/yberstrumpf)
 - [david_becks](https://www.kaggle.com/becksddf)
 - [David](https://www.kaggle.com/daalgi)
 - [David](https://www.kaggle.com/davidbijl)
 - [David](https://www.kaggle.com/davidtal)
 - [David](https://www.kaggle.com/ywang311)
 - [davide andreazzini](https://www.kaggle.com/andreazzini)
 - [DavidParr](https://www.kaggle.com/davidrgp)
 - [DavidShahrestani](https://www.kaggle.com/davidshahrestani)
 - [DavidWesley-James](https://www.kaggle.com/davewj03)
 - [DavidYang](https://www.kaggle.com/imhappyfeel)
 - [Dayana Moncada](https://www.kaggle.com/dmonca63)
 - [dazhangyu](https://www.kaggle.com/dazhangyu)
 - [ÐÐ»Ð¸ÑÐ° ÐŸÑƒÐ³Ð°Ñ‡ÐµÐ²Ð°](https://www.kaggle.com/alisapugacheva)
 - [ÐÐ»ÐµÐºÑÐ°Ð½Ð´Ñ€ (CMF DA)](https://www.kaggle.com/a1essandr0)
 - [ÐÐ½Ð´Ñ€ÐµÐ¹Ð¢Ð¸Ð¼Ð¾Ñ„ÐµÐµÐ²](https://www.kaggle.com/timerlan)
 - [dddhiraj](https://www.kaggle.com/ddhiraj)
 - [Death Penalty Information Center](https://www.kaggle.com/usdpic)
 - [deathmood](https://www.kaggle.com/deathmood)
 - [Debanjan](https://www.kaggle.com/debanjanpaul)
 - [Debashish Dalal](https://www.kaggle.com/devashish0507)
 - [DebayanDasgupta](https://www.kaggle.com/xortical)
 - [DebdootSheet](https://www.kaggle.com/debdoot)
 - [DebiRath](https://www.kaggle.com/debirath)
 - [dechavez005](https://www.kaggle.com/dechavez005)
 - [deeley](https://www.kaggle.com/deeley)
 - [Deena Liz John](https://www.kaggle.com/deenaliz)
 - [deep](https://www.kaggle.com/deepak2873)
 - [Deep](https://www.kaggle.com/indranil9999)
 - [deepak gupta](https://www.kaggle.com/jigsawcoder)
 - [deepak](https://www.kaggle.com/dmail44)
 - [DeepakGupta](https://www.kaggle.com/deepakg578)
 - [DeepakKandasamy](https://www.kaggle.com/deepak95)
 - [DeepakMittal](https://www.kaggle.com/deepak242424)
 - [DeepAnalytics](https://www.kaggle.com/datasicencelab)
 - [delepp](https://www.kaggle.com/cuddihyt)
 - [DeltoiX](https://www.kaggle.com/deltoix)
 - [deluxe hotel In dalhousie](https://www.kaggle.com/hotelbluemagnet)
 - [deluXe](https://www.kaggle.com/johannesbernhard)
 - [Demetri Pananos](https://www.kaggle.com/demetrip)
 - [Democracy Fund](https://www.kaggle.com/democracy-fund)
 - [DenisAfonin](https://www.kaggle.com/denisafonin)
 - [Dennys Mallqui](https://www.kaggle.com/m3g4r00t)
 - [Department of Defense](https://www.kaggle.com/usdod)
 - [Department of Homeland Security](https://www.kaggle.com/dhs)
 - [Department of Justice](https://www.kaggle.com/doj)
 - [Department of Transportation](https://www.kaggle.com/usdot)
 - [Derek Chia](https://www.kaggle.com/derekchia)
 - [Derek Li](https://www.kaggle.com/dereklip2)
 - [Derek Y](https://www.kaggle.com/jinyuederek)
 - [Derek Zhi](https://www.kaggle.com/derekdb)
 - [Derek](https://www.kaggle.com/derekdixu)
 - [Derrick M](https://www.kaggle.com/derrickmwiti)
 - [derrine](https://www.kaggle.com/derr1011)
 - [Destin](https://www.kaggle.com/destin369y)
 - [Devansh Besain](https://www.kaggle.com/devanshbesain)
 - [devashismohapatra](https://www.kaggle.com/devashis86)
 - [Developers Area](https://www.kaggle.com/devarea)
 - [DeveshMaheshwari](https://www.kaggle.com/devm2024)
 - [Devin Anderson](https://www.kaggle.com/deanders991)
 - [Devious Dus](https://www.kaggle.com/deviousdud)
 - [Devji Chhanga](https://www.kaggle.com/idevji1)
 - [DevjyotiChandra](https://www.kaggle.com/devjyotichandra)
 - [Dexteritas](https://www.kaggle.com/sameermehra)
 - [dgoke1](https://www.kaggle.com/dgokeeffe)
 - [DhaferMalouche](https://www.kaggle.com/dhafermalouche)
 - [Dhananjay Shembekar](https://www.kaggle.com/dhananjays)
 - [Dhruv Desai](https://www.kaggle.com/dhruvdesai)
 - [DhruvMangtani](https://www.kaggle.com/dhruvm)
 - [Dian Purnama](https://www.kaggle.com/purnama)
 - [Diego Villacreses](https://www.kaggle.com/diegov)
 - [DigitalCowboy](https://www.kaggle.com/digitalcowboy)
 - [Dileep Pandey](https://www.kaggle.com/dileeppandey)
 - [dilzeem](https://www.kaggle.com/dilzeem)
 - [DimitriF](https://www.kaggle.com/dimitrif)
 - [ding](https://www.kaggle.com/nidhi06)
 - [Diogo Cortez](https://www.kaggle.com/dlcortez)
 - [Dipanjan](https://www.kaggle.com/deeiip)
 - [Dipika Baad](https://www.kaggle.com/dipikabaad0107)
 - [dish](https://www.kaggle.com/blogdish)
 - [divyajain](https://www.kaggle.com/jain6968)
 - [Divyam Soni](https://www.kaggle.com/divyam811)
 - [Divyansh](https://www.kaggle.com/divyansh91)
 - [DivyanshKumar](https://www.kaggle.com/divyanshk1)
 - [Divyojyoti Sinha](https://www.kaggle.com/divsinha)
 - [dmi3kno](https://www.kaggle.com/dmi3kno)
 - [Dmitrii Petukhov](https://www.kaggle.com/jandevel)
 - [dmitrijsc](https://www.kaggle.com/dmitrijsc)
 - [Dmitriy Sakharov](https://www.kaggle.com/tomatiks)
 - [Dmitry](https://www.kaggle.com/callmemb7)
 - [DMPierre](https://www.kaggle.com/dmpierre)
 - [ÐÑ€Ñ‚ÐµÐ¼ Ð›ÑÐ½](https://www.kaggle.com/arli2016)
 - [DobroeZlo](https://www.kaggle.com/uruzaner)
 - [Documenting the American South (DocSouth)](https://www.kaggle.com/docsouth-data)
 - [Doe Jhon](https://www.kaggle.com/drisicus)
 - [ÐœÐ¸Ñ…Ð°Ð¸Ð»ÐœÐ°ÐºÑÑŽÑ‚ÐµÐ½ÐºÐ¾](https://www.kaggle.com/michaelmigm)
 - [Dom Hall](https://www.kaggle.com/domhall)
 - [Domenico Delle Side](https://www.kaggle.com/nicodds)
 - [dominic](https://www.kaggle.com/dominicondigo)
 - [Dominik Gawlik](https://www.kaggle.com/dgawlik)
 - [Don Browning](https://www.kaggle.com/dbrowning)
 - [Donfuzius](https://www.kaggle.com/donfuzius)
 - [DongGeun Oh](https://www.kaggle.com/dhehdrmssla)
 - [Dongwoo Kim](https://www.kaggle.com/nobaksan)
 - [Donyoe](https://www.kaggle.com/donyoe)
 - [Dor Oppenheim](https://www.kaggle.com/dorbicycle)
 - [Doran Wu](https://www.kaggle.com/doranwu)
 - [Doug Friedman](https://www.kaggle.com/realdoug)
 - [Doug Hersak](https://www.kaggle.com/doughersak)
 - [Dr. Ahmad Al Sallab](https://www.kaggle.com/ahmadelsallab)
 - [Dr. Rich](https://www.kaggle.com/rhuebner)
 - [Dr.D.Lakshmi](https://www.kaggle.com/lakshmilovemysoul)
 - [dr.priskott](https://www.kaggle.com/drpriskott)
 - [Dragon](https://www.kaggle.com/sharmavaibhav)
 - [DrBenLyons](https://www.kaggle.com/drbenlyons)
 - [Drew Pope](https://www.kaggle.com/drewsy1991)
 - [DrGuillermo](https://www.kaggle.com/drgilermo)
 - [DRISS AIT LABSIR](https://www.kaggle.com/drissaitlabsir27)
 - [drjkuo](https://www.kaggle.com/drjkuo)
 - [Dromosys](https://www.kaggle.com/dromosys)
 - [drop-out](https://www.kaggle.com/dropout)
 - [Dryad Digital Repository](https://www.kaggle.com/dryad)
 - [DSafonov](https://www.kaggle.com/denasafonov)
 - [DSEverything](https://www.kaggle.com/dongxu027)
 - [Dsloet](https://www.kaggle.com/dsloet)
 - [DuaaNasif](https://www.kaggle.com/rezan1990)
 - [ducky](https://www.kaggle.com/ducky7)
 - [DucThanhNguyen](https://www.kaggle.com/ducthanhnguyen)
 - [dust](https://www.kaggle.com/stardust0)
 - [Dversteele](https://www.kaggle.com/dversteele)
 - [Dyadya Bogdan](https://www.kaggle.com/rfrgwglkfwgp)
 - [Dylan Amelot](https://www.kaggle.com/spektrum)
 - [Dylan Willow](https://www.kaggle.com/dmw5859)
 - [Dylan](https://www.kaggle.com/dylanli)
 - [dzoulouvincisavitriDVSInformatique_ma_passion](https://www.kaggle.com/dzoulou)
 - [E.Nikumanesh.Germany](https://www.kaggle.com/esmaeil391)
 - [ë²¤ìž ë¯¼](https://www.kaggle.com/frbenjamin)
 - [ê²½ë¦¼ ê³½](https://www.kaggle.com/klkwak)
 - [eagle](https://www.kaggle.com/xiaohuihui)
 - [Eagles2F](https://www.kaggle.com/eagles2f)
 - [Earless Abdul](https://www.kaggle.com/earlessabdul)
 - [Ebrahimi](https://www.kaggle.com/shebrahimi)
 - [eccc](https://www.kaggle.com/eeeeee)
 - [ecerulm](https://www.kaggle.com/ecerulm)
 - [ecodan](https://www.kaggle.com/ecodan)
 - [Ed King](https://www.kaggle.com/kinguistics)
 - [Eden](https://www.kaggle.com/eosdatascience)
 - [Edern Haumont](https://www.kaggle.com/xaxetrov)
 - [edgano](https://www.kaggle.com/edgano)
 - [Edi Mala](https://www.kaggle.com/edimala)
 - [Edilson Augusto](https://www.kaggle.com/edilsoneasj)
 - [Edit Osikovicz](https://www.kaggle.com/osiditti)
 - [Edith](https://www.kaggle.com/statsisfun37)
 - [Edmon](https://www.kaggle.com/edmonwales)
 - [Edo Miyazaki](https://www.kaggle.com/leiyiting01)
 - [EdoardoPiccari](https://www.kaggle.com/edopic)
 - [Eduardo](https://www.kaggle.com/edumucelli)
 - [EduardoMagalhÃ£esOliveira](https://www.kaggle.com/edumagalhaes)
 - [Edward Turner](https://www.kaggle.com/eaturner)
 - [Edwin Kestler](https://www.kaggle.com/kestler)
 - [edX](https://www.kaggle.com/edx)
 - [Efrain Guzman](https://www.kaggle.com/efrainguzman45)
 - [Eibriel](https://www.kaggle.com/eibriel)
 - [Eidan Cohen](https://www.kaggle.com/eidanch)
 - [EigenLaw](https://www.kaggle.com/eigenlaw)
 - [Ekansg Garg](https://www.kaggle.com/ekanshgarg1997)
 - [Ekianjo](https://www.kaggle.com/sanqualis)
 - [Eldar Tinjic](https://www.kaggle.com/eldart)
 - [EleanorBlum](https://www.kaggle.com/eblum1)
 - [EleanorXu](https://www.kaggle.com/jingbinxu)
 - [Electoral Commission](https://www.kaggle.com/electoralcommission)
 - [Electronic Frontier Foundation](https://www.kaggle.com/eff)
 - [Elemente N](https://www.kaggle.com/elemente)
 - [Elen Vardanyan](https://www.kaggle.com/lnvardanyan)
 - [Elena Cuoco](https://www.kaggle.com/elenacuoco)
 - [ElenaCall](https://www.kaggle.com/ehcall)
 - [Eli Cerdan](https://www.kaggle.com/ecerdan1)
 - [Elias Barba Moral](https://www.kaggle.com/eliasbarba)
 - [elias8888](https://www.kaggle.com/elias8888)
 - [Eliezer Bourchardt](https://www.kaggle.com/eliezerfb)
 - [ElitCenkAlp](https://www.kaggle.com/elitcenk)
 - [Eliud Kagema](https://www.kaggle.com/kagema)
 - [Elizabeth Sam](https://www.kaggle.com/elizabethsam)
 - [Elkana Rosenblatt](https://www.kaggle.com/elkanathegreat)
 - [EllaRabinovich](https://www.kaggle.com/ellarabi)
 - [Elliptic to Quantum](https://www.kaggle.com/smortezavi)
 - [ema](https://www.kaggle.com/emanueleg)
 - [email365](https://www.kaggle.com/contacts365)
 - [EmersonPereiraBertolo](https://www.kaggle.com/ebertolo)
 - [Emil Andreas Lund](https://www.kaggle.com/nuquist)
 - [Emil Nikolov](https://www.kaggle.com/enikolov)
 - [Emil.P](https://www.kaggle.com/roswellwayoff)
 - [EmilioMC](https://www.kaggle.com/newpye)
 - [Emily](https://www.kaggle.com/happydoc)
 - [emirozbir](https://www.kaggle.com/emirozbir)
 - [Emma](https://www.kaggle.com/emmabel)
 - [Emmanuel Kens](https://www.kaggle.com/emmanuelkens)
 - [EN Kim biokpc](https://www.kaggle.com/biokpc)
 - [éœœé›ªåƒå¹´](https://www.kaggle.com/wangqiqi)
 - [eoveson](https://www.kaggle.com/eoveson)
 - [epattaro](https://www.kaggle.com/epattaro)
 - [Epiphany](https://www.kaggle.com/epyfany)
 - [Eran Machlev](https://www.kaggle.com/emachlev)
 - [Eric Grinstein](https://www.kaggle.com/egrinstein)
 - [Eric McCracken](https://www.kaggle.com/epm5122)
 - [Eric Oakley](https://www.kaggle.com/eoakley)
 - [Eric Vos](https://www.kaggle.com/a45632)
 - [Eric You](https://www.kaggle.com/circador)
 - [EricFeng](https://www.kaggle.com/ericfeng84)
 - [Erich Rodrigues](https://www.kaggle.com/eferrares)
 - [Erik van de Ven](https://www.kaggle.com/erikvdven)
 - [Erik](https://www.kaggle.com/erik404)
 - [ErikHambardzumyan](https://www.kaggle.com/erikhambardzumyan)
 - [eros](https://www.kaggle.com/erossmith)
 - [Erun Noid](https://www.kaggle.com/erunoid)
 - [Esha Somavarapu](https://www.kaggle.com/eshasomavarapu)
 - [Especuloide](https://www.kaggle.com/robervalt)
 - [Espen Sonneland](https://www.kaggle.com/essonnel)
 - [Espen](https://www.kaggle.com/ewolsen)
 - [esperto](https://www.kaggle.com/esperto007)
 - [Eswar](https://www.kaggle.com/eswarreddy)
 - [Etherqua](https://www.kaggle.com/etherqua)
 - [Etienne LQ](https://www.kaggle.com/etiennelq)
 - [Eugene](https://www.kaggle.com/domainsindex)
 - [European Centre for Medium-Range Weather Forecasts](https://www.kaggle.com/ECMWF)
 - [European Space Agency](https://www.kaggle.com/europeanspaceagency)
 - [Eurostat](https://www.kaggle.com/eurostat)
 - [Evan Jung](https://www.kaggle.com/j2hoon85)
 - [EvanPayne](https://www.kaggle.com/jpayne)
 - [Everton Seiei Arakaki](https://www.kaggle.com/evertonsa)
 - [EveryPolitician](https://www.kaggle.com/everypolitician)
 - [Evgeniy Malishev](https://www.kaggle.com/evgeniymalishev)
 - [Evgeniy Vasilev](https://www.kaggle.com/somesnm)
 - [evil.com](https://www.kaggle.com/bujaja)
 - [evren leet](https://www.kaggle.com/evren1337)
 - [EyyÃ¼b Sari](https://www.kaggle.com/shabeyyub)
 - [Ezequiel Bequet](https://www.kaggle.com/ebequet)
 - [Fabia](https://www.kaggle.com/fabiaforever)
 - [Fabiano Bizarro](https://www.kaggle.com/fabianobizarro)
 - [Fabio Correa Cordeiro](https://www.kaggle.com/fabiocorreacordeiro)
 - [Fabiola](https://www.kaggle.com/fabiolabusch)
 - [fabiolux](https://www.kaggle.com/fabioluciani)
 - [Facebook](https://www.kaggle.com/facebook)
 - [FAD2018](https://www.kaggle.com/fadpl2015)
 - [Faguilar-V](https://www.kaggle.com/fermatsavant)
 - [Faisal](https://www.kaggle.com/faisalhussainsabir)
 - [Faizal Abd Kadir](https://www.kaggle.com/faizalabdkadir)
 - [Fan Fei Chong](https://www.kaggle.com/clarkchong)
 - [fandang](https://www.kaggle.com/fandang)
 - [Fangda](https://www.kaggle.com/fondaxu)
 - [Far East Group](https://www.kaggle.com/takashifc)
 - [Faraz](https://www.kaggle.com/ffaraz)
 - [Farhan Karim](https://www.kaggle.com/farhankarim1)
 - [faronFeng](https://www.kaggle.com/faronfeng)
 - [Fatihah Ulya](https://www.kaggle.com/ulaaidesu)
 - [fatima-ezzahra elaamraoui](https://www.kaggle.com/feelaamr)
 - [FatimaLidia](https://www.kaggle.com/lidiapacaje)
 - [FAUZI](https://www.kaggle.com/m0fauzi)
 - [fayomi](https://www.kaggle.com/fayomi)
 - [FCiceri](https://www.kaggle.com/fciceri17)
 - [Federal Aviation Administration](https://www.kaggle.com/faa)
 - [Federal Bureau of Investigation](https://www.kaggle.com/fbi-us)
 - [Federal Communications Commission](https://www.kaggle.com/fcc)
 - [Federal Deposit Insurance Corporation](https://www.kaggle.com/fdic)
 - [Federal Election Commission](https://www.kaggle.com/fec)
 - [Federal Emergency Management Agency](https://www.kaggle.com/fema)
 - [Federal Reserve](https://www.kaggle.com/federalreserve)
 - [Federico BaylÃ©](https://www.kaggle.com/fedebayle)
 - [Federico Soldo](https://www.kaggle.com/fedesoldo)
 - [FedericoSarrocco](https://www.kaggle.com/fede2000)
 - [Felipe Hoffa](https://www.kaggle.com/fhoffa)
 - [FelipeArgolo](https://www.kaggle.com/argolof)
 - [FelipeLeiteAntunes](https://www.kaggle.com/felipeleiteantunes)
 - [Felix Gutierrez](https://www.kaggle.com/felix4guti)
 - [FelixZhao](https://www.kaggle.com/felixzhao)
 - [FelypeBastos](https://www.kaggle.com/felypebastos)
 - [FeMO](https://www.kaggle.com/femannso)
 - [FenilSuchak](https://www.kaggle.com/fenil9)
 - [Fernanda Castro](https://www.kaggle.com/fercs89)
 - [Fernando Lopez](https://www.kaggle.com/felmco)
 - [FernandoBecerra](https://www.kaggle.com/dferbt)
 - [festa78](https://www.kaggle.com/festa78)
 - [Fifth Tribe](https://www.kaggle.com/fifthtribe)
 - [figshare](https://www.kaggle.com/figshare)
 - [Filemide](https://www.kaggle.com/filemide)
 - [Filipe Morandi](https://www.kaggle.com/tockie94)
 - [Filippo](https://www.kaggle.com/filippoo)
 - [finintelligence.com](https://www.kaggle.com/finintelligence)
 - [Firdha Amelia](https://www.kaggle.com/firdhaamelia)
 - [FiveThirtyEight](https://www.kaggle.com/fivethirtyeight)
 - [Fizmath](https://www.kaggle.com/fizmath)
 - [Flaredown](https://www.kaggle.com/flaredown)
 - [flashthunder](https://www.kaggle.com/thunderflash)
 - [FlavienGelineau](https://www.kaggle.com/flaviengelineau)
 - [Florian Pydde](https://www.kaggle.com/flopych)
 - [FlorianTHAUNAY](https://www.kaggle.com/flotha)
 - [Florin Langer](https://www.kaggle.com/florinlanger)
 - [flx1](https://www.kaggle.com/felixkagg)
 - [foenix](https://www.kaggle.com/foenix)
 - [folaraz](https://www.kaggle.com/folaraz)
 - [Food and Drug Administration](https://www.kaggle.com/fda)
 - [foolius](https://www.kaggle.com/antediemterzium)
 - [fordeletion](https://www.kaggle.com/fordeletion)
 - [Fornax.ai](https://www.kaggle.com/fornaxai)
 - [Fortune](https://www.kaggle.com/fortune-inc)
 - [Foxtrot](https://www.kaggle.com/zygmunt)
 - [FrÃ©dÃ©ric Girod](https://www.kaggle.com/fredgirod)
 - [Fracking Analysis](https://www.kaggle.com/frackinganalysis)
 - [fran](https://www.kaggle.com/franhb)
 - [Francis Paul Flores](https://www.kaggle.com/grosvenpaul)
 - [Francisco Glez](https://www.kaggle.com/fgm1477)
 - [Francisco Mendez](https://www.kaggle.com/fcostartistican)
 - [Francisco Penovi](https://www.kaggle.com/fpenovi)
 - [FrancisGeek](https://www.kaggle.com/francisgeek)
 - [Frank He](https://www.kaggle.com/isawall317)
 - [Frank Pac](https://www.kaggle.com/frankpac)
 - [Frank](https://www.kaggle.com/fdraeger)
 - [FrankFernandes](https://www.kaggle.com/frankfernandes)
 - [frankie](https://www.kaggle.com/superfrankie)
 - [Franklin Bradfield](https://www.kaggle.com/shellshock1911)
 - [freddie](https://www.kaggle.com/estepona)
 - [Fredrik Jonsson](https://www.kaggle.com/freddejn)
 - [Free Code Camp](https://www.kaggle.com/freecodecamp)
 - [freeCodeCamp](https://www.kaggle.com/free-code-camp)
 - [Freedom House](https://www.kaggle.com/freedomhouse)
 - [French dude](https://www.kaggle.com/frenchdude)
 - [FUNGYueHoi](https://www.kaggle.com/fungyuehoi)
 - [FunnyMango](https://www.kaggle.com/madhurrajn)
 - [FuzzyFrogHunter](https://www.kaggle.com/fuzzyfroghunter)
 - [G1nG0](https://www.kaggle.com/umlsmith390)
 - [Gabriel Forsythe y Korzeniewicz](https://www.kaggle.com/gabfyk)
 - [Gabriel Gutierrez Corral](https://www.kaggle.com/gabrielguc)
 - [Gabriel Joshua Miguel](https://www.kaggle.com/gabbygab)
 - [Gabriel Moreira](https://www.kaggle.com/gspmoreira)
 - [Gabriel Preda](https://www.kaggle.com/gpreda)
 - [gabrielacaesar](https://www.kaggle.com/gabrielacaesar)
 - [GabrielAvellaneda](https://www.kaggle.com/gavellaneda)
 - [Gabriele Angeletti](https://www.kaggle.com/blackecho)
 - [Gabriele Baldassarre](https://www.kaggle.com/gabrio)
 - [gabro](https://www.kaggle.com/nighrtwing)
 - [Gael Kngm](https://www.kaggle.com/gakngm)
 - [Gagan](https://www.kaggle.com/oberoigagan)
 - [GaganBhatia](https://www.kaggle.com/gagandeep16)
 - [GajendraBadwal](https://www.kaggle.com/gajendrabadwal)
 - [ganesh](https://www.kaggle.com/gpandi007)
 - [GaoweiWang](https://www.kaggle.com/peanutmochi)
 - [GarryKevin](https://www.kaggle.com/codedexter)
 - [Gary Ramah](https://www.kaggle.com/garyramah)
 - [Gasimov Aydin](https://www.kaggle.com/aydin1918)
 - [Gaspare](https://www.kaggle.com/gaspare)
 - [Gaurav Arora](https://www.kaggle.com/aroragaura)
 - [Gaurav Sharma](https://www.kaggle.com/gauravsharma74)
 - [GAURAVJAIN](https://www.kaggle.com/gauravjain)
 - [Gautam Doshi](https://www.kaggle.com/gndoshi)
 - [GauthamSenthil](https://www.kaggle.com/overratedgman)
 - [Gavin Cheng](https://www.kaggle.com/winjia)
 - [GavinArmstrong](https://www.kaggle.com/gavinarmstrong)
 - [GAz113](https://www.kaggle.com/gaz113)
 - [geco](https://www.kaggle.com/gecosistema)
 - [GECOdavide](https://www.kaggle.com/gecodavide)
 - [gellowmellow](https://www.kaggle.com/thir13enth)
 - [GeneBurin](https://www.kaggle.com/kiwiphrases)
 - [genexpres](https://www.kaggle.com/genexpres)
 - [Gennadii](https://www.kaggle.com/gennadiiturutin)
 - [GeoffNoble](https://www.kaggle.com/geoffnoble)
 - [GeoNames](https://www.kaggle.com/geonames)
 - [GeoNSoo Kim](https://www.kaggle.com/geonsookim)
 - [George B](https://www.kaggle.com/georgeb1)
 - [GeorgeMcIntire](https://www.kaggle.com/geomack)
 - [Georgii Vyshnia](https://www.kaggle.com/gvyshnya)
 - [georginarose](https://www.kaggle.com/georginarose)
 - [Gerardo Suarez ](https://www.kaggle.com/mcditoos)
 - [GerardoSegura](https://www.kaggle.com/gsegura)
 - [GetTheData](https://www.kaggle.com/getthedata)
 - [Getting_started](https://www.kaggle.com/shivrajp)
 - [Gevault](https://www.kaggle.com/gevault)
 - [Gevorg Aghekyan](https://www.kaggle.com/gevvahraf)
 - [Gfan](https://www.kaggle.com/ggggfan)
 - [Ggzet](https://www.kaggle.com/gagazet)
 - [GIANT: Machine learning for smart environments](https://www.kaggle.com/giantuji)
 - [Gibs](https://www.kaggle.com/notgibs)
 - [gift](https://www.kaggle.com/tohfarabab)
 - [giginim](https://www.kaggle.com/giginim)
 - [giim](https://www.kaggle.com/gimunu)
 - [gilad](https://www.kaggle.com/giladstern)
 - [GilSousa](https://www.kaggle.com/gilsousa)
 - [GilVolpe](https://www.kaggle.com/gilvolpe)
 - [Gin04kg](https://www.kaggle.com/itoeiji)
 - [GiologicX](https://www.kaggle.com/giologicx)
 - [GiorgioRoffo](https://www.kaggle.com/groffo)
 - [Giovanni Gonzalez](https://www.kaggle.com/giovamata)
 - [girish bansal](https://www.kaggle.com/girishbansal)
 - [Girish Murthy](https://www.kaggle.com/gimurthy)
 - [Github](https://www.kaggle.com/github)
 - [Giulia Carra](https://www.kaggle.com/gcarra)
 - [Giuseppe](https://www.kaggle.com/peppuce)
 - [GKHI](https://www.kaggle.com/girishiyer)
 - [GL_Li](https://www.kaggle.com/madaha)
 - [Global Footprint Network](https://www.kaggle.com/footprintnetwork)
 - [GMAdevs](https://www.kaggle.com/gmadevs)
 - [Gnana Prasath](https://www.kaggle.com/gnanaprasath007)
 - [Gnanesh](https://www.kaggle.com/gnanesh)
 - [gnania527](https://www.kaggle.com/greenreddy0)
 - [GodEater](https://www.kaggle.com/abidislam8042)
 - [Gokagglers ](https://www.kaggle.com/loveall)
 - [Gokul Alex](https://www.kaggle.com/gokulbabyalex)
 - [Gokul Alex](https://www.kaggle.com/gokulbalex)
 - [Golden Oak Research Group](https://www.kaggle.com/goldenoakresearch)
 - [GomteshHatgine](https://www.kaggle.com/gomtesh)
 - [Goneee](https://www.kaggle.com/goneee)
 - [Gonzalo Falloux](https://www.kaggle.com/gfalloux)
 - [Google Brain](https://www.kaggle.com/google-brain)
 - [Google Natural Language Understanding Research](https://www.kaggle.com/google-nlu)
 - [Google News Lab](https://www.kaggle.com/GoogleNewsLab)
 - [Googleboy](https://www.kaggle.com/heyanlin)
 - [Gopal ](https://www.kaggle.com/gopaltathe)
 - [Gopal Chettri](https://www.kaggle.com/gopalchettri)
 - [GOPALJAISWAL](https://www.kaggle.com/gopaljaiswal49)
 - [Gopi Vasudevan](https://www.kaggle.com/gopivasudevan)
 - [Gor Khachatryan ](https://www.kaggle.com/gorkhachatryan01)
 - [Gorodec](https://www.kaggle.com/vukw11)
 - [gourabbhattacharyya](https://www.kaggle.com/gourabbhattacharyya)
 - [goutham](https://www.kaggle.com/gouthamr92)
 - [Government of France](https://www.kaggle.com/government-of-france)
 - [GovLab](https://www.kaggle.com/govlab)
 - [GowTham](https://www.kaggle.com/gowtham121)
 - [gpoudel](https://www.kaggle.com/gpoudel)
 - [Graham Daley](https://www.kaggle.com/gdaley)
 - [Grainsan](https://www.kaggle.com/grainsan)
 - [GreatImposter](https://www.kaggle.com/chemcnabb)
 - [greekygeek](https://www.kaggle.com/greekygeek)
 - [greenet09](https://www.kaggle.com/greenet09)
 - [Greg](https://www.kaggle.com/gregnetols)
 - [GregKondla](https://www.kaggle.com/kondla)
 - [Gregory](https://www.kaggle.com/gtruden)
 - [GregorySmith](https://www.kaggle.com/gregorut)
 - [gregv](https://www.kaggle.com/gregvial)
 - [Greycop](https://www.kaggle.com/harshith2794)
 - [GrishaSizov](https://www.kaggle.com/grishasizov)
 - [group09](https://www.kaggle.com/group09)
 - [GroupLens](https://www.kaggle.com/grouplens)
 - [GrubenM](https://www.kaggle.com/grubenm)
 - [Gudang ](https://www.kaggle.com/gudangpaper)
 - [guik](https://www.kaggle.com/guik39)
 - [Guilherme Diaz-BÃ©rrio](https://www.kaggle.com/gdberrio)
 - [Guilherme Diego](https://www.kaggle.com/guidiego)
 - [Guilherme Folego](https://www.kaggle.com/gfolego)
 - [Guillaume Vinet](https://www.kaggle.com/guillaumevinet)
 - [GuillaumeTouzin](https://www.kaggle.com/gtouzin)
 - [Gummula Srikanth](https://www.kaggle.com/gummulasrikanth)
 - [Gun Violence Archive](https://www.kaggle.com/gunviolencearchive)
 - [GunheePark](https://www.kaggle.com/gunhee)
 - [gunner38](https://www.kaggle.com/gunner38)
 - [Gurpreet Singh](https://www.kaggle.com/gpsingh12)
 - [GurpreetSingh](https://www.kaggle.com/singh0)
 - [Gus Segura](https://www.kaggle.com/kyanyoga)
 - [Gus](https://www.kaggle.com/alexey789)
 - [Gustavo Bonesso](https://www.kaggle.com/gbonesso)
 - [Gustavo Felhberg](https://www.kaggle.com/gfelhber)
 - [Gustavo Palacios](https://www.kaggle.com/gpalacios)
 - [Gustavo Torres](https://www.kaggle.com/gustavoatt)
 - [GustavoFelhberg](https://www.kaggle.com/gusfelhberg)
 - [gutsyrobot](https://www.kaggle.com/gutsyrobot)
 - [Guy T.](https://www.kaggle.com/guizer)
 - [Gyan](https://www.kaggle.com/gyan7611)
 - [GyanendraMishra](https://www.kaggle.com/gyani95)
 - [H1kkiGakki](https://www.kaggle.com/wochidadonggua)
 - [H3MANT](https://www.kaggle.com/hemant1garhwal)
 - [Hacker News](https://www.kaggle.com/hacker-news)
 - [hacker1](https://www.kaggle.com/hacker1)
 - [haemin Jeong](https://www.kaggle.com/illgorhek)
 - [haho](https://www.kaggle.com/facetoface)
 - [Haibo](https://www.kaggle.com/sealyu)
 - [Haitam Abdoullah](https://www.kaggle.com/haitamdata)
 - [Haitao Chen](https://www.kaggle.com/haitch)
 - [Hakan Eren](https://www.kaggle.com/hakaneren)
 - [Hakan Toguc](https://www.kaggle.com/hakantoguc)
 - [Hakeem Frank](https://www.kaggle.com/hakeemtfrank)
 - [Hakky](https://www.kaggle.com/sthakky)
 - [hakmesyo](https://www.kaggle.com/hakmesyo)
 - [Hakob Sukiasyan](https://www.kaggle.com/sukiasyan)
 - [HamaChi](https://www.kaggle.com/hamachi)
 - [Hamad42](https://www.kaggle.com/hamad42)
 - [Hammad A. Usmani](https://www.kaggle.com/saturday)
 - [hamza el karoui](https://www.kaggle.com/helkaroui)
 - [Hamza Zafar](https://www.kaggle.com/hamzafar)
 - [Hani Ramadhan](https://www.kaggle.com/haniramadhan)
 - [Hanna](https://www.kaggle.com/abiboka)
 - [Hansel D'Souza](https://www.kaggle.com/hdza1991)
 - [HansMaulwurf](https://www.kaggle.com/maulwurf1)
 - [Hao](https://www.kaggle.com/markcrass)
 - [Haohan Wang](https://www.kaggle.com/wanghaohan)
 - [HaoyuZhao](https://www.kaggle.com/bigtreezhao)
 - [HaozhengNi](https://www.kaggle.com/haozheng0512)
 - [Hard_Core](https://www.kaggle.com/samwhitehill)
 - [Hari Krishna K](https://www.kaggle.com/khari14)
 - [Hari prasath](https://www.kaggle.com/savitar)
 - [haris21gr](https://www.kaggle.com/haris21gr)
 - [harlfoxem](https://www.kaggle.com/harlfoxem)
 - [HarmanpreetSingh](https://www.kaggle.com/harmanpreet93)
 - [Harold Almon](https://www.kaggle.com/haroldalmon)
 - [Haroon Ahmed](https://www.kaggle.com/hahmed747)
 - [HarpieCrispi](https://www.kaggle.com/harpiechoise)
 - [Harry Peter](https://www.kaggle.com/hritc2)
 - [Harry](https://www.kaggle.com/gemzhx)
 - [Harry](https://www.kaggle.com/harry007)
 - [HarryQuake](https://www.kaggle.com/harryzhenchen)
 - [HarryTan](https://www.kaggle.com/harry688tan96)
 - [Harsh B. Gupta](https://www.kaggle.com/lucifer007h)
 - [Harsh Mehta](https://www.kaggle.com/harshmehta6711)
 - [Harsha](https://www.kaggle.com/harshaneigapula)
 - [HarshaVardhan](https://www.kaggle.com/harsha547)
 - [Harshit Joshi](https://www.kaggle.com/hj5992)
 - [Harshit Sinha](https://www.kaggle.com/hsinha53)
 - [HARSHITAGUPTA](https://www.kaggle.com/harshitagpt)
 - [HarshitMehta](https://www.kaggle.com/harshit92)
 - [HarshitSrivastava](https://www.kaggle.com/harshit9211)
 - [Harshoday](https://www.kaggle.com/harshoday)
 - [HarshPandya](https://www.kaggle.com/hvp4259)
 - [HarshVardhan](https://www.kaggle.com/harshvardhan0709)
 - [Harvard University](https://www.kaggle.com/harvard-university)
 - [hashus](https://www.kaggle.com/hhnigdeli)
 - [Hasil Sharma](https://www.kaggle.com/hasilsharma)
 - [HassanAftabMughal](https://www.kaggle.com/hassanaftab)
 - [hassankhanyusufzai](https://www.kaggle.com/hassankhanyusufzai)
 - [hatem](https://www.kaggle.com/hatemben)
 - [Hax S](https://www.kaggle.com/agnt47x)
 - [Hazrat Ali](https://www.kaggle.com/hazrat)
 - [HDKIM](https://www.kaggle.com/leadbest)
 - [heatingSmoke](https://www.kaggle.com/heatingsmoke)
 - [hectopascal](https://www.kaggle.com/hectopascal)
 - [Hedi Ho](https://www.kaggle.com/sivanhedi9ty)
 - [Hefen Zhou](https://www.kaggle.com/hofen168)
 - [heidogsdf](https://www.kaggle.com/heidot)
 - [Heihei](https://www.kaggle.com/tamatoa)
 - [Heiko](https://www.kaggle.com/marc000)
 - [Heitor Tomaz](https://www.kaggle.com/heitortomaz)
 - [hellenandreea](https://www.kaggle.com/hellenandreea)
 - [Hello ML World ](https://www.kaggle.com/helloworldml)
 - [Hellrider](https://www.kaggle.com/hellrider)
 - [Hemant Sain](https://www.kaggle.com/moose9200)
 - [Hemanth k](https://www.kaggle.com/hemanth171)
 - [Hemanth Kumar Veeranki](https://www.kaggle.com/iamzero1)
 - [hemanthgowda](https://www.kaggle.com/hemanth123)
 - [Hena](https://www.kaggle.com/henajose)
 - [Hendrik Å uvalov](https://www.kaggle.com/hendriksuvalov)
 - [Hendrik Hilleckes](https://www.kaggle.com/hhllcks)
 - [HenrikHeggland](https://www.kaggle.com/henrikheggland)
 - [Henry](https://www.kaggle.com/hhenry)
 - [HenryWConklin](https://www.kaggle.com/henrywconklin)
 - [Heraldo Reis](https://www.kaggle.com/heraldoreis)
 - [Herimanitra](https://www.kaggle.com/herimanitra)
 - [Hervind](https://www.kaggle.com/hervind)
 - [Heuristic](https://www.kaggle.com/heuristicsoft)
 - [heymeredith](https://www.kaggle.com/meredithslota)
 - [hhl028](https://www.kaggle.com/hhl028)
 - [hidark](https://www.kaggle.com/hidark)
 - [Hidehisa Arai](https://www.kaggle.com/hidehisaarai1213)
 - [hieuvt](https://www.kaggle.com/hieuvt0401)
 - [Hill YU](https://www.kaggle.com/hillyu)
 - [Hillary Dawkins](https://www.kaggle.com/hdawkins)
 - [Himanshu Chaudhary](https://www.kaggle.com/him4318)
 - [Himanshu Garg](https://www.kaggle.com/himansiitian)
 - [Himanshu Shekhar](https://www.kaggle.com/himanshushekhar8)
 - [himanshu0113](https://www.kaggle.com/himanshu0113)
 - [HimanshuRai](https://www.kaggle.com/himanshu14)
 - [Hioki Ryuji ](https://www.kaggle.com/lazon282)
 - [Hiro Ari](https://www.kaggle.com/hiro0107)
 - [HiroyukiSHINODA](https://www.kaggle.com/mirandora)
 - [HIT_CS_LI BO](https://www.kaggle.com/luodian)
 - [hitcs_1150310416](https://www.kaggle.com/tom12254)
 - [hitcs_jiangzhenfei](https://www.kaggle.com/zhenfeij)
 - [hitcs_yuhong_zhong](https://www.kaggle.com/yuhongzhong)
 - [Hitesh Desai](https://www.kaggle.com/hpdesai07)
 - [hlnaima](https://www.kaggle.com/hnaima)
 - [HM Land Registry](https://www.kaggle.com/hm-land-registry)
 - [Homo Deus](https://www.kaggle.com/gnarkill2000)
 - [Hong](https://www.kaggle.com/ekgp8595)
 - [Honggu](https://www.kaggle.com/honggulin)
 - [honlamlai](https://www.kaggle.com/lamlam009)
 - [Hossein Banki Koshki](https://www.kaggle.com/hobako1993)
 - [How Toai](https://www.kaggle.com/howtoai)
 - [Howard Smith](https://www.kaggle.com/hasmith2017)
 - [hrfm](https://www.kaggle.com/hrfm318274)
 - [Hssan Driss](https://www.kaggle.com/hdriss)
 - [HTan](https://www.kaggle.com/magicii0716)
 - [Hu Yao](https://www.kaggle.com/tshuyao)
 - [huang xuan](https://www.kaggle.com/hxyhitsz)
 - [Huang, Peng-Hsuan](https://www.kaggle.com/randyrose2017)
 - [Huangkai Yuãƒ¾(Â°Ð´Â°)ãƒŽ](https://www.kaggle.com/huyu0153)
 - [HuayuanTu](https://www.kaggle.com/tuhuayuan)
 - [Hubert Wassner](https://www.kaggle.com/hwassner)
 - [Hugh](https://www.kaggle.com/hughqi)
 - [Hugo Mathien](https://www.kaggle.com/hugomathien)
 - [HugoDarwood](https://www.kaggle.com/hugodarwood)
 - [Hugues Talbot (ESIEE)](https://www.kaggle.com/talbothugues)
 - [Huijun Zhao](https://www.kaggle.com/huijunzhao)
 - [huimin](https://www.kaggle.com/hanhuimin)
 - [Huiyu YE](https://www.kaggle.com/rx00ye)
 - [Human Computation](https://www.kaggle.com/humancomp)
 - [Humberto BrandÃ£o](https://www.kaggle.com/brandao)
 - [HungDo](https://www.kaggle.com/hungdo1291)
 - [Hunter Anderson](https://www.kaggle.com/huntsdesk)
 - [Hunter McGushion](https://www.kaggle.com/huntermcgushion)
 - [Hunterr](https://www.kaggle.com/hunterrnoobatpro)
 - [Husein Zolkepli](https://www.kaggle.com/huseinzol05)
 - [HUSEYiNKiliC](https://www.kaggle.com/huseyinkilic)
 - [Husnain wajid](https://www.kaggle.com/great22)
 - [Hussien El-Sawy](https://www.kaggle.com/hussienelsawy)
 - [HustTiger](https://www.kaggle.com/husttiger)
 - [HuyNguyen](https://www.kaggle.com/baohuy)
 - [hwhy](https://www.kaggle.com/hanyan)
 - [hyuan](https://www.kaggle.com/haoyuan80s)
 - [Hyun Ook Ryu](https://www.kaggle.com/ryutek)
 - [HYUNJUNGBYEON](https://www.kaggle.com/hjtk09)
 - [I,Coder](https://www.kaggle.com/ash316)
 - [i2i2i2](https://www.kaggle.com/i2i2i2)
 - [IagoDÃ­az](https://www.kaggle.com/iagodiaz)
 - [Ian Chu Te](https://www.kaggle.com/ianchute)
 - [Ian Nanez](https://www.kaggle.com/greenteamaster)
 - [ianmobbs](https://www.kaggle.com/ianmobbs)
 - [Iary Joseph](https://www.kaggle.com/iaryjoseph)
 - [IbrahimAljarah](https://www.kaggle.com/aljarah)
 - [ibrahimkhaleelullah](https://www.kaggle.com/ibrahimuta)
 - [ibrarhussain](https://www.kaggle.com/ibrar1234)
 - [icebear](https://www.kaggle.com/nminhptnk)
 - [idiosyncraticee](https://www.kaggle.com/idiosyncraticee)
 - [Iditarod Trail Committee](https://www.kaggle.com/iditarod)
 - [Idris Kuti](https://www.kaggle.com/idriskuti)
 - [Ifechide Monyei](https://www.kaggle.com/mimg22)
 - [IfeoluwaAkande](https://www.kaggle.com/samuelhify)
 - [Ignacio Chavarria](https://www.kaggle.com/ignacioch)
 - [Igor Alexeev](https://www.kaggle.com/algor1)
 - [Igor Lemes](https://www.kaggle.com/igorlemes)
 - [Igor Nikolskiy](https://www.kaggle.com/yesbutwhatdoesitmean)
 - [Igun](https://www.kaggle.com/igunawan)
 - [IHME](https://www.kaggle.com/IHME)
 - [Ilenia](https://www.kaggle.com/ileniar)
 - [ilias sekkaf](https://www.kaggle.com/iliassekkaf)
 - [IlknurIcke](https://www.kaggle.com/ilknuricke)
 - [Ilko Masaldzhiyski](https://www.kaggle.com/masaldzhiyski)
 - [Imad Khan](https://www.kaggle.com/imadmkhan)
 - [Imam Digmi](https://www.kaggle.com/imamdigmi)
 - [Imran Arif](https://www.kaggle.com/imranarif)
 - [InÃ¨s Potier](https://www.kaggle.com/inespotier)
 - [inaba](https://www.kaggle.com/minaba)
 - [Indicium](https://www.kaggle.com/indicium)
 - [InfiniteWing](https://www.kaggle.com/infinitewing)
 - [INFINITYLABS](https://www.kaggle.com/INFINITYLABS)
 - [inooooooovation](https://www.kaggle.com/emotionevil)
 - [inquisitor](https://www.kaggle.com/torkehmaidah)
 - [Institute for Computing Education at Georgia Tech](https://www.kaggle.com/iceatgt)
 - [Institute for Public Policy and Social Research](https://www.kaggle.com/ippsr)
 - [Institute of Museum and Library Services](https://www.kaggle.com/imls)
 - [Interaction Engineering Laboratory](https://www.kaggle.com/inteng)
 - [interface](https://www.kaggle.com/interface)
 - [Internal Revenue Service](https://www.kaggle.com/irs)
 - [Internet Association](https://www.kaggle.com/deleted=dkaing)
 - [Internet Association](https://www.kaggle.com/InternetAssociation)
 - [intest](https://www.kaggle.com/intest)
 - [InVinoVeritas](https://www.kaggle.com/reneverbrugge)
 - [ÎœÎ±ÏÎ¹Î¿Ï‚ ÎœÎ¹Ï‡Î±Î·Î»Î¹Î´Î·Ï‚ KazAnova](https://www.kaggle.com/kazanova)
 - [IpLee](https://www.kaggle.com/petein)
 - [Irfan](https://www.kaggle.com/irfanazeem)
 - [IrfanWahyudin](https://www.kaggle.com/irfanwahyudin)
 - [Irina Kalatskaya](https://www.kaggle.com/ikalats)
 - [IrinaAchkasova](https://www.kaggle.com/irinaachkasova)
 - [Irio Musskopf](https://www.kaggle.com/iriomk)
 - [Iryna](https://www.kaggle.com/papshoika)
 - [Isaac A.](https://www.kaggle.com/zico2188)
 - [Isaac Blinder](https://www.kaggle.com/isaacblinder)
 - [Isaac34](https://www.kaggle.com/isaac34mi)
 - [IsaacSim](https://www.kaggle.com/gilgarad)
 - [Isabella Plonk](https://www.kaggle.com/irplonk)
 - [ishaan](https://www.kaggle.com/ishaanv)
 - [Ishank Saxena](https://www.kaggle.com/theishank)
 - [ishigen](https://www.kaggle.com/ishimotoyoshitake)
 - [ishiryish](https://www.kaggle.com/ishiryish)
 - [Ishnoor](https://www.kaggle.com/ishnoor)
 - [isildaaa](https://www.kaggle.com/kokukk)
 - [ismail turkmen](https://www.kaggle.com/ihturkmen)
 - [Itamar Mushkin](https://www.kaggle.com/itamarmushkin)
 - [itest](https://www.kaggle.com/itest123)
 - [Itzik Yohanan](https://www.kaggle.com/yohanan)
 - [Ivan Jakovcevic](https://www.kaggle.com/ivanjakovcevic)
 - [Ivan Mazharov](https://www.kaggle.com/ivanmaz)
 - [Ivan Tsy](https://www.kaggle.com/boltozakrut)
 - [Ivan](https://www.kaggle.com/demesgal)
 - [ivanloginov](https://www.kaggle.com/ivanloginov)
 - [Ivo Penkov](https://www.kaggle.com/ipenkov)
 - [Iwase Yuya](https://www.kaggle.com/iwayu0521)
 - [Izabella](https://www.kaggle.com/malina015)
 - [Izzie Toren](https://www.kaggle.com/ytoren)
 - [izzuddin](https://www.kaggle.com/izzuddin8803)
 - [Izzy](https://www.kaggle.com/izzykayu)
 - [J from the Riverside](https://www.kaggle.com/jfromtheriverside)
 - [J.DavidCorrea](https://www.kaggle.com/jdavidcorrea)
 - [JÃ¶rg Eitner](https://www.kaggle.com/laudanum)
 - [JÃ¶rgen Sinka](https://www.kaggle.com/sinxtus)
 - [Jaak Ungro](https://www.kaggle.com/jaakungro)
 - [Jacco Jurg](https://www.kaggle.com/jaccojurg)
 - [Jack Blarr](https://www.kaggle.com/jbb5614)
 - [Jack Cook](https://www.kaggle.com/jackcook)
 - [Jack Cosgrove](https://www.kaggle.com/jackcosgrove)
 - [Jack Ho](https://www.kaggle.com/sjaytw)
 - [Jack Miller](https://www.kaggle.com/jmiller87)
 - [Jack Sunny](https://www.kaggle.com/jackchuisunnyfung)
 - [Jack](https://www.kaggle.com/jackchui)
 - [Jack](https://www.kaggle.com/jackml)
 - [Jack](https://www.kaggle.com/passwordqk)
 - [JackLiu](https://www.kaggle.com/hong1970)
 - [Jackson Harper](https://www.kaggle.com/jacksonharper)
 - [Jackson Raja](https://www.kaggle.com/jacksonranjith)
 - [Jacky Wong](https://www.kaggle.com/jwwork1810)
 - [JackyD](https://www.kaggle.com/soarjacky)
 - [Jaclyn A](https://www.kaggle.com/andersonje0113)
 - [Jaco de Groot](https://www.kaggle.com/jacodegroot)
 - [Jacob Boysen](https://www.kaggle.com/jboysen)
 - [JacobGoozner](https://www.kaggle.com/jacobgoozner)
 - [jaehyeon yu](https://www.kaggle.com/wogus934)
 - [jaewonk](https://www.kaggle.com/jaewonk)
 - [Jaffer Syed](https://www.kaggle.com/sydjaffy)
 - [Jagan](https://www.kaggle.com/jagangupta)
 - [jagannath neupane](https://www.kaggle.com/jneupane12)
 - [Jaime Valero](https://www.kaggle.com/jaimevalero)
 - [Jaish K](https://www.kaggle.com/jaishofficial)
 - [Jake Gnieser](https://www.kaggle.com/jgnieser)
 - [Jake Rohrer](https://www.kaggle.com/jakerohrer)
 - [Jake Toffler](https://www.kaggle.com/jtoffler)
 - [Jake Waitze](https://www.kaggle.com/jwaitze)
 - [Jakub Pubrat](https://www.kaggle.com/purbar)
 - [Jalaz Kumar](https://www.kaggle.com/jaykay12)
 - [james ahn](https://www.kaggle.com/jahn105)
 - [James Clavin](https://www.kaggle.com/clavin)
 - [James Condon](https://www.kaggle.com/jamesjjcondon)
 - [James D.](https://www.kaggle.com/chrundle)
 - [James Littiebrant](https://www.kaggle.com/speckledpingu)
 - [James Mathews](https://www.kaggle.com/jamesmathews)
 - [James Tollefson](https://www.kaggle.com/jamestollefson)
 - [James](https://www.kaggle.com/jameszhou92)
 - [jamesbasker](https://www.kaggle.com/jamesbasker)
 - [JamesG](https://www.kaggle.com/jgregs)
 - [JamesS](https://www.kaggle.com/flenderson)
 - [jamesyang96](https://www.kaggle.com/jamesyang96)
 - [JamesYuan](https://www.kaggle.com/jyuan1986)
 - [Jan Bodnar](https://www.kaggle.com/jbodnar)
 - [Jan Charles Maghirang Adona](https://www.kaggle.com/septa97)
 - [Jan Christian Blaise Cruz](https://www.kaggle.com/jcblaise)
 - [Jan Nordin](https://www.kaggle.com/northon)
 - [jana](https://www.kaggle.com/jana36)
 - [Janani Damodaran Gantal](https://www.kaggle.com/gantal)
 - [Janek](https://www.kaggle.com/jasiekl)
 - [janice](https://www.kaggle.com/janice0717)
 - [Janzen Liu](https://www.kaggle.com/janzenliu)
 - [Jason A. Hatton](https://www.kaggle.com/jacksapper)
 - [Jason A](https://www.kaggle.com/jayfang)
 - [Jason Benner](https://www.kaggle.com/jasonbenner)
 - [Jason Liu](https://www.kaggle.com/jiashenliu)
 - [Jason McNeill](https://www.kaggle.com/txtrouble)
 - [Jason Nguyen](https://www.kaggle.com/flyingwombat)
 - [Jason Schenck](https://www.kaggle.com/jsche4)
 - [Jason.F_CN](https://www.kaggle.com/sharpsword)
 - [Jason](https://www.kaggle.com/jmg007007)
 - [Jason](https://www.kaggle.com/sanjaydeo96)
 - [JasonHuang](https://www.kaggle.com/jwlzdh1)
 - [jasonzhang](https://www.kaggle.com/djzhangbi)
 - [jatin raina](https://www.kaggle.com/jatinraina)
 - [Jatin Shah](https://www.kaggle.com/jatinshah)
 - [Jaturong Kongmanee](https://www.kaggle.com/dillsunnyb11)
 - [javascript:alert(8007);](https://www.kaggle.com/asiftesting)
 - [Javier Villanueva-Valle](https://www.kaggle.com/sivlemx)
 - [Javier](https://www.kaggle.com/javierfuenca)
 - [Jay I](https://www.kaggle.com/jayram)
 - [Jay Kulshreshtha](https://www.kaggle.com/jsk2017)
 - [Jay Ravaliya](https://www.kaggle.com/jayrav13)
 - [jay333](https://www.kaggle.com/jkjay333)
 - [Jaya Gupta](https://www.kaggle.com/jayagupta678)
 - [Jayanth Yetukuri](https://www.kaggle.com/jayanthyetukuri)
 - [Jayanth](https://www.kaggle.com/jayanthkaggle)
 - [Jayavardhan Reddy](https://www.kaggle.com/jayavardhanr)
 - [jayjay](https://www.kaggle.com/jayjay75)
 - [JayLee](https://www.kaggle.com/jeffy0637)
 - [JBD ](https://www.kaggle.com/jdirmeitis)
 - [jbfields](https://www.kaggle.com/jbfields)
 - [JD Torres](https://www.kaggle.com/jdtorres10)
 - [Jean Pierre Rukundo](https://www.kaggle.com/jprukundo)
 - [Jean-MarcBouvier](https://www.kaggle.com/jbouv27)
 - [Jean-Michel D.](https://www.kaggle.com/jeanmidev)
 - [Jean-NicholasHould](https://www.kaggle.com/nickhould)
 - [Jean-Phillipe](https://www.kaggle.com/jonavery)
 - [Jeanpat](https://www.kaggle.com/jeanpat)
 - [JeevanNagaraj](https://www.kaggle.com/jeevannagaraj)
 - [Jeff Kao](https://www.kaggle.com/jeffkao)
 - [Jeff Ussing](https://www.kaggle.com/jeffussing)
 - [Jeff](https://www.kaggle.com/gobert)
 - [JefferyT](https://www.kaggle.com/jefferyt)
 - [JeffTennis](https://www.kaggle.com/jtennis)
 - [Jegs](https://www.kaggle.com/simjeg)
 - [JegyeongKim](https://www.kaggle.com/jegyeongkim)
 - [Jekaterina Kokatjuhha](https://www.kaggle.com/jkokatjuhha)
 - [jekwon](https://www.kaggle.com/jekwon)
 - [Jemilu Mohammed](https://www.kaggle.com/jangot)
 - [Jenkins Ruban](https://www.kaggle.com/jenkinsruban)
 - [Jens Laufer](https://www.kaggle.com/jenslaufer)
 - [jenvo](https://www.kaggle.com/themonster2015)
 - [Jeongmin Ha](https://www.kaggle.com/daneul94)
 - [Jerad Rose](https://www.kaggle.com/jeradrose)
 - [Jeremy Seibert](https://www.kaggle.com/jaseibert)
 - [Jeremy Wang](https://www.kaggle.com/jeremy4555)
 - [jeremymiles](https://www.kaggle.com/jeremymiles)
 - [JeremyWickman](https://www.kaggle.com/jeremywickman)
 - [Jerrin Joe Varghese](https://www.kaggle.com/jerrinv)
 - [jerryg](https://www.kaggle.com/gaojianj96)
 - [JerryWang](https://www.kaggle.com/miningjerry)
 - [Jesse Montgomery](https://www.kaggle.com/jlmontie)
 - [Jessica Yung](https://www.kaggle.com/jessicayung)
 - [Jessie-Raye Bauer](https://www.kaggle.com/jrbauer)
 - [Jesus Jara LÃ³pez](https://www.kaggle.com/jesusjara)
 - [Jesus Santander](https://www.kaggle.com/rymnikski)
 - [Jguerreiro](https://www.kaggle.com/jguerreiro)
 - [JhonatanZubieta](https://www.kaggle.com/yosuer)
 - [JiachuanDeng](https://www.kaggle.com/jiachuandeng)
 - [JiaJane](https://www.kaggle.com/s663962004)
 - [Jiaming Huang](https://www.kaggle.com/hjmjerry)
 - [Jian W](https://www.kaggle.com/jhw6976)
 - [Jian Zhang](https://www.kaggle.com/jianzhang1)
 - [Jiang Yu](https://www.kaggle.com/nguwijy)
 - [jiangzuo](https://www.kaggle.com/jiangzuo)
 - [JiansheFeng](https://www.kaggle.com/jianshefeng)
 - [Jibsgrl](https://www.kaggle.com/jibsgrl)
 - [Jigarkumar Patel](https://www.kaggle.com/jigarpatel)
 - [Jihane HAMMOUT](https://www.kaggle.com/jhammout)
 - [Jihye Sofia Seo](https://www.kaggle.com/jihyeseo)
 - [Jiji](https://www.kaggle.com/daifarij)
 - [Jill_M](https://www.kaggle.com/jillm5)
 - [JimmyMarguerite](https://www.kaggle.com/djim02)
 - [Jin Liu](https://www.kaggle.com/jinliu)
 - [Jin-HwaChiu](https://www.kaggle.com/jhchiuh)
 - [Jindong Wang](https://www.kaggle.com/jindongwang92)
 - [Jindra Lacko](https://www.kaggle.com/jlacko)
 - [jinesh John](https://www.kaggle.com/jinesh777)
 - [Jing Zhang](https://www.kaggle.com/jingzbu)
 - [Jing](https://www.kaggle.com/jinghuang)
 - [JingdaZhou](https://www.kaggle.com/zhou854)
 - [jingjuewang](https://www.kaggle.com/juejuewang)
 - [jingli](https://www.kaggle.com/jacklizhi)
 - [jingwang](https://www.kaggle.com/evelynwang16)
 - [Jinner](https://www.kaggle.com/what0919)
 - [Jinsoo Yeo](https://www.kaggle.com/jinsooyeo)
 - [Jinze He](https://www.kaggle.com/jinze1234599)
 - [Jiri Roznovjak](https://www.kaggle.com/jiriroz)
 - [Jirka Vrany](https://www.kaggle.com/jirivrany)
 - [Jitendra Rajpurohit](https://www.kaggle.com/jitendra1998)
 - [JitendraKumarBansal](https://www.kaggle.com/jbansal)
 - [jiuzhang](https://www.kaggle.com/jiuzhang)
 - [jjjooo1](https://www.kaggle.com/jjjooo1)
 - [JLucas](https://www.kaggle.com/jlucas)
 - [jmataya](https://www.kaggle.com/jmataya)
 - [JO-Team](https://www.kaggle.com/melissaangel)
 - [JoÃ£o Pedro Peinado](https://www.kaggle.com/joaopmpeinado)
 - [Joao Januario](https://www.kaggle.com/joaojanuario)
 - [Joao Pedro Evangelista](https://www.kaggle.com/joaoevangelista)
 - [JobsPikr](https://www.kaggle.com/JobsPikrHQ)
 - [Joe Kim](https://www.kaggle.com/joewkim)
 - [Joe Philleo](https://www.kaggle.com/joephilleo)
 - [Joe Ramir](https://www.kaggle.com/jraramirez)
 - [Joe Young](https://www.kaggle.com/jsphyg)
 - [joejoe](https://www.kaggle.com/joejoe2)
 - [Joel Jacobsen](https://www.kaggle.com/jej13b)
 - [Joel Lee](https://www.kaggle.com/jzerox2)
 - [Joel Wilson](https://www.kaggle.com/joelwilson)
 - [joeland209](https://www.kaggle.com/joeland209)
 - [Joerg Simon Wicker](https://www.kaggle.com/jswicker)
 - [joeymeyer](https://www.kaggle.com/joeymeyer)
 - [Joffles](https://www.kaggle.com/kembles5)
 - [Johannes Plambeck](https://www.kaggle.com/jplambeck)
 - [JohannesBuchner](https://www.kaggle.com/jbuchner)
 - [JohanneslaPoutre](https://www.kaggle.com/jlapoutre)
 - [John Bourassa](https://www.kaggle.com/johink)
 - [John Doe](https://www.kaggle.com/gwhittington)
 - [John Doe](https://www.kaggle.com/heyushin)
 - [John Doe](https://www.kaggle.com/mimlmmj01ky8aka4)
 - [john doe](https://www.kaggle.com/z3r0s3c0)
 - [john joe](https://www.kaggle.com/missedsss)
 - [John Jones](https://www.kaggle.com/jajones1097)
 - [John Lin](https://www.kaggle.com/ironcrow)
 - [John Mark](https://www.kaggle.com/juandimarq)
 - [John Olafenwa](https://www.kaggle.com/johnolafenwa)
 - [John Ostrowski](https://www.kaggle.com/ostrowski)
 - [John Ruth](https://www.kaggle.com/johnruth)
 - [John Sumerel](https://www.kaggle.com/johnluke999)
 - [John Traavis](https://www.kaggle.com/mvsk93)
 - [John Wu](https://www.kaggle.com/leapoahead)
 - [john](https://www.kaggle.com/devilvrs)
 - [John](https://www.kaggle.com/qeyzn2143)
 - [John](https://www.kaggle.com/yszhong)
 - [john2](https://www.kaggle.com/z3r0s3c)
 - [JohnCurcio](https://www.kaggle.com/jcurcio)
 - [Johnd](https://www.kaggle.com/samuel86)
 - [johndebugger](https://www.kaggle.com/johnzyh)
 - [JohnHeyrich](https://www.kaggle.com/johnney12)
 - [JohnJayChou&MichelleZhuang](https://www.kaggle.com/John-Michelle)
 - [JohnnyHa](https://www.kaggle.com/johnnyjai)
 - [JohnWorne](https://www.kaggle.com/johnworne)
 - [JohnX](https://www.kaggle.com/kennethjohn)
 - [jolhe006](https://www.kaggle.com/jolhe006)
 - [jomendes](https://www.kaggle.com/jomendes)
 - [Jon B](https://www.kaggle.com/derpferd)
 - [Jon Hong](https://www.kaggle.com/jonmhong)
 - [jon.bill](https://www.kaggle.com/iwilldoit)
 - [Jonah Mary17](https://www.kaggle.com/jonahmary17)
 - [jonahelisio](https://www.kaggle.com/jonahelisio)
 - [Jonatan Cisneros](https://www.kaggle.com/jonatancr)
 - [Jonathan](https://www.kaggle.com/jonathankeith)
 - [Jonathan](https://www.kaggle.com/jonomendelson)
 - [JonathanPhoon](https://www.kaggle.com/jphoon)
 - [Jones](https://www.kaggle.com/marshald)
 - [Jonh Doe](https://www.kaggle.com/msusername)
 - [JoniHoppen](https://www.kaggle.com/joniarroba)
 - [JoostLubach](https://www.kaggle.com/joostlubach)
 - [Jordan Goblet](https://www.kaggle.com/jordangoblet)
 - [Jordan Meta](https://www.kaggle.com/jordan26)
 - [Jordan Tremoureux](https://www.kaggle.com/jtremoureux)
 - [JorgeZazueta](https://www.kaggle.com/zazueta)
 - [JosÄ—AndrÄ—sAlvarezCabrera](https://www.kaggle.com/josealvarez97)
 - [JosÃ© Vicente](https://www.kaggle.com/pepe93)
 - [JosÃ©Prado](https://www.kaggle.com/xpecttrum)
 - [Jose Berengueres](https://www.kaggle.com/harriken)
 - [Jose Fco Morales](https://www.kaggle.com/jos3fc0)
 - [Jose Lery Nunes](https://www.kaggle.com/lerynunes)
 - [Jose Luis Juarez Ruelas](https://www.kaggle.com/imajor)
 - [Jose Manuel Vera](https://www.kaggle.com/jomavera)
 - [Jose Toro](https://www.kaggle.com/soulstuff)
 - [jose](https://www.kaggle.com/josemayorga)
 - [Josep A.](https://www.kaggle.com/josepandreu)
 - [Joseph Leichter](https://www.kaggle.com/joeleichter)
 - [Joseph](https://www.kaggle.com/josephshieh)
 - [JosephBae](https://www.kaggle.com/joebae)
 - [Josh Haimson](https://www.kaggle.com/joshhaimson)
 - [Josh Wheeler](https://www.kaggle.com/slaffterphish)
 - [josh woulfe](https://www.kaggle.com/woulfe64)
 - [josh777](https://www.kaggle.com/josh777)
 - [joshkyh](https://www.kaggle.com/joshkyh)
 - [JoshMcKenney](https://www.kaggle.com/jmckenney1)
 - [Joshua Schnessl](https://www.kaggle.com/jschnessl)
 - [joshuaherman](https://www.kaggle.com/aconsapart)
 - [JosS](https://www.kaggle.com/josdatalake)
 - [jossssss](https://www.kaggle.com/joswx21)
 - [JPSS](https://www.kaggle.com/jatindersehdev)
 - [jr91](https://www.kaggle.com/jacobrichards91)
 - [jruots](https://www.kaggle.com/jruots)
 - [jruvika](https://www.kaggle.com/jruvika)
 - [jrvalentin](https://www.kaggle.com/jrvalentin)
 - [jscharbach](https://www.kaggle.com/jscharbach)
 - [Juan Corporan](https://www.kaggle.com/siriuscorp)
 - [Juan R](https://www.kaggle.com/merkabahnk)
 - [JUAN SOLER-COMPANY](https://www.kaggle.com/joansolcom)
 - [JuanRodriguez](https://www.kaggle.com/juanroma)
 - [Juanu](https://www.kaggle.com/juanumusic)
 - [jujuuu](https://www.kaggle.com/jujuuu)
 - [Julian Christov](https://www.kaggle.com/jchristov)
 - [Julian Simon de Castro](https://www.kaggle.com/juliansimon)
 - [julie](https://www.kaggle.com/juliecav)
 - [Julien Frisch](https://www.kaggle.com/jfrisch)
 - [Jun Zhu](https://www.kaggle.com/nookki)
 - [Juncheng ZHOU](https://www.kaggle.com/junchengzhou)
 - [Junfeng Zhang](https://www.kaggle.com/junfeng142857)
 - [JuniaGeorge](https://www.kaggle.com/juniag11)
 - [Junki Cho](https://www.kaggle.com/jungi21cc)
 - [Juran](https://www.kaggle.com/littlewhilte)
 - [Just try](https://www.kaggle.com/helensy)
 - [Justin Pan](https://www.kaggle.com/justinpan)
 - [JustinMoore](https://www.kaggle.com/lazyjustin)
 - [JuturuPavan](https://www.kaggle.com/juturu97)
 - [jvent](https://www.kaggle.com/jessevent)
 - [jvm56](https://www.kaggle.com/jvm056)
 - [Jwuthrich](https://www.kaggle.com/jwuthrich)
 - [Jyothi Kamakshi](https://www.kaggle.com/jyothikamakshi)
 - [Jyoti Sharma](https://www.kaggle.com/jyoti1706)
 - [Jyun-Ting](https://www.kaggle.com/b04202048)
 - [jyzaguirre](https://www.kaggle.com/jyzaguirre)
 - [JZ2771](https://www.kaggle.com/jz2771)
 - [k6box](https://www.kaggle.com/bjaton)
 - [KÃ¤rt](https://www.kaggle.com/kartilja)
 - [KÃ¢zÄ±m AnÄ±l Eren](https://www.kaggle.com/kazimanil)
 - [Kaan Can](https://www.kaggle.com/kanncaa1)
 - [Kaan Ulgen](https://www.kaggle.com/kulgen)
 - [kaffes](https://www.kaggle.com/kaffes)
 - [kagami](https://www.kaggle.com/kagami)
 - [Kaggle](https://www.kaggle.com/kaggle)
 - [KaggleRay](https://www.kaggle.com/kaggleray)
 - [kaguser](https://www.kaggle.com/kaguser)
 - [kaho](https://www.kaggle.com/sdcskaho)
 - [Kai Wang](https://www.kaggle.com/wangk4)
 - [Kaique da Silva](https://www.kaggle.com/kdwyzstk)
 - [Kairit](https://www.kaggle.com/kpeekman)
 - [kajot](https://www.kaggle.com/piotrgrabo)
 - [kalcal](https://www.kaggle.com/kalcal)
 - [KalyanYerra](https://www.kaggle.com/yerra1)
 - [Kamal raj](https://www.kaggle.com/kamalkraj)
 - [Kamau John](https://www.kaggle.com/sophicist)
 - [kambarakun](https://www.kaggle.com/kambarakun)
 - [kamesh s](https://www.kaggle.com/kameshsoft)
 - [Kamil Jurek](https://www.kaggle.com/kamiljurek)
 - [Kamil Kaczmarek](https://www.kaggle.com/kamilkk)
 - [Kamlesh](https://www.kaggle.com/iamkamleshrangi)
 - [kamran](https://www.kaggle.com/kamrankausar)
 - [Kande Bonfim](https://www.kaggle.com/kandebonfim)
 - [Kane](https://www.kaggle.com/kaneca)
 - [Kanika Narang](https://www.kaggle.com/kanikanarang94)
 - [KanikaChopra](https://www.kaggle.com/kanikachopra)
 - [Kanishka Misra](https://www.kaggle.com/kanishkamisra)
 - [KanishkPratapSingh](https://www.kaggle.com/kanishkapsingh)
 - [KannanPiedy](https://www.kaggle.com/kenstars)
 - [Karamveer](https://www.kaggle.com/karamveer)
 - [Karan Thakkar](https://www.kaggle.com/thakkark1313)
 - [KaranSharma](https://www.kaggle.com/karan1276)
 - [KardoPaska](https://www.kaggle.com/kardopaska)
 - [KarelVerhoeven](https://www.kaggle.com/karelrv)
 - [Karim Ardi](https://www.kaggle.com/fadomp)
 - [KarimBELAYATI](https://www.kaggle.com/belayati)
 - [KarimNahas](https://www.kaggle.com/karimnahas)
 - [Karmanya Aggarwal](https://www.kaggle.com/calmdownkarm)
 - [KarmoT](https://www.kaggle.com/tarmokullas)
 - [Karolina Wullum](https://www.kaggle.com/kwullum)
 - [Kartheek](https://www.kaggle.com/kartheek588)
 - [karthickveerakumar](https://www.kaggle.com/karthickveerakumar)
 - [KarthickVel](https://www.kaggle.com/kkarthick12)
 - [karthik](https://www.kaggle.com/karthik10111)
 - [Karthiks](https://www.kaggle.com/kar446)
 - [karthikziffer](https://www.kaggle.com/karthikziffer)
 - [Kartik](https://www.kaggle.com/kartik71)
 - [KartikPatnaik](https://www.kaggle.com/numberswithkartik)
 - [kashif kaleem](https://www.kaggle.com/kashifkaleem)
 - [Kashish Suneja](https://www.kaggle.com/kashish52)
 - [kashyap](https://www.kaggle.com/prashantkashyap)
 - [Kasper Nielsen](https://www.kaggle.com/kappernielsen)
 - [Kate](https://www.kaggle.com/katerynad)
 - [Katrina Ni](https://www.kaggle.com/katrinadataing)
 - [katzwigmore](https://www.kaggle.com/katzwigmore)
 - [Kaus](https://www.kaggle.com/kaus19)
 - [Kaushik S](https://www.kaggle.com/kaushik3497)
 - [Kaveti Naveen Kumar](https://www.kaggle.com/naveenkaveti)
 - [Kaylan Foster](https://www.kaggle.com/kfoster)
 - [Kayode Emmanuel Oluwatobi](https://www.kaggle.com/tobinfinity)
 - [Kazuki](https://www.kaggle.com/gotoukaz)
 - [KedanLi](https://www.kaggle.com/likedan55)
 - [Keelan Robinson](https://www.kaggle.com/keelanrobinson)
 - [Keheira](https://www.kaggle.com/keheira)
 - [Keik@](https://www.kaggle.com/lucianakeiko)
 - [keisei](https://www.kaggle.com/keisei)
 - [Keita Shimizu](https://www.kaggle.com/keitashimizu)
 - [Kelvin Wellington](https://www.kaggle.com/odartey)
 - [Kelvin Xiao](https://www.kaggle.com/xiaotawkaggle)
 - [Kemal Yilmaz](https://www.kaggle.com/kemaly)
 - [Kemical](https://www.kaggle.com/kemical)
 - [Ken Yamaji](https://www.kaggle.com/kenyam)
 - [KendallGillies](https://www.kaggle.com/kendallgillies)
 - [KenichiNakatani](https://www.kaggle.com/kenichinakatani)
 - [Kenji Kondo](https://www.kaggle.com/kkondo)
 - [Kenneth Benavides](https://www.kaggle.com/dragondeldesierto)
 - [Kenneth Chua](https://www.kaggle.com/kencjy)
 - [kenomaru](https://www.kaggle.com/kenomaru)
 - [KentaroTakemoto](https://www.kaggle.com/takemoto)
 - [Kenton W. Murray](https://www.kaggle.com/kentonnlp)
 - [Keras](https://www.kaggle.com/keras)
 - [Keval M](https://www.kaggle.com/kevalm)
 - [Kevin ](https://www.kaggle.com/kevin11522914)
 - [Kevin Chow](https://www.kaggle.com/kchow23)
 - [Kevin Mader](https://www.kaggle.com/kmader)
 - [Kevin Mario Gerard](https://www.kaggle.com/kevinmariogerard)
 - [Kevin Moodley](https://www.kaggle.com/kevinmgp)
 - [Kevin Pertsovsky](https://www.kaggle.com/kpertsovsky)
 - [Kevin Ree](https://www.kaggle.com/kevinree)
 - [Kevin Soucy](https://www.kaggle.com/kevinsoucy)
 - [Kevin](https://www.kaggle.com/kevinv)
 - [kevin](https://www.kaggle.com/lijiangwei)
 - [Kevin](https://www.kaggle.com/taiden)
 - [KevinH](https://www.kaggle.com/kevinmh)
 - [kevv](https://www.kaggle.com/kevvvv)
 - [Khac Bao Anh NGUYEN](https://www.kaggle.com/baoanh)
 - [Khai Xiang](https://www.kaggle.com/eigenvectors)
 - [khaled salah](https://www.kaggle.com/bekaaa)
 - [Khashayar Baghizadeh Hosseini](https://www.kaggle.com/heptapod)
 - [Kheirallah Samaha](https://www.kaggle.com/khsamaha)
 - [Khepry Quixote](https://www.kaggle.com/khepryquixote)
 - [Khushboo](https://www.kaggle.com/khushboosrivastava2)
 - [Kiefer Smith](https://www.kaggle.com/ksmith)
 - [Kilian Batzner](https://www.kaggle.com/batzner)
 - [Kilian. O](https://www.kaggle.com/brindesable)
 - [Kim Schreier](https://www.kaggle.com/scki1016)
 - [Kimos](https://www.kaggle.com/kimosoo)
 - [Kimura](https://www.kaggle.com/nocotan)
 - [Kingsley Samuel](https://www.kaggle.com/kelvinkins)
 - [Kiran Ganji](https://www.kaggle.com/kiranganji99)
 - [Kiran Gutha](https://www.kaggle.com/gkiranseo)
 - [KiranKarri](https://www.kaggle.com/kirankarri)
 - [KirthikaBabu](https://www.kaggle.com/kirthi2609)
 - [Kishan P](https://www.kaggle.com/omsairam)
 - [kishore](https://www.kaggle.com/fuck123)
 - [Kittisak](https://www.kaggle.com/kittisaks)
 - [kiweee](https://www.kaggle.com/kiweee)
 - [KiyonariHarigae](https://www.kaggle.com/cloudysunny14)
 - [KK](https://www.kaggle.com/kilimnik)
 - [KK](https://www.kaggle.com/kkonakan)
 - [KK16](https://www.kaggle.com/kkanda)
 - [KKDDAll](https://www.kaggle.com/c55303)
 - [kktestin2'""](https://www.kaggle.com/kktesting2)
 - [Kleber Bernardo](https://www.kaggle.com/kleberbernardo)
 - [km1west](https://www.kaggle.com/km1west)
 - [KMMR](https://www.kaggle.com/kruark)
 - [Kmuvunyi](https://www.kaggle.com/kmuvunyi)
 - [Kola Adebayo](https://www.kaggle.com/adekola)
 - [Kondalarao Vonteru](https://www.kaggle.com/sunnysai12345)
 - [Konstantin Lopuhin](https://www.kaggle.com/lopuhin)
 - [Konstantin](https://www.kaggle.com/iskynet)
 - [Konstantinos Bazakos](https://www.kaggle.com/thebuzz)
 - [Korakot Chaovavanich](https://www.kaggle.com/korakot)
 - [Kory Becker](https://www.kaggle.com/primaryobjects)
 - [kosiewmm](https://www.kaggle.com/kosiewmm)
 - [Kostiantyn Isaienkov](https://www.kaggle.com/isaienkov)
 - [Kostya](https://www.kaggle.com/ktochylin)
 - [Kote42](https://www.kaggle.com/nbolton04)
 - [Kotobotov](https://www.kaggle.com/kotobotov)
 - [KOUASSI Konan Jean-Claude](https://www.kaggle.com/kjeanclaude)
 - [Kozlova](https://www.kaggle.com/geitursdottir)
 - [KP](https://www.kaggle.com/skihikingkevin)
 - [kpapamih](https://www.kaggle.com/kpapamih)
 - [kravdiy](https://www.kaggle.com/kravdiy)
 - [Krishna Agarwal](https://www.kaggle.com/kriaga)
 - [Krishna Bharadwaj](https://www.kaggle.com/bharadwajpro)
 - [KrishnaDheeraj](https://www.kaggle.com/dheerajkrishna90)
 - [Krishnan](https://www.kaggle.com/krishnansailam)
 - [KrishnaPraveen](https://www.kaggle.com/felicis)
 - [KrishnaThiyagarajan](https://www.kaggle.com/krisht)
 - [KrisMurphy](https://www.kaggle.com/krismurphy01)
 - [Kristian H](https://www.kaggle.com/morphlng7)
 - [Kristjan PÃ¤rn](https://www.kaggle.com/kraalike)
 - [KristofferHess](https://www.kaggle.com/kristofferhess)
 - [Kristopher Sheets, PhD](https://www.kaggle.com/sheetskg)
 - [Krithel](https://www.kaggle.com/krithel)
 - [KrizsÃ³ Gergely](https://www.kaggle.com/lucifer19)
 - [krsimons](https://www.kaggle.com/krsimons)
 - [ksayantani](https://www.kaggle.com/ksayantani)
 - [Ksenia Sukhova](https://www.kaggle.com/tovarischsukhov)
 - [kso.](https://www.kaggle.com/fanatiks)
 - [kumar abhishek](https://www.kaggle.com/kumarabhishekone)
 - [Kumar Nityan Suman](https://www.kaggle.com/knityansuman)
 - [Kumar](https://www.kaggle.com/amitabh08)
 - [Kumaran K](https://www.kaggle.com/kumarandatascientist)
 - [kumarbhrgv](https://www.kaggle.com/kumarbhrgv)
 - [KumarHalake](https://www.kaggle.com/kumarhalake)
 - [Kunal Kotian](https://www.kaggle.com/kunalkotian)
 - [Kunal Singh](https://www.kaggle.com/kunaliitkgp)
 - [Kunal Vaishnavi](https://www.kaggle.com/kunalvaishnavi)
 - [kunalkumawat](https://www.kaggle.com/kunalkk99)
 - [kunimune](https://www.kaggle.com/muni0893)
 - [Kuntal Sardar](https://www.kaggle.com/kuntalcse006)
 - [Kushal](https://www.kaggle.com/pkushal)
 - [Kushneryk Pavel](https://www.kaggle.com/kushneryk)
 - [KutsalBaranÃ–zkurt](https://www.kaggle.com/makerb)
 - [kveykva](https://www.kaggle.com/kveykva)
 - [kvpratama](https://www.kaggle.com/kvpratama)
 - [Kwan Lowe](https://www.kaggle.com/digitalhermit)
 - [kwangrok lee](https://www.kaggle.com/krleee)
 - [kwtcut](https://www.kaggle.com/kwtcut)
 - [Kyle McClurg](https://www.kaggle.com/kmcclurg)
 - [kyle moon](https://www.kaggle.com/mooneruma)
 - [L Sun](https://www.kaggle.com/luelly)
 - [La Sul](https://www.kaggle.com/laoralipow)
 - [LA Times Data Desk](https://www.kaggle.com/la-times)
 - [Lacie ](https://www.kaggle.com/laciecool)
 - [LacksonMundira](https://www.kaggle.com/lmundira)
 - [LAdams](https://www.kaggle.com/laa283)
 - [lahouarami](https://www.kaggle.com/lahouarami)
 - [LaiyiLin](https://www.kaggle.com/lylin84)
 - [lakshadvani](https://www.kaggle.com/lakshadvani)
 - [Lakshya Khandelwal](https://www.kaggle.com/lakshyak)
 - [Lalit Khandelwal](https://www.kaggle.com/lalitkhandelwal)
 - [Lalit Parihar](https://www.kaggle.com/lalitparihar44)
 - [lalitsomnathe](https://www.kaggle.com/lalitsomnathe)
 - [lalthan](https://www.kaggle.com/lalthan)
 - [lamda-dev](https://www.kaggle.com/lamdadev)
 - [langzi](https://www.kaggle.com/q525614)
 - [Lantana Camara](https://www.kaggle.com/lantanacamara)
 - [LanVukuÅ¡iÄ](https://www.kaggle.com/lanls1)
 - [Lasteg](https://www.kaggle.com/zxspectrum)
 - [LastJedi76](https://www.kaggle.com/romuloflores)
 - [Laura](https://www.kaggle.com/lctc12)
 - [Laurae](https://www.kaggle.com/laurae2)
 - [LauraMoen](https://www.kaggle.com/moenl742)
 - [Lauren BK](https://www.kaggle.com/laurenbk)
 - [Laurenstc](https://www.kaggle.com/laurenstc)
 - [LaurentBerder](https://www.kaggle.com/lberder)
 - [lavi](https://www.kaggle.com/anchal479)
 - [LavishGulati](https://www.kaggle.com/lavishgulati)
 - [lazkol](https://www.kaggle.com/lazkol)
 - [LE PALLEC ClÃ©ment](https://www.kaggle.com/clementlepallec)
 - [Leandro dos Santos Coelho](https://www.kaggle.com/lscoelho)
 - [Leandro Silva](https://www.kaggle.com/leandrodoze)
 - [Learner](https://www.kaggle.com/gaurav2555)
 - [Lee Worthington](https://www.kaggle.com/lworthington)
 - [LeeYun](https://www.kaggle.com/leeyun)
 - [lefant](https://www.kaggle.com/lefant)
 - [Lehmaudar](https://www.kaggle.com/lehmaudar)
 - [Lei Ding](https://www.kaggle.com/bigding)
 - [leigh](https://www.kaggle.com/ljewell)
 - [Leo Arruda](https://www.kaggle.com/leoarruda)
 - [Leo](https://www.kaggle.com/tondji)
 - [Leon Martin ](https://www.kaggle.com/leonmartin)
 - [Leon](https://www.kaggle.com/laleon)
 - [Leonardo Ferreira](https://www.kaggle.com/kabure)
 - [Leonidas](https://www.kaggle.com/nnair25)
 - [LeonPaul](https://www.kaggle.com/leonpaul93)
 - [Leroberge](https://www.kaggle.com/leroberge)
 - [Lesoler](https://www.kaggle.com/lesoler)
 - [LesPaulCustom](https://www.kaggle.com/lespaulcustom)
 - [LeticiaFilgueiras](https://www.kaggle.com/filgueirasl)
 - [LeviMa](https://www.kaggle.com/levima)
 - [Lewis](https://www.kaggle.com/lewisyang)
 - [Lexie Dempsey](https://www.kaggle.com/ard5001)
 - [Lgpatel](https://www.kaggle.com/lgp33333)
 - [Liam Cusack](https://www.kaggle.com/lrcusack)
 - [LiamLarsen](https://www.kaggle.com/kingburrito666)
 - [librahu](https://www.kaggle.com/librahu)
 - [Lieven23](https://www.kaggle.com/lieven23)
 - [light-boat](https://www.kaggle.com/lightcc)
 - [lihan](https://www.kaggle.com/llihan)
 - [Lihaoyang](https://www.kaggle.com/gerryl)
 - [Liisi](https://www.kaggle.com/liisirammo)
 - [LiLi](https://www.kaggle.com/lorcha)
 - [Liling Tan](https://www.kaggle.com/alvations)
 - [Lilit Janjughazyan](https://www.kaggle.com/ljanjughazyan)
 - [limi44](https://www.kaggle.com/limi44)
 - [Liming](https://www.kaggle.com/tongjiyiming)
 - [limmen](https://www.kaggle.com/limmen)
 - [Limon M](https://www.kaggle.com/limonm)
 - [Lin Gao](https://www.kaggle.com/gao297)
 - [Lin Ying Lung](https://www.kaggle.com/shadowkshs)
 - [lincoln](https://www.kaggle.com/bharaniabhishek123)
 - [Lindada](https://www.kaggle.com/a763337092)
 - [Lingzhi](https://www.kaggle.com/vrtjso)
 - [LinkanRay](https://www.kaggle.com/linkanray)
 - [Lisa](https://www.kaggle.com/arpitajena)
 - [lisjin](https://www.kaggle.com/lisjin)
 - [Lislejoem](https://www.kaggle.com/lislejoem)
 - [Lissette Guzman](https://www.kaggle.com/lissetteg)
 - [litianyi](https://www.kaggle.com/evelisky)
 - [Little Boat](https://www.kaggle.com/xiaozhouwang)
 - [Litu Rout](https://www.kaggle.com/liturout)
 - [liuenda](https://www.kaggle.com/liuenda)
 - [liuxiaoliu](https://www.kaggle.com/hana0211)
 - [LiuYang](https://www.kaggle.com/liuyangbeta)
 - [liuyongqi](https://www.kaggle.com/baodier)
 - [liuzhe0125](https://www.kaggle.com/liuzhe0125)
 - [livi](https://www.kaggle.com/livvlivi)
 - [liwste](https://www.kaggle.com/liwste)
 - [Liza Bolton](https://www.kaggle.com/dataembassy)
 - [ljhuang](https://www.kaggle.com/cshlj199)
 - [lkytal](https://www.kaggle.com/lkytal)
 - [lnicalo](https://www.kaggle.com/lnicalo)
 - [LogHorizon](https://www.kaggle.com/loghorizon)
 - [logwinner](https://www.kaggle.com/hassanouda)
 - [lohith](https://www.kaggle.com/lohitharcot)
 - [lomungo](https://www.kaggle.com/lomungo)
 - [looo](https://www.kaggle.com/luogangnk)
 - [Lorna Maria](https://www.kaggle.com/lornamariak)
 - [Louis Marmet](https://www.kaggle.com/marmetl)
 - [louis](https://www.kaggle.com/louissg)
 - [Louis](https://www.kaggle.com/ttetls)
 - [LouweAL](https://www.kaggle.com/anneloes)
 - [loyf](https://www.kaggle.com/lclave)
 - [LPitre](https://www.kaggle.com/lpitre)
 - [LuanHo](https://www.kaggle.com/luanho)
 - [LuÃ­s Gustavo Modelli](https://www.kaggle.com/gustavomodelli)
 - [lubaroli](https://www.kaggle.com/lubaroli)
 - [Lucas Astorian](https://www.kaggle.com/lucasastorian)
 - [Lucas Dixon](https://www.kaggle.com/iislucas)
 - [Lucas Erring](https://www.kaggle.com/drlucaserring)
 - [Lucas Venezian Povoa](https://www.kaggle.com/lucasvenez)
 - [Lucas Vergeest](https://www.kaggle.com/lucasvergeest)
 - [Lucas](https://www.kaggle.com/nordstjernen)
 - [LucasVinze](https://www.kaggle.com/vinchinzu)
 - [Lucio LÃ³pez Lecube](https://www.kaggle.com/lucio1)
 - [Ludovic benistant](https://www.kaggle.com/ludobenistant)
 - [Lugark](https://www.kaggle.com/lugark)
 - [Luigi](https://www.kaggle.com/luigimersico)
 - [Luis Andre Dutra e Silva](https://www.kaggle.com/mindcool)
 - [Luis Bronchal](https://www.kaggle.com/lbronchal)
 - [Luis Moneda](https://www.kaggle.com/lgmoneda)
 - [LuisaAPF](https://www.kaggle.com/luisaapf)
 - [luistelmocosta](https://www.kaggle.com/luistelmocosta)
 - [Luiz Gerosa](https://www.kaggle.com/gerosa)
 - [Luiz Gustavo Schiller](https://www.kaggle.com/schiller)
 - [Luiz Henrique Amorim](https://www.kaggle.com/luizoamorim)
 - [Luiza Fontana](https://www.kaggle.com/zafontana)
 - [Luke Bunge](https://www.kaggle.com/lukebunge14)
 - [Luke Godwin-Jones](https://www.kaggle.com/lagodw)
 - [lukebyrne](https://www.kaggle.com/lukebyrne)
 - [LukeLee](https://www.kaggle.com/infgeoax)
 - [Lumin](https://www.kaggle.com/lumins)
 - [LunarLlama](https://www.kaggle.com/lunarllama)
 - [Luu](https://www.kaggle.com/namluu)
 - [LyAhmedTidiane](https://www.kaggle.com/tizezie)
 - [lyh19970409](https://www.kaggle.com/lyuyanhan)
 - [Lynn dai](https://www.kaggle.com/lynndai)
 - [LynnPan](https://www.kaggle.com/lynnpan168)
 - [M Baddar](https://www.kaggle.com/baddar)
 - [M Ganiyu](https://www.kaggle.com/mascotinme)
 - [M.F.](https://www.kaggle.com/mfrincu)
 - [maarten](https://www.kaggle.com/maartenko)
 - [Mabs](https://www.kaggle.com/mabs003)
 - [MACHINE LEARNING DATASETS](https://www.kaggle.com/pitasr)
 - [Maciej Witkowiak](https://www.kaggle.com/ytmytm)
 - [Mad Hab](https://www.kaggle.com/madhab)
 - [Madhan Varadhodiyil](https://www.kaggle.com/varadhodiyil)
 - [Madhav Iyengar](https://www.kaggle.com/madhavthegod)
 - [Madhavi  Burra](https://www.kaggle.com/madhaviburra)
 - [Madhur Inani](https://www.kaggle.com/madhurinani)
 - [Madis_Lemsalu](https://www.kaggle.com/madislemsalu)
 - [Madison Curtis](https://www.kaggle.com/mfc5300)
 - [MadScientist](https://www.kaggle.com/keremt)
 - [Maghilnan](https://www.kaggle.com/maghilnan)
 - [MagicK](https://www.kaggle.com/katedubbs)
 - [Magsgiust ](https://www.kaggle.com/magsgiust)
 - [Mahadevan](https://www.kaggle.com/mahadevansv)
 - [MahdiJavid](https://www.kaggle.com/mahdijavid)
 - [Mahdy Nabaee](https://www.kaggle.com/mnabaee)
 - [Mahek Hooda](https://www.kaggle.com/mahekhooda)
 - [Mahesh Sinha](https://www.kaggle.com/maheshsinha)
 - [Mahesh_PRS](https://www.kaggle.com/maheshprs)
 - [MahirKukreja](https://www.kaggle.com/mahirkukreja)
 - [Mahmoud Aljabary](https://www.kaggle.com/maljabary)
 - [MahreenAhmed](https://www.kaggle.com/mahreen)
 - [maik3141](https://www.kaggle.com/maik3141)
 - [Mainak kUNDU](https://www.kaggle.com/mainakdatageek)
 - [Maitree Priyadarsini](https://www.kaggle.com/maitree)
 - [MakarandVelankar](https://www.kaggle.com/makvel)
 - [Maksim Mikhotov](https://www.kaggle.com/mmikhotov)
 - [Maksym](https://www.kaggle.com/intell)
 - [Malathi Arumugam](https://www.kaggle.com/malathiarumugam)
 - [Malek Trabelsi](https://www.kaggle.com/malektrabelsi)
 - [Malinee Fawcett](https://www.kaggle.com/malineef)
 - [Malini](https://www.kaggle.com/malinikocheri)
 - [Mamun](https://www.kaggle.com/mdmahmudulalam)
 - [Manan Jain](https://www.kaggle.com/mananjain)
 - [Manan Manwani](https://www.kaggle.com/manan904)
 - [Manas](https://www.kaggle.com/manasgarg)
 - [Manav Sehgal](https://www.kaggle.com/startupsci)
 - [mancml](https://www.kaggle.com/hhmanlee)
 - [Manfredi Federico Pivetta ](https://www.kaggle.com/manfredipivetta)
 - [Mani](https://www.kaggle.com/dmvreddy91)
 - [MANIKANTA](https://www.kaggle.com/mani443)
 - [ManikHossain](https://www.kaggle.com/manik500)
 - [Manimala](https://www.kaggle.com/vikrishnan)
 - [Manish jain](https://www.kaggle.com/manishjain15051982)
 - [Manish Kumar](https://www.kaggle.com/mkagenius)
 - [Manjeet Singh](https://www.kaggle.com/manjeetsingh)
 - [Manoj Kumar](https://www.kaggle.com/sumanoj23)
 - [manoj2891](https://www.kaggle.com/manoj2891)
 - [ManojHariharan](https://www.kaggle.com/manojhariharan)
 - [MANOJKUMAR PARMAR](https://www.kaggle.com/parmarmanojkumar)
 - [MANOJKUMAR](https://www.kaggle.com/manojk15)
 - [Manqiong](https://www.kaggle.com/manqiong)
 - [Manshubh Singh Rihal](https://www.kaggle.com/manshubh)
 - [Mansoor Iqbal](https://www.kaggle.com/mansoordaku)
 - [Mansour Movahhedinia](https://www.kaggle.com/mmovahhedinia)
 - [Mantas Zimnickas](https://www.kaggle.com/sirexo)
 - [Manuel Barrena](https://www.kaggle.com/mbarrenag)
 - [Mapik88](https://www.kaggle.com/mapik88)
 - [MarÃ­a Otero](https://www.kaggle.com/maotero)
 - [Marc Kossa](https://www.kaggle.com/marckossa)
 - [marc moreaux](https://www.kaggle.com/mmoreaux)
 - [Marc Robert](https://www.kaggle.com/vluijpen)
 - [Marc Slaughter](https://www.kaggle.com/marcslaughter)
 - [Marc Velmer](https://www.kaggle.com/marcvelmer)
 - [Marc](https://www.kaggle.com/marc45773)
 - [Marcel](https://www.kaggle.com/mkempers)
 - [Marcell ""Mazuh"" Guilherme Costa da Silva](https://www.kaggle.com/mazuh69)
 - [Marcelo Santos](https://www.kaggle.com/mefsantos)
 - [Marco Boaretto](https://www.kaggle.com/mboaretto)
 - [Marco De Nadai](https://www.kaggle.com/marcodena)
 - [Marco Molina](https://www.kaggle.com/marcomolina)
 - [Marco Zanchi](https://www.kaggle.com/inquisitivecrow)
 - [MarcoCarnini](https://www.kaggle.com/marcocarnini)
 - [Marcos Boaglio](https://www.kaggle.com/mboaglio)
 - [MarcSchroeder](https://www.kaggle.com/marcschroeder)
 - [MarcTorrellas](https://www.kaggle.com/marctorsoc)
 - [Marcus Lin](https://www.kaggle.com/marcuslin)
 - [Maria Bile](https://www.kaggle.com/mariabile)
 - [Maria Luiza](https://www.kaggle.com/marialuiza07)
 - [mariakatosvich](https://www.kaggle.com/qwikfix)
 - [Mariehane](https://www.kaggle.com/mariehane)
 - [Marielen Ferreira](https://www.kaggle.com/mferreira)
 - [Mario Navas](https://www.kaggle.com/mnavas)
 - [Mario Pasquato](https://www.kaggle.com/mariopasquato)
 - [Marius](https://www.kaggle.com/titamarius)
 - [Mark DiMarco](https://www.kaggle.com/markmarkoh)
 - [Mark Eldridge](https://www.kaggle.com/mkeldridge)
 - [Mark](https://www.kaggle.com/baileymm)
 - [MarkArchieGamayan](https://www.kaggle.com/markarchie)
 - [Marketing As Is](https://www.kaggle.com/bnguye05)
 - [Marko K](https://www.kaggle.com/knelle87)
 - [MarkSchultz](https://www.kaggle.com/schulm3)
 - [Markus Lang](https://www.kaggle.com/markuslang)
 - [Marlesson](https://www.kaggle.com/marlesson)
 - [Marouane Benmeida](https://www.kaggle.com/atmarouane)
 - [Martin Enzinger](https://www.kaggle.com/enzinger)
 - [Martin Pereira](https://www.kaggle.com/pera21)
 - [MartinBoyanov](https://www.kaggle.com/mboyanov)
 - [MartJ](https://www.kaggle.com/martj42)
 - [Marty](https://www.kaggle.com/mboren)
 - [marvin](https://www.kaggle.com/marvinlsj)
 - [Marwa Saied](https://www.kaggle.com/marwaf)
 - [masahito429](https://www.kaggle.com/masahito429)
 - [masakt](https://www.kaggle.com/masakt)
 - [Masato Hagiwara](https://www.kaggle.com/mhagiwara)
 - [Masato](https://www.kaggle.com/giwada)
 - [Masood Hussain](https://www.kaggle.com/masoodhussain)
 - [Massachusetts Institute of Technology](https://www.kaggle.com/mit)
 - [Masseycre](https://www.kaggle.com/masseyratings)
 - [Mateus](https://www.kaggle.com/mateus51)
 - [Mathew Savage](https://www.kaggle.com/mathewsavage)
 - [Mathias Meldgaard Pedersen](https://www.kaggle.com/mattidk)
 - [MathiasEdman](https://www.kaggle.com/skeletor)
 - [Mathieu Goutay](https://www.kaggle.com/mgoutay)
 - [Mathijs Waegemakers](https://www.kaggle.com/mathijs)
 - [mathishammel](https://www.kaggle.com/mathishammel)
 - [Mathurin AchÃ©](https://www.kaggle.com/mathurinache)
 - [matiasfeld](https://www.kaggle.com/feldmatias)
 - [matsueushi](https://www.kaggle.com/matsueushi)
 - [Matt Hixon](https://www.kaggle.com/mhixon)
 - [Matt Rose](https://www.kaggle.com/mattrose3)
 - [Matt Snell](https://www.kaggle.com/mattsnellaai)
 - [Matt](https://www.kaggle.com/mssilver)
 - [Matteo Casadei](https://www.kaggle.com/matteocasadei)
 - [Matteo_Mazzola](https://www.kaggle.com/ciotolaaaa)
 - [Matthew Allbee](https://www.kaggle.com/grafs50)
 - [Matthew Anderson](https://www.kaggle.com/matthewa313)
 - [Matthew Carter](https://www.kaggle.com/mattcarter865)
 - [matthew](https://www.kaggle.com/matthewweb)
 - [MatthewHonnibal](https://www.kaggle.com/honnibal)
 - [Matthieu C](https://www.kaggle.com/theognosis)
 - [Mattia Gigliotti](https://www.kaggle.com/gigliotti)
 - [mattilgale](https://www.kaggle.com/mattilgale)
 - [maurice_f](https://www.kaggle.com/mauricefreund)
 - [Mauro Reverter](https://www.kaggle.com/mreverter)
 - [mavez DABAS](https://www.kaggle.com/mavezdabas)
 - [Max Candocia](https://www.kaggle.com/mcandocia)
 - [Max Halford](https://www.kaggle.com/maxhalford)
 - [Max Horowitz](https://www.kaggle.com/maxhorowitz)
 - [Max Mind](https://www.kaggle.com/max-mind)
 - [Max Stanford-Taylor](https://www.kaggle.com/m0ongg)
 - [Max.liu](https://www.kaggle.com/madmaxliu)
 - [Maxime Fuccellaro](https://www.kaggle.com/blackbee2016)
 - [Maximilian Hahn](https://www.kaggle.com/maximilianhahn)
 - [Maximilian Kapsecker](https://www.kaggle.com/maxkapsecker)
 - [Mayank Singla](https://www.kaggle.com/mayanksingla)
 - [MayankSiddharth](https://www.kaggle.com/mayanksiddharth)
 - [MayankTiwari](https://www.kaggle.com/mayanktiwari09)
 - [Maykon Ravy](https://www.kaggle.com/maykonravy)
 - [McDonald's](https://www.kaggle.com/mcdonalds)
 - [MCrescenzo](https://www.kaggle.com/crescenzo)
 - [Md Irfan Ali](https://www.kaggle.com/irfanalidv)
 - [Mearafat](https://www.kaggle.com/fuckbitch)
 - [Medicare](https://www.kaggle.com/medicare)
 - [meep](https://www.kaggle.com/meepbobeep)
 - [Meetika Sharma](https://www.kaggle.com/meetika)
 - [Meg Shields](https://www.kaggle.com/meghshields)
 - [Megan Risdal](https://www.kaggle.com/mrisdal)
 - [Mehdi](https://www.kaggle.com/mnoori)
 - [Mehedi Shafi](https://www.kaggle.com/exilour)
 - [mehrdad](https://www.kaggle.com/mehrdat)
 - [mehrdadz007](https://www.kaggle.com/mehrdadz007)
 - [Mehta](https://www.kaggle.com/fm4023)
 - [Meigang Gu](https://www.kaggle.com/vradore)
 - [Meinertsen](https://www.kaggle.com/meinertsen)
 - [Melody Z](https://www.kaggle.com/melodyxyz)
 - [melvincheung](https://www.kaggle.com/melvincheung)
 - [Melvyn Drag](https://www.kaggle.com/juliancienfuegos)
 - [Mengfei Li](https://www.kaggle.com/meli19)
 - [mengmengyong](https://www.kaggle.com/mengmengyong)
 - [mengyan](https://www.kaggle.com/mengyanli)
 - [MengYe](https://www.kaggle.com/konohayui)
 - [meow](https://www.kaggle.com/nguyentp)
 - [mepotts](https://www.kaggle.com/mepotts)
 - [Merilin KÃµrnas](https://www.kaggle.com/merilink)
 - [Mesum Raza Hemani](https://www.kaggle.com/mesumraza)
 - [mgkmgk](https://www.kaggle.com/mgkmgk)
 - [MGN](https://www.kaggle.com/mguzmann)
 - [mharrys](https://www.kaggle.com/mharrys)
 - [MHouellemont](https://www.kaggle.com/mhouellemont)
 - [Miaomiao](https://www.kaggle.com/jinmm1992)
 - [MichaÅ‚ Jamry](https://www.kaggle.com/abecadel)
 - [MichaÅ‚Puchalski](https://www.kaggle.com/zeniott13)
 - [Michael Clouting](https://www.kaggle.com/mclouts91)
 - [Michael Ibrahim](https://www.kaggle.com/michaelibrahim)
 - [Michael KS](https://www.kaggle.com/ashurali)
 - [Michael Nation](https://www.kaggle.com/michaelnation)
 - [Michael Pang](https://www.kaggle.com/akababa)
 - [Michael Pavlukhin](https://www.kaggle.com/archelunch)
 - [Michael Plohhotnichenko](https://www.kaggle.com/mixanikk)
 - [Michael Skrzypiec](https://www.kaggle.com/skrzym)
 - [Michael](https://www.kaggle.com/aenimaxoxo)
 - [Michael](https://www.kaggle.com/mdquigg)
 - [MichaelKirk](https://www.kaggle.com/heliodata)
 - [MichaelKlear](https://www.kaggle.com/alliedtoasters)
 - [MichaelStone](https://www.kaggle.com/stoney71)
 - [Michal Januszewski](https://www.kaggle.com/meehau)
 - [Michelle HY](https://www.kaggle.com/hyyeoh)
 - [MieMie Kurisu](https://www.kaggle.com/miemiekurisu)
 - [Miguel LladÃ³](https://www.kaggle.com/mlladocunyat)
 - [Miguel](https://www.kaggle.com/miguel2523)
 - [Miguel](https://www.kaggle.com/miguelgvieira)
 - [MiguelSalazar](https://www.kaggle.com/migue1284)
 - [Mihai Oltean](https://www.kaggle.com/moltean)
 - [Mihir Garg](https://www.kaggle.com/mihirgarg)
 - [Mihkel Gering](https://www.kaggle.com/airtton)
 - [MihwaHan](https://www.kaggle.com/hanriver0618)
 - [miinooo](https://www.kaggle.com/miinoooo)
 - [mijim](https://www.kaggle.com/jimgoh)
 - [Mike Chirico](https://www.kaggle.com/mchirico)
 - [Mike Johnson Jr](https://www.kaggle.com/mikejohnsonjr)
 - [Mike Kim](https://www.kaggle.com/mikeskim)
 - [Mike Mekilo](https://www.kaggle.com/mmek31)
 - [Mike Pastore](https://www.kaggle.com/mpastore)
 - [mike sebel](https://www.kaggle.com/mykcbel)
 - [Mikhail Chesnokov](https://www.kaggle.com/chesnokov)
 - [miki112](https://www.kaggle.com/miki112)
 - [MikioKubo](https://www.kaggle.com/logopt)
 - [mikr](https://www.kaggle.com/milankryl)
 - [MilindParadkar](https://www.kaggle.com/milind81)
 - [Miljenko Bartulovic](https://www.kaggle.com/bartulovic)
 - [mimic1](https://www.kaggle.com/mimic1)
 - [Mina](https://www.kaggle.com/mnanlch)
 - [Minat Verma](https://www.kaggle.com/minatverma)
 - [MindaugasMejeras](https://www.kaggle.com/mindaugasm)
 - [Minerwa Min](https://www.kaggle.com/minerva666)
 - [mingming](https://www.kaggle.com/billy8399)
 - [minmind](https://www.kaggle.com/minmind)
 - [Minso](https://www.kaggle.com/wjeong)
 - [Minx](https://www.kaggle.com/songbm524)
 - [Minxuan](https://www.kaggle.com/minxuanchen)
 - [minyao](https://www.kaggle.com/minyao)
 - [Mir Ali](https://www.kaggle.com/mirbaig)
 - [Miranda](https://www.kaggle.com/miiranda)
 - [Mircea Stanciu](https://www.kaggle.com/baiazid)
 - [Mirko MÃ¤licke](https://www.kaggle.com/mmaelicke)
 - [Miro Karpis](https://www.kaggle.com/kam1ro)
 - [Miroslav Sabo](https://www.kaggle.com/miroslavsabo)
 - [Miroslav Zoricak](https://www.kaggle.com/mirosval)
 - [MiroslavTyurin](https://www.kaggle.com/miroslavtyurin)
 - [MirrorLu](https://www.kaggle.com/mirrorlu)
 - [Mission San Jose AI Club](https://www.kaggle.com/msjaiclub)
 - [MistyMoo](https://www.kaggle.com/alisonp)
 - [Mitchell J](https://www.kaggle.com/datasnaek)
 - [mithileshwaribhade](https://www.kaggle.com/varsha97)
 - [mitillo](https://www.kaggle.com/mitillo)
 - [mitsu](https://www.kaggle.com/mitsuru1)
 - [Mitusha](https://www.kaggle.com/mitusha)
 - [Miza'](https://www.kaggle.com/miza203)
 - [mizosalah](https://www.kaggle.com/mizosalah)
 - [MKMK](https://www.kaggle.com/koogle)
 - [ML Coder](https://www.kaggle.com/rsaiml)
 - [ML_CX](https://www.kaggle.com/chenmingml)
 - [mlagunas](https://www.kaggle.com/mlagunas)
 - [MLane](https://www.kaggle.com/skyrmion)
 - [MLS](https://www.kaggle.com/sushanta)
 - [mlxd](https://www.kaggle.com/loriordan)
 - [mnakajima](https://www.kaggle.com/mnakajima75)
 - [Modeling Online Auctions](https://www.kaggle.com/onlineauctions)
 - [Moghazy](https://www.kaggle.com/moghazy)
 - [Mohamed Abul Danish](https://www.kaggle.com/danish1998)
 - [Mohamed Elsayed](https://www.kaggle.com/sayedovic)
 - [Mohamed Loey](https://www.kaggle.com/mloey1)
 - [Mohamed Ramadan](https://www.kaggle.com/mramadan85)
 - [Mohamed Shawky DG](https://www.kaggle.com/darkgeekms)
 - [MohamedSaidDaw](https://www.kaggle.com/kito96)
 - [MohamedShawky](https://www.kaggle.com/mohshawky)
 - [MohamedWasim](https://www.kaggle.com/uchihaaitachi)
 - [Mohammad Ali](https://www.kaggle.com/mohalikhan)
 - [Mohammad Ghahramani](https://www.kaggle.com/analystmasters)
 - [Mohammad Kachuee](https://www.kaggle.com/mkachuee)
 - [MohammadAmir](https://www.kaggle.com/amirkhn33)
 - [MohammadAseemUrRehman](https://www.kaggle.com/aseem1981)
 - [Mohammed Alnemari](https://www.kaggle.com/alnemari)
 - [Mohit Balani](https://www.kaggle.com/mohit770)
 - [Mohit Sainani](https://www.kaggle.com/msainani)
 - [Moi](https://www.kaggle.com/francismoi)
 - [Moko Sharma](https://www.kaggle.com/mokosan)
 - [Monika Munjal](https://www.kaggle.com/monika11)
 - [MonishC](https://www.kaggle.com/monishc)
 - [monkeyking](https://www.kaggle.com/supersp1234)
 - [moon soo Lee](https://www.kaggle.com/leemoonsoo)
 - [morcinim](https://www.kaggle.com/morcinim)
 - [MorganMazer](https://www.kaggle.com/socialmedianews)
 - [Moses Salifu](https://www.kaggle.com/moses87)
 - [Moshfiqur Rahman](https://www.kaggle.com/moshfiqur)
 - [Motaz Saad](https://www.kaggle.com/mksaad)
 - [Moufid](https://www.kaggle.com/moufid)
 - [Mouli](https://www.kaggle.com/crmouli)
 - [moxious](https://www.kaggle.com/moxious)
 - [Mozilla](https://www.kaggle.com/mozillaorg)
 - [MphoGodfreyNkadimeng](https://www.kaggle.com/gnkadimeng)
 - [Mr. Analytics](https://www.kaggle.com/emoneyanalytics)
 - [mrdeeds](https://www.kaggle.com/mrdeeds)
 - [MridulSharma](https://www.kaggle.com/midzsh98)
 - [MritunjayMohitesh](https://www.kaggle.com/latentheat)
 - [mrjazz](https://www.kaggle.com/mrjazz)
 - [MrNasalHazel](https://www.kaggle.com/zwarner)
 - [mrpantherson](https://www.kaggle.com/mrpantherson)
 - [mrsantos](https://www.kaggle.com/mrsantos)
 - [Mrverde](https://www.kaggle.com/mrverde)
 - [mrzzheng](https://www.kaggle.com/mrzzheng)
 - [Ms Brown](https://www.kaggle.com/msbrown)
 - [msiebold](https://www.kaggle.com/msiebold)
 - [msjass](https://www.kaggle.com/msjass)
 - [MsZombie](https://www.kaggle.com/zombie)
 - [MT](https://www.kaggle.com/mtinti)
 - [Mudit Choraria](https://www.kaggle.com/muditchoraria)
 - [Mufti Mubarak](https://www.kaggle.com/muftimm)
 - [Muhamad Nady](https://www.kaggle.com/muhamadnady)
 - [Muhammad Abdul Rehman](https://www.kaggle.com/rehmanm)
 - [Muhammad Alfiansyah](https://www.kaggle.com/muhammadalfiansyah)
 - [Muhammad Ali](https://www.kaggle.com/alisubhan)
 - [Muhammad Aseem Ur Rehman](https://www.kaggle.com/maseemurrehman)
 - [Muhammad Asif khan](https://www.kaggle.com/engrasifkhan)
 - [Muhammad Jamil Moughal](https://www.kaggle.com/mjamilmoughal)
 - [MuhammadMahadTariq](https://www.kaggle.com/mmahadt)
 - [MuhammadYasirAdnan](https://www.kaggle.com/yasiradnan)
 - [Mukarram Pasha](https://www.kaggle.com/mpasha96)
 - [Mukesh Kumar](https://www.kaggle.com/mukesh2626)
 - [Muneeb ul Hassan](https://www.kaggle.com/muneeb2405)
 - [MuonNeutrino](https://www.kaggle.com/muonneutrino)
 - [Murali_Munna](https://www.kaggle.com/muralimunna18)
 - [MURALIDHAR ANUMULA](https://www.kaggle.com/anumulamuralidhar)
 - [Murder Accountability Project](https://www.kaggle.com/murderaccountability)
 - [mureren](https://www.kaggle.com/mureren)
 - [Murilo Siqueira](https://www.kaggle.com/murilosiqueira)
 - [Murilo Viviani](https://www.kaggle.com/mviviani)
 - [MuskanBararia](https://www.kaggle.com/muskanbararia)
 - [Mustakim](https://www.kaggle.com/abdaatif)
 - [Muthukumar.J](https://www.kaggle.com/muthuj7)
 - [Muttaqi Ismail](https://www.kaggle.com/muttaqi)
 - [My Khe Nguyen](https://www.kaggle.com/mykhe1097)
 - [Myles O'Neill](https://www.kaggle.com/mylesoneill)
 - [mypapit](https://www.kaggle.com/mypapit)
 - [n&n student](https://www.kaggle.com/nnstudent)
 - [n01z3](https://www.kaggle.com/drn01z3)
 - [Nabeel Raza](https://www.kaggle.com/nabeel965)
 - [Nada Fathallah](https://www.kaggle.com/nadafathallah)
 - [Nadin Tamer](https://www.kaggle.com/nadintamer)
 - [Nagabhushan S B](https://www.kaggle.com/nagabhushan1995)
 - [NAGARAJ RAMAKRISHNA](https://www.kaggle.com/nagarajh)
 - [Nagendra Yadav](https://www.kaggle.com/nagendrayadav)
 - [nailo](https://www.kaggle.com/nailo2c)
 - [nami](https://www.kaggle.com/nami0917)
 - [Namory Koulibaly](https://www.kaggle.com/sonamkoul2)
 - [Namsraijav Dugersuren](https://www.kaggle.com/namsraijavd)
 - [NAN JI](https://www.kaggle.com/frupaul)
 - [Nancy Lubalo](https://www.kaggle.com/nlubalo)
 - [Nandagopal M](https://www.kaggle.com/nandum)
 - [NaomiNguyen](https://www.kaggle.com/naominguyen7)
 - [narmeen ](https://www.kaggle.com/narmeen29)
 - [NASA](https://www.kaggle.com/nasa)
 - [Nasir Mushtaq](https://www.kaggle.com/nasirmushtaq773384)
 - [Naszy](https://www.kaggle.com/nasma1)
 - [Nat T](https://www.kaggle.com/natalieytan)
 - [Natalia](https://www.kaggle.com/natt77)
 - [Natalia](https://www.kaggle.com/nlyubova)
 - [Natalie Ha](https://www.kaggle.com/natalieh)
 - [Natasha Zope](https://www.kaggle.com/nata009)
 - [Natasha](https://www.kaggle.com/natashaevpak)
 - [Natasha](https://www.kaggle.com/natashasavc)
 - [Nate](https://www.kaggle.com/natehenderson)
 - [Nathan Burns](https://www.kaggle.com/nateofspades)
 - [Nathan Cohen](https://www.kaggle.com/propanon)
 - [Nathan Zhang](https://www.kaggle.com/oneespresso)
 - [Nathan](https://www.kaggle.com/nathanto)
 - [NathanGeorge](https://www.kaggle.com/wordsforthewise)
 - [Nathaniel See](https://www.kaggle.com/nathanielysee)
 - [National Archives](https://www.kaggle.com/nationalarchives)
 - [National Health Service](https://www.kaggle.com/nhs)
 - [National Institutes of Health Chest X-Ray Dataset](https://www.kaggle.com/nih-chest-xrays)
 - [National Library of Medicine](https://www.kaggle.com/nlm-nih)
 - [National Park Service](https://www.kaggle.com/nationalparkservice)
 - [National Snow and Ice Data Center](https://www.kaggle.com/nsidcorg)
 - [National UFO Reporting Center (NUFORC)](https://www.kaggle.com/NUFORC)
 - [Navdeep Pal](https://www.kaggle.com/navdeeppal)
 - [naveen holla](https://www.kaggle.com/naveenholla)
 - [Naveen Kumar](https://www.kaggle.com/naveenbanda)
 - [Naveen Pandian](https://www.kaggle.com/naveenpandianv)
 - [navneethc](https://www.kaggle.com/navneethc)
 - [NavyashreeS](https://www.kaggle.com/navyasudhakar)
 - [Nayan Bhattacharya](https://www.kaggle.com/nayan7631)
 - [Nayan solanki](https://www.kaggle.com/nayansolanki2411)
 - [Nazimamzz](https://www.kaggle.com/nazimamzz)
 - [NCAA](https://www.kaggle.com/ncaa)
 - [Ncls byr](https://www.kaggle.com/n3k0l6s)
 - [Neel Shah](https://www.kaggle.com/neelshah18)
 - [Neeraj Kasturi](https://www.kaggle.com/neerajkasturi)
 - [Neerav Kharche](https://www.kaggle.com/nkharche)
 - [neha singh](https://www.kaggle.com/n05011996)
 - [Neha](https://www.kaggle.com/neha1703)
 - [NeilS](https://www.kaggle.com/neilslab)
 - [neinei](https://www.kaggle.com/neinei)
 - [neKsdrawkcaB](https://www.kaggle.com/isbs39083)
 - [Nelson Chu](https://www.kaggle.com/nelsonchu)
 - [Nelson](https://www.kaggle.com/mu202199)
 - [Nema](https://www.kaggle.com/nemanema)
 - [Nerdiholic](https://www.kaggle.com/jnnerd)
 - [NetanelMalka](https://www.kaggle.com/netanel246)
 - [Netflix](https://www.kaggle.com/netflix-inc)
 - [NeuroGuy](https://www.kaggle.com/neuroguy)
 - [Never_die](https://www.kaggle.com/bahoury)
 - [New America](https://www.kaggle.com/newamerica)
 - [New York Philharmonic](https://www.kaggle.com/nyphil)
 - [New York Public Library](https://www.kaggle.com/nypl)
 - [newman](https://www.kaggle.com/newman123)
 - [Nguyen Tang Tri Duc](https://www.kaggle.com/mathormad)
 - [NHTSA](https://www.kaggle.com/nhtsa)
 - [nic](https://www.kaggle.com/nicw102168)
 - [Nicholas Zufelt](https://www.kaggle.com/zufelt)
 - [Nick DiGiulio](https://www.kaggle.com/ndigiulio)
 - [Nick Rose](https://www.kaggle.com/nsrose7224)
 - [Nick Schroeder](https://www.kaggle.com/imnickschroeder)
 - [Nick Spadafora](https://www.kaggle.com/spaddy08)
 - [Nick Torsky](https://www.kaggle.com/ntorsky)
 - [Nick Wagner](https://www.kaggle.com/monsieurwagner)
 - [Nick Wong](https://www.kaggle.com/nickwong64)
 - [NickAchin](https://www.kaggle.com/nja1019)
 - [NickSehy](https://www.kaggle.com/nicksehy)
 - [Niclas KjÃ¤ll-Ohlsson](https://www.kaggle.com/niclasko)
 - [Nico Belov](https://www.kaggle.com/travelerspb)
 - [NicolÃ¡s](https://www.kaggle.com/nidafra92)
 - [NicolaBernini](https://www.kaggle.com/nicolabernini)
 - [Nicolas P](https://www.kaggle.com/nepuerto)
 - [Nigel Dalziel](https://www.kaggle.com/ndalziel)
 - [nihal88](https://www.kaggle.com/nihal88)
 - [Nika Ioramishvili](https://www.kaggle.com/ioramishvili)
 - [Nikhil Akki](https://www.kaggle.com/akkithetechie)
 - [Nikhil Gargeya](https://www.kaggle.com/nikhil27gargeya)
 - [Nikhil Gupta](https://www.kaggle.com/nikhil04)
 - [Nikhil Jain](https://www.kaggle.com/jainnikhil)
 - [Nikhil Parihar](https://www.kaggle.com/nikhilparihar)
 - [Nikhil Reddy](https://www.kaggle.com/nikhi264)
 - [Nikhil](https://www.kaggle.com/nikhack16)
 - [nikhil](https://www.kaggle.com/nikhil5642)
 - [Nikita Malyshev](https://www.kaggle.com/mlshff)
 - [Nikunj](https://www.kaggle.com/nikunjm88)
 - [Nilesh Sakpal](https://www.kaggle.com/neiljs)
 - [Nilesh](https://www.kaggle.com/nacharya)
 - [Nils Ponomarchuk](https://www.kaggle.com/nils86)
 - [Nilzone](https://www.kaggle.com/nilzone)
 - [Ning Zhou](https://www.kaggle.com/edgedislocation)
 - [niniyan](https://www.kaggle.com/ni00ni)
 - [Nirajk18](https://www.kaggle.com/nirajkalantri99)
 - [Niranjan Nakkala](https://www.kaggle.com/niranjanmudhiraj)
 - [NiranjanDeshpande](https://www.kaggle.com/niranjan0272)
 - [Nirav Nikunj Patel](https://www.kaggle.com/niravdito)
 - [nirmalelumalai](https://www.kaggle.com/nirmalelumalai)
 - [NirmalyaKumarMohanty](https://www.kaggle.com/nkmlt31)
 - [Nishant ](https://www.kaggle.com/nishant88y)
 - [Nishant Arora](https://www.kaggle.com/nishanta)
 - [Nishant Bhadauria](https://www.kaggle.com/nishantbhadauria)
 - [Nishant K](https://www.kaggle.com/nishant4k)
 - [Nishant Kumar](https://www.kaggle.com/nishkgp)
 - [nishantjain](https://www.kaggle.com/nishantjain91)
 - [NISHIO Hirokazu](https://www.kaggle.com/nishio)
 - [Nishit Sehgal](https://www.kaggle.com/sehgalfuture)
 - [Nitesh Tiwari](https://www.kaggle.com/niteeshtiwari)
 - [NItesh Yadav](https://www.kaggle.com/niteshyadav)
 - [NiteshSurana](https://www.kaggle.com/nykebarz)
 - [Nitin Bisht](https://www.kaggle.com/nitsbat)
 - [Nitin Venkateswaran](https://www.kaggle.com/tundraman)
 - [nitishaadhikari](https://www.kaggle.com/nitishaadhikari)
 - [Niwech Harnkham](https://www.kaggle.com/niwech)
 - [Niyamat Ullah](https://www.kaggle.com/niyamatalmass)
 - [NLSpdX](https://www.kaggle.com/sport16dx)
 - [NLTK Data](https://www.kaggle.com/nltkdata)
 - [NMIN](https://www.kaggle.com/nicolasmin)
 - [No more overfitting ](https://www.kaggle.com/ngoquochung)
 - [No Re](https://www.kaggle.com/bearenon0743)
 - [NOAA](https://www.kaggle.com/noaa)
 - [Noah Gift](https://www.kaggle.com/noahgift)
 - [Noah Schwartz](https://www.kaggle.com/noahlumos)
 - [Noah Wang](https://www.kaggle.com/sunnywhj)
 - [Nodes](https://www.kaggle.com/uiuxwebdesign)
 - [Noel Yoo](https://www.kaggle.com/noelyoo)
 - [Nolan Conaway](https://www.kaggle.com/nolanbconaway)
 - [Nooh](https://www.kaggle.com/nuhsikander)
 - [NorbertBudincsevity](https://www.kaggle.com/budincsevity)
 - [NORC.org](https://www.kaggle.com/norc)
 - [Nosbielcs](https://www.kaggle.com/nosbielcs)
 - [Nowshin Nawar Arony](https://www.kaggle.com/nowshin01)
 - [NPO 2799](https://www.kaggle.com/npo2799)
 - [Nuggs](https://www.kaggle.com/ahmedelnaggar)
 - [Numerai](https://www.kaggle.com/numerai)
 - [Nupur Warke](https://www.kaggle.com/nupurw)
 - [Nuraddin](https://www.kaggle.com/sti18214046)
 - [NurÅŸenÃ–ÄŸÃ¼tveren](https://www.kaggle.com/nursen)
 - [NV27](https://www.kaggle.com/nvarganov)
 - [NYC Open Data](https://www.kaggle.com/nycopendata)
 - [NYC Parks and Recreation](https://www.kaggle.com/nycparks)
 - [NYPD](https://www.kaggle.com/nypd)
 - [Ø¹Ø¨Ø¯Ø§Ù„Ù„Ø·ÙŠÙØ£Ø­Ù…Ø¯ØºÙ„Ø§Ø¨](https://www.kaggle.com/ghallab1984)
 - [ObadiahJeshurenNaidoo](https://www.kaggle.com/acevanoj)
 - [obandoruben](https://www.kaggle.com/obandoruben)
 - [obey ismael](https://www.kaggle.com/obismey)
 - [Ocelot](https://www.kaggle.com/foxeared)
 - [OctavioG](https://www.kaggle.com/octaviog)
 - [OfayMailey](https://www.kaggle.com/nisi01)
 - [Oh InQueue](https://www.kaggle.com/gomjellie)
 - [Ohhm Prakash K I](https://www.kaggle.com/ohhmprakashki)
 - [Okus](https://www.kaggle.com/okuspokus)
 - [Ole KrÃ¶ger](https://www.kaggle.com/wikunia)
 - [Oleg Brizhatiy](https://www.kaggle.com/brizol)
 - [Oleg O](https://www.kaggle.com/smeilz)
 - [OlegSolomka](https://www.kaggle.com/legomushroom)
 - [Oleksii Nidzelskyi](https://www.kaggle.com/onidzelskyi)
 - [Olga Belitskaya](https://www.kaggle.com/olgabelitskaya)
 - [Olga Ivanova ](https://www.kaggle.com/olgaiv39)
 - [Oliveira, L. O. V. B.](https://www.kaggle.com/oliveiralovb)
 - [Oliver Collins](https://www.kaggle.com/olivercollins)
 - [OliverMoralesLopez](https://www.kaggle.com/tivelos)
 - [olivia](https://www.kaggle.com/lsd0304hh)
 - [Olivier Richard](https://www.kaggle.com/olivri)
 - [olivier](https://www.kaggle.com/ogrellier)
 - [ololo](https://www.kaggle.com/agrigorev)
 - [Omajaykarthik](https://www.kaggle.com/omajaykarthik)
 - [Omar](https://www.kaggle.com/oxanderv)
 - [Omer Gozuacik](https://www.kaggle.com/ogozuacik)
 - [Omicron](https://www.kaggle.com/andromi)
 - [OmkarP](https://www.kaggle.com/omkar24)
 - [OnkarKadam](https://www.kaggle.com/onkarkadam)
 - [Onno Eberhard](https://www.kaggle.com/onnoeberhard)
 - [Onofrio_BIScience](https://www.kaggle.com/biaiscience)
 - [Open Food Facts](https://www.kaggle.com/openfoodfacts)
 - [Open Knowledge International](https://www.kaggle.com/okfn)
 - [Open Source Sports](https://www.kaggle.com/open-source-sports)
 - [Open Sourcing Mental Illness, LTD](https://www.kaggle.com/osmi)
 - [OpenAddresses](https://www.kaggle.com/openaddresses)
 - [OpenFlights](https://www.kaggle.com/open-flights)
 - [ophelia1234](https://www.kaggle.com/jratchford)
 - [OrCo](https://www.kaggle.com/orelcoh)
 - [Orges Leka](https://www.kaggle.com/orgesleka)
 - [OrgodolDawaasuren](https://www.kaggle.com/dawaasuren)
 - [orgrimm9](https://www.kaggle.com/bashit)
 - [Oscar Takeshita](https://www.kaggle.com/pliptor)
 - [Oscar Zamora](https://www.kaggle.com/oscarzapi)
 - [oscarleo](https://www.kaggle.com/oscarleo)
 - [ostrokach](https://www.kaggle.com/ostrokach)
 - [OSUBMI](https://www.kaggle.com/osubmi)
 - [Oswin Rahadiyan Hartono](https://www.kaggle.com/oswinrh)
 - [ouissa souliman](https://www.kaggle.com/souliman)
 - [ouyangxuan](https://www.kaggle.com/oyxuan)
 - [Owais](https://www.kaggle.com/owaisraza009)
 - [Ozan Aygun](https://www.kaggle.com/dataygun)
 - [ozgur](https://www.kaggle.com/ozgurb)
 - [P111110](https://www.kaggle.com/p111110)
 - [Pablo ](https://www.kaggle.com/pablorr10)
 - [Pablo Escobar](https://www.kaggle.com/pescobar)
 - [Pablo Tabales](https://www.kaggle.com/pablotab)
 - [PabloMonleon](https://www.kaggle.com/pablomonleon)
 - [Padmavathi R](https://www.kaggle.com/padma2590)
 - [paesibassi](https://www.kaggle.com/paesibassi)
 - [painkiller](https://www.kaggle.com/allenshi820)
 - [Pakshal Jain](https://www.kaggle.com/apletin)
 - [Palak Sharma](https://www.kaggle.com/palak29)
 - [PalashShah](https://www.kaggle.com/palashio)
 - [Pallav Routh](https://www.kaggle.com/pallavr)
 - [Pallavi Ramicetty](https://www.kaggle.com/pallaviroyal)
 - [Panagiotis G. Togias](https://www.kaggle.com/ptogias)
 - [panchicore](https://www.kaggle.com/panchicore)
 - [Pancho](https://www.kaggle.com/nathantunning)
 - [Panda974](https://www.kaggle.com/xfontaine)
 - [pandataDelta](https://www.kaggle.com/pandatadelta)
 - [Pandey Nilesh Prasad](https://www.kaggle.com/npd1211)
 - [Panos Kostakos](https://www.kaggle.com/panoskostakos)
 - [panos](https://www.kaggle.com/panosa)
 - [Panos](https://www.kaggle.com/panosc)
 - [Paolo Campanelli](https://www.kaggle.com/paololol)
 - [paolo](https://www.kaggle.com/paolop)
 - [paosheng](https://www.kaggle.com/paosheng)
 - [Parallax](https://www.kaggle.com/nikhilmudholkar)
 - [Paras Jindal](https://www.kaggle.com/parasjindal96)
 - [Paresh](https://www.kaggle.com/pareshkadoo)
 - [Parichart](https://www.kaggle.com/parichartpanichpol)
 - [Parindsheel Singh](https://www.kaggle.com/psdhillon)
 - [park thirty-two](https://www.kaggle.com/parksami)
 - [Parmanand Sahu](https://www.kaggle.com/analystanand)
 - [Parole Hearing Data Project](https://www.kaggle.com/parole-hearing-data)
 - [parseltung](https://www.kaggle.com/parselt)
 - [Parth Gupta](https://www.kaggle.com/parthgupta28)
 - [Parth Iramani](https://www.kaggle.com/iramaniparth)
 - [ParthMaheshwari](https://www.kaggle.com/parthm1801)
 - [Pascal Brenner](https://www.kaggle.com/pascalbrenner)
 - [Patatae](https://www.kaggle.com/patatae)
 - [Patit Pawan Karmakar](https://www.kaggle.com/patspk)
 - [Patrick Hyland](https://www.kaggle.com/patrickhyland)
 - [Patrick J](https://www.kaggle.com/patjob)
 - [Patrick Murphy](https://www.kaggle.com/patrickmurphy)
 - [Patryk NiedÅºwiedziÅ„ski](https://www.kaggle.com/patrykn)
 - [Paul Abramshe](https://www.kaggle.com/sonicschnooze)
 - [Paul Curry](https://www.kaggle.com/marict)
 - [Paul Larmuseau](https://www.kaggle.com/plarmuseau)
 - [Paul Magda](https://www.kaggle.com/pmagda)
 - [Paul Rossotti](https://www.kaggle.com/pablote)
 - [Paul Schale](https://www.kaggle.com/pschale)
 - [Paul Tracey](https://www.kaggle.com/ptrace02)
 - [Paul Watt](https://www.kaggle.com/paulw8)
 - [Paul Yang](https://www.kaggle.com/paulyangsz)
 - [Paul-Louis Hery](https://www.kaggle.com/plhery)
 - [paul](https://www.kaggle.com/semakulapaul)
 - [Paula Ceccon](https://www.kaggle.com/pceccon)
 - [Paulo Henrique Vasconcellos](https://www.kaggle.com/paulovasconcellos)
 - [paultimothymooney](https://www.kaggle.com/paultimothymooney)
 - [PaulZH](https://www.kaggle.com/paulzh)
 - [pavansubhash](https://www.kaggle.com/pavansubhasht)
 - [PavelTroshenkov](https://www.kaggle.com/pavetr)
 - [Pavlin Bakalov](https://www.kaggle.com/kaiserbdevios)
 - [Pavlos Zitis](https://www.kaggle.com/pavlosz)
 - [pawan](https://www.kaggle.com/pawanyalla)
 - [Pazookii](https://www.kaggle.com/pazookii)
 - [pbcquoc](https://www.kaggle.com/phamquoc94)
 - [PCMiners](https://www.kaggle.com/pcminers)
 - [Pedro Lima](https://www.kaggle.com/pvlima)
 - [Pedro Velez](https://www.kaggle.com/pdvelez)
 - [PedroFrantz](https://www.kaggle.com/pafrantz)
 - [PengM(MySaturdaySelf)](https://www.kaggle.com/pengmei83)
 - [pengzha](https://www.kaggle.com/pengzha)
 - [People HR Analytics Repository](https://www.kaggle.com/HRAnalyticRepository)
 - [peppermintshake](https://www.kaggle.com/peppermintshake)
 - [perastikos](https://www.kaggle.com/perastikos)
 - [PerfectFit](https://www.kaggle.com/perfectfit)
 - [Peter Joseph Arienza](https://www.kaggle.com/parienza)
 - [Peter Klauke](https://www.kaggle.com/pepeeee)
 - [Peter Ostroukhov](https://www.kaggle.com/twelveth)
 - [Peter Wittek](https://www.kaggle.com/peterwittek)
 - [Peter Yang](https://www.kaggle.com/pacificyang)
 - [Peter](https://www.kaggle.com/guillp)
 - [Petit Ours](https://www.kaggle.com/yeqiang0428)
 - [pguptha](https://www.kaggle.com/pyennamp)
 - [phalaris](https://www.kaggle.com/devinanzelmo)
 - [phatgamer](https://www.kaggle.com/willwetzel)
 - [Philip Corr](https://www.kaggle.com/corrphilip)
 - [PhilipHarmuth](https://www.kaggle.com/harmuth)
 - [philipjames11](https://www.kaggle.com/philipjames11)
 - [Philipp Schmidt](https://www.kaggle.com/philschmidt)
 - [PhillipChin](https://www.kaggle.com/ekkus93)
 - [PhillipLiu](https://www.kaggle.com/phillipliu)
 - [Phung Van Hoa](https://www.kaggle.com/vanhoa)
 - [pickleChu](https://www.kaggle.com/meiyizi)
 - [pickou](https://www.kaggle.com/pickou)
 - [Pierre Sardin](https://www.kaggle.com/psardin)
 - [Piks Ral](https://www.kaggle.com/princyralaivao)
 - [PiperGragg](https://www.kaggle.com/pipergragg)
 - [pistachio_overlord](https://www.kaggle.com/myqrizzo)
 - [piyushgoyal443](https://www.kaggle.com/piyushgoyal443)
 - [piyushgupta](https://www.kaggle.com/piyusamp)
 - [pjmonti](https://www.kaggle.com/prashant3912)
 - [pkugoodspeed](https://www.kaggle.com/pkugoodspeed)
 - [PKylas](https://www.kaggle.com/pkylas)
 - [pmohun](https://www.kaggle.com/philmohun)
 - [Poetri Heriningtyas](https://www.kaggle.com/poetri)
 - [Polina Vakhrusheva](https://www.kaggle.com/polyav)
 - [Poorna](https://www.kaggle.com/poornapallela)
 - [Poornima Ravishankar](https://www.kaggle.com/poornimasai)
 - [PoornimaShanbhag](https://www.kaggle.com/poornimashanbhag)
 - [poquilia](https://www.kaggle.com/ines80)
 - [portia brat](https://www.kaggle.com/hahdawg)
 - [pourmehrab](https://www.kaggle.com/pourmehrab)
 - [Pradeep.narayanan](https://www.kaggle.com/pradeepp)
 - [Pradeep](https://www.kaggle.com/lookdeepu)
 - [PradeepKumar](https://www.kaggle.com/contactprad)
 - [Pragya Goyal](https://www.kaggle.com/pragya05)
 - [Prajit Datta](https://www.kaggle.com/prajitdatta)
 - [prajwal](https://www.kaggle.com/prajwalv94)
 - [Prakash Tiwary](https://www.kaggle.com/pctiwary)
 - [PrakashGawas](https://www.kaggle.com/gunners009)
 - [Prakhar Srivastava](https://www.kaggle.com/prakharsr)
 - [Prakriti Iyengar](https://www.kaggle.com/prakriti73)
 - [Pramit](https://www.kaggle.com/pramit1)
 - [Pramod Kumar](https://www.kaggle.com/pramodkumar8)
 - [Pramud](https://www.kaggle.com/pramud)
 - [Pranav](https://www.kaggle.com/thoughtcircle)
 - [Pranay Aryal](https://www.kaggle.com/speedoheck)
 - [Pranesh Kumar Palanisamy Padmavathy](https://www.kaggle.com/pashern)
 - [PranjalGandhi](https://www.kaggle.com/pg2457)
 - [pranstar](https://www.kaggle.com/pran93)
 - [Prasanna Nadimpalli](https://www.kaggle.com/dataswimmer)
 - [Prasanna steed](https://www.kaggle.com/prasanna9417)
 - [Prashant Singh Chauhan](https://www.kaggle.com/pchauhan13)
 - [Prashanth Poojary](https://www.kaggle.com/mprashanth73)
 - [Prashanth Sekar](https://www.kaggle.com/prashanth1994)
 - [prashanthsreepuram](https://www.kaggle.com/prashanthsr)
 - [Prateek Gupta](https://www.kaggle.com/iamprateek)
 - [Prateek Joshi](https://www.kaggle.com/pjoshi15)
 - [Prateik](https://www.kaggle.com/prateikmahendra)
 - [Pratibha Sharma](https://www.kaggle.com/pratibhasharma)
 - [PratibhaSharma](https://www.kaggle.com/pratizilla)
 - [Pratik Agrawal](https://www.kaggle.com/pratiksagrawal)
 - [Pratik K](https://www.kaggle.com/pk13055)
 - [Pratik Singh](https://www.kaggle.com/impratiksingh)
 - [Pratiksha Salimath](https://www.kaggle.com/psalimat)
 - [Pratiush Prasunn](https://www.kaggle.com/pratiush309)
 - [pravallika](https://www.kaggle.com/pravallika30)
 - [Pravesh_Ghorawat](https://www.kaggle.com/pravesh97)
 - [preeth kumar](https://www.kaggle.com/preeth)
 - [PreetSinghKhalsa](https://www.kaggle.com/bazuka)
 - [Prem Patrick](https://www.kaggle.com/prempatrick007)
 - [PreMon](https://www.kaggle.com/premamonish)
 - [PremTewari](https://www.kaggle.com/premtewari)
 - [Prince Grover](https://www.kaggle.com/grroverpr)
 - [priscilla](https://www.kaggle.com/prisro)
 - [Priya_ds](https://www.kaggle.com/priya2908)
 - [PriyaChowdary](https://www.kaggle.com/poojitha21)
 - [Priyaljain](https://www.kaggle.com/priyalj)
 - [Priyank Shah](https://www.kaggle.com/czar123)
 - [priyanka gagneja](https://www.kaggle.com/datageekpriyanka)
 - [Priyanka Kolli](https://www.kaggle.com/priyak19)
 - [priyanka Kukunuru](https://www.kaggle.com/prkukunoor)
 - [PriyanshJain](https://www.kaggle.com/priyanshj72)
 - [Progress Queens](https://www.kaggle.com/progressqueens)
 - [Project Jupyter](https://www.kaggle.com/jupyter)
 - [proland](https://www.kaggle.com/rolandp)
 - [PromphongBandhuvara](https://www.kaggle.com/boocertified)
 - [PromptCloud](https://www.kaggle.com/PromptCloudHQ)
 - [Pronto Cycle Share](https://www.kaggle.com/pronto)
 - [Properati Data](https://www.kaggle.com/properati-data)
 - [prvns](https://www.kaggle.com/singhpraveen)
 - [ps](https://www.kaggle.com/ps2811)
 - [psparks](https://www.kaggle.com/psparks)
 - [Pulkit Jha](https://www.kaggle.com/pappukrjha)
 - [PULKIT KHANDELWAL](https://www.kaggle.com/pulkit8595)
 - [puneet](https://www.kaggle.com/puneetbhaya)
 - [puneeth019](https://www.kaggle.com/puneeth019)
 - [Punxsutawney Groundhog Club](https://www.kaggle.com/groundhogclub)
 - [Purvank](https://www.kaggle.com/purvank)
 - [Pushkar Jain](https://www.kaggle.com/pushkar39)
 - [PushpendraPratap](https://www.kaggle.com/pushpendra7)
 - [pylyfe](https://www.kaggle.com/pylyfe)
 - [PythonMython](https://www.kaggle.com/pythonmython)
 - [PyTorch](https://www.kaggle.com/pytorch)
 - [Q82 Capital](https://www.kaggle.com/q82capital)
 - [QadeemKhan](https://www.kaggle.com/qadeemkhan)
 - [Qishen Ha](https://www.kaggle.com/haqishen)
 - [qixiang109](https://www.kaggle.com/qixiang109)
 - [qizheng](https://www.kaggle.com/yuqizheng)
 - [Quan Do](https://www.kaggle.com/qmdo97)
 - [Quan Nguyen](https://www.kaggle.com/quanbk)
 - [Quang Nguyen](https://www.kaggle.com/nhmquang)
 - [QuantScientist](https://www.kaggle.com/solomonk)
 - [Quentin Garnier](https://www.kaggle.com/ptitmoustique)
 - [Quentin Mouton](https://www.kaggle.com/moutov)
 - [QuinnCarver](https://www.kaggle.com/qcarver)
 - [Quoc Thang Nguyen](https://www.kaggle.com/victorythang113)
 - [quoniammm](https://www.kaggle.com/quoniammm)
 - [Quora](https://www.kaggle.com/quora)
 - [R.Venkatesh](https://www.kaggle.com/rvenkatesh2020)
 - [R1q3](https://www.kaggle.com/ruanqian)
 - [RÅÅ©KÄ©Ä…](https://www.kaggle.com/csroukia)
 - [raam](https://www.kaggle.com/raam93)
 - [Raaz](https://www.kaggle.com/raaz181)
 - [Rachael Tatman](https://www.kaggle.com/rtatman)
 - [Rachit Sapra](https://www.kaggle.com/rachit72)
 - [Rachit Srivastava](https://www.kaggle.com/rachit1307)
 - [RadociechBubuSierakowski](https://www.kaggle.com/bubu89)
 - [Radu Stoicescu](https://www.kaggle.com/radustoicescu)
 - [Rafael Novello](https://www.kaggle.com/rafanovello)
 - [Rafal Cycon (blaine)](https://www.kaggle.com/rafalcycon)
 - [RafflesiaKhan](https://www.kaggle.com/rafflesia)
 - [Raghavi](https://www.kaggle.com/raghavi9607)
 - [RaghuReddy](https://www.kaggle.com/raghu07)
 - [Rahi](https://www.kaggle.com/braintickle)
 - [Rahul Bagga](https://www.kaggle.com/rahulbagga)
 - [rahul batham](https://www.kaggle.com/rahulbthm46)
 - [Rahul Chaudhary](https://www.kaggle.com/rahulxc1)
 - [rahul kumar](https://www.kaggle.com/rahulin05)
 - [rahul patil](https://www.kaggle.com/rrp170330)
 - [Rahul Sathyajit](https://www.kaggle.com/rahulsathyajit)
 - [rahul](https://www.kaggle.com/rahul897)
 - [Rahul](https://www.kaggle.com/sroohul656)
 - [RahulBhambri](https://www.kaggle.com/rbhambri)
 - [RahulMayuranath](https://www.kaggle.com/kedi96)
 - [RahulVerma](https://www.kaggle.com/smugglaz)
 - [Raihan Kibria](https://www.kaggle.com/rkibria)
 - [Rainey](https://www.kaggle.com/rainey)
 - [Raj Sharma](https://www.kaggle.com/therajsharma)
 - [RajaGanapathy](https://www.kaggle.com/rganapathy)
 - [Rajanand Ilangovan / à®‡à®°à®¾à®œà¯à®†à®©à®¨à¯à®¤à¯ à®‡à®³à®™à¯à®•à¯‹à®µà®©à¯](https://www.kaggle.com/rajanand)
 - [Rajasankar Viswanathan](https://www.kaggle.com/rajasankar)
 - [rajat arora](https://www.kaggle.com/rajatarora)
 - [Rajat Sharma](https://www.kaggle.com/rajatiitg)
 - [Rajeev kumar ](https://www.kaggle.com/john2195)
 - [Rajeev](https://www.kaggle.com/rajeevmeda)
 - [rajesh kumar](https://www.kaggle.com/kumar012)
 - [RAJESH PURWAR](https://www.kaggle.com/rajeshpurwar)
 - [RajeshM](https://www.kaggle.com/codingnirvana)
 - [Rajiv Jeeva](https://www.kaggle.com/rajivjeeva)
 - [Rajmund Mokso](https://www.kaggle.com/rajmund)
 - [Rajorshi Chaudhuri](https://www.kaggle.com/knight079)
 - [RajSekhar](https://www.kaggle.com/rajasekhardodda)
 - [Raju Alluri](https://www.kaggle.com/rajualluri)
 - [RakanNimer](https://www.kaggle.com/rakannimer)
 - [Rakesh Raushan](https://www.kaggle.com/rakeshrau)
 - [RakeshSk](https://www.kaggle.com/skrakesh5)
 - [Rakuraku](https://www.kaggle.com/rakuraku678)
 - [RalicLo](https://www.kaggle.com/raliclo)
 - [Ram Ramrakhya](https://www.kaggle.com/axel81)
 - [Ramakrishnan Srinivasan](https://www.kaggle.com/toramky)
 - [ramamet](https://www.kaggle.com/ramamet4)
 - [Ramanujam Allam](https://www.kaggle.com/anjuram25)
 - [Ramesh](https://www.kaggle.com/grameshbabu)
 - [Ramiro](https://www.kaggle.com/ramirobmar)
 - [ramirobentes](https://www.kaggle.com/ramirobentes)
 - [RamNemani](https://www.kaggle.com/ramnemani)
 - [Randy Betancourt](https://www.kaggle.com/PythonforSASUsers)
 - [Ranjan Kumar](https://www.kaggle.com/ranjan73)
 - [Ranjit kumar](https://www.kaggle.com/ranjit5600)
 - [RanjithaKorrapati](https://www.kaggle.com/ranjitha1)
 - [Ranjithkumar M](https://www.kaggle.com/rkmunusamy)
 - [RaphaÃ«lMontaud](https://www.kaggle.com/raphboss)
 - [Raphael](https://www.kaggle.com/elraphabr)
 - [Raquel Aoki](https://www.kaggle.com/rysaoki)
 - [Rashid Ali](https://www.kaggle.com/rashidali)
 - [Rashid Khan](https://www.kaggle.com/rashidallama)
 - [Rashmi Singh Chauhan](https://www.kaggle.com/singhchauhan)
 - [RatnaChowdary](https://www.kaggle.com/ratna364)
 - [Raul](https://www.kaggle.com/racu10)
 - [Ravali](https://www.kaggle.com/ravaliraj)
 - [Ravi Rokhade](https://www.kaggle.com/ravirk66)
 - [Ravi Verma](https://www.kaggle.com/machinoai)
 - [Ravi](https://www.kaggle.com/kavinotravi)
 - [ravi](https://www.kaggle.com/ravi12344)
 - [RaviBhalala](https://www.kaggle.com/ravibhalala217)
 - [Ravichandra Malapati](https://www.kaggle.com/malapatiravi)
 - [RaviJain](https://www.kaggle.com/ravijain056)
 - [RaviKiran](https://www.kaggle.com/ravikiran378)
 - [Ravin ](https://www.kaggle.com/ravin0512)
 - [Ravindra Kompella](https://www.kaggle.com/kmsravindra)
 - [Ray](https://www.kaggle.com/raford2)
 - [rayen](https://www.kaggle.com/rayenkhayat)
 - [Raymond Delord](https://www.kaggle.com/raymos)
 - [RaymondMak](https://www.kaggle.com/makray)
 - [raysar](https://www.kaggle.com/raysar)
 - [Razib Mustafiz](https://www.kaggle.com/razibmustafiz)
 - [RBakes](https://www.kaggle.com/bakesril)
 - [Rcaer](https://www.kaggle.com/rcavelino)
 - [rdayala](https://www.kaggle.com/rdayala)
 - [RDizzl3](https://www.kaggle.com/rdizzl3)
 - [Reason Foundation](https://www.kaggle.com/reason-foundation)
 - [rechards](https://www.kaggle.com/rechards)
 - [Recruit Institute of Technology](https://www.kaggle.com/ritresearch)
 - [Reddit](https://www.kaggle.com/reddit)
 - [RedRegressor](https://www.kaggle.com/salilchitnis)
 - [REE_](https://www.kaggle.com/zhenzhouren)
 - [Regis Nunes Vargas](https://www.kaggle.com/regisnv)
 - [Reinhard](https://www.kaggle.com/reisel)
 - [Remi Myers](https://www.kaggle.com/rmyersapco)
 - [Renata Barros](https://www.kaggle.com/renatabarros)
 - [RenzoRamirez](https://www.kaggle.com/freshrenzo)
 - [Retailrocket](https://www.kaggle.com/retailrocket)
 - [Reynald Riviere](https://www.kaggle.com/reynaldriviere)
 - [Reza Agung Pambudi](https://www.kaggle.com/rezaagungpambudi)
 - [Reza Javidi](https://www.kaggle.com/javidimail)
 - [Reza Katebi](https://www.kaggle.com/rezakatebi)
 - [REZA](https://www.kaggle.com/reza2866)
 - [rhammell](https://www.kaggle.com/rhammell)
 - [rhishikesh nepal](https://www.kaggle.com/rhishikesh)
 - [RhitamjeetSaharia](https://www.kaggle.com/rhitamjeet)
 - [Rhostam](https://www.kaggle.com/rhostam)
 - [Ri_Nandiya](https://www.kaggle.com/nandiya)
 - [Ricardo Moya](https://www.kaggle.com/ricardomoya)
 - [Ricardo Suarez](https://www.kaggle.com/ricardosuarez)
 - [Ricardo Zuccolo](https://www.kaggle.com/rzuccolo)
 - [Riccardo Bongiovanni](https://www.kaggle.com/rbonjovi)
 - [Riccardo Miccini](https://www.kaggle.com/miccio)
 - [Riccardo Nizzolo](https://www.kaggle.com/riccardonizzolo)
 - [Richa Gautam](https://www.kaggle.com/gautamricha)
 - [Richard Churchill](https://www.kaggle.com/rschurchill)
 - [Richard Gu](https://www.kaggle.com/guchenghao)
 - [Richard Nagyfi](https://www.kaggle.com/sedthh)
 - [richard](https://www.kaggle.com/richardbebin)
 - [RichardBJ](https://www.kaggle.com/richardbj)
 - [RichardNguyen](https://www.kaggle.com/richardnguyen)
 - [Rick Chen](https://www.kaggle.com/ddongchen)
 - [rickvenadata](https://www.kaggle.com/rickvenadata)
 - [Ricky](https://www.kaggle.com/zurfer)
 - [RickyMak](https://www.kaggle.com/rmak230)
 - [rickysaurav](https://www.kaggle.com/rickysaurav)
 - [Ridhi Adyanthaya](https://www.kaggle.com/ridhiadyanthaya)
 - [Rini](https://www.kaggle.com/rinivabini)
 - [Rio 2016](https://www.kaggle.com/rio2016)
 - [Rippon](https://www.kaggle.com/ripponmangaraj)
 - [Riri](https://www.kaggle.com/rharrak)
 - [Rishab Gargeya](https://www.kaggle.com/rishabg)
 - [Rishabh Kumar Jha](https://www.kaggle.com/rishabhkumarjha)
 - [Rishabh Mishra](https://www.kaggle.com/soulreaper328)
 - [Rishi Anand](https://www.kaggle.com/rishianand)
 - [Rishi Sankineni](https://www.kaggle.com/rishisankineni)
 - [RishiBarath](https://www.kaggle.com/rb1181)
 - [riti ](https://www.kaggle.com/ritidata)
 - [RitikaJain](https://www.kaggle.com/nobody404)
 - [RITUSHARMA15BCE1347](https://www.kaggle.com/ritusharma8124)
 - [River](https://www.kaggle.com/rsnively)
 - [Riyas](https://www.kaggle.com/riyasvk)
 - [rjcampa](https://www.kaggle.com/rjcampa)
 - [rjl2155](https://www.kaggle.com/richardjameslopez)
 - [RM](https://www.kaggle.com/rmtest)
 - [rmsda2](https://www.kaggle.com/rmsda2)
 - [Roam Analytics](https://www.kaggle.com/roamresearch)
 - [Rob Harrand](https://www.kaggle.com/tentotheminus9)
 - [Rob Wishart](https://www.kaggle.com/robwishart)
 - [Robbert Manders](https://www.kaggle.com/robbertmanders)
 - [RobbieS](https://www.kaggle.com/robbies)
 - [Robert Hargraves](https://www.kaggle.com/dataharg)
 - [Robert Nolan](https://www.kaggle.com/robertnolan)
 - [Robert Wexler](https://www.kaggle.com/rwexler)
 - [Roberto Sousa](https://www.kaggle.com/ominivac)
 - [Roberto Spadim](https://www.kaggle.com/rspadim)
 - [Roberto Williams](https://www.kaggle.com/robbat1)
 - [Robin E. Masliah](https://www.kaggle.com/robmaslh)
 - [Robin Nicole](https://www.kaggle.com/robinnicolem)
 - [Robin Praet](https://www.kaggle.com/robinpraet)
 - [RobinReni](https://www.kaggle.com/robinreni)
 - [robotcator](https://www.kaggle.com/robotcator)
 - [rocha](https://www.kaggle.com/rochachan)
 - [Rock Pereira](https://www.kaggle.com/rockp1)
 - [RockBottom](https://www.kaggle.com/rockbottom73)
 - [Rodrigo Ancavil](https://www.kaggle.com/rancavil)
 - [Rodrigo Domingos](https://www.kaggle.com/rodrigodomingos)
 - [Rodrigo Ramele](https://www.kaggle.com/rramele)
 - [Rodrigo Salas](https://www.kaggle.com/rsalaschile)
 - [Rodrigo](https://www.kaggle.com/crdias)
 - [Roel van den Boom](https://www.kaggle.com/roelvdboom)
 - [roger](https://www.kaggle.com/roger1315)
 - [Rogerio Lopes](https://www.kaggle.com/rglopes)
 - [RogierMonshouwer](https://www.kaggle.com/rogier2012)
 - [Rohan Kale](https://www.kaggle.com/rohankale)
 - [Rohan Kayan](https://www.kaggle.com/rohankayan)
 - [Rohan Patel](https://www.kaggle.com/rohan8594)
 - [Rohit Sharma](https://www.kaggle.com/rohitx007)
 - [Rohit Singh](https://www.kaggle.com/rhtsingh)
 - [RohithRPai](https://www.kaggle.com/rohithpai)
 - [RohitMathur](https://www.kaggle.com/rohitmathur100)
 - [Rohk](https://www.kaggle.com/therohk)
 - [Roi Shikler](https://www.kaggle.com/roishik)
 - [rojour](https://www.kaggle.com/rojour)
 - [Rolandas Å imkus](https://www.kaggle.com/rolandassimkus)
 - [Rolando P. Aguirre](https://www.kaggle.com/rpaguirre)
 - [Romain Loiseau](https://www.kaggle.com/romainloiseau)
 - [Romain LOURY](https://www.kaggle.com/rloury)
 - [romainvincent](https://www.kaggle.com/romainvincent)
 - [Roman Akhunov](https://www.kaggle.com/romanakhunov)
 - [Roman Semenyk](https://www.kaggle.com/laurlct)
 - [Roman](https://www.kaggle.com/netroman)
 - [RomitDhamija](https://www.kaggle.com/romitdhamija)
 - [Romy](https://www.kaggle.com/romy25)
 - [Ron Graf](https://www.kaggle.com/ronaldjgrafjr)
 - [Ron Leplae](https://www.kaggle.com/rleplae)
 - [Ronald Troncoso](https://www.kaggle.com/ronaldtroncoso20)
 - [rongruosong](https://www.kaggle.com/rongruosong)
 - [ronnie](https://www.kaggle.com/rohandx1996)
 - [Ronny Kimathi kaimenyi](https://www.kaggle.com/ronnykym)
 - [Rony Lussari](https://www.kaggle.com/ronylussari)
 - [RoopaliKaujalgi](https://www.kaggle.com/roopalik)
 - [Rosanaider](https://www.kaggle.com/rosado)
 - [rosegao](https://www.kaggle.com/rosegao)
 - [Roselyn Kinuthia](https://www.kaggle.com/rkinuthia)
 - [RoshaanKhan](https://www.kaggle.com/khanrm2)
 - [Roshan](https://www.kaggle.com/roshan1986)
 - [Rounak Banik](https://www.kaggle.com/rounakbanik)
 - [roundedup](https://www.kaggle.com/roundedup)
 - [rovilayjnr](https://www.kaggle.com/rovilayjnr)
 - [Roy Garrard](https://www.kaggle.com/noriuk)
 - [Roy Kiran](https://www.kaggle.com/royalrk)
 - [Roy Klaasse Bos](https://www.kaggle.com/royklaassebos)
 - [RoyWWilson](https://www.kaggle.com/smedleykagnovitch)
 - [RoyXss](https://www.kaggle.com/royxss)
 - [RpyGamer](https://www.kaggle.com/rpygamer)
 - [RShorty30](https://www.kaggle.com/rshorty30)
 - [Rudd Fawcett](https://www.kaggle.com/ruddfawcett)
 - [Ruhshan](https://www.kaggle.com/ruhshan)
 - [Rui Romanini](https://www.kaggle.com/ruiromanini)
 - [ruijie li](https://www.kaggle.com/liruijie4)
 - [Ruishen Lyu](https://www.kaggle.com/lruishen)
 - [Rumen Manev](https://www.kaggle.com/rmanev)
 - [rupali](https://www.kaggle.com/rupalish)
 - [Rush Kirubi](https://www.kaggle.com/rush4ratio)
 - [Ruslan Khalitov](https://www.kaggle.com/ruslankhalitov)
 - [Ruslan](https://www.kaggle.com/luckysturr)
 - [Rutuj Gavankar](https://www.kaggle.com/rutujsg)
 - [Ryan Bain](https://www.kaggle.com/cocowaffle)
 - [Ryan Buck](https://www.kaggle.com/stravinsky)
 - [Ryan Chang](https://www.kaggle.com/juiyangchang)
 - [Ryan Cushen](https://www.kaggle.com/rcushen)
 - [Ryan Epp](https://www.kaggle.com/reppic)
 - [Ryan Harrison](https://www.kaggle.com/rrharrison90)
 - [Ryan Li](https://www.kaggle.com/statikk)
 - [Ryan Sloot](https://www.kaggle.com/rsloot)
 - [Ryan](https://www.kaggle.com/snarfed)
 - [RyanHuang](https://www.kaggle.com/ryan88)
 - [RyanLott](https://www.kaggle.com/greygoo)
 - [RyoOgata](https://www.kaggle.com/ryoogata)
 - [RyuJiseung](https://www.kaggle.com/lsk7421)
 - [ryvolum](https://www.kaggle.com/ryvolum)
 - [S Sakarin](https://www.kaggle.com/sangcrazy4)
 - [S. Zotos](https://www.kaggle.com/szotos)
 - [s.ayadi](https://www.kaggle.com/salemayadi)
 - [S.S. Tarek](https://www.kaggle.com/heavymetalrebel)
 - [S1M0N38](https://www.kaggle.com/s1m0n38)
 - [SÃ©bastien Aroulanda](https://www.kaggle.com/paladeur)
 - [SÃ©bastien MATHIEU](https://www.kaggle.com/negtitep)
 - [SÃ©bastien Pouilly](https://www.kaggle.com/sebwdz)
 - [saagie_anthony](https://www.kaggle.com/anthobau)
 - [sab30226](https://www.kaggle.com/sab30226)
 - [Sabber Ahamed](https://www.kaggle.com/msahamed)
 - [Sabyasachi](https://www.kaggle.com/sabysachi)
 - [SachGupta](https://www.kaggle.com/sachgupta)
 - [Sachiemon](https://www.kaggle.com/sachiemon)
 - [Sachin Kalsi](https://www.kaggle.com/sachinkalsi)
 - [Sachin Patel](https://www.kaggle.com/sachinpatel21)
 - [sachinumrao](https://www.kaggle.com/sachin1512)
 - [SadhanaSingh](https://www.kaggle.com/sadhanasingh)
 - [Safecast](https://www.kaggle.com/safecast)
 - [Sagar Sarkar](https://www.kaggle.com/sagarsarkar043)
 - [Sagarnil Das](https://www.kaggle.com/sagarnildass)
 - [SagarSen](https://www.kaggle.com/sagarsen)
 - [Sahil Gandhi](https://www.kaggle.com/sahilgandhi94)
 - [Sai C](https://www.kaggle.com/nsaikn)
 - [Sai Pranav](https://www.kaggle.com/saipranava)
 - [Saida Antonyan](https://www.kaggle.com/saidaantonyan)
 - [saigonapps](https://www.kaggle.com/saigonapps)
 - [saikiran](https://www.kaggle.com/jellasaikiran)
 - [SaiKumar](https://www.kaggle.com/sailsk)
 - [Saimagesh R](https://www.kaggle.com/saimageshr)
 - [sainath](https://www.kaggle.com/sainathreddy)
 - [Saiprasad](https://www.kaggle.com/sunmoon)
 - [Sajal](https://www.kaggle.com/sajalkumar)
 - [Sajid](https://www.kaggle.com/noobchef)
 - [SakinaDas](https://www.kaggle.com/sakinadas)
 - [SakthiSiva](https://www.kaggle.com/sakthisiva)
 - [Sakti Prasad](https://www.kaggle.com/spn007)
 - [Salil Gautam](https://www.kaggle.com/salil007)
 - [Salim Dohri](https://www.kaggle.com/cythun)
 - [SalimChouai](https://www.kaggle.com/salim94)
 - [salmanpathan](https://www.kaggle.com/salmanasylum)
 - [Salomon](https://www.kaggle.com/dollarbillio)
 - [SalvadorDali](https://www.kaggle.com/salvadordali)
 - [Sam Edelstein](https://www.kaggle.com/samedelstein)
 - [Sam Harris](https://www.kaggle.com/samharris)
 - [sam komo](https://www.kaggle.com/samson22)
 - [Sam Shideler](https://www.kaggle.com/sjshide)
 - [Sam Stonesifer](https://www.kaggle.com/sds5578)
 - [Sam Wong](https://www.kaggle.com/shwong)
 - [samael](https://www.kaggle.com/emcmii)
 - [SambitSekhar](https://www.kaggle.com/sambit7)
 - [samdeeplearning](https://www.kaggle.com/samdeeplearning)
 - [SamDotson](https://www.kaggle.com/samdotson)
 - [Sameer Mahajan](https://www.kaggle.com/sameersmahajan)
 - [Sameer](https://www.kaggle.com/sameerqayyum)
 - [Sami Rahman](https://www.kaggle.com/samirahman)
 - [SamiraKlaylat](https://www.kaggle.com/suso172)
 - [SamiTabet](https://www.kaggle.com/stabet)
 - [Sammy Klasfeld](https://www.kaggle.com/sklasfeld)
 - [sammy123](https://www.kaggle.com/sammy123)
 - [Samrat](https://www.kaggle.com/samratp)
 - [Samriddhi Sinha](https://www.kaggle.com/djokester)
 - [Samuel Longwell](https://www.kaggle.com/thebirdofhermes)
 - [Samuel](https://www.kaggle.com/slucomb)
 - [Samyak Jain](https://www.kaggle.com/samyak3098)
 - [SanD](https://www.kaggle.com/sandipdatta)
 - [Sandeep Kumar](https://www.kaggle.com/sanbelief)
 - [Sandeep](https://www.kaggle.com/sdalvi)
 - [SandeepRamesh](https://www.kaggle.com/sandeep04201988)
 - [SandeepYadav](https://www.kaggle.com/sandeepyadav007)
 - [sandhya raghavan](https://www.kaggle.com/raghavansandhya)
 - [Sandra Cristina Bustos Galvis](https://www.kaggle.com/sanbuga)
 - [sandrarivera](https://www.kaggle.com/sandrarivera)
 - [Sandro Marcelo Peirano Gozalvez](https://www.kaggle.com/ordnas)
 - [sandsp](https://www.kaggle.com/sandsp)
 - [Sandy HE](https://www.kaggle.com/sandyhe)
 - [SangamVerma](https://www.kaggle.com/vermasangam)
 - [Sangeetha Sasikumar](https://www.kaggle.com/sangeetha007)
 - [sanjay kushwah](https://www.kaggle.com/sanjaykushwah)
 - [Sanjaya Wijeratne](https://www.kaggle.com/sanjayaw)
 - [Sanjeet Kumar Yadav](https://www.kaggle.com/sanjeet41)
 - [Sanjeev Upreti](https://www.kaggle.com/sanjeevupreti)
 - [Sanket Kumar](https://www.kaggle.com/sk9000)
 - [Santa Meilisa](https://www.kaggle.com/smeilisa07)
 - [SanthoshMurali](https://www.kaggle.com/sanedhika)
 - [SantiagoVazquezGomez](https://www.kaggle.com/siryago)
 - [Santosh Boina](https://www.kaggle.com/santoshb183)
 - [Sanyam](https://www.kaggle.com/sanyammehta)
 - [Saqib Mujtaba](https://www.kaggle.com/saqibmujtaba)
 - [Sara G. Mille](https://www.kaggle.com/saramille)
 - [Sarah Adsit](https://www.kaggle.com/sea5238)
 - [Sarah VCH](https://www.kaggle.com/sarahvch)
 - [SarahZ](https://www.kaggle.com/xzhang159)
 - [Sarai Rosenberg](https://www.kaggle.com/saraislet)
 - [Saravanan B](https://www.kaggle.com/sarvasub)
 - [Saravanan Jaichandar](https://www.kaggle.com/saranchandar)
 - [sariya](https://www.kaggle.com/dssariya)
 - [sarra zammit chatti](https://www.kaggle.com/sarraz)
 - [sarthak nautiyal](https://www.kaggle.com/sarthaknautiyal)
 - [sarubhava](https://www.kaggle.com/sarukaggle)
 - [Sasan Jafarnejad](https://www.kaggle.com/sasanj)
 - [sash](https://www.kaggle.com/sashchernuh)
 - [sasi](https://www.kaggle.com/venkatakumar81)
 - [Saswata Das](https://www.kaggle.com/sasd3107)
 - [satadru5](https://www.kaggle.com/satadru5)
 - [Satavisha Mitra](https://www.kaggle.com/satavisham)
 - [satheeshperepu](https://www.kaggle.com/satheesh841)
 - [Sathu79](https://www.kaggle.com/sathutr)
 - [Satish Karivedha](https://www.kaggle.com/karivedha)
 - [Satish Tiwari](https://www.kaggle.com/satishtiwari23)
 - [Satya Patel](https://www.kaggle.com/satya05)
 - [Satyaki Banik](https://www.kaggle.com/satyakibanik)
 - [satyasai](https://www.kaggle.com/krishnasai)
 - [SaudAl-Zakwani](https://www.kaggle.com/szakwani)
 - [saurabh singh](https://www.kaggle.com/saurabh00007)
 - [Saurabh Singh](https://www.kaggle.com/saurabh13nov)
 - [Saurabh](https://www.kaggle.com/skhemka)
 - [SaurabhBhagvatula](https://www.kaggle.com/saurabhbhagvatula)
 - [saurav ghosh](https://www.kaggle.com/sauravghosh)
 - [Saurav Kumar](https://www.kaggle.com/saurabhkmr707)
 - [SAURAV SUMAN](https://www.kaggle.com/tastelesswine)
 - [Sauro Grandi](https://www.kaggle.com/saurograndi)
 - [savannahlogan](https://www.kaggle.com/savannahvi)
 - [SavasYÄ±ldÄ±rÄ±m](https://www.kaggle.com/savasy)
 - [Savioz](https://www.kaggle.com/savioz)
 - [sawayaka](https://www.kaggle.com/sawayaka)
 - [Saxinou](https://www.kaggle.com/saxinou)
 - [SazidurRahman](https://www.kaggle.com/sazid28)
 - [SciELO](https://www.kaggle.com/scieloorg)
 - [Scott A. Miller](https://www.kaggle.com/smiller933)
 - [Scott Cole](https://www.kaggle.com/srcole)
 - [Scott](https://www.kaggle.com/pippey)
 - [Scott](https://www.kaggle.com/sfennell)
 - [Scottfree Analytics LLC](https://www.kaggle.com/scottfree)
 - [ScottHendrickson](https://www.kaggle.com/scotth64)
 - [sdorius](https://www.kaggle.com/sdorius)
 - [SeaGoat](https://www.kaggle.com/vbandaru)
 - [Seagullbird](https://www.kaggle.com/seagullbird)
 - [Sean Kelley](https://www.kaggle.com/seangtkelley)
 - [Sean Marjason](https://www.kaggle.com/mrmarjo)
 - [Sean Saito](https://www.kaggle.com/saitosean)
 - [Sean](https://www.kaggle.com/seannn)
 - [SeanKim](https://www.kaggle.com/yuzuri)
 - [SeanLahman](https://www.kaggle.com/seanlahman)
 - [Seattle Public Library](https://www.kaggle.com/seattle-public-library)
 - [Sebastian Mantey](https://www.kaggle.com/sebastianmantey)
 - [Sebastian](https://www.kaggle.com/sebastianp)
 - [sebastianmarkow](https://www.kaggle.com/sebastianmarkow)
 - [SebastianZanabria](https://www.kaggle.com/seussz)
 - [Securities and Exchange Commission](https://www.kaggle.com/securities-exchange-commission)
 - [security3test](https://www.kaggle.com/security3test)
 - [securityteamvictim4](https://www.kaggle.com/securityteamvictim4)
 - [Seetharam Indurti](https://www.kaggle.com/seetzz)
 - [Sekar M G](https://www.kaggle.com/sekarmg)
 - [Selah](https://www.kaggle.com/selahlynch)
 - [Selfish Gene](https://www.kaggle.com/selfishgene)
 - [selvakumar](https://www.kaggle.com/selvakumarvr)
 - [Semin](https://www.kaggle.com/eliotyoon)
 - [SemionKorchevskiy](https://www.kaggle.com/semioniy)
 - [Seong-Jae Chu](https://www.kaggle.com/saychuwho)
 - [SEPTA](https://www.kaggle.com/septa)
 - [Serena Chen](https://www.kaggle.com/y578chen)
 - [Sergei Fironov](https://www.kaggle.com/sergeifironov)
 - [Sergey Kosterin](https://www.kaggle.com/skosterin88)
 - [Sergey Kuznetsov](https://www.kaggle.com/mousehead)
 - [Sergey](https://www.kaggle.com/devorvant)
 - [SergeyA](https://www.kaggle.com/sergeya)
 - [Sergio GQ](https://www.kaggle.com/sergioalbertogq)
 - [SergioGonzalez](https://www.kaggle.com/sergiogq)
 - [SergioPerez](https://www.kaggle.com/sergioperez)
 - [Sergiy Chumachenko](https://www.kaggle.com/chumachenkosergiy)
 - [Serhiy Subota](https://www.kaggle.com/subota)
 - [Serigne ](https://www.kaggle.com/serigne)
 - [SeungHyun Jeon](https://www.kaggle.com/towever)
 - [sevaspb](https://www.kaggle.com/sevaspb)
 - [seyvar](https://www.kaggle.com/seyvar)
 - [SGDE](https://www.kaggle.com/adsa00sgde)
 - [sgDysregulation](https://www.kaggle.com/sophieg)
 - [SH Lee](https://www.kaggle.com/bigshushu)
 - [shabeer](https://www.kaggle.com/pshabeerm)
 - [Shabu KC](https://www.kaggle.com/shabukc)
 - [Shahebaz](https://www.kaggle.com/shaz13)
 - [SHAHUMANGKAMLESHBHAI15BCE1303](https://www.kaggle.com/umangshah97)
 - [Shaik Kamran](https://www.kaggle.com/shaikkamran3)
 - [Shakaed Subin](https://www.kaggle.com/subinshakaed)
 - [Shakti Sharma](https://www.kaggle.com/shaktisharma)
 - [Shakti](https://www.kaggle.com/shaktirajput)
 - [ShalvaRai16MCB0025](https://www.kaggle.com/shalv16mcb0025)
 - [Shams ul arfeen](https://www.kaggle.com/shamsularfeen)
 - [shan](https://www.kaggle.com/shan4224)
 - [Shan](https://www.kaggle.com/shanmugasundarammk)
 - [Shane Smith](https://www.kaggle.com/smid80)
 - [Shang Pengxu](https://www.kaggle.com/shangpx)
 - [Shanger Lin](https://www.kaggle.com/mic771112)
 - [ShaniGershtein](https://www.kaggle.com/sgershtein)
 - [Shankar](https://www.kaggle.com/shankarpandala)
 - [ShantamVijayputra](https://www.kaggle.com/vshantam)
 - [Shantanu Acharya](https://www.kaggle.com/shanwizard)
 - [Shantanu](https://www.kaggle.com/shantanuladhwe)
 - [Shanth](https://www.kaggle.com/shanth84)
 - [Sharadhi V](https://www.kaggle.com/sharadhiv)
 - [Sharan Naribole](https://www.kaggle.com/nsharan)
 - [sharddha](https://www.kaggle.com/sharddha)
 - [Sharon Lin](https://www.kaggle.com/sharonlin)
 - [Shashank ](https://www.kaggle.com/shashankpathak2015)
 - [Shashank Kumar](https://www.kaggle.com/shashank12)
 - [Shashank Shekhar Shukla](https://www.kaggle.com/shashank2011)
 - [Shashank Yadav](https://www.kaggle.com/shashank1558)
 - [ShashankNainwal](https://www.kaggle.com/clayman1)
 - [Shatiel](https://www.kaggle.com/shatiel)
 - [ShaunakChadha](https://www.kaggle.com/hanumanstark)
 - [Shaurya Munshi](https://www.kaggle.com/mshaurya)
 - [Shaurya Munshi](https://www.kaggle.com/shauryamunshi)
 - [ShauryaChawla](https://www.kaggle.com/emorres25)
 - [Shawn Tian](https://www.kaggle.com/zuckgo)
 - [Shayenne Moura](https://www.kaggle.com/shayenne)
 - [Shazad Udwadia](https://www.kaggle.com/shazadudwadia)
 - [Sheik Mohamed Imran](https://www.kaggle.com/imrandude)
 - [Sheikh Asif Imran Shouborno](https://www.kaggle.com/strawhats)
 - [Sheil Naik](https://www.kaggle.com/sheilnaik)
 - [Sheng Guo](https://www.kaggle.com/anyezijue49)
 - [shengwei](https://www.kaggle.com/syushengwei)
 - [shenjiawei](https://www.kaggle.com/shenjiawei)
 - [Sherry_CS](https://www.kaggle.com/sherrycs)
 - [Shihao](https://www.kaggle.com/pulchritudinous)
 - [Shikhar](https://www.kaggle.com/shikhar1)
 - [shilpibhattacharyya](https://www.kaggle.com/shilpibhattacharyya)
 - [shilpitha](https://www.kaggle.com/shilpitha)
 - [shiMu](https://www.kaggle.com/ddongjian0001)
 - [Shiny](https://www.kaggle.com/shinydhar)
 - [shirley](https://www.kaggle.com/shirleyw)
 - [ShiSanCD](https://www.kaggle.com/shisancd)
 - [Shishir](https://www.kaggle.com/shisnir)
 - [Shitao Zeng](https://www.kaggle.com/hjkhjk)
 - [shiv gehlot](https://www.kaggle.com/shivml89)
 - [Shiv Santosh](https://www.kaggle.com/shivsj)
 - [Shiva Manhar](https://www.kaggle.com/shivamanhar)
 - [ShivajiAlaparthi](https://www.kaggle.com/shivaji9999)
 - [Shivam Panchal](https://www.kaggle.com/shivampanchal)
 - [Shivam Patel](https://www.kaggle.com/shivamp629)
 - [Shivam Patel](https://www.kaggle.com/spatel4140)
 - [shivamagrawal](https://www.kaggle.com/shivam2503)
 - [ShivamGoel](https://www.kaggle.com/sg1791)
 - [shivamnijhawan](https://www.kaggle.com/shivamnijhawan96)
 - [ShivinderKapil](https://www.kaggle.com/shivinder)
 - [shodiq](https://www.kaggle.com/shodiqmh)
 - [ShradhaJoshi](https://www.kaggle.com/shradhapj)
 - [Shreeya Bhosale](https://www.kaggle.com/shreeyabhosale)
 - [Shreyams Jain](https://www.kaggle.com/shreyams)
 - [ShreyasSomashekara](https://www.kaggle.com/shreyas0906)
 - [shrihans giriraj meena](https://www.kaggle.com/shrihans)
 - [ShruthiShankar](https://www.kaggle.com/shruthi2512)
 - [Shruti Bhargava](https://www.kaggle.com/shrutibhargava94)
 - [Shubham ](https://www.kaggle.com/slimshady19)
 - [Shubham Barudwale](https://www.kaggle.com/barudwale20)
 - [Shubham Deshmukh](https://www.kaggle.com/shubham619)
 - [SHUBHAM KARANDE](https://www.kaggle.com/shubham17mcb1015)
 - [ShubhamAgarwal](https://www.kaggle.com/shubhamagarwal269)
 - [ShubhamMaurya](https://www.kaggle.com/mauryashubham)
 - [ShubhamPawar](https://www.kaggle.com/shubhmamp)
 - [ShubhamThakur](https://www.kaggle.com/sythakur)
 - [shubhangi](https://www.kaggle.com/shubhangi)
 - [Shuchi](https://www.kaggle.com/shuchirb)
 - [Shuhei Fujiwara](https://www.kaggle.com/sfujiwara)
 - [Shunpoco](https://www.kaggle.com/shunsuke313320)
 - [SHUNYA](https://www.kaggle.com/rahul3321)
 - [shuwenz](https://www.kaggle.com/shuwenz)
 - [Shwet Prakash](https://www.kaggle.com/shwetp)
 - [shweta](https://www.kaggle.com/sk12190n)
 - [shwetabh123](https://www.kaggle.com/shwetabh123)
 - [sibappa](https://www.kaggle.com/sibappa)
 - [sichunlam](https://www.kaggle.com/sichunlam)
 - [Sid Shetty](https://www.kaggle.com/iamsidshetty)
 - [Siddartha](https://www.kaggle.com/siddarthareddyt)
 - [Siddhanth VInay](https://www.kaggle.com/sidvin97)
 - [siddhartha sharan](https://www.kaggle.com/siddharthasharan)
 - [Siddhartha](https://www.kaggle.com/meaninglesslives)
 - [SidG](https://www.kaggle.com/cheedcheed)
 - [sidhant](https://www.kaggle.com/sidhanta)
 - [SidhantDeka](https://www.kaggle.com/sidhant09)
 - [siero](https://www.kaggle.com/siero5335)
 - [SiewKamOnn](https://www.kaggle.com/kosiew)
 - [Siim M](https://www.kaggle.com/kedokedokedo)
 - [Sijo VM](https://www.kaggle.com/sijovm)
 - [silicon99](https://www.kaggle.com/silicon99)
 - [Silogram](https://www.kaggle.com/psilogram)
 - [Silvio Santana](https://www.kaggle.com/silviosantana)
 - [Simo](https://www.kaggle.com/simn93)
 - [Simon Asiimwe](https://www.kaggle.com/asimonp)
 - [Simon Fraser University - Summit](https://www.kaggle.com/sfu-summit)
 - [Simon Gurcke](https://www.kaggle.com/itssimon)
 - [Simon Plovyt](https://www.kaggle.com/simonplovyt)
 - [Simon Tse](https://www.kaggle.com/ghostintheshell)
 - [Simon](https://www.kaggle.com/shuofxz)
 - [Simon](https://www.kaggle.com/simonprevoteaux)
 - [Simon](https://www.kaggle.com/swwintels)
 - [Simone Seregni](https://www.kaggle.com/ssersim)
 - [SimoneDalessio](https://www.kaggle.com/sdalessio)
 - [SimonRazniewski](https://www.kaggle.com/srazniewski)
 - [Sindhu Rao](https://www.kaggle.com/raosindhu)
 - [Sirish](https://www.kaggle.com/sirishamatya)
 - [Siva Kumar](https://www.kaggle.com/dsivakumar)
 - [Siva Swaminathan](https://www.kaggle.com/subraminion)
 - [SiyuanH](https://www.kaggle.com/siyuanh)
 - [SIZZLE](https://www.kaggle.com/SIZZLE)
 - [skakki](https://www.kaggle.com/skakki)
 - [Skalldihor](https://www.kaggle.com/skalldihor)
 - [SkalskiP](https://www.kaggle.com/skalskip)
 - [Skiddie](https://www.kaggle.com/deftskiddie)
 - [SkyLord](https://www.kaggle.com/skylord)
 - [sleight82](https://www.kaggle.com/sleight82)
 - [Smart Revolution](https://www.kaggle.com/cetingzhou)
 - [smeschke](https://www.kaggle.com/smeschke)
 - [smota](https://www.kaggle.com/santiagomota)
 - [sna](https://www.kaggle.com/shoaib)
 - [Snehaa Ganesan](https://www.kaggle.com/gsnehaa21)
 - [snehanshusengupta](https://www.kaggle.com/snehanshu17)
 - [SnehaReddy](https://www.kaggle.com/snehareddy5)
 - [Snow Dog](https://www.kaggle.com/snowdog)
 - [snow2011](https://www.kaggle.com/ilyaivanchenko)
 - [Sofiya](https://www.kaggle.com/sofiyag87)
 - [Sohaib Ali](https://www.kaggle.com/sohaibali)
 - [SohaibOmar](https://www.kaggle.com/sohaibomar)
 - [Soham Patel](https://www.kaggle.com/sohamshp)
 - [sohel](https://www.kaggle.com/sohelhasan)
 - [Sohier Dane](https://www.kaggle.com/sohier)
 - [SohiniBhattacharya](https://www.kaggle.com/sohinibhattacharya86)
 - [Somasundaram Sankaranaraynan](https://www.kaggle.com/somasundaram0504)
 - [somesh](https://www.kaggle.com/somesh)
 - [Sommenoob](https://www.kaggle.com/yang727)
 - [Somnath Roy](https://www.kaggle.com/roysomnath93)
 - [Son Genacrys](https://www.kaggle.com/songenacrys)
 - [Sonali Chawla](https://www.kaggle.com/sona58)
 - [SonamSrivastava](https://www.kaggle.com/sonaam1234)
 - [Song WanG](https://www.kaggle.com/swang215)
 - [soojung](https://www.kaggle.com/csjcsj7477)
 - [soorajms](https://www.kaggle.com/smsubrahmannian)
 - [soroosh](https://www.kaggle.com/sorooshnazem)
 - [Sotopia](https://www.kaggle.com/bakrianoo)
 - [Soufiane Fhiyil](https://www.kaggle.com/soufianefhy95)
 - [soufianeorama](https://www.kaggle.com/soufianeorama)
 - [souhaiel](https://www.kaggle.com/souhaiel)
 - [Souhail Toumdi](https://www.kaggle.com/soutou)
 - [Soukaina](https://www.kaggle.com/soukiii)
 - [Souman Roy](https://www.kaggle.com/souman)
 - [Soumitra Agarwal](https://www.kaggle.com/artimous)
 - [SourabhMittal](https://www.kaggle.com/srbhmitt)
 - [Sourav Nandi](https://www.kaggle.com/souravstat)
 - [Sourav Roy](https://www.kaggle.com/souravroy1)
 - [Sourav Verma](https://www.kaggle.com/srgrace)
 - [SouravMaharana](https://www.kaggle.com/srvmaharana)
 - [SovBoc2018](https://www.kaggle.com/sovannt)
 - [sowhit](https://www.kaggle.com/saisowhit)
 - [Sowmiya Nagarajan](https://www.kaggle.com/codess)
 - [soywu](https://www.kaggle.com/soywugzm)
 - [SpaceX](https://www.kaggle.com/spacex)
 - [Spencer Buja](https://www.kaggle.com/csbuja)
 - [Spider Pig](https://www.kaggle.com/apartmentguru)
 - [sprabakar](https://www.kaggle.com/sprabakar)
 - [Sreeram Reddy Kasarla (SRK16113)](https://www.kaggle.com/ksr102631)
 - [Sreyansh Jain](https://www.kaggle.com/sreyanshjain)
 - [sri charan](https://www.kaggle.com/dgscharan)
 - [Sri Kamma](https://www.kaggle.com/funnelai)
 - [SRI KANTH](https://www.kaggle.com/srikanthkon21)
 - [Sri Manjusha](https://www.kaggle.com/srimanjushatella)
 - [Sri Santhosh Hari](https://www.kaggle.com/srisanthoshhari)
 - [sridhar narasaiahgari](https://www.kaggle.com/sridharnarasaiahgari)
 - [Sridhar](https://www.kaggle.com/sridar1803)
 - [Srihari Vasudevan](https://www.kaggle.com/sriharivasu)
 - [SrihariRao](https://www.kaggle.com/sriharirao)
 - [Srilakshmi](https://www.kaggle.com/srilakshminagesh)
 - [srilakshminandamuri](https://www.kaggle.com/nandamuri)
 - [SriLBG](https://www.kaggle.com/srilbg)
 - [Srinath Sridharan](https://www.kaggle.com/srinath2648)
 - [SrinivasRao](https://www.kaggle.com/srinivas1)
 - [SriniVinnakota](https://www.kaggle.com/srinivinnakota)
 - [SRK](https://www.kaggle.com/sudalairajkumar)
 - [Ssvitian](https://www.kaggle.com/ssvitian)
 - [Stack Overflow](https://www.kaggle.com/stackoverflow)
 - [Stan](https://www.kaggle.com/stan2517)
 - [Stanford Network Analysis Project ](https://www.kaggle.com/snap)
 - [Stanford Open Policing Project](https://www.kaggle.com/stanford-open-policing)
 - [Stanford University](https://www.kaggle.com/stanfordu)
 - [Starbucks](https://www.kaggle.com/starbucks)
 - [starconf](https://www.kaggle.com/starinconf)
 - [starmine.ai](https://www.kaggle.com/biomimic)
 - [START Consortium](https://www.kaggle.com/START-UMD)
 - [Startup Policy Lab](https://www.kaggle.com/startuppolicylab)
 - [stawary](https://www.kaggle.com/stawary)
 - [steal](https://www.kaggle.com/tbsteal)
 - [SteeveHuang](https://www.kaggle.com/huangkh19951228)
 - [Stefanie04736](https://www.kaggle.com/stefanie04736)
 - [Stephan Andre](https://www.kaggle.com/sandreds)
 - [Stephan Wessels](https://www.kaggle.com/slwessels)
 - [Stephane Bernadac](https://www.kaggle.com/sbernadac)
 - [Stephanerappeneau](https://www.kaggle.com/stephanerappeneau)
 - [Stephanie Le Grange](https://www.kaggle.com/slegra78)
 - [Stephen Cranney](https://www.kaggle.com/scranney)
 - [Stephen Huan](https://www.kaggle.com/vazarum)
 - [Stephen McGlennon](https://www.kaggle.com/srmcglennon)
 - [Stephen Thompson](https://www.kaggle.com/coffeenmusic)
 - [Stephen](https://www.kaggle.com/sbrady)
 - [StephRouen](https://www.kaggle.com/stephrouen)
 - [Steve Ahn](https://www.kaggle.com/dsteveahn)
 - [Steve Joly](https://www.kaggle.com/sjoly123)
 - [Steve Palley](https://www.kaggle.com/stevepalley)
 - [Steven Venezie](https://www.kaggle.com/svenezie)
 - [SteveN](https://www.kaggle.com/sniafas)
 - [Steven](https://www.kaggle.com/stevenknguyen)
 - [Stoddy](https://www.kaggle.com/jwstodd)
 - [stonepurple](https://www.kaggle.com/stonepurple)
 - [Streichholz](https://www.kaggle.com/aihsani)
 - [Stuart Chan](https://www.kaggle.com/stuart002)
 - [Stuart Colianni](https://www.kaggle.com/scolianni)
 - [stytch](https://www.kaggle.com/stytch16)
 - [Styven Ponnusamy](https://www.kaggle.com/styven)
 - [SubarnaRana](https://www.kaggle.com/subarnarana1)
 - [Subham Das](https://www.kaggle.com/subhamdas)
 - [Subhransu Sekhar Sahoo](https://www.kaggle.com/subhransuss)
 - [Submarineering](https://www.kaggle.com/submarineering)
 - [Subra](https://www.kaggle.com/nssubramanya)
 - [Suchit Gupta](https://www.kaggle.com/suchitgupta60)
 - [Sudarshan](https://www.kaggle.com/sdevkota007)
 - [Sudeepta Kkr](https://www.kaggle.com/skr912)
 - [Sudheej Sudhakaran](https://www.kaggle.com/sudheej)
 - [Sudheer Sankar](https://www.kaggle.com/sudheersankar)
 - [Sudhir Thuppale](https://www.kaggle.com/sudhirtk)
 - [Sudip Das](https://www.kaggle.com/sudipdas)
 - [Suhel](https://www.kaggle.com/suhelm)
 - [Sujan Ghimire](https://www.kaggle.com/sujanme)
 - [sujan](https://www.kaggle.com/sujanpokharel)
 - [Sujay Khandagale](https://www.kaggle.com/sujaykhandagale)
 - [Sujith](https://www.kaggle.com/samuelsujith)
 - [sujithramkotagiri](https://www.kaggle.com/ksujithram)
 - [Sulata Patra](https://www.kaggle.com/anshilata)
 - [sultan](https://www.kaggle.com/sultanmkhan)
 - [sumanth](https://www.kaggle.com/sumanthpola)
 - [SumanthSRao](https://www.kaggle.com/sumanthrao)
 - [sumendar](https://www.kaggle.com/sumendar)
 - [Sumit Bhongale](https://www.kaggle.com/sumithbhongale)
 - [Sumit Kant](https://www.kaggle.com/sumitkant)
 - [Sumit Kothari](https://www.kaggle.com/usersumit)
 - [Sumit Kumar](https://www.kaggle.com/sirpunch)
 - [Sumit](https://www.kaggle.com/sumit9)
 - [SunDai](https://www.kaggle.com/friday20121221)
 - [SuneetSawant](https://www.kaggle.com/suneet94)
 - [Sungpil Han](https://www.kaggle.com/shanmdphd)
 - [Sunil Kumar SV](https://www.kaggle.com/sunilkumarsv)
 - [Sunil Neurgaonkar](https://www.kaggle.com/sunilneurgaonkar)
 - [Sunil Sethi](https://www.kaggle.com/sunilsethi25)
 - [sunilp](https://www.kaggle.com/sunilp)
 - [sunmarkil](https://www.kaggle.com/sunmarkil)
 - [SuperDave](https://www.kaggle.com/superdave)
 - [Suprabhat Tiwari](https://www.kaggle.com/suprabhat)
 - [Suprabhat Tiwari](https://www.kaggle.com/suprabhatt)
 - [SupriyaDubey](https://www.kaggle.com/priyasd)
 - [Surabhi](https://www.kaggle.com/surabhitomer)
 - [Suraj](https://www.kaggle.com/surajcet)
 - [SurajPathak](https://www.kaggle.com/freesuraj)
 - [Suresh Bhusare](https://www.kaggle.com/sureshbhusare)
 - [SureshSrinivas](https://www.kaggle.com/sureshsrinivas)
 - [SuryaSista](https://www.kaggle.com/sistasp)
 - [Susan Noboa](https://www.kaggle.com/snoboay)
 - [Susan Wang](https://www.kaggle.com/rabbitsusan)
 - [susanna](https://www.kaggle.com/susannayangcao)
 - [sushant ](https://www.kaggle.com/sushant120)
 - [Sushant jha](https://www.kaggle.com/sushantjha8)
 - [Susmitha](https://www.kaggle.com/susmithamanda)
 - [Sustainable Development Solutions Network](https://www.kaggle.com/unsdsn)
 - [Svidon](https://www.kaggle.com/svidon)
 - [Swami Krishnamurthy](https://www.kaggle.com/nathsri1983)
 - [Swapnil](https://www.kaggle.com/swapni1)
 - [swapnilkale](https://www.kaggle.com/swappyk)
 - [SwaroopVenigalla](https://www.kaggle.com/swaroopvenigalla)
 - [Swathi Priyadarsini ](https://www.kaggle.com/kswathipriya)
 - [swati](https://www.kaggle.com/kianswati)
 - [Swatish Swaminathan](https://www.kaggle.com/swatish)
 - [Swayam Mittal](https://www.kaggle.com/swayammittal65)
 - [Sweety ](https://www.kaggle.com/sweetyparmar1)
 - [SwetaAgrawal](https://www.kaggle.com/swetaagrawal)
 - [Sylas](https://www.kaggle.com/jsylas)
 - [Sylvia Mittal](https://www.kaggle.com/sylvia23)
 - [Szery](https://www.kaggle.com/szerus)
 - [Szkript](https://www.kaggle.com/szkript)
 - [szrlee](https://www.kaggle.com/szrlee)
 - [T Byrnes](https://www.kaggle.com/tbyrnes)
 - [T McKetterick](https://www.kaggle.com/tmcketterick)
 - [T Michaels](https://www.kaggle.com/tommichaels)
 - [T Peng](https://www.kaggle.com/tzp5165)
 - [T. Scharf](https://www.kaggle.com/scharf)
 - [T](https://www.kaggle.com/tudor9)
 - [T7 - Pokemon Challenge](https://www.kaggle.com/terminus7)
 - [TadashiNagao](https://www.kaggle.com/zanjibar)
 - [Taffey Lewis](https://www.kaggle.com/taffeylewis)
 - [Taha Zerrouki](https://www.kaggle.com/linuxscout)
 - [Tahsin Mayeesha](https://www.kaggle.com/mayeesha)
 - [TaichiWang](https://www.kaggle.com/taichi53719)
 - [Taimur Khan](https://www.kaggle.com/taimurkhan)
 - [TaiwoO.Adetiloye](https://www.kaggle.com/taiwotman)
 - [Taka](https://www.kaggle.com/taka152)
 - [takuoko](https://www.kaggle.com/takuok)
 - [Tamber](https://www.kaggle.com/tamber)
 - [Tamil Dhoni](https://www.kaggle.com/tamilarasu75)
 - [Tamilselvan Sudalai](https://www.kaggle.com/tamilsud)
 - [Tammy Rotem](https://www.kaggle.com/tammyrotem)
 - [Tan Kinh Bui](https://www.kaggle.com/tankinhbui)
 - [Tang Yiming](https://www.kaggle.com/tymatfd)
 - [tanishk parihar](https://www.kaggle.com/tan305)
 - [tankeestka](https://www.kaggle.com/tankeestka)
 - [TANYA MAKKAR ](https://www.kaggle.com/tanyamakkar123)
 - [TÃº Anh HoÃ ng](https://www.kaggle.com/hoangtuanh1805)
 - [Tara Rutkowski](https://www.kaggle.com/taradaqtal)
 - [Taraprasanna Saha Babu](https://www.kaggle.com/sahababu)
 - [Taras](https://www.kaggle.com/ustyk5)
 - [tarek benkhelif](https://www.kaggle.com/tarekbenkhelif)
 - [Tarun Khanna](https://www.kaggle.com/tennispro1213)
 - [TARUN KUMAR](https://www.kaggle.com/tarunkumar)
 - [tdougherty223](https://www.kaggle.com/tdougherty223)
 - [Team AI](https://www.kaggle.com/team-ai)
 - [Team PuppyGoGo](https://www.kaggle.com/puppygogo)
 - [techmn](https://www.kaggle.com/techmn)
 - [teck44""><](https://www.kaggle.com/teck44)
 - [tecperson](https://www.kaggle.com/datamunge)
 - [TehreemAnsari](https://www.kaggle.com/tehreem)
 - [tejasvagarwal](https://www.kaggle.com/tejasvdante)
 - [Temilade Adefioye Aina](https://www.kaggle.com/apttemi)
 - [Teng Lei](https://www.kaggle.com/nichaoku)
 - [Teodosiy](https://www.kaggle.com/openaimaniac)
 - [TeraFlops](https://www.kaggle.com/sekrier)
 - [TerenceLiu](https://www.kaggle.com/terenceliu4444)
 - [Terminal Security Agency](https://www.kaggle.com/terminal-security-agency)
 - [test ""><img src=x onerror=alert(document.domain)>](https://www.kaggle.com/buggyguy)
 - [test""><img src=x>](https://www.kaggle.com/test123654)
 - [test](https://www.kaggle.com/rajauzairabdullah)
 - [test](https://www.kaggle.com/strukt)
 - [test2""><](https://www.kaggle.com/tona9900)
 - [testaccountkagglee](https://www.kaggle.com/testaccountkagglee)
 - [testbugmasooddd](https://www.kaggle.com/testbugmasooddd)
 - [tester](https://www.kaggle.com/hkpow2)
 - [TESTIMON @ NTNU](https://www.kaggle.com/ntnu-testimon)
 - [testingshi](https://www.kaggle.com///facebook.com)
 - [TetianaMyronivska](https://www.kaggle.com/mtetiana)
 - [TetyanaLoskutova](https://www.kaggle.com/tetyanal)
 - [TetyanaYatsenko](https://www.kaggle.com/tetyanayatsenko)
 - [TEVEC Systems](https://www.kaggle.com/tevecsystems)
 - [Thais Rodrigues Neubauer](https://www.kaggle.com/thaisneubauer)
 - [thaisalmeida](https://www.kaggle.com/thaisalmeida)
 - [Thanakom Sangnetra](https://www.kaggle.com/thanakomsn)
 - [thanuj](https://www.kaggle.com/thanuj11)
 - [Thao](https://www.kaggle.com/vuthao)
 - [Tharini Padmagirisan](https://www.kaggle.com/tharini)
 - [The Bear](https://www.kaggle.com/saramahar)
 - [The BGU Cyber Security Research Center](https://www.kaggle.com/BGU-CSRC)
 - [The Fellow](https://www.kaggle.com/ardenn)
 - [The Flying Munkey](https://www.kaggle.com/theflyingmunkey)
 - [The Guardian](https://www.kaggle.com/the-guardian)
 - [The Huffington Post](https://www.kaggle.com/huffingtonpost)
 - [The Marshall Project](https://www.kaggle.com/marshallproject)
 - [The Metropolitan Museum of Art](https://www.kaggle.com/metmuseum)
 - [The Movie Database (TMDb)](https://www.kaggle.com/tmdb)
 - [The Museum of Modern Art](https://www.kaggle.com/momanyc)
 - [The Nobel Foundation](https://www.kaggle.com/nobelfoundation)
 - [The Smithsonian Institution](https://www.kaggle.com/smithsonian)
 - [The Wall Street Journal](https://www.kaggle.com/wsj)
 - [The Washington Post](https://www.kaggle.com/washingtonpost)
 - [the1owl](https://www.kaggle.com/the1owl)
 - [Theo Ioa](https://www.kaggle.com/codeteo)
 - [TheScientistBR](https://www.kaggle.com/TheScientistBR)
 - [thetraderrr](https://www.kaggle.com/thetraderrr)
 - [Theudas](https://www.kaggle.com/theudas)
 - [Thiago Balbo](https://www.kaggle.com/thibalbo)
 - [Thiago Oliveira](https://www.kaggle.com/pintowar)
 - [Thinh Uy Quang](https://www.kaggle.com/takahirotachi)
 - [THIRU MAALAVAN](https://www.kaggle.com/thirumaalavan)
 - [Thobani Hlophe](https://www.kaggle.com/thobani)
 - [Thomas De Jonghe](https://www.kaggle.com/jinxbe)
 - [Thomas Nelson](https://www.kaggle.com/thomasnelson)
 - [Thomas Pappas](https://www.kaggle.com/tpapp157)
 - [Thomas Ranvier](https://www.kaggle.com/thomasranvier)
 - [Thomas Wade Culbertson](https://www.kaggle.com/ugnix911aalc)
 - [Thomas](https://www.kaggle.com/thomasd9)
 - [ThomasLuby](https://www.kaggle.com/bluehorseshoe)
 - [ThomasVoreyer](https://www.kaggle.com/tvoreyer)
 - [THORODINOVICH](https://www.kaggle.com/thorinhood)
 - [Thought Vector](https://www.kaggle.com/thoughtvector)
 - [throne1032](https://www.kaggle.com/throne1032)
 - [ThuanHieu](https://www.kaggle.com/thuanhieu147)
 - [Thulani Tembo](https://www.kaggle.com/thulani96)
 - [Tiago V. Melo](https://www.kaggle.com/tiagovmelo)
 - [Tiago Vinhoza](https://www.kaggle.com/tiagotvv)
 - [Tiantian](https://www.kaggle.com/tiantianchen76)
 - [Tianyi Wang](https://www.kaggle.com/tianyiwang)
 - [Tigran Davtyan](https://www.kaggle.com/tigran97)
 - [Tilak](https://www.kaggle.com/tilakd)
 - [Tim Hradil](https://www.kaggle.com/timhradil)
 - [Tim Kartawijaya](https://www.kaggle.com/timkartawijaya)
 - [Tim Pearce](https://www.kaggle.com/trpearce)
 - [Time Magazine](https://www.kaggle.com/timemagazine)
 - [Timo Bozsolik](https://www.kaggle.com/timoboz)
 - [Timothy Leung](https://www.kaggle.com/timleunghk)
 - [TimRu](https://www.kaggle.com/timrus)
 - [timsyang](https://www.kaggle.com/timschutzyang)
 - [Ting Zhou](https://www.kaggle.com/ztlevi)
 - [tiredgeek](https://www.kaggle.com/tiredgeek)
 - [TirthGajjar](https://www.kaggle.com/tirthgajjar)
 - [Tito Maraca](https://www.kaggle.com/elyisu)
 - [tivoli2](https://www.kaggle.com/tivoli2)
 - [Tiziano Teso](https://www.kaggle.com/tesotiziano)
 - [Tjb5670](https://www.kaggle.com/tjb5670)
 - [TK](https://www.kaggle.com/tttkkk)
 - [tmthyjames](https://www.kaggle.com/tmthyjames)
 - [TobeyStrauch](https://www.kaggle.com/tobey1)
 - [toby jolly](https://www.kaggle.com/teajay)
 - [Tolu Toluhi](https://www.kaggle.com/toluoverscore)
 - [Tom Bombadil](https://www.kaggle.com/haixili2007)
 - [Tom Hill](https://www.kaggle.com/thomill)
 - [TomÃ¡s Accini](https://www.kaggle.com/tomasaccini)
 - [TomÃ¡s Bustamante](https://www.kaggle.com/bustamantejt)
 - [Tomasz Bartczak](https://www.kaggle.com/kretes)
 - [Tomato](https://www.kaggle.com/kebabdk400)
 - [Tomer Eldor](https://www.kaggle.com/tomerel)
 - [Tomi-Andre](https://www.kaggle.com/tomiandrep)
 - [tommert](https://www.kaggle.com/tommert)
 - [Tommy Pompo](https://www.kaggle.com/tpompo)
 - [TomNeeld](https://www.kaggle.com/tomneeld)
 - [Tomo](https://www.kaggle.com/dosukoi)
 - [Tony Pino](https://www.kaggle.com/anthonypino)
 - [Tony Xie](https://www.kaggle.com/tonyxie)
 - [TonyChan](https://www.kaggle.com/tonychanyt)
 - [tophatsteve](https://www.kaggle.com/tophatsteve)
 - [torr](https://www.kaggle.com/ayush01)
 - [Toshnoue](https://www.kaggle.com/toshinoue)
 - [TP](https://www.kaggle.com/tharindraparanagama)
 - [traceyvanp](https://www.kaggle.com/traceyvanp)
 - [tranndo](https://www.kaggle.com/tranndo)
 - [Transparency International](https://www.kaggle.com/transparencyint)
 - [Trent Baur](https://www.kaggle.com/trentbaur)
 - [Trey Kollmer](https://www.kaggle.com/treykollmer)
 - [TripleFireYan](https://www.kaggle.com/yansun1996)
 - [Trond Magne Lamprecht Haaland](https://www.kaggle.com/trondmagne)
 - [TruMedicines](https://www.kaggle.com/trumedicines)
 - [Truong An](https://www.kaggle.com/ancs21)
 - [Truth Lover](https://www.kaggle.com/tjtong)
 - [tsimins](https://www.kaggle.com/tsiresi)
 - [Tuhin Saha](https://www.kaggle.com/tuhinsaha84)
 - [Tung Thanh Le](https://www.kaggle.com/ttungl)
 - [tusha kutusha](https://www.kaggle.com/aradzhabov)
 - [Tushar Dhyani](https://www.kaggle.com/thanatoz)
 - [Tushar Gupta](https://www.kaggle.com/tushar987)
 - [Tushar Mahendra Patil](https://www.kaggle.com/tusharpatil15)
 - [Tushar Makkar](https://www.kaggle.com/tusharmakkar)
 - [Tushar Yadav](https://www.kaggle.com/tusharyad)
 - [tvscitechtalk](https://www.kaggle.com/tvscitechtalk)
 - [TwistFateBOY](https://www.kaggle.com/twistfateboy)
 - [TY](https://www.kaggle.com/tywangty)
 - [tyjzhong](https://www.kaggle.com/tyjzhong)
 - [tylerfuller](https://www.kaggle.com/tylerfuller)
 - [TylerTuschhoff](https://www.kaggle.com/tsquared)
 - [u_kag](https://www.kaggle.com/utkarshasthana)
 - [U.S. National Archives and Records Administration](https://www.kaggle.com/national-archives)
 - [UC San Diego](https://www.kaggle.com/ucsandiego)
 - [UCI Machine Learning](https://www.kaggle.com/uciml)
 - [Udacity](https://www.kaggle.com/udacity)
 - [UDAS](https://www.kaggle.com/k2sguard)
 - [Uday](https://www.kaggle.com/udaykp)
 - [Uddeshya Singh](https://www.kaggle.com/uds5501)
 - [Udeme Udofia](https://www.kaggle.com/udemeudofia)
 - [ugocupcic](https://www.kaggle.com/ugocupcic)
 - [Ujjwal Kr Gupta](https://www.kaggle.com/ujjwalkg)
 - [Ujjwal](https://www.kaggle.com/ujjwal9)
 - [Ujjwal](https://www.kaggle.com/ujjwalsaxena)
 - [ultra-jack](https://www.kaggle.com/ultrajack)
 - [Umakant](https://www.kaggle.com/umakantjena)
 - [Umang Dhiman](https://www.kaggle.com/umangdhiman)
 - [Umberto](https://www.kaggle.com/umbertogriffo)
 - [umut](https://www.kaggle.com/iklotho)
 - [Union of Concerned Scientists](https://www.kaggle.com/ucsusa)
 - [United Nations Development Program](https://www.kaggle.com/undp)
 - [United Nations](https://www.kaggle.com/unitednations)
 - [United States Air Force](https://www.kaggle.com/usaf)
 - [United States Department of Agriculture](https://www.kaggle.com/usdeptofag)
 - [United States Drought Monitor](https://www.kaggle.com/us-drought-monitor)
 - [University of Connecticut](https://www.kaggle.com/uconn)
 - [University of Copenhagen](https://www.kaggle.com/University-of-Copenhagen)
 - [University of Michigan](https://www.kaggle.com/umichigan)
 - [University of North Texas](https://www.kaggle.com/unt)
 - [University of Pittsburgh](https://www.kaggle.com/pitt)
 - [University of Virginia](https://www.kaggle.com/university-of-virginia)
 - [uranio255](https://www.kaggle.com/uranio255)
 - [UrvangPatel](https://www.kaggle.com/urvang)
 - [US Bureau of Labor Statistics](https://www.kaggle.com/bls)
 - [US Census Bureau](https://www.kaggle.com/census)
 - [US Customs and Border Protection](https://www.kaggle.com/cbp)
 - [US Department of Agriculture](https://www.kaggle.com/usda)
 - [US Department of Energy](https://www.kaggle.com/us-doe)
 - [US Department of Health and Human Services](https://www.kaggle.com/hhs)
 - [US Environmental Protection Agency](https://www.kaggle.com/epa)
 - [US Geological Survey](https://www.kaggle.com/usgs)
 - [US Patent and Trademark Office](https://www.kaggle.com/uspto)
 - [US Senate](https://www.kaggle.com/senate)
 - [USB](https://www.kaggle.com/utsavbanka)
 - [usfundamentals](https://www.kaggle.com/usfundamentals)
 - [ushchent](https://www.kaggle.com/ushchent)
 - [Utagh](https://www.kaggle.com/utathya)
 - [Utkarsh Aggarwal](https://www.kaggle.com/utkarshaggarwal)
 - [utmhikari](https://www.kaggle.com/utmhikari)
 - [uttahjazz](https://www.kaggle.com/ubonguttah)
 - [V.A. Freeman](https://www.kaggle.com/m3financial)
 - [V81msk](https://www.kaggle.com/v81msk)
 - [Vadim Shmelev](https://www.kaggle.com/wadims)
 - [Vahe Andonians](https://www.kaggle.com/andonians)
 - [Vahik95](https://www.kaggle.com/vahe95)
 - [vaibhav_varshney](https://www.kaggle.com/vaibhavvarshney0)
 - [vaibhavgeek](https://www.kaggle.com/vaibhavgeek)
 - [Vaibhavi Singh](https://www.kaggle.com/didi17)
 - [Vaibs](https://www.kaggle.com/vaibhao)
 - [Valentina C](https://www.kaggle.com/carusova)
 - [Valeria BarÃ³n](https://www.kaggle.com/valabaron)
 - [ValerieSalazar](https://www.kaggle.com/valsal27)
 - [Valerio Luciani](https://www.kaggle.com/valeriol93)
 - [Valerio Luzzi](https://www.kaggle.com/valluzzi)
 - [ValerioVaccaro](https://www.kaggle.com/valeriovaccaro)
 - [vanAmsen](https://www.kaggle.com/vanamsen)
 - [Vanessa ](https://www.kaggle.com/vanessaboucinha)
 - [Vardan](https://www.kaggle.com/vardan95ghazaryan)
 - [VarDial](https://www.kaggle.com/vardial)
 - [Varun Belliappa](https://www.kaggle.com/varunbelliappa)
 - [Varun Bhargava](https://www.kaggle.com/varunbhargava17)
 - [Varun Kashyap.K.S.](https://www.kaggle.com/varunkashyapks)
 - [varunagarwal](https://www.kaggle.com/aguyhasnoname)
 - [vasilisnikolaou](https://www.kaggle.com/vasilis73)
 - [VasyaVologdin](https://www.kaggle.com/dogama)
 - [Vedant Ruparelia](https://www.kaggle.com/vedantnr)
 - [VedapragnaReddy](https://www.kaggle.com/vedapragnareddy)
 - [Vein](https://www.kaggle.com/veinpy)
 - [Venkat Ramakrishnan](https://www.kaggle.com/venkatramakrishnan)
 - [VenkataDuvvuri](https://www.kaggle.com/ramanamurthy)
 - [VenkataSivaAbhishek](https://www.kaggle.com/hanumanjunction)
 - [Venkatesh Madhava](https://www.kaggle.com/venmadh)
 - [Venkateshgopal](https://www.kaggle.com/venkateshgopal)
 - [Vera Lei](https://www.kaggle.com/veralei)
 - [Vered Shwartz](https://www.kaggle.com/vered1986)
 - [verginer](https://www.kaggle.com/alucaria)
 - [Veysel Kocaman](https://www.kaggle.com/vkocaman)
 - [Vicc Alexander](https://www.kaggle.com/viccalexander)
 - [Vicky1](https://www.kaggle.com/vignesh1234)
 - [VickyLee](https://www.kaggle.com/vickylee745)
 - [Victor dos Santos](https://www.kaggle.com/m1thr4nd1r)
 - [Victor Genin](https://www.kaggle.com/victorgenin)
 - [Victor Hugo](https://www.kaggle.com/vhcg77)
 - [Victor Paslay](https://www.kaggle.com/vpaslay)
 - [Victor](https://www.kaggle.com/zhangruinan9652)
 - [victor7246](https://www.kaggle.com/victor7246)
 - [VictorElie](https://www.kaggle.com/victorelie07)
 - [VictorGrobberio](https://www.kaggle.com/victorgrobberio)
 - [Vidhu Shekhar Tripathi](https://www.kaggle.com/vidhushekhart)
 - [viditjain](https://www.kaggle.com/viditj)
 - [Vignesh Varadarajan](https://www.kaggle.com/vigneshv59)
 - [vihan](https://www.kaggle.com/vihansp)
 - [vijay dhameliya](https://www.kaggle.com/dhamvi01)
 - [vijay](https://www.kaggle.com/vijayaghanapathy)
 - [Vijaykumar Ummadisetty](https://www.kaggle.com/vijayuv)
 - [VijayN](https://www.kaggle.com/vijaychowthri)
 - [Vikas Kamath M](https://www.kaggle.com/vikasjce)
 - [Vikas Pandey](https://www.kaggle.com/vikasp)
 - [VikasSangwan](https://www.kaggle.com/trekkerthemaker)
 - [vikassrivastava](https://www.kaggle.com/onlyricks)
 - [vikrant yadav](https://www.kaggle.com/vikrant4)
 - [VikrantThakur](https://www.kaggle.com/vikrantthakur14)
 - [Viktor Malyi](https://www.kaggle.com/vmalyi)
 - [ViktoriaSuponenko](https://www.kaggle.com/vikichocolate)
 - [vinay shanbhag](https://www.kaggle.com/vinayshanbhag)
 - [Vinayagam.D.Ganesh](https://www.kaggle.com/vinaylogics)
 - [vinceallenvince](https://www.kaggle.com/vinceallenvince)
 - [Vincent Assoun](https://www.kaggle.com/vincenta1812)
 - [VincentLa](https://www.kaggle.com/vincela9)
 - [VineetKothari](https://www.kaggle.com/vineetkothari)
 - [vinodkumar](https://www.kaggle.com/vinodkumarcvk)
 - [Viraj Bhambri](https://www.kaggle.com/virajb)
 - [Virginie Do](https://www.kaggle.com/virginiedo)
 - [VirgoData](https://www.kaggle.com/virgodata)
 - [viru](https://www.kaggle.com/virugadde)
 - [Vish Chekuri](https://www.kaggle.com/chekuri1961)
 - [Vish Vishal](https://www.kaggle.com/altavish)
 - [VishakhHegde](https://www.kaggle.com/vishakhhegde)
 - [VISHAL MODAGEKAR](https://www.kaggle.com/vishalmodagekar)
 - [VishnuRaghavan](https://www.kaggle.com/vishnusraghavan)
 - [Vishwas Shrikhande](https://www.kaggle.com/vishwasshrikhande)
 - [Vishwesh S](https://www.kaggle.com/vishweshs)
 - [viswateja gajulavarthy](https://www.kaggle.com/viswatejag)
 - [Vitalii Peretiatko](https://www.kaggle.com/vitaliiperetiatko)
 - [Vitaly Burachyonok](https://www.kaggle.com/byrachonok)
 - [Vitaly Korchagin](https://www.kaggle.com/vitalykorchagin)
 - [Vitor R. F.](https://www.kaggle.com/vitorrf)
 - [Vivek Chutke](https://www.kaggle.com/vivekchutke)
 - [Vivek Kumar](https://www.kaggle.com/viveknium)
 - [Vivek Pandey](https://www.kaggle.com/thevivekpandey)
 - [Vivek Singh](https://www.kaggle.com/viv541)
 - [VivekGopinathlal](https://www.kaggle.com/vivekgopinathlal)
 - [VivekMangipudi](https://www.kaggle.com/stansilas)
 - [Vivian l](https://www.kaggle.com/vivianl0)
 - [Vivin Abraham](https://www.kaggle.com/vsa5027)
 - [vl](https://www.kaggle.com/dogedoge)
 - [Vlad Golubev](https://www.kaggle.com/golubev)
 - [vlad.pambucol](https://www.kaggle.com/pambucol)
 - [VladB](https://www.kaggle.com/vladb37)
 - [vladifidchuk](https://www.kaggle.com/vladifidchuk)
 - [Vladimir Alencar](https://www.kaggle.com/valencar)
 - [Vladimir Belyaev](https://www.kaggle.com/vbelyaev)
 - [Vladimir Gmyzin](https://www.kaggle.com/pushero)
 - [Vladimir Kiselev](https://www.kaggle.com/wikiselev)
 - [Vladimir Kuznetsov](https://www.kaggle.com/miracula)
 - [Vladislav Zavadskyy](https://www.kaggle.com/zavadskyy)
 - [Volodymyr Sadovyy](https://www.kaggle.com/vovsad)
 - [Vonage Garage](https://www.kaggle.com/vonagegarage)
 - [voronwe2007](https://www.kaggle.com/voronwe2007)
 - [VoteView](https://www.kaggle.com/voteview)
 - [Vrushali Patel](https://www.kaggle.com/vrushalipatel)
 - [vsmolyakov](https://www.kaggle.com/vsmolyakov)
 - [Vyas](https://www.kaggle.com/vedavyasv)
 - [W. Yifan](https://www.kaggle.com/evanwang1028)
 - [Wal8800](https://www.kaggle.com/wal8800)
 - [walla2ae](https://www.kaggle.com/walla2ae)
 - [Wally Atkins](https://www.kaggle.com/wallyatkins)
 - [Walter_Sam](https://www.kaggle.com/samirankundustat)
 - [wanglaiqi](https://www.kaggle.com/wanglaiqi)
 - [WangQiucheng](https://www.kaggle.com/idealmaster)
 - [wangtianju](https://www.kaggle.com/wangtianju)
 - [WanqiWang](https://www.kaggle.com/wanqwang)
 - [Waqas Malik](https://www.kaggle.com/waqasafz)
 - [Ward Bradt](https://www.kaggle.com/wardbradt)
 - [Warren Elder](https://www.kaggle.com/warrenelder)
 - [warrentnt](https://www.kaggle.com/warrentnt)
 - [Washim Ahmed](https://www.kaggle.com/washimahmed)
 - [Washington University](https://www.kaggle.com/wustl)
 - [Watts](https://www.kaggle.com/watts2)
 - [Wayne Haubner](https://www.kaggle.com/whaubner)
 - [WayneC](https://www.kaggle.com/chanfai514)
 - [Wazeed](https://www.kaggle.com/wazeed)
 - [Web IR](https://www.kaggle.com/webirlab)
 - [WebDev](https://www.kaggle.com/webdevday)
 - [weeliangng](https://www.kaggle.com/weeliangng)
 - [Wei Chun Chang](https://www.kaggle.com/justjun0321)
 - [Wei Ouyang](https://www.kaggle.com/weiouyang)
 - [weibo](https://www.kaggle.com/webber008wang)
 - [weisinhong](https://www.kaggle.com/weisinhong)
 - [wellll](https://www.kaggle.com/wellll)
 - [WENBOCAO](https://www.kaggle.com/wenbocao)
 - [wenchen](https://www.kaggle.com/wenchenkof2001)
 - [Wenchi](https://www.kaggle.com/zhangwenchi)
 - [Wendy Kan](https://www.kaggle.com/wendykan)
 - [wenlong](https://www.kaggle.com/longwade)
 - [WesDuckett](https://www.kaggle.com/wduckett)
 - [wh0801](https://www.kaggle.com/wh0801)
 - [whosonit 1](https://www.kaggle.com/whosonit1)
 - [WÎ”](https://www.kaggle.com/keplersmachines)
 - [Wijdan Aljumiah](https://www.kaggle.com/wijdan)
 - [wil o c ward](https://www.kaggle.com/wilocw)
 - [WildGrok](https://www.kaggle.com/wildgrok)
 - [Wilian Osaku](https://www.kaggle.com/wosaku)
 - [Will Gao](https://www.kaggle.com/pirateshadow)
 - [will hunt](https://www.kaggle.com/glovepm)
 - [WillamGreen](https://www.kaggle.com/dskswu)
 - [William Cao](https://www.kaggle.com/williamcao)
 - [William Cukierski](https://www.kaggle.com/wcukierski)
 - [William Hyde](https://www.kaggle.com/wjhyde1)
 - [William Straus](https://www.kaggle.com/willstr)
 - [William Walter](https://www.kaggle.com/colara)
 - [williamnowak](https://www.kaggle.com/wpncrh)
 - [Willie Liao](https://www.kaggle.com/willieliao)
 - [willinghorse](https://www.kaggle.com/jiezi2004)
 - [Winastwan Gora](https://www.kaggle.com/winastwangora)
 - [Windson](https://www.kaggle.com/fengshenfeilian)
 - [Windy Torgerud](https://www.kaggle.com/windytorgerud)
 - [Winnie](https://www.kaggle.com/awenqi)
 - [WNYC](https://www.kaggle.com/wnyc)
 - [WojciechWÅ‚odarczyk](https://www.kaggle.com/heolin)
 - [Wol4ara_Vio](https://www.kaggle.com/wol4aravio)
 - [Work1810](https://www.kaggle.com/mywork1810)
 - [World Bank](https://www.kaggle.com/theworldbank)
 - [World Bank](https://www.kaggle.com/worldbank)
 - [World Economic Forum](https://www.kaggle.com/weforum)
 - [WorldValueSurvey](https://www.kaggle.com/worldvaluesurvey)
 - [woutervh88](https://www.kaggle.com/woutervh88)
 - [WrackShipParty](https://www.kaggle.com/sdeng2)
 - [Wrong](https://www.kaggle.com/miguelllana)
 - [WU Wuhui](https://www.kaggle.com/canonwu)
 - [WUZZUF](https://www.kaggle.com/WUZZUF)
 - [xachi](https://www.kaggle.com/seniorxachi)
 - [Xai Nano](https://www.kaggle.com/xainano)
 - [xaliap](https://www.kaggle.com/xaliap)
 - [XavierBays](https://www.kaggle.com/xavierepfl)
 - [XavierMartinezBartra](https://www.kaggle.com/xavier14)
 - [Xavya](https://www.kaggle.com/xavya77)
 - [xgan](https://www.kaggle.com/xgan2010)
 - [Xiang Zhang](https://www.kaggle.com/datafreshman)
 - [xiaocongSonia](https://www.kaggle.com/xiaocongsonia)
 - [XiaojingLi](https://www.kaggle.com/xiaojingli)
 - [Xiaoxiao Wu](https://www.kaggle.com/cathywu)
 - [XIAOZHOU YANG](https://www.kaggle.com/yangxiaozhou)
 - [Ximing](https://www.kaggle.com/jackalex)
 - [Xin](https://www.kaggle.com/huxin216)
 - [xingzhangren](https://www.kaggle.com/xingzhangren)
 - [Xiong Songsong](https://www.kaggle.com/bigsomg)
 - [xjtushilei](https://www.kaggle.com/xjtushilei)
 - [xss](https://www.kaggle.com/bbbbbbbu)
 - [xtyscut](https://www.kaggle.com/xtyscut)
 - [Xuetao Shi](https://www.kaggle.com/xuetaoshi)
 - [XuleiYang](https://www.kaggle.com/yangxulei)
 - [xuseniayu](https://www.kaggle.com/xuchuanyu)
 - [xuy2](https://www.kaggle.com/constanceyoung)
 - [xWang](https://www.kaggle.com/seniorwx)
 - [xx](https://www.kaggle.com/hackxxy)
 - [Yabir Canario](https://www.kaggle.com/ycanario)
 - [YachunCheng](https://www.kaggle.com/yachuncheng)
 - [YaGana Sheriff-Hussaini](https://www.kaggle.com/sheriytm)
 - [Yagnesh Badiyani](https://www.kaggle.com/byagnesh)
 - [YahyaCivelek](https://www.kaggle.com/mylogic)
 - [yaliTsai](https://www.kaggle.com/yalitsai)
 - [yamuuu](https://www.kaggle.com/yamuuu)
 - [Yan Ramos da Silva](https://www.kaggle.com/yrdasilva)
 - [Yan Zhu](https://www.kaggle.com/vincent625)
 - [Yang Lin](https://www.kaggle.com/ljjsfe)
 - [Yang Yunfan](https://www.kaggle.com/kevinyang372)
 - [Yanir](https://www.kaggle.com/ycalisar)
 - [Yannis Pappas](https://www.kaggle.com/yannisp)
 - [YannMallegol](https://www.kaggle.com/yannmallegol)
 - [Yannsar](https://www.kaggle.com/yannsar)
 - [Yao Hu](https://www.kaggle.com/hooyao)
 - [Yao Lu](https://www.kaggle.com/bitandatom)
 - [YaoHsiao](https://www.kaggle.com/yaohsiaopid)
 - [YaoSenYou](https://www.kaggle.com/litterboy)
 - [Yaoxiang Li](https://www.kaggle.com/lzyacht)
 - [Yap Wei Yih](https://www.kaggle.com/yapweiyih)
 - [Yapi Donatien Achou](https://www.kaggle.com/rubben)
 - [Yarden Sharon](https://www.kaggle.com/yardenandchen)
 - [Yasar Kocal](https://www.kaggle.com/uyasarkocal)
 - [Yaser Ahmed](https://www.kaggle.com/codeworm)
 - [Yash Pradhan](https://www.kaggle.com/pradhan1234)
 - [Yash](https://www.kaggle.com/urstrulyyashu)
 - [yashjain](https://www.kaggle.com/yoyo1704)
 - [Yashna shravani](https://www.kaggle.com/yashnashravani)
 - [Yashu](https://www.kaggle.com/yashikabansal92)
 - [YasmeenW](https://www.kaggle.com/otto531)
 - [Yassine Marzougui](https://www.kaggle.com/ymarzougui)
 - [Yassine Morakkam](https://www.kaggle.com/ymorakkam)
 - [yassineameur](https://www.kaggle.com/yassine)
 - [yasuhiro_121](https://www.kaggle.com/yasuhiro121)
 - [Yaswanth Gosula](https://www.kaggle.com/yaswanth5)
 - [Yatishbn](https://www.kaggle.com/yatishbn)
 - [yazi](https://www.kaggle.com/wuyazi)
 - [Ye HuangJie](https://www.kaggle.com/kiet321)
 - [YeoMyungRo](https://www.kaggle.com/rymyung)
 - [yeongchan](https://www.kaggle.com/yeongchan)
 - [yeongseok](https://www.kaggle.com/yeongseokkwon)
 - [Yevgeniya Migranova](https://www.kaggle.com/migranova)
 - [Yexiaofeng](https://www.kaggle.com/stenen)
 - [Yi Cao](https://www.kaggle.com/yicao2)
 - [Yi Jingyuan-é™è¿œ](https://www.kaggle.com/universeyi)
 - [Yi Su](https://www.kaggle.com/yisunext408)
 - [Yichenâ€œEddieâ€Shen](https://www.kaggle.com/shenyichen105)
 - [Yifan Xie](https://www.kaggle.com/yifanxie)
 - [YijieZhuang](https://www.kaggle.com/jes2ica)
 - [Yin  Zhang](https://www.kaggle.com/yinzhang1)
 - [YingHan](https://www.kaggle.com/hollin0620)
 - [Yingzhu](https://www.kaggle.com/zhaoyingzhu)
 - [YiqiZhang](https://www.kaggle.com/zhang17)
 - [yiweihuang](https://www.kaggle.com/yiweihuang)
 - [Yixin Sun](https://www.kaggle.com/yixinsunn)
 - [ykamikawa](https://www.kaggle.com/ykamikawa)
 - [ykatayama](https://www.kaggle.com/ykatayama)
 - [YL ](https://www.kaggle.com/yl1202)
 - [Ylan Kazi](https://www.kaggle.com/ylankazi)
 - [yliu](https://www.kaggle.com/yliu9999)
 - [ymlai87416](https://www.kaggle.com/ymlai87416)
 - [ymtoo](https://www.kaggle.com/ymtoo86)
 - [Yoann Pradat](https://www.kaggle.com/yoannpradat)
 - [Yochanan Scharf](https://www.kaggle.com/yochanan)
 - [Yogesh Gupta](https://www.kaggle.com/yogeshgupta5)
 - [yogeshsingh](https://www.kaggle.com/yogeshsinghrbt)
 - [Yogi](https://www.kaggle.com/yogalakshmi18)
 - [Yoka](https://www.kaggle.com/yoka33)
 - [Yonatan Vaizman](https://www.kaggle.com/yvaizman)
 - [Yongho Choi](https://www.kaggle.com/yongho1037)
 - [Young And Dumb](https://www.kaggle.com/ayushpaliwal2015)
 - [YourKingdomCome](https://www.kaggle.com/yourwillbedone)
 - [ysaz](https://www.kaggle.com/imanazas)
 - [Yu Sheng Lu](https://www.kaggle.com/yushenglu)
 - [YU_CHIH](https://www.kaggle.com/cutyhell)
 - [Yuanjie Li](https://www.kaggle.com/yuanjieli)
 - [yuansaijie0604](https://www.kaggle.com/yuansaijie0604)
 - [Yueming](https://www.kaggle.com/carolzhangdc)
 - [YueSu](https://www.kaggle.com/suyue715)
 - [YuhaoWang](https://www.kaggle.com/yuhaowang)
 - [YuhuaXiong](https://www.kaggle.com/yuhuaxiong)
 - [yujack](https://www.kaggle.com/yuyijack)
 - [Yukarin](https://www.kaggle.com/yukarin)
 - [Yulia G](https://www.kaggle.com/yuliag)
 - [Yuncheng Li](https://www.kaggle.com/raingo)
 - [Yunguan FU](https://www.kaggle.com/yunguanfu)
 - [yuqing01](https://www.kaggle.com/yuqing01)
 - [Yura Shakhnazaryan](https://www.kaggle.com/yuridias)
 - [Yuranan](https://www.kaggle.com/yuranan)
 - [Yurii Biurher](https://www.kaggle.com/yburger)
 - [Yury Kashnitsky](https://www.kaggle.com/kashnitsky)
 - [Yusuf](https://www.kaggle.com/rybekci)
 - [YuwenJin](https://www.kaggle.com/yuwenjin)
 - [Yuzie Yu](https://www.kaggle.com/yuyugrin)
 - [Yvon](https://www.kaggle.com/yvon123)
 - [yvonhk](https://www.kaggle.com/yvonhk)
 - [Zach Barillaro](https://www.kaggle.com/zquant)
 - [zach](https://www.kaggle.com/balloonanimal)
 - [zack](https://www.kaggle.com/mzharif88)
 - [ZackCode](https://www.kaggle.com/zackcode)
 - [ZacKentonASI](https://www.kaggle.com/zacasi)
 - [zackthoutt](https://www.kaggle.com/zynicide)
 - [ZagarsurenSukhbaatar](https://www.kaggle.com/zagarsuren)
 - [Zain Baig](https://www.kaggle.com/mzainbaig)
 - [Zain Rizvi](https://www.kaggle.com/zainrizvi)
 - [Zakar H.](https://www.kaggle.com/zakarh)
 - [Zalando Research](https://www.kaggle.com/zalando-research)
 - [Zan Huang](https://www.kaggle.com/zanhuang314)
 - [Zaruhi Avagyan](https://www.kaggle.com/zaraavagyan)
 - [Zaur Begiev](https://www.kaggle.com/zaurbegiev)
 - [zedd](https://www.kaggle.com/zeddmaxx)
 - [Zeeshan-ul-hassan Usmani](https://www.kaggle.com/zusmani)
 - [zelhassn](https://www.kaggle.com/ljlr34449)
 - [Zeta](https://www.kaggle.com/zeta2191622)
 - [zhai kun](https://www.kaggle.com/video1243)
 - [zhangchengwei](https://www.kaggle.com/zcw607)
 - [zhanglanqing](https://www.kaggle.com/zhanglanqing)
 - [ZhaofengLi](https://www.kaggle.com/lzfxxx)
 - [zhaojingnan](https://www.kaggle.com/jingnanzhao)
 - [Zhe LIN](https://www.kaggle.com/linzhe)
 - [ZheCJ](https://www.kaggle.com/markshizhe)
 - [Zhengyi Zhu](https://www.kaggle.com/zzhu56)
 - [ZhenyuBo](https://www.kaggle.com/zbi441)
 - [Zheye Yuan](https://www.kaggle.com/tet21tet)
 - [Zhijin](https://www.kaggle.com/zhijinzhai)
 - [zhiliang](https://www.kaggle.com/chenzhiliang)
 - [zhixing](https://www.kaggle.com/zhixing629)
 - [zhousheng](https://www.kaggle.com/zhouzhiguang)
 - [Zielak](https://www.kaggle.com/mczielinski)
 - [Zillow](https://www.kaggle.com/zillow)
 - [Zinuo Jia](https://www.kaggle.com/xiaojia129)
 - [ZiyuanZhong](https://www.kaggle.com/zhongzzy9)
 - [zjf](https://www.kaggle.com/zhangjuefei)
 - [zluckyH](https://www.kaggle.com/zluckyhou)
 - [ZoeRenwick](https://www.kaggle.com/zoerenwick)
 - [Zoey](https://www.kaggle.com/zoe1580)
 - [ztyh0121](https://www.kaggle.com/ztyh0121)
 - [ZuhaibAli](https://www.kaggle.com/zohaib1111)
 - [Zuoyu Miao](https://www.kaggle.com/zymiao)
 - [Zurda](https://www.kaggle.com/hakabuk)
 - [ZuSwi](https://www.kaggle.com/nidhirastogi)
 - [Zwidofhelangani Gabara](https://www.kaggle.com/gabarazwido)
 - [zyaj](https://www.kaggle.com/zyajnokid)
",.csv
Comprehensive Supply Chain Analysis,1,us-regional-sales,US_Regional_Sales_Data.csv,DbCL-1.0,"

This supply chain analysis provides a comprehensive view of the company's order and distribution processes, allowing for in-depth analysis and optimization of various aspects of the supply chain, from procurement and inventory management to sales and customer satisfaction. It empowers the company to make data-driven decisions to improve efficiency, reduce costs, and enhance customer experiences.
The provided supply chain analysis dataset contains various columns that capture important information related to the company's order and distribution processes:


•	OrderNumber
•	Sales Channel
•	WarehouseCode
•	ProcuredDate
•	CurrencyCode
•	OrderDate
•	ShipDate
•	DeliveryDate
•	SalesTeamID
•	CustomerID
•	StoreID
•	ProductID
•	Order Quantity
•	Discount Applied
•	Unit Cost
•	Unit Price
",.csv
Computation used to train notable AI,1,asdasdasdasd,AI training computation.csv,Apache 2.0,"This dataset delves into the computational underpinnings of training notable artificial intelligence systems, offering insights into the magnitude of computational resources involved. Computation is quantified in total petaFLOP (floating-point operations per second), a standard metric in the AI domain. The dataset provides estimates derived from AI literature, with a focus on petaFLOP measurements, while acknowledging inherent uncertainties. It sheds light on the computational complexities inherent in training AI models, with estimates expected to be accurate within a factor of 2, or a factor of 5 for recent undisclosed models like GPT-4. This dataset serves as a valuable resource for researchers, analysts, and enthusiasts interested in understanding the computational demands of AI training endeavors.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F13244501%2Fceca25d02cc0d20dc494509e459807f8%2FAI%20training%20computation.png?generation=1712916971325298&alt=media)

Computation is measured in total petaFLOP, which is 10¹⁵ floating-point operations estimated from AI literature, albeit
with some uncertainty. Estimates are expected to be accurate within a factor of 2, or a factor of 5 for recent undisclosed
models like GPT-4.



Photo by <a href=""https://unsplash.com/@solenfeyissa?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Solen Feyissa</a> on <a href=""https://unsplash.com/photos/a-person-holding-a-cell-phone-in-their-hand-hWSNT_Pp4x4?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv
Computer Network Traffic,1,computer-network-traffic,cs448b_ipasn.csv,CC0-1.0,"### Context

Computer Network Traffic Data - A ~500K CSV with summary of some real network traffic data from the past. The dataset has ~21K rows and covers 10 local workstation IPs over a three month period. Half of these local IPs were compromised at some point during this period and became members of various botnets. 

### Content

Each row consists of four columns:

- date: yyyy-mm-dd (from 2006-07-01 through 2006-09-30)
- l_ipn: local IP (coded as an integer from 0-9)
- r_asn: remote ASN (an integer which identifies the remote ISP)
- f: flows (count of connnections for that day)

Reports of ""odd"" activity or suspicions about a machine's behavior triggered investigations on the following days (although the machine might have been compromised earlier)

Date : IP
08-24 : 1
09-04 : 5
09-18 : 4
09-26 : 3 6

### Acknowledgements

This public dataset was found on [http://statweb.stanford.edu/~sabatti/data.html][1]

### Inspiration

Can you discover when a compromise has occurred by a change in the pattern of communication?

  [1]: http://statweb.stanford.edu/~sabatti/data.html",.csv
Concrete Compressive Strength,1,concrete-compressive-strength,Concrete Compressive Strength.csv,CC0-1.0,"### Context

Concrete is the most important material in civil engineering. The 
concrete compressive strength is a highly nonlinear function of age and 
ingredients. These ingredients include cement, blast furnace slag, fly ash, 
water, superplasticizer, coarse aggregate, and fine aggregate.


### Content

Data Characteristics:
    
The actual concrete compressive strength (MPa) for a given mixture under a 
specific age (days) was determined from laboratory. Data is in raw form (not scaled). 

Summary Statistics: 

Number of instances (observations): 1030
Number of Attributes: 9
Attribute breakdown: 8 quantitative input variables, and 1 quantitative output variable
Missing Attribute Values: None

Variable Information:

Given is the variable name, variable type, the measurement unit and a brief description. 
The concrete compressive strength is the regression problem. The order of this listing 
corresponds to the order of numerals along the rows of the database. 

Name -- Data Type -- Measurement -- Description

Cement (component 1) -- quantitative -- kg in a m3 mixture -- Input Variable
Blast Furnace Slag (component 2) -- quantitative -- kg in a m3 mixture -- Input Variable
Fly Ash (component 3) -- quantitative -- kg in a m3 mixture -- Input Variable
Water (component 4) -- quantitative -- kg in a m3 mixture -- Input Variable
Superplasticizer (component 5) -- quantitative -- kg in a m3 mixture -- Input Variable
Coarse Aggregate (component 6) -- quantitative -- kg in a m3 mixture -- Input Variable
Fine Aggregate (component 7) -- quantitative -- kg in a m3 mixture -- Input Variable
Age -- quantitative -- Day (1~365) -- Input Variable
Concrete compressive strength -- quantitative -- MPa -- Output Variable 


### Acknowledgements

  Original Owner and Donor
  Prof. I-Cheng Yeh
  Department of Information Management 
  Chung-Hua University, 
  Hsin Chu, Taiwan 30067, R.O.C.
  e-mail:icyeh@chu.edu.tw
  TEL:886-3-5186511

  Date Donated: August 3, 2007


Past Usage: 

Main
1. I-Cheng Yeh, ""Modeling of strength of high performance concrete using artificial 
neural networks,"" Cement and Concrete Research, Vol. 28, No. 12, pp. 1797-1808 (1998).

Others
2. I-Cheng Yeh, ""Modeling Concrete Strength with Augment-Neuron Networks,"" J. of 
Materials in Civil Engineering, ASCE, Vol. 10, No. 4, pp. 263-268 (1998).

3. I-Cheng Yeh, ""Design of High Performance Concrete Mixture Using Neural Networks,""  
J. of Computing in Civil Engineering, ASCE, Vol. 13, No. 1, pp. 36-42 (1999).

4. I-Cheng Yeh, ""Prediction of Strength of Fly Ash and Slag Concrete By The Use of 
Artificial Neural Networks,"" Journal of the Chinese Institute of Civil and Hydraulic 
Engineering, Vol. 15, No. 4, pp. 659-663 (2003).

5. I-Cheng Yeh, ""A mix Proportioning Methodology for Fly Ash and Slag Concrete Using 
Artificial Neural Networks,"" Chung Hua Journal of Science and Engineering, Vol. 1, No. 
1, pp. 77-84 (2003).

6. Yeh, I-Cheng, ""Analysis of strength of concrete using design of experiments and 
neural networks,"": Journal of Materials in Civil Engineering, ASCE, Vol.18, No.4, 
pp.597-604 ?2006?.",.csv
Concrete Strength Prediction,1,predict-concrete-strength,ConcreteStrengthData.csv,CC0-1.0,"There Various Factors that affects the Strength of Concrete Such as  Materials Used, Age etc.
Predict the Strength of the Concrete Based on the Components and Other Factors as Predictors.

**Description of Fields are as follows:-**
- **CementComponent**:- Amount of cement is mixed
- **BlastFurnaceSlag**:- Amount of Blast Furnace Slag is mixed
- **FlyAshComponent**:- Amount of FlyAsh is mixed
- **WaterComponent**:- Amount of water is mixed
- **SuperplasticizerComponent**:- Amount of Super plasticizer is mixed
- **CoarseAggregateComponent**:- Amount of Coarse Aggregate is mixed
- **FineAggregateComponent**:- Amount of Coarse Aggregate is mixed
- **AgeInDays**:- How many days it was left dry
- **Strength**:- What was the final strength of concrete- **(Target)**",.csv
Connectionist Bench (Mines & Rocks),1,connectionist-bench-mines-and-rocks,Sonar.csv,Attribution 4.0 International (CC BY 4.0),"
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16192307%2F5e910cb753eb547f0ac4f07c27acf860%2F.gif?generation=1713534692510345&alt=media)



Sonar (ultrasound) is the technique of using sound to navigate, communicate with, and identify objects on or under water, such as ships.

This dataset contains response metrics for 60 different sonar frequencies ranging from 0.0 to 1.0 sent to known objects such as mines and rocks. For each sent and received signal, data about the object to which the sonar was directed (mine or stone) was recorded. The transmitted sonar signal is a frequency-modulated chirp, the frequency of which increases. The dataset contains signals obtained from different viewing angles, spanning 90 degrees for the cylinder and 180 degrees for the stone. The integration aperture for higher frequencies occurs later in time because these frequencies are transmitted later during the chirp. The label associated with each entry contains the letter ""R"" if the object is a rock, and ""M"" if it is a mine (a metal cylinder). The numbers in the labels are arranged in ascending order of viewing angle, but they do not directly encode the angle.



",.csv
Consumer's Buying Behavior,1,consumers-buying-behavior,social_ads.csv,MIT,"Consumer's Buying Behavior Dataset

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16551504%2F2b65e55bf9fec4123786767250fca1fc%2FScreenshot%20(372).png?generation=1713321050423421&alt=media)

Additional Information
This dataset can be used to analyze the relationship between age, estimated salary, and purchase behavior in response to the advertisement.
The dataset appears to be suitable for binary classification tasks, where the goal might be to predict whether an individual will make a purchase based on age and estimated salary.
Exploratory data analysis (EDA) techniques can be applied to understand patterns and correlations within the dataset before building predictive models.",.csv
Copy of wikipedia-language-iso639,1,wikipedia-language-iso639,lang.csv,CC0-1.0,"### Context

Simply [list of ISO_639-1_codes](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes)


### Content

Needed to access through kaggle 


### Acknowledgements

 1. [https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes)
 2. [Image from Goran Ivos at unplash](https://unsplash.com/@givos)",.csv
Corn Ear Physical Measurements,1,corn-ear-physical-measurements,Corn_Ear_Physical_Characteristics.csv,Attribution 4.0 International (CC BY 4.0),"# Description Of the Data
## Sample Collection and Processing.
* Whole corn ears were collected from fields after maturity in the fall of 2022 in central and southern Illinois.
* The samples were then dried down and processed by hand to collect the metrics below in the 2022_samples.csv
* After the samples were dried, measured, and hand shelled they were then imaged by a camera that was placed in front of a seed meter to singulate the kernels. More about the imaging is below.

## Corn_Ear_Physical_Characteristics.csv
* Each line item in this table represents one ear and the metrics associated with it. The Ear number in this file corresponds to the ear number in the images dataset which we will highlight later.
* Each ear was measured, then shelled, and then placed into the respective bag for Large Rounds, Body and Small Rounds.
* The Large Rounds' kernels were the large rounds at the base of the ear. The Small Rounds' kernels were classified as the small round kernels at the tip of the ear and the body are the kernels in between which are usually large flats. One thing to note is that the metrics in this table are for the full ear. The importance of the distinction between Large Rounds, Body, and Small Rounds is in the Images as they were scanned separately so that they were pre-labeled for modeling.
* For the data in the table there are 7 attributes associated with each ear. The data was collected by hand. Below is a description of each column in the table.
&gt;* count_round - The number of kernels around the ear.
&gt;* max_diameter_mm -  The max diameter of the ear in mm. This was taken with a caliper.
&gt;* count_long -  The number of kernels long on the ear.
&gt;* length_mm - The total length of the ear.
&gt;* tip_back_len - The amount of cob at the end of the ear in mm, that had no kernels on it.
&gt;* count_missing - The number of kernels that were no longer on the ear but were present at harvest.
&gt;* poor_pollenation_kernels_count - The number of poor pollination kernels which are defined as kernels that have no neighbors and have a golf ball shape.

## Examples of ear measurements
* count round:
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F20501156%2Fd87f2b67605c394ab5d84558540d72b1%2F5Qz8kLXok69f2io.png?generation=1713900566743634&alt=media)

* count long:
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F20501156%2Fdadca51cfdf4c6d686224b39004106cc%2F8YdEfGxnwHVgk88.png?generation=1713900582017948&alt=media)

* tip of the ear with no kernels:
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F20501156%2Fd155a0117493cc27600831db50b44c01%2F5jbYWKxMFdA5CcV.png?generation=1713900651052160&alt=media)

* corn ear with poor pollinated kernels:
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F20501156%2Fa82a9ae8961ec0b842098fc1d2f2352f%2F6xRZcFtz3Hwknwi.png?generation=1713900640455385&alt=media)",.csv
Coronary_Artery_Disease,1,coronary-artery-disease,Coronary_Artery_Disease.csv,GNU Lesser General Public License 3.0,"<div><h2>About Dataset</h2><p></p><div><p><strong>Z-Alizadeh Sani Dataset Description:</strong></p><p>The Z-Alizadeh Sani dataset stands as one of the predominant datasets employed in machine learning for the automatic detection of Coronary Artery Disease (CAD). Comprising 303 samples, it encompasses data from 216 CAD patients and 87 individuals classified as normal. Within this dataset, each sample is characterized by 55 features.</p><p>These features are grouped into four primary categories, offering a multifaceted view of the patients' health status:</p><ol><li><p><strong>Demographic</strong>: This category encompasses demographic information about the patients, providing insights into factors such as age, gender, and other relevant demographic attributes.</p></li><li><p><strong>Symptoms and Examination</strong>: This category delves into the symptoms experienced by the patients and the results of their medical examinations. It offers valuable information regarding symptoms associated with CAD and diagnostic findings.</p></li><li><p><strong>Electrocardiogram (ECG)</strong>: This category comprises data derived from electrocardiograms, which provide detailed insights into the electrical activity of the heart. ECG features play a pivotal role in diagnosing various cardiac conditions, including CAD.</p></li><li><p><strong>Laboratory and Echo Features</strong>: This category encompasses laboratory test results and echocardiographic features, offering comprehensive information about the patients' biochemical profiles and cardiac function.</p></li></ol><p>By leveraging the diverse array of features within these categories, researchers and practitioners can develop machine learning models capable of accurately detecting CAD and distinguishing between CAD patients and individuals without the condition. The Z-Alizadeh Sani dataset serves as a valuable resource for advancing CAD detection algorithms and enhancing the diagnosis and treatment of this prevalent cardiovascular condition.</p>
<p></p>
<li>The main advantage of this dataset is its <strong>completeness</strong>. There are no missing values or outliers in this dataset</li>
<li>This dataset is publicly available in the UCI Machine Learning repository for <strong>researchers</strong>📚</li>

<p><strong>Features of Z-Alizadeh Sani dataset</strong></p>
<p><strong>Demographic:</strong></p>
<ul>
<li>Age 30–86</li>
<li>Weight 48–120</li>
<li>Sex Male, female</li>
<li>BMI (body mass index Kg/m2) 18–41</li>
<li>DM (Diabetes Mellitus) Yes, no</li>
<li>HTN (hyper tension) Yes, no</li>
<li>Current smoker Yes, no</li>
<li>Ex-Smoker Yes, no</li>
<li>FH (family history) Yes, no</li>
<li>Obesity Yes if MBI &gt; 25, no otherwise</li>
<li>CRF (chronic renal failure) Yes, no</li>
<li>CVA (Cerebrovascular Accident) Yes, no</li>
<li>Airway disease Yes, no</li>
<li>Thyroid Disease Yes, no</li>
<li>CHF (congestive heart failure) Yes, no</li>
<li>DLP (Dyslipidemia) Yes, no</li>
</ul>
<p><strong>Symptom and examination :</strong></p>
<ul>
<li>BP (blood pressure: mmHg) 90–190</li>
<li>PR (pulse rate) (ppm) 50–110</li>
<li>Edema Yes, no</li>
<li>Weak peripheral pulse Yes, no</li>
<li>Lung rales Yes, no</li>
<li>Systolic murmur Yes, no</li>
<li>Diastolic murmur Yes, no</li>
<li>Typical Chest Pain Yes, no</li>
<li>Dyspnea Yes, no</li>
<li>Function class 1, 2, 3, 4</li>
<li>Atypical Yes, no</li>
<li>Nonanginal CP Yes, no</li>
<li>Exertional CP (Exertional Chest Pain) Yes, no</li>
<li>Low Th Ang (low Threshold angina) Yes, no</li>
</ul>
<p><strong>ECG:</strong></p>
<ul>
<li>Rhythm Sin, AF</li>
<li>Q Wave Yes, no</li>
<li>ST Elevation Yes, no</li>
<li>ST Depression Yes, no</li>
<li>T inversion Yes, no</li>
<li>LVH (left ventricular hypertrophy) Yes, no</li>
<li>Poor R progression (poor R wave progression) Yes, no</li>
</ul>
<p><strong>Laboratory and echo:</strong></p>
<ul>
<li>FBS (fasting blood sugar) (mg/dl) 62–400</li>
<li>Cr (creatine) (mg/dl) 0.5–2.2</li>
<li>TG (triglyceride) (mg/dl) 37–1050</li>
<li>LDL (low density lipoprotein) (mg/dl) 18–232</li>
<li>HDL (high density lipoprotein) (mg/dl) 15–111</li>
<li>BUN (blood urea nitrogen) (mg/dl) 6–52</li>
<li>ESR (erythrocyte sedimentation rate) (mm/h) 1–90</li>
<li>HB (hemoglobin) (g/dl) 8.9–17.6</li>
<li>K (potassium) (mEq/lit) 3.0–6.6</li>
<li>Na (sodium) (mEq/lit) 128–156</li>
<li>WBC (white blood cell) (cells/ml) 3700–18,000</li>
<li>Lymph (Lymphocyte) (%) 7–60</li>
<li>Neut (neutrophil) (%) 32–89</li>
<li>PLT (platelet) (1000/ml) 25–742</li>
<li>EF (ejection fraction) (%) 15–60</li>
<li>Region with RWMA (regional wall motion abnormality) 0, 1, 2, 3, 4</li>
<li>VHD (valvular heart disease) Normal, mild, moderate, severe</li>
</ul>
</div></div>",.csv
Coronavirus (covid19) Tweets,1,coronavirus-covid19-tweets,Countries.CSV,CC0-1.0,"### Context

This dataset contains the Tweets of users who have applied the following hashtags: #coronavirus, #coronavirusoutbreak, #coronavirusPandemic, #covid19, #covid_19

From about 17 March, the dataset also included the following additional hashtags: #epitwitter, #ihavecorona

This is the first dataset in the series, as the Data tab only displays 20 files at a time and I have been uploading files with a single day's worth of data. To ensure that all files are visible to users and no files are too large, it seems prudent to create a second dataset to split the files into manageable groups of approximately half a month. The first file also contains a file that matches `country` with `country_code` and may be useful for users.

The second dataset (for early April, plus the final few days of March) is located here: https://www.kaggle.com/smid80/coronavirus-covid19-tweets-early-april
The third dataset (for Tweets in late April) is located here: [https://www.kaggle.com/smid80/coronavirus-covid19-tweets-late-april](https://www.kaggle.com/smid80/coronavirus-covid19-tweets-late-april)

### Content

The dataset contains variables associated with Twitter: the text of various tweets and the accounts that tweeted them, the hashtags used and the locations of the accounts. 

Note that due to the large volume of Tweets, there may be some gaps for some hashtags (not all Tweets with a given hashtag may be captured). Because some hashtags are used less frequently than other hashtags, less frequently used hashtags may span a longer period of time (going back earlier) than more frequently used hashtags. The hashtag ""#coronavirus"" seems to be the most frequently used - despite scraping 500,000 Tweets, there was no overlap between Tweets with this hashtag in version 1 and version 5, therefore gaps remain. 

The retweets argument has been set to FALSE, so this dataset does not include retweets (although a count of retweets is provided as a variable). 


### Acknowledgements

This dataset would not be possible without the creators of the rtweet package on CRAN. The cover and thumbnail images are from the CDC, and downloaded from unsplash.

### Inspiration

Do countries with more cases also have more Tweets? ",.csv
Corporate Credit Rating,1,corporate-credit-rating,corporate_rating.csv,Attribution 4.0 International (CC BY 4.0),"### Context

A corporate credit rating expresses the ability of a firm to repay its debt to creditors. Credit rating agencies are the entities responsible to make the assessment and give a verdict.  When a big corporation from the US or anywhere in the world wants to issue a new bond it hires a credit agency to make an assessment so that investors can know how trustworthy is the company. The assessment is based especially in the financials indicators that come from the balance sheet. Some of the most important agencies in the world are Moodys, Fitch and Standard and Poors. 

### Content
A list of 2029 credit ratings issued by major agencies such as Standard and Poors to big US firms (traded on NYSE or Nasdaq) from 2010 to 2016. 
There are 30 features for every company of which 25 are financial indicators. They can be divided in:

- `Liquidity Measurement Ratios:` currentRatio, quickRatio, cashRatio, daysOfSalesOutstanding
-  `Profitability Indicator Ratios:` grossProfitMargin, operatingProfitMargin, pretaxProfitMargin, netProfitMargin, effectiveTaxRate, returnOnAssets, returnOnEquity, returnOnCapitalEmployed
- `Debt Ratios:` debtRatio, debtEquityRatio
Operating Performance Ratios:` assetTurnover
- `Cash Flow Indicator Ratios:` operatingCashFlowPerShare, freeCashFlowPerShare, cashPerShare, operatingCashFlowSalesRatio, freeCashFlowOperatingCashFlowRatio

For more information about financial indicators visit: https://financialmodelingprep.com/market-indexes-major-markets
The additional features are Name, Symbol (for trading), Rating Agency Name, Date and Sector. 

The dataset is unbalanced, here is the frequency of ratings:
- AAA:         7
- AA:	        89
- A:	       398
- BBB:	       671
- BB:	       490
- B:	       302
- CCC:       64
- CC:	       5
- C:	       2
- D:	       1

### Acknowledgements
This dataset was possible thanks to [financialmodelingprep](https://financialmodelingprep.com/) and [opendatasoft](https://public.opendatasoft.com/explore/?sort=modified) - the sources of the data. To see how the data was integrated and reshaped check [here](https://github.com/Agewerc/ML-Finance).

### Inspiration
Is it possible to forecast the rating an agency will give to a company based on its financials? 
",.csv
Correlation between Posture & Personality Trait,1,correlation-between-posture-personality-trait,Myers Briggs Table_S1.csv,CC0-1.0,"Occupational back pain is a disorder that commonly affects the working population, resulting in disability, health-care utilization, and a heavy socioeconomic burden. Although the etiology of occupational pain remains largely unsolved, anecdotal evidence exists for the contribution of personality and posture to long-term pain management, pointing to a direct contribution of the mind-body axis. In the current study, we have conducted an extensive evaluation into the relationships between posture and personality.

## Please Upvote. Your upvotes keep me motivated and will help me in my job hunt !!!
##Comment your views please",.csv
Cosmetic Brand Products Dataset🎨🎨,1,cosmetic-brand-products-dataset,output.csv,CC0-1.0,"#Key Features

| **Column Names**    |  **Description**  | 
| ------------- |:-------------:|
| id                    | Unique identifier for the cosmetic product.         |
| brand                 | The brand or manufacturer of the product.           |
| name                  | The name of the cosmetic product.                   |
| price                 | The price of the product.                            |
| price_sign            | The currency sign for the price.                     |
| currency              | The currency in which the price is listed.          |
| image_link            | URL to the image of the product.                     |
| product_link          | URL to the product page or collection.              |
| website_link          | URL to the brand's website.                          |
| description           | Description of the cosmetic product.                |
| rating                | Rating of the product if available.                 |
| category              | Category of the cosmetic product.                   |
| product_type          | Type or form of the cosmetic product.               |
| tag_list              | List of tags or attributes associated with the product. |
| created_at            | Date and time when the product entry was created.    |
| updated_at            | Date and time when the product entry was last updated. |
| product_api_url       | URL to the product's API endpoint.                   |
| api_featured_image    | URL to the featured image in the API.                |
| product_colors        | List of product colors with hex values and names.    |


#How to use this Dataset

**1. Brand Analysis**: Explore which brands are most prominent in the dataset. This can help you identify popular cosmetic brands or market leaders.

**2. Pricing Insights**: Investigate the pricing information to understand the distribution of prices across different cosmetic products.

**3. Product Categories**: Examine the various cosmetic product categories to determine which types of products are most prevalent.

**4. Tag Analysis**: Explore tags associated with the products, such as ""cruelty-free"" or ""vegan,"" to identify trends related to product attributes.

**5. Temporal Trends**: Analyze how the dataset has evolved over time by examining the ""created_at"" and ""updated_at"" columns.

**6. Color Trends**: Investigate the most popular colors used in cosmetic products.",.csv
Cosmetics datasets,1,cosmetics-datasets,cosmetics.csv,GPL-2.0,"### Context

Whenever I want to try a new cosmetic item, it's so difficult to choose. It's actually more than difficult. It's sometimes scary because new items that I've never tried end up giving me skin trouble. We know the information we need is on the back of each product, but it's really hard to interpret those ingredient lists unless you're a chemist. You may be able to relate to this situation.


### Content

we are going to create a content-based recommendation system where the 'content' will be the chemical components of cosmetics. Specifically, we will process ingredient lists for 1472 cosmetics on Sephora via word embedding, then visualize ingredient similarity using a machine learning method called t-SNE and an interactive visualization library called Bokeh. Let's inspect our data first.


### Acknowledgements

DataCamp

",.csv
Cost Prediction on acquiring Customers.,1,medias-cost-prediction-in-foodmart,media prediction and its cost.csv,CC0-1.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F6279218%2Fd60f31abd8bd38d5b0fa92cb1d7a4092%2Fimages-_23_.jpeg?generation=1662456998926514&alt=media)


## PREDICT COST ON MEDIA CAMPAIGNS IN FOOD MART OF USA .
## ON THE BASIS OF 60K CUSTOMERS INCOME ,PRODUCT,PROMOTION AND STORE FEATURES. 


**ABOUT FOODMART:**

Food Mart (CFM) is a chain of convenience stores in the United States. The private company's headquarters are located in Mentor, Ohio, and there are currently approximately 325 stores located in the US. Convenient Food Mart operates on the franchise system.

 Food Mart was the nation's third-largest chain of convenience stores as of 1988.

The NASDAQ exchange dropped Convenient Food Mart the same year when the company failed to meet financial reporting requirements.

Carden & Cherry advertised Convenient Food Mart with the Ernest character in the 1980s.

...KNOW MORE FROM WIKI .",.csv
Cost of Living Index 2022,1,cost-of-living-index-2022,Cost_of_Living_Index_2022.csv,other,"Cost of Living Index (Excl. Rent) is a relative indicator of consumer goods prices, including groceries, restaurants, transportation and utilities. Cost of Living Index does not include accommodation expenses such as rent or mortgage. If a city has a Cost of Living Index of 120, it means Numbeo has estimated it is 20% more expensive than New York (excluding rent).

Please refer further to: https://www.numbeo.com/cost-of-living/cpi_explained.jsp for motivation and methodology.

All credits to https://www.numbeo.com . 

This dataset would surely help socio-economic researchers to analyse and get deeper insights regarding the life of people country-wise.

Thanks to @andradaolteanu for the motivation! Upwards and onwards...",.csv
Countries ISO Codes,1,countries-iso-codes,wikipedia-iso-country-codes.csv,CC0-1.0,"### Context

This dataset was uploadedto be able to link the Countries ISO codes to any data in a better way than just names.
This Dataset can give the opportunity to improve current and new Notebooks as well as other datasets.
Libraries like plotly use country codes to easily identify the data linked to the country. This dataset can help with that task.

### Content

The dataset contains a list of ALL the states and their codes.
**Columns:**
 - **Alpha-2 code**: The alpha-2 code of the country (2 characters)
 - **Alpha-3 code**: The alpha-3 code of the country (3 characters)
 - **Numeric code**: The numeric code of the country (int)
 - **ISO 3166-2**: The ISO 3166-2 code. Formatted as: ISO 3166-2:[2 characters]

### Acknowledgements

https://gist.github.com/radcliff/f09c0f88344a7fcef373

### Inspiration

Any dataset that contains a country column, can be linked to this dataset and be used to link other data, as well as plotting MAPS.
Libraries like plotly use country codes to easily identify the data linked to the country. This dataset can help with that task.",.csv
Countries ISO Codes | Continent | Flags URL,1,countries-iso-codes-continent-flags-url,countries_continents_codes_flags_url.csv,GPL-2.0,"### Context

The dataset contais all the countries in the world

### Content

The dataset contains:
- Countries names
- ISO 2 and 3 codes
- Flag image url to load in Plotly or Matplotlib
- Continent/region of each country


### Acknowledgements

Not all the data is completed so if you find any missings, you can ping me to update it

### Inspiration

Helpful for those who want to plot countries in the most cool way!",.csv
Countries Life Expectancy,1,countries-life-expectancy,Life expectancy.csv,CC0-1.0,"### Context
Average age people in a country lived. 


### Content
15 different countries with over 217 years


### Acknowledgements

Photo by Andrew Butler on Unsplash",.csv
Countries Olympics Medals since 1896 ,1,countries-olympics-medals-since-1896,olympics_medals_country_wise.csv,CC-BY-SA-3.0,"The modern Olympic Games or Olympics are the leading international sporting events featuring summer and winter sports competitions in which thousands of athletes from around the world participate in a variety of competitions. The Olympic Games are considered the world's foremost sports competition with more than 200 nations participating. The Olympic Games are normally held every four years, and since 1994, has alternated between the Summer and Winter Olympics every two years during the four-year period.

A medal ceremony is held after the conclusion of each Olympic event. The winner, and the second- and third-place competitors or teams, stand on top of a three-tiered rostrum to be awarded their respective medals by a member of the IOC. After the medals have been received, the national flags of the three medallists are raised while the national anthem of the gold medallist's country is played. Volunteering citizens of the host country also act as hosts during the medal ceremonies, assisting the officials who present the medals and acting as flag-bearers. In the Summer Olympics, each medal ceremony is held at the venue where the event has taken place, but the ceremonies at the Winter Olympics are usually held in a special ""plaza"". ",.csv
Countries in Conflict Dataset (1989-2022),1,countries-in-conflict-dataset,countries-in-conflict-data.csv,CC0-1.0,"Since 1800, more than 37 million people worldwide have died while actively fighting in wars.

The number would be much higher still if it also considered the civilians who died due to the fighting, the increased number of deaths from hunger and disease resulting from these conflicts, and the deaths in smaller conflicts that are not considered wars.1

Wars are also terrible in many other ways: they make people’s lives insecure, lower their living standards, destroy the environment, and, if fought between countries armed with nuclear weapons, can be an existential threat to humanity.

Looking at the news alone, it can be difficult to understand whether more or less people are dying as a result of war than in the past. One has to rely on statistics that are carefully collected so that they can be compared over time.

While every war is a tragedy, the data suggests that fewer people died in conflicts in recent decades than in most of the 20th century. Countries have also built more peaceful relations between and within them.

How many wars are avoided, and whether the trend of fewer deaths in them continues, is up to our own actions. Conflict deaths recently increased in the Middle East, Africa, and Europe, stressing that the future of these trends is uncertain.

# Dataset Description:
This dataset offers insights into countries experiencing ongoing conflicts, providing estimates of fatalities resulting from these conflicts across various years. It serves as a valuable resource for understanding the global landscape of conflict and its human toll.",.csv
Countries in the World by Population 2022,1,countries-in-the-world-by-population-2022,world_population.csv,DbCL-1.0,"## Content

This dataset contains current estimates (live population clock), historical data, and projected figures of world countries and  dependent territories.  Data based on the latest **United Nations Population Division** estimates.

## Attribute Information

- **Country/Other** - Name of countries and dependent territories.
- **Population (2020)** - Population in the year 2020
- **Yearly Change** - Percentage Yearly Change in Population 
- **Net Change** - Net Change in Population
- **Density (P/Km²)**- Population density (population per square km)
- **Land Area (Km²)** - Land area of countries / dependent territories.
- **Migrants (net)** - Total number of migrants
- **Fert. Rate** - Fertility rate
- **Med. Age** - Median age of the population
- **Urban Pop %**- Percentage of urban population
- **World Share** - Population share

## Source
Link : https://www.worldometers.info/world-population/population-by-country/

## Updated Covid 19 Datasets
Link : https://www.kaggle.com/anandhuh/datasets

If you find it useful, please support by **upvoting**  ❤️ 
### Thank You",.csv
Countries of the World,1,countries-of-the-world,countries of the world.csv,CC0-1.0,"### Context

World fact sheet, fun to link with other datasets.


### Content

Information on population, region, area size, infant mortality and more.


### Acknowledgements

[Source:][1] All these data sets are made up of data from the US government. Generally they are free to use if you use the data in the US. If you are outside of the US, you may need to contact the US Govt to ask.
Data from the World Factbook is public domain. The website says ""The World Factbook is in the public domain and may be used freely by anyone at anytime without seeking permission.""    
https://www.cia.gov/library/publications/the-world-factbook/docs/faqs.html   

### Inspiration

When making visualisations related to countries, sometimes it is interesting to group them by attributes such as region, or weigh their importance by population, GDP or other variables.


  [1]: http://gsociology.icaap.org/dataupload.html",.csv
Country Health Trends Dataset,1,country-health-trends-dataset,gapminder.csv,Apache 2.0,"This dataset contains key demographic, health, and socio-economic indicators that are crucial for a wide range of analyses. Researchers and data scientists can use these indicators to study global development trends, compare regional progress, and identify factors that contribute to disparities in health and wealth.

I believe there are numerous analyses that can be performed with this dataset, including:

- **Exploratory Data Analysis (EDA)**: Initial exploratory analysis can uncover trends, patterns, and outliers in life expectancy and fertility rates across different regions and over time. This can involve generating summary statistics, distributions, and visualizations.
- **Comparative Analysis**: By comparing countries or regions, analysts can identify factors that contribute to higher life expectancy or lower fertility rates. This could involve grouping data by region or income level, then comparing average life expectancy and fertility rates.
- **Correlation and Regression Analysis**: Investigating the relationship between life expectancy, fertility rate, and population size could reveal insights into how these variables influence each other.
",.csv
Country Life Expectancy,1,country-life-expectancy,Life Expectancy.csv,Apache 2.0,"This dataset was put together from the data publicly available at different sections of https://ourworldindata.org/.
It consists of 1365 records and 19 columns:
- Polio incidence: Total (reported) polio cases
- Tuberculosis incidence: Estimated rate of new tuberculosis cases per 100,000 people. This includes both new and latent reactivated infections.
- Tuberculosis deaths: Estimated mortality from all forms of tuberculosis per 100,000 population.
- Malaria deaths: The number of deaths from malaria per 100,000 people.
- Malaria incidence:  the number of new cases of malaria in a year per 1,000 population at risk.
- Alcohol deaths: Annual number of deaths from alcohol use disorders per 100,000 people.
- Smoking deaths: Deaths that are from all causes attributed to smoking per 100,000 people, in both sexes, aged age-standardized
- Obesity deaths: Deaths that are from all causes attributed to high body-mass index per 100,000 people
- Cardiovascular disease deaths: Death rate due to Cardiovascular diseases per 100,000 people
- Cardiovascular disease incidence: Number of new cases of cardiovascular diseases per 100 people
- Deaths by suicide: Annual number of suicides per 100,000 people. Suicide deaths are underreported in many countries due to social stigma and cultural or legal concerns. This data is adjusted for this underreporting to estimate the actual rate of suicides.
- Deaths due to Cardiovascular diseases: Deaths due to cardiovascular diseases per 100,000 people.
- Mean years of schooling: Average number of years adults over 25 years participated in formal education.
- GDP: GDP per capita, PPP (constant 2017 international $)
- Gov health expenditure: Domestic general government health expenditure (GGHE-D) as percentage of general government expenditure (GGE) (%)
- Undernourishment: Share of individuals that have a daily food intake that is insufficient to provide the amount of dietary energy required to maintain a normal, active, and healthy life.",.csv
Country Longitude Latitude,1,country-longitude-latitude,longitude-latitude.csv,CC0-1.0,"This dataset is thought as a utility dataset to find geo locations (longitude and latitude) when you only have the names or codes for the countries. Besides [ISO-Alpha-3](https://en.wikipedia.org/wiki/ISO_3166-1_alpha-3) and [ISO-Alpha-2](https://en.wikipedia.org/wiki/ISO_3166-1_alpha-2) codes I added [IOC](https://en.wikipedia.org/wiki/List_of_IOC_country_codes) and [FIFA](https://en.wikipedia.org/wiki/List_of_FIFA_country_codes) codes.

Sometimes there is more than one row for a country. This is when there are different (official) names or historical predecessors of a country. If it is the official name as defined by ISO 3166 Maintenance Agency it is marked with the value 1 in the column ""ISO-Name"".

The locations given here are not intended to be correct geographical centers of a country or region. These locations should be useful  for positioning graphical elements (e.g. pie charts) on a map. Since version 4 of this data I added the coordinate locations given in the matching WikiData entities because they seem to be more centered in the countries shape (unfortunately not for all countries).",.csv
"Country Names with Short Codes A2, A3, ISO",1,country-names-with-short-codes-a2-a3-iso,country code.csv,CC0-1.0,"# COUNTRY CODES ALPHA-2 & ALPHA-3

This is a complete list of all country ISO codes as described in the ISO 3166 international standard.
These codes are used throughout the IT industry by computer systems and software to ease the identification of country names.
We have compiled them in the quick reference table below in order to help our clients do quick conversions from the numeric or 2 letter code to any country name.

## Import System
`df=pd.read_csv(""/kaggle/input/country-names-with-short-codes-a2-a3-iso/country code.csv"",encoding = ""ISO-8859-1"")`",.csv
"Country, Regional and World GDP",1,country-regional-and-world-gdp,gdp_csv.csv,Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0),"## Read me

Country, regional and world GDP in current US Dollars ($). Regional means collections of countries e.g. Europe & Central Asia.

## Data 

The data is sourced from the World Bank, which in turn lists as sources: World Bank national accounts data, and OECD National Accounts data files.",.csv
Course Relevance Dataset,1,course-relevance-dataset,Course Relevance Dataset.csv,CC0-1.0,"This is a Tabular-Text Dataset. It entails list of programs available at an autonomous college with details of subjects and the information about which of the developmental needs are fulfilled on completion of the syllabus respective subject. Developmental Needs are segregated as Local, Regional , National and Global.


| Feature |Description |
| --- | --- |
| SrNo | Serial Number |
| Name Of the Program | Graduation or Post Graduation Program |
| Type of Course | Subject Name within selected program |
| Code | Subject Code |
| Need | Type of Developmental Need the subject is catering to |
| Description of the need | Description of Developmental Need associated to the subject|




## Image Credits:
&gt; Image by <a href=""https://pixabay.com/users/mohamed_hassan-5229782/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=4137887"">Mohamed Hassan</a> from <a href=""https://pixabay.com//?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=4137887"">Pixabay</a>",.csv
Covid Cases and Deaths WorldWide,1,covid-cases-and-deaths-worldwide,covid_worldwide.csv,CC0-1.0,"Coronavirus disease **(COVID-19)** is an infectious disease caused by the **SARS-CoV-2** virus.

Most people infected with the virus will experience mild to moderate respiratory illness and recover without requiring special treatment. However, some will become seriously ill and require medical attention. Older people and those with underlying medical conditions like cardiovascular disease, diabetes, chronic respiratory disease, or cancer are more likely to develop serious illness. Anyone can get sick with COVID-19 and become seriously ill or die at any age.

The best way to prevent and slow down transmission is to be well informed about the disease and how the virus spreads. Protect yourself and others from infection by staying at least **1 metre** apart from others, wearing a properly fitted mask, and washing your hands or using an alcohol-based rub frequently. **Get vaccinated when it’s your turn and follow local guidance.**

The virus can spread from an infected person’s mouth or nose in small liquid particles when they cough, sneeze, speak, sing or breathe. These particles range from larger respiratory droplets to smaller aerosols. It is important to practice respiratory etiquette, for example by coughing into a flexed elbow, and to stay home and self-isolate until you recover if you feel unwell.

**Where are cases still high?**

Daily global cases fell after a spike in the spring but are now rising again, with the emergence of the **BA.4** and **BA.5** subvariants of the **Omicron** variant.

Studies suggest that Omicron - which quickly became dominant in numerous countries - is milder than the Delta variant, but far more contagious. The subvariants are even more contagious.",.csv
Covid in African Countries - Latest Data,1,covid-in-african-countries-latest-data,covid_africa.csv,DbCL-1.0,"## Content

This dataset contains Covid-19 data of African countries as on **September 19, 2023**

## Attribute Information

- **Country** - Name of African countries
- **Total Cases** - Total number of Covid-19 cases
- **Total Deaths** - Total number of Deaths
- **Total Recovered** - Total number of recovered cases
- **Active Cases** - Total number of Active cases
- **Total Cases/1 mil population**- Total Cases per 1 million of the population
- **Deaths/1 mil population** - Total Deaths per 1 million of the population
- **Total Tests** - Total number of Covid tests done
- **Tests/1 mil population** - Covid tests done per 1 million of the population
- **Population** - Population of the country

## Source
Link : https://www.worldometers.info/coronavirus/#countries

## Other Updated Covid19 Datasets

Link : https://www.kaggle.com/anandhuh/datasets

### Thank You",.csv
Covid-19 Data Deaths and Vaccinations,1,covid19-data-deaths-and-vaccinations,covid_data_cleaned.csv,CC0-1.0,"The data is collected from the Our World in Data website, which contains information about the deaths and the vaccination happening worldwide over a time frame of February 2020 till May 2022. 
Data as of 5th May 2022.
",.csv
Covid-19 Lockdown Survey of Kolkata Residents,1,covid-19-lockdown-survey-of-kolkata-residents,covid-lockdown-survey.csv,GPL-3.0,"The pandemic paved the way for a new era of work-from-home salary men/women, online school8, home-delivered food, and daily essentials. To help shed some light on their respective perspectives, a survey was conducted over 29 such individuals residing in the Greater Metropolitan Kolkata area. These individuals were surveyed on their mental and physical health statuses and any financial hardships they had experienced during the first 6 months of the Covid-19 lockdown. Analyses conducted on the survey findings were reported in the following paper: https://www.researchgate.net/publication/376349477_An_Analysis_of_the_Financial_Impact_of_Covid-19_on_the_Residents_of_Kolkata_India
The survey responses have been anonymised. Both csv and xlsx file type are provided.",.csv
Crab Age Prediction,1,crab-age-prediction,CrabAgePrediction.csv,CC0-1.0,"### Context

The dataset is used to estimate the age of the crab based on the physical attributes. Its a great starting point for classical regression analysis and feature engineering and understand the impact of feature engineering in Data Science domain.


### Content

Crab is very tasty and many countries of the world import huge amount of crabs for consumption every year. The main benefits of crab farming are, labor cost is very low, production cost is comparatively lower and they grow very fast. Commercial crab farming business is developing the lifestyle of the people of coastal areas. By proper care and management we can earn more from crab farming business than shrimp farming. You can raise mud crabs in two systems. Grow out farming and fattening systems. 


### Inspiration

For a commercial crab farmer knowing the right age of the crab helps them decide if and when to harvest the crabs. Beyond a certain age, there is negligible growth in crab's physical characteristics and hence, it is important to time the harvesting to reduce cost and increase profit. The goal of the dataset is:
1. Exploratory data analysis - Understand how different physical features change with age.
2. Feature Engineering - Define new features using a combination of given data points to help improve model accuracy.
3. Regression Model - Build a regression model to predict the age of the Crab.",.csv
Credit Card Approval Prediction (Cleaned Version),1,application-data,Application_Data.csv,CC0-1.0,"# Credit Card Approval Prediction (Cleaned Version)
**Original** Dataset Available [here](https://www.kaggle.com/rikdifos/credit-card-approval-prediction).
---

### ▶ Context 📝

The dataset is originally from @rikdifos. This dataset cleaned, merged, and transformed using Pentaho Data Integration (PDI). 
⏩ Full explanation about ***merged, transformation, and cleaning process*** is available on *[GitHub](https://github.com/caesarmario/etl-credit-card-dataset-using-pentaho)*.

### ▶ Inspiration 💭

- Implementing machine learning models to determine 'good' or 'bad' applicants.
- Handling imbalance data.

---

📷 *Image by [Avery Evans](https://unsplash.com/@averye457).*",.csv
Credit Card Customer Data,1,credit-card-customer-data,Credit Card Customer Data.csv,CC0-1.0,"### Context

A Customer Credit Card Information Dataset which can be used for Identifying Loyal Customers, Customer Segmentation, Targeted Marketing and other such use cases in the Marketing Industry.

A few tasks that can be performed using this dataset is as follows:
- Perform Data-Cleaning,Preprocessing,Visualizing and Feature Engineering on the Dataset.
- Implement Heirarchical Clustering, K-Means Clustering models.
- Create RFM (Recency,Frequency,Monetary) Matrix to identify Loyal Customers.

### Content

The Attributes Include:
- Sl_No
- Customer Key
- AvgCreditLimit
- TotalCreditCards
- Totalvisitsbank
- Totalvisitsonline
- Totalcallsmade",.csv
Credit Card Customers Prediction,1,credit-card-customers-prediction,BankChurners.csv,CC0-1.0,"A manager at the bank is disturbed with more and more customers leaving their credit card services. They would really appreciate if one could predict for them who is gonna get churned so they can proactively go to the customer to provide them better services and turn customers' decisions in the opposite direction.

I got this dataset from a website with the URL as https://leaps.analyttica.com/home. I have been using this for a while to get datasets and accordingly work on them to produce fruitful results. The site explains how to solve a particular business problem.

Now, this dataset consists of 10,000 customers mentioning their age, salary, marital_status, credit card limit, credit card category, etc. There are nearly 18 features.

We have only 16.07% of customers who have churned. Thus, it's a bit difficult to train our model to predict churning customers.

### Data Dictionary
| Column | Description |
|---|---|
| CLIENTNUM | Client number. Unique identifier for the customer holding the account |
| Attrition_Flag | Internal event (customer activity) variable - if the account is closed then 1 else 0 |
| Customer_Age | Demographic variable - Customer's Age in Years |
| Gender | Demographic variable - M=Male, F=Female |
| Dependent_count | Demographic variable - Number of dependents | 
| Education_Level | Demographic variable - Educational Qualification of the account holder (example: high school, college graduate, etc.) |
| Marital_Status | Demographic variable - Married, Single, Divorced, Unknown |
| Income_Category | Demographic variable - Annual Income Category of the account holder (&lt; $40K, $40K - 60K, $60K - $80K, $80K-$120K, &gt; |
| Card_Category | Product Variable - Type of Card (Blue, Silver, Gold, Platinum) |
| Months_on_book | Period of relationship with bank |
| Total_Relationship_count | Total no. of products held by the customer |
| Months_Inactive_12_mon | No. of months inactive in the last 12 months |
| Contacts_Count_12_mon | No. of Contacts in the last 12 months |
| Credit_Limit | Credit Limit on the Credit Card |
| Total_Revolving_Bal | Total Revolving Balance on the Credit Card |
| Avg_Open_To_Buy | Open to Buy Credit Line (Average of last 12 months) |
| Total_Amt_Chng_Q4_Q1 | Change in Transaction Amount (Q4 over Q1) |
| Total_Trans_Amt | Total Transaction Amount (Last 12 months) |
| Total_Trans_Ct | Total Transaction Count (Last 12 months) |
| Total_Ct_Chng_Q4_Q1 | Change in Transaction Count (Q4 over Q1) |
| Avg_Utilization_Ratio | Average Card Utilization Ratio |
| Naive_Bayes_Classifier_attribution | Naive Bayes |
| Naive_Bayes_Classifier_attribution | Naive Bayes |",.csv
Credit Card Fraud,1,credit-card-fraud,credit_card_fraud.csv,Apache 2.0,"Welcome to Incribo's synthetic tourism dataset! Crafted with precision, this dataset offers a realistic representation of travel history, making it an ideal playground for various analytical tasks.

Use the credit card fraud dataset to help you assess the merchant name, card type, encrypted CVV, and more!

Remember, this is just a sample! If you're intrigued and want access to the complete dataset or have specific requirements, don't hesitate to contact us(info@incribo.com). Happy building!",.csv
Credit Card Fraud Detection,1,creditcardfraud,creditcard.csv,DbCL-1.0,"Context
---------

It is important that credit card companies are able to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase.

Content
---------

The dataset contains transactions made by credit cards in September 2013 by European cardholders. 
This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.

It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, ... V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-sensitive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise. 

Given the class imbalance ratio, we recommend measuring the accuracy using the Area Under the Precision-Recall Curve (AUPRC). Confusion matrix accuracy is not meaningful for unbalanced classification.

Update (03/05/2021)
---------

A simulator for transaction data has been released as part of the practical handbook on Machine Learning for Credit Card Fraud Detection - https://fraud-detection-handbook.github.io/fraud-detection-handbook/Chapter_3_GettingStarted/SimulatedDataset.html. We invite all practitioners interested in fraud detection datasets to also check out this data simulator, and the methodologies for credit card fraud detection presented in the book.

Acknowledgements
---------

The dataset has been collected and analysed during a research collaboration of Worldline and the Machine Learning Group (http://mlg.ulb.ac.be) of ULB (Université Libre de Bruxelles) on big data mining and fraud detection.
More details on current and past projects on related topics are available on [https://www.researchgate.net/project/Fraud-detection-5][1] and the page of the [DefeatFraud][2] project

Please cite the following works: 

Andrea Dal Pozzolo, Olivier Caelen, Reid A. Johnson and Gianluca  Bontempi. [Calibrating Probability with Undersampling for Unbalanced  Classification.][3] In Symposium on Computational Intelligence and Data  Mining (CIDM), IEEE, 2015

Dal Pozzolo, Andrea; Caelen, Olivier; Le Borgne, Yann-Ael; Waterschoot, Serge; Bontempi, Gianluca.  [Learned lessons in credit  card fraud detection from a practitioner perspective][4], Expert systems with applications,41,10,4915-4928,2014, Pergamon

Dal Pozzolo, Andrea; Boracchi, Giacomo; Caelen, Olivier; Alippi,  Cesare; Bontempi, Gianluca. [Credit card fraud detection: a realistic modeling and a novel learning strategy,][5]  IEEE transactions on neural networks and learning systems,29,8,3784-3797,2018,IEEE

Dal Pozzolo, Andrea [Adaptive Machine learning for credit card fraud detection][6] ULB MLG PhD thesis (supervised by G. Bontempi)

Carcillo, Fabrizio; Dal Pozzolo, Andrea; Le Borgne, Yann-Aël; Caelen, Olivier; Mazzer, Yannis; Bontempi, Gianluca. [Scarff: a scalable  framework for streaming credit card fraud detection with Spark][7], Information fusion,41, 182-194,2018,Elsevier

Carcillo, Fabrizio; Le Borgne, Yann-Aël; Caelen, Olivier; Bontempi, Gianluca. [Streaming active learning strategies for real-life credit card fraud detection: assessment and visualization,][8] International Journal of Data Science and Analytics, 5,4,285-300,2018,Springer International Publishing

Bertrand Lebichot, Yann-Aël Le Borgne, Liyun He, Frederic Oblé, Gianluca Bontempi [Deep-Learning Domain Adaptation Techniques for Credit Cards Fraud Detection](https://www.researchgate.net/publication/332180999_Deep-Learning_Domain_Adaptation_Techniques_for_Credit_Cards_Fraud_Detection),  INNSBDDL 2019: Recent Advances in Big Data and Deep Learning, pp 78-88, 2019

Fabrizio Carcillo, Yann-Aël Le Borgne, Olivier Caelen, Frederic Oblé, Gianluca Bontempi [Combining Unsupervised and Supervised Learning in Credit Card Fraud Detection ](https://www.researchgate.net/publication/333143698_Combining_Unsupervised_and_Supervised_Learning_in_Credit_Card_Fraud_Detection) Information Sciences, 2019

Yann-Aël Le Borgne, Gianluca Bontempi [Reproducible machine Learning for Credit Card Fraud Detection - Practical Handbook ](https://www.researchgate.net/publication/351283764_Machine_Learning_for_Credit_Card_Fraud_Detection_-_Practical_Handbook) 

Bertrand Lebichot, Gianmarco Paldino, Wissam Siblini, Liyun He, Frederic Oblé, Gianluca Bontempi [Incremental learning strategies for credit cards fraud detection](https://www.researchgate.net/publication/352275169_Incremental_learning_strategies_for_credit_cards_fraud_detection),  IInternational Journal of Data Science and Analytics

  [1]: https://www.researchgate.net/project/Fraud-detection-5
  [2]: https://mlg.ulb.ac.be/wordpress/portfolio_page/defeatfraud-assessment-and-validation-of-deep-feature-engineering-and-learning-solutions-for-fraud-detection/
  [3]: https://www.researchgate.net/publication/283349138_Calibrating_Probability_with_Undersampling_for_Unbalanced_Classification
  [4]: https://www.researchgate.net/publication/260837261_Learned_lessons_in_credit_card_fraud_detection_from_a_practitioner_perspective
  [5]: https://www.researchgate.net/publication/319867396_Credit_Card_Fraud_Detection_A_Realistic_Modeling_and_a_Novel_Learning_Strategy
  [6]: http://di.ulb.ac.be/map/adalpozz/pdf/Dalpozzolo2015PhD.pdf
  [7]: https://www.researchgate.net/publication/319616537_SCARFF_a_Scalable_Framework_for_Streaming_Credit_Card_Fraud_Detection_with_Spark
  
[8]: https://www.researchgate.net/publication/332180999_Deep-Learning_Domain_Adaptation_Techniques_for_Credit_Cards_Fraud_Detection",.csv
Credit Card Spending Habits in India,1,analyzing-credit-card-spending-habits-in-india,Credit card transactions - India - Simple.csv,other,"_____
# Credit Card Spending Habits in India
### Gender, Location, and Transaction Trends
By Sadat Akash [[source]](https://data.world/ash018)
_____

### About this dataset
&gt; This dataset contains insights into a collection of credit card transactions made in India, offering a comprehensive look at the spending habits of Indians across the nation. From the Gender and Card type used to carry out each transaction, to which city saw the highest amount of spending and even what kind of expenses were made, this dataset paints an overall picture about how money is being spent in India today. With its variety in variables, researchers have an opportunity to uncover deeper trends in customer spending as well as interesting correlations between data points that can serve as invaluable business intelligence. Whether you're interested in learning more about customer preferences or simply exploring unbiased data analysis techniques, this data is sure to provide insight beyond what one could anticipate

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset 
&gt; - To get started with this dataset, you first need to select the columns you want to analyze. Once your columns are selected, use pivot tables to create a summary of the total amount spent by month or city or other parameters of analysis. Some suggested analysis would include factors such as gender, seasonality/timing of spending etc which can help to better understand Indian consumer behaviour related to credit cards as well as provide insights into personal finance management that could be useful for improved financial decisions.  
&gt; - Once a summary table is created from the selected columns it could be useful to add more detailed breakdowns by combining multiple criteria such as ‘amount’ with ‘expense type’ or ‘date’ etc., this way more informative visuals and summaries can be generated which could then again help in forming better conclusions about financial habits within India related to Credit Card usage trends and recommendations for future improvement measures if needed .  
&gt; - Additionally , if available other external information (i.e population size/density/income levels etc.)could also be compared with these findings so further actionable areas of focus can be identified on an overall level or credited towards specific buyer personas / cities etc.

### Research Ideas
&gt; - To analyze consumer trends and interests by looking at the type of purchases people make based on their gender and city. 
&gt; - To detect potential credit card fraud or malicious activity, such as by analyzing changes in spending habits or unusual purchases, by city and gender. 
&gt; - To predict spending patterns for promotional campaigns, such as during festivals or holidays, in order to better target customer segments according to city and gender based spending habits

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://data.world/ash018)
&gt;  

### License 
&gt; 
&gt; See the dataset description for more information.

### Columns

**File: Credit card transactions - India - Simple.csv**
| Column name   | Description                                                   |
|:--------------|:--------------------------------------------------------------|
| **City**      | The city in which the transaction took place. (String)        |
| **Date**      | The date of the transaction. (Date)                           |
| **Card Type** | The type of credit card used for the transaction. (String)    |
| **Exp Type**  | The type of expense associated with the transaction. (String) |
| **Gender**    | The gender of the cardholder. (String)                        |
| **Amount**    | The amount of the transaction. (Number)                       |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [Sadat Akash](https://data.world/ash018).

-",.csv
Credit Card Spendings,1,credit-card-spendings,Credit card transactions - India - Simple.csv,Apache 2.0,"This dataset contains insights into a collection of credit card transactions made in India, offering a comprehensive look at the spending habits of Indians across the nation. From the Gender and Card type used to carry out each transaction, to which city saw the highest amount of spending and even what kind of expenses were made, this dataset paints an overall picture about how money is being spent in India today. With its variety in variables, researchers have an opportunity to uncover deeper trends in customer spending as well as interesting correlations between data points that can serve as invaluable business intelligence. Whether you're interested in learning more about customer preferences or simply exploring unbiased data analysis techniques, this data is sure to provide insight beyond what one could anticipate",.csv
Credit Card customers,1,credit-card-customers,BankChurners.csv,CC0-1.0,"A manager at the bank is disturbed with more and more customers leaving their credit card services. They would really appreciate if one could predict for them who is gonna get churned so they can proactively go to the customer to provide them better services and turn customers' decisions in the opposite direction

I got this dataset from a website with the URL as https://leaps.analyttica.com/home. I have been using this for a while to get datasets and accordingly work on them to produce fruitful results. The site explains how to solve a particular business problem. 

Now, this dataset consists of 10,000 customers mentioning their age, salary, marital_status, credit card limit, credit card category, etc. There are nearly 18 features. 

We have only 16.07% of customers who have churned. Thus, it's a bit difficult to train our model to predict churning customers. ",.csv
Credit Risk Dataset,1,credit-risk-dataset,credit_risk_dataset.csv,CC0-1.0,"Detailed data description of Credit Risk dataset:
| **Feature Name** | **Description** | 
| --- | --- |
| person_age | Age | 
| person_income | Annual Income | 
| person_home_ownership | Home ownership |
| person_emp_length | Employment length (in years) | 
| loan_intent | Loan intent |  
| loan_grade | Loan grade | 
| loan_amnt | Loan amount | 
| loan_int_rate | Interest rate | | 
| loan_status | Loan status (0 is non default 1 is default) | 
| loan_percent_income | Percent income | 
| cb_person_default_on_file | Historical default | 
| cb_preson_cred_hist_length | Credit history length | 
",.csv
Credit Score Classification Dataset,1,credit-score-classification-dataset,Credit Score Classification Dataset.csv,Attribution 4.0 International (CC BY 4.0),"**This dataset contains information about a sample of over 100 people across the world. The data includes the following information:**

1. Age
2. Gender
3. Income
4. Education
5. Marital Status
6. Number of Children
7. Home Ownership
8. Credit Score",.csv
Credit Score Classification [Clean Data],1,credit-score-classification-clean-data,Credit_Score_Clean.csv,other,"Clean Dataset for Credit Card Classification

I have managed to clean null values and some format issues from the original data. Feel free to use it",.csv
CreditScoreClassification_train_cleaned,1,creditscoreclassification-train-cleaned,CreditScoreClassification_train_cleaned1.csv,other,"Cleaned train data from: https://www.kaggle.com/datasets/parisrohan/credit-score-classification?select=train.csv

To view Data Cleaning for train data: https://www.kaggle.com/datasets/demettal/creditscoreclassification-train-cleaned",.csv
Credit_Card_Application,1,credit-card-application,Credit_Card_Applications.csv,Apache 2.0,"""This project provides an opportunity to analyze and predict credit card application data. The dataset includes various attributes such as income, age, occupation, and previous credit history, which can influence the credit card approval decision.

The objective of this project is to explore the dataset, clean it, and generate necessary features to build machine learning models that can predict the likelihood of credit card approval.

We will utilize different machine learning algorithms such as logistic regression, decision trees, and random forests, and evaluate them to determine the best-performing model.

Our goal is to develop a model that demonstrates good performance and accurately predicts real-world credit card approval decisions. Through this project, we aim to understand credit risk and assist credit card companies in decision-making processes.""

**About This File**:


**1. CustomerID:** Unique identifier for each customer in the dataset.

**2. A1:** Description of attribute A1 is not provided. It seems to represent some characteristic or feature related to the customer.

**3. A2:** Description of attribute A2 is not provided. Similar to A1, it represents a customer feature.

**4. A3:** Description of attribute A3 is not provided. It likely corresponds to another customer characteristic.

**5. A4: **Description of attribute A4 is not provided. It likely corresponds to another customer characteristic.

**6. A5: **Description of attribute A5 is not provided. It likely corresponds to another customer characteristic.

**7. A6:** Description of attribute A6 is not provided. It likely corresponds to another customer characteristic.

**8. A7:** Description of attribute A7 is not provided. It likely corresponds to another customer characteristic.

**9. A8:** Description of attribute A8 is not provided. It likely corresponds to another customer characteristic.

**10. A9:** Description of attribute A9 is not provided. It likely corresponds to another customer characteristic.

**11. A10: **Description of attribute A10 is not provided. It likely corresponds to another customer characteristic.

**12. A11: **Description of attribute A11 is not provided. It likely corresponds to another customer characteristic.

**13. A12:** Description of attribute A12 is not provided. It likely corresponds to another customer characteristic.

**14. A13: **Description of attribute A13 is not provided. It likely corresponds to another customer characteristic.

**15. A14: **Description of attribute A14 is not provided. It likely corresponds to another customer characteristic.

**16. A15: **Class label indicating whether the credit card application was approved or rejected.





",.csv
Credit_Risk_Analysis,1,credit-risk-analysis,credit_risk.csv,Apache 2.0,"

**Description**:
Welcome to the ""Loan Applicant Data for Credit Risk Analysis"" dataset on Kaggle! This dataset provides essential information about loan applicants and their characteristics. Your task is to develop predictive models to determine the likelihood of loan default based on these simplified features.

In today's financial landscape, assessing credit risk is crucial for lenders and financial institutions. This dataset offers a simplified view of the factors that contribute to credit risk, making it an excellent opportunity for data scientists to apply their skills in machine learning and predictive modeling.

**Column Descriptions**:

- **ID**: Unique identifier for each loan applicant.
- **Age**: Age of the loan applicant.
- **Income**: Income of the loan applicant.
- **Home**: Home ownership status (Own, Mortgage, Rent).
- **Emp_Length**: Employment length in years.
- **Intent**: Purpose of the loan (e.g., education, home improvement).
- **Amount**: Loan amount applied for.
- **Rate**: Interest rate on the loan.
- **Status**: Loan approval status (Fully Paid, Charged Off, Current).
- **Percent_Income**: Loan amount as a percentage of income.
- **Default**: Whether the applicant has defaulted on a loan previously (Yes, No).
- **Cred_Length**: Length of the applicant's credit history.

Explore this dataset, preprocess the data as needed, and develop machine learning models, especially using Random Forest, to predict loan default. Your insights and solutions could contribute to better credit risk assessment methods and potentially help lenders make more informed decisions.

Remember to respect data privacy and ethics guidelines while working with this data. Good luck, and happy analyzing!

",.csv
Creditability - German Credit Data,1,cusersmarildownloadsgermancsv,german.csv,other,"### Context

When a bank receives a loan application, based on the applicant’s profile the bank has to make a decision regarding whether to go ahead with the loan approval or not. Two types of risks are associated with the bank’s decision.""

""If the applicant is a good credit risk, i.e. is likely to repay the loan, then not approving the loan to the person results in a loss of business to the bank
If the applicant is a bad credit risk, i.e. is not likely to repay the loan, then approving the loan to the person results in a financial loss to the bank.""

The predictors that may potentially have any influence on Creditability:

Account Balance: No account (1), None (No balance) (2), Some Balance (3)

Payment Status: Some Problems (1), Paid Up (2), No Problems (in this bank) (3)

Savings/Stock Value: None, Below 100 DM, [100, 1000] DM, Above 1000 DM

Employment Length: Below 1 year (including unemployed), [1, 4), [4, 7), Above 7

Sex/Marital Status: Male Divorced/Single, Male Married/Widowed, Female

No of Credits at this bank: 1, More than 1

Guarantor: None, Yes

Concurrent Credits: Other Banks or Dept Stores, None

ForeignWorker variable may be dropped from the study

Purpose of Credit: New car, Used car, Home Related, Other

https://online.stat.psu.edu/stat508/resource/analysis/gcd


### Content

The German Credit Data contains data on 20 variables and the classification whether an applicant is considered a Good or a Bad credit risk for 1000 loan applicants.   A predictive model developed on this data is expected to provide a bank manager guidance for making a decision whether to approve a loan to a prospective applicant based on his/her profiles.


### Acknowledgements

https://online.stat.psu.edu/stat508/resource/analysis/gcd

Photo by Alice Pasqual on Unsplash


### Inspiration

Unemployment in time of crisis.",.csv
Cricket Social Media Dataset,1,icc-social-media-dataset,icc_fb_page.csv,ODC Attribution License (ODC-By),"

### Dataset Description

#### Dataset Overview
This dataset encompasses a meticulously compiled collection of 2000 posts from the official International Cricket Council (ICC) Facebook page. Each entry captures the dynamic interactions of cricket enthusiasts around the globe, presenting a unique opportunity to explore the trends, sentiments, and patterns within the cricket community. The data was ethically mined today, ensuring up-to-date insights into the latest discussions and opinions circulating among ICC followers.

#### Data Science Applications
The breadth and depth of this dataset offer a fertile ground for a variety of data science projects, including but not limited to:
- **Sentiment Analysis**: Gauge the emotional tone and sentiment of the global cricket community towards events, matches, and players.
- **Trend Analysis**: Identify emerging trends in discussions, such as rising popularity of players or reactions to cricketing events.
- **Engagement Analysis**: Understand what type of content generates the most engagement in terms of likes, shares, and comments.
- **Network Analysis**: Explore the social dynamics and influence patterns within the cricket fan community.
- **Natural Language Processing (NLP)**: Employ advanced NLP techniques to extract insights, themes, and patterns from textual content.

#### Column Descriptors
The dataset is structured into four key columns:
- **Comments**: Number of comments on each post, reflecting the level of interaction and discussion each topic generates.
- **Likes**: Number of likes on each post, indicating the overall popularity and approval from the community.
- **Shares**: Number of shares for each post, showing the extent to which content is circulated beyond the immediate audience.
- **Text**: The textual content of the post, providing rich qualitative data for textual analysis and insight generation.

#### Ethically Mined Data
This dataset was ethically mined with strict adherence to privacy and data use policies, ensuring that all information was collected in a manner that respects user privacy and platform guidelines. No personal user data was collected or used in the creation of this dataset.

#### Acknowledgements
We extend our gratitude to the International Cricket Council (ICC) and Facebook for fostering an engaging and vibrant community where fans from around the world can share their passion for cricket. Their platforms not only bring fans closer to the game but also provide valuable data that can be used to enhance our understanding of sports communities and fan engagement.

This dataset serves as an invaluable resource for data scientists, researchers, and cricket enthusiasts alike, offering insights into the global conversation surrounding one of the world's most beloved sports.",.csv
Crime - Statistics [2000 - 2020],1,crimestatistics,Crime_Statistics_2000-2020.csv,CC0-1.0,"This dataset contains the number of crimes recorded in a city over a period of 21 years, from 2000 to 2020. The dataset is presented in a comma-separated value format, and includes the year of the recorded crime, the type of crime (Assault, Burglary, Robbery, Vehicle Theft), and the number of occurrences of that crime in that year. This dataset could be used for analyzing crime trends over time, identifying areas where specific types of crimes are more prevalent, and for creating predictive models to estimate the likelihood of certain types of crimes occurring in a given year.",.csv
Crime Against Women 2001-2014 (India),1,crime-against-women-20012014-india,crimes_against_women_2001-2014.csv,other,"This data is collated from https://data.gov.in. It has state-wise and district level data on the various crimes committed against women between 2001 to 2014. Some crimes that are included are Rape, Kidnapping and Abduction, Dowry Deaths etc. ",.csv
Crimes in US Communities Dataset,1,crimedata,crimedata.csv,other,"This is a dataset of 2018 US communities, demographics of each community, and their crime rates. The dataset has 146 variables where the first four columns are community/location, the middle features are demographic information about each community such as population, age, race, income, and the final columns are types of crimes and overall crime rates.",.csv
Crimes in india Dataset (2001-2013),1,crimes-in-india-dataset-2001-2013,Crimes_in_india_2001-2013.csv,CC0-1.0,"
### Dataset Description:

This dataset contains crime statistics in India, categorized by State/Union Territory (STATE/UT) and District (DISTRICT) on a yearly basis (YEAR). It provides insights into various criminal activities reported across different regions of India.

### Columns:

1. **STATE/UT:** The State or Union Territory where the crime was reported.
2. **DISTRICT:** The district within the State/UT where the crime was reported.
3. **YEAR:** The year when the crime was reported.
4. **MURDER:** Number of reported cases of murder.
5. **ATTEMPT TO MURDER:** Number of reported cases of attempted murder.
6. **CULPABLE HOMICIDE NOT AMOUNTING TO MURDER:** Number of reported cases of culpable homicide not amounting to murder.
7. **RAPE:** Number of reported cases of rape.
8. **CUSTODIAL RAPE:** Number of reported cases of custodial rape.
9. **OTHER RAPE:** Number of reported cases of rape other than custodial rape.
10. **KIDNAPPING & ABDUCTION:** Number of reported cases of kidnapping and abduction.
11. **KIDNAPPING AND ABDUCTION OF WOMEN AND GIRLS:** Number of reported cases of kidnapping and abduction of women and girls.
12. **KIDNAPPING AND ABDUCTION OF OTHERS:** Number of reported cases of kidnapping and abduction of others.
13. **DACOITY:** Number of reported cases of dacoity.
14. **PREPARATION AND ASSEMBLY FOR DACOITY:** Number of reported cases related to preparation and assembly for dacoity.
15. **ROBBERY:** Number of reported cases of robbery.
16. **BURGLARY:** Number of reported cases of burglary.
17. **THEFT:** Number of reported cases of theft.
18. **AUTO THEFT:** Number of reported cases of auto theft.
19. **OTHER THEFT:** Number of reported cases of other theft.
20. **RIOTS:** Number of reported cases of riots.
21. **CRIMINAL BREACH OF TRUST:** Number of reported cases of criminal breach of trust.
22. **CHEATING:** Number of reported cases of cheating.
23. **COUNTERFIETING:** Number of reported cases of counterfeiting.
24. **ARSON:** Number of reported cases of arson.
25. **HURT/GREVIOUS HURT:** Number of reported cases of hurt/grievous hurt.
26. **DOWRY DEATHS:** Number of reported cases of dowry deaths.
27. **ASSAULT ON WOMEN WITH INTENT TO OUTRAGE HER MODESTY:** Number of reported cases of assault on women with intent to outrage her modesty.
28. **INSULT TO MODESTY OF WOMEN:** Number of reported cases of insult to modesty of women.
29. **CRUELTY BY HUSBAND OR HIS RELATIVES:** Number of reported cases of cruelty by husband or his relatives.
30. **IMPORTATION OF GIRLS FROM FOREIGN COUNTRIES:** Number of reported cases of importation of girls from foreign countries.
31. **CAUSING DEATH BY NEGLIGENCE:** Number of reported cases of causing death by negligence.
32. **OTHER IPC CRIMES:** Number of reported cases of other IPC crimes.
33. **TOTAL IPC CRIMES:** Total number of reported IPC crimes.

",.csv
Cristiano Ronaldo | All Club Goals,1,cr7-cristiano-ronaldo-all-club-goals-stats,data.csv,ODbL-1.0,"# Context
This dataset contains all the stats of **all club goals** of **Cristiano Ronaldo dos Santos Aveiro**.

# About Cristiano Ronaldo
**Cristiano Ronaldo dos Santos Aveiro** is a Portuguese professional footballer who plays as a forward for Premier League club Manchester United and captains the Portugal national team.
 
- Current team: Portugal national football team (#7 / Forward) Trending
                                               
- Born: February 5, 1985 (age 37 years), Hospital Dr. Nélio Mendonça, Funchal, Portugal
- Height: 1.87 m
- Partner: Georgina Rodríguez (2017–)
- Salary: 26.52 million GBP (2022)
- Children: Cristiano Ronaldo Jr., Alana Martina dos Santos Aveiro, Eva Maria Dos Santos, Mateo Ronaldo

![CR7](https://assets.goal.com/v3/assets/bltcc7a7ffd2fbf71f5/blt4851623938e7dbe9/625aea2f638d944cfb0c0dce/Cristiano_Ronaldo_Manchester_United_2021-22.jpg?auto=png&format=jpg&quality=100)

# Content
- data.csv file containing Goal_no, Season, Competition, Matchday, Venue, Team, Opponent, Result, Position, Minute, At_score, Type_of_goal

# Featured Notebook
[**CR7 - Extensive EDA & Analytics-Cristiano Ronaldo**](https://www.kaggle.com/azminetoushikwasi/cr7-extensive-eda-analytics-cristiano-ronaldo)

# Related Datasets
- [EPL 2021-22 | Stats | Matches and Players](https://www.kaggle.com/datasets/azminetoushikwasi/epl-21-22-matches-players)
- [⚽ Lionel Messi ⭐ All Club Goals 📈📊](https://www.kaggle.com/datasets/azminetoushikwasi/-lionel-messi-all-club-goals)

# Download
kaggle API Command

`!kaggle datasets download -d azminetoushikwasi/cr7-cristiano-ronaldo-all-club-goals-stats`

## Disclaimer
The data collected are all publicly available and it's intended for educational purposes only.

## Acknowledgement
Cover image credit - goal.com",.csv
Crop Datasets for All Indian States: 2010-2017,1,crop-datasets-for-all-indian-states-2010-2017,Crops_data.csv,other,"**Description:**
This dataset provides comprehensive agricultural crop data spanning the years 2010 to 2017 for all states across India. It includes detailed information on crop production, yield, acreage, and other relevant agricultural metrics at the state level. The dataset aims to facilitate analysis and exploration of agricultural trends, crop diversification, and regional variations in crop production patterns over the specified time period. Researchers, policymakers, and agricultural stakeholders can utilize this dataset to gain insights into the dynamics of Indian agriculture, identify patterns, and inform decision-making processes related to crop planning, resource allocation, and agricultural development initiatives.

**Key Features:**

1. State-wise crop production statistics
2. Crop yield per hectare
3. Cultivated area for each crop
4. Temporal trends in crop production
5. Seasonal variations and cropping patterns
6. Potential for crop diversification and agricultural sustainability assessments

**Dataset Contents:**
The dataset includes structured data files in CSV format, organized by year and state, with columns representing different crop types and relevant agricultural indicators. Each record corresponds to a specific crop category within a particular state and year, providing a granular overview of agricultural activities and crop performance across India during the specified timeframe.

**Use Cases:**

1. Analyzing crop production dynamics and trends over time
2. Identifying key drivers of agricultural productivity at the state level
3. Assessing the impact of climatic factors, policy interventions, and technological advancements on crop yields
4. Supporting evidence-based decision-making in agricultural planning, resource allocation, and policy formulation
5. Conducting research on crop diversification strategies, sustainable agriculture practices, and food security initiatives

**Data Sources**:
The dataset integrates information from diverse sources, including government agricultural surveys, crop estimation reports, and official statistical publications from various state and national agricultural agencies in India. Efforts have been made to ensure data consistency, accuracy, and reliability across different sources to facilitate meaningful analysis and interpretation.

*Note:*
This dataset is intended for research and informational purposes and may require validation and contextual interpretation based on specific analytical objectives and regional considerations.",.csv
Crop Price Prediction Dataset,1,crop-price-prediction-dataset,Crop_Yield_Prediction.csv,MIT,"**CROP PRICE PREDICTION**

INTRODUCTION

Crop yield prediction plays a vital role in modern agriculture, especially with the increasing adoption of data-driven approaches. Comprehensive datasets, including information about soil composition, environmental factors, historical yield data, and crop management practices, are crucial for accurate yield predictions. Analyzing and understanding these datasets can provide valuable insights for optimizing agricultural practices and ensuring sustainable crop production.

WHY IS YIELD PREDICTION IMPORTANT?

*1. Optimized Production:* Accurate yield predictions help farmers optimize their production plans by adjusting planting schedules, selecting suitable crop varieties, and implementing appropriate management practices.

*2. Resource Efficiency:* Data-driven yield predictions enable efficient use of resources such as water, fertilizers, and pesticides, leading to cost savings and reduced environmental impact.

*3. Risk Mitigation:* Predicting yields allows farmers to anticipate and mitigate risks such as crop failures due to adverse weather conditions, pest infestations, or diseases.

*4. Market Planning:* Yield predictions assist farmers in planning for market fluctuations by forecasting supply and demand dynamics, thereby optimizing marketing strategies and maximizing profits.

*5. Sustainability*: By promoting optimal resource use and reducing waste, accurate yield predictions contribute to sustainable agriculture practices and environmental conservation.

CONCLUSION

Accurate crop yield prediction is essential for modern agriculture's success, enabling farmers to make informed decisions, optimize resource use, mitigate risks, and enhance sustainability. Leveraging comprehensive datasets and advanced analytical tools empowers farmers and agricultural experts to improve production efficiency, resilience, and profitability, ultimately ensuring food security and environmental stewardship in the agricultural sector.",.csv
Crop Production Statistics - India,1,crop-production-statistics-india,APY.csv,CC0-1.0,"# Context
The dataset contains comprehensive data on crop production statistics for India, categorized by state and district. The dataset covers four major crop seasons, namely kharif, rabbi, summer, and autumn, from the year 1997 to 2023. The data provides information on the annual production and yield of crops grown in different parts of the country.

The dataset will be useful for researchers, policymakers, and farmers who are interested in understanding crop production patterns in different regions of India. By analyzing the data, researchers can identify the factors that influence crop yields and production and can make informed decisions on how to improve agricultural productivity in the country. Policymakers can use the data to design and implement agricultural policies that promote sustainable farming practices and improve food security.

Farmers can also benefit from the dataset by gaining insights into the best crops to grow in their region and making informed decisions on crop management practices. Additionally, the dataset can be used to train machine learning models to predict crop yields and production in different parts of the country, which can be valuable for agricultural businesses and organizations. Overall, the dataset provides a comprehensive overview of crop production statistics in India, which is essential for understanding the country's agricultural landscape and developing effective strategies for sustainable agriculture.

# Sources
This dataset contains comprehensive information on agricultural production statistics in India, sourced from the Indian government's Area Production Statistics (APS) database. The APS is maintained by the Ministry of Agriculture and Farmers Welfare and provides detailed data on crop production, yield, and area under cultivation across different states and districts in India.
Overall, this dataset is an important resource for anyone interested in agriculture and its impact on the Indian economy and society.
## Link :- ***https://aps.dac.gov.in/APY/Public_Report1.aspx***

# Inspiration 
Agriculture is the backbone of the Indian economy, providing employment to millions of people and contributing significantly to the country's GDP. However, the sector is faced with several challenges, including climate change, low productivity, and food security issues. To address these challenges, there is a need for data-driven solutions that can inform policy and decision-making.

Creating a dataset that captures agricultural production statistics in India can help in this regard. The dataset can provide valuable insights into crop yields, area under cultivation, and other metrics that can inform agricultural policies and practices. It can also be used to identify trends and patterns in agricultural production, helping farmers and policymakers make informed decisions about crop selection, irrigation, and other important factors that affect agricultural productivity.

Additionally, the dataset can be used for machine learning and predictive modeling to generate insights and make accurate predictions about crop production in different parts of the country. Overall, the dataset has the potential to contribute significantly to the development of the agriculture sector in India and help address some of the challenges faced by the sector.





",.csv
Crop Production in India,1,crop-production-in-india,crop_production.csv,other,"### Context

This dataset provides a huge amount of information on crop production in India ranging from several years. Based on the Information the ultimate goal would be to predict crop production using powerful machine learning techniques.


### Content
The content is taken from data.world website
https://data.world/thatzprem/agriculture-india

### Inspiration

Can you predict the crop production in India, which is vital for so many things? ",.csv
Crop Yields,1,crop-yields,agriculture-value-added-per-worker-wdi new.csv,CC0-1.0,"this graph was created in Loocker studio, Tableau and canva :

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fe1ae580aa89175855954abd10804312e%2Fgraph2.png?generation=1712437107613119&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F34f17c84bbd4062f55fd554fd7887c6d%2Fgraph1.jpg?generation=1712437113898571&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F192a31abbabf566924b50cbe187eb41c%2Fgraph3.png?generation=1712437119272457&alt=media)

In the intricate tapestry of global challenges, the quest for improved crop yields stands as a linchpin, a silent yet crucial protagonist in the narrative of human survival and environmental stewardship. Amidst the cacophony of pressing issues, from climate change to socioeconomic disparities, the imperative to enhance crop yields emerges as a beacon of hope, offering a pathway towards feeding an ever-expanding populace while mitigating the environmental toll of agricultural practices.

The nexus between crop yields, population growth, and environmental sustainability is not merely a matter of agricultural optimization; it is a fundamental tenet of our collective future. As the global population burgeons, surpassing the 8 billion mark and continuing its upward trajectory, the pressure on agricultural systems intensifies exponentially. In this crucible of burgeoning demands and finite resources, the quest for increased crop yields becomes an existential imperative, a cornerstone upon which the edifice of global food security rests.

At its core, the quest for enhanced crop yields transcends the confines of agrarian science; it embodies a holistic approach towards harmonizing human needs with planetary boundaries. The symbiotic relationship between agricultural productivity and environmental sustainability underscores the urgency of our endeavor. By bolstering crop yields, we not only satiate the appetites of a burgeoning populace but also alleviate the strain on natural ecosystems, curtailing deforestation, soil degradation, and water scarcity.

Moreover, the ramifications of stagnant crop yields reverberate far beyond the confines of agricultural landscapes. In the crucible of poverty and food insecurity, where millions languish on the fringes of subsistence existence, the imperative for enhanced productivity assumes a moral dimension. Elevating crop yields isn't merely a matter of enhancing agricultural efficiency; it is a clarion call for social justice, a means of emancipating the marginalized from the shackles of hunger and deprivation.

In the annals of agricultural innovation, the pursuit of enhanced crop yields has yielded a panoply of transformative solutions, ranging from genetic engineering to precision agriculture. The advent of genetically modified organisms (GMOs), endowed with traits conducive to higher yields and resilience against pests and diseases, has revolutionized agricultural landscapes, propelling productivity to unprecedented heights.

Similarly, the advent of precision agriculture, underpinned by cutting-edge technologies such as satellite imaging, drones, and IoT sensors, has engendered a paradigm shift in farming practices. By harnessing real-time data and analytics, farmers can fine-tune their operations with surgical precision, optimizing resource allocation and maximizing yields while minimizing environmental impacts.

However, amidst the zeal for technological innovation, it is imperative to heed the imperatives of equity and inclusivity. The benefits of enhanced crop yields must accrue equitably, reaching the smallholder farmers who comprise the backbone of global food production. Empowering smallholder farmers with access to innovative technologies, financial resources, and knowledge resources is not merely a matter of altruism; it is an investment in the resilience and sustainability of agricultural systems worldwide.

Furthermore, the pursuit of enhanced crop yields necessitates a paradigm shift in our collective mindset, transcending the ethos of production at all costs towards one of regenerative stewardship. Sustainable intensification, predicated on agroecological principles and holistic land management practices, offers a pathway towards reconciling productivity with environmental resilience.

By harnessing the power of biodiversity, soil health, and ecosystem services, sustainable intensification fosters resilient agricultural systems capable of weathering the storms of climate change while simultaneously nourishing both people and planet. From agroforestry to cover cropping, the arsenal of sustainable intensification strategies embodies the ethos of symbiosis, weaving together the threads of ecological resilience and human prosperity.

In conclusion, the quest for enhanced crop yields stands as a linchpin in the tapestry of global sustainability, embodying the convergence of human ingenuity, social equity, and environmental stewardship. In a world beset by myriad challenges, from hunger and poverty to environmental degradation, the imperative to bolster agricultural productivity assumes paramount importance.

As we navigate the turbulent currents of the 21st century, let us heed the clarion call for agricultural innovation, embracing a holistic vision of sustainability that nourishes both people and planet. In the crucible of collaboration and solidarity, let us forge a brighter future, where bountiful harvests coexist harmoniously with thriving ecosystems, and where the seeds of hope and resilience are sown in the fertile soil of collective endeavor.",.csv
CropSeason_State_AgriculturalData,1,crop-data-of-the-indian-states,Crop_Data.csv,Apache 2.0,"This dataset provides comprehensive information on crop cultivation practices across different regions, seasons, and soil types. It includes data on various crops such as cotton, onion, potato, rice, wheat, ragi, groundnut, sugarcane, and banana, along with relevant agricultural parameters and environmental factors. The dataset covers key attributes including the cropping season (kharif, rabi, or whole year), geographical location (state), cultivated area, soil type (e.g., alluvial soil, black soil), pesticide usage levels (high, low, average), soil pH, temperature conditions (low, high, average), fertilizer usage levels (low, high, average), crop prices, and rainfall levels (high, low, average).

Columns:

**Crop**: Type of crop being cultivated.
**Season**: Cropping season (kharif, rabi, whole year).
**State**: Geographical location or state where the crop is cultivated.
**Area**: Area of land dedicated to cultivating the respective crop.
**Soil Type**: Type of soil prevalent in the cultivation area.
**Pesticide Usage**: Level of pesticide usage for crop protection (high, low, average).
**pH**: pH level of the soil.
**Temperature**: Average temperature conditions during the crop cultivation period.
**Fertilizer Usage**: Level of fertilizer usage for crop nourishment (low, high, average).
**Price**: Price of the crop.
**Rainfall**: Amount of rainfall experienced during the cultivation period.

This dataset is valuable for agricultural research, enabling analysis of the relationships between various factors and crop yields, prices, or quality. It can aid in predicting optimal cultivation conditions, understanding the impact of environmental factors on crop growth, and optimizing agricultural practices for different regions and seasons.",.csv
Crowdedness at the Campus Gym,1,crowdedness-at-the-campus-gym,data.csv,DbCL-1.0,"# Background

When is my university campus gym least crowded, so I know when to work out? We measured how many people were in this gym once every 10 minutes over the last year. We want to be able to predict how crowded the gym will be in the future.


# Goals

 1. Given a time of day (and maybe some other features, including weather), predict how crowded the gym will be. 
 2. Figure out which features are actually important, which are redundant, and what features **could be added** to make the predictions more accurate.


# Data

The dataset consists of 26,000 people counts (about every 10 minutes) over the last year. In addition, I gathered extra info including weather and semester-specific information that might affect how crowded it is. The label is the number of people, which I'd like to predict given some subset of the features. 

Label:

 - Number of people 

Features:
 
 - date (string; datetime of data)
 - timestamp (int; number of seconds since beginning of day)
 - day_of_week (int; 0 [monday] - 6 [sunday])
 - is_weekend (int; 0 or 1) [boolean, if 1, it's either saturday or sunday, otherwise 0]
 - is_holiday (int; 0 or 1) [boolean, if 1 it's a federal holiday, 0 otherwise]
 - temperature (float; degrees fahrenheit)
 - is_start_of_semester (int; 0 or 1) [boolean, if 1 it's the beginning of a school semester, 0 otherwise]
 - month (int; 1 [jan] - 12 [dec])
 - hour (int; 0 - 23)



# Acknowledgements

This data was collected with the consent of the university and the gym in question.",.csv
Crude oil,1,crude-oil,crude-oil-prices.csv,CC0-1.0,"This dataset provides a comprehensive view of crude oil data, including prices, production levels, and market trends over a specific period. It contains data from various sources to offer a detailed insight into the global crude oil market. This dataset includes information on daily crude oil prices, production rates by country, and other relevant metrics such as supply and demand. It is ideal for analysts, researchers, and industry professionals interested in studying crude oil market dynamics, forecasting trends, and making data-driven decisions. The data is cleaned and structured for easy use and analysis.",.csv
Crypto Data,1,crypto-data,Crypto.csv,DbCL-1.0,"Cryptocurrency web scraping involves extracting data related to digital currencies from various online sources such as cryptocurrency exchanges, news websites, forums, and social media platforms. This data can encompass a wide range of information, including real-time price data, trading volumes, market sentiment, blockchain statistics, ICO details, and more.

Cryptocurrency web scraping is utilized by traders, analysts, researchers, and developers to gather insights, conduct market research, develop trading strategies, build financial models, and create data-driven applications. By collecting and analyzing large volumes of cryptocurrency data, stakeholders can make informed decisions and stay up-to-date with the rapidly evolving crypto market landscape.",.csv
CryptoCurrencies Smart Contract platfrom Dataset,1,cryptocurrenciestoken-and-coin-platrform-support,dataset.csv,Apache 2.0,"## **Context**

Dataset of cryptocurrency support smart contract A dataset of cryptocurrency support smart contracts is a valuable resource for developers and researchers in the field of blockchain technology. These datasets contain information about the various smart contracts that have been deployed on different blockchains, including their contract addresses, token Id, the data scientist inside me started raising questions like:

Which networks support which tokens?

So what next?
Now that we have smart contract of each token we can collect what network can support each token

This will help understand the other factors related to tokens 

## **Content**

The dataset has one csv file for each currency. There are almost more than **2200** tokens and coins collected in this dataset

**Id**: name of each token

**symbol**: Short name of each token

**platfroms**: which can include networks such as Ethereum, Binance, Cardano, fantom and...


## **Acknowledgements**
This data is taken from Coingecko and it is free to use the data.

Cover Image : Photo by Zoltan Tasi on Unsplash

## **Inspiration**
Some of the questions which could be inferred from this dataset are:

Which networks support which tokens?

Which network supports the most tokens?

Which token has smart contracts in most networks?",.csv
Cryptocurrency Prediction Artificial Intelligence,1,cryptocurrency-prediction-artificial-intelligence,12 (2) (Data).csv,GNU Affero General Public License 3.0,"# **Cryptocurrency-Prediction-with-Artificial-Intelligence**
First Version.. Cryptocurrency Prediction with Artificial Intelligence (Deep Learning via LSTM Neural Networks)- Emirhan BULUT
I developed Cryptocurrency Prediction (Deep Learning with LSTM Neural Networks) software with Artificial Intelligence. I predicted the fall on December 28, 2021 with 98.5% accuracy in the XRP/USDT pair. '0.009179626158151918' MAE Score, '0.0002120391943355104' MSE Score, 98.35% Accuracy Question software has been completed.

The XRP/USDT pair forecast for December 28, 2021 was correctly forecasted based on data from Binance.

Software codes and information are shared with you as open source code free of charge on GitHub and My Personal Web Address.

Happy learning!

Emirhan BULUT

Senior Artificial Intelligence Engineer & Inventor


###**The coding language used:**

`Python 3.9.8`

###**Libraries Used:**

`Tensorflow - Keras`

`NumPy`

`Matplotlib`

`Pandas`

`Scikit-learn - (SKLEARN)`

<img src=""https://raw.githubusercontent.com/emirhanai/Cryptocurrency-Prediction-with-Artificial-Intelligence/main/XRP-1%20-%20PREDICTION.png"" alt=""Cryptocurrency Prediction with Artificial Intelligence (Deep Learning via LSTM Neural Networks)- Emirhan BULUT"">
     
### **Developer Information:**

Name-Surname: **Emirhan BULUT**

Contact (Email) : **emirhan@isap.solutions**

LinkedIn : **[https://www.linkedin.com/in/artificialintelligencebulut/][LinkedinAccount]**

[LinkedinAccount]: https://www.linkedin.com/in/artificialintelligencebulut/

Kaggle: **[https://www.kaggle.com/emirhanai][Kaggle]**

Official Website: **[https://www.emirhanbulut.com.tr][OfficialWebSite]**

[Kaggle]: https://www.kaggle.com/emirhanai

[OfficialWebSite]: https://www.emirhanbulut.com.tr
",.csv
Crystal System Properties for Li-ion batteries,1,crystal-system-properties-for-liion-batteries,lithium-ion batteries.csv,CC0-1.0,"This dataset contains data about the physical and chemical properties of the Li-ion silicate cathodes. These properties can be useful to predict the class of a Li-ion battery. These batteries can be classified on the basis of their crystal system. Three major classes of crystal system include: monoclinic, orthorhombic and triclinic. Go play out with the dataset to predict the battery classes with any classification algorithm you want!",.csv
Currency Exchange Rates,1,currency-exchange-rates,exchange_rates.csv,CC0-1.0,"### Content
&gt; Foreign exchange rates for every currency (updated daily)

### Inspiration
&gt; Time series analysis of foreign exchange rates for different currencies",.csv
Curvo Fund Price Data,1,curvo-fund-data,funddata.csv,MIT,"Historical price data for roughly 900 funds available in the curvo.eu website. These historical prices include reconstructed prices, that is prices for dates before the index funds and their corresponding ETFs were available.",.csv
Customer Churn Rate,1,customer-churn-rate,Churn_Modelling.csv,other,"This dataset contains the details of the customers of a bank.
The customers details contains name, gender, salary, credit score.
The output column or feature is ""exited"" which is a binary column.",.csv
Customer Feedback Dataset,1,customer-feedback-dataset,sentiment-analysis.csv,other,"This dataset contains customer sentiments expressed in various sources such as social media, review platforms, testimonials, and more. The dataset includes text, sentiment (positive or negative), source of the sentiment, date/time of the sentiment, user ID, location, and confidence score. The sentiments reflect customers' opinions and experiences with products, services, movies, music, books, restaurants, websites, customer support, and more.
You can do below things on the dataset:
Data cleaning
Sentiment analysis
Statistical analysis
Data visualization
Text preprocessing
Topic modeling
Feature engineering
Machine learning modeling
Data integration
Data aggregation
NLP...",.csv
Customer Personality Analysis,1,customer-personality-analysis,marketing_campaign.csv,CC0-1.0,"### Context

**Problem Statement**

Customer Personality Analysis is a detailed analysis of a company’s ideal customers. It helps a business to better understand its customers and makes it easier for them to modify products according to the specific needs, behaviors and concerns of different types of customers. 

Customer personality analysis helps a business to modify its product based on its target customers from different types of customer segments. For example, instead of spending money to market a new product to every customer in the company’s database, a company can analyze which customer segment is most likely to buy the product and then market the product only on that particular segment.


### Content

**Attributes**

**People**

* ID: Customer's unique identifier
* Year_Birth: Customer's birth year
* Education: Customer's education level
* Marital_Status: Customer's marital status
* Income: Customer's yearly household income
* Kidhome: Number of children in customer's household
* Teenhome: Number of teenagers in customer's household
* Dt_Customer: Date of customer's enrollment with the company
* Recency: Number of days since customer's last purchase
* Complain: 1 if the customer complained in the last 2 years, 0 otherwise

**Products**

* MntWines: Amount spent on wine in last 2 years
* MntFruits: Amount spent on fruits in last 2 years
* MntMeatProducts: Amount spent on meat in last 2 years
* MntFishProducts: Amount spent on fish in last 2 years
* MntSweetProducts: Amount spent on sweets in last 2 years
* MntGoldProds: Amount spent on gold in last 2 years

**Promotion**

* NumDealsPurchases: Number of purchases made with a discount
* AcceptedCmp1: 1 if customer accepted the offer in the 1st campaign, 0 otherwise
* AcceptedCmp2: 1 if customer accepted the offer in the 2nd campaign, 0 otherwise
* AcceptedCmp3: 1 if customer accepted the offer in the 3rd campaign, 0 otherwise
* AcceptedCmp4: 1 if customer accepted the offer in the 4th campaign, 0 otherwise
* AcceptedCmp5: 1 if customer accepted the offer in the 5th campaign, 0 otherwise
* Response: 1 if customer accepted the offer in the last campaign, 0 otherwise

**Place**

* NumWebPurchases: Number of purchases made through the company’s website
* NumCatalogPurchases: Number of purchases made using a catalogue
* NumStorePurchases: Number of purchases made directly in stores
* NumWebVisitsMonth: Number of visits to company’s website in the last month

### Target

Need to perform clustering to summarize customer segments.

### Acknowledgement

The dataset for this project is provided by Dr. Omar Romero-Hernandez. 

### Solution 

You can take help from following link to know more about the approach to solve this problem.
[Visit this URL  ](https://thecleverprogrammer.com/2021/02/08/customer-personality-analysis-with-python/)


### Inspiration

happy learning....

**Hope you like this dataset please don't forget to like this dataset**",.csv
Customer Purchase Data,1,customer-purchase-data,shopping_data.csv,Apache 2.0,"Welcome to the Online shopping Customer Purchase Behaviour Dataset Analysis! This dataset offers a comprehensive set of consumer transaction records from a wide variety of products offered by an online retail platform. You will be able to work with real-world data as an educator, serving students from different backgrounds and skill levels",.csv
Customer Purchases Behaviour Dataset,1,customer-purchases-behaviour-dataset,customer_data.csv,Apache 2.0,"# Subtitle:
Simulated Dataset of Customer Purchase Behavior

# Description:
This dataset contains simulated data representing customer purchase behavior. It includes various features such as age, gender, income, education, region, loyalty status, purchase frequency, purchase amount, product category, promotion usage, and satisfaction score.

# File Information:
- File Format: CSV
- Number of Rows: 100000
- Number of Columns: 12

# Column Descriptors:
- `age`: Age of the customer.
- `gender`: Gender of the customer (0 for Male, 1 for Female).
- `income`: Annual income of the customer.
- `education`: Education level of the customer.
- `region`: Region where the customer resides.
- `loyalty_status`: Loyalty status of the customer.
- `purchase_frequency`: Frequency of purchases made by the customer.
- `purchase_amount`: Amount spent by the customer in each purchase.
- `product_category`: Category of the purchased product.
- `promotion_usage`: Indicates whether the customer used promotional offers (0 for No, 1 for Yes).
- `satisfaction_score`: Satisfaction score of the customer.

# Provenance:
The dataset was simulated using the simstudy package in R. Various distributions and formulas were used to generate synthetic data representing customer purchase behavior. The data is organized to mimic real-world scenarios, but it does not represent actual customer data.",.csv
Customer Segementation & Personas,1,customer-segementation-and-personas,Jewellery Customer Segmentation Analysis Personas.csv,MIT,"
This dataset provides jewellery sales data, including customer purchases, to facilitate RFM analysis and calculate Customer Lifetime Value (CLTV). It's structured for easy use in Excel, Python, R, Tableau, PowerBI and SPSS, making it ideal for those looking to segment customers based on purchase recency, frequency, and monetary value. With this data, you can gain insights into customer behaviour, identify valuable segments, and tailor marketing strategies to enhance customer engagement and retention. Simple and straightforward, it’s perfect for businesses looking to leverage their sales data for smarter marketing decisions.
Audiences: Marketers, Data Engineers or Data Scientist who are interested in Marketing ",.csv
Customer Segmentation & Clustering (Python),1,customer-segmentation-and-clustering-python,Mall_Customers.csv,CC0-1.0,"**Mall Shoppers Customer Segmentation Dataset**

**Overview:**

The Mall Shoppers Customer Segmentation Dataset is a rich collection of data designed to provide insights into the shopping behaviors and demographic profiles of customers visiting a mall. This dataset is pivotal for businesses aiming to tailor their marketing strategies, improve customer engagement, and enhance the shopping experience through targeted offers and services.

**Content:**

The dataset includes information on several hundred mall visitors, encompassing a variety of features such as:

- **Customer ID**: A unique identifier for each customer.
- **Age**: The age of the customer.
- **Gender**: The gender of the customer.
- **Annual Income (k$)**: The annual income of the customer, expressed in thousands of dollars.
- **Spending Score (1-100)**: A score assigned to the customer based on their spending behavior and purchasing data. A higher score indicates higher spending.

**Purpose:**

The primary purpose of this dataset is to enable the identification of distinct customer segments within the mall's clientele. By analyzing patterns in age, income, spending score, and gender, businesses can uncover valuable insights into customer preferences and behaviors. This, in turn, allows for the development of targeted marketing strategies, personalized shopping experiences, and improved product offerings to meet the diverse needs of each customer segment.

**Applications:**

This dataset is an excellent resource for:
- **Customer Segmentation**: Utilizing clustering techniques to categorize customers into meaningful groups based on their features.
- **Targeted Marketing**: Crafting personalized marketing campaigns aimed at specific customer segments to increase engagement and sales.
- **Market Analysis**: Understanding the demographic makeup and spending habits of mall visitors to inform business decisions and strategies.
- **Personalization**: Enhancing the customer experience through personalized services, recommendations, and offers.

**Conclusion:**

The Mall Shoppers Customer Segmentation Dataset offers a foundational step towards a deeper understanding of customer dynamics in a retail environment. It serves as a valuable asset for retailers, marketers, and business analysts seeking to leverage data-driven insights for strategic advantage.
",.csv
Customer Segmentation : Clustering,1,customer-segmentation-clustering,customer_segmentation.csv,Apache 2.0,"Customer Personality Analysis involves a thorough examination of a company's optimal customer profiles. This analysis facilitates a deeper understanding of customers, enabling businesses to tailor products to meet the distinct needs, behaviors, and concerns of various customer types.

By conducting a Customer Personality Analysis, businesses can refine their products based on the preferences of specific customer segments. Rather than allocating resources to market a new product to the entire customer database, companies can identify the segments most likely to be interested in the product. Subsequently, targeted marketing efforts can be directed toward those particular segments, optimizing resource utilization and increasing the likelihood of successful product adoption.

Details of Features are as below:

* **Id:** Unique identifier for each individual in the dataset.
* **Year_Birth:** The birth year of the individual.
* **Education:** The highest level of education attained by the individual.
* **Marital_Status:** The marital status of the individual.
* **Income:** The annual income of the individual.
* **Kidhome:** The number of young children in the household.
* **Teenhome:** The number of teenagers in the household.
* **Dt_Customer:** The date when the customer was first enrolled or became a part of the company's database.
* **Recency:** The number of days since the last purchase or interaction.
* **MntWines:** The amount spent on wines.
* **MntFruits:** The amount spent on fruits.
* **MntMeatProducts:** The amount spent on meat products.
* **MntFishProducts:** The amount spent on fish products.
* **MntSweetProducts:** The amount spent on sweet products.
* **MntGoldProds:** The amount spent on gold products.
* **NumDealsPurchases:** The number of purchases made with a discount or as part of a deal.
* **NumWebPurchases:** The number of purchases made through the company's website.
* **NumCatalogPurchases:** The number of purchases made through catalogs.
* **NumStorePurchases:** The number of purchases made in physical stores.
* **NumWebVisitsMonth:** The number of visits to the company's website in a month.
* **AcceptedCmp3:** Binary indicator (1 or 0) whether the individual accepted the third marketing campaign.
* **AcceptedCmp4:** Binary indicator (1 or 0) whether the individual accepted the fourth marketing campaign.
* **AcceptedCmp5:** Binary indicator (1 or 0) whether the individual accepted the fifth marketing campaign.
* **AcceptedCmp1:** Binary indicator (1 or 0) whether the individual accepted the first marketing campaign.
* **AcceptedCmp2:** Binary indicator (1 or 0) whether the individual accepted the second marketing campaign.
* **Complain:** Binary indicator (1 or 0) whether the individual has made a complaint.
* **Z_CostContact:** A constant cost associated with contacting a customer.
* **Z_Revenue:** A constant revenue associated with a successful campaign response.
* **Response:** Binary indicator (1 or 0) whether the individual responded to the marketing campaign.",.csv
Customer Segmentation Data,1,customer-segmentation-data,customer_segmentation_data.csv,CC0-1.0,"This dataset provides comprehensive customer data suitable for segmentation analysis. It includes anonymized demographic, transactional, and behavioral attributes, allowing for detailed exploration of customer segments. Leveraging this dataset, marketers, data scientists, and business analysts can uncover valuable insights to optimize targeted marketing strategies and enhance customer engagement. Whether you're looking to understand customer behavior or improve campaign effectiveness, this dataset offers a rich resource for actionable insights and informed decision-making.

## Key Features:

Anonymized demographic, transactional, and behavioral data.
Suitable for customer segmentation analysis.
Opportunities to optimize targeted marketing strategies.
Valuable insights for improving campaign effectiveness.
Ideal for marketers, data scientists, and business analysts.

## Usage Examples:

Segmenting customers based on demographic attributes.
Analyzing purchase behavior to identify high-value customer segments.
Optimizing marketing campaigns for targeted engagement.
Understanding customer preferences and tailoring product offerings accordingly.
Evaluating the effectiveness of marketing strategies and iterating for improvement.
Explore this dataset to unlock actionable insights and drive success in your marketing initiatives!",.csv
Customer Shopping Dataset - Retail Sales Data,1,customer-shopping-dataset,customer_shopping_data.csv,CC0-1.0,"## Context

Welcome to the shopping world of Istanbul! Our dataset contains shopping information from 10 different shopping malls between 2021 and 2023. We have gathered data from various age groups and genders to provide a comprehensive view of shopping habits in Istanbul. The dataset includes essential information such as invoice numbers, customer IDs, age, gender, payment methods, product categories, quantity, price, order dates, and shopping mall locations. We hope that this dataset will serve as a valuable resource for researchers, data analysts, and machine learning enthusiasts who want to gain insights into shopping trends and patterns in Istanbul. Explore the dataset and discover the fascinating world of Istanbul shopping!

## Content

Attribute Information:

- **invoice_no:** Invoice number. Nominal. A combination of the letter 'I' and a 6-digit integer uniquely assigned to each operation.
- **customer_id:** Customer number. Nominal. A combination of the letter 'C' and a 6-digit integer uniquely assigned to each operation.
- **gender:** String variable of the customer's gender.
- **age:** Positive Integer variable of the customers age.
- **category:** String variable of the category of the purchased product.
- **quantity:** The quantities of each product (item) per transaction. Numeric.
- **price:** Unit price. Numeric. Product price per unit in Turkish Liras (TL).
- **payment_method:** String variable of the payment method (cash, credit card or debit card) used for the transaction.
- **invoice_date:** Invoice date. The day when a transaction was generated.
- **shopping_mall:** String variable of the name of the shopping mall where the transaction was made.

",.csv
Customer Support Ticket Dataset,1,customer-support-ticket-dataset,customer_support_tickets.csv,CC0-1.0,"The Customer Support Ticket Dataset is a dataset that includes customer support tickets for various tech products. It consists of customer inquiries related to hardware issues, software bugs, network problems, account access, data loss, and other support topics. The dataset provides information about the customer, the product purchased, the ticket type, the ticket channel, the ticket status, and other relevant details. 

The dataset can be used for various analysis and modelling tasks in the customer service domain.

#### Features Description:
   - Ticket ID: A unique identifier for each ticket.
   - Customer Name: The name of the customer who raised the ticket.
   - Customer Email: The email address of the customer (Domain name - @example.com is intentional for user data privacy concern).
   - Customer Age: The age of the customer.
   - Customer Gender: The gender of the customer.
   - Product Purchased: The tech product purchased by the customer.
   - Date of Purchase: The date when the product was purchased.
   - Ticket Type: The type of ticket (e.g., technical issue, billing inquiry, product inquiry).
   - Ticket Subject: The subject/topic of the ticket.
   - Ticket Description: The description of the customer's issue or inquiry.
   - Ticket Status: The status of the ticket (e.g., open, closed, pending customer response).
   - Resolution: The resolution or solution provided for closed tickets.
   - Ticket Priority: The priority level assigned to the ticket (e.g., low, medium, high, critical).
   - Ticket Channel: The channel through which the ticket was raised (e.g., email, phone, chat, social media).
   - First Response Time: The time taken to provide the first response to the customer.
   - Time to Resolution: The time taken to resolve the ticket.
   - Customer Satisfaction Rating: The customer's satisfaction rating for closed tickets (on a scale of 1 to 5).

#### Use Cases of such dataset:
   - Customer Support Analysis: The dataset can be used to analyze customer support ticket trends, identify common issues, and improve support processes.
   - Natural Language Processing (NLP): The ticket descriptions can be used for training NLP models to automate ticket categorization or sentiment analysis.
   - Customer Satisfaction Prediction: The dataset can be used to train models to predict customer satisfaction based on ticket information.
   - Ticket Resolution Time Prediction: The dataset can be used to build models for predicting the time it takes to resolve a ticket based on various factors.
   - Customer Segmentation: The dataset can be used to segment customers based on their ticket types, issues, or satisfaction levels.
   - Recommender Systems: The dataset can be used to build recommendation systems for suggesting relevant solutions or products based on customer inquiries.",.csv
Customer Transactions,1,customer-transactions,sample_dataset.csv,Community Data License Agreement - Sharing - Version 1.0,"Synthetic Dataset of Customer Transactions with Demographic and Shopping Behavior Information

###### Features

- **Customer ID:**The unique identifier for each customer.
- **Name:** The customer's name.
- **Surname:** The customer's last name.
- **Gender:**The gender of the customer.
- **Birthdate:** The customer's date of birth.
- **Transaction Amount:**The amount of the transaction. ($)
- **Date:** The date of the transaction.
- **Merchant Name:**The name of the merchant where the transaction was made.
- **Category:** The category of the transaction.",.csv
Customer's data including income,1,customers-data-taken-in-a-survey,Customers_Data.csv,other,"This dataset taken in a survey. It contains the details of the people with their names, income, email id, birth date, marital status, gender, total number of children he has, education level, occupation and is he the home owner or not.",.csv
Customer_Spending_Dataset,1,customer-spending-dataset,customer_data.csv,CC0-1.0,"📊 Welcome to the Customer Dataset! 🤝👥

This dataset provides valuable insights into customer demographics, income, spending habits, and purchase behavior. 🎯💰 It's designed to support your analysis, prediction, and customer segmentation tasks. 📈🔍

Let's dive in and uncover the patterns that drive customer behavior! 🕵️‍♂️💡💼

Feel free to explore, experiment, and apply various data analysis techniques to unlock meaningful insights. 🧐💡✨

Happy exploring! 🚀🔬🔍",.csv
Customer_Transactions_2023_24,1,customer-transactions-2023-24,Customer_Transactions.csv,other,"This dataset contains transaction records from a retail business, including fields such as transaction date, customer name, card number, zip code, and transaction amount. The data spans the year 2023-24 and has been generated using the Faker library in Python to simulate realistic transaction data. The dataset is intended for use in analyzing customer spending patterns, fraud detection, and other retail analytics applications.",.csv
Customers Purchase Behavior Dataset,1,purchase-behavior-dataset,purchase behaviou dataset.csv,ODC Public Domain Dedication and Licence (PDDL),"Customers Purchase Behavior Dataset is a collection of data that tracks customer purchase behavior. The dataset includes information about customers, products, promotions, and the place where the purchases were made through. This data can be used to understand customer buying habits, identify trends, and develop marketing campaigns.

The dataset contains information about 400 customers, including their unique ID, gender, age, salary, and whether they decided to buy specific products or not. The dataset also includes information about 100 products, including their name, category, price, and whether they were promoted. Finally, the dataset includes information about 50 promotions, including their name, type, and start and end dates.",.csv
Cyber Crime Statewise (INDIA),1,cyber-crime-statewise,cyber_crimes.csv,CC0-1.0,"### Context

This dataset contains information about state-wise cybercrime in India and can be used to predict future crime rates. Some interesting insights can be generated by predicting the crimes in 2020 and how pandemic has effected the increasing cybercrimes.

### Inspiration
 This dataset has been inspired by the recent increase in cyber crimes during a pandemic lockdown",.csv
Cyber Security Indexes,1,cyber-security-indexes,Cyber_security.csv,other,"The Dataset ""Cyber Security Indexes"" includes four indicators which illustrate the current cyber security situation around the world. The data is provided on 193 countries and territories, grouped by five geographical regions - Africa, North America,  South America, Europe and Asia-Pasific. 


*The Cybersecurity Exposure Index* **(CEI)** defines the level of exposure to cybercrime by country from 0 to 1; the higher the score, the higher the exposure (provided by [10guard](https://10guards.com/en/articles/global-cybersecurity-exposure-index-2020/)). The indicator was last updated in 2020.

*The Global Cyber Security Index* **(GCI)** is a trusted reference that measures the commitment of countries to cybersecurity at a global level – to raise awareness of the importance and different dimensions of the issue (provided by the International Telecommunication Union - [ITU](https://composite-indicators.jrc.ec.europa.eu/explorer/explorer/indices/GCI/global-cyber-security-index)). The indicator was last updated in 2021.

*The National Cyber Security Index* **(NCSI)** measures a country's readiness to address cyber threats and manage cyber incidents. It is composed of categories, capacities, and indicators (provided by [NCSI](https://ncsi.ega.ee/ncsi-index/)). The indicator was last updated in January 2023.

*The Digital Development Level* **(DDL)** defines the average percentage the country received from the maximum value of both indices (provided by [NCSI](https://ncsi.ega.ee/ncsi-index/)). The indicator was last updated in January 2023.

The dataset can be used for practising data cleaning, data visualization (on maps and round/bar charts), finding correlations between the indexes and predicting the missing data.

The data was used in the analytical article research [*The Geography of Cybersecurity: Cyber Threats and Vulnerabilities*](https://intersog.com/blog/geography-of-cyber-security/)",.csv
Cyber Security Salaries 💲 ,1,cyber-security-salaries,salaries_cyber.csv,CC0-1.0,"# Content

The dataset contains the following columns:
|Column Header| Dtype |
| --- | --- |
|work_year| int |
|experience_level| string |
|employment_type| string |
|job_title| string |
|salary| int |
|salary_currency| int |
|salary_in_usd| int |
|employee_residence| string |
|remote_ratio| int |
|company_location| string |
|company_size| string |

# Data Source / Acknowledgement

The survey to collect the salaries was hosted and organized by salaries.infosec-jobs.com 
",.csv
Cyberbullying Classification,1,cyberbullying-classification,cyberbullying_tweets.csv,Attribution 4.0 International (CC BY 4.0),"# Abstract
&gt; With rise of social media coupled with the Covid-19 pandemic, cyberbullying has reached all time highs. We can combat this by creating models to automatically flag potentially harmful tweets as well as break down the patterns of hatred.

# About this dataset
&gt; As social media usage becomes increasingly prevalent in every age group, a vast majority of citizens rely on this essential medium for day-to-day communication. Social media’s ubiquity means that cyberbullying can effectively impact anyone at any time or anywhere, and the relative anonymity
of the internet makes such personal attacks more difficult to stop than traditional bullying.

&gt; On April 15th, 2020, UNICEF issued a warning in response to the increased risk of cyberbullying during the COVID-19 pandemic due to widespread school closures, increased screen time, and decreased face-to-face social interaction. The statistics of cyberbullying are outright alarming: 36.5% of middle and high school students have felt cyberbullied and 87% have observed cyberbullying, with effects ranging from decreased academic performance to depression to suicidal thoughts.

&gt; In light of all of this, this dataset contains more than **47000** tweets labelled according to the class of cyberbullying:
- Age;
- Ethnicity;
- Gender;
- Religion;
- Other type of cyberbullying;
- Not cyberbullying

&gt; The data has been balanced in order to contain ~8000 of each class.

&gt; **Trigger Warning** These tweets either describe a bullying event or are the offense themselves, therefore explore it to the point where you feel comfortable.



# How to use this dataset
&gt; - Create a multiclassification model to predict cyberbullying type;
- Create a binary classification model to flag potentially harmful tweets;
- Explore words and patterns associated with each type of cyberbullying.


# Highlighted Notebooks
&gt; - [Cyberbullying on Twitter Visualization 🤬](https://www.kaggle.com/lizakonopelko/cyberbullying-on-twitter-visualization) by [Liza Konopelko](https://www.kaggle.com/lizakonopelko)
- Your kernel can be featured here!
- [More datasets](https://www.kaggle.com/andrewmvd/datasets)



# Acknowledgements
If you use this dataset in your research, please credit the authors.
&gt; ### Citation
&gt; J. Wang, K. Fu, C.T. Lu, “[SOSNet: A Graph Convolutional Network Approach to Fine-Grained Cyberbullying Detection](https://ieeexplore.ieee.org/document/9378065),” Proceedings of the 2020 IEEE International Conference on Big Data (IEEE BigData 2020), December 10-13, 2020.

&gt; ### License
CC BY 4.0


&gt; ### Splash banner
Icons by [Freepik](https://www.flaticon.com/authors/freepik) and [Juicy Fish](https://www.flaticon.com/authors/juicy-fish).",.csv
Cybersecurity: Suspicious Web Threat Interactions,1,cybersecurity-suspicious-web-threat-interactions,CloudWatch_Traffic_Web_Attack.csv,GPL-3.0,"This dataset contains web traffic records collected through **AWS CloudWatch**, aimed at detecting suspicious activities and potential attack attempts. 

The data were generated by monitoring traffic to a production web server, using various detection rules to identify anomalous patterns.

## Context
In today's cloud environments, cybersecurity is more crucial than ever. The ability to detect and respond to threats in real time can protect organizations from significant consequences. This dataset provides a view of web traffic that has been labeled as suspicious, offering a valuable resource for developers, data scientists, and security experts to enhance threat detection techniques.

##Dataset Content
Each entry in the dataset represents a stream of traffic to a web server, including the following columns:

`bytes_in`: Bytes received by the server.

`bytes_ou`t: Bytes sent from the server.

`creation_time`: Timestamp of when the record was created.

`end_time`: Timestamp of when the connection ended.

`src_ip`: Source IP address.

`src_ip_country_code`: Country code of the source IP.

`protocol`: Protocol used in the connection.

`response.code`: HTTP response code.

`dst_port`: Destination port on the server.

`dst_ip`: Destination IP address.

`rule_names`: Name of the rule that identified the traffic as suspicious.

`observation_name`: Observations associated with the traffic.

`source.meta`: Metadata related to the source.

`source.name`: Name of the traffic source.

`time`: Timestamp of the detected event.

`detection_types`: Type of detection applied.


##Potential Uses

This dataset is ideal for:

- **Anomaly Detection**: Developing models to detect unusual behaviors in web traffic.
- **Classification Models**: Training models to automatically classify traffic as normal or suspicious.
- **Security Analysis**: Conducting security analyses to understand the tactics, techniques, and procedures of attackers.",.csv
DAIGT | External Dataset,1,daigt-external-dataset,daigt_external_dataset.csv,MIT,"**Important Note:** the `text` column is NOT AI generated. However, the `source_text` is, which can still be used as AI generated text. I will update the dataset accordingly. Consequently, this dataset provides 2421 student generated texts (`text` column) and 2421 AI generated texts (`source_text` column). I will update as soon as possible.

In the [LLM- Detect AI Generated Text](https://www.kaggle.com/competitions/llm-detect-ai-generated-text) competition you are required to distinguish between student-made and AI-generated texts. However, the competition's data only provides student-made texts. 

Luckily, for CommonLit's competition I made a dataset with AI generated texts to use for that competition. Surprisingly, it's very much alike the data we need for in this competition!

My dataset not only has **2421 Chat GPT generated texts** but also their prompts and source texts! That's **double** the data we are given in this competition!

Also, it's **very diverse** since the texts are generated from unique prompts.

The best of luck to all of you in this competition! 🍀

### Dataset Description

- `id`: unique identifier for each text.
- `text`: extracted text from FeedBack Prize 3 competition. Can be used as student text.
- `instructions`: the instruction for ChatGPT to generate the text.
- `source_text`: AI generated text.",.csv
DC and MCU,1,dc-and-mcu,Movies.csv,Apache 2.0,"This dataset is a collection of all Marvel and DC movies up to Feb 2024 in order which contains several columns related to the movies like Director, Stars, IMDB rating etc

Please upvote if you download and use the dataset. Thanks",.csv
DMart Products,1,dmart-products,DMart.csv,CC0-1.0,"The dataset contains the products listed on the website of online grocery store Big Basket.

Avenue Supermarts Limited, d/b/a DMart, is an Indian retail corporation that operates a chain of hypermarkets in India. It was founded by Radhakishan Damani in 2002, with its first branch in Powai's Hiranandani Gardens.",.csv
DURING WAR: Factors Affecting Individual Survival,1,during-war-factors-affecting-individual-survival,war_survival_data.csv,MIT,"## Introduction:
The War Survival Dataset presents simulated data reflecting various factors influencing individual survival during times of conflict. This dataset was generated using Python's NumPy and Pandas libraries to simulate conditions for 1000 individuals across multiple categories crucial for sustaining life and well-being in war-torn environments.

##  Related Information

**Individual Information:**
**Name:** Randomly generated names for each individual.
**Age:** Randomly assigned ages between 18 and 60 years old.

**Basic Needs:**
**Food Supply (Days):** Number of days of food supply available for each individual.
**Water per Day (Liters):** Daily water consumption per person in liters.

**Health and Medical Supplies:**
**First Aid Kits:** Availability of first aid kits per individual.
**Antibiotics:** Quantity of antibiotics accessible to each person.
**Painkillers:** Quantity of painkillers accessible to each person.

**Security and Defense:**
**Weapons Available:** Number of weapons available to each individual.
**Defensive Structures:** Presence of defensive structures (e.g., bunkers, barricades) near each person.
**Training Level:** Level of combat training on a scale of 0 to 5.

**Communication and Information:**
**Radios Available:** Number of communication devices (e.g., radios, walkie-talkies) accessible to each individual.
**Access to Reliable Information:** Availability of reliable information sources, denoted as ""Yes"" or ""No"".

**Psychological Well-being:**
**Support Groups Available:** Availability of support groups or counseling services for each individual, denoted as ""Yes"" or ""No"".
**Entertainment Available:** Access to distractions or entertainment (e.g., books, games) for psychological well-being.

## Conclusion:
**NOTE:** This dataset provides valuable insights into the readiness and resilience of individuals during wartime scenarios, serving as a foundation for research and analysis aimed at improving strategies for survival and humanitarian assistance in conflict zones.",.csv
Daily Data of Reservoir Level of Indian Rivers,1,daily-data-of-reservoir-level-of-indian-rivers,Daily_data_of_reservoir_level_of_Central_Water_Commission_(CWC)_Agency_during_March_2024.csv,Community Data License Agreement - Permissive - Version 1.0,"Explore the dynamic landscapes of water management with CWC comprehensive dataset on reservoir levels. From fluctuating water levels to storage capacities, this data provides an unparalleled view of reservoir operations across diverse regions. Delve into trends, identify anomalies, and forecast future scenarios through meticulous analysis. Understand how environmental factors and human interventions shape water resources. Use our dataset to fuel research, inform policy decisions, and drive sustainability initiatives. Uncover the hidden patterns of water usage and conservation in this critical exploration of hydro data.

## column description :


**Reservoir_name**: This column lists the names of the reservoirs included in the dataset.

**Basin**: This column specifies the river basin in which each reservoir is located. River basins are geographical areas determined by the watershed of a river and its tributaries.

**Subbasin**: A more specific categorization within a river basin, detailing a smaller section or a particular tributary area that contributes water to the reservoir.

**Agency_name**: The agency responsible for managing the reservoir. In this case, it appears to be the Central Water Commission (CWC).

**Lat (Latitude)**: The latitude coordinate of the reservoir, indicating its north-south position on the Earth's surface.
Long (Longitude): The longitude coordinate of the reservoir, indicating its east-west position.

**Date**: The specific date on which the data was recorded.

**Year**: The year in which the data was recorded, here it is consistently 2024.

**Month**: The month during which the data was collected, indicated here as March (month 3).

**Full_reservoir_level (FRL)**: This is the maximum water level that the reservoir can safely reach.

**Live_capacity_FRL**: The volume of water (in millions of cubic meters) that the reservoir can hold when filled to the full reservoir level.

**Storage**: The actual volume of water stored in the reservoir on the recorded date, measured in million cubic meters.

Level: The actual water level in the reservoir on the recorded date, usually measured in meters above sea level.",.csv
Daily Exchange Rates per Euro 1999-,1,euro-exchange-daily-rates-19992020,euro-daily-hist_1999_2022.csv,DbCL-1.0,"### 22+ years of the euro € 💶           
 &gt; 04 Jan 1999 - 11 Apr 2024

It wasn't until 1999 that the euro really began its journey, when 11 countries (Austria, Belgium, Finland, France, Germany, Ireland, Italy, Luxembourg, the Netherlands, Portugal and Spain) fixed their exchange rates and created a new currency with monetary policy passed to the European Central Bank. Today euro is 20+ years old.

### Content

Reference rates are euro foreign exchange rates observed on major foreign exchange trading venues at a certain point in time = they are the price of one currency in terms of another currency. The rates are usually updated around 16:00 CET on every working day, except on [TARGET closing days](https://www.ecb.europa.eu/home/contacts/working-hours/html/index.en.html).   

Dataset contains date and Euro rate corresponding to *Australian dollar, Bulgarian lev, Brazilian real, Canadian dollar, Swiss franc, Chinese yuan renminbi, Cypriot pound, Czech koruna, Danish krone, Estonian kroon, UK pound sterling, Greek drachma, Hong Kong dollar, Croatian kuna, Hungarian forint, Indonesian rupiah, Israeli shekel, Indian rupee, Iceland krona, Japanese yen, Korean won, Lithuanian litas, Latvian lats, Maltese lira, Mexican peso, Malaysian ringgit, Norwegian krone, New Zealand dollar, Philippine peso, Polish zloty, Romanian leu, Russian rouble, Swedish krona, Singapore dollar, Slovenian tolar, Slovak koruna, Thai baht, Turkish lira, US dollar, South African rand*.

- Some currency in the list doesn't exist anymore; it was replaced by the Euro €: Cypriot pound (2007), Estonian kroon (2011), Greek drachma (2002), Lithuanian litas (2015), Latvian lats (2014), Maltese lira (2008), Slovenian tolar (2007), Slovak koruna (2009).   
- Bulgarian lev since 2002 is pegged to the Euro: 1 € = 1.9558 leva.

### Acknowledgements

All data provided by European Central Bank [Statistical Data WareHouse, EXR - Exchange Rates](http://sdw.ecb.europa.eu/browseExplanation.do?node=1495).  
Dataset is versioned and stays on update.",.csv
Daily Gold Price (2015-2021) Time Series,1,daily-gold-price-20152021-time-series,Gold Price.csv,other,"### Content

Daily gold prices (2014-01-01 to 2022-08-05)


### Acknowledgements

Raw Data Source: https://in.investing.com/commodities/gold-mini
This data frame is preprocessed to time series analysis and forecasting

### Inspiration

Forecast, Predict Prices, Time Series Forecasting

### Note
Gold Prices in this dataset makes no guarantee or warranty on the accuracy or completeness of the data provided.",.csv
Daily Horoscope Dataset,1,daily-horoscope-dataset,Daily_Horoscope.csv,CC0-1.0,"# Dataset Information:
&gt;- This dataset is created for NLP enthusiasts to test their learnings and implement text analysis. It has 14 features with Date columns, source information and date-wise 12 zodiac sign predictions. Dataset is refreshed daily starting from 1st Jan,2024.  


#  Image Credit: 
&gt;Photo by <a href=""https://unsplash.com/@jakubpabis?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Jakub Pabis</a> on <a href=""https://unsplash.com/photos/a-building-that-has-a-bunch-of-drawings-on-it-m4-7DngV2Yo?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  
  ",.csv
Daily Statistics of the 2022 Iran Protests,1,daily-statistics-of-the-2022-iran-protests,Iran Protests Dataset (Ver 2.21.23).csv,CC-BY-NC-SA-4.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F12064410%2Fee3ed59182d37c0bc5fe26287a023607%2FBlue%20Zigzag%20Lines%20Store%20Header.png?generation=1672079658462253&alt=media)

# 158 DAYS (September 16, 2022 - February 21, 2023)
### UPDATE: HRANA appears to have stopped their daily update reports on February 22nd, 2023.
This is a dataset that describes daily estimates of statistics regarding the 2022 Iran protests.

All data are official estimates from the Human Rights Activists News Agency (HRANA) that have been compiled and structured by myself. However, there are many significant figures claimed by various media outlets that have not been taken into account by HRANA due to a lack of sufficient details, so the **ACTUAL NUMBERS** are **LIKELY TO BE HIGHER.**

# Data Sources
##### The primary data source used was the Human Rights Activists News Agency (HRANA), an organization that has covered the 2022 Iran protests extensively since its inception. HRANA has attempted to compile countless individual, group, media, and government reports to make rough statistical estimates, something no other public organization has done so far.

1. [HRANA's English Twitter Account](https://twitter.com/HRANA_English) - HRANA published daily updates in English since 10/16/22 on their Twitter, but several days' worth of data was skipped (primarily during early December 2022). 
2. [HRANA's Persian Instagram Account](https://www.instagram.com/hra.news/?hl=en) - HRANA published daily updates in Persian since 10/12/22 on their Instagram, and at a rate far more consistent than HRANA's English Twitter account. I used Google Translate's image scan to read the Persian graphics with the missing data I needed. 
3. [HRANA's ""A Comprehensive Report of the First 82 Days of Nationwide Protests in Iran""](https://www.en-hrana.org/wp-content/uploads/2022/12/82-Day-WLF-Protest-in-Iran-2022-English.pdf) - Since HRANA's daily statistical updates only began after 10/12/22, there was no data for the first 25 days of the Iran protests. To fill in the missing values, I referenced HRANA's comprehensive report on the first 82 days of the protests to manually tally missing figures using the dates provided. 
4. [HRANA's ""Woman, Life, Freedom; Comprehensive Report of 20 Days of Protest Across Iran""](https://www.en-hrana.org/wp-content/uploads/2022/10/Mahsa-Amini-20-Days-of-protests-Englisht.pdf) - HRANA's comprehensive report on the first 82 days of the protests tended to focus on the data as a whole. However, HRANA's report on the first 20 days were far more analytical and provided data visualizations that allowed me to properly deduce the rest of the missing values.

# Statistics Being Tracked
- Death Toll of Protestors
- Number of Children Killed
- Number of Military-Security Personnel Killed
- Number of Individuals Arrested
- Number of Detainees Identified
- Number of Students Arrested
- Number of Protests
- Number of Cities Involved
- Number of Universities Involved

# Dataset History
2022-12-25 - Dataset is created (101 days after protests began).

[GitHub Repository](https://github.com/justin-2028/Daily-Statistics-of-the-2022-Iran-Protests) - The same data but on GitHub.

# Code Starter
[Daily Data and Plot Example](https://www.kaggle.com/code/justin2028/daily-statistics-of-2022-iran-protests)
Important: Each new record is accumulated data from previous days.

# Acknowledgements
I took much inspiration with the formatting of my Kaggle dataset from Petro Ivaniuk's dataset about the [2022 Russia Ukraine War](https://www.kaggle.com/datasets/piterfm/2022-ukraine-russian-war), kudos to him!",.csv
Daily Transactions Dataset ,1,daily-transactions-dataset,Daily Household Transactions.csv,other,"The ""Daily Transactions"" dataset contains information on dummy transactions made by an individual on a daily basis. The dataset includes data on the products that were purchased, the amount spent on each product, the date and time of each transaction, the payment mode of each transaction,  and the source of each record (Expense/Income). 

This dataset can be used to analyze purchasing behavior and money management, forecasting expenses, and optimizing savings and budgeting strategies. The dataset is well-suited for data analysis and machine learning applications,it can be used to train predictive models and make data-driven decisions.

# ```Column Descriptors```

- **Date:** The date and time when the transaction was made
- **Mode:** The payment mode used for the transaction  
- **Category:** Each record is divided into a set of categories of transactions
- **Subcategory:** Categories are further broken down into Subcategories of transactions
- **Note:** A brief description of the transaction made
- **Amount:** The transactional amount
- **Income/Expense:** The indicator of each transaction representing either expense or income
- **Currency:** All transactions are recorded in official currency of India 
",.csv
Daily Updated Exchange Rates(2015-now),1,daily-updated-exchange-rates2015-now,exchanges.csv,CC0-1.0,"Explore a rich collection of daily records capturing the top 56 global currencies from 2015 to the present day. This meticulously maintained dataset provides valuable insights into currency trends, exchange rates, and market dynamics. Analyze and research comprehensive data for in-depth currency analysis, enabling you to make informed decisions in a rapidly evolving global financial landscape.

Note: Currencies are based on ""EUR""",.csv
"Daily total female births in California, 1959",1,daily-total-female-births-in-california-1959,daily-total-female-births-CA.csv,other,"### Context
A time series dataset depicting the total number of female births recording in California, USA during the year of 1959.


### Content
This is a very basic time series dataset, with only the date (""dd/mm/yyyy"" format), and the number of births. There are 365 records in total.


### Acknowledgements
The dataset was taken from https://datamarket.com, and originally published by Newton in 1988.

Dataset title:	Daily total female births in California, 1959
Last updated:	1 Feb 2014, 19:52
Last updated: by source	21 Jun 2012
Provider:	Time Series Data Library
Provider source:	Newton (1988)
Source URL:	http://datamarket.com/data/list/?q=provider:tsdl
Units:	Births
Dataset metrics: 365 fact values in 1 timeseries.
Time granularity:	Date
Time range:	1 Jan 1959 – 31 Dec 1959
Language:	English
License:	Default open license
Description: Demography, Source: Newton (1988), in file: data/calfem, Description: Daily total female births in California, 1959

###Default open license
####Licence summary
You may copy and redistribute the data. You may make derivative works from the data. You may use the data for commercial purposes. You may not sublicence the data when redistributing it. You may not redistribute the data under a different license. Source attribution on any use of this data: Must refer source.

####Licence
You are allowed to copy and redistribute the data as long as you clearly indicate the data provider and DataMarket as the original source.",.csv
Daily-Delhi-Climate,1,daily-delhi-climate,DailyDelhiClimate.csv,CC0-1.0,"This dataset presents daily meteorological observations collected from the official government website of the Delhi region. The data includes measurements of mean temperature, humidity, wind speed, and mean pressure recorded over a period of time. The inspiration behind compiling this dataset lies in the necessity for researchers, environmentalists, and policymakers to access accurate and up-to-date climate information for the Delhi area. By providing this dataset sourced directly from governmental sources, it aims to support various stakeholders in conducting climate research, analyzing weather patterns, and making informed decisions related to environmental policies and practices.",.csv
Dairy Goods Sales Dataset,1,dairy-goods-sales-dataset,dairy_dataset.csv,CC0-1.0,"The Dairy Goods Sales Dataset provides a detailed and comprehensive collection of data related to dairy farms, dairy products, sales, and inventory management. This dataset encompasses a wide range of information, including farm location, land area, cow population, farm size, production dates, product details, brand information, quantities, pricing, shelf life, storage conditions, expiration dates, sales information, customer locations, sales channels, stock quantities, stock thresholds, and reorder quantities.

#### Features:

1. Location: The geographical location of the dairy farm.
2. Total Land Area (acres): The total land area occupied by the dairy farm.
3. Number of Cows: The number of cows present in the dairy farm.
4. Farm Size: The size of the dairy farm(in sq.km).
5. Date: The date of data recording.
6. Product ID: The unique identifier for each dairy product.
7. Product Name: The name of the dairy product.
8. Brand: The brand associated with the dairy product.
9. Quantity (liters/kg): The quantity of the dairy product available.
10. Price per Unit: The price per unit of the dairy product.
11. Total Value: The total value of the available quantity of the dairy product.
12. Shelf Life (days): The shelf life of the dairy product in days.
13. Storage Condition: The recommended storage condition for the dairy product.
14. Production Date: The date of production for the dairy product.
15. Expiration Date: The date of expiration for the dairy product.
16. Quantity Sold (liters/kg): The quantity of the dairy product sold.
17. Price per Unit (sold): The price per unit at which the dairy product was sold.
18. Approx. Total Revenue (INR): The approximate total revenue generated from the sale of the dairy product.
19. Customer Location: The location of the customer who purchased the dairy product.
20. Sales Channel: The channel through which the dairy product was sold (Retail, Wholesale, Online).
21. Quantity in Stock (liters/kg): The quantity of the dairy product remaining in stock.
22. Minimum Stock Threshold (liters/kg): The minimum stock threshold for the dairy product.
23. Reorder Quantity (liters/kg): The recommended quantity to reorder for the dairy product.

#### Potential Use-Case:
This dataset can be used by researchers, analysts, and businesses in the dairy industry for various purposes, such as:

1. Analyzing the performance of dairy farms based on location, land area, and cow population.
2. Understanding the sales and distribution patterns of different dairy products across various brands and regions.
3. Studying the impact of storage conditions and shelf life on the quality and availability of dairy products.
4. Analyzing customer preferences and buying behavior based on location and sales channels.
5. Optimizing inventory management by tracking stock quantities, minimum thresholds, and reorder quantities.
6. Conducting market research and trend analysis in the dairy industry.
7. Developing predictive models for demand forecasting and pricing strategies.

Note: This dataset includes data from the period between 2019 and 2022, and it specifically focuses on selected dairy brands operating in specific states and union territories of India. There is an intentional drift highlighted in the dataset's figures due to its opensource and creative license, currently !",.csv
Dairy vs plant-based milk,1,dairy-vs-plant-based-milk,environmental-footprint-milks newv2.csv,CC0-1.0,"this graph was created in PowerBi,Loocker studio and Tableau :

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fcf95d78502abc745bbd405d1930dd18e%2Fgraph3.png?generation=1713641082992114&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F170938323db528f1621a3a819097af00%2Fgraph2.png?generation=1713641088548940&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Ff4e2dbff7327311c15d513cfff863141%2Fgraph1.png?generation=1713641096512299&alt=media)

In an era marked by heightened environmental consciousness, the spotlight is increasingly turning towards the impact of dietary choices on our planet. Milk, a ubiquitous dietary staple across many cultures, has come under scrutiny for its significant contribution to greenhouse gas emissions and other environmental concerns. As a result, an escalating number of individuals are considering plant-based alternatives as a means to mitigate their carbon footprint.

Across the European Union, dairy consumption is responsible for over a quarter of the carbon footprint in typical diets, with variations that could push it to as much as one-third. This staggering figure underscores the urgent need for alternative options that are more sustainable. Surveys conducted in the UK reveal a notable shift in consumer preferences, with approximately one-quarter of adults and even higher proportions among younger demographics opting for non-dairy milk alternatives.

The emergence of a diverse array of plant-based milk substitutes, including soy, oat, almond, rice, and coconut, presents consumers with a myriad of choices. However, discerning which option boasts the most favorable environmental profile requires a closer examination of key metrics such as land use, greenhouse gas emissions, water consumption, and eutrophication – the harmful over-enrichment of ecosystems with nutrients.

Comparative analysis reveals stark disparities between traditional cow's milk and its plant-based counterparts across all environmental metrics. Cow's milk exhibits significantly higher impacts, with approximately three times the greenhouse gas emissions, ten times the land usage, and notably elevated levels of freshwater consumption and eutrophication. This stark contrast underscores the potential of plant-based alternatives to alleviate environmental strain.

Yet, when delving into the realm of plant-based milks, the question arises: which option reigns supreme? The answer is nuanced and contingent upon the specific environmental metric one prioritizes. For instance, almond milk boasts lower greenhouse gas emissions and land usage compared to soy milk. However, it necessitates higher water consumption and yields increased eutrophication levels. Thus, while each alternative presents a more sustainable choice than dairy, there is no definitive victor across all metrics.

Beyond environmental considerations, nutritional quality also warrants attention, particularly for certain populations. While plant-based milks offer an array of nutrients, including essential vitamins and minerals, disparities exist among them. For example, soy milk is renowned for its protein content, making it a favorable choice for individuals seeking a protein-rich alternative. Conversely, almond milk tends to be lower in protein but may appeal to those with nut allergies or sensitivities.

In navigating the landscape of plant-based milk alternatives, consumers are encouraged to consider not only the environmental impact but also their individual dietary preferences and nutritional requirements. Embracing diversity in consumption patterns allows for a more holistic approach to sustainability, wherein individuals can align their dietary choices with both planetary health and personal well-being.

Furthermore, the quest for sustainability extends beyond the realm of milk alternatives to encompass broader systemic changes within the food industry. Innovations in agricultural practices, supply chain management, and waste reduction strategies are imperative in fostering a more regenerative and equitable food system.

In conclusion, the transition towards plant-based milk alternatives represents a promising avenue for reducing the environmental footprint of our diets. While each option presents unique advantages and challenges, collectively, they offer a pathway towards greater sustainability and resilience in the face of environmental challenges. By making informed choices and embracing diversity in consumption, we can collectively contribute to a healthier planet for future generations.",.csv
Dark Patterns,1,dark-patterns,dataset.csv,Apache 2.0,"The proposed dataset aims to facilitate research in automatic dark pattern detection on e-commerce websites. Unlike previous approaches that relied on manually extracted features, this dataset focuses solely on text data automatically extracted from web pages. The inspiration for this dataset comes from previous work by Mathur et al. in 2019, which contained 1,818 dark pattern texts from shopping sites. To create a balanced dataset, non-dark pattern texts were added to this existing dataset.

A. Dark Pattern Texts in E-commerce Sites:
The initial dataset of dark patterns, manually curated by Mathur et al., contained 1,818 dark pattern texts from 1,254 shopping sites. From this dataset, texts with missing or duplicate data were excluded, resulting in 1,178 dark pattern texts.

B. Non-Dark Pattern Texts in E-commerce Sites:
Negative samples, or non-dark pattern texts, were collected from the same e-commerce websites where the dark patterns were sourced. This involved the following steps:

1. Collecting web pages: Web pages from e-commerce sites were gathered using headless Chrome. If a website was unreachable or encountered errors, it was ignored. JavaScript execution was employed to ensure comprehensive content retrieval, as most websites rely on JavaScript for page rendering.

2. Extracting texts: After collecting web pages, the Puppeteer library was used to scrape content, including screenshots and text. Unlike Mathur et al.'s approach, which focused on text within UI components, this method targeted text from the entire web page.

By combining these steps, the dataset comprises both dark pattern and non-dark pattern texts, enabling research into automatic dark pattern detection without the need for manually extracted features.",.csv
Data Analysis: Investigating IMDB movies dataset.,1,data-analysis-investigating-imdb-movies-dataset,tmdb-movies.csv,Attribution-NoDerivatives 4.0 International (CC BY-ND 4.0),"The analysis reveals that higher movie budgets tend to correspond with increased revenues. Additionally, more recent release years are associated with higher revenue and profit. Drama emerged as the most widespread genre, and Universal Pictures was identified as the most productive production company. Robert De Niro had the highest number of appearances among actors. While some movies achieved outstanding success, the film industry remains challenging. Finally, while movie budget is important, it is not the sole indicator of a film's success.",.csv
Data Analyst Jobs,1,data-analyst-jobs,DataAnalyst.csv,other,"# Abstract
&gt; Looking for a job as Data Analyst? Maybe this dataset can help you.

# About this dataset
&gt; Amidst the pandemic many people lost their jobs, with this dataset it is possible to hone the job search so that more people in need can find employment.
This dataset was created by [picklesueat](https://github.com/picklesueat/data_jobs_data) and contains more than **2000 job listing for data analyst** positions, with features such as:
- Salary Estimate
- Location
- Company Rating
- Job Description
- and more.

# How to use
&gt; - Find the best jobs by salary and company rating
- Explore skills required in job descriptions
- Predict salary based on industry, location, company revenue
- Your kernel can be featured here!
- [Data Engineer Jobs](https://www.kaggle.com/andrewmvd/data-engineer-jobs)
- [Business Analyst Jobs](https://www.kaggle.com/andrewmvd/business-analyst-jobs)
- [Data Scientist Jobs](https://www.kaggle.com/andrewmvd/data-scientist-jobs)
- [More Datasets](https://www.kaggle.com/andrewmvd/datasets)


# Acknowledgements
If you use this dataset, please [support the author](https://github.com/picklesueat/data_jobs_data).

&gt; ### License
License was not specified at the source


&gt; ### Splash banner
Photo by [Chris Liverani](https://unsplash.com/@chrisliverani?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/photos/NDfqqq_7QWM)

&gt; ### Splash Icon
Icon by [Eucalyp](https://www.flaticon.com/authors/eucalyp) available on [flaticon.com](https://www.flaticon.com/free-icon/businessman_1465883?term=data%20analyst&page=1&position=9) ",.csv
Data Breaches,1,data-breaches-a-comprehensive-list,df_1.csv,CC0-1.0,"# Data Breaches Dataset
### 30,000 Records of cyber-security data breaches
_____

### About this dataset
&gt; This dataset is a compilation of data from various sources detailing data breaches. These sources include press reports, government news releases, and mainstream news articles. The list includes those involving the theft or compromise of 30,000 or more records, although many smaller breaches occur continually. In addition, the various methods used in the breaches are listed, with hacking being the most common.
&gt; 
&gt; Organizations of all types and sizes are susceptible to data breaches, which can have devastating consequences. This dataset can help shed light on which organizations are most at risk and how these breaches occur so that steps can be taken to prevent them in the future

### How to use the dataset
&gt; There are many ways to use this dataset. Here are a few ideas:
&gt; 
&gt; - Use the data to understand which types of organizations are most commonly breached, and what methods are used most often.
&gt; - Analyze the data to see if there are any trends or patterns in when or how breaches occur.
&gt; - Use the data to create a visualizations or infographic showing the prevalence of data breaches

### Research Ideas
&gt; - This dataset can be used to identify trends in data breaches in terms of methods used, types of organizations breached, and geographical distribution.
&gt; 
&gt; - This dataset can be used to study the effect of data breaches on organizational reputation and customer trust.
&gt; 
&gt; - This dataset can be used by organizations to benchmark their own security measures against those of similar organizations that have experienced data breaches

### Acknowledgements

&gt; 
&gt; 
&gt; ### License
&gt; 
&gt; 
&gt; &gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; &gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: df_1.csv**
| Column name           | Description                                                          |
|:----------------------|:---------------------------------------------------------------------|
| **Entity**            | The name of the organization that was breached. (String)             |
| **Year**              | The year when the breach occurred. (Integer)                         |
| **Records**           | The number of records that were compromised in the breach. (Integer) |
| **Organization type** | The type of organization that was breached. (String)                 |
| **Method**            | The method that was used to breach the organization. (String)        |
| **Sources**           | The sources from which the data was collected. (String)              |

",.csv
Data Engineer Salary in 2024,1,data-engineer-salary-in-2024,salaries (2).csv,Apache 2.0,"This dataset provides insights into data engineer salaries and employment attributes for the year 2024. It includes information such as salary, job title, experience level, employment type, employee residence, remote work ratio, company location, and company size.

The dataset allows for analysis of salary trends, employment patterns, and geographic variations in data engineering roles. It can be used by researchers, analysts, and organizations to understand the evolving landscape of data engineering employment and compensation.

## **Feature Description:**

- **work_year:** The year in which the data was collected (2024).
- **experience_level:** The experience level of the employee, categorized as SE (Senior Engineer), MI (Mid-Level Engineer), or EL (Entry-Level Engineer).
- **employment_type:** The type of employment, such as full-time (FT), part-time (PT), contract (C), or freelance (F).
- **job_title:** The title or role of the employee within the company, for example, AI Engineer.
- **salary:** The salary of the employee in the local currency (e.g., 202,730 USD).
- **salary_currency:** The currency in which the salary is denominated (e.g., USD).
- **salary_in_usd:** The salary converted to US dollars for standardization purposes.
- **employee_residence:** The country of residence of the employee.
- **remote_ratio:** The ratio indicating the extent of remote work allowed in the position (0 for no remote work, 1 for fully remote).
- **company_location:** The location of the company where the employee is employed.
- **company_size:** The size of the company, often categorized by the number of employees (S for small, M for medium, L for large).",.csv
Data Hackers Survey 2019,1,pesquisa-data-hackers-2019,datahackers-survey-2019-anonymous-responses.csv,CC-BY-NC-SA-4.0,"**Pesquisa de mercado de Data Science no Brasil feita pela comunidade Data Hackers. A pesquisa foi conduzida de forma online durante o mês de Novembro de 2019**.

O *dataset* foi anonimizado ao remover alguns *outliers* que poderiam identificar o entrevistado e, portanto, nem todos os dados coletados na pesquisa estarão disponíveis aqui. Estados com menor incidência de resposta, como aqueles das regiões Norte, Nordeste e Centro-Oeste terão apenas sua região indicada no *dataset*, também como consequência do processo de anonimização. 

**As perguntas cujas respostas são multi-valoradas ocupam mais de uma coluna no *dataset*. Portanto, para diferenciar quais colunas pertencem a quais perguntas, cada coluna é identificada com uma tupla**. Sendo o primeiro identificador o da pergunta, e, no caso de várias respostas, o segundo identificador referencia a alternativa escolhida. As perguntas mapeadas são mostradas abaixo (lembrando que algumas foram removidas e outras tiveram alguns *outliers* transformados/apagados no processo de anonimização)

1. Pergunta_1 (P1) = Idade? [Mascarada]
2. Pergunta_2 (P2) = Gênero? [Mascarada]
3. Pergunta_3 (P3) = Atualmente você vive no Brasil?
4. Pergunta_4 (P4) = ~~Em que país você vive hoje?~~
5. Pergunta_5 (P5) = Em que estado você vive hoje? [Mascarada]
6. Pergunta_6 (P6) = Na questão anterior você disse que vive em _____ . Esse é seu estado de origem (onde nasceu ou se formou)?
7. Pergunta_7 (P7) = ~~Qual seu estado de origem?~~
8. Pergunta_8 (P8) = Qual seu nível de ensino? 
9. Pergunta_9 (P9) = ~~Qual sua área de formação?~~
10. Pergunta_10 (P10) = Qual sua situação atual de trabalho? 
11. Pergunta_11 (P11) = ~~A empresa em que você trabalha pertence a qual setor?~~
12. Pergunta_12 (P12) = A empresa em que você trabalha possui quantos funcionários atualmente?
13. Pergunta_13 (P13) = Você atua como gestor?
14. Pergunta_14 (P14) = ~~Qual das opções abaixo definem melhor seu cargo de trabalho atual como gestor?~~
15. Pergunta_15 (P15) = ~~Qual das opções abaixo definem melhor seu cargo de trabalho atual?~~
16. Pergunta_16 (P16) = Qual sua faixa salarial atual? [Mascarada]
17. Pergunta_17 (P17) = Quanto tempo de experiência na área de dados você tem?
18. Pergunta_18 (P18) = Quanto tempo de experiência na área de TI/Engenharia de Software você teve antes de começar a trabalhar na área de dados?
19. Pergunta_19 (P19) = Você se considera um profissional que atua na área de Data Science?
20. Pergunta_20 (P20) = Quais dos métodos listados abaixo você costuma utilizar no trabalho?
21. Pergunta_21 (P21) = Quais das linguagens de programação listadas abaixo você utiliza no trabalho?
22. Pergunta_22 (P22) = Entre as linguagens de programação listadas abaixo, qual é a que você mais utiliza no trabalho? [Mascarada]
23. Pergunta_23 (P23) = Quais das fontes de dados listadas você já analisou no trabalho?
24. Pergunta_24 (P24) = Entre as fontes de dados listadas, quais você utiliza na maior parte do tempo? Selecione no máximo duas opções que você mais utiliza.
25. Pergunta_25 (P25) = Quais das opções de Cloud listadas abaixo você utiliza no trabalho?
26. Pergunta_26 (P26) = Quais dos bancos de dados/fontes de dados listados abaixo você utiliza para consultar informações, e posteriormente analisar, no trabalho?
27. Pergunta_27 (P27) = Quais as Ferramentas de Business Intelligence você utiliza no trabalho?
28. Pergunta_28 (P28) = Quais as tecnologias são utilizadas como ferramenta de ETL no seu trabalho?
29. Pergunta_29 (P29) = Sua organização possui um Data Warehouse?
30. Pergunta_30 (P30) = Qual tecnologia utilizada como plataforma do Data Warehouse?
31. Pergunta_31 (P31) = Quais das iniciativas do Data Hackers que você já acessou/acompanhou?
32. Pergunta_32 (P32) = Entre as iniciativas do Data Hackers qual a sua preferida?
33. Pergunta_33 (P33) = De quais outras formas que você costuma se atualizar no mundo dos dados?
34. Pergunta_34 (P34) = Em quais dessas plataformas listadas abaixo você já iniciou/completou cursos na área de Data Science?
35. Pergunta_35 (P35) = Dentre as plataformas listadas abaixo qual foi a sua preferida para cursos de Data Science?
36. Pergunta_36 (P36) = Você deseja participar do sorteio?

Além dessas, derivamos algumas outras colunas:
1. Derivado_1 (D1) = Macrorregião em que mora
2. Derivado_2 (D2) = Macrorregião em que nasceu
3. Derivado_3 (D3) = Área de formação anonimizada
4. Derivado_4 (D4) = Setor de mercado anonimizado
5. Derivado_5 (D5) = Nível de gerência anonimizado
6. Derivado_6 (D6) = Cargo anonimizado",.csv
Data Police shootings,1,data-police-shootings,fatal-police-shootings-data.csv,CC-BY-SA-4.0,"The FBI and the Centers for Disease Control and Prevention log fatal shootings by police, but officials acknowledge that their data is incomplete. In 2015, The Post documented more than two times more fatal shootings by police than had been recorded by the FBI. Last year, the FBI announced plans to overhaul how it tracks fatal police encounters.",.csv
Data Science Fields Salary Categorization,1,data-science-fields-salary-categorization,Data_Science_Fields_Salary_Categorization.csv,CC0-1.0,"Data Science Fields Salary Categorization Dataset contains 9 columns :- 
| Dimension | Description |
| --- | --- |
| Working Year | The year the salary was paid ( 2020, 2021, 2022 ) |
| Designation | The role worked in during the year |
| Experience | The experience level in the job during the year. [ EN - Entry level / Junior, MI - Mid level / Intermediate, SE - Senior level / Expert, EX -  Executive level / Director ]|
| Employment Status | The type of employment for the role. [ PT - Part time, FT - Full time, CT - Contract, FL - Freelance ]|
| Salary In Rupees | The total gross salary amount paid. |
| Employee Location | Employee's primary country of residence in during the work year as an ISO 3166 country code.( PFB Link to ISO 3166 country code ) |
| Company Location | The country of the employer's main office or contracting branch. |
| Company Size | The median number of people that worked for the company during the year. [ S(small) - Less than 50 employees , M(medium) - 50 to 250 employees , L(large) - More than 250 employees  ]|
| Remote Working Ratio | The overall amount of work done remotely. [ 0 - No Remote Work (less than 20%), 50 - Partially Remote, 100 - Fully Remote (more than 80%) ]|

I have collected the data from ai-jobs.net & modified it for my own convenience
Original Data Source -
https://salaries.ai-jobs.net/download/
ISO 3166 Country Code - 
https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes


",.csv
Data Science Interview Q&A Treasury,1,data-science-interview-q-and-a-treasury,dataset.csv,Apache 2.0,"The ""Ultimate Data Science Interview Q&A Treasury"" dataset is a meticulously curated collection designed to empower aspiring data scientists with the knowledge and insights needed to excel in the competitive field of data science. Whether you're a beginner seeking to ground your foundations or an experienced professional aiming to brush up on the latest trends, this treasury serves as an indispensable guide. Furthermore, you might want to work on the following exercises using this dataset :

1)Keyword Analysis for Trending Topics:
     Frequency Analysis: Identify the most common keywords or terms that appear in the questions to spot trending topics or skills.
2)Topic Modeling:
    Use algorithms like Latent Dirichlet Allocation (LDA) or Non-negative Matrix Factorization (NMF) to group questions into topics automatically. This can reveal the underlying themes or areas of focus in data science interviews.
3)Text Difficulty Level Analysis:
    Implement Natural Language Processing (NLP) techniques to evaluate the complexity of questions and answers. This could help in categorizing them into beginner, intermediate, and advanced levels.
4)Clustering for Unsupervised Learning:
   Apply clustering techniques to group similar questions or answers together. This could help identify unique question patterns or common answer structures.
5)Automated Question Generation:
   Train a model to generate new interview questions based on the patterns and topics discovered in the dataset. This could be a valuable tool for creating mock interviews or study guides.
",.csv
Data Science Job Salaries 2024,1,data-science-job-salaries-2024,salaries.csv,DbCL-1.0,"work_year    :	  The year the salary was paid.
experience_level    :     The experience level in the job during the year with the following possible values: EN Entry-level / Junior MI Mid-level / Intermediate SE Senior-level / Expert EX Executive-level / Director
employment_type    :	The type of employement for the role: PT Part-time FT Full-time CT Contract FL Freelance
job_title	:    The role worked in during the year.
salary	:    The total gross salary amount paid.
salary_currency	:     The currency of the salary paid as an ISO 4217 currency code.
salary_in_usd	:   The salary in USD (FX rate divided by avg. USD rate for the respective year via fxdata.foorilla.com).
employee_residence	:    Employee's primary country of residence in during the work year as an ISO 3166 country code.
remote_ratio	:     The overall amount of work done remotely, possible values are as follows: 0 No remote work (less than 20%) 50 Partially remote 100 Fully remote (more than 80%)
company_location	:    The country of the employer's main office or contracting branch as an ISO 3166 country code.
company_size	:        The average number of people that worked for the company during the year: S less than 50 employees (small) M 50 to 250 employees (medium) L more than 250 employees (large)",.csv
Data Science Jobs Salaries Dataset,1,data-science-jobs-salaries,Data Science Jobs Salaries.csv,CC0-1.0,"# What's inside dataset 

## work_year
The year during which the salary was paid. There are two types of work year values:
2020
Year with a definitive amount from the past
2021e
Year with an estimated amount (e.g. current year)

## experience_level
The experience level in the job during the year with the following possible values:
EN
Entry-level / Junior
MI
Mid-level / Intermediate
SE
Senior-level / Expert
EX
Executive-level / Director

## employment_type
The type of employement for the role:
PT
Part-time
FT
Full-time
CT
Contract
FL
Freelance

## job_title
The role worked in during the year.
salary
The total gross salary amount paid.

## salary_currency
The currency of the salary paid as an ISO 4217 currency code.

## salary_in_usd
The salary in USD (FX rate divided by avg. USD rate for the respective year via fxdata.foorilla.com).

## employee_residence
Employee's primary country of residence in during the work year as an ISO 3166 country code.

## remote_ratio
The overall amount of work done remotely, possible values are as follows:
0
No remote work (less than 20%)
50
Partially remote
100
Fully remote (more than 80%)

## company_location
The country of the employer's main office or contracting branch as an ISO 3166 country code.

## company_size
The average number of people that worked for the company during the year:
S
less than 50 employees (small)
M
50 to 250 employees (medium)
L
more than 250 employees (large)



# Dataset Source - ai-jobs.net Salaries",.csv
Data Science Programs list,1,data-science-programs-list,datascience_programs_list.csv,Attribution 4.0 International (CC BY 4.0),"That sounds like a valuable dataset for anyone interested in pursuing a master's degree in Data Science or Analytics in the United States! This dataset is very helpful to pursuing a master's degree in the US.
- Are you looking to analyze this dataset for any specific insights or purposes? 
- Do you need assistance with anything related to it?

&gt; ## About .csv file
* **Subject Name:** The name or field of study of the master's program, such as Data Science, Data Analytics, or Applied Biostatistics.
* **University Name:** The name of the university offering the master's program.
* **Per Year Fees:** The program's tuition fees are usually in euros per year. For some programs, the fees may be listed as ""full"" or ""full-time,"" indicating a lump sum for the entire program or full-time enrollment, respectively.
* **About Program:** A brief description or overview of the master's program, providing insights into its curriculum, focus areas, and any unique features.
* **Program Duration:** The duration of the master's program, typically expressed in years or months.
* **University Location:** The location of the university where the program is offered, including the city and state.
* **Program Name:** The official name of the master's program, often indicating its degree type (e.g., M.Sc. for Master of Science) and format (e.g., full-time, part-time, online).",.csv
Data Science Salaries,1,data-science-salaries,data_science_salaries.csv,Apache 2.0,"Embark on a journey into the realm of data science salaries with this comprehensive dataset sourced from Kaggle. Delve deep into the intricate landscape of compensation within the data science field, featuring insights into salaries, demographics, education, experience levels, and more. This dataset offers a wealth of information for analysts, researchers, and aspiring data scientists alike, providing a nuanced understanding of the factors influencing earnings in this rapidly evolving industry. Uncover trends, patterns, and correlations to gain valuable insights into salary dynamics across different regions, industries, and job roles. Whether you're exploring career opportunities, benchmarking your own salary, or conducting research on compensation trends, this dataset serves as an invaluable resource for illuminating the complex interplay between skills, experience, and remuneration in the data science domain. Harness the power of data-driven analysis to navigate the landscape of data science salaries and chart your course towards professional success.",.csv
Data Science Salaries 2019-2021 - from reddit,1,datasciencesalaries-reddit,reddit_ds_salaries2019-2021.csv,CC0-1.0,"on r/datascience reddit subthread there is an annual data science salary survey thread.  I have scrapped this data using RStudio jsonlite and then cleaned it up.

## Column Descriptions: 
- *year:* year of survey
- Title: job title
- tenure_length: how long this person is at this particular job
- tenure_length_period:  years or months
- Location: location where the work is performed 
$Remote:
- Salary:  can be in different currencies
- Company/Industry:
- Education: education 
- Prior Experience: prior experience before getting this job

- Relocation/Signing Bonus:  when starting this job.  This is typically one-off bonus
- Stock and/or recurring bonuses:  what are recurring bonuses
- Total comp:  total compensation (salary + recurring bonus)
",.csv
Data Science Salaries And Fields,1,data-science-salaries-and-fields,DataScience_Salaries_And_Fields.csv,MIT,"# Data Science Salaries and Fields

This dataset contains information about salaries and fields within the data science domain. The data is collected from various sources and covers the working years from 2020 to 2024.

## Data Columns:

1. **Working_Year**: The working year in which the salary is reported.
2. **Designation**: The position or title of the employee within the company.
3. **Experience**: The level of experience of the employee.
4. **Employment_Status**: The employment status (full-time, part-time, etc.).
5. **Salary_In_Rupees**: The salary in the local currency (Rupees, Dollars, etc.).
6. **Employee_Location**: The location of the employee's residence.
7. **Company_Location**: The location of the company where the employee works.
8. **Company_Size**: The size of the company (large, medium, small).
9. **Remote_Working_Ratio**: The percentage of remote working time.
10. **Salary_Currency**: The currency in which the salary is denoted.
11. **Salary_In_USD**: The salary converted to US Dollars.

This dataset provides valuable insights into the salaries and roles within the data science field, which can be used for analysis and research purposes.",.csv
Data Science questions and answers,1,data-science-questions-and-answers,DataScience QA.csv,Apache 2.0,"This dataset contains questions and their corresponding answers related to various concepts and techniques in reinforcement learning, supervised learning, unsupervised learning, deep learning. Each entry consists of a question regarding a specific aspect of followed by its detailed answer, providing comprehensive insights into the fundamentals, algorithms, methodologies, and applications within the domain. ",.csv
Data Scientist Jobs,1,data-scientist-jobs,DataScientist.csv,other,"# Abstract
&gt; Looking for a job as Data Scientist? This dataset can help you!

# About this dataset
&gt; Amidst the pandemic many people lost their jobs, with this dataset it is possible to hone the job search so that more people in need can find employment.
This dataset was created by [picklesueat](https://github.com/picklesueat/data_jobs_data) and contains more than **3900 job listing for data scientist** positions, with features such as:
- Salary Estimate
- Location
- Company Rating
- Job Description
- and more.

# How to use
&gt; - Find the best jobs by salary and company rating
- Explore skills required in job descriptions
- Predict salary based on industry, location, company revenue
- Your kernel can be featured here!
- [Business Analyst Jobs](https://www.kaggle.com/andrewmvd/business-analyst-jobs)
- [Data Analyst Jobs](https://www.kaggle.com/andrewmvd/data-analyst-jobs)
- [More Datasets](https://www.kaggle.com/andrewmvd/datasets)


# Acknowledgements
If you use this dataset, please [support the author](https://github.com/picklesueat/data_jobs_data).

&gt; ### License
License was not specified at the source


&gt; ### Splash banner
Photo by [Adam Nowakowski](https://unsplash.com/@adamaszczos?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/photos/MFms-wkv3Ow)

&gt; ### Splash Icon
Icon by [Freepik](https://www.flaticon.com/authors/freepik) available on [flaticon.com](https://www.flaticon.com/free-icon/statistics_3050256?term=statistical&page=1&position=42) ",.csv
Data Scientist Salary in 2024,1,data-scientist-salary-in-2024,salaries _2.csv,Apache 2.0,"This dataset serves as a valuable resource for conducting in-depth analysis and research on data scientist salaries and employment dynamics in the year 2024, providing insights that can inform decision-making and strategy development in the field of data science.

## **Feature Description:**

- **work_year:**The year in which the data was collected (2024 in this case).
- **experience_level:** The experience level of the employee, typically categorized as entry-level (EL), mid-level (MI), or senior-level (SL).
- **employment_type:** The type of employment, such as full-time (FT), part-time (PT), contract (C), or freelance (F).
- **job_title:** The title or role of the employee within the company, for example, Data Scientist.
- **salary:** The salary of the employee in the local currency (e.g., 120,000 AUD).
- **salary_currency:** The currency in which the salary is denominated (e.g., USD or AUD).
- **salary_in_usd:** The salary converted to US dollars for standardization purposes.
- **employee_residence:** The country of residence of the employee.
- **remote_ratio:** The ratio indicating the extent of remote work allowed in the position (0 for no remote work, 1 for fully remote).
- **company_location:** The location of the company where the employee is employed.
- **company_size:** The size of the company, often categorized by the number of employees (S for small, M for medium, L for large).",.csv
Data for Admission in the University,1,data-for-admission-in-the-university,adm_data.csv,CC0-1.0,"This dataset includes various information like GRE score, TOEFL score, university rating, SOP (Statement of Purpose), LOR (Letter of Recommendation), CGPA, research and chance of admit. In this dataset, 400 entries are included.

GRE Scores ( out of 340 )
TOEFL Scores ( out of 120 )
University Rating ( out of 5 )
Statement of Purpose (SOP) and Letter of Recommendation (LOR) Strength ( out of 5 )
Undergraduate GPA ( out of 10 )
Research Experience ( either 0 or 1 )
Chance of Admit ( ranging from 0 to 1 ).",.csv
Data jobs salaries,1,data-jobs-salaries,salaries.csv,CC0-1.0,"**####About Dataset**

This dataset was retrieved from the page https://ai-jobs.net/salaries/download/

This site collects salary information anonymously from professionals all over the world in the AI, ML, Data Science space and makes it publicly available for anyone to use, share and play around with.

The primary goal is to have data that can provide better guidance in regards to what's being paid globally. So newbies, experienced pros, hiring managers, recruiters and also startup founders or people wanting to make a career switch can make better informed decisions.

work_year: The year the salary was paid.
experience_level: The experience level in the job during the year with the following possible values:
EN: Entry-level / Junior
MI: Mid-level / Intermediate
SE: Senior-level / Expert
EX: Executive-level / Director
employment_type: The type of employement for the role:
PT: Part-time
FT: Full-time
CT: Contract
FL: Freelance
job_title: The role worked in during the year.
salary: The total gross salary amount paid.
salary_currency: The currency of the salary paid as an ISO 4217 currency code.
salary_in_usd: The salary in USD (FX rate divided by avg. USD rate of respective year via data from fxdata.foorilla.com).
employee_residence: Employee's primary country of residence in during the work year as an ISO 3166 country code.
remote_ratio: The overall amount of work done remotely, possible values are as follows:
0: No remote work (less than 20%)
50: Partially remote/hybrid
100: Fully remote (more than 80%)
company_location: The country of the employer's main office or contracting branch as an ISO 3166 country code.
company_size: The average number of people that worked for the company during the year:
S: less than 50 employees (small)
M: 50 to 250 employees (medium)
L: more than 250 employees (large)",.csv
Data minat mahasiswa,1,data-mahasiswa,raw data.csv,CC0-1.0,"Dataset terdiri dari 100 entri yang merekam rekam jejak pemilihan mata kuliah pilihan mahasiswa dalam berbagai mata kuliah pilihan. 

Setiap entri dalam dataset ini mencakup informasi berikut:

Nama Mahasiswa: Nama dari mahasiswa yang tercatat dalam dataset.

NIM : NIM dari mahasiswa yang tercatat dalam dataset. 

Mata Kuliah: Nama mata kuliah pilihan yang diambil oleh mahasiswa. Ini mencakup berbagai jenis mata kuliah, seperti data mining, desain grafis, sistem informasi pendidikan, dll.

Dataset ini dibuat sebagai mencari informasi mengenai minat mahasiswa. Tujuannya adalah untuk memberikan informasi minat mahasiswa sehingga berguna untuk pihak UPT dan juga pemahaman tentang bagaimana data dapat diorganisir dalam konteks machine learning, serta bagaimana model dapat dilatih untuk menganalisis hubungan minat mahasiswa dalam pemilihan mata kuliah pilihan.
",.csv
Data science job salary,1,data-science-job-salary,datascience_salaries.csv,other,"With the help of this data, we can analyze the salaries of data science positions
and also&nbsp;make predictions using any regression method...

I appreciate ai-jobs.net Salaries collecting this information, they're great!",.csv
Data scientist salary,1,data-scientist-salary-us-glassdoor,data_cleaned_2021.csv,CC0-1.0,"![Data scientist image](https://www.uwinnipeg.ca/mathstats/images/data-science-768x384.png)

### Context

This dataset was made by scrapping the job postings related to the position of 'Data Scientist' from www.glassdoor.com in USA, I used selenium to scrap the data. After scrapping the raw data, I removed the duplicated rows from it which reduced the records from 1000 to 742. After this, several simplifications were performed to make the data user friendly for further data analysis and modelling.

### Content

With each job, I got the following columns: Job title, Salary Estimate, Job Description, Rating, Company, Location, Company , Headquarters, , , any Size, Company Founded Date, Type of Ownership, Industry, Sector, Revenue, Competitors.

Note: Columns with value -1 means either the data scraping was unsuccessful for that or the data was not present.

### Acknowledgements

Thanks to Ken Jee for the inspiration behind the dataset and special thanks to Ezequiel Starecinch for the scrapper.

### Inspiration

I was inspired by Ken Jee to scrap this dataset and to clean it.
https://github.com/PlayingNumbers/ds_salary_proj
While scrapping and cleaning, I took ideas from Ezequiel Starecinch.
https://github.com/echestare",.csv
DataCoSupplychain Dataset & EDA with report,1,datacosupplychain-dataset-and-eda-with-report,DataCoSupplyChainDataset.csv,Apache 2.0,"Our team conducted an in-depth analysis of **Data Co's supply chain data** spanning *2015 to 2018*. The analysis revealed significant insights and actionable recommendations across various facets of the supply chain, from shipping delays and fraud detection to customer segmentation and market expansion. Key findings highlighted challenges in 'Same Day' shipping, potential for centralized warehouses, and opportunities in product profitability. Additionally, RFM analysis offered insights into **customer segmentation** for targeted marketing strategies. Our recommendations focus on improving **inventory management**, **streamlining order fulfillment**, and enhancing customer satisfaction. We also emphasized the importance of resilience and **risk management** in the face of external challenges, such as natural disasters. Overall, our comprehensive approach provides Data Co with a strategic roadmap for operational optimization and business growth.",.csv
Dataset Financial Statement in IDX Indonesia,1,financial-statement-data-idx-2020-2023,combined_financial_data_idx.csv,ODbL-1.0,"# Introduction
This dataset contains 604 public company financial statement annually in IDX (Bursa Efek Indonesia), largest number that I can see in kaggle :D. Company that's not included in this dataset either do not report their financial statement or contains some irrelevant publishing date.

# Usability
- EDA
- Classifier Stock
- Fundamental Analysis
- Financial Statement Analysis

# Wanna Contribute?
Please leave a message on suggestions!

# Appendix

## Type:

| **Type** | **Description** | **Translate (in Indonesia)** |
| --- | --- | --- |
| BS | Balance Sheet/Statement of FInancial Position | Laporan Posisi Neraca / Laporan Posisi Keuangan |
| IS | (Consolidated) Income Statement | Laporan Laba/Rugi (Konsolidasian) |
| CF | Statement of Cash Flow | Laporan Arus Kas |

## Account:

| **Account** | **Type** | **Translate (in Indonesia)** |
| --- | --- | --- |
|Accounts Payable|BS|Utang Usaha|
|Accounts Receivable|BS|Piutang Usaha|
|Accumulated Depreciation|BS|Akumulasi Penyusutan|
|Additional Paid In Capital (PIC) / Share Premium|BS|Saham premium|
|Allowance For Doubtful Accounts Receivable (AFDA)|BS|Cadangan Piutang Usaha|
|Buildings And Improvements|BS|Bangunan dan Pengembangan|
|Capital Stock|BS|Saham|
|Cash And Cash Equivalents|BS|Kas dan Setara Kas|
|Cash Cash Equivalents And Short Term Investments|BS|Kas, Setara Kas, dan Investasi Jangka Pendek|
|Cash Equivalents|BS|Setara Kas|
|Cash Financial|BS|Kas yang berhubungan dengan aktiviatas keuangan|
|Common Stock|BS|Saham Biasa|
|Common Stock Equity|BS|Ekuitas Saham Biasa|
|Construction In Progress|BS|Konstruksi yang Sedang Berlangsung|
|Current Assets|BS|Aset Lancar|
|Current Debt|BS|Utang Lancar|
|Current Debt And Capital Lease Obligation|BS|Utang Lancar dan Kewajiban Sewa Kapital|
|Current Liabilities|BS|Liabilitas Lancar|
|Finished Goods|BS|Barang Jadi|
|Goodwill|BS|Nilai Tambah (Goodwill)|
|Goodwill And Other Intangible Assets|BS|Nilai Tambah (Goodwill) dan Aset Tidak Berwujud Lainnya|
|Gross Accounts Receivable|BS|Piutang Usaha Bruto|
|Gross PPE|BS|Aktiva Tetap Bruto (Properti, Pabrik, dan Peralatan)|
|Inventory|BS|Persediaan|
|Invested Capital|BS|Kapital yang Diinvestasikan|
|Investmentsin Joint Venturesat Cost|BS|Investasi dalam Usaha Patungan dengan Harga Perolehan|
|Land And Improvements|BS|Tanah dan Pengembangan|
|Long Term Debt|BS|Utang Jangka Panjang|
|Long Term Debt And Capital Lease Obligation|BS|Utang Jangka Panjang dan Kewajiban Sewa Kapital|
|Long Term Equity Investment|BS|Investasi Ekuitas Jangka Panjang|
|Machinery Furniture Equipment|BS|Mesin, Perabotan dan Perlengkapan|
|Minority Interest|BS|Kepentingan Minoritas|
|Net Debt|BS|Utang Bersih|
|Net PPE|BS|Aktiva Tetap Bersih (Properti, Pabrik, dan Peralatan)|
|Net Tangible Assets|BS|Aset Berwujud Bersih|
|Non Current Deferred Taxes Assets|BS|Aset Pajak Tangguhan Non Lancar|
|Non Current Deferred Taxes Liabilities|BS|Liabilitas Pajak Tangguhan Non Lancar|
|Non Current Pension And Other Postretirement Benefit Plans|BS|Rencana Pensiun Non Lancar dan Manfaat Pasca Pensiun Lainnya|
|Ordinary Shares Number|BS|Jumlah Saham Biasa|
|Other Current Liabilities|BS|Liabilitas Lancar Lainnya|
|Other Equity Interest|BS|Kepentingan Ekuitas Lainnya|
|Other Inventories|BS|Persediaan Lainnya|
|Other Non Current Assets|BS|Aset Non Lancar Lainnya|
|Other Non Current Liabilities|BS|Liabilitas Non Lancar Lainnya|
|Other Payable|BS|Hutang Lainnya|
|Other Properties|BS|Properti Lainnya|
|Other Receivables|BS|Piutang Lainnya|
|Payables|BS|Utang|
|Pensionand Other Post Retirement Benefit Plans Current|BS|Rencana Pensiun dan Manfaat Pasca Pensiun Lainnya Saat Ini|
|Prepaid Assets|BS|Aset Dibayar Dimuka|
|Properties|BS|Properti|
|Raw Materials|BS|Bahan Baku|
|Retained Earnings|BS|Laba Ditahan|
|Share Issued|BS|Saham yang Diterbitkan|
|Stockholders Equity|BS|Ekuitas Pemegang Saham|
|Tangible Book Value|BS|Nilai Buku Berwujud|
|Total Assets|BS|Total Aset|
|Total Capitalization|BS|Total Kapitalisasi|
|Total Debt|BS|Total Utang|
|Total Equity Gross Minority Interest|BS|Total Ekuitas Bruto dengan Kepentingan Minoritas|
|Total Liabilities Net Minority Interest|BS|Total Liabilitas Bersih dengan Kepentingan Minoritas|
|Total Non Current Assets|BS|Total Aset Non Lancar|
|Total Non Current Liabilities Net Minority Interest|BS|Total Liabilitas Non Lancar Bersih dengan Kepentingan Minoritas|
|Total Tax Payable|BS|Total Utang Pajak|
|Treasury Shares Number|BS|Jumlah Saham Treasuri|
|Work In Process|BS|Pekerjaan dalam Proses|
|Working Capital|BS|Modal Kerja / Kapital Jangka Pendek|
|Beginning Cash Position|CF|Posisi Kas Awal|
|Capital Expenditure|CF|Pengeluaran - Kapital|
|Capital Expenditure Reported|CF|Pengeluaran - Kapital yang Dilaporkan|
|Cash Dividends Paid|CF|Dividen Tunai yang Dibayarkan|
|Cash Flowsfromusedin Operating Activities Direct|CF|Arus Kas yang Digunakan dalam Aktivitas Operasional Langsung|
|Changes In Cash|CF|Perubahan Kas|
|Classesof Cash Payments|CF|Bagian dari Pembayaran Kas|
|Classesof Cash Receiptsfrom Operating Activities|CF|Bagian dari Penerimaan Kas dari Aktivitas Operasional|
|Common Stock Dividend Paid|CF|Dividen Saham Biasa yang Dibayarkan|
|Effect Of Exchange Rate Changes|CF|Dampak Perubahan Nilai Tukar|
|End Cash Position|CF|Posisi Kas Akhir|
|Financing Cash Flow|CF|Arus Kas Pembiayaan|
|Free Cash Flow|CF|Arus Kas Bebas|
|Interest Paid Cff|CF|Pembayaran Bunga dari Arus Kas Pembiayaan|
|Interest Received Direct|CF|Penerimaan Bunga Langsung|
|Investing Cash Flow|CF|Arus Kas Investasi|
|Issuance Of Debt|CF|Penerbitan Utang|
|Long Term Debt Issuance|CF|Penerbitan Utang Jangka Panjang|
|Long Term Debt Payments|CF|Pembayaran Utang Jangka Panjang|
|Net Issuance Payments Of Debt|CF|Pembayaran Penerbitan Bersih Utang|
|Net Long Term Debt Issuance|CF|Penerbitan Utang Jangka Panjang Bersih|
|Net Other Financing Charges|CF|Beban Pembiayaan Lain Bersih|
|Net Other Investing Changes|CF|Perubahan Investasi Lain Bersih|
|Net PPE Purchase And Sale|CF|Pembelian dan Penjualan Aktiva Tetap Bersih|
|Other Cash Paymentsfrom Operating Activities|CF|Pembayaran Kas Lain dari Aktivitas Operasional|
|Paymentsto Suppliersfor Goodsand Services|CF|Pembayaran kepada Pemasok untuk Barang dan Jasa|
|Purchase Of PPE|CF|Pembelian Aktiva Tetap (Properti, Pabrik, dan Peralatan)|
|Receiptsfrom Customers|CF|Penerimaan dari Pelanggan|
|Repayment Of Debt|CF|Pembayaran Utang|
|Taxes Refund Paid Direct|CF|Pembayaran Pajak Pengembalian Langsung|
|Basic Average Shares|IS|Jumlah Saham Rata-rata Biasa|
|Basic EPS|IS|Laba per Saham Biasa|
|Cost Of Revenue|IS|Biaya Pendapatan|
|Depreciation And Amortization In Income Statement|IS|Penyusutan dan Amortisasi dalam Laporan Laba Rugi|
|Depreciation Income Statement|IS|Penyusutan - Laporan Laba Rugi |
|Diluted Average Shares|IS|Jumlah Saham Rata-rata Dilusi|
|Diluted EPS|IS|Laba per Saham Dilusi|
|Diluted NI Availto Com Stockholders|IS|Laba Bersih Tersedia untuk Pemegang Saham Biasa Dilusi|
|EBIT|IS|Laba Sebelum Bunga dan Pajak|
|EBITDA|IS|Laba Sebelum Bunga, Pajak, Penyusutan, dan Amortisasi|
|General And Administrative Expense|IS|Beban Umum dan Administrasi|
|Gross Profit|IS|Laba Kotor|
|Impairment Of Capital Assets|IS|Penurunan Nilai Aset Kapital|
|Interest Expense|IS|Beban Bunga|
|Interest Expense Non Operating|IS|Beban Bunga Non Operasional|
|Interest Income|IS|Pendapatan Bunga|
|Interest Income Non Operating|IS|Pendapatan Bunga Non Operasional|
|Minority Interests|IS|Kepentingan Minoritas|
|Net Income|IS|Laba Bersih|
|Net Income Common Stockholders|IS|Laba Bersih untuk Pemegang Saham Biasa|
|Net Income Continuous Operations|IS|Laba Bersih dari Operasi Berkelanjutan|
|Net Income From Continuing And Discontinued Operation|IS|Laba Bersih dari Operasi Berkelanjutan dan yang Dihentikan|
|Net Income From Continuing Operation Net Minority Interest|IS|Laba Bersih dari Operasi Berlanjut Setelah Bunga Minoritas|
|Net Income Including Noncontrolling Interests|IS|Laba Bersih Termasuk Kepentingan Nonkontrol|
|Net Interest Income|IS|Pendapatan Bunga Bersih|
|Net Non Operating Interest Income Expense|IS|Beban Pendapatan Bunga Non Operasional Bersih|
|Normalized EBITDA|IS|EBITDA Disesuaikan|
|Normalized Income|IS|Laba Disesuaikan|
|Operating Expense|IS|Beban Operasional|
|Operating Income|IS|Laba Operasional|
|Operating Revenue|IS|Pendapatan Operasional|
|Other Non Operating Income Expenses|IS|Pendapatan Beban Non Operasional Lainnya|
|Other Operating Expenses|IS|Beban Operasional Lainnya|
|Other Special Charges|IS|Beban Khusus Lainnya|
|Otherunder Preferred Stock Dividend|IS|Lainnya di bawah Dividen Saham Preferen|
|Pretax Income|IS|Laba Sebelum Pajak|
|Reconciled Cost Of Revenue|IS|Biaya Pendapatan yang Disesuaikan|
|Reconciled Depreciation|IS|Penyusutan yang Disesuaikan|
|Research And Development|IS|Penelitian dan Pengembangan|
|Selling And Marketing Expense|IS|Beban Penjualan dan Pemasaran|
|Selling General And Administration|IS|Penjualan, Umum, dan Administrasi|
|Special Income Charges|IS|Beban Pendapatan Khusus|
|Tax Effect Of Unusual Items|IS|Dampak Pajak dari Item Tidak Biasa|
|Tax Provision|IS|Penyediaan Pajak|
|Tax Rate For Calcs|IS|Tarif Pajak untuk Perhitungan|
|Total Expenses|IS|Total Beban|
|Total Other Finance Cost|IS|Total Biaya Keuangan Lainnya|
|Total Revenue|IS|Total Pendapatan|
|Total Unusual Items|IS|Total Item Tidak Biasa|
|Total Unusual Items Excluding Goodwill|IS|Total Item Tidak Biasa yang Tidak Termasuk Nilai Tambah (Goodwill)|
|Write Off|IS|Beban Penghapusan|",.csv
"Dataset Tanaman Padi Sumatera, Indonesia",1,datasettanamanpadisumatera,Data_Tanaman_Padi_Sumatera_version_1.csv,CC0-1.0,"Pulau Sumatera mempunyai lebih dari 50 persen lahan pertanian setiap provinsinya dengan komoditas pangan utama paling dominan adalah padi, sedangkan sisanya adalah jagung, kacang tanah, dan ubi. Hasil pertanian di Sumatera sangat rentan terhadap perubahan iklim karena dapat memengaruhi pola tanam, waktu tanam, produksi dan kualitas hasil. Perubahan iklim dapat memberikan dampak negatif terhadap produksi bahan pokok tersebut. Apalagi bertambahnya suhu bumi akibat dampak dari pemanasan global yang akan mempengaruhi pola presipitasi, evaporasi, water-run off, kelembaban tanah, dan variasi iklim yang sangat fluktuatif secara keseluruhan dapat mengancam keberhasilan hasil produksi pertanian. Prediksi hasil pertanian komoditas bahan pangan banyak dipengaruhi oleh perubahan cuaca (climate change). Untuk mendukung Sustainable Development Goals dunia, kita sebagai data scientist perlu membangun model prediktif dari masalah yang disebutkan. Regresi yang digunakan adalah metode supervised learning dari decision tree dan Artificial neural network.

Pengambilan data diperoleh melalui website BPS pada kategori tanaman pangan utama dari 8 provinsi di pulau Sumatera yaitu Nanggroe Aceh Darussalam (NAD), Sumatera Utara, Riau, Jambi, Sumatera Selatan, Bengkulu dan Lampung. Data yang digunakan adalah data dari tahun 1993 hingga tahun 2020 untuk dataset padi. Data memuat hasil produksi tahunan dan luas panen atau luas lahan. Kemudian data perubahan cuaca diperoleh melalui website BMKG untuk data harian curah hujan, kelembapan, dan temperatur rata-rata atau suhu rata-rata dari tahun 1993 hingga tahun 2020.

Silahkan bangun model regresi dengan machine learning untuk memprediksi produksi padi di pulau Sumatera.",.csv
Dataset Ujian Nasional,1,dataset-ujian-nasional,Dataset Pelatihan.csv,CC0-1.0,"Dataset ini dibuat secara simulasi untuk memberikan contoh latihan dalam pelatihan machine learning. Dataset terdiri dari 100 entri yang merekam rekam jejak nilai mahasiswa dalam berbagai mata kuliah.

Setiap entri dalam dataset ini mencakup informasi berikut:

Nama Siswa: Nama lengkap dari mahasiswa yang tercatat dalam dataset. Nama-nama ini dibuat secara acak dan tidak berkaitan dengan individu nyata.

Mata Kuliah: Nama mata kuliah yang diambil oleh mahasiswa. Ini mencakup berbagai jenis mata kuliah, seperti Matematika, Fisika, Bahasa Inggris, Sejarah, dan lain-lain.

Nilai: Nilai yang diperoleh oleh mahasiswa dalam mata kuliah tertentu. Nilai ini dalam bentuk numerik dan mencerminkan kinerja akademik mahasiswa dalam mata kuliah tersebut.

Dataset ini dibuat sebagai contoh untuk latihan machine learning, dan nilai-nilai yang terdapat di dalamnya bersifat fiktif. Tujuannya adalah untuk memberikan pemahaman tentang bagaimana data dapat diorganisir dalam konteks machine learning, serta bagaimana model dapat dilatih untuk memprediksi atau menganalisis hubungan antara nilai, nama siswa, dan mata kuliah.

Dataset ini tidak memiliki tujuan akademik atau klinis yang sebenarnya. Semua data bersifat fiksi dan tidak mencerminkan prestasi sebenarnya dari individu yang nyata. Digunakan hanya untuk keperluan pembelajaran dan eksperimen dalam bidang machine learning.",.csv
Dataset for Bengaluru House Price Prediction,1,dataset-for-bengaluru-house-price-prediction,bengaluru_house_prices.csv,Apache 2.0,"Embark on a journey through the bustling streets of Bengaluru with this comprehensive dataset, meticulously curated to unveil the city's vibrant real estate landscape. Featuring a diverse array of housing properties, ranging from cozy apartments nestled in the heart of the city to luxurious villas tucked away in serene suburbs, this dataset offers a rich tapestry of residential options.

With over [insert number] meticulously collected entries, each boasting a plethora of features including location, square footage, number of bedrooms and bathrooms, amenities, and more, this dataset provides aspiring homeowners and seasoned investors alike with invaluable insights into Bengaluru's dynamic housing market.

Whether you're a data enthusiast eager to dive into predictive modeling or a savvy investor seeking to make informed decisions, this dataset serves as your compass in navigating Bengaluru's real estate maze. Join us in unraveling the mysteries of property pricing and uncovering the hidden gems scattered throughout this vibrant metropolis.",.csv
Dataset for Omicron variant of COVID-19,1,omicron-variant-of-covid19,covid-cases-omicron.csv,CC0-1.0,"### Context

The Omicron variant, variant B.1.1.529, was first reported to WHO on 24 November 2021 and was classified as a variant of concern by WHO on 26 November 2021. The classification was made on the advice of the Technical Advisory Group on Virus Evolution, based primarily on information from South Africa that the variant has a large number of mutations and has caused a detrimental change in COVID-19 epidemiology.

The data set is downloaded from https://ourworldindata.org/


### Content

The dataset contains:
Entity: Country Details 
Code : Country: Country Code
Day: Day of Report 
Omicron_Percentage: Percentage of Omnicron Impact on the day mentioned in Day column


### Acknowledgements

To all the authors and laboratories responsible for producing this data and sharing it via the GISAID initiative.

Khare, S., et al (2021) GISAID’s Role in Pandemic Response. China CDC Weekly, 3(49): 1049-1051. doi: 10.46234/ccdcw2021.255 PMCID: 8668406

Elbe, S. and Buckland-Merrett, G. (2017) Data, disease, and diplomacy: GISAID’s innovative contribution to global health. Global Challenges, 1:33-46. doi:10.1002/gch2.1018 PMCID: 31565258

Shu, Y. and McCauley, J. (2017) GISAID: from vision to reality. EuroSurveillance, 22(13) doi:10.2807/1560-7917.ES.2017.22.13.30494 PMCID: PMC5388101

Also  CoVariants.org and https://ourworldindata.org/

### Inspiration

Visualize the Omicron variant, variant B.1.1.529 spread.",.csv
Dataset of USED CARS,1,dataset-of-used-cars,car_data.csv,Apache 2.0,"**It's completely ready to use!**

- consists of 40k+ original and real records
- cleaned
- english language

This simple dataset is suitable for a beginner. No strange and empty data! The easiest way to start your own research journey 😃

The file contans a basic info in engish of sale offers: brand, model, price, city of sale, type of fuel, type of transmission, type of drive, mileage, country of origin,  engine capacity, engine power, age.",.csv
"Dataset of people's height, weight and shoe size ",1,dataset-of-people,hight.csv,other,"**Description**

Dataset of people's hThis data set includes height, weight collected from 100 participants. This dataset is taken for the effect of height and weight on BMIeight, weight, shoe size and gender from 109 person",.csv
Dataset: NetFlix Shows,1,dataset-netflix-shows,netflix_titles.csv,CC0-1.0,"The raw data is Web Scrapped through Selenium. It contains Unlabelled text data of around 9000 Netflix Shows and Movies along with Full details like Cast, Release Year, Rating, Description, etc.",.csv
Dataset_2022_IPL,1,dataset-2022-ipl,Ipl_Dataset_2022.csv,CC0-1.0,"This dataset appears to contain information related to the players participating in the Indian Premier League (IPL), including details such as their names, base prices, player types (batsman, bowler, all-rounder, wicketkeeper), costs in Indian Rupees and US Dollars, their respective teams, and additional details like retained status for some players. The dataset also includes information on players who were unsold during the auction process.

Here's a breakdown of the columns in the dataset:

1. Player: Name of the player.

2. Base Price: The initial price set for the player during the auction.

3. Type: The player's role or position in cricket (e.g., batsman, bowler, all-rounder, wicketkeeper).

4. Cost in ₹ (CR.): Cost of the player in Indian Rupees.

5. Cost in $ (000): Cost of the player in US Dollars.

6. 2021 Squad: The team the player belonged to in the previous season (2021).

7. Team: The team the player is assigned to for the upcoming season.

8. Remarks: Additional remarks or details about the player, such as retained status or if the player went unsold during the auction.

This dataset could be useful for analyzing various aspects of IPL auctions and team compositions, including player valuations, team budgets, player distributions across teams, and team strategies during auctions.",.csv
Dataset_Python_Question_Answer,1,dataset-python-question-answer,Dataset_Python_Question_Answer.csv,Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO),"This dataset is about Python programming. Question and answers are generated using Gemma. There are more than four  hundred questions and their corresponding answers about Python programming. 

Questions are ranging from concepts like data-types, variables and keywords to regular-expression and threading.

I have used this dataset [here](https://www.kaggle.com/code/chinmayadatt/python-question-answer-gemma-model) 

The code used for dataset generated is available [here](https://www.kaggle.com/code/chinmayadatt/generating-python-question-answer-dataset-by-gemma/notebook)",.csv
Death_rates_for_suicide_United_States,1,death-rates-for-suicide-united-states,Death_rates_for_suicide__by_sex__race__Hispanic_origin__and_age__United_States.csv,CC0-1.0,"
This data provides information on death rates for suicide in the United States, categorized by various population characteristics such as sex, race, Hispanic origin, and age. It's sourced from the National Vital Statistics System (NVSS) and includes data from different years, with references provided.

For detailed measures, definitions, and changes over time, it's recommended to refer to the PDF or Excel version of the table in the HUS 2019 Data Finder on the CDC website. This additional information can provide context and clarity regarding the presented statistics.

The National Vital Statistics System (NVSS) is a program of the National Center for Health Statistics (NCHS), which collects and disseminates vital statistics data, including information on births, deaths, marriages, divorces, and fetal deaths in the United States.",.csv
Decadal Consumer Price Index India Dataset 🌾🇮🇳,1,decadal-consumer-price-index-india-dataset,All_India_Index_Upto_April23.csv,CC0-1.0,"This extensive dataset captures the Consumer Price Index (CPI) evolution from 2013 to 2023 for rural and urban areas across India, as well as a consolidated rural-urban sector. 🌇🚜 Spanning over a decade, the dataset provides monthly indices for a variety of categories, including foodstuffs like cereals, meat, and vegetables 🍲, non-food items such as clothing and housing 🧥🏘️, and services like health and education 🏥🎓. The indices reflect the change in prices of goods and services consumed by households and are essential for evaluating the inflation rate and cost of living over time. 📈 The ""General Index"" offers a snapshot of overall inflation, representing the changing economic landscape for consumers in India. 📉 Notably, the dataset serves as a crucial tool for economists, government agencies, and analysts to monitor trends, formulate policies, and understand the economic health of the nation. 📝 Note that some entries may be missing (""NA""), indicating gaps in data collection or reporting for certain sectors or months.",.csv
Deceptive Opinion Spam Corpus,1,deceptive-opinion-spam-corpus,deceptive-opinion.csv,CC-BY-NC-SA-4.0,"### Context
This corpus consists of truthful and deceptive hotel reviews of 20 Chicago hotels. The data is described in two papers according to the sentiment of the review. In particular, we discuss positive sentiment reviews in [1] and negative sentiment reviews in [2].
While we have tried to maintain consistent data preprocessing procedures across the data, there are differences which are explained in more detail in the associated papers. Please see those papers for specific details.

### Content
This corpus contains:

* 400 truthful positive reviews from TripAdvisor (described in [1])
* 400 deceptive positive reviews from Mechanical Turk (described in [1])
* 400 truthful negative reviews from Expedia, Hotels.com, Orbitz, Priceline, TripAdvisor and Yelp (described in [2])
* 400 deceptive negative reviews from Mechanical Turk (described in [2])

Each of the above datasets consist of 20 reviews for each of the 20 most popular Chicago hotels (see [1] for more details). The files are named according to the following conventions:
Directories prefixed with fold correspond to a single fold from the cross-validation experiments reported in [1] and [2].

### Hotels included in this dataset

* affinia: Affinia Chicago (now MileNorth, A Chicago Hotel)
* allegro: Hotel Allegro Chicago - a Kimpton Hotel
* amalfi: Amalfi Hotel Chicago
* ambassador: Ambassador East Hotel (now PUBLIC Chicago)
* conrad: Conrad Chicago
* fairmont: Fairmont Chicago Millennium Park
* hardrock: Hard Rock Hotel Chicago
* hilton: Hilton Chicago
* homewood: Homewood Suites by Hilton Chicago Downtown
* hyatt: Hyatt Regency Chicago
* intercontinental: InterContinental Chicago
* james: James Chicago
* knickerbocker: Millennium Knickerbocker Hotel Chicago
* monaco: Hotel Monaco Chicago - a Kimpton Hotel
* omni: Omni Chicago Hotel
* palmer: The Palmer House Hilton
* sheraton: Sheraton Chicago Hotel and Towers
* sofitel: Sofitel Chicago Water Tower
* swissotel: Swissotel Chicago
*  talbott: The Talbott Hotel

### References
[1] M. Ott, Y. Choi, C. Cardie, and J.T. Hancock. 2011. Finding Deceptive Opinion Spam by Any Stretch of the Imagination. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies.

[2] M. Ott, C. Cardie, and J.T. Hancock. 2013. Negative Deceptive Opinion Spam. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.

### Acknowledgements
If you use any of this data in your work, please cite the appropriate associated paper (described above). Please direct questions to Myle Ott (myleott@cs.cornell.edu).",.csv
Default of Credit Card Clients Dataset,1,default-of-credit-card-clients-dataset,UCI_Credit_Card.csv,CC0-1.0,"## Dataset Information 

This dataset contains information on default payments, demographic factors, credit data, history of payment, and bill statements of credit card clients in Taiwan from April 2005 to September 2005. 

## Content

There are 25 variables:

* **ID**: ID of each client
* **LIMIT_BAL**: Amount of given credit in NT dollars (includes individual and family/supplementary credit
* **SEX**: Gender (1=male, 2=female)
* **EDUCATION**: (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)
* **MARRIAGE**: Marital status (1=married, 2=single, 3=others)
* **AGE**: Age in years
* **PAY_0**: Repayment status in September, 2005 (-1=pay duly, 1=payment delay for one month, 2=payment delay for two months, ... 8=payment delay for eight months, 9=payment delay for nine months and above)
* **PAY_2**: Repayment status in August, 2005 (scale same as above)
* **PAY_3**: Repayment status in July, 2005 (scale same as above)
* **PAY_4**: Repayment status in June, 2005 (scale same as above)
* **PAY_5**: Repayment status in May, 2005 (scale same as above)
* **PAY_6**: Repayment status in April, 2005 (scale same as above)
* **BILL_AMT1**: Amount of bill statement in September, 2005 (NT dollar)
* **BILL_AMT2**: Amount of bill statement in August, 2005 (NT dollar)
* **BILL_AMT3**: Amount of bill statement in July, 2005 (NT dollar)
* **BILL_AMT4**: Amount of bill statement in June, 2005 (NT dollar)
* **BILL_AMT5**: Amount of bill statement in May, 2005 (NT dollar)
* **BILL_AMT6**: Amount of bill statement in April, 2005 (NT dollar)
* **PAY_AMT1**: Amount of previous payment in September, 2005 (NT dollar)
* **PAY_AMT2**: Amount of previous payment in August, 2005 (NT dollar)
* **PAY_AMT3**: Amount of previous payment in July, 2005 (NT dollar)
* **PAY_AMT4**: Amount of previous payment in June, 2005 (NT dollar)
* **PAY_AMT5**: Amount of previous payment in May, 2005 (NT dollar)
* **PAY_AMT6**: Amount of previous payment in April, 2005 (NT dollar)
* **default.payment.next.month**: Default payment (1=yes, 0=no)

## Inspiration

Some ideas for exploration:

1. How does the probability of default payment vary by categories of different demographic variables?
2. Which variables are the strongest predictors of default payment?

## Acknowledgements

Any publications based on this dataset should acknowledge the following: 

Lichman, M. (2013). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.

The original dataset can be found [here](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients) at the UCI Machine Learning Repository.",.csv
Deforestation dataset,1,deforestation-dataset,goal15.forest_shares.csv,ODbL-1.0,"From the project website: https://sdga2022.github.io/sdga2022/goal-15-life-on-land

SDG 15 aims to protect, restore, and promote the sustainable use of terrestrial ecosystems and forests, to halt and reverse land degradation, and to put a stop to loss in biodiversity. In 2020, forests accounted for almost a third percent of global land area. Since 2000, forest area across the world has declined by 2.4 percent, an area equivalent to the size of Egypt.
",.csv
Deforestation in Federal Conservation Units.,1,cusersmarildownloadstserofcsv,tserof.csv,other,"### Context
 Updating page:https://dados.gov.br/dados/conjuntos-dados/incendios-em-unidades-de-conservacao-federais

 This dataset is available in Brazilian Open Data Portal. http://dados.gov.br/ The portal acts as a federated catalog that facilitates the search and use of data published by government agencies. Legal Amazon: Contains all nine states in the Amazon basin. The region was created in 1948 based on studies of the Brazilian government on how to plan the economic and social development of the Amazon region. https://en.wikipedia.org/wiki/Amaz%C3%B4nia_Legal ***Part of this translation was made by a bot(Google Translate).


### Content

Summary: Area deforested by clearcut, in hectares, inside Federal conservation Units between 2012 and 2017 - PRODES System - images from Landsat satellites. 
***Abbreviations 2nd column (uc_name):APA (Environmental Protection Area). ARIE (Area of Relevant Ecological Interest). ESEC (Ecological Station). FLONA (National Forest). MONA (Natural Monument). PARNA (National Park). RDS (Sustainable Development Reserve). REBIO (Biological Reserve). RESEX (Extractive Reserve). REVIS (Wildlife Refuge). 
****Forest is diversity. Protect diversity.


### Acknowledgements

Author: Chico Mendes Institute for Biodiversity Conservation - ICMBio **Maintainer: CGPRO/COIN/DMIF - Environmental Information and Monitoring Division. **Source: http://terrabrasilis.info/composer/PRODES. ***License not specified. **Photo by pixpoetry on Unsplash. I chose this photo because I still believe there is light at the end of the tunnel.


### Inspiration

Chico Mendes a Brazilian environmentalist that was murdered (December 22,1988). The Chico Mendes Institute is named in his honor. *""At first I thought I was fighting to save rubber trees, then I thought I was fighting to save the Amazon rainforest. Now I realize I am fighting for humanity. — said Chico Mendes"".",.csv
Delaware Electric Vehicle Charging Station Rebate,1,delaware-electric-vehicle-charging-station-rebate,delaware_ev_charging_rebates.csv,Apache 2.0,"## Delaware EV Rebates Dataset

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F1937611%2Fc6f971a8e5bad0f8525df008a899beb6%2F_477d3150-53a9-4f70-81ff-09b9718cceba.jpeg?generation=1715765044007046&alt=media)

This dataset provides information on electric vehicle (EV) charging stations and associated rebates in Delaware. It includes the following columns:

- **Award Number**: Unique identifier for each rebate award.
- **Month**: Month when the rebate was awarded.
- **Year**: Year when the rebate was awarded.
- **City**: City where the charging station is located.
- **Zip**: ZIP code of the location of the charging station.
- **Charging Station Brand**: Brand or manufacturer of the charging station.
- **County**: County where the charging station is located.
- **Cost of Charging Station**: Cost of the charging station.
- **Rebate Amount**: Amount of rebate awarded for the charging station.

This dataset is valuable for understanding the distribution of EV charging infrastructure and incentives in Delaware.",.csv
Delaware Restaurant Inspection Violations Records,1,delaware-restaurant-inspection-violations-records,Delaware_Restaurant_Inspection_Violations.csv,Apache 2.0,"# Delaware Restaurant Inspection Violations

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F1937611%2F39323def880ecf76bed13a82884d5986%2F_dd93e9b2-4d48-46e5-95da-de327d66983b.jpeg?generation=1715758303243279&alt=media)

This dataset provides detailed information on restaurant inspection violations in Delaware over the past two years. It includes the following categories:

- **Food Establishment Name**: Restaurant name
- **Food Establishment Street Address**: Restaurant street address
- **Food Establishment City**: Restaurant city
- **Food Establishment Zip Code**: Restaurant Zip Code
- **Inspection Date**: Date of restaurant inspection conducted by the Division of Public Health - Office of Food Protection
- **Inspection Type**: Inspection visit type: routine, follow-up, or complaint.
- **Violation Code**: The violation code that this restaurant was cited for in this inspection. If no violation code is present, there were no violations for this inspection. There may be numerous violations that a restaurant is cited for in a single visit. If this is the case, there will be multiple rows for this restaurant with the same inspection date.
- **Violation Description**: Description of the violation which corresponds to the violation code.
- **Geocoded Location**: Street address, city, state, and zip code for geolocation purposes",.csv
Delhi Metro Lost and Found Dataset,1,delhi-metro-lost-and-found-dataset,delhimetrorail.csv,Apache 2.0,"## Updated Data Card for Kaggle

**Delhi Metro Lost and Found Items (Dec 2021 - Mar 2024)**

This dataset contains information about items lost and found in the Delhi Metro Rail Corporation (DMRC) network between December 2021 and March 2024. It includes details such as:

* **item_name:** The name of the item lost (e.g., Pen, Phone, Laptop)
* **description:** A brief description of the item (e.g., Blue, new iPhone 13) - Note that many descriptions are missing
* **item_quantity:** The quantity of the item lost (e.g., 1, but many quantities are missing)
* **station_name:** The name of the metro station where the item was lost
* **receiving_date:** The date the item was received by the lost and found department
* **receiving_time:** The time the item was received by the lost and found department

**Data Characteristics:**

* The dataset contains 13,713 rows (observations) and 6 columns (features)
* Several columns have missing values: description (39%), item_quantity (77%)

**Potential Uses:**

This dataset could be useful for understanding what kind of items are commonly lost in the Delhi Metro, and at which stations. It could also be used to develop machine learning models to predict which items are more likely to be claimed by their owners.

**Additional Information:**

* The data was collected from the Delhi Metro Rail Corporation (DMRC).
* The data provides a sample of lost and found items between December 2021 and March 2024. 

**Example Rows:**

| Column Name | Description | Example Value |
|---|---|---|
| item_name | The name of the item lost | CHAIN |
| description | A brief description of the item | METAL CHAIN |
| item_quantity | The quantity of the item lost | 1 |
| station_name | The name of the metro station where the item was lost | VAISHALI |
| receiving_date | The date the item was received by the lost and found department | 21/03/2024 |
| receiving_time | The time the item was received by the lost and found department | 11:35:00 |

Thumbnail photo by <a href=""https://unsplash.com/@k4if?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Kaif</a> on <a href=""https://unsplash.com/photos/gray-train-Md-trFhJGZg?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv
Delhi's Meteorological Data,1,delhi-meteorological-data,POWER_Point_Daily_20170101_20231031_028d6400N_077d2100E_LST.csv,MIT,"## Dataset Overview
The dataset comprises data of various meteorological factors for Delhi from 01/01/2017 to 10/31/2023.

## Info About dataset
Location: Latitude  28.64   Longitude 77.21 
Elevation from MERRA-2: Average for 0.5 x 0.625 degree lat/lon region = 206.37 meters
The value for missing source data that cannot be computed or is outside of the sources availability range: -999 
Parameter(s): 
T2M    -   MERRA-2 Temperature at 2 Meters (C) 
WS10M  -   MERRA-2 Wind Speed at 10 Meters (m/s) 
WD10M  -   MERRA-2 Wind Direction at 10 Meters (Degrees) 
RH2M   -   MERRA-2 Relative Humidity at 2 Meters (%) 
PS    -    MERRA-2 Surface Pressure (kPa) ",.csv
Delhivery Data ,1,delhivery,delhivery_data.csv,CC0-1.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F12038776%2F94c7116862ef19cbcd7a554868ad5f1d%2FDELHIVERY-22-8-2023.jpg?generation=1714753072672002&alt=media)
# About Data :
Delhivery is the largest and fastest-growing fully integrated player in India by revenue in Fiscal 2021. They aim to build the operating system for commerce, through a combination of world-class infrastructure, logistics operations of the highest quality, and cutting-edge engineering and technology capabilities. The Data team builds intelligence and capabilities using this data that helps them to widen the gap between the quality, efficiency, and profitability of their business versus their competitors.
# Purpose
The company aims to comprehend and process data emerging from data engineering pipelines, undertaking tasks such as cleaning, sanitizing, and manipulating data to extract valuable features from raw fields. The overarching objective is to derive actionable insights from raw data, thereby aiding the data science team in constructing accurate forecasting models",.csv
Delta Airways Reviews✈️,1,delta-airways-reviews,delta_airways_reviews.csv,ODC Attribution License (ODC-By),"

**Dataset Overview:**
Dive into the world of air travel experiences with the ""Delta Airways Reviews✈️"" dataset, a comprehensive collection of customer feedback sourced from TripAdvisor. This dataset offers a panoramic view of passenger sentiments and experiences, presenting a unique opportunity to explore the intricacies of airline service quality and customer satisfaction.Spanning a wide range of travel dates, this dataset encapsulates the varied experiences of Delta Airways passengers. From the excitement of boarding to the nuances of in-flight service, these reviews provide a raw, unfiltered glimpse into the world of travel through the eyes of real customers.

**Data Science Application:**
Ideal for sentiment analysis, trend identification, and service improvement insights, this dataset is a treasure trove for data scientists keen on harnessing natural language processing (NLP) and machine learning. Whether it's predicting customer satisfaction, identifying areas for service enhancement, or mapping out sentiment trends over time, the applications are as vast as the skies.

**Column Descriptors:**
- **published_platform**: The digital terrain where the review was shared.
- **rating**: A quantifiable measure of satisfaction, ranging from low to high.
- **type**: The nature of the submission, in this case, a review.
- **helpful_votes**: A gauge of the review's resonance with others.
- **travel_date**: When the journey took place, offering temporal insights.
- **text**: The heart of the dataset, where experiences are vividly narrated.
- **title**: A snapshot of sentiment, encapsulating the essence of the review.
- **machine_translated**: Indicates whether the review has been translated by machine, preserving the authenticity of global voices.
- **machine_translatable**: A marker of linguistic accessibility, ensuring no voice is left unheard.

**Ethically Mined Data:**
This dataset stands as a testament to responsible data collection practices. Sourced ethically from TripAdvisor, it respects privacy and complies with all relevant data use policies, ensuring that insights are gleaned without compromising individual privacy.

**A special nod of gratitude goes to TripAdvisor:**  for serving as the platform where travelers share their stories. It's through these shared experiences that the dataset derives its value, offering a lens into the multifaceted world of air travel, marked by diverse perspectives and shared human experiences.

Embark on a data-driven journey through the skies with ""Delta Airways Reviews✈️"" and unlock insights that soar beyond the ordinary.",.csv
"Dementia Patient Health,Prescriptions ML Dataset",1,dementia-patient-health-and-prescriptions-dataset,dementia_patients_health_data.csv,Apache 2.0,"# About Dataset
**Diabetic (Binary)**: Indicates whether a patient has been diagnosed with diabetes (1 for yes, 0 for no).

**Alcohol Level (Continuous)**: Measures the alcohol consumption level of patients, possibly reflecting lifestyle choices.

**Heart Rate (Continuous)**: Denotes the number of heartbeats per minute, a critical indicator of cardiovascular health.

**Blood Oxygen Level (Continuous)**: The saturation of oxygen in the blood, a vital sign of respiratory function.

**Body Temperature (Continuous)**: The measured temperature of the body in Celsius, indicating potential fever or hypothermia.

**Weight (Continuous)**: The mass of the patient in kilograms, a fundamental measure of health.

**MRI Delay (Continuous)**: The time delay in obtaining an MRI scan, potentially indicative of the progression or severity of medical conditions.

**Prescription**: The specific medication prescribed to the patient, relevant for treatment analysis.

**Dosage in mg (Continuous)**: The amount of medication prescribed, critical for dosage-effect studies.

**Age (Continuous)**: The age of the patient, an essential demographic factor.

**Education_Level**: The highest level of education attained by the patient, which may correlate with health literacy.

**Dominant_Hand**: Indicates the dominant hand of the patient, which could relate to neurological functions.

**Gender**: The gender of the patient, a key demographic characteristic.

**Family_History**: Indicates a family history of dementia, a significant risk factor.

**Smoking_Status**: Reflects the patient's smoking habits, an important lifestyle indicator.

**APOE_ε4**: Shows the presence of the APOE ε4 allele, a genetic variant associated with Alzheimer's disease.

**Physical_Activity**: The level of physical activity of the patient, highlighting lifestyle impacts on health.

**Depression_Status**: Indicates whether the patient has depression, which can be related to cognitive health.

**Cognitive_Test_Scores (Continuous)**: Scores from cognitive tests, direct measures of cognitive function.

**Medication_History**: Records whether the patient has a history of medication use, relevant for drug interactions.

**Nutrition_Diet**: Describes the patient's diet, an important health factor.

**Sleep_Quality**: Assesses the quality of the patient's sleep, a critical aspect of health.

**Chronic_Health_Conditions**: Notes any chronic health conditions the patient has, key for comorbidity studies.

**Dementia (Binary)**: Serves as the target variable, indicating the presence (1) or absence (0) of dementia.

This dataset serves as a rich source for analysis, providing a multifaceted view of factors that may contribute to the onset and progression of dementia. It is a valuable resource for researchers looking to explore the complex interplay between lifestyle, genetics, and health outcomes. From PUBMED, Online research sources, NHS, Google scholar and consultation with healthcare professionals.",.csv
Dementia prediction,1,dementia,OPTIMAL_combined_3studies_6feb2020.csv,Attribution 4.0 International (CC BY 4.0),"**Description**

Data from the three studies used in analysis in this paper. The three studies are SCANS, RUN DMC and ASPS. The dataset is the pooled dataset used to look at prediction of dementia using the simple MRI score and the amended MRI score. Fields are: Age-years Gender Dementia during follow-up - 1=dementia Years of education EF= Executive function PS= Processing speed Global=global cognitive score Diabetes mellitus - 1=yes smoking Hypertension 1=yes hypercholesterolaemia-1=yes Number of lacunes- zero or more than zero Fazekas white matter hyperintensity category Study data originated from -SCANS-RUN DMC ASPS Study1- differentiates which ASPS dataset data came from SVD simple score SVD amended score Fazekas score Lacune count CMB count.",.csv
Dengue Dataset of Bangladesh,1,dengue-dataset-bangladesh,dataset.csv,Attribution 4.0 International (CC BY 4.0),"## Dengue Phenomenon in Bangladesh - Dhaka Region

#### Dataset Description:

This dataset presents real-world data collected through surveys conducted in the Dhaka region of Bangladesh. It focuses on understanding the prevalence and characteristics of the Dengue fever phenomenon, a significant public health concern in the area. The dataset is updated monthly to reflect the evolving nature of the Dengue outbreak.

#### Context:

Dengue fever is a vector-borne disease transmitted to humans through the Aedes mosquito. Bangladesh, particularly the Dhaka region, has experienced periodic Dengue outbreaks, making it a critical area for research, monitoring, and public health interventions.

#### Key Features:

**Gender:** Gender of the survey respondent.

**Age:** Age of the survey respondent.

**NS1:** NS1 test's data positive as 1 negative as 0.

**IgG:** IgG data positive as 1 negative as 0.

**IgM:** IgM data positive as 1 negative as 0.

**Area:** The area within the Dhaka region where the respondent resides.

**Area Type:** Classification of the area as ""Developed"" or ""Undeveloped.""

**House Type:** The type of housing in the area, e.g., ""Building,"" ""Tin-Shed,"" or ""Others.""

**District:** The specific district within Dhaka.

**Outcome:** Outcome variable indicating the presence (1) or absence (0) of Dengue cases reported.

#### Data Collection:

The dataset is a result of a systematic survey conducted by [Kawsar Ahmad and Farzana Eva] to collect data on Dengue fever. Data collection is an ongoing process, and updates are made monthly to provide up-to-date information on the Dengue situation in Dhaka.

#### Use Cases:

**Public Health Research:** Researchers can use this dataset to study the epidemiology of Dengue fever in Dhaka, identify risk factors, and develop strategies for prevention and control.

**Machine Learning Classification:** Data scientists and machine learning enthusiasts can employ this dataset for classification tasks, such as predicting Dengue cases based on demographic and environmental factors.

**Government and NGOs:** Government agencies and non-governmental organizations (NGOs) can use this data to inform public health policies and allocate resources effectively.

#### Data Availability:

This dataset is open source and freely available for research, analysis, and any purpose. You are free to:

Share: Copy and redistribute the material in any medium or format.
Adapt: Remix, transform, and build upon the material for any purpose, even commercially.
However, you must provide appropriate attribution, including a link to the **Creative Commons Attribution 4.0 International License (CC BY 4.0)**, and indicate if changes were made.

#### Acknowledgments:

We would like to express our gratitude to the survey participants and the dedicated team involved in data collection.

**Contact Information:**

For inquiries, collaborations, or dataset updates, please contact [ahmad43.bu@gmail.com].

",.csv
Dengue Prediction(Supervised),1,dengue-prediction,final.csv,CC0-1.0,"This dataset contains number of dengue cases expected in a region depending on the weather data for that region.
It can be expanded to use over other regions and for other diseases as well",.csv
Denuncias defensa del consumidor (2019-2020),1,denuncias-defensa-del-consumidor-20192020,denuncias-defensa-del-consumidor.csv,CC0-1.0,"### Context

Conjunto de datos extraído de la página oficial del gobierno de la Ciudad de Buenos Aires, Argentina.



### Content

En el siguiente conjunto de datos encontrará un listado con información de las denuncias realizadas en la Dirección General de Defensa y Protección al Consumidor de la provincia de Buenos Aires (Argentina) entre los años 2019-2020
*Columnas*:
**Denuncia_ID**: Número con el que se identifica la denuncia.
**Fecha_Creacion**: Fecha en la que se realizó la denuncia.
**Comuna**: Lugar de la Ciudad de Buenos Aires desde donde se realizó la denuncia.
**Motivo_Denuncia**: Motivo por el cual la persona realizó la denuncia.
**Rubro**: Rubro que fue denunciado.[](https://data.buenosaires.gob.ar/)



",.csv
Depression and Mental Health Data Analysis,1,depression-and-mental-health-data-analysis,mental_health_finaldata_1.csv,CC-BY-SA-4.0,"RHMCD-20 dataset, we took care to include information from a wide range of sources, including teenagers from Bangladesh, college students, housewives, professionals from businesses and corporations, and other people.This is survey data for Depression and Mental Health Data Analysis.

Survey questions : 
- Age: Represents the age of the participants.
- Gender: Indicates the gender of the participants.
- Occupation: Represents the participant's occupations.
- Days_Indoors :Indicates the number of days the participant has not been out of the house
- Growing_Stress: Indicates the participant's stress is increasing day by day (Yes/No).
- Quarantine_Frustration: Frustrations in the first two weeks of quarantine (Yes/Maybe/No).
- Changes_Habits: Represents major changes in eating habits and sleeping (Yes/Maybe/No).
- Mental_Health_History : A precedent of mental disorders in the previous generation (Yes/No).
- Weight_Change :Highlights changes in body weight during quarantine (Yes/Maybe/No)
- Mood_Swings: Represents extreme mood changes (Low/Medium/High).
- Coping_Struggles: The inability to cope with daily problems or stress (Yes/Maybe/No).
- Work_Interest :Represents whether the participant is losing interest in working (Yes/No).
- Social_Weakness :Conveys feeling mentally weak when interacting with others (Yes/No).

**Data is reference from [here](https://data.mendeley.com/datasets/pxjmjyfdh2/2)**

**Credits goes to original author**
Salehin, Imrus; Amin, Nazrul  (2024), “The&nbsp;RHMCD-20 datasets for Depression and Mental Health Data Analysis with Machine Learning ”, Mendeley Data, V2, doi: 10.17632/pxjmjyfdh2.2",.csv
Depression and anxiety data,1,depression-and-anxiety-data,depression_anxiety_data.csv,CC0-1.0,"Depression is a serious mental illness that may be identified by its distinctive symptoms, which include feelings of melancholy and emptiness, feelings of worry and disturbed sleep, as well as a general loss of initiative and interest in activities. In addition, symptoms such as the sensation of guilt or worthlessness, decreased energy, difficulties concentrating, suicidality, and psychotic symptoms may be present. The number, severity, and length of symptoms, as well as the impact on one's ability to function socially and at work, are all factors that go into determining the severity of a depression. Anxiety is a natural response to stress, and there are circumstances in which it can really be helpful. It can warn us of potential threats, assist us in preparing for them, and help us pay attention. Anxiety disorders are distinct from everyday sensations of worry or anxiousness because they include abnormally high levels of these emotions. Anxiety disorders are the most prevalent kind of mental illness, affecting roughly one in every four individuals at some time in their life. However, anxiety disorders may be treated, and there are a variety of therapies that are proven to be helpful. The majority of patients benefit from treatment, which enables them to enjoy normal, productive lives. Depression and anxiety are very common among students. Which affects the studies and social behavior of the students. The dataset is collected from undergraduate students of University of lahore. There are 787 participants contributed to the dataset. This dataset is generated from the inspiration of the Beck Depression and Beck Anxiety inventories. 
This dataset can be used as the basis for evaluating different machine learning methods and approaches such as: classification of the severity of depression and anxiety. This dataset is also suitable for comparing different machine learning classification approaches.",.csv
Depression: Reddit Dataset (Cleaned),1,depression-reddit-cleaned,depression_dataset_reddit_cleaned.csv,CC0-1.0,The raw data is collected through web scrapping Subreddits and is cleaned using multiple NLP techniques. The data is only in English language. It mainly targets mental health classification.,.csv
Depression: Twitter Dataset + Feature Extraction,1,mental-health-social-media,Mental-Health-Twitter.csv,CC0-1.0,"The data is in uncleaned format and is collected using Twitter API. The Tweets has been filtered to keep only the English context. It targets mental health classification of the user at Tweet-level. Also check out notebooks I have provided which demonstrates Data Cleaning and Feature Extraction Techniques on the given dataset
1. **Topic Modelling Features** using LDA (Latent Dirichlet Allocation) i.e. summarizing tweet into one of Top k topics
2. **Emoji Sentiment Features** i.e. count of Positive, Negative and Neutral Expression emoji's present in the tweet",.csv
Dermatology Dataset (Multi-class classification),1,dermatology-dataset-classification,dermatology_database_1.csv,other,"* The differential diagnosis of **""erythemato-squamous""** diseases is a real problem in dermatology. They all share the clinical features of erythema and scaling, with minimal differences. The disorders in this group are psoriasis, seborrheic dermatitis, lichen planus, pityriasis rosea, chronic dermatitis, and pityriasis rubra pilaris. Usually, a biopsy is necessary for the diagnosis, but unfortunately, these diseases share many histopathological features as well. 

* Patients were first evaluated clinically with 12 features.  Afterward, skin samples were taken for the evaluation of 22 histopathological features. The values of the histopathological features are determined by an analysis of the samples under a microscope

## Feature Value Information 

In the dataset constructed for this domain, the **family history feature** has the value 1 if any of these diseases has been observed in the family, and 0 otherwise. The age feature simply represents the age of the patient. 

Every other feature **clinical and histopathological** was given a degree in the range of 0 to 3. Here, 0 indicates that the feature was not present, 3 indicates the largest amount possible, and 1, 2 indicate the relative intermediate values.

## **Exploration Ideas**

* **Distribution of each attribute:** Explore the distribution of each attribute (column) in the dataset. You can use histograms or boxplots to visualize the distribution of each attribute and look for any patterns or outliers.

* **Correlation analysis**: Use correlation matrices to explore the relationship between the different attributes in the dataset. This can help identify which attributes are most closely related to each other and may be useful in predicting the class labels.

* **Missing values analysis**: Investigate the missing values in the Age attribute, which are represented with '?' in the dataset. Determine the proportion of missing values and evaluate whether imputation is needed.

* **Class distribution**: Explore the distribution of the class labels in the dataset. You can use bar plots to visualize the number of instances for each class, and determine whether the dataset is balanced or imbalanced.

* **Feature engineering**: Consider creating new features that may be useful in predicting the class labels. For example, you could create a feature that combines the presence of specific clinical attributes or histopathological attributes.

* **Outlier detection**: Explore the presence of any outliers in the dataset. Outliers can skew the distribution of the data and impact the performance of machine learning models. You can use boxplots or scatterplots to visualize the distribution of each attribute and identify any potential outliers.",.csv
Dermatology Question-Answer Dataset: Skin Disease ,1,skin-disease-medical-text-data-for-fine-tuning,combined_data.csv,Apache 2.0,"This dataset is a comprehensive compilation of questions related to dermatology, spanning inquiries about various skin diseases, their symptoms, recommended medications, and available treatment modalities. Each question is paired with a concise and informative response, making it an ideal resource for training and fine-tuning language models in the field of dermatological healthcare. The dataset is designed to facilitate the development of advanced medical chat-bots and language models tailored to dermatology, providing valuable insights into skin health-related inquiries.


Please Explore the Work Here: https://github.com/Mreeb/llama2-Fine-tuning-On-Custom-Medical_data/tree/master",.csv
Despacho_Medicamento_Hospitales_RD,1,despacho-medicamento-hospitales-rd,Estadsticas_Despacho.csv,ODC Public Domain Dedication and Licence (PDDL),"Este conjunto de datos contiene las Estadísticas sobre Despacho de medicamentos del Programa de Medicamentos Esenciales / Central de Apoyo Logístico (PROMESE/CAL), del periodo 2018 - 2024, mostrando datos generales sobre la cantidad y porcentaje de hospitales programados y despachados, mes y año.",.csv
Diabetes Dataset - Pima Indians,1,review,diabetes.csv,CC0-1.0,"


&gt; ## What is Diabetes Dataset - Pima Indians Dataset?


This dataset is originally from the National Institute of Diabetes and Digestive and Kidney 
Diseases. The objective of the dataset is to diagnostically predict whether a patient has diabetes, 
based on certain diagnostic measurements included in the dataset. Several constraints were placed 
on the selection of these instances from a larger database. In particular, all patients here are females 
at least 21 years old of Pima Indian heritage.2
From the data set in the (.csv) File We can find several variables, some of them are independent 
(several medical predictor variables) and only one target dependent variable (Outcome).


![178112363-36a719ea-2f2f-4131-9ec4-83f6bb2194f1](https://user-images.githubusercontent.com/36210723/179423454-754b0e67-3b28-461c-afdc-96537e65d93c.png)


.



&gt; ## Acknowledgments


When we use this dataset in our research, we credit the authors as :


- **License** : `CC0: Public Domain.`


- **Smith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261--265). IEEE Computer Society Press**, and it is published t to reuse in the google research dataset.



&gt; ###  **The main idea for uploading this dataset is to practice data analysis with my students, as I am working in college and want my student to train our studying ideas in a big dataset, It may be not up to date and I mention the collecting years, but it is  a good resource of data to practice**",.csv
Diabetes Dataset 2019,1,diabetes-dataset-2019,diabetes_dataset__2019.csv,Attribution 4.0 International (CC BY 4.0),"### Context

This dataset was collected by Neha Prerna Tigga and Dr. Shruti Garg of the Department of Computer Science and Engineering, BIT Mesra, Ranchi-835215 for research, non-commercial purposes only. An article is also published implementing this dataset. For more information and citation of this dataset please refer: 

Tigga, N. P., & Garg, S. (2020). Prediction of Type 2 Diabetes using Machine Learning Classification Methods. Procedia Computer Science, 167, 706-716. DOI: https://doi.org/10.1016/j.procs.2020.03.336


### Content

There is a total of 952 instances with 17 independent predictor variables and one binary target or dependent variable, `Diabetes`. 


### Acknowledgements

We would like to thank all the participants who contributed towards the building of this dataset.


### Inspiration

To build a machine learning algorithm to predict if a person has diabetes or not?",.csv
Diabetes Dataset for Beginners,1,diabetes-dataset-for-beginners,diabetes.csv,other,"### Context

This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage


### Content

The datasets consists of several medical predictor variables and one target variable, Outcome. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.


### Acknowledgements

Smith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261--265). IEEE Computer Society Press.

### Inspiration

Can you build a  model (Machine learning or deep learning ) to accurately predict whether or not the patients in the dataset have diabetes or not?",.csv
Diabetes Healthcare: Comprehensive Dataset-AI,1,diabetes-healthcare-comprehensive-dataset,health care diabetes.csv,DbCL-1.0,"DESCRIPTION

NIDDK (National Institute of Diabetes and Digestive and Kidney Diseases) research creates knowledge about and treatments for the most chronic, costly, and consequential diseases.

The dataset used in this project is originally from NIDDK. The objective is to predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset.
Build a model to accurately predict whether the patients in the dataset have diabetes or not.
 

Dataset Description

The datasets consists of several medical predictor variables and one target variable (Outcome). Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and more.

 

Variables	Description
Pregnancies	Number of times pregnant
Glucose	Plasma glucose concentration in an oral glucose tolerance test
BloodPressure	Diastolic blood pressure (mm Hg)
SkinThickness	Triceps skinfold thickness (mm)
Insulin	Two hour serum insulin
BMI	Body Mass Index
DiabetesPedigreeFunction	Diabetes pedigree function
Age	Age in years
Outcome	Class variable (either 0 or 1). 268 of 768 values are 1, and the others are 0
Project Task: Week 1

Data Exploration:

Perform descriptive analysis. Understand the variables and their corresponding values. On the columns below, a value of zero does not make sense and thus indicates missing value:

Glucose

BloodPressure

SkinThickness

Insulin

BMI

Visually explore these variables using histograms. Treat the missing values accordingly.

There are integer and float data type variables in this dataset. Create a count (frequency) plot describing the data types and the count of variables. 

 

Data Exploration:

Check the balance of the data by plotting the count of outcomes by their value. Describe your findings and plan future course of action.

Create scatter charts between the pair of variables to understand the relationships. Describe your findings.

Perform correlation analysis. Visually explore it using a heat map.

 

Project Task: Week 2

Data Modeling:

Devise strategies for model building. It is important to decide the right validation framework. Express your thought process. 

Apply an appropriate classification algorithm to build a model.

Compare various models with the results from KNN algorithm.

Create a classification report by analyzing sensitivity, specificity, AUC (ROC curve), etc.

Please be descriptive to explain what values of these parameter you have used.

 

Data Reporting:

Create a dashboard in tableau by choosing appropriate chart types and metrics useful for the business. The dashboard must entail the following:

Pie chart to describe the diabetic or non-diabetic population

Scatter charts between relevant variables to analyze the relationships

Histogram or frequency charts to analyze the distribution of the data

Heatmap of correlation analysis among the relevant variables

Create bins of these age values: 20-25, 25-30, 30-35, etc. Analyze different variables for these age brackets using a bubble chart.",.csv
Diabetes Prediction,1,diabetes-prediction,Diabetes_prediction.csv,Apache 2.0,"The dataset generated for diabetes prediction purposes contains a range of features associated with diabetes risk factors. These features may include variables such as blood sugar levels, body mass index (BMI), age, family history, and other relevant health indicators. Each set of feature values is accompanied by a diagnosis label that indicates whether the individual has diabetes or not. This dataset is valuable for training machine learning models to predict the likelihood of diabetes based on the provided risk factors. It can be used for research, analysis, and the development of predictive models aimed at improving diabetes diagnosis and management.",.csv
Diabetes_Dataset_With_18_Features,1,diabetes-dataset-with-18-features,diabetes.csv,other,"Diabetes is the fourth leading cause of death in the world and one of the most common endocrine disorders. According to studies, Type 2 diabetes kills thousands of people around the world every year and imposes huge costs on societies in the form of surgeries and other treatment programs, as well as controlling complications and disability. Therefore, predicting and early diagnosis of this disease can greatly help governments and patients.

This dataset is the output of a Chinese research study conducted in 2016. It includes 1304 samples of patients who tested positive for diabetes, and the age of the participants ranges from 21 to 99 years old. The dataset was collected according to the indicators and standards of the World Health Organization, making it a reliable source for building diabetes diagnosis models. Researchers and healthcare professionals can use this dataset to train and test machine learning models to predict and diagnose diabetes in patients.

Features of Dataset:
Age
Gender
BMI
SBP (Systolic Blood Pressure)
DBP (Diastolic Blood Pressure)
FPG (Fasting Plasma Glucose)
FFPG (Final Fasting Plasma Glucose)
Cholesterol
Triglyceride
HDL (High-Density Lipoprotein)
LDL (Low-Density Lipoprotein)
ALT (Alanine Aminotransferase)
BUN (Blood urea nitrogen)
CCR (Creatinine Clearance)
Smoking Status: (1: Current Smoker, 2: Ever Smoker, 3: Never Smoker)
Drinking Status: (1: Current Drinker, 2: Ever Drinker,  3: Never Drinker)
Family History of Diabetes: (1: Yes, 0: No)
Diabetes

More details about dataset:
The main dataset, without cleaning, is available at the following link: https://datadryad.org/stash/dataset/doi:10.5061/dryad.ft8750v. 
The main article corresponding to the dataset can be found at: https://doi.org/10.11.../bmjopen-2018-021768

",.csv
Diabeties Dataset,1,diabeties-dataset,diabetes.csv,Apache 2.0,"Dive into the intricate world of diabetes research with this extensive dataset sourced from Kaggle. Featuring a diverse array of variables including patient demographics, medical history, and diagnostic measurements, this dataset provides a rich landscape for in-depth analysis and exploration. Investigate patterns, correlations, and predictive models to enhance our understanding of diabetes risk factors, disease progression, and treatment outcomes. Whether you're a seasoned data scientist, a healthcare professional, or an enthusiast eager to contribute to diabetes research, this dataset offers invaluable insights and opportunities for groundbreaking discoveries in the fight against diabetes. Unlock the potential of data-driven insights to revolutionize diabetes care and management.",.csv
Dialogue Lines of The Simpsons,1,dialogue-lines-of-the-simpsons,simpsons_dataset.csv,CC-BY-SA-3.0,"### Context

I chose to play with the script from the Simpsons, both because I love the Simpsons and because with more than 150k lines of dialogues, the dataset was substantial!

### Content

This dataset contains the characters, locations, episode details, and script lines for approximately 600 Simpsons episodes, dating back to 1989.


### Acknowledgements

Inspiration and credit for gathering the data goes to Todd Schneider:

http://toddwschneider.com/posts/the-simpsons-by-the-data/ <br>
https://github.com/toddwschneider/flim-springfield

and Bukun:

https://www.kaggle.com/ambarish/fun-in-text-mining-with-simpsons/data
",.csv
Diamond dataset,1,diamond-dataset,diamonds.csv,Apache 2.0,"**Context**

This classic dataset contains the prices and other attributes of almost 54,000 diamonds. It's a great dataset for beginners learning to work with data analysis and visualization.

**Content**

price price in US dollars (\$326--\$18,823)

carat weight of the diamond (0.2--5.01)

cut quality of the cut (Fair, Good, Very Good, Premium, Ideal)

color diamond colour, from J (worst) to D (best)

clarity a measurement of how clear the diamond is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best))

x length in mm (0--10.74)

y width in mm (0--58.9)

z depth in mm (0--31.8)

depth total depth percentage = z / mean(x, y) = 2 * z / (x + y) (43--79)

table width of top of diamond relative to widest point (43--95)",.csv
Diamonds Price Dataset ,1,diamonds-price-dataset,diamonds.csv,Community Data License Agreement - Sharing - Version 1.0,"This Dataset represents a range of diamonds with different features such as size, and clarity, And also they have prices!

you can discover different types of diamonds and create a model to predict unseen diamonds too.

|Description|Column|
|:------:|:--------:|
|Diamond weight in carat|<code>carat</code>|
|diamond cutting quality|<code>cut</code>|
|diamond color from J (worst) to D (best)|<code>color</code>|
|A measure of diamond clarity <i>(from left to right is worst to best: I1, SI2, SI1, VS2, VS1, VVS2, VVS1, IF)<i>|<code>clarity</code>|
|diamond length in mm|<code>x</code>|
|diamond width in mm|<code>y</code>|
|diamond depth in mm|<code>z</code>|
|Percentage depth that is equal to z / mean(x,y)|<code>depth</code>|
|The width of the widest point at the top of the diamond|<code>table</code>|
|diamond price|<code>price [target variable]</code>|</i></i>",.csv
Diamonds Prices ,1,diamonds-prices,Diamonds Prices2022.csv,CC-BY-NC-SA-4.0,"
&gt; ## What is Diamonds Prices  Dataset?



This document explores a dataset containing prices and attributes for approximately 54,000 round-cut diamonds.
There are 53,940 diamonds in the dataset with 10 features (carat, cut, color, clarity, depth, table, price, x, y, and z). Most variables are numeric in nature, but the variables cut, color, and clarity are ordered factor variables with the following levels.


**About the currency for the price column: it is ` Price ($)`**

And About the columns x,y, and z they are diamond measurements  as  (( `x:  length in mm, y: width in mm,z:  depth in mm` ))

.


![2022-08-02_171709](https://user-images.githubusercontent.com/36210723/182397020-a1bcc086-d086-4e37-9975-99a762f328c6.png)


.



&gt; ## Acknowledgments


When we use this dataset in our research, we credit the authors as :


- **License** : `CC BY 4.0.`


- The dataset  published  to reuse in [google research dataset ](https://datasetsearch.research.google.com/search?src=0&query=Diamonds%20Prices&docid=L2cvMTFyOW52a2o2cw%3D%3D)



&gt; ###  **The main idea for uploading this dataset is to practice data analysis with my students, as I am working in college and want my student to train our studying ideas in a big dataset, It may be not up to date and I mention the collecting years, but it is  a good resource of data to practice**",.csv
Diamonds Sale Data,1,diamonds-sale-data,diamonds.csv,Apache 2.0,"This classic dataset contains the prices and other attributes of almost 54,000 diamonds. It's a great dataset for beginners learning to work with data analysis and visualisation.",.csv
Diarrheal Diseases,1,diarrheal-diseases,causes-of-death-in-children-under-5 NEW.csv,CC0-1.0,"this graph was created in Loocker,PowerBi and OurDataWorld : 

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F08b171b66fa0a02cd45f9463c6d9ae08%2Fgraph1.png?generation=1712345480096520&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Ff36b97fb4c4dd027c79849d3c4d79bf3%2Fgraph2.jpg?generation=1712345486395022&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F389766848cf4bbc6b7cad14f2e691a82%2Fgraph3.jpg?generation=1712345492867088&alt=media)

Diarrheal diseases have long been recognized as a significant threat to public health, particularly in developing countries where access to clean water and sanitation facilities is limited. In 2019, these diseases claimed the lives of approximately 1.5 million people worldwide, with children bearing a disproportionate burden, accounting for around half a million of these deaths. These staggering figures underscore the urgent need for continued efforts to combat diarrheal diseases and prevent unnecessary loss of life.

Despite the grim statistics, there is reason for cautious optimism. In recent decades, advancements in public health interventions have led to a notable decline in diarrheal-related deaths globally. This progress can be attributed to various factors, including improved access to clean water and sanitation, widespread adoption of oral rehydration treatment, and the implementation of vaccination programs targeting key pathogens.

Central to the fight against diarrheal diseases is the recognition that these deaths are largely preventable. The primary culprits behind these illnesses are pathogens such as bacteria, viruses, and parasites, which thrive in unsanitary conditions and spread through contaminated food and water sources. By addressing the root causes of transmission and bolstering public health infrastructure, significant strides can be made in reducing the burden of diarrheal diseases worldwide.

One of the most effective interventions in preventing diarrheal-related deaths is ensuring universal access to clean water and sanitation facilities. Access to safe drinking water is essential for preventing waterborne pathogens from contaminating food and causing infections. Similarly, proper sanitation practices, including the safe disposal of human waste, are critical for reducing the spread of diarrheal pathogens within communities. By investing in infrastructure and promoting hygiene education, governments and organizations can make substantial gains in preventing diarrheal diseases at their source.

In addition to improving access to clean water and sanitation, the widespread adoption of oral rehydration therapy (ORT) has revolutionized the treatment of diarrheal illnesses. ORT involves administering a solution of salts and sugars orally to restore lost fluids and electrolytes, thereby preventing dehydration and potentially life-threatening complications. This simple yet effective treatment has saved countless lives, particularly in resource-limited settings where access to medical care may be limited.

Furthermore, vaccination plays a crucial role in preventing diarrheal diseases by targeting specific pathogens responsible for causing illness. Vaccines against rotavirus, a leading cause of severe diarrhea in young children, have been instrumental in reducing morbidity and mortality associated with the disease. By expanding access to these vaccines through routine immunization programs, countries can further mitigate the impact of diarrheal diseases on vulnerable populations.

Despite significant progress in combatting diarrheal diseases, considerable challenges remain. Disparities in access to essential health services persist, particularly in low-income countries where infrastructure gaps and socioeconomic barriers hinder progress. Additionally, emerging threats such as antimicrobial resistance pose new challenges to effective treatment and prevention efforts, underscoring the need for ongoing surveillance and innovation in public health strategies.

To sustain and accelerate progress in the fight against diarrheal diseases, concerted action is required on multiple fronts. This includes increased investment in water and sanitation infrastructure, expanded access to ORT and essential medicines, and strengthened immunization programs targeting diarrheal pathogens. Furthermore, efforts to promote hygiene education and behavior change must be integrated into broader health initiatives to ensure lasting impact.

In conclusion, while diarrheal diseases continue to exact a heavy toll on global health, significant strides have been made in reducing mortality rates through targeted interventions and public health initiatives. By building on these achievements and addressing remaining challenges, we can work towards a future where diarrheal diseases are no longer a leading cause of preventable death, particularly among children in underserved communities. Through collective action and sustained commitment to improving health equity, we can realize the vision of a world free from the burden of diarrheal illnesses.",.csv
Did it rain in Seattle? (1948-2017),1,did-it-rain-in-seattle-19482017,seattleWeather_1948-2017.csv,CC0-1.0,"### Context: 

Besides coffee, grunge and technology companies, one of the things that Seattle is most famous for is how often it rains. This dataset contains complete records of daily rainfall patterns from January 1st, 1948 to December 12, 2017. 

### Content

This data was collected at the [Seattle-Tacoma International Airport](https://www.ncdc.noaa.gov/cdo-web/datasets/GHCND/stations/GHCND:USW00024233/detail). The dataset contains five columns: 

* DATE = the date of the observation
* PRCP = the amount of precipitation, in inches 
* TMAX = the maximum temperature for that day, in degrees Fahrenheit
* TMIN = the minimum temperature for that day, in degrees Fahrenheit
* RAIN = TRUE if rain was observed on that day, FALSE if it was not

### Acknowledgements: 

This dataset was compiled by NOAA and is in the public domain.

### Inspiration: 

* Can you use this dataset to build a model of whether it will rain on a specific day given information on the previous days?
* Is there a correlation between the minimum and maximum temperature? Can you predict one given the other?
* Can you model changes in the amount of precipitation over time? Is there seasonality?  ",.csv
Dielectric Breakdown Prediction Dataset,1,dielectric-breakdown-prediction-dataset,data.csv,Apache 2.0,"The challenge of formulating a predictive framework for the electric breakdown behavior of materials  has persisted due to the intricate nature of dielectric degradation and breakdown in materials. This complexity arises from the dynamic interactions among various factors, including the intensity of the electric field, the duration of its application, ambient temperature, and the material's condition, particularly its defects and structural characteristics.

Empirically tracking dielectric degradation, which ultimately leads to breakdown, proves challenging due to the gradual formation and accumulation of defects at both the atomic and nanoscale levels. Therefore, the emphasis of this study is on the **intrinsic dielectric breakdown field**, a quantity calculated from first-principle numerical calculation. This parameter holds particular importance as it represents the maximum electric field that an ideal, defect-free material can withstand, thereby establishing the theoretical threshold for dielectric breakdown.

This dataset contains 82 rows of semiconductor/insulators, 2 columns of materials categories, and 8 columns of experimental/calculated (DFT) features. The prediction target being the intrinsic dielectric breakdown field, which is simplified as ""log_breakdown_field"" in the data file. The logarithm is taken in accordance with the treatments in the original paper. This dataset is intended to serve as an example for data-driven material discovery and for deriving phenomenological laws for electric breakdown field strength prediction.

Citation required:
C. Kim, G. Pilania and R. Ramprasad, Chem. Mater. 28, 1304 (2016).
",.csv
Differentiated Thyroid Cancer Recurrence,1,differentiated-thyroid-cancer-recurrence,Thyroid_Diff.csv,Attribution 4.0 International (CC BY 4.0),"**Overview**

This data set contains 13 clinicopathologic features aiming to predict recurrence of well differentiated thyroid cancer. The data set was collected in duration of 15 years and each patient was followed for at least 10 years.

**Dataset Information**

For what purpose was the dataset created?
It was a part of research in the field of AI and Medicine

Who funded the creation of the dataset?
No funding was provided.

What do the instances in this dataset represent?
Individual patients

Are there recommended data splits?
No

Does the dataset contain data that might be considered sensitive in any way?
No

Has Missing Values?
No

**Introductory Paper**

[Machine learning for risk stratification of thyroid cancer patients: a 15-year cohort study](https://link.springer.com/article/10.1007/s00405-023-08299-w)
By Shiva Borzooei, Giovanni Briganti, Mitra Golparian, Jerome R. Lechien, Aidin Tarokhian. 2023
Published in Head and Neck

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F2003977%2F0487ed5db9403bdec1c9ea9ebacae28d%2FScreenshot%20from%202024-01-19%2013-15-51.png?generation=1705634175457589&alt=media)",.csv
Digikala Comments (Persian Sentiment Analysis),1,digikala-comments-persian-sentiment-analysis,data.csv,DbCL-1.0,"### Context

Where you can test your models for Persian (Farsi) Language.


### Content

This Dataset is all about comments in the Digikala website site. These comments are scraped from Digikala.com and have been labeled based on the stars people who had bought the products gave to them. Also many of the comments are noisy and do not provide a clean data for us and it is not such a reliable source by adding the second label to the data we can ensure a higher accuracy of our training data. For more clarifying the labels: 
**1 indicates suggesting others to buy 
2 means otherwise
3 illustrate a neutral opinion about the product 
4 means the person has rate the product, but not suggest whether to buy or not**
Finally the two or three digits number indicates the satisfaction percentage of the consumer with the preceding comment.


### Inspiration

Your data will be in front of the world's largest data science community. What questions do you want to see answered?",.csv
Digit_recognizer,1,digit-recognizer,s.csv,MIT,"Delve into the fascinating world of digit recognition, where advanced algorithms and machine learning decipher handwritten numbers, revolutionizing fields from finance to digital communication.",.csv
Digital Asset Adoption Sentiment,1,digital-asset-adoption-sentiment-2023,digital_asset_research_second_wave_2023_clean.csv,Apache 2.0,"This dataset is a collection of adoption behavior across various select digital assets. The data is sourced from a random sample of 5000 unique survey respondents, representative of the United State population. This open-source data can be used by researchers, investors, and other interested parties to gain insights into adoption benchmarks for digital asset adoption during this period.

Cross-sectional data is a type of data that is collected at a single point in time and is representative of a population or a group at that particular moment.

The dataset was designed and distributed by **Bitmason**, a leader in Bitcoin adoption, development, and infrastructure research.",.csv
Digital Currencies 2024,1,digital-currencies-2024,datasetbcfinalmiss.csv,other,"This dataset consists of seven columns and 2740 rows collected from thirteen different sources for digital currencies. The dataset includes information on the opening price, closing price, highest price, lowest price, and volume, as well as the percentage change and the currencies collected in March 2024.

 Here's a description of the contents based on the available columns in the data:

Last Price: The most recent recorded price of Bitcoin.
Open Price: The opening price of Bitcoin at the start of the specified time period.
Max: The maximum price of Bitcoin during the specified time period.
Min: The minimum price of Bitcoin during the specified time period.
Size: This may refer to the trading volume of Bitcoin during the specified time period, but requires further clarification to confirm its meaning.
Change Persent: The percentage change in the price of Bitcoin compared to the previous time period, it seems there's a typographical error and it might mean ""Change Percent"".
Class: The classification of the currency, in this context, all the data is classified under ""Bitcoin"".
This data could be useful in financial market analytics, especially for those interested in cryptocurrencies and the dynamics of Bitcoin prices. It can be used to study price changes, market fluctuations, or even to develop models for predicting cryptocurrency prices.

Applications in Machine Learning and Beyond
This dataset, focusing on Bitcoin prices and their fluctuations, has a wide range of applications, especially within the realm of machine learning and financial analysis:

Price Prediction: Utilizing historical data to train models that can predict future Bitcoin prices. Techniques like time series analysis, regression models, and more sophisticated neural networks (e.g., LSTM) could be applied.
Volatility Modeling: Analyzing the variability in Bitcoin prices over time. Machine learning models can help understand patterns in price fluctuations, potentially leading to insights for investors about risk and volatility.
Trend Analysis: Identifying long-term trends in Bitcoin's market performance. Machine learning algorithms can detect underlying patterns and trends, helping investors make informed decisions.
Anomaly Detection: Spotting unusual patterns or outliers in Bitcoin prices that could indicate market manipulation, fraud, or significant market events. Machine learning models, especially unsupervised algorithms, are adept at detecting anomalies.
Sentiment Analysis: By integrating this dataset with social media and news sentiment data, models can assess how public sentiment impacts Bitcoin prices. This involves natural language processing (NLP) techniques to gauge sentiment and correlate it with price movements.
Portfolio Management: In the broader scope of financial management, machine learning models can use such datasets to optimize cryptocurrency portfolios, balancing risk and return based on historical performance.
Risk Assessment: Analyzing the data to evaluate the financial risk associated with Bitcoin investments. Machine learning can provide probabilistic estimates of future price drops or gains, aiding in risk management strategies.
Overall, the detailed data on Bitcoin's pricing and trading volume offers a rich foundation for various analytical and predictive modeling efforts in both academic research and practical financial applications. ​


Collected and Preprocessing: Wisam Abdullah , Dr. Modhar , and Dr. Ahmed Alsardly are lecturers in Tikrit University. ",.csv
Digital Marketing Metrics & KPIs to Measure (SQL),1,analyze-the-marketing-spending,Marketing.csv,CC0-1.0,"Analyze the marketing spending.

1- Overall ROMI
2- ROMI by campaigns
3- Performance of the campaign depending on the date - on which date did we spend the most money on advertising, when we got the biggest revenue when conversion rates were high and low? What were the average order values?
4- When buyers are more active? What is the average revenue on weekdays and weekends?
5- Which types of campaigns work best - social, banner, influencer, or a search?
6- Which geo locations are better for targeting - tier 1 or tier 2 cities?


Column.                                               Description
Date                                                     date of spending of the marketing budget
Campaign name                                  description of campaign
Category                                             type of marketing source
Campaign id                                        unique identifier
Impressions                                         number of times the ad has been shown
Mark. budget                                       money spent on this campaign on this day
Clicks                                                   how many people clicked on a banner (=visited website)
Leads                                                   how many people signed up and left their credentials
Orders                                                  how many people paid for the product
Revenue                                               how much money we earned

Clicks, Leads, orders, and revenue are calculated for a specific marketing campaign on a specific date. E.g. For the “facebook_tier1” marketing campaign on the 1st of February, we spent INR 7,307.37, got 148,263 impressions that converted to 1,210 clicks that in turn converted to 13 leads and 1 order. We earned INR 4,981.

This data reflects some facts about what happened - how much we spent, how much we earned, how customers behaved (who clicked on the ad banner, who signed up, who paid). Now we need to calculate marketing metrics that would help us evaluate if we did a good job or not and also identify some parameters of the campaign that would be important for analysis.
What are these metrics:

* Return on marketing investment (ROMI)
* Cost per click (CPC)
* Cost per lead (CPL)
* Customer acquisition cost (CAC)
* Average order value (AOV)
* Conversion rate 1
* Conversion rate 2

These metrics are actionable and allow us not only to analyze but to make decisions and act to improve the business result.

Let’s dive deeper.

ROMI                                      return on marketing investments, how effective is marketing   
                                               campaign, one metric that shows effectiveness of every rupee spent. 
                                               It is calculated ( Total earning (Revenue) - Marketing cost ) / Marketing cost )

Click-through rate(CTR).       percentage of people who clicked at banner (Clicks/ Impressions)

Conversion 1                          conversion from visitors to leads for this campaign (Leads/Click)

Conversion 2                         conversion rate from leads to sales (Orders/Leads)

Average order value (AOV)   Average order value for this campaign (Revenue/Number of Orders)

Cost per click (CPC)              how much does it cost us to attract 1 click (on average) 
                                               (Marketing spending/Clicks)

Cost per lead (CPL)              how much does it cost us to attract 1 lead (on average)
                                              (Marketing spending/Leads)

Customer acquisition cost (CAC) --  how much does it cost us to attract 1 order (on average)
                                                            (marketing spend/ orders)
Gross profit                           Profit or loss after deducting marketing cost (Revenue-Marketing spending)


ROMI is the most important metric and it is used as the ultimate way to evaluate if the campaign is good or bad.

You can use this article to know more about marketing metrics.
https://www.owox.com/blog/articles/digital-marketing-metrics-and-kpis/",.csv
Digital currency - Time series,1,digital-currency-time-series,dc.csv,CC0-1.0,"### Context

Howdy folks! 

I have prepared a starter dataset for time series practice. This is my 1st upload. Any questions/feedback are welcome. 

### Content

- The data was prepared using Alpha Vantage API
- The data represents historical daily time series for a digital currency (BTC) traded on the Saudi market (SAR/Sudi Riyal)
- Prices and volumes are quoted in both SAR & USD.
- Data date range: 2018-05-11 to 30.01.2021

### Task: Use the past to predict the future!
- Check Tasks tab


### Acknowledgements

Special thanks to all my instructors and friends at GA.",.csv
Disabled Population in India,1,disabled-population-in-india,India-disability-data.csv,other,"### Context

Overall, 1846 and 1499 per lakh population had any type of disability during the survey in rural and urban areas respectively. In some places, people with disabilities are seen as wicked or deceitful, or as unable to progress to adulthood and dependent on charity and pity for assistance. In such scenarios, people with disabilities are often socially segregated, often as a results of ingrained cultural and religious attitudes toward disability.


### Content

The dataset consists of 14 columns having information about people with disabilities across the country. The data is divided for all the states within India.

### Inspiration

Let us all make use of power of ML and come up with various insights to dig deeper in the issue.",.csv
Disaster Tweets,1,disaster-tweets,tweets.csv,CC0-1.0,"### Context

The file contains over 11,000 tweets associated with disaster keywords like “crash”, “quarantine”, and “bush fires” as well as the location and keyword itself. The data structure was inherited from [Disasters on social media](https://appen.com/resources/datasets/)

The tweets were collected on Jan 14th, 2020.

Some of the topics people were tweeting:
- The eruption of Taal Volcano in Batangas, Philippines
- Coronavirus
- Bushfires in Australia
- Iran downing of the airplane flight PS752


Disclaimer: The dataset contains text that may be considered profane, vulgar, or offensive.


### Inspiration
The intention was to enrich the already available data for this topic with newly collected and manually classified tweets.
The initial source **[Disasters on social media](https://appen.com/resources/datasets/)** which is used in **[Real or Not? NLP with Disaster Tweets](https://www.kaggle.com/c/nlp-getting-started)** competition on Kaggle.",.csv
Disasters on social media,1,disasters-on-social-media,socialmedia-disaster-tweets-DFE.csv,CC0-1.0,"### Context
To spot disasters, many institutions rely on social media. Bystanders often post about what is happening making information on social media faster and more informative than news reports. That is, if you know which posts actually are about disasters and which posts are irrelevant. 

This dataset stems from the figure-eight (formally known as Crowdflower) [data for everyone website](https://www.figure-eight.com/data-for-everyone/).


### Content

The dataset is a collection of tweets, hand classified as relevant or irrelevant. See the data section for information about the columns in the CSV file.",.csv
Discogs Electronic Music Dataset ,1,discogs-electronic-music-dataset-1990-2000,discogs_electronic.csv,CC0-1.0,"##Context##
This dataset consists of a subset of electronic music from 1990-2000, mostly Vinyl and some CDs. It's been compiled from Discogs, a renowned database and marketplace for music. The data was collected via web scraping using Python in conjunction with Scrapy. The dataset captures a range of sub-genres within electronic music, such as House, Techno, Tech House, Electro, Progressive House, Hip Hop, and Ambient.


## Content ##
**Artist**: Name of the artist or group who performed or created the music.  
**Title**: Title of the track or album.  
**Label**: Record label that released the music.  
**Country**: The country where the music was released.  
**Format**: The format of the release.  
**Release Date**: The date when the music was released.  
**Genre**: The general genre of the music.  
**Styles**: Specific styles or sub-genres.  
**Have/Want**: Metrics indicating how many people own or want the record.  
**Number of Ratings**: The total number of ratings the record has received.  
**Average Rating**: The average rating out of all received ratings.  
**Price Statistics**: This includes the lowest, median, and highest prices of the records.  



##Inspiration##
**Rarity and Desirability**: Use the want/have ratios to figure out which records or styles are rare or in demand. Find out which records are popular but not widely owned, and see if there's a link between rarity, artist popularity, style, or when the record was released.  
**Geographic Influences**: Examine how the electronic music scene differed across countries. Which countries were leaders in producing electronic music? How did styles vary by region?  
**Artist Popularity and Influence**: Explore which artists were most influential in the 90s. This could be assessed through the number of ratings, average ratings, or the number of people who have/want their records.   

",.csv
Disease Symptoms and Patient Profile Dataset,1,disease-symptoms-and-patient-profile-dataset,Disease_symptom_and_patient_profile_dataset.csv,CC0-1.0,"Note: If you find this dataset useful, Do upvote the dataset so it can reach further kagglers.

Unveil the mysteries of diseases with our Comprehensive Disease Symptom and Patient Profile Dataset. This captivating dataset offers a treasure trove of information, revealing the fascinating connections between symptoms, demographics, and health indicators. Delve into the rich tapestry of fever, cough, fatigue, and difficulty breathing, intertwined with age, gender, blood pressure, and cholesterol levels. Whether you're a medical researcher, healthcare professional, or data enthusiast, this dataset holds the key to unlocking profound insights. Explore the hidden patterns, uncover unique symptom profiles, and embark on a captivating journey through the world of medical conditions. Get ready to revolutionize healthcare understanding with our dataset.

**Columns and Usage:**
&gt;Disease: The name of the disease or medical condition.<br>
Fever: Indicates whether the patient has a fever (Yes/No).<br>
Cough: Indicates whether the patient has a cough (Yes/No).<br>
Fatigue: Indicates whether the patient experiences fatigue (Yes/No).<br>
Difficulty Breathing: Indicates whether the patient has difficulty breathing (Yes/No).<br>
Age: The age of the patient in years.<br>
Gender: The gender of the patient (Male/Female).<br>
Blood Pressure: The blood pressure level of the patient (Normal/High).<br>
Cholesterol Level: The cholesterol level of the patient (Normal/High).<br>
Outcome Variable: The outcome variable indicating the result of the diagnosis or assessment for the specific disease (Positive/Negative).<br>

This dataset can be used by various stakeholders, including:

- Healthcare Professionals: Medical practitioners, doctors, and researchers can utilize this dataset for clinical analysis, research studies, and epidemiological investigations related to different diseases. It can aid in understanding the prevalence and patterns of symptoms among patients with specific medical conditions.


- Medical Researchers: Researchers focused on specific diseases or conditions mentioned in the dataset can utilize it to explore relationships between symptoms, age, gender, and other variables. This data can contribute to developing new insights, treatment strategies, and preventive measures.

- Healthcare Technology Companies: Companies developing healthcare applications, diagnostic tools, or AI algorithms can use this dataset to train and validate their models. The data can assist in the development of predictive models for disease diagnosis or monitoring based on symptoms and patient characteristics.

Find more datasets [here](https://www.kaggle.com/uom190346a/datasets)
",.csv
Diseases Articles,1,diseases-articles,diseases_articles.csv,Apache 2.0,"This dataset encompasses a broad range of information about various diseases, their article headlines, and corresponding tokenization targets using Spacy and BERT libraries. Each entry includes the disease name, associated article headline, and target labels suitable for training and evaluating language processing models employing different tokenization approaches. Created to facilitate research in text processing and further refinement of neural network-based algorithms, this dataset aims to streamline advancements in natural language understanding and processing.


**If you found this dataset helpful and valuable, please upvote it.**",.csv
Disney Movies,1,disney-movies,disney_movies.csv,other,"All Disney movies with their release dates, genre, rating, total gross and inflation adjusted gross(2016).
Disney has produced many movies, this data has all Disney movies till 2016.",.csv
Disney Movies 1937-2016 Gross Income,1,disney-movies-19372016-total-gross,disney_movies_total_gross.csv,CC0-1.0,"# Dataset
Walt Disney Studios is the foundation on which The Walt Disney Company was built. The Studios has produced more than 600 films since its debut film,  Snow White and the Seven Dwarfs in 1937. While many of its films were big hits, some of them were not.  This dataset contains all the movies from 1937 to 2016 that were released by Disney. The data contains 579 Disney movies with six following attributes: 

- movie_title
- release_data
- genre
- mpaa_rating
- total_gross
- inflation_adjusted gross",.csv
Disney Movies and Films Dataset,1,disney-movies-dataset,DisneyMoviesDataset.csv,CC0-1.0,"### Content
The dataset consists of data that was scraped from Wikipedia and cleaned, which comprised a comprehensive list of movies.

### Inspiration
- Predict IMDB Ratings.",.csv
Disney Plus Movies and TV Shows,1,disney-plus-shows,disney_plus_shows.csv,CC0-1.0,"[![forthebadge made-with-python](http://ForTheBadge.com/images/badges/made-with-python.svg)](https://www.python.org/) [![ForTheBadge built-with-love](http://ForTheBadge.com/images/badges/built-with-love.svg)](https://GitHub.com/unanimad/)

---

Please, If you enjoyed this dataset, don't forget to upvote it.

---

### Content

This dataset contains a couple of shows and series are available on [Disney+ stream service](https://disneyplus.com/). Also, this dataset contains Internet Mobie Database (IMDb) ratings that can provide many interesting insights.


---

### Acknowledgements

1. The dataset is collected from [Flixable](https://flixable.com/disney-plus/).
2. The dataset is updated monthly, every 1st day.

---


### Inspiration

1. What is the content available in different countries?
2. Are there similar content by genre, writer or director?
3. Are there similar plot by genre?
4. Which was the biggest title that won most awards?",.csv
Disney World Activities,1,disney-world-florida-parks-activities,activities.csv,Apache 2.0,I extracted this dataset from the Disney World website. It contains the names of all the parks and the activities in each one. I am planning a trip to Disney this month and wanted to get a better idea of what to expect. I hope this helps!,.csv
Disney+ Hotstar Tv and Movie Catalog,1,disney-hotstar-tv-and-movie-catalog,hotstar.csv,CC-BY-SA-3.0,"Disney+ Hotstar (also known as Hotstar) is an Indian brand of subscription video on-demand over-the-top streaming service owned by Novi Digital Entertainment of Disney Star and operated by Disney Media and Entertainment Distribution, both divisions of The Walt Disney Company.

The brand was first introduced as Hotstar for a streaming service carrying content from Disney Star's local networks, including films, television series, live sports, and original programming, as well as featuring content licensed from third-parties such as HBO and Showtime among others. Amid the significant growth of mobile broadband in India, Hotstar quickly became the dominant streaming service in the country.

Following the acquisition of Star India's parent company 21st Century Fox by Disney in 2019, Hotstar was integrated with the company's new global streaming brand Disney+ as 'Disney+ Hotstar' in April 2020. The co-branded service added Disney+ original programming, and films and television series from its main content brands of Walt Disney Studios, Pixar, Marvel Studios, Lucasfilm, and National Geographic alongside the domestic and third-party content already carried on the platform.

Outside of India, the Disney+ Hotstar service also operates in Indonesia, Malaysia, and Thailand, which similarly combines entertainment content licensed from local, third-party studios, with the larger Disney+ library. Disney+ Hotstar is also expected to launch in the Philippines and Vietnam in the end of 2022. In Singapore, Canada, and the United Kingdom, Hotstar operates as a streaming service targeting overseas Indians, focusing on Disney Star's domestic entertainment and sports content; Disney+ operates as a standalone service in these markets. In 2021, Disney announced that it would discontinue the U.S. version of Hotstar in November 2021, in favor of adding its content to the domestic Hulu and ESPN+ services instead.",.csv
Diversity in Tech Companies,1,diversity-in-tech-companies,Diversity in tech companies.csv,CC0-1.0,"This dataset provides a comprehensive breakdown of employee demographics, focusing on cultural and gender diversity, in key technology companies from the years 2014 to 2018. It includes the percentage of female and male employees, as well as the percentage of employees from different ethnic backgrounds, including White, Asian, Latino, Black, and others. The dataset aims to shed light on the diversity landscape within these tech giants, offering valuable insights for diversity and inclusion initiatives in the tech industry.",.csv
Divorce Prediction,1,divorce-prediction,divorce_data.csv,other,"# Abstract
&gt; Ever been heart broken and/or wondered what makes a lasting relationship? This dataset may help you.

# About this dataset
&gt; This dataset contains data about 150 couples with their corresponding Divorce Predictors Scale variables (DPS) on the basis of Gottman couples therapy.
The couples are from various regions of Turkey wherein the records were acquired from face-to-face interviews from couples who were already divorced or happily married.
All responses were collected on a 5 point scale (0=Never, 1=Seldom, 2=Averagely, 3=Frequently, 4=Always).

# How to use
&gt;- Predict divorce events
- Explore predictive factors that lead to divorce
- [More datasets](https://www.kaggle.com/andrewmvd/datasets)

# Acknowledgements
If you use this dataset in your research, please credit the authors.

&gt; ### Citation
Yöntem, M , Adem, K , İlhan, T , Kılıçarslan, S. (2019). DIVORCE PREDICTION USING CORRELATION BASED FEATURE SELECTION AND ARTIFICIAL NEURAL NETWORKS. Nevşehir Hacı Bektaş Veli University SBE Dergisi, 9 (1), 259-273. ([link](https://dergipark.org.tr/tr/download/article-file/748448))

&gt; ### License
License was not specified at the source.

&gt; ### Splash icon
Icon by [Freepik](https://www.flaticon.com/authors/freepik) available on [Flaticon](https://www.flaticon.com/free-icon/broken-heart_555706)

&gt; ### Splash banner
Photo by [Kelly Sikkema](https://unsplash.com/@kellysikkema) on [Unsplash](https://unsplash.com/photos/E8H76nY1v6Q)",.csv
Diwali Sales Dataset,1,diwali-sales-dataset,Diwali Sales Data.csv,CC0-1.0,"| **Column Name**       | **Description**                                     |
|-------------------|-------------------------------------------------|
| User_ID           | User identification number                     |
| Cust_name         | Customer name                                   |
| Product_ID        | Product identification number                  |
| Gender            | Gender of the customer (e.g., Male, Female)    |
| Age Group         | Age group of the customer                      |
| Age               | Age of the customer                            |
| Marital_Status    | Marital status of the customer (e.g., Married, Single) |
| State             | State of the customer                          |
| Zone              | Geographic zone of the customer                |
| Occupation        | Customer's occupation                          |
| Product_Category  | Category of the product                        |
| Orders            | Number of orders made by the customer          |
| Amount            | Amount spent by the customer                   |
| Status            | Empty Column |
| unnamed1          | Empty Column |",.csv
Dog Intelligence Comparison Based on Size,1,dog-intelligence-comparison-based-on-size,Dog Intelligence.csv,CC0-1.0,"This dataset is based on research by Stanley Coren, a professor of canine psychology at Univ. of BC.

This dataset is based on research by Stanley Coren, a professor of canine psychology at the University of British Columbia. When Coren first published his book in 1994, there was a high degree of dispute of his analysis, though over time his work has been largely accepted.

Source: https://en.m.wikipedia.org/wiki/The_Intelligence_of_Dogs#cite_ref-ReferenceA_18-0",.csv
Dog breeds,1,dog-breeds,dog_breeds.csv,CC0-1.0,"Who doesn't love dogs? 🐕  Those wonderful creatures make our life so much better! So if you love dogs as much as I do, you'd be probably interested in this dataset. 

It includes the name of the breed, country of origin, longevity, height, color of fur and eyes, their character traits and typical health problems for each breed.",.csv
Dogecoin Historical Data,1,dogecoin-historical-data,DOGE-USD.csv,CC0-1.0,"## Introduction

Dogecoin is an open source peer-to-peer digital currency, favored by Shiba Inus worldwide. It is qualitatively more fun while being technically nearly identical to its close relative Bitcoin. This dataset contains its historical stock price in USD on a daily frequency starting from 17 September 2014.

For more information refer to https://dogecoin.com/

## Credits

Image Credits: [Unsplash - claybanks](https://unsplash.com/photos/NPlMmVsC40I)",.csv
Dollar Vs Asian Currencies,1,dollar-vs-asian-currencies,Dollar-Exchange.csv,world-bank,"Examining the amount of changes in the exchange rate of two currencies can help us with many issues. Like investment, life, and more.
In this dataset, the exchange rates of a 37 Asian countries have been compared against the dollar.
This is a time series dataset and has been recorded from 2004 to 2022. Based on the Asian Development Bank website, it has been collected in order to compare different Asian countries in relation to the dollar. By fully comparing this dataset, you can compare different countries in terms of currency value.
Enjoy the analysis of this data set and make it more visible by **voting** for this data.💯✔️
More information about currencies:
CNY = Chinese Yuan
OMR = Omani Rial
IRR = Irani Rial
THB = Thai Baht
SYP = Syrian Pound
MYR = Malaysian Ringgit
YER = Yemenei Rial
VND = Vietnamese Dong
ILS = Israeli New Shekel
JPY = Japanese Yen
LKR = Sri Lanka Rupee
IQD = Iraqi Dinar
PKR = Pakistani Rupee
KWD = Kuwaiti Dinar
KHR = Cambodian Riel
UZS = Uzbekistani SOM
SGD = Singapore Dollar
INR = Indian Rupee
BDT = Bangladeshi Taka
PHP = Philippine Peso
JOD = Jordanian Dinar
LAK = Lao Kip
IDR = Indonesian Rupiah
KRW = South Korean Won
KZT = Kazakhstani Tenge
ADE = UAE Dirham
BHD = Bahraini Dinar
LBP = Lebanese Pound
TRY = Turkish Lira
TMT = Turkmenistani Manat
SAR = Saudi Riyal
MVR = Maldivian Rufiyaa
QAR = Qatari Riyal
MMK = Burmese Kyat
NPR = Nepalese Rupee
BND = Brunei Dollar
AFN = Afghan Afghani",.csv
Domestic violence in Colombia,1,domestic-violence-in-colombia,Reporte_Delito_Violencia_Intrafamiliar_Polic_a_Nacional.csv,CC0-1.0,"### Context

This is a compilation of data on domestic violence that has been developing in Colombia over time.


### Content

It is divided between

**Departments**: which are political and administrative divisions that make up the national territory.

**Municipalities**: Which correspond to the second level of administrative division in Colombia

**DANE Code**: It is a standardized nomenclature, designed by DANE for the identification of Territorial Entities (departments, districts and municipalities), Non-Municipalized Areas and Populated Centers, by assigning a unique numerical code to each of these territorial units.

**Weapons Medium**: Which is an allowance for the items that were used to commit the act of violence
**Date Made**: Which describes the day on which the violent event took place

**Gender**: Sex of the victim
**Quantity**: Number of people who have been injured
",.csv
Dota 2 Hero Stat Showcase: Patchwise Overview,1,dota-2-hero-stat-showcase-patchwise-overview,dota2_hero_stats.csv,Apache 2.0,"# Dota 2 Hero Performance Analysis: Patchwise Insights

![Dota2](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F1937611%2F51ffc92e75717961ffc0501fa9b300bc%2F2424049e3abddf0832c68381afaccf2f.jpeg?generation=1715252548682954&alt=media)

The dataset aims to provide insights into the performance of Dota 2 heroes across various patches. Here's a breakdown of the columns in the dataset:

- **Hero**: The name of the Dota 2 hero.
- **Win Rate**: The win rate of the hero, indicating the percentage of games won when the hero is picked.
- **Pick Rate**: The pick rate of the hero, representing the frequency at which the hero is selected in matches.
- **KDA Ratio**: The Kill-Death-Assist (KDA) ratio of the hero, providing an overall measure of performance in battles.
- **Patch**: The version or patch of Dota 2 in which the hero performance data was collected.

This analysis aims to achieve the following objectives:

1. **Understand Hero Performance**: Analyze win rates, pick rates, and KDA ratios to understand the performance of Dota 2 heroes across different patches.

2. **Identify Meta Trends**: Identify trends in hero popularity and effectiveness over time, shedding light on the evolving meta-game of Dota 2.

3. **Assess Balance Changes**: Evaluate the impact of balance changes and updates introduced in different patches on hero performance and player strategies.

4. **Inform Player Strategies**: Provide insights to Dota 2 players and enthusiasts to inform their hero selection strategies and gameplay decisions.

5. **Track Patchwise Dynamics**: Track changes in hero performance metrics across patches to anticipate meta shifts and adapt gameplay accordingly.

By analyzing this dataset, players, analysts, and enthusiasts can gain valuable insights into the performance dynamics of Dota 2 heroes and make informed decisions to enhance their gameplay experience.
",.csv
Dragon Ball Z Characters,1,dragon-ball-z-characters-information,dragon_ball_z.csv,CC-BY-SA-4.0,"**Dataset Description:**

This dataset contains information about various characters from the popular anime series Dragon Ball Z. Each row represents a different character, including details such as their race, gender, power level, key techniques, speed, special attacks, and transformations. The dataset aims to provide insights into the diverse range of characters in the Dragon Ball Z universe and their unique abilities.

**Problem Statement:**

The goal of this dataset is to analyze the characteristics and abilities of Dragon Ball Z characters to gain insights into their strengths, weaknesses, and transformations. This analysis can be used for various purposes, such as understanding the dynamics of battles, predicting the outcomes of confrontations, or exploring the evolution of characters throughout the series.",.csv
Drake Lyrics,1,drake-lyrics,drake_data.csv,other,"### Context

This is a dataset consisting of Drake lyrics and other information gathered from [Genius.com](https://genius.com/artists/Drake). I'm currently working on a side project while enrolled in the Data Science program at Flatiron. I've lovingly entitled this project ""[Ye-Spirations](https://github.com/Juicob/ye-spirations)"" which will essentially be a motivational poster generator that renders high-quality images with random lines of text generated from hip hop lyrics. I have a simple prototype built out with Kanye lyrics but I would like to continue working on it and add additional features before sharing a final version. I intend on expanding the artist options for lyrics which brings me here. This dataset is a byproduct of the expansion (which I am excited to call ""Inspo-Papi"") and I wanted to publish this for others to use for their own projects or even my future self. 

### Content

This dataset contains 3 files. 
.txt - lyrics only
.json - lyrics, song title, album title, url, view count (at this time)
.csv - lyrics, song title, album title, url, view count (at this time)


### Acknowledgements

Data gathered from the GOAT of lyrics and annotations - [Genius.com](https://genius.com/artists/Drake)

### Requests

I intend on expanding to multiple artists so if y'all have any requests feel free to shout em out!",.csv
Dropout and Success: Student Data Analysis,1,dropout-and-success-student-data-analysis,student_data.csv,Apache 2.0,"## Summary
dataset created from a higher education institution (acquired from several disjoint databases) related to students enrolled in different undergraduate degrees, such as agronomy, design, education, nursing, journalism, management, social service, and technologies. The dataset includes information known at the time of student enrollment (academic path, demographics, and social-economic factors) and the students' academic performance at the end of the first and second semesters. The data is used to build classification models to predict students' dropout and academic sucess. The problem is formulated as a three category classification task, in which there is a strong imbalance towards one of the classes.

## Introduction
This dataset delves into the correlation between dropout rates and student success in various educational settings. It includes comprehensive information on student demographics, academic performance, and factors contributing to dropout incidents. The dataset aims to provide valuable insights for educators, policymakers, and researchers to enhance strategies for fostering student retention and academic achievement.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F17474923%2Fc00e9ef81fed562fd0f70e620fef80f7%2Fcollege-dropouts1.jpg?generation=1704037747011701&alt=media)

## Dataset
The dataset includes information known at the time of student enrollment – academic path, demographics, and social-economic factors. 

**- Marital status:** Categorical variable indicating the marital status of the individual. 
(1 – single 2 – married 3 – widower 4 – divorced 5 – facto union 6 – legally separated)

**- Application mode:** Categorical variable indicating the mode of application.
(1 - 1st phase - general contingent 2 - Ordinance No. 612/93 5 - 1st phase - special contingent (Azores Island) 7 - Holders of other higher courses 10 - Ordinance No. 854-B/99 15 - International student (bachelor) 16 - 1st phase - special contingent (Madeira Island) 17 - 2nd phase - general contingent 18 - 3rd phase - general contingent 26 - Ordinance No. 533-A/99, item b2) (Different Plan) 27 - Ordinance No. 533-A/99, item b3 (Other Institution) 39 - Over 23 years old 42 - Transfer 43 - Change of course 44 - Technological specialization diploma holders 51 - Change of institution/course 53 - Short cycle diploma holders 57 - Change of institution/course (International)).

**- Application order:** Numeric variable indicating the order of application.
(between 0 - first choice; and 9 last choice).

**- Course:** Categorical variable indicating the chosen course.
(33 - Biofuel Production Technologies 171 - Animation and Multimedia Design 8014 - Social Service (evening attendance) 9003 - Agronomy 9070 - Communication Design 9085 - Veterinary Nursing 9119 - Informatics Engineering 9130 - Equinculture 9147 - Management 9238 - Social Service 9254 - Tourism 9500 - Nursing 9556 - Oral Hygiene 9670 - Advertising and Marketing Management 9773 - Journalism and Communication 9853 - Basic Education 9991 - Management (evening attendance)).

**- evening attendance:** Binary variable indicating whether the individual attends classes during the daytime or evening. 
(1 for daytime, 0 for evening).

**- Previous qualification:** Numeric variable indicating the level of the previous qualification.
(1 - Secondary education 2 - Higher education - bachelor's degree 3 - Higher education - degree 4 - Higher education - master's 5 - Higher education - doctorate 6 - Frequency of higher education 9 - 12th year of schooling - not completed 10 - 11th year of schooling - not completed 12 - Other - 11th year of schooling 14 - 10th year of schooling 15 - 10th year of schooling - not completed 19 - Basic education 3rd cycle (9th/10th/11th year) or equiv. 38 - Basic education 2nd cycle (6th/7th/8th year) or equiv. 39 - Technological specialization course 40 - Higher education - degree (1st cycle) 42 - Professional higher technical course 43 - Higher education - master (2nd cycle)).

**- Nationality:** Categorical variable indicating the nationality of the individual. 
(1 - Portuguese; 2 - German; 6 - Spanish; 11 - Italian; 13 - Dutch; 14 - English; 17 - Lithuanian; 21 - Angolan; 22 - Cape Verdean; 24 - Guinean; 25 - Mozambican; 26 - Santomean; 32 - Turkish; 41 - Brazilian; 62 - Romanian; 100 - Moldova (Republic of); 101 - Mexican; 103 - Ukrainian; 105 - Russian; 108 - Cuban; 109 - Colombian).

**- Mother's qualification:** Numeric variable indicating the level of the mother's qualification.   
(1 - Secondary Education - 12th Year of Schooling or Eq. 2 - Higher Education - Bachelor's Degree 3 - Higher Education - Degree 4 - Higher Education - Master's 5 - Higher Education - Doctorate 6 - Frequency of Higher Education 9 - 12th Year of Schooling - Not Completed 10 - 11th Year of Schooling - Not Completed 11 - 7th Year (Old) 12 - Other - 11th Year of Schooling 14 - 10th Year of Schooling 18 - General commerce course 19 - Basic Education 3rd Cycle (9th/10th/11th Year) or Equiv. 22 - Technical-professional course 26 - 7th year of schooling 27 - 2nd cycle of the general high school course 29 - 9th Year of Schooling - Not Completed 30 - 8th year of schooling 34 - Unknown 35 - Can't read or write 36 - Can read without having a 4th year of schooling 37 - Basic education 1st cycle (4th/5th year) or equiv. 38 - Basic Education 2nd Cycle (6th/7th/8th Year) or Equiv. 39 - Technological specialization course 40 - Higher education - degree (1st cycle) 41 - Specialized higher studies course 42 - Professional higher technical course 43 - Higher Education - Master (2nd cycle) 44 - Higher Education - Doctorate (3rd cycle)).

**- Father's qualification:** Numeric variable indicating the level of the father's qualification.  
(1 - Secondary Education - 12th Year of Schooling or Eq. 2 - Higher Education - Bachelor's Degree 3 - Higher Education - Degree 4 - Higher Education - Master's 5 - Higher Education - Doctorate 6 - Frequency of Higher Education 9 - 12th Year of Schooling - Not Completed 10 - 11th Year of Schooling - Not Completed 11 - 7th Year (Old) 12 - Other - 11th Year of Schooling 13 - 2nd year complementary high school course 14 - 10th Year of Schooling 18 - General commerce course 19 - Basic Education 3rd Cycle (9th/10th/11th Year) or Equiv. 20 - Complementary High School Course 22 - Technical-professional course 25 - Complementary High School Course - not concluded 26 - 7th year of schooling 27 - 2nd cycle of the general high school course 29 - 9th Year of Schooling - Not Completed 30 - 8th year of schooling 31 - General Course of Administration and Commerce 33 - Supplementary Accounting and Administration 34 - Unknown 35 - Can't read or write 36 - Can read without having a 4th year of schooling 37 - Basic education 1st cycle (4th/5th year) or equiv. 38 - Basic Education 2nd Cycle (6th/7th/8th Year) or Equiv. 39 - Technological specialization course 40 - Higher education - degree (1st cycle) 41 - Specialized higher studies course 42 - Professional higher technical course 43 - Higher Education - Master (2nd cycle) 44 - Higher Education - Doctorate (3rd cycle)).

**- Mother's occupation:** Categorical variable indicating the mother's occupation.   
(0 - Student 1 - Representatives of the Legislative Power and Executive Bodies, Directors, Directors and Executive Managers 2 - Specialists in Intellectual and Scientific Activities 3 - Intermediate Level Technicians and Professions 4 - Administrative staff 5 - Personal Services, Security and Safety Workers and Sellers 6 - Farmers and Skilled Workers in Agriculture, Fisheries and Forestry 7 - Skilled Workers in Industry, Construction and Craftsmen 8 - Installation and Machine Operators and Assembly Workers 9 - Unskilled Workers 10 - Armed Forces Professions 90 - Other Situation 99 - (blank) 122 - Health professionals 123 - teachers 125 - Specialists in information and communication technologies (ICT) 131 - Intermediate level science and engineering technicians and professions 132 - Technicians and professionals, of intermediate level of health 134 - Intermediate level technicians from legal, social, sports, cultural and similar services 141 - Office workers, secretaries in general and data processing operators 143 - Data, accounting, statistical, financial services and registry-related operators 144 - Other administrative support staff 151 - personal service workers 152 - sellers 153 - Personal care workers and the like 171 - Skilled construction workers and the like, except electricians 173 - Skilled workers in printing, precision instrument manufacturing, jewelers, artisans and the like 175 - Workers in food processing, woodworking, clothing and other industries and crafts 191 - cleaning workers 192 - Unskilled workers in agriculture, animal production, fisheries and forestry 193 - Unskilled workers in extractive industry, construction, manufacturing and transport 194 - Meal preparation assistants).

**- Father's occupation:** Categorical variable indicating the father's occupation.  
(0 - Student 1 - Representatives of the Legislative Power and Executive Bodies, Directors, Directors and Executive Managers 2 - Specialists in Intellectual and Scientific Activities 3 - Intermediate Level Technicians and Professions 4 - Administrative staff 5 - Personal Services, Security and Safety Workers and Sellers 6 - Farmers and Skilled Workers in Agriculture, Fisheries and Forestry 7 - Skilled Workers in Industry, Construction and Craftsmen 8 - Installation and Machine Operators and Assembly Workers 9 - Unskilled Workers 10 - Armed Forces Professions 90 - Other Situation 99 - (blank) 101 - Armed Forces Officers 102 - Armed Forces Sergeants 103 - Other Armed Forces personnel 112 - Directors of administrative and commercial services 114 - Hotel, catering, trade and other services directors 121 - Specialists in the physical sciences, mathematics, engineering and related techniques 122 - Health professionals 123 - teachers 124 - Specialists in finance, accounting, administrative organization, public and commercial relations 131 - Intermediate level science and engineering technicians and professions 132 - Technicians and professionals, of intermediate level of health 134 - Intermediate level technicians from legal, social, sports, cultural and similar services 135 - Information and communication technology technicians 141 - Office workers, secretaries in general and data processing operators 143 - Data, accounting, statistical, financial services and registry-related operators 144 - Other administrative support staff 151 - personal service workers 152 - sellers 153 - Personal care workers and the like 154 - Protection and security services personnel 161 - Market-oriented farmers and skilled agricultural and animal production workers 163 - Farmers, livestock keepers, fishermen, hunters and gatherers, subsistence 171 - Skilled construction workers and the like, except electricians 172 - Skilled workers in metallurgy, metalworking and similar 174 - Skilled workers in electricity and electronics 175 - Workers in food processing, woodworking, clothing and other industries and crafts 181 - Fixed plant and machine operators 182 - assembly workers 183 - Vehicle drivers and mobile equipment operators 192 - Unskilled workers in agriculture, animal production, fisheries and forestry 193 - Unskilled workers in extractive industry, construction, manufacturing and transport 194 - Meal preparation assistants 195 - Street vendors (except food) and street service providers).

**- Displaced:** Binary variable indicating whether the individual has been displaced (1 – yes 0 – no).

**- Educational special needs:** Binary variable indicating whether the individual has educational special needs (1 for yes, 0 for no).

**- Debtor**: Binary variable indicating whether the individual is a debtor (1 for yes, 0 for no).

**- Tuition fees up to date:** Binary variable indicating whether the tuition fees are up to date (1 for yes, 0 for no).

**- Gender:** Binary variable indicating the gender of the individual (1 for male, 0 for female).

**- Scholarship holder:** Binary variable indicating whether the individual holds a scholarship (1 for yes, 0 for no).

**- Age at enrollment:** Numeric variable indicating the age of the individual at the time of enrollment.

**- International:** Binary variable indicating whether the individual is international (1 for yes, 0 for no).

**- Curricular units 1st sem (credited):** Numeric variable indicating the number of credited curricular units in the 1st semester.

**- Curricular units 1st sem (enrolled):** Numeric variable indicating the number of enrolled curricular units in the 1st semester.

**- Curricular units 1st sem (evaluations):** Numeric variable indicating the number of evaluations for curricular units in the 1st semester.

**- Curricular units 1st sem (approved):** Numeric variable indicating the number of approved curricular units in the 1st semester.

**- Curricular units 1st sem (grade):** Numeric variable indicating the average grade for curricular units in the 1st semester.

**- Curricular units 1st sem (without evaluations):** Numeric variable indicating the number of curricular units in the 1st semester without evaluations.

**- Curricular units 2nd sem (credited):** Numeric variable indicating the number of credited curricular units in the 2nd semester.

**- Curricular units 2nd sem (enrolled):** Numeric variable indicating the number of enrolled curricular units in the 2nd semester.

**- Curricular units 2nd sem (evaluations):** Numeric variable indicating the number of evaluations for curricular units in the 2nd semester.

**- Curricular units 2nd sem (approved):** Numeric variable indicating the number of approved curricular units in the 2nd semester.

**- Curricular units 2nd sem (grade):** Numeric variable indicating the average grade for curricular units in the 2nd semester.

**- Curricular units 2nd sem (without evaluations):** Numeric variable indicating the number of curricular units in the 2nd semester without evaluations.

**- Unemployment rate:** variable indicating the unemployment rate(Unemployment rate (%)).

**- Inflation rate:** Numeric variable indicating the inflation rate(Inflation rate (%)).

**- GDP:** Numeric variable indicating the Gross Domestic Product.

**- output:** Categorical variable indicating the target variable (e.g., Dropout, Graduate, Enrolled).
",.csv
Drug Classification,1,drug-classification,drug200.csv,CC0-1.0,"### Context

Since as a beginner in machine learning it would be a great opportunity to try some techniques to predict the outcome of the drugs that might be accurate for the patient. 


### Content

#### The target feature is 
- Drug type

#### The feature sets are:
- Age
- Sex
- Blood Pressure Levels (BP)
- Cholesterol Levels
- Na to Potassium Ration

### Inspiration

The main problem here in not just the feature sets and target sets but also the approach that is taken in solving these types of problems as a beginner. So best of luck.",.csv
Drug Use By Age,1,drug-use-by-age,drug-use-by-age.csv,Attribution 4.0 International (CC BY 4.0),"# Drug Use By Age

This directory contains data behind the story [How Baby Boomers Get High](http://fivethirtyeight.com/datalab/how-baby-boomers-get-high/). It covers 13 drugs across 17 age groups.

Source: [National Survey on Drug Use and Health from the Substance Abuse and Mental Health Data Archive](http://www.icpsr.umich.edu/icpsrweb/content/SAMHDA/index.html).

Header | Definition
---|---------
`alcohol-use` | Percentage of those in an age group who used alcohol in the past 12 months
`alcohol-frequency` | Median number of times a user in an age group used alcohol in the past 12 months
`marijuana-use` | Percentage of those in an age group who used marijuana in the past 12 months
`marijuana-frequency` | Median number of times a user in an age group used marijuana in the past 12 months
`cocaine-use` | Percentage of those in an age group who used cocaine in the past 12 months
`cocaine-frequency` | Median number of times a user in an age group used cocaine in the past 12 months
`crack-use` | Percentage of those in an age group who used crack in the past 12 months
`crack-frequency` | Median number of times a user in an age group used crack in the past 12 months
`heroin-use` | Percentage of those in an age group who used heroin in the past 12 months
`heroin-frequency` | Median number of times a user in an age group used heroin in the past 12 months
`hallucinogen-use` | Percentage of those in an age group who used hallucinogens in the past 12 months
`hallucinogen-frequency` | Median number of times a user in an age group used hallucinogens in the past 12 months
`inhalant-use` | Percentage of those in an age group who used inhalants in the past 12 months
`inhalant-frequency` | Median number of times a user in an age group used inhalants in the past 12 months
`pain-releiver-use` | Percentage of those in an age group who used pain relievers in the past 12 months
`pain-releiver-frequency` | Median number of times a user in an age group used pain relievers in the past 12 months
`oxycontin-use` | Percentage of those in an age group who used oxycontin in the past 12 months
`oxycontin-frequency` | Median number of times a user in an age group used oxycontin in the past 12 months
`tranquilizer-use` | Percentage of those in an age group who used tranquilizer in the past 12 months
`tranquilizer-frequency` | Median number of times a user in an age group used tranquilizer in the past 12 months
`stimulant-use` | Percentage of those in an age group who used stimulants in the past 12 months
`stimulant-frequency` | Median number of times a user in an age group used stimulants in the past 12 months
`meth-use` | Percentage of those in an age group who used meth in the past 12 months
`meth-frequency` | Median number of times a user in an age group used meth in the past 12 months
`sedative-use` | Percentage of those in an age group who used sedatives in the past 12 months
`sedative-frequency` | Median number of times a user in an age group used sedatives in the past 12 months
",.csv
Drug overdose death,1,drug-overdose-death,drug-overdose-death-rates new.csv,CC0-1.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F8a1e63df085793d18e2d1fa2109ebd44%2Fgrap%20video%201.gif?generation=1708634385396138&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F296225796c579724b56cb1d746475d93%2FToday%20(1).gif?generation=1708634392024756&alt=media)

Annual number of deaths in the United States from drug overdose per 100,000 people.
Overdoses can result from intentional excessive use of a substance, but can also result from 'poisoning' where substances have been
altered or mixed, such that the user is unaware of the drug's potency.


The data of this indicator is based on the following sources:
US Centers for Disease Control and Prevention WONDER
Data published by
US Centers for Disease Control and Prevention WONDER

Retrieved from
https://www.drugabuse.gov/related-topics/trends-statistics/overdose-death-rates
How we process data at Our World in Data:
All data and visualizations on Our World in Data rely on data sourced from one or several original data providers. Preparing this original data involves several processing steps. Depending on the data, this can include standardizing country names and world region definitions, converting units, calculating derived indicators such as per capita measures, as well as adding or adapting metadata such as the name or the description given to an indicator.

At the link below you can find a detailed description of the structure of our data pipeline, including links to all the code used to prepare data across Our World in Data.

Read about our data pipeline
How to cite this data:
In-line citation
If you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:

Any opioids
Deaths per 100,000 people attributed to any opioids.

Source
US Centers for Disease Control and Prevention WONDER – processed by Our World in Data
Unit
deaths per 100,000",.csv
Drug overdose deaths,1,drug-overdose-deaths,drug_deaths.csv,CC0-1.0,"### Context

The rate of overdose deaths in Connecticut increased from 9.9 per 100,000 residents in 2012 to 28.5 per 100,000 residents in 2018-a 221 % increase-with the majority occurring among persons aged 35-64 (65.3 %), men (73.9 %), and non-Hispanic whites (78.5 %). Among deaths involving fentanyl, the overall deaths escalated from 5.2 deaths per 100,000 residents in 2015 to 21.3 deaths per 100,000 residents in 2018 and more than 50% of these fentanyl-related deaths involved polysubstance use.

### Inspiration
- To examine trends in polysubstance detection associated with drug-related overdose deaths
",.csv
"Drug samples collected in Lagos State, Nigeria",1,drug-samples-collected-in-lagos-state-nigeria,pone.0211567.s001 (1).csv,other,"including the price of drug samples, the amount of active drug substance, the level of purity and the socio-economic status of the local government area where the drug is procured from.
",.csv
Dry Bean Dataset Classification,1,dry-bean-dataset-classification,Dry_Bean_Dataset.csv,other,"**Relevant Information:**
Seven different types of dry beans were used in this research, taking into account the features such as form, shape, type, and structure by the market situation. A computer vision system was developed to distinguish seven different registered varieties of dry beans with similar features in order to obtain uniform seed classification. For the classification model, images of 13,611 grains of 7 different registered dry beans were taken with a high-resolution camera. Bean images obtained by computer vision system were subjected to segmentation and feature extraction stages, and a total of 16 features; 12 dimensions and 4 shape forms, were obtained from the grains.",.csv
"Dubai Real Estate Goldmine, UAE Rental Market Data",1,real-estate-goldmine-dubai-uae-rental-market,dubai_properties.csv,Apache 2.0,"## Dubai, UAE Rental Properties Dataset
<h1 style=""font-family: &quot;poppins&quot;; font-weight: bold; color: rgba(0, 128, 0, 1)"">👨‍💻 Author: Azhar Saleem</h1>

[![GitHub](https://img.shields.io/badge/GitHub-Profile-blue?style=for-the-badge&logo=github)](https://github.com/azharsaleem18) [![Kaggle](https://img.shields.io/badge/Kaggle-Profile-blue?style=for-the-badge&logo=kaggle)](https://www.kaggle.com/azharsaleem) [![LinkedIn](https://img.shields.io/badge/LinkedIn-Profile-blue?style=for-the-badge&logo=linkedin)](https://www.linkedin.com/in/azhar-saleem/) 

[![YouTube](https://img.shields.io/badge/YouTube-Profile-red?style=for-the-badge&logo=youtube)](https://www.youtube.com/@AzharSaleem19) [![Facebook](https://img.shields.io/badge/Facebook-Profile-blue?style=for-the-badge&logo=facebook)](https://www.facebook.com/azhar.saleem1472/) [![TikTok](https://img.shields.io/badge/TikTok-Profile-black?style=for-the-badge&logo=tiktok)](https://www.tiktok.com/@azhar_saleem18) 

[![Twitter/X](https://img.shields.io/badge/Twitter-Profile-blue?style=for-the-badge&logo=twitter)](https://twitter.com/azhar_saleem18) [![Instagram](https://img.shields.io/badge/Instagram-Profile-blue?style=for-the-badge&logo=instagram)](https://www.instagram.com/azhar_saleem18/) [![Email](https://img.shields.io/badge/Email-Contact%20Me-red?style=for-the-badge&logo=email)](mailto:azharsaleem6@gmail.com)

This dataset presents a comprehensive overview of rental property listings across multiple cities in the United Arab Emirates, including Abu Dhabi, Dubai, Sharjah, Ajman, Ras Al Khaimah, Umm Al Quwain, and Al Ain. Compiled from bayut.com, it is a valuable resource for Data Analysts, Data Scientists, and Researchers looking to explore real estate trends, rental pricing patterns, or urban development studies in the UAE.

### Dataset Overview

Each entry in the dataset represents a rental property listing with details about the property's features, rental terms, and location specifics. This primary and unique dataset is designed for analysis and can be used to generate insights into the rental market dynamics of the UAE.

### Columns Description

- **Address**: Full address of the property.
- **Rent**: The annual rent price in AED.
- **Beds**: Number of bedrooms in the property.
- **Baths**: Number of bathrooms in the property.
- **Type**: Type of property (e.g., Apartment, Villa, Penthouse).
- **Area_in_sqft**: Total area of the property in square feet.
- **Rent_per_sqft**: Rent price per square foot, calculated as Rent divided by Area_in_sqft.
- **Rent_category**: Categorization of the rent price (Low, Medium, High) based on thresholds.
- **Frequency**: Rental payment frequency, which is consistently 'Yearly'.
- **Furnishing**: Furnishing status of the property (Furnished, Unfurnished).
- **Purpose**: The purpose of the listing, typically 'For Rent'.
- **Posted_date**: The date the property was listed for rent.
- **Age_of_listing_in_days**: The number of days the listing has been active since it was posted.
- **Location**: A more specific location within the city where the property is located.
- **City**: City in which the property is situated.
- **Latitude**, **Longitude**: Geographic coordinates of the property.

### Usage

This dataset is open for public use and is particularly suited for:

- Analyzing trends in the rental market.
- Studying the geographical distribution of rental properties.
- Comparing rental prices across different cities and property types.
- Developing machine learning models to predict rental prices or classify property types.

Feel free to explore this dataset and derive meaningful insights to understand the dynamics of the UAE rental market.
",.csv
Dubizzle used car sales data,1,dubizzle-used-car-sale-data,data.csv,CC0-1.0,"## Dataset Description 

Dubizzle is the UAE'S (Middle east country) favorite marketplace to buy, sell and find anything. In this dataset I scrapped almost all data from Dubizzle related to automobile selling. This data can be used for finding interesting fact and correlation between different kind brands, resell value of a specific car related to year and more.  Enjoy and explore.

## Summary
- There are 20 columns and 9170 rows
- Scrapped date 12/05/2022

## Column Description
1. *title* - Vehicle name with model details
2.  *price_in_aed*  - Vehicle price in united arab emirates dhirham
3.  *kilometer* - How many kilometer the vehicle travelled 
4.  *body_condition* - Body condition of vehicle 
5. *mechanical_condition* - Mechanical condition of vehicle
6.  *seller_type* - Type of seller ( Dealer, Owner, Other)
7.  *body_type* - Body type ( SUV, Sedan, Other)
8.  *no_of_cylinder* - Number of cylinder 
9. *transmission_type* - Vehicle transmission type ( Automatic Transmission, Manual Transmission )
10. *regional_spec* - Regional Specification of vehicle
11.  *horsepower* - Horsepower
12. *fuel_type* - Fuel Type 
13. *steering_side* - Steering side of the vehicle
14. *year* - Vehicle model year
15. *color* - Vehicle color
16. *emirates* - Emirates is like state
17. *motor_trim* - Motor trim type
18. *company* - Vehicle manufacture company name
19. *model* - Vehicle model
20. *date_posted* - Date of ad posted",.csv
Dummy Marketing and Sales Data,1,dummy-advertising-and-sales-data,Dummy Data HSS.csv,CC0-1.0,"I made this data for my students in 'Data-Driven Marketing' and 'Data Science for Business'. Data contains:
- TV promotion budget (in million)
- Social Media promotion budget (in million)
- Radio promotion budget (in million)
- Influencer: Whether the promotion collaborate with Mega, Macro, Nano, Micro influencer
- Sales (in million)

This data can be used for simple tasks:
- Data preprocessing
- Exploratory Data Analysis
- Visualization
- Prediction using Linear Regression and Model Evaluation",.csv
Dune: Part Two IMDB Reviews,1,dune-part-two-imdb-reviews,dune_2_reviews.csv,Apache 2.0,"This dataset carries the whispers of Arrakis! It holds over 1,000 reviews for Dune: Part 2, scraped fresh from the IMDB. Explore what audiences say about the film's grand battles, prophetic visions, and epic desert landscapes. 

**Here's what awaits you:**

* **Review Titles & Content:**  Unearth the hopes and frustrations of viewers through their own words. 
* **Review Dates:**  Track the flow of opinions over time. 
* **User Ratings:**  See how the movie measured up on a scale of 1 to 10. 

**May your analysis be fruitful.**

**P.S.** Look out for missing data!
",.csv
Duygu Analizi Veri Seti (Olumlu/Olumsuz/Tarafsız),1,duygu-analizi-icin-urun-yorumlari,magaza_yorumlari_duygu_analizi.csv,CC0-1.0,"Veriler, Türkçe olarak, çeşitli elektronik mağazalardan toplanmıştır. Bu yüzden tekrar eden değerler olabilir. Modellerinizde daha başarılı sonuçlar elde etmek için verileri ön işleme aşamasından geçirmeniz sizin yararınıza olacaktır.

Duygu ayrımı, ""Olumlu"", ""Olumsuz"" ve ""Tarafsız"" olmak üzere üçe ayrılmıştır.

Bazen, görüşlerle uyuşmayan duygular görebilirsiniz, bunlar tamamen yorumu yapan kişiden kaynaklıdır.

Veri seti .csv uzantılı olup, utf-16 olarak kodlanmıştır. Projelerinizde, veriyi okurken bunları dikkate almanız gerekecektir.

(Turkish reviews for sentiment analysis.)",.csv
Dynamic Pricing Dataset,1,dynamic-pricing-dataset,dynamic_pricing.csv,CC0-1.0,"A ride-sharing company wants to implement a dynamic pricing strategy to optimize fares based on real-time market conditions. The company only uses ride duration to decide ride fares currently. The company aims to leverage data-driven techniques to analyze historical data and develop a predictive model that can dynamically adjust prices in response to changing factors.

The dataset containing historical ride data has been provided. It  includes features such as the *number of riders, number of drivers, location category, customer loyalty status, number of past rides, average ratings, time of booking, vehicle type, expected ride duration, and historical cost of the rides.*

Your goal is to build a dynamic pricing model that incorporates the provided features to predict optimal fares for rides in real-time. The model must consider factors such as demand patterns and supply availability.

![ridimage](https://i0.wp.com/vitalflux.com/wp-content/uploads/2023/07/dynamic-pricing-machine-learning-strategies-examples.png?resize=1536%2C698&ssl=1)

**Features:** 

'Number_of_Riders',
'Number_of_Drivers',
'Location_Category',
'Customer_Loyalty_Status',
'Number_of_Past_Rides', 
'Average_Ratings',
'Time_of_Booking',
'Vehicle_Type',
'Expected_Ride_Duration',
'Historical_Cost_of_Ride'

**Some References:** 

*- [Dynamic Pricing Explained: Machine Learning in Revenue Management and Pricing Optimization](https://www.altexsoft.com/blog/dynamic-pricing-explained-use-in-revenue-management-and-pricing-optimization/)*

*- [Dynamic Pricing using Reinforcement Learning](https://towardsdatascience.com/dynamic-pricing-using-reinforcement-learning-and-neural-networks-cc3abe374bf5)*

*- [Dynamic Pricing on E-commerce Platform with Deep Reinforcement Learning: A Field Experiment](https://arxiv.org/abs/1912.02572)*

*- [Engineering Extreme Event Forecasting at Uber with Recurrent Neural Networks](https://www.uber.com/en-IN/blog/neural-networks/)*",.csv
E-Commerce Data,1,ecommerce-data,data.csv,CC0-1.0,"### Hello

Ever been excited to see a sales dataset ? Well, this data is perfectly curated to perform sales analysis. We have an e-commerce sales dataset from India with 3 csv files -List of Orders, Order details, Sales target


### What's inside?

1. List of Orders-This dataset contains purchase information. The information includes ID, Date of Purchase and customer details
2. Order Details- This dataset contains order ID, with the order price, quantity,profit, category and subcategory of product
3. Sales target-This dataset contains sales target amount and date for each product category

### Acknowledgements

Dataset received from my University, Original Author unknown 
",.csv
E-Commerce Pet Supplies Dataset,1,e-commerce-pet-supplies-dataset,aliexpress_pet_supplies.csv,ODC Attribution License (ODC-By),"

### Dataset Overview
The ""E-Commerce Pet Supplies Dataset"" offers a comprehensive snapshot of pet products sold on an online platform. This dataset includes 1,998 entries, each representing a unique pet supply product available for purchase. It is tailored for data science projects focused on e-commerce trends, product popularity, and consumer preferences within the pet supply market.

### Data Science Applications
This dataset is ideal for several data science applications, including:
- **Market Trend Analysis:** Understanding popular products based on sales and customer wishes.
- **Product Rating Analysis:** Evaluating customer satisfaction through average star ratings.
- **Inventory Management:** Analyzing quantity data to optimize stock levels.
- **Sales Prediction:** Developing models to predict future sales based on existing data.

### Column Descriptors
- **title:** The name or description of the pet supply product.
- **averageStar:** The average rating of the product, scaled from 0 to 5.
- **quantity:** The number of units available in stock.
- **tradeAmount:** The total number of units sold, presented in a string format like '5 sold' or '1,000+ sold'.
- **wishedCount:** The number of times customers have added the product to their wishlist.

### Ethically Mined Data and No Personal Data/Information
This dataset is compiled using ethical mining practices with the assistance of Apify and does not contain any personal data or sensitive customer information, ensuring compliance with data protection standards.

### Acknowledgements
We express our gratitude to **Apify** for facilitating the data collection and **AliExpress** for allowing access to the relevant e-commerce data. Additionally, we acknowledge **DALL-E 3** for creating the thumbnail and cover images used for this dataset.

### Usage
This dataset is provided for learning and educational purposes only. It should not be used for commercial purposes. Users are encouraged to use this data to enhance their understanding of e-commerce dynamics, specifically in the pet supply sector, and to develop data science skills related to real-world applications.

",.csv
E-Ticaret Ürün Yorumları,1,eticaret-urun-yorumlari,e-ticaret_urun_yorumlari.csv,CC0-1.0,"Bu veri seti Hepsiburada, Trendyol ve N11 gibi e-ticaret platformlarından çeşitli ürün yorumları çekilerek hazırlanmıştır. Toplamda 15170 yorumun yer aldığı veri setinde 6799 olumlu, 6978 olumsuz ve 1393 nötr yorum yer almaktadır. ",.csv
E-commerce Cosmetic Products,1,e-commerce-cosmetics-dataset,E-commerce  cosmetic dataset.csv,MIT,"The popularity of cosmetic products has snowballed over the past few years. Hence, there have been many more brands and makeup products on the market, especially in the online market. To analyze the online marketing trends in the Indian cosmetic industry, we have used some of the most popular Indian websites like Amazon, Flipkart, Ulta, and Sephora to scrape the product data. This dataset also contains the ingredients of these products, which can be further analyzed. 

Here is the taxonomy of the dataset:

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16052878%2F23ac2e6750de0f11c6c5783a268a923c%2Ftaxonomy%20of%20the%20cosmetics%20dataset.png?generation=1709132308112031&alt=media)",.csv
E-commerce Customer Behavior Dataset,1,e-commerce-customer-behavior-dataset,E-commerce Customer Behavior - Sheet1.csv,CC0-1.0,"**Dataset Description: E-commerce Customer Behavior**

**Overview:**
This dataset provides a comprehensive view of customer behavior within an e-commerce platform. Each entry in the dataset corresponds to a unique customer, offering a detailed breakdown of their interactions and transactions. The information is crafted to facilitate a nuanced analysis of customer preferences, engagement patterns, and satisfaction levels, aiding businesses in making data-driven decisions to enhance the customer experience.

**Columns:**

1. **Customer ID:**
   - *Type:* Numeric
   - *Description:* A unique identifier assigned to each customer, ensuring distinction across the dataset.

2. **Gender:**
   - *Type:* Categorical (Male, Female)
   - *Description:* Specifies the gender of the customer, allowing for gender-based analytics.

3. **Age:**
   - *Type:* Numeric
   - *Description:* Represents the age of the customer, enabling age-group-specific insights.

4. **City:**
   - *Type:* Categorical (City names)
   - *Description:* Indicates the city of residence for each customer, providing geographic insights.

5. **Membership Type:**
   - *Type:* Categorical (Gold, Silver, Bronze)
   - *Description:* Identifies the type of membership held by the customer, influencing perks and benefits.

6. **Total Spend:**
   - *Type:* Numeric
   - *Description:* Records the total monetary expenditure by the customer on the e-commerce platform.

7. **Items Purchased:**
   - *Type:* Numeric
   - *Description:* Quantifies the total number of items purchased by the customer.

8. **Average Rating:**
   - *Type:* Numeric (0 to 5, with decimals)
   - *Description:* Represents the average rating given by the customer for purchased items, gauging satisfaction.

9. **Discount Applied:**
   - *Type:* Boolean (True, False)
   - *Description:* Indicates whether a discount was applied to the customer's purchase, influencing buying behavior.

10. **Days Since Last Purchase:**
    - *Type:* Numeric
    - *Description:* Reflects the number of days elapsed since the customer's most recent purchase, aiding in retention analysis.

11. **Satisfaction Level:**
    - *Type:* Categorical (Satisfied, Neutral, Unsatisfied)
    - *Description:* Captures the overall satisfaction level of the customer, providing a subjective measure of their experience.

**Use Cases:**

1. **Customer Segmentation:**
   - Analyze and categorize customers based on demographics, spending habits, and satisfaction levels.

2. **Satisfaction Analysis:**
   - Investigate factors influencing customer satisfaction and identify areas for improvement.

3. **Promotion Strategy:**
   - Assess the impact of discounts on customer spending and tailor promotional strategies accordingly.

4. **Retention Strategies:**
   - Develop targeted retention strategies by understanding the time gap since the last purchase.

5. **City-based Insights:**
   - Explore regional variations in customer behavior to optimize marketing efforts based on location-specific trends.

**Note:** This dataset is synthetically generated for illustrative purposes, and any resemblance to real individuals or scenarios is coincidental.",.csv
E-commerce Dataset with 30K Products,1,ecommerce-fashion-dataset,FashionDataset.csv,other,"This dataset is a collection of 30000 women fashion products. Categories covered in this dataset is western wear, Indian wear, perfumes and fragrances, watches and nightwear. ✨ 
You can use this dataset to apply your data cleaning, visualization and analytical skills.
Column description is mentioned below:  
BrandName: Mentions the brand of the product
Details: Deatils about the product  
Size: Sizes available   
MRP: This is max retail price  
SellPrice: This is the price after discount  
Category: Category of the product  
*Nan value is null value*

**I hope you liked the dataset. I'd love to get you feedback.**🙌 
*Please upvote  this dataset.*👍 ",.csv
ECB speeches etc. 1997 to 2024-05-13,1,ecb-speeches-1997-to-20191122-frequencies-dm,export_datamart.csv,CC-BY-SA-4.0,"### Context

I am preparing a book on change to add to my publications (https://robertolofaro.com/published), and I was looking into speeches delivered by ECB, and the search on the website wasn't what I needed.

Started posting online updates in late 2019, currently the online webapp that allows to search via a tag cloud is updated on a weekly basis, each Monday evening.

Search by tag: https://robertolofaro.com/ECBSpeech 
(links also to dataset on kaggle)

From 2024-03-25, the dataset contains also the AI-based audio transcripts of any ECB item collected, whenever the audio file is accessible

source: ECB website

### Content

In late October/early November 2019, ECB posted on Linkedin a link to a CSV dataset extending from 1997 up to 2019-10-25 with all the speeches delivered, as per their website

The dataset was ""flat""- and I needed to both search quickly for associations of people to concepts, and to see directly the relevant speech in a human-readable format (as some speeches had pictures, tables, attachments, etc)

So, I recycled a concept that I had developed for other purposes and used in an experimental ""search by tag cloud on structured content"" on https://robertolofaro.com/BFM2013tag

The result is https://robertolofaro.com/ECBSpeech, that contains information from the CSV file (see website for the link to the source), with the additional information as shown within the ""About this file"".

The concept behind this sharing of the dataset on Kaggle, and releasing on my public website the application I use to navigate date (I have a local Xampp where I use this and other applications to support the research side of my past business and current publication activities) is shared on http://robertolofaro.com/datademocracy

This tag cloud contains the most common words 1997-2020 across the dataset

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F3925987%2Fcf58205d2447ed7355c1a4e213f5b477%2F20200902_kagglerelease.png?generation=1599033600865103&alt=media)


### Acknowledgements

Thanks to the ECB for saving my time (I was going to copy-and-paste or ""scrape"" with R from the speeches posted on their website) by releasing the dataset https://www.ecb.europa.eu/press/key/html/downloads.en.html


### Inspiration

In my cultural and organizational change activities and within data collection, collation, and processing to support management decision-making (including my own) since the 1980s, I always saw that the more data we collect, the less time to retrieve it when needed there is.

I usually worked across multiple environments, industries, cultures, and ""collecting"" was never good enough if I could not then ""retrieve by association"".

In storytelling is fine just to roughly remember ""cameos from the past"", but in data storytelling (or when trying to implement a new organization, process, or even just software or data analysis) being able to pinpoint a source that might have been there before is equally important.

So, I am simply exploring different ways to cross-reference information from different domains, as I am quite confident that within all the open data (including the ECB speeches) there are the results of what niche experts saw on various items.

Therefore, why should time and resources be wasted on redoing what was done from others, when you can start from their endpoint, before adapting first, and adopting then (if relevant)?


### Updates

2020-01-25: added GITHUB repository for versioning and release of additional material
as the upload of the new export_datamart.csv wasn't possible, it is now available at: https://github.com/robertolofaro/ecbspeech

changes in the dataset: 
1. fixed language codes
2. added speeches published on the ECB website in January 2020 (up to 2020-01-25 09:00 CET)
3. added all the items listed under the ""interview"" section of the ECB website

current content: 340 interviews, 2374 speeches

2020-01-29: the same file on GITHUB released on 2020-01-25, containing both speeches and interviews, and within an additional column to differentiate between the two, is now available on Kaggle

current content: 340 interviews, 2374 speeches

2020-02-26: monthly update, with items released on the ECB website up to 2020-02-22

current content:  2731 items, 345 interviews, 2386 speeches

2020-03-25: monthly update, with items released on the ECB website up to 2020-03-20

since March 2020, the dataset includes also press conferences available on he ECB website

current content:  2988 records (2392 speeches, 351 interviews, 245 press conferences)

2020-06-07: update, with items released on the ECB website up to 2020-06-07

since June 2020, the dataset includes also press conferences, blog posts, and podcasts available on the ECB website

current content:  3030 records (2399 speeches, 369 interviews, 247 press conferences, 8 blog posts, 7 ECB Podcast).
  
2020-09-02: update, with items released on the ECB website up to 2020-08-30

current content:  3073 records (2418 speeches, 385 interviews, 248 press conferences, 14 blog posts, 8 ECB Podcast), released between 1997-02-07 and 2020-08-30

2020-12-06: update, with items released on the ECB website up to 2020-12-05

current content:  3149 records (2458 speeches, 410 interviews, 250 press conferences, 19 blog posts, 12 ECB Podcasts), released between 1997-02-07 and 2020-12-05

2021-03-01: update, with items released on the ECB website up to 2021-02-28

current content:  3181 records (2476 speeches, 419 interviews, 252 press conferences, 20 blog posts, 14 ECB Podcasts), released between 1997-02-07 and 2021-02-28

2021-06-13: update, with items released on the ECB website up to 2021-06-13

current content:  3232 records (2501 speeches, 434 interviews, 255 press conferences, 26 blog posts, 16 ECB Podcasts), released between 1997-02-07 and 2021-02-28

2021-09-05: update, with items released on the ECB website up to 2021-09-05

current content:  3268 records (2516 speeches, 446 interviews, 257 press conferences, 30 blog posts, 19 ECB Podcasts), released between 1997-02-07 and 2021-09-05

2021-12-05: update, with items released on the ECB website up to 2021-12-05

current content: 3329 records (2560 speeches, 455 interviews, 258 press conferences, 33 blog posts, 23 ECB Podcasts), released between 1997-02-07 and 2021-12-05

From 2022-01-01, the Kaggle frequencies dataset update will be on a weekly basis, with a monthly ""alignment"" refresh on the speeches part from the ECB speeches data, as since QTR IV 2021 ECB updated on a monthly basis its own dataset ([latest ECB dataset update: 2021-12-01](https://www.ecb.europa.eu/press/key/html/downloads.en.html))

2022-01-08 attached the excel file containing the cross-check between:
- ECB file as of 2022-01-01
- export data file as 2022-01-02

From 2022-01-09: updated on a weekly basis, see outline [on the search by tag cloud website](https://robertolofaro.com/ECBSpeech)

From 2024-03-23: the dataset as well as the webapp on [robertolofaro.com/ECBSpeech](https://robertolofaro.com/ECBSpeech) contain also the text extracted automatically from the ECBPodcasts (which have been published since 2019)

From 2024-03-25: added also the audio transcripts for ECB Blog (or other audio files that will be provided within items added, whenever the audio is accessible)
",.csv
ECG of Cardiac Ailments Dataset,1,ecg-of-cardiac-ailments-dataset,ECGCvdata.csv,other,"The Data set consists of 1200 records of Cardiovascular ECGs where each of the 300 records belongs to one ailment, in such a way 4 ailments have been considered. The original signals are taken from the MIT-BIH physio-net Database. One ailment is the MIT-BIH Arrhythmia Database, the other is BIDMC Congestive Heart Failure Database and MIT-BIH Atrial Fibrillation Database and finally MIT-BIH Normal Sinus Rhythm Database. From these four databases, ECG records have been segmented at 4120 samples each forming 300 signals. They are normalized with mentioned gain for each database and are preprocessed with bandpass filters. MODWPT technique was used to obtain 54 features that are given as columns in .csv file that is uploaded here. So the file has 1200 x 54 size records.
Note:: Missing values have to be handled according to your application.

**ACKNOWLEDGEMENT**
Please credit the authors if you use this dataset file in your research.

Citation:

1. Alekhya, L., and P. Rajesh Kumar, ""A new approach to detect cardiovascular diseases using ECG scalograms and ML-based CNN algorithm."" Mar 20, 2023. International Journal of Computational Vision and Robotics/Inderscience publishers. 
DOI: 10.1504/IJCVR.2022.10051429 
Link: https://www.inderscience.com/info/ingeneral/forthcoming.php?jcode=IJCVR

2. Alekhya, L., and P. Rajesh Kumar. ""A Novel Application for Autonomous Detection of Cardiac Ailments using ECG 
Scalograms with Alex Net Convolution Neural Network."" Design Engineering (2021): 13176-13189.
Link: http://www.thedesignengineering.com/index.php/DE/article/view/6434

3. Autonomous Detection of Cardiac Ailments using Long-short term Memory Model based on Electrocardiogram signals, L. Alekhya, P. Rajesh Kumar, A. Venkata Sriram
DOI: 10.14704/nq.2022.20.7.NQ33431. Pages: 3509 - 3518.
Link: https://www.neuroquantology.com/open-access/Autonomous+Detection+of+Cardiac+Ailments+using+Longshort+term+Memory+Model+based+on+Electrocardiogram+signals_5781/

4. Autonomous Detection of Cardia Ailments diagnosed by Electrocardiogram using various Supervised Machine Learning AlgorithmsAutonomous Detection of Cardia Ailments diagnosed by Electrocardiogram using various Supervised Machine Learning Algorithms
AMA, Agricultural Mechanization in Asia, Africa and Latin America (ISSN: 00845841) · Sep 18, 2021.
Link: https://www.shin-norinco.com/article/autonomous-detection-of-cardia-ailments-diagnosed-by-electrocardiogram-using-various-supervised-machine-learning-algorithms
 
5. L Alekhya, P Rajesh Kumar, “Maximal Overlap Discrete Wavelet Packet Transform Based Characteristic waves detection in Electrocardiogram of Cardiovascular Diseases”, INTERNATIONAL JOURNAL OF SPECIAL EDUCATION, vol 36 (1), pp 51-61, 2021.





**License**
License was not specified at the source, yet access to the data is public and a citation was requested.

",.csv
EPL Player Shooting Stats 23-24 Premier League,1,epl-player-shooting-stats-23-24-premier-league,player_shooting_2023_2024.csv,CC0-1.0,"### Table Description: Premier League Shooting Statistics

This dataset contains shooting statistics for players in the English Premier League. It includes metrics such as goals scored, shots taken, shot accuracy, expected goals (xG), and more. The data is sourced from FBRef and covers the latest Premier League season.

**Column Descriptions:**

1. **Rk:** Index of the player in the list.
2. **Player:** Name of the player.
3. **Nation:** Nationality of the player.
4. **Pos:** Position of the player on the field.
5. **Squad:** Team the player belongs to.
6. **Age:** Age of the player at the time of Aug 1st 2023(season start).
7. **Born:** Birth year of the player.
8. **90s:** Number of 90-minute intervals the player participated in.
9. **Gls:** Total goals scored by the player.
10. **Sh:** Total shots taken by the player.
11. **SoT:** Shots on target by the player.
12. **SoT%:** Shot accuracy percentage.
13. **Sh/90:** Shots per 90 minutes.
14. **SoT/90:** Shots on target per 90 minutes.
15. **G/Sh:** Goals per shot.
16. **G/SoT:** Goals per shot on target.
17. **Dist:** Average distance of shots taken by the player.
18. **FK:** Free kicks taken by the player.
19. **PK:** Penalty kicks made by the player.
20. **PKatt:** Penalty kick attempts by the player.
21. **xG:** Expected goals.
22. **npxG:** Non-penalty expected goals.
23. **npxG/Sh:** Non-penalty expected goals per shot.
24. **G-xG:** Difference between actual goals and expected goals.
25. **np:G-xG:** Difference between non-penalty actual goals and non-penalty expected goals.
26. **Matches:** Link to matches played as a str.
27. **Birth Month:** Month of birth of the player.",.csv
ERCOT Electricity Model,1,ercot-electricity-model,ERCOT_dataset.csv,ODbL-1.0,"Energy machine learning model for predicting ERCOT generation in megawatts. Dependent variables include EV stock prices, commodity prices, macroeconomic indicators, energy indexes, and CO2 emissions.",.csv
Early Classification of Diabetes ,1,early-diabetes-classification,diabetes_data.csv,other,"# About this dataset
&gt; Diabetes is one of the fastest growing chronic life threatening diseases that have already affected **422 million people worldwide** according to the report of World Health Organization (WHO), in 2018. Due to the presence of a relatively long asymptomatic phase, early detection of diabetes is always desired for a clinically meaningful outcome. Around **50% of all people suffering from diabetes are undiagnosed because of its long-term asymptomatic phase**. 


&gt; This dataset contains 520 observations with 17 characteristics, collected using direct questionnaires and diagnosis results from the patients in the Sylhet Diabetes Hospital in Sylhet, Bangladesh. 



# How to use this dataset
&gt; - Create a classification model to predict diabetes;
- Explore the most common features associated with diabetic risk.


# Highlighted Notebooks
&gt; - Your kernel can be featured here!
- [More datasets](https://www.kaggle.com/andrewmvd/datasets)



# Acknowledgements
If you use this dataset in your research, please credit the authors.
&gt; ### Citation

&gt; Islam M.M.F., Ferdousi R., Rahman S., Bushra H.Y. (2020) Likelihood Prediction of Diabetes at Early Stage Using Data Mining Techniques. In: Gupta M., Konar D., Bhattacharyya S., Biswas S. (eds) Computer Vision and Machine Intelligence in Medical Image Analysis. Advances in Intelligent Systems and Computing, vol 992. Springer, Singapore. https://doi.org/10.1007/978-981-13-8798-2_12



&gt; ### License
License was not specified, yet data is free and public.


&gt; ### Splash banner
Icon by [Freepik](https://www.flaticon.com/authors/freepik).",.csv
Early Stage Diabetes Risk Prediction Dataset,1,early-stage-diabetes-risk-prediction-dataset,diabetes_data_upload.csv,DbCL-1.0,"###Data Set Information:

This has been collected using direct questionnaires from the patients of Sylhet Diabetes
Hospital in Sylhet, Bangladesh and approved by a doctor.

###Data Set Information:

This has been col-
lected using direct questionnaires from the patients of Sylhet Diabetes
Hospital in Sylhet, Bangladesh and approved by a doctor.

###Attribute Information:

Age 1.20-65
Sex 1. Male, 2.Female
Polyuria 1.Yes, 2.No.
Polydipsia 1.Yes, 2.No.
sudden weight loss 1.Yes, 2.No.
weakness 1.Yes, 2.No.
Polyphagia 1.Yes, 2.No.
Genital thrush 1.Yes, 2.No.
visual blurring 1.Yes, 2.No.
Itching 1.Yes, 2.No.
Irritability 1.Yes, 2.No.
delayed healing 1.Yes, 2.No.
partial paresis 1.Yes, 2.No.
muscle stiness 1.Yes, 2.No.
Alopecia 1.Yes, 2.No.
Obesity 1.Yes, 2.No.
Class 1.Positive, 2.Negative.

###Relevant Papers:

Likelihood Prediction of Diabetes at Early Stage Using Data Mining Techniques
[Web Link]
Authors and affiliations
M. M. Faniqul IslamEmail
Rahatara Ferdousi
Sadikur Rahman
Humayra Yasmin Bushra

###Citation Request:

Islam, MM Faniqul, et al. 'Likelihood prediction of diabetes at early stage using data mining techniques.' Computer Vision and Machine Intelligence in Medical Image Analysis. Springer, Singapore, 2020. 113-125.
Islam, MM Faniqul, et al. 'Likelihood prediction of diabetes at early stage using data mining techniques.' Computer Vision and Machine Intelligence in Medical Image Analysis. Springer, Singapore, 2020. 113-125.",.csv
Earnings of females and males employees.,1,cusersmarildownloadsearningcsv,earning.csv,other,"### Context


The Bureau of Labor Statistics reported that, in 2013, female full-time workers had median weekly earnings of $706, compared to men's median weekly earnings of $860. Women aged 35 years and older earned 74% to 80% of the earnings of their male counterparts. https://en.wikipedia.org › wiki › Gender_pay_gap_in_the_United_States


### Content

What is the gender pay gap 2019?
Study after study has identified a persistent gender pay gap. A PayScale report found that women still make only $0.79 for each dollar men make in 2019. A Bureau of Labor Statistics (BLS) analysis discovered that in 2018, median weekly earnings for female full-time wage and salary workers was 81% of men's earnings.Jul 11, 2019
https://www.forbes.com/sites/shaharziv/2019/07/11/gender-pay-gap-bigger-than-you-thnk/#36ca335f7d8a.


### Acknowledgements
 Linked through data.gov.au for discoverability and availability.
This dataset was originally found on data.gov.au
https://data.gov.au/data/dataset/a5776c56-bdde-4643-a3fd-dcc2775d7d7a
***Photo by Samantha Sophia on Unsplash.


### Inspiration

Great females scientists:  Mileva Maric', Frances ""Poppy"" Northcut, Hedy Lamarr, Marie Sklodowska Curie and Ada Lovelace.
If you don't know them yet, just  search on Google.  ",.csv
"Earthquakes in 1910-2017, Turkey @alpkoc",1,earthquake,earthquake.csv,CC-BY-NC-SA-4.0,"*I fork the data from @alpkoc and i have fixed several areas in cvs like wrong country names and wrong number formats,
So here is the explanation of original data owner:*

**Context**
Over the years the earthquakes have been recorded by different organisations in Turkey. Bogazici University, as the most successful university in Turkey, has a earthquake research center and they collected up all the data during the years. They have the most technological devices to uncover the specifications about the earthquakes. The data was collected from the database with particular filters.

**Content**
The data covers up all the recorded earthquakes in the latitudes between 25 - 50; longitudes 15 - 60. As the metering stations are placed in Turkey most of the recorded earthquakes are in latitudes between 35 - 45; longitudes 25 - 45. The database search time filter was set to dates 27/09/1910 to 27/09/2017. As there are too many earthquakes which have intensities smaller than 4.0, the filter of intensity was set to 3.5 to 9.0 (there was no earthquakes recorded larger than 9.0 intensity).
Not being an earthquake specilist or geologist, I have no idea about the different kind of intensity measurements in the dataset (the columns between xM and Ms). 

**Acknowledgements**
All the data here is owned by ""Boğaziçi Üniversitesi Rektörlüğü"" and it can only be used for uncommercial issues with regards to ""Boğaziçi Üniversitesi Kandilli Rasathanesi ve Deprem Araştırma Enstitüsü Bölgesel Deprem-Tsunami İzleme ve Değerlendirme Merkezi"". 

Inspiration
I hope all kind of data scientists would be interested in this data in order to: - Visualize the current data on any kind of GIS. - Reveal some truths and correleations behind and across the data. - Analyze seasonality across months, years and decades. - Improve any kind of data model which can be useful to represent the eathquakes in Turkey. - Develop algorithms to predict the earthquake with an intensity, an interval and a coordinate corridor. ",.csv
Earthquakes on Chile,1,earthquakes-on-chile,seismic_data.csv,Apache 2.0,"The data used to create this dataset was taken from the database of the [Centro Sismológico Nacional](https://evtdb.csn.uchile.cl/).

Chile is a country famous for its high seismic activity. In fact, its one of the most seismic places in the world, which makes it a place of interest for many researchers investigating this topic.

This dataset contain a single file called **seismic_data.csv**, which is composed from the following columns:
- **Date(UTC)**: Timestamp in which the earthquake was registered (precision up to 1 second).
- **Latitude/Longitude**: The location of the earthquake.
- **Depth**: The depth (measured in km) of the earthquake.
- **Magnitude**: The earthquake's magnitude.

This data covers earthquakes with magnitudes ranging from 3 to 9, and that occurred between 2012-01-01 and today. The data is generated from a notebook that's scheduled to run daily, so the dataset should receive frequent updates. All the earthquakes in the dataset have a maximum depth of 300 km.

# What can you do with this data?

- Explore the data to find the zones with the highest probability of earthquakes.
- Search the zones with the highest seismical energy.
- Relate earthquake occurrence with physical variables available on other datasets.
- Estimate the probability of occurrence of a big earthquake given previous events.
- And much more!",.csv
Easiest Diabetes Classification Dataset,1,easiest-diabetes-classification-dataset,Diabetes Classification.csv,Attribution 4.0 International (CC BY 4.0),"The dataset consists of 100+ patient records. Each record contains the following information:

Age: The patient's age, in years.

Gender: The patient's gender, male or female.

BMI: The patient's body mass index (BMI), a measure of weight relative to height.

Blood pressure: The patient's blood pressure, in mmHg.

FBS: The patient's fasting blood sugar, in mg/dL.

HbA1c: The patient's hemoglobin A1c, a measure of blood sugar control over the past 3 months.

Family history of diabetes: Whether the patient has a family history of diabetes.

Smoking: Whether the patient smokes.

Diet: Whether the patient has a poor or healthy diet.

Exercise: Whether the patient exercises regularly.

Diagnosis: The patient's diagnosis, either diabetes or no diabetes.",.csv
Economic Data (Life after Covid),1,economic-data-life-after-covid,economic data.csv,CC0-1.0,"![](https://static01.nyt.com/images/2020/11/18/nyregion/00nyblind1/merlin_179220645_b77f46ff-a503-40b6-bf2b-4922a676e61b-superJumbo.jpg)
This dataset offers a comprehensive insight into the economic trajectories of nine major economies from the onset of the COVID-19 pandemic through the beginning of 2024. It encompasses crucial economic indicators and financial market data, covering aspects such as manufacturing and services performance, consumer sentiment, monetary policies, inflation rates, unemployment rates, and overall economic output. Additionally, it includes price data for each economy, with values compared against the dollar for clarity. With data spanning this period, the dataset provides valuable insights for analysts, researchers, and stakeholders into the impact of the pandemic and other significant events on these economies, facilitating an assessment of their resilience, challenges, and opportunities.

**Countries included** : Australia / Canada / China / Europe / Japan / New Zealand / Switzerland / United Kingdom / United States

## Column Descriptions:

- **Country** : The name of the country.
- **Date** : The date format (e.g., YYYY-MM-DD).
- **Manufacturing PMI** : Purchasing Managers' Index (PMI) for the manufacturing sector, indicating the economic health and activity level of the manufacturing industry.
- **Services PMI** : Purchasing Managers' Index (PMI) for the services sector, indicating the economic health and activity level of the services industry.
- **Consumer Confidence** : A measure of consumer sentiment or confidence in the economy, indicating consumers' optimism or pessimism about their financial situation and the overall state of the economy.
- **Interest Rates** : The prevailing interest rates set by the central bank or monetary authority, which influence borrowing costs and investment decisions.
- **CPI YoY** : Consumer Price Index (CPI) Year-over-Year change, indicating the percentage change in the average price level of a basket of consumer goods and services over the previous year.
- **Core CPI** : Core Consumer Price Index (CPI), which excludes volatile items such as food and energy prices, providing a measure of underlying inflation trends.
- **Unemployment Rate** : The percentage of the labor force that is unemployed and actively seeking employment, indicating the health of the labor market.
- **GDP YoY** : Gross Domestic Product (GDP) Year-over-Year change, indicating the percentage change in the total value of goods and services produced by a country's economy.
- **Ticker**: Ticker symbol for the corresponding financial asset or index.
- **Open**: The opening price of the financial asset or index on the specified date.
- **High**: The highest price of the financial asset or index during the specified date.
- **Low**: The lowest price of the financial asset or index during the specified date.
- **Close**: The closing price of the financial asset or index on the specified date.",.csv
Economy and Rice Production Sri Lanka (1960-2020),1,economy-and-rice-production-sri-lanka-1960-2020,Economy vs Rice production in Sri Lanka.csv,CC0-1.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F7578003%2F8c90f1693dcb54220280dfd20b562cf3%2FywtLecVp.jpg?generation=1713616199294584&alt=media)

**Description:**
This dataset presents a comprehensive overview of the Sri Lankan economy and rice production from 1960 to 2020. It includes key economic indicators such as GDP, inflation, manufacturing output, population, growth rate, imports, arable land, military expenditure, and rice production.

**Variables:**

    GDP ($B): Gross Domestic Product in billions of dollars.
    Inflation (%): Annual inflation rate as a percentage.
    Manufacturing ($B): Manufacturing output in billions of dollars.
    Population: Total population of Sri Lanka.
    Growth Rate (%): Population growth rate as a percentage.
    Imports ($B): Value of imports in billions of dollars.
    Arable Land: Total arable land area in Sri Lanka.
    Military($B): Military expenditure in billions of dollars.
    Rice Production: Rice production in metric tons.

**Use Case:**
Researchers, economists, and policymakers can utilize this dataset to analyze the trends and relationships between economic indicators and rice production in Sri Lanka. It can be used to study the impact of various factors on the economy and agriculture sector, aiding in informed decision-making and policy formulation.

**Code:**

https://github.com/namalhappy/Impact-of-Economic-Indicators-on-Rice-Production.git

",.csv
"Economy, Business and Finance Articles",1,economy-business-and-finance-articles,combined_file.csv,Apache 2.0,"This dataset is a curated collection of articles related to economy, finance, and business, each uniquely identified by a UUID. It includes URLs, authorship details, publication timestamps, and full article text. Highlights indicate keywords or phrases, while language and sentiment analysis offer linguistic and emotional insights.

Content is categorized from broad to specific domains, with embedded external links and images enriching the context. A rating system evaluates article relevance. Crawled and updated timestamps ensure data recency, and thread metadata captures the breadth of online discussions, including engagement and social reach metrics.

Social media interaction data across platforms reflects digital engagement, and entity tracking identifies people, organizations, and locations mentioned. Performance scores and domain ranks provide a gauge of source authority and content visibility, making this dataset valuable for content trend analysis and sentiment gauging in the financial sector.",.csv
Effects of Alcohol on Student Performance.,1,effects-of-alcohol-on-student-performance,Stats survey.csv,ODbL-1.0,"Aim:
The main aim of this project is to predict students academic performance (grades) using a multilinear regression model built on the predictors mentioned based on 2023 student information.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F19333363%2F7407dacb72918118e038f55b63fbaa03%2FScreenshot%202024-03-25%20at%2014.29.47.jpg?generation=1711370483318757&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F19333363%2F0343dcc8ef6a299793ac9c2ac765346c%2Fbeg.jpg?generation=1711370517515575&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F19333363%2Fd9ff245cbe0eb71665863e78a7ae5050%2FScreenshot%202024-03-25%20at%2014.40.09.jpg?generation=1711370529500014&alt=media)

*Monthly_allowance are amounts are in rands

This is the raw data file, straight from the survey collected. You will see some responses on ""what year were you in last year"" have been left blank which indicates that the students previous year of study was not in university but rather high school. Since the point of the model is to be based on university students, these observations that have been left blank will be removed so that only students who were in university in 2023 and onwards are taken into consideration. |  
",.csv
Electoral Bonds India,1,purchaser-details-of-electoral-bonds,part1.csv,CC0-1.0,"The dataset was uploaded by the Election Commission of India on their official website. Initially, the dataset was in PDF format, which has been subsequently processed into a .CSV file.

1. Date of Purchase: Indicates the date when the electoral bond was purchased, providing insights into the timing of political contributions.
2. Purchaser Name: Identifies the individual or entity purchasing the electoral bond, shedding light on the stakeholders involved in political financing.
3. Denomination: Specifies the denomination of the electoral bond, offering details on the monetary value of the contribution made.",.csv
Electoral bonds full data with donors & parties,1,electoral-bonds-full-data-of-donors-and-parties,electrol_data.csv,CC-BY-SA-4.0,"This dataset provides information about electoral bond transactions between purchasers and political parties in India. Electoral bonds are financial instruments introduced by the Government of India to facilitate transparent political funding. Purchasers, which can be individuals or entities, can donate money to political parties through electoral bonds, providing a mechanism for legitimate and accountable political financing.
Contents:

Purchaser: Name of the individual or entity making the donation.
Party Name: Name of the political party receiving the donation.
Amount (in Crores): The amount of money donated in Crores.
Potential Applications:

Analysis of political funding trends: Researchers and analysts can use this dataset to analyze patterns and trends in political funding, including the distribution of donations among different parties and the behavior of donors.
Transparency and accountability: By making electoral bond transactions publicly available, this dataset promotes transparency and accountability in the political financing process.
Policy evaluation: Policymakers and government agencies can use insights from this dataset to evaluate the effectiveness of electoral bond policies and regulations.
Acknowledgments:

The data in this dataset is sourced from publicly available reports and disclosures by the Election Commission of India and other relevant government agencies.",.csv
Electric Vehicle Charging Connecticut,1,electric-vehicle-charging-connecticut,Electric_Vehicle_Charging_Stations.csv,Apache 2.0,"# Connecticut's Electric Vehicle Charging Infrastructure

In Connecticut, the adoption of electric vehicles (EVs) is supported by a growing network of public charging stations. 

![](https://media.giphy.com/media/SUiFaBaEhQSPJIir6e/giphy.gif?cid=790b7611n7kj1dnn59d6e30eltfmmq2lma64xnmo8j7113fa&ep=v1_gifs_search&rid=giphy.gif&ct=g)

The dataset below provides information about existing public EV charging stations within the state, as compiled from the US Department of Energy map and additional research conducted by the Connecticut Department of Energy and Environmental Protection (DEEP) as of May 27, 2020.

![](https://media.giphy.com/media/AKQRDg7eK9C46ROfGp/giphy.gif?cid=790b7611n7kj1dnn59d6e30eltfmmq2lma64xnmo8j7113fa&ep=v1_gifs_search&rid=giphy.gif&ct=g)

**Station Name**: The name of the EV charging station.
**Street Address**: The street address where the charging station is located.
**City**: The city where the charging station is situated.
**Access Days Time**: The days and times when the charging station is accessible for use.
**EV Level1 EVSE Num**: The number of Level 1 Electric Vehicle Supply Equipment (EVSE) available at the station. Level 1 EVSE typically uses a standard 120-volt AC plug and provides a slower charge.
**EV Level2 EVSE Num**: The number of Level 2 Electric Vehicle Supply Equipment (EVSE) available at the station. Level 2 EVSE uses a 240-volt AC plug and provides a faster charge than Level 1.
**EV DC Fast Count**: The count of DC Fast Chargers available at the station. DC Fast Chargers provide a much faster charge compared to Level 1 and Level 2 chargers.
**EV Other Info**: Any additional information about the EV charging station.
**New Georeferenced Column**: Geographical coordinates (longitude and latitude) of the charging station location in the format of a POINT.

![](https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExbjdrajFkbm41OWQ2ZTMwZWx0Zm1tcTJsbWE2NHhubW84ajcxMTNmYSZlcD12MV9naWZzX3NlYXJjaCZjdD1n/282FVV3gOTojMwgcDm/giphy.gif)

This dataset seems to contain information about public EV charging stations within Connecticut, sourced from the US Department of Energy map and supplemented with research from the Connecticut Department of Energy and Environmental Protection (DEEP) as of May 27, 2020.",.csv
Electric Vehicle Charging Stations 2024,1,electric-vehicle-charging-stations-2024,Electric_Vehicle_Charging_Stations.csv,Apache 2.0,"An overview of public Electric Vehicle (EV) charging stations within Connecticut from US DOE map.

Data obtained from Department of Energy and Environmental Protection",.csv
Electric Vehicle Population,1,electric-vehicle-population,Electric_Vehicle_Population_Size_History_By_County.csv,other,"This dataset shows the number of vehicles that were registered by Washington State Department of Licensing (DOL) each month. The data is separated by county for passenger vehicles and trucks.

DOL integrates National Highway Traffic Safety Administration (NHTSA) data and the Environmental Protection Agency (EPA) fuel efficiency ratings with DOL titling and registration data to create this information.

Take the Percent Electric Vehicles as a target and share your analysis for this matter.
",.csv
Electric Vehicle Population Data,1,electric-vehicle-population-data,electric_vehicle_population_data.csv,DbCL-1.0,"The dataset I am sharing provides information on Battery Electric Vehicles (BEVs) and Plug-in Hybrid Electric Vehicles (PHEVs) currently registered through the Washington State Department of Licensing (DOL). 

The columns in the dataset include:

1. VIN (1-10): Partial vehicle identification number consisting of the first 10 digits.
2. County: The county where the vehicle is registered.
3. City: The city where the vehicle is registered.
4. State: The state where the vehicle is registered.
5. Postal Code: The postal code of the vehicle registration location
6. Model Year: The year the vehicle was manufactured.
7. Make: The manufacturer or brand of the vehicle.
8. Model: The specific model of the vehicle.
9. Electric Vehicle Type: Indicates whether the vehicle is a Battery Electric Vehicle (BEV) or a Plug-in Hybrid Electric Vehicle (PHEV).
10. Clean Alternative Fuel Vehicle (CAFV) Eligibility: Indicates if the vehicle is eligible for Clean Alternative Fuel Vehicle benefits.
11. Electric Range: The range of the vehicle on a full electric charge.
12. Base MSRP: The manufacturer's suggested retail price for the vehicle.
13. Legislative District: The legislative district associated with the vehicle registration location.
14. DOL Vehicle ID: Unique identifier assigned by the Washington State Department of Licensing.
15. Vehicle Location: The precise location of the vehicle.
16. Electric Utility: The electric utility company associated with the vehicle.
17. 2020 Census Tract: The census tract where the vehicle is registered.

This dataset was sourced from the data.gov website and aims to contribute to the understanding of electric vehicle adoption and distribution in Washington State.",.csv
Electric Vehicle Population by Country (2024),1,electric-vehicle-population-size-2024,Electric_Vehicle_Population_Size_History_By_County_.csv,Apache 2.0,This dataset shows the number of vehicles that were registered by Washington State Department of Licensing (DOL) each month. The data is separated by county for passenger vehicles and trucks.,.csv
Electricity Consumption and Meteorology in Sceaux,1,electricity-consumption-and-meteorology-in-sceaux,final_dataset.csv,CC0-1.0,"Householder electricity consumption data accompanied with meteorological data at Sceaux, France.",.csv
Electricity Consumption and Production Data,1,electricity-consumption-and-production-data,Electricity.csv,CC0-1.0,"Time-series data on Romania's electricity consumption and production, categorized by production type, at hourly intervals.",.csv
Electricity Production Dataset,1,global-electricity-production,global_electricity_production_data.csv,other,"### Context
This dataset offers a comprehensive overview of global electricity production data spanning 48 countries from 2010 to 2023. It provides valuable insights into the balance, production, and values of electricity generation across different regions over the specified timeframe. With its focus on electricity production, this dataset is instrumental for energy analysts, policymakers, and researchers aiming to understand global energy trends, identify patterns, and develop strategies for sustainable energy production and consumption.

### Content
Containing essential columns such as country name, date, balance, product, value, and unit, this dataset enables thorough analyses of electricity production dynamics. Researchers can explore the temporal trends in electricity generation, assess the distribution of production across countries, and investigate the impacts of various factors on energy production. By examining the balance between different energy sources, understanding production trends, and analyzing the variation in production values, stakeholders can make informed decisions regarding energy policies, infrastructure investments, and renewable energy adoption strategies.

### Dataset Structure:
The dataset (`global_electricity_production_data.csv`) encompasses data from 48 countries for the years 2010 to 2023, with the following columns:

| Column Name         | Description                                          |
| ------------------- | ---------------------------------------------------- |
| `country_name`      | Name of the Country                                  |
| `date`         | Date of the production                                     |
| `parameter`         | Parameter being measured in each row                         |
| `product`      | Type of electricity product                      |
| `value`      | Value of electricity production              |
| `unit`   | Unit of measurement for electricity production           |


### Acknowledgment
The primary dataset was sourced from [IEA (2024)](https://www.iea.org/data-and-statistics/data-tools/monthly-electricity-statistics) Monthly Electricity Statistics, IEA, Paris, and I extend my sincere gratitude to the team for providing the core data used in this dataset.

© Image credit: [Freepik](https://img.freepik.com/free-photo/sun-setting-silhouette-electricity-pylons_1127-3239.jpg)",.csv
Eligibility Prediction for Loan,1,eligibility-prediction-for-loan,Loan_Data.csv,CC0-1.0,"
![Data Set Screen Shot](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F5905558%2F51d24a6006a411355a7cab507ba85dd0%2F11.PNG?generation=1668494178086820&alt=media)

**Context**
Dream Housing Finance company deals in all kinds of home loans. They have presence across all urban, semi urban and rural areas. Customer first applies for home loan and after that company validates the customer eligibility for loan.

Company wants to automate the loan eligibility process (real time) based on customer detail provided while filling online application form. These details are Gender, Marital Status, Education, Number of Dependents, Income, Loan Amount, Credit History and others. To automate this process, they have provided a dataset to identify the customers segments that are eligible for loan amount so that they can specifically target these customers. 

**Dataset Glossary (Column-wise)**

Train file: CSV containing the customers for whom loan eligibility is known as 'Loan_Status'
|Variable  | Description |
| --- | --- |
| Loan_ID | Unique Loan ID |
| Gender| Male/ Female |
|Married|Applicant married (Y/N)|
|Dependents|Number of dependents|
|Education|Applicant Education (Graduate/ Under Graduate)|
|Self_Employed|Self employed (Y/N)|
|ApplicantIncome|Applicant income|
|CoapplicantIncome|Coapplicant income|
|LoanAmount|Loan amount in thousands|
|Loan_Amount_Term|Term of loan in months|
|Credit_History|credit history meets guidelines|
|Property_Area|Urban/ Semi Urban/ Rural|
|Loan_Status|(Target) Loan approved (Y/N)|

",.csv
Elon Musk Tweets (Daily Updated),1,elon-musk-tweets-updated-daily,elonmusk.csv,CC0-1.0,"#Context
Tweets by Elon Musk are very popular. He is currently one of the most followed users on Twitter, with &gt;100M followers. He is also constantly tweeting, so the content generated is interesting.

#Content
This dataset is collected daily using snscrape.
The source of the dataset is public tweets by Elon Musk.

#Data columns
The following columns are included:

1. Tweet Id
2. Datetime
3. Text
4. Username

You can use this dataset (daily updated) to test your skills with NLP tools and techniques.
If you find this helpful, drop a like :)",.csv
"Elon Musk Tweets, 2010 to 2017",1,elon-musk-tweets,elon_musk_tweets.csv,other,"# Content

 - tweet id, contains tweet-stamp
 - date + time, date and time of day (24hr)
 - tweet text, text of tweet, remove 'b'

# usage

What's someone going to do with a bunch of tweets?

 - Maybe someone would want to generate text using this dataset
 - or do sentiment analysis
 - Or find out the most likely time of day Elon would tweet.
 - pie his tweets per month, ITS DATA!!

Either way its up to you!

# Inspiration:

![elon][1]


  [1]: http://iotblog.ir/wp-content/uploads/2017/01/eloninfograph.jpg",.csv
Elon Musk's Tweets,1,elon-musks-tweets,data_elonmusk.csv,CC0-1.0,"### Context

[Elon Musk](https://en.wikipedia.org/wiki/Elon_Musk) is an American business magnate. He was one of the founders of PayPal in the past, and the founder and/or cofounder and/or CEO of SpaceX, Tesla, SolarCity, OpenAI, Neuralink, and The Boring Company in the present. He is known as much for his extremely forward-thinking ideas and huge media presence as he is for his extremely business savvy.

Musk is famously active on Twitter. This dataset contains all tweets made by [@elonmusk](https://twitter.com/elonmusk), his official Twitter handle, between November 16, 2012 and September 29, 2017.

### Content

This dataset includes the body of the tweet and the time it was made, as well as who it was re-tweeted from (if it is a retweet).

### Inspiration

* Can you figure out Elon Musk's opinions on various things by studying his Twitter statements?
* How Elon Musk's post rate increased, decreased, or stayed about the same over time? ",.csv
Email Classification (Ham-Spam),1,email-classification-ham-spam,email_classification.csv,other,"The Email Classification dataset has been synthetically generated. This meticulously curated dataset is designed to enhance your natural language processing prowess. It comprises 2 columns.

-&gt; Email: This column contains the textual description of the email/ message, offering a diverse range of vocabulary and language patterns.

-&gt; Label: Each review is classified into either Ham (non-spam) or Spam.

You can use this dataset to fine-tune existing pre-trained Large Language Models, create your own NLP models, and perform tasks of text-classification using techniques such as Logistic Regression, Naive Bayes, Recursive Neural Network (RNN), and various other methods to hone your NLP skills.

Useful Tip: For better use, you can map the label column to numeric values. You can also create N-gram models and tables for the same to analyze the dataset better.",.csv
Email Ham/Spam Dataset,1,email-hamspam-dataset,email_spam.csv,Apache 2.0,"This dataset is a collection of labeled email messages that have been categorized as either ""ham"" (legitimate, non-spam) or ""spam"" (unsolicited, often unwanted messages).This dataset encompasses a wide range of email content, reflecting the diversity of messages encountered in real-world email communication. This diversity is crucial for training models that can generalize well across various types of messages. This dataset serves as a valuable resource for developing and evaluating machine learning models, particularly in the field of email filtering and spam detection.",.csv
Email Spam,1,email-spam,dataset.csv,DbCL-1.0,"Email spam is a type of unsolicited electronic mail (email) that is sent in bulk to a large number of recipients. Spam is often used to send viruses, malware, and phishing scams. It can also be used to promote products or services.

Email spam data is a collection of emails that have been labeled as spam or not spam. This data can be used to train and test spam filters, as well as to study the characteristics of spam emails.

Email spam data typically includes the following fields:

Email: The full text of the email, including the subject and body.
category: spam /non-spam.
Body: The body of the email.
Email spam data can be collected from a variety of sources, including:

Public datasets: Datasets of spam emails that have been made available for research purposes.
Email spam data is a valuable resource for researchers and practitioners who are working on spam filtering and email classification.

Here are some of the ways that email spam data can be used:

To train and test spam filters: Spam filters can be trained on email spam data to learn the characteristics of spam emails. This allows the filters to more accurately identify spam emails in the future.
To study the characteristics of spam emails: Email spam data can be used to study the characteristics of spam emails, such as the language used, the types of attachments, and the sender's email address. This information can help researchers to develop better spam filters and to understand the motivations of spammers.
To develop new spam filtering techniques: Email spam data can be used to develop new spam filtering techniques. For example, researchers can use machine learning to develop algorithms that can automatically identify spam emails.
Email spam data is an important resource for researchers and practitioners who are working on spam filtering and email classification.",.csv
Email Spam Classification Dataset CSV,1,email-spam-classification-dataset-csv,emails.csv,ODbL-1.0,"### Introduction

This is a csv file containing related information of 5172 randomly picked email files and their respective labels for spam or not-spam classification.


### About the Dataset

The csv file contains 5172 rows, each row for each email. There are 3002 columns. The first column indicates Email name. The name has been set with numbers and not recipients' name to protect privacy. The last column has the labels for prediction : 1 for spam, 0 for not spam. The remaining 3000 columns are the 3000 most common words in all the emails, *after excluding the non-alphabetical characters/words*. ***For each row, the count of each word(column) in that email(row) is stored in the respective cells.*** **Thus, information regarding all 5172 emails are stored in a compact dataframe rather than as separate text files.**
",.csv
Email Spam Detection Dataset (classification),1,email-spam-detection-dataset-classification,spam.csv,other,"### Context

TO CLASSIFY THE MAIL AS SPAM OR HAM BY USING MACHINE OR DEEP LEARNING MODEL.


### Content

This is the dataset in which some randomly mails are collected and classified as spam or ham .1st column contains spam/ham classification resr column have the mail itself

",.csv
Email Spam Text Classification Dataset,1,email-spam-classification,email_spam.csv,Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0),"# Email Spam Classification, Text Classification Dataset

The dataset consists of a collection of emails categorized into two major classes: **spam** and **not spam**. It is designed to facilitate the development and evaluation of spam detection or email filtering systems. 

# 💴 For Commercial Usage: To discuss your requirements, learn about the price and buy the dataset, leave a request on **[TrainingData](https://trainingdata.pro/datasets/spambase?utm_source=kaggle&utm_medium=cpc&utm_campaign=email-spam-classification)** to buy the dataset

**The spam emails** in the dataset are typically unsolicited and unwanted messages that aim to promote products or services, spread malware, or deceive recipients for various malicious purposes. These emails often contain misleading subject lines, excessive use of advertisements, unauthorized links, or attempts to collect personal information.

The **non-spam emails** in the dataset are genuine and legitimate messages sent by individuals or organizations. They may include personal or professional communication, newsletters, transaction receipts, or any other non-malicious content.

The dataset encompasses emails of varying *lengths, languages, and writing styles*, reflecting the inherent heterogeneity of email communication. This diversity aids in training algorithms that can generalize well to different types of emails, making them robust against different spammer tactics and variations in non-spam email content.

### The dataset's possible applications:
- spam detection
- fraud detection
- email filtering systems
- customer support automation
- natural language processing

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F618942%2F4d1fdedb2827152696dd0c0af05fd8da%2Ff.png?generation=1690286497115141&alt=media)

# 💴 Buy the Dataset: This is just an example of the data. Leave a request on **[https://trainingdata.pro/datasets](https://trainingdata.pro/datasets/spambase?utm_source=kaggle&utm_medium=cpc&utm_campaign=email-spam-classification)** to discuss your requirements, learn about the price and buy the dataset.

# File with the extension .csv

includes the following information:

- **title**: title of the email,
- **text**: text of the email,
- **type**: type of the email

# Email spam might be collected in accordance with your requirements.

## **[TrainingData](https://trainingdata.pro/datasets/spambase?utm_source=kaggle&utm_medium=cpc&utm_campaign=email-spam-classification)** provides high-quality data annotation tailored to your needs

*keywords: spam mails dataset, email spam classification, spam or not-spam, spam e-mail database, spam detection system, email spamming data set, spam filtering system, spambase, feature extraction, spam ham email dataset, classifier, machine learning algorithms, cybersecurity, text dataset, sentiment analysis, llm dataset, language modeling, large language models, text classification, text mining dataset, natural language texts, nlp, nlp open-source dataset, text data*",.csv
EmoBank,1,emobank,emobank.csv,CC0-1.0,"EmoBank is a large-scale dataset created for the purpose of sentiment analysis and emotion recognition in natural language processing (NLP). It contains text samples annotated with both emotion categories and valence-arousal scales. This dual annotation approach allows EmoBank to capture not only basic emotional labels like ""happy"" or ""sad,"" but also to quantify the intensity (arousal) and positivity/negativity (valence) of each emotion.

The dataset is derived from various sources, including online articles, reviews, and other user-generated content. Each entry in the dataset is tagged with the emotional category (e.g., anger, joy, sadness, surprise), as well as with valence and arousal values on a continuous scale, providing a comprehensive view of emotional content.

EmoBank is widely used in sentiment analysis research, emotional intelligence in AI, and other fields where understanding human emotions in text is critical. Its comprehensive annotations and large-scale nature make it a valuable resource for developing and evaluating NLP models with an emotional understanding.

In the EmoBank dataset, the terms ""V,"" ""A,"" and ""D"" stand for:

**V (Valence)**: Refers to the positivity or negativity of an emotion. It is typically measured on a scale from negative to positive. A high valence indicates positive emotions like happiness or joy, while a low valence suggests negative emotions like anger or sadness.

**A (Arousal)**: Represents the level of energy or intensity of the emotion. A high arousal value suggests intense or energetic emotions such as excitement or anger, while a low arousal value indicates calmer emotions like contentment or sadness.

**D (Dominance)**: This measures the level of control or influence the emotion has. High dominance suggests emotions where one feels in control or powerful, while low dominance reflects emotions where one might feel dominated or lacking control.

Together, these three components provide a comprehensive way to represent emotions in a multi-dimensional space. The combination of valence, arousal, and dominance allows for a more nuanced analysis of emotions in textual data.",.csv
Emotion Detection from Text,1,emotion-detection-from-text,tweet_emotions.csv,CC0-1.0,"### Context

Emotion detection from text is one of the challenging problems in Natural Language Processing. The reason is the unavailability of labeled dataset and the multi-class nature of the problem. Humans have a variety of emotions and it is difficult to collect enough records for each emotion and hence the problem of class imbalance arises. Here we have a labeled data for emotion detection and the objective is to build an efficient model to detect emotion.


### Content

The data is basically a collection of tweets annotated with the emotions behind them. We have three columns tweet_id, sentiment, and content. In ""content"" we have the raw tweet. In ""sentiment"" we have the emotion behind the tweet. Refer to the starter notebook for more insights.

### Acknowledgements

This public domain dataset is collected from data.world platform. Thanks, data.world for releasing it under Public License. 


### Inspiration

The data that we have is having 13 different emotion  40000 records. So it's challenging to build an efficient multiclass classification model.  We may need to logically reduce the number of classes here and use some advanced methods to build efficient model.",.csv
Empathetic Dialogues (Facebook AI) 25k,1,empathetic-dialogues-facebook-ai,emotion-emotion_69k.csv,CC-BY-NC-SA-4.0,"# Towards Empathetic Open-domain Conversation Models: a New Benchmark and Dataset
[Paper](https://arxiv.org/abs/1811.00207)


### Content
A dataset of 25k conversations grounded in emotional situations to facilitate training and evaluating dialogue systems.

### Abstract
One challenge for dialogue agents is recognizing feelings in the conversation partner and replying accordingly, a key communicative skill. While it is straightforward for humans to recognize and acknowledge others' feelings in a conversation, this is a significant challenge for AI systems due to the paucity of suitable publicly-available datasets for training and evaluation. This work proposes a new benchmark for empathetic dialogue generation and EmpatheticDialogues, a novel dataset of 25k conversations grounded in emotional situations. Our experiments indicate that dialogue models that use our dataset are perceived to be more empathetic by human evaluators, compared to models merely trained on large-scale Internet conversation data. We also present empirical comparisons of dialogue model adaptations for empathetic responding, leveraging existing models or datasets without requiring lengthy re-training of the full model.


### Acknowledgements
- [Paper](https://arxiv.org/abs/1811.00207)
- [Code](https://parl.ai/) 
",.csv
Employee Attrition,1,employee-attrition-data,MFG10YearTerminationData.csv,CC0-1.0,"# Context 

This data was originally posted on my personal oneDrive account.

It represent **fictitious/fake data** on terminations. For each of 10 years it show employees that are active and those that terminated.

The intent is to see if  individual terminations can be predicted from the data provided.

The thing to be predicted is status of active or terminated

# Content

The data contains

employee id
employee record date ( year of data)
birth date
hire date
termination date
age
length of service
city
department
job title 
store number
gender
termination reason
termination type
status year
status
business unit

These might be typical types of data in hris

# Acknowledgements

None- its fake data


# Inspiration

A lot of turnover analyses occur at an aggregate level-such as turnover rates. But few analyses concentrate on trying to identify exactly which individuals might leave based on  patterns that might be present in existing data.

Machine learning algorithms often showcase customer churn examples for telcos or product marketing. Those algorithms equally apply to employee churn.",.csv
Employee Attrition and Factors,1,employee-attrition-and-factors,HR_Analytics.csv.csv,CC0-1.0,"_____
# Employee Attrition and Factors
### Examining Performance, Financials, and Job Role for Impact on Retention
By  [[source]](https://zenodo.org/record/4088439#.Y9Y3rtJBwUE)
_____

### About this dataset
> This dataset offers a comprehensive and varied analysis of an organization's employees, focusing on areas such as employee attrition, personal and job-related factors, and financials. Included are numerous parameters such as Age, Gender, Marital Status, Business Travel Frequency, Daily Rate of Pay, Departmental Information such as Distance From Home Office or Education Level Obtained by the employee in question. Also included is a variant series of parameters related to the job being performed such as Job Involvement (level), Job Level (relative to similar roles within the same organization), Job Role specifically meant for that individual(function/task), total working hours in a week/month/year be it overtime or standard hours for a given role. Furthermore detailed aspects include Percent Salary Hike during their tenure with the company from promotion or otherwise , Performance Rating based on specific criteria established by leadership , Relationship Satisfaction among peers at workplace but also taking into account outside family members that can influence stress levels in varying capacities ,Monthly Income considered at its starting point once hired then compared against their monthly payrate with overtime hours included if applicable along with Number Companies Worked before if any. Lastly the Retirement Status commonly known as Attrition is highlighted; covering whether there was an intent to stay with one employer through retirement age or if attrition took place for reasons beyond ones control earlier than expected . Through this dataset you can get an insight into various major aspect regarding today's workforce management philosphies which have changed drastically over time due to advancements in technology 

### More Datasets
> For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
> - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
> - Understand the variables that make up this dataset.  The dataset includes several personal and job-related variables such as Age, Gender, Marital Status, Business Travel, Daily Rate, Department, Distance From Home, Education, Education Field, Employee Count, Employee Number, Environment Satisfaction Hoursly Rate and so on. Knowing what each variable is individuallly will help when exploring employee attrition as a whole. 
> - Analyze the data for patterns as well as outliers or anomalies either at an individual level or across all of the data points together. Identifying these patterns or discrepancies can offer insight into factors that are related to employee attrition. 
> - Visualize the data using charts and graphs to allow for easy understanding of which relationships might be causing higher levels of employees leaving the organization over time dimensions like age or job role can be key factors in employee attrition rates visually displaying how they relate to one another can provide clarity into what needs to change within an organization in order to reduce attrition rates
> - Explore relationships between pairs of variables through correlation analysis correlations are measures of how strongly two variables are related when looking at employment retention it’s important to analyze correlations at both an individual level and for all variables together showing which pairings have more influence than others when it comes to influencing employee decisions  
> 5 Use descriptive analytics methods such as scatter plots histograms boxplots etc with aggregated values from each field like average age average monthly income etc These analytics help gain a deeper understanding about where changes need to be made internally   
> 6 Utilize predictive analytics with more advanced techniques such as regressions clustering decision trees in order identify trendsfrom past data points then build models on those insights from different perspectives helping further prepare organizations against potential high levelsinvolving employees departing ?

### Research Ideas
> - Identifying performance profiles of employees at risk for attrition through predictive analytics and using this insight to create personalized development plans or retention strategies. 
> - Using the data to assess the impact of different financial incentives or variations in job role/structure on employee attitudes, satisfaction and ultimately attrition rates. 
> - Analyzing different age groups' responses to various perks or turnover patterns in order to understand how organizations can better engage different demographic segments

### Acknowledgements
> If you use this dataset in your research, please credit the original authors.
> [Data Source](https://zenodo.org/record/4088439#.Y9Y3rtJBwUE)
> 
>


### License
> 
> 
> **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
> No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: HR_Analytics.csv.csv**
| Column name                  | Description                                                                           |
|:-----------------------------|:--------------------------------------------------------------------------------------|
| **Age**                      | The age of the employee. (Numerical)                                                  |
| **Attrition**                | Whether or not the employee has left the organization. (Categorical)                  |
| **BusinessTravel**           | The frequency of business travel for the employee. (Categorical)                      |
| **DailyRate**                | The daily rate of pay for the employee. (Numerical)                                   |
| **Department**               | The department the employee works in. (Categorical)                                   |
| **DistanceFromHome**         | The distance from home in miles for the employee. (Numerical)                         |
| **Education**                | The level of education achieved by the employee. (Categorical)                        |
| **EducationField**           | The field of study for the employee's education. (Categorical)                        |
| **EmployeeCount**            | The total number of employees in the organization. (Numerical)                        |
| **EmployeeNumber**           | A unique identifier for each employee profile. (Numerical)                            |
| **EnvironmentSatisfaction**  | The employee's satisfaction with their work environment. (Categorical)                |
| **Gender**                   | The gender of the employee. (Categorical)                                             |
| **HourlyRate**               | The hourly rate of pay for the employee. (Numerical)                                  |
| **JobInvolvement**           | The level of involvement required for the employee's job. (Categorical)               |
| **JobLevel**                 | The job level of the employee. (Categorical)                                          |
| **JobRole**                  | The role of the employee in the organization. (Categorical)                           |
| **JobSatisfaction**          | The employee's satisfaction with their job. (Categorical)                             |
| **MaritalStatus**            | The marital status of the employee. (Categorical)                                     |
| **MonthlyIncome**            | The monthly income of the employee. (Numerical)                                       |
| **MonthlyRate**              | The monthly rate of pay for the employee. (Numerical)                                 |
| **NumCompaniesWorked**       | The number of companies the employee has worked for. (Numerical)                      |
| **Over18**                   | Whether or not the employee is over 18. (Categorical)                                 |
| **OverTime**                 | Whether or not the employee works overtime. (Categorical)                             |
| **PercentSalaryHike**        | The percentage of salary hike for the employee. (Numerical)                           |
| **PerformanceRating**        | The performance rating of the employee. (Categorical)                                 |
| **RelationshipSatisfaction** | The employee's satisfaction with their relationships. (Categorical)                   |
| **StandardHours**            | The standard hours of work for the employee. (Numerical)                              |
| **StockOptionLevel**         | The stock option level of the employee. (Numerical)                                   |
| **TotalWorkingYears**        | The total number of years the employee has worked. (Numerical)                        |
| **TrainingTimesLastYear**    | The number of times the employee was taken for training in the last year. (Numerical) |
| **WorkLifeBalance**          | The employee's perception of their work-life balance. (Categorical)                   |
| **YearsAtCompany**           | The number of years the employee has been with the company. (Numerical)               |
| **YearsInCurrentRole**       | The number of years the employee has been in their current role. (Numerical)          |
| **YearsSinceLastPromotion**  | The number of years since the employee's last promotion. (Numerical)                  |
| **YearsWithCurrManager**     | The number of years the employee has been with their current manager. (Numerical)     |

### Acknowledgements
> If you use this dataset in your research, please credit the original authors.
> If you use this dataset in your research, please credit [](https://zenodo.org/record/4088439#.Y9Y3rtJBwUE).

",.csv
Employee Future Prediction,1,employee-future-prediction,Employee.csv,CC0-1.0,"## About The Data
A company's HR department wants to predict whether some customers would leave the company in next 2 years. Your job is to build a predictive model that predicts the prospects of future and present employee.
Perform EDA and bring out insights 
Dummy Data Used For A Private Hackathon
Image Credits-Unsplash",.csv
Employee Productivity and Satisfaction HR Data,1,employee-productivity-and-satisfaction-hr-data,hr_dashboard_data.csv,CC-BY-NC-SA-4.0,"This dataset was created to explore the diverse factors impacting employee performance and satisfaction in a typical organization. It spans a variety of fields from personal demographics to performance metrics and job details, offering a comprehensive view into the dynamics of the workplace.

The inspiration behind the creation of this dataset is to provide an accessible resource for those interested in the field of HR analytics. It can be used to derive insights into employee performance, satisfaction, and overall engagement at work. This dataset is particularly useful for tasks such as predicting employee turnover, analyzing employee performance, and understanding the factors that influence job satisfaction.",.csv
Employee Salaries Analysis,1,employee-salaries-analysis,Employee_Salaries.csv,Apache 2.0,"Annual salary information including gross pay and overtime pay for all active, permanent employees of Montgomery County, MD paid in calendar year 2023. This dataset is a prime candidate for conducting analyses on salary disparities, the relationship between department/division and salary, and the distribution of salaries across gender and grade levels. 

Statistical models can be applied to predict base salaries based on factors such as department, grade, and length of service. Machine learning techniques could also be employed to identify patterns and anomalies in the salary data, such as outliers or instances of significant inequity.

Some analysis to be performed with this dataset can include:

- **Gender Pay Gap Analysis**: An examination of salary differences between genders within similar roles, grades, and departments to identify any disparities that need to be addressed.
- **Departmental Salary Analysis**: Analyzing the distribution of salaries across different departments and divisions to understand how compensation varies within the organization.
- **Impact of Overtime and Longevity Pay**: Evaluating how overtime and longevity pay contribute to the overall compensation of employees and identifying trends or patterns in these payments. ​
",.csv
Employee Salaries for different job roles,1,employee-salaries-for-different-job-roles,ds_salaries.csv,other,"Welcome to the Employee Salaries for Different Job Roles Dataset! This dataset provides valuable insights into the compensation and job roles of employees across various industries and regions. Whether you're an HR analyst, data scientist, or someone interested in understanding salary trends, this dataset offers a wealth of information to explore and analyze.

Content:

The dataset contains the following fields:

work_year: The year of employment.
experience_level: The experience level of the employee (e.g., entry-level, mid-level, senior).
employment_type: The type of employment (e.g., full-time, part-time, contract).
job_title: The job title or position of the employee within the company.
salary: The salary amount in the local currency.
salary_currency: The currency in which the salary is denoted.
salary_in_usd: The equivalent salary amount in USD (United States Dollars).
employee_residence: The location of the employee's residence.
remote_ratio: The percentage of remote work allowed for the position.
company_location: The location of the company.
company_size: The size of the company (e.g., small, medium, large).

Usage:

This dataset can be utilized for various purposes, including but not limited to:
1. Analyzing salary trends across different job titles and experience levels.
2. Investigating the impact of remote work on compensation.
3. Comparing salary levels between full-time and part-time employment.
4. Understanding the correlation between company size and employee salaries.
5.  Predictive analysis for forecasting salaries based on experience and job roles.

We encourage you to explore the data, perform insightful analyses, and share your findings with the Kaggle community. If you find any interesting patterns or make significant discoveries, don't forget to acknowledge this dataset in your work.

Please note that all data has been anonymized to ensure the privacy and confidentiality of individuals and organizations.

We hope you find this dataset valuable for your research and analysis. Happy exploring!",.csv
Employee Satisfaction Survey Data,1,employees-satisfaction-analysis,Employee Attrition.csv,Apache 2.0,"The Employee Satisfaction Survey dataset is a comprehensive collection of information regarding employees within a company. It includes essential details such as employee identification numbers, self-reported satisfaction levels, performance evaluations, project involvement, work hours, tenure with the company, work accidents, promotions received in the last 5 years, departmental affiliations, and salary levels. This dataset offers valuable insights into the factors influencing employee satisfaction and can be used to analyze and understand various aspects of the workplace environment.",.csv
Employee Turnover,1,employee-turnover,turnover.csv,CC-BY-NC-SA-4.0,"### About the dataset:
No, it's not about survive from drowning or something like that (just for illustration).

This Employee Turnover dataset is a real dataset shared from [Edward Babushkin's blog](https://edwvb.blogspot.com/2017/10/employee-turnover-how-to-predict-individual-risks-of-quitting.html) used to predict an Employee's risk of quitting (with a Survival Analysis Model). Edward Babushkin explained that ""Survival Analysis is one of the most importance but it's not the most popular algorithm to predict employee turnover. Analysts use more familiar algorithms like Logistic Regression but, for example, Pasha Roberts writes: 'Don't use logistic methods to predict attrition!'. I think that we can only apply for a short-term situation like whether the employee has worked more or less than three months. If our goal is to predict individual quitting risks, then the best method is Survival Analysis.""

### Acknowledgements:
All credit goes to [Edward Babushkin](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwi6-bbkhdLrAhW6_3MBHUX_CAoQFjAMegQIBRAB&url=https%3A%2F%2Fmu.linkedin.com%2Fpub%2Fedward-babushkin%2F1b%2F839%2F75%3Ftrk%3Dseokp-post-author-name&usg=AOvVaw2_ONGoTpyAJ6uzuEgTHGPp) for sharing this useful dataset.


### Inspirations:
This dataset can be used for predicting Employee Churn / Employee Turnover, Employee Survival Analysis, Uplift Modeling, or even Uplift Survival Analysis.",.csv
Employee dataset,1,employee-dataset,Employee.csv,CC0-1.0,"**Context:**
This dataset contains information about employees in a company, including their educational backgrounds, work history, demographics, and employment-related factors. It has been anonymized to protect privacy while still providing valuable insights into the workforce.

**Columns:**

1. **Education:** The educational qualifications of employees, including degree, institution, and field of study.

2. **Joining Year:** The year each employee joined the company, indicating their length of service.

3. **City:** The location or city where each employee is based or works.

4. **Payment Tier:** Categorization of employees into different salary tiers.

5. **Age:** The age of each employee, providing demographic insights.

6. **Gender:** Gender identity of employees, promoting diversity analysis.

7. **Ever Benched:** Indicates if an employee has ever been temporarily without assigned work.

8. **Experience in Current Domain:** The number of years of experience employees have in their current field.

9. **Leave or Not:** a target column

**Usage:**
This dataset can be used for various HR and workforce-related analyses, including employee retention, salary structure assessments, diversity and inclusion studies, and leave pattern analyses. Researchers, data analysts, and HR professionals can gain valuable insights from this dataset.

**Potential Research Questions:**
1. What is the distribution of educational qualifications among employees?
2. How does the length of service (Joining Year) vary across different cities?
3. Is there a correlation between Payment Tier and Experience in Current Domain?
4. What is the gender distribution within the workforce?
5. Are there any patterns in leave-taking behavior among employees?


**Acknowledgments:**
We would like to acknowledge the contributions of our HR department in providing this dataset for research and analysis purposes.
",.csv
Employee’s Performance for HR Analytics,1,employees-performance-for-hr-analytics,Uncleaned_employees_final_dataset (1).csv,ODC Public Domain Dedication and Licence (PDDL),"**employee performance for HR analytics📊📈**

employee performance for HR analytics can provide valuable insights to organizations in terms of employee engagement, productivity, and overall organizational effectiveness. HR analytics involves using data to make informed decisions about human resources and employee-related matters. Here are some key aspects to consider when analyzing employee performance for HR analytics:

**1. Performance Metrics: **Start by identifying the key performance metrics that are relevant to your organization's goals and objectives. Common performance metrics include:

**Key Performance Indicators (KPIs):** These can be specific to each role or department, such as sales revenue, customer satisfaction scores, or project completion rates.
Attendance and Punctuality: Analyzing attendance records and punctuality can provide insights into employee reliability and commitment.
**Employee Turnover Rate:** Understanding the rate at which employees leave the organization can help identify potential issues and retention strategies.
**Employee Satisfaction Surveys:** Analyzing the results of employee satisfaction surveys can give insights into employee morale and job satisfaction.
**Performance Appraisals:** Reviewing performance appraisal data can help assess individual performance and identify areas for improvement.
**Data Collection:** Gather relevant data from various sources, including HR databases, performance evaluation records, time tracking systems, employee surveys, and other relevant sources.

**Data Cleaning and Preparation:** Clean and preprocess the data to ensure it is accurate and consistent. Handle missing values and outliers appropriately.

**2. Exploratory Data Analysis (EDA):** Perform EDA to gain insights into the distribution of performance metrics, identify patterns, and visualize trends. This can involve creating histograms, scatter plots, box plots, and other visualizations.

**3. Performance Segmentation:** Group employees based on their performance levels and other relevant characteristics. This segmentation can help identify high-performing employees, average performers, and those who may need additional support.

**4. Identifying Factors Affecting Performance:** Use statistical analysis and machine learning techniques to identify factors that correlate with high performance. This may include factors like training, work experience, education level, department, or other relevant variables.

**5. Predictive Analytics: **Use predictive modeling to forecast future performance and potential turnover risks. This can help HR teams proactively address potential issues.

**6. Employee Engagement Analysis:** Analyze employee engagement data, such as survey responses and feedback, to understand the impact of engagement on performance.

**7. Retention Analysis:** Examine data related to employee turnover to identify patterns and factors that contribute to attrition. This can help develop retention strategies and improve employee satisfaction.

**8. Recommendations and Actionable Insights:** Based on the analysis, provide actionable insights and recommendations to the HR department and relevant stakeholders. These insights can support talent management decisions, training and development programs, and employee engagement initiatives.

column descriptions for analyzing employee performance for HR analytics:

**1. Introduction**

Overview of the HR Analytics Project
Importance of Analyzing Employee Performance
**2. Dataset Description**

Explanation of the Columns in the Dataset
Meaning and Role of Each Column
**3. Employee ID**

Unique Identifier for Each Employee
Tracking Employee Performance Using ID
**4. Department**

Categorization of Employees into Different Departments
Impact of Department on Performance
**5. Region**

Geographical Region of Employee's Work Location
Regional Differences in Performance
**6. Education**

Employee's Educational Background
Relationship between Education and Performance
**7. Gender**

Distribution of Employees by Gender
Gender-Based Performance Analysis
**8. Recruitment Channel**

Source through which Employees were Recruited
Performance Comparison Based on Recruitment Channel
**9. Number of Trainings**

Count of Training Programs Attended by Each Employee
Effect of Training on Performance
**10. Age**

Age of Employees
Impact of Age on Employee Performance
**11. Previous Year Rating**

Performance Rating of Employees from the Previous Year
Relationship between Previous Year Rating and Current Performance
**12. Length of Service**

Duration of Employment with the Company
Employee Performance Based on Tenure

**Conclusion**

Summary of Findings and Insights
Recommendations for Enhancing Employee Performance",.csv
Employment Growth || LinkedIn Data💹🧑🏼‍💻,1,employment-growth-linkedin-data,linkedin_to_isic_industry_mapping.csv,Apache 2.0,"The Employment Growth LinkedIn dataset contains information about job postings related to employment growth, including:

**About Column:**
- isic_section: A to X 
- isic_section_name:  Agriculture; forestry and fishing, Mining and quarrying
- isic_division: Show the division number.
- isic_division_name: Crop and animal production, hunting and related service activities, Mining of coal 
   and lignite,
- industry_sk
- industry_name: ranching, mining & metals, oil & energy, dairy, farming, etc
- Industry_group_sk: Show the digits.
- Industry_group_name: Manufacturing, Corporate services, Consumer goods,


*This dataset can be used to analyze:*

- Job market trends and growth areas
- In-demand skills for employment growth
- Geographic distribution of employment growth
- Industry-specific employment growth metrics

*This dataset can be used for various purposes such as:
*
- Job market analysis
- Workforce planning
- Economic development
- Research and development
",.csv
Empower Women Now,1,empower-women-now,unemploymentratewomen new2.csv,CC0-1.0,"this graphs was created in Ourdataworld,Tableu and PowerBi: 

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fd1f82accce4a02bce4418c5f9afe2040%2Fgraph1.png?generation=1711310230092757&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F2b041e5dad3c721ef35b30181d38d2bb%2Fgraph2.png?generation=1711310236207783&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F7f70c805cd89f9fbb085fd3769c94c46%2Fgraph3.png?generation=1711310243376241&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F316568090119ff2644e3540f6ae53f58%2Fgraph4.jpg?generation=1711310250268715&alt=media)

Introduction:

Understanding gender disparities in labor force participation is essential for shaping inclusive economic policies worldwide. Across regions and countries, significant variations exist, highlighting the complex interplay of cultural, social, and economic factors. This analysis delves into the intricacies of women's labor force participation, utilizing data from the International Labor Organization (ILO) to elucidate trends and disparities on a global scale.

Global Overview:

Globally, approximately half of women are part of the labor force, although significant variations exist across regions. While many regions surpass the global average, such as Europe and North America, others, notably the Middle East, North Africa, and South Asia, exhibit substantially lower participation rates. Men generally participate more frequently in labor markets than women, illustrating pervasive gender disparities in workforce engagement.

Regional Disparities:

Examining regional disparities reveals nuanced patterns. In Europe and North America, women's participation rates often exceed global averages, reflecting advancements in gender equality and inclusive labor policies. Conversely, regions like the Middle East, North Africa, and South Asia lag behind, hindered by cultural norms, limited educational opportunities, and restrictive gender roles.

Mapping Gender Disparities:

Visualizing gender disparities through a global map provides insights into country-level variations. The female-to-male ratio in labor force participation rates illustrates the extent of gender gaps across nations. Data from the ILO, which harmonizes diverse sources for enhanced comparability, reveal stark contrasts. While most countries exhibit ratios below 100%, indicating lower female participation, disparities range from below 25% to parity or even a slight female predominance in some instances.

Key Factors Influencing Gender Disparities:

Education: Disparities in educational attainment significantly influence women's participation in the labor force. Access to quality education empowers women economically, leading to higher workforce engagement.

Legal Frameworks: Gender-sensitive legislation and policies promoting equal opportunities are crucial for narrowing labor force disparities. Ensuring legal protections against discrimination and providing support for work-life balance can enhance women's workforce participation.

Cultural Norms: Societal attitudes towards women's roles and responsibilities shape labor force dynamics. Challenging traditional gender norms and fostering inclusive workplaces are essential for creating environments conducive to women's employment.

Economic Development: The level of economic development and access to employment opportunities profoundly impact women's labor force participation. Investment in infrastructure, vocational training, and entrepreneurship programs can enhance women's economic empowerment and workforce integration.

Policy Implications:

Addressing gender disparities in labor force participation requires a multifaceted approach encompassing policy reforms, social interventions, and cultural transformations. Governments, businesses, and civil society must collaborate to enact inclusive policies that promote gender equality, expand educational opportunities, and create supportive work environments. Empowering women economically not only enhances individual livelihoods but also fosters sustainable development and prosperity for societies as a whole.

Conclusion:

Analyzing global gender disparities in labor force participation underscores the imperative of advancing gender equality in economic spheres. By addressing systemic barriers and fostering inclusive policies, societies can harness the full potential of women as active contributors to workforce development and economic growth. Embracing diversity and promoting gender parity are essential steps towards building more equitable and prosperous societies worldwide.",.csv
Energy Consumption,1,energy-consumption,energy-consumption-2020-1.csv,CC0-1.0,"Energy consumption refers to the amount of energy used or consumed by various processes, activities, appliances, or systems over a given period. It's typically measured in units like kilowatt-hours (kWh) for electricity or British thermal units (BTUs) for other forms of energy like natural gas or oil.

There are several factors that influence energy consumption:

**Type of Energy:** Different sources of energy have varying efficiencies and environmental impacts. Common energy sources include fossil fuels (coal, oil, natural gas), renewable sources (solar, wind, hydroelectric), and nuclear power.

**Efficiency of Equipment:** The efficiency of appliances, machinery, and devices plays a significant role in determining energy consumption. Energy-efficient appliances can perform the same tasks while using less energy compared to less efficient ones.

**Behavioral Patterns:** Individual or organizational behavior can influence energy consumption. Practices like turning off lights when not in use, using energy-saving settings on appliances, and optimizing heating and cooling systems can all impact energy usage.

**Climate and Seasonal Variations:** Energy consumption often fluctuates with changes in weather and climate. For example, heating and cooling demands increase during extreme temperatures, leading to higher energy usage.

**Industrial Processes:** Industrial activities, manufacturing processes, and commercial operations contribute significantly to overall energy consumption. Optimization of these processes can lead to reduced energy usage and increased efficiency.

**Transportation: **Energy consumption in the transportation sector includes fuel used by vehicles such as cars, trucks, trains, ships, and airplanes. Efforts to improve fuel efficiency and promote alternative fuels can help reduce energy consumption in this sector.

**Technological Advances: **Advances in technology, such as the development of more efficient appliances, vehicles, and industrial processes, can lead to reductions in energy consumption over time.

Reducing energy consumption is essential for mitigating climate change, conserving natural resources, and reducing energy costs. Strategies for reducing energy consumption include adopting energy-efficient technologies, improving insulation and building design, promoting renewable energy sources, and encouraging conservation behaviors.



CODE:
def calculate_energy_consumption(power, time):
    """"""
    Function to calculate energy consumption.

    Parameters:
    - power: power rating of the device/appliance in watts
    - time: duration of usage in hours

    Returns:
    - energy_consumed: energy consumed in kilowatt-hours (kWh)
    """"""
    energy_consumed = (power * time) / 1000  # Convert watts to kilowatts
    return energy_consumed

def main():
    print(""Energy Consumption Calculator"")
    print(""============================="")
    power = float(input(""Enter the power rating of the device/appliance (in watts): ""))
    time = float(input(""Enter the duration of usage (in hours): ""))

    energy_consumed = calculate_energy_consumption(power, time)
    print(f""\nThe energy consumed is: {energy_consumed:.2f} kWh"")

if __name__ == ""__main__"":
    main()


This program prompts the user to enter the power rating of a device/appliance in watts and the duration of its usage in hours. It then calculates the energy consumed in kilowatt-hours (kWh) using the formula:

Energy consumed (kWh)
=
Power (W)
×
Time (hrs)
1000
Energy consumed (kWh)= 
1000
Power (W)×Time (hrs)
​
 Finally, it prints out the calculated energy consumption.",.csv
Energy Efficiency Data Set,1,energy-efficiency-data-set,energy_efficiency_data.csv,CC0-1.0,"This Data Set is collected from UCI Machine Learning Repository.

Data Set Description in UCI as follows:
""
Abstract: This study looked into assessing the heating load and cooling load requirements of buildings (that is, energy efficiency) as a function of building parameters.



We perform energy analysis using 12 different building shapes simulated in Ecotect. The buildings differ with respect to the glazing area, the glazing area distribution, and the orientation, amongst other parameters. We simulate various settings as functions of the afore-mentioned characteristics to obtain 768 building shapes. The dataset comprises 768 samples and 8 features, aiming to predict two real valued responses. It can also be used as a multi-class classification problem if the response is rounded to the nearest integer.
""",.csv
Energy Efficiency Dataset,1,eergy-efficiency-dataset,ENB2012_data.csv,CC0-1.0,"Source:

The dataset was created by Angeliki Xifara (angxifara '@' gmail.com, Civil/Structural Engineer) and was processed by Athanasios Tsanas (tsanasthanasis '@' gmail.com, Oxford Centre for Industrial and Applied Mathematics, University of Oxford, UK).

Data Set Information:

We perform energy analysis using 12 different building shapes simulated in Ecotect. The buildings differ with respect to the glazing area, the glazing area distribution, and the orientation, amongst other parameters. We simulate various settings as functions of the afore-mentioned characteristics to obtain 768 building shapes. The dataset comprises 768 samples and 8 features, aiming to predict two real valued responses. It can also be used as a multi-class classification problem if the response is rounded to the nearest integer.

Attribute Information:

The dataset contains eight attributes (or features, denoted by X1...X8) and two responses (or outcomes, denoted by y1 and y2). The aim is to use the eight features to predict each of the two responses.

Specifically:
X1 Relative Compactness
X2 Surface Area
X3 Wall Area
X4 Roof Area
X5 Overall Height
X6 Orientation
X7 Glazing Area
X8 Glazing Area Distribution
y1 Heating Load
y2 Cooling Load

Relevant Papers:

A. Tsanas, A. Xifara: 'Accurate quantitative estimation of energy performance of residential buildings using statistical machine learning tools', Energy and Buildings, Vol. 49, pp. 560-567, 2012


Citation Request:

A. Tsanas, A. Xifara: 'Accurate quantitative estimation of energy performance of residential buildings using statistical machine learning tools', Energy and Buildings, Vol. 49, pp. 560-567, 2012 (the paper can be accessed from [Web Link])

For further details on the data analysis methodology:
A. Tsanas, 'Accurate telemonitoring of Parkinsonâ€™s disease symptom severity using nonlinear speech signal processing and statistical machine learning', D.Phil. thesis, University of Oxford, 2012 (which can be accessed from [Web Link])",.csv
Energy Output From Two Solar Arrays in SF,1,energy-output-from-two-solar-arrays-in-sf,solar.csv,other,"Energy Output From Two Solar Arrays in San Francisco
Description
The data provide the energy output for several months from two roof-top solar arrays in San Francisco. This city is known for having highly variable weather, so while these two arrays are only about 1 mile apart from each other, the Inner Sunset location tends to have more fog.

Usage
solar
Format
A data frame with 284 observations on the following 3 variables. Each row represents a single day for one of the arrays.

location
Location for the array.

date
Date.

kwh
Number of kWh

Details
The Haight-Ashbury array is a 10.4 kWh array, while the Inner Sunset array is a 2.8 kWh array. The kWh units represents kilowatt-hours, which is the unit of energy that typically is used for electricity bills. The cost per kWh in San Francisco was about $0.25 in 2016.

Source
These data were provided by Larry Rosenfeld, a resident in San Francisco.",.csv
Energy-consumption-prediction,1,energy-consumption-prediction,Energy_consumption.csv,Apache 2.0,"This dataset encapsulates a diverse array of features, including temperature, humidity, occupancy, HVAC and lighting usage, renewable energy contributions, and more. Each timestamp provides a snapshot of a hypothetical environment, allowing for in-depth analysis and modeling of energy consumption behaviors. Dive into the nuances of this synthetic dataset, designed to emulate real-world scenarios, and unravel the complexities that influence energy usage. Whether you are delving into predictive modeling or honing your data analysis skills, this dataset offers a dynamic playground for experimentation and discovery.",.csv
Engineering Graduate Salary,1,engineering-graduate-salary,Engineering_graduate_salary.csv,Apache 2.0,"This dataset provides a detailed look into the salary trends of engineering graduates. It includes various factors such as the field of engineering, the university from which the degree was obtained, the year of graduation, the location of employment, the employing company, the job title, the starting salary, the current salary, and the years of experience in the field. This data can be used to analyze and understand the patterns and trends associated with the salaries of engineering graduates. It’s important to note that all data is anonymized to protect the privacy of the individuals involved. The dataset serves as a valuable resource for researchers, data scientists, and industry professionals. It can help in developing effective career guidance strategies, wage negotiation tactics, and predictive models for future salary trends. Please remember to use this data responsibly.",.csv
Engineering Placements Prediction,1,engineering-placements-prediction,collegePlace.csv,CC0-1.0,"A University Announced Its On-Campus Placement Records For The Engineering Course. The Data Is From The Years 2013 And 2014.
The Following Is The College Placements Data Compiled Over 2 years. Use This Data To Predict And Analyse Whether A Student Gets Placed, Based On His/Her Background.
Perform Extensive EDAs And Bring Out Insights.
Build A Robust Model Using ML Techniques Or Neural Networks. Use Multiple Algorithms.
Go Ahead!
Image Credits-Unsplash(free to use)
",.csv
England Weather,1,england-weather,EnglandWeather.csv,other,"In this research, the meteorological data of England has been reviewed, which includes the following information: 

Formatted Date: date and time of information recorded
Summary: The state of the sky in terms of cloud cover
Precip Type: Type of precipitation 
Temperature (C): Temperature
Wind Speed (km/h): Wind speed
Pressure (millibars): air pressure in kilopascals
Humidity: Air humidity",.csv
English Premier League (EPL) Results,1,english-premier-league-results,results.csv,CC0-1.0,"### Context

EPL Results

### Columns
| Column | Description |
| ------------- | ------------- |
| Season | Match Season |
| DateTime | Match Date and Time (yyyy-mm-dd hh:mm:ss) |
| HomeTeam | Home Team |
| AwayTeam | Away Team |
| FTHG | Full Time Home Team Goals |
| FTAG | Full Time Away Team Goals |
| FTR | Full Time Result (H=Home Win, D=Draw, A=Away Win) |
| HTHG | Half Time Home Team Goals |
| HTAG | Half Time Away Team Goals |
| HTR | Half Time Result (H=Home Win, D=Draw, A=Away Win) |
| Referee | Match Referee |
| HS | Home Team Shots |
| AS | Away Team Shots |
| HST | Home Team Shots on Target |
| AST | Away Team Shots on Target |
| HC | Home Team Corners |
| AC | Away Team Corners |
| HF | Home Team Fouls Committed |
| AF | Away Team Fouls Committed |
| HY | Home Team Yellow Cards |
| AY | Away Team Yellow Cards |
| HR | Home Team Red Cards |
| AR | Away Team Red Cards |


### Acknowledgements

Current results and Match statistics
Xcores, BBC, ESPN Soccer
",.csv
English Premier League 2022-2023,1,english-premier-league-2022-2023,epl_results_2022-23.csv,Apache 2.0,"The English Premier League 2022-2023 dataset is here.
Using this dataset, you can explore match day statistics of every game and every team during the 2022-2023 season of the English Premier League! 

Please upvote if you download and use the dataset. Thanks!",.csv
English Premier League Matches 2023/2024 Season,1,english-premier-league-matches-20232024-season,matches.csv,MIT,"English Premier League matches from 2023/2024 season, will be updated weekly. Data is scraped from [https://fbref.com/en/](url)

**Unnamed**: 0: An index or identifier column.

**Date**: The date when the match took place.

**Time**: The kickoff time of the match.

**Comp**: The competition name, which is the Premier League for the rows displayed.

**Round**: The matchweek or round of the competition.

**Day**: The day of the week the match was played.

**Venue**: Indicates whether the team was playing at home or away.

**Result**: The outcome of the match from the perspective of the team mentioned at the end (W = Win, D = Draw, L = Loss).

**GF (Goals For)**: The number of goals scored by the team.

**GA (Goals Against)**: The number of goals conceded by the team.

**Opponent**: The name of the opposing team.

**xG**: Expected goals for the team.

**xGA**: Expected goals against the team.

**Poss**: Possession percentage during the match.

**Attendance**: The number of spectators present at the venue.

**Captain**: The name of the team captain.

**Formation**: The team's formation.

**Referee**: The name of the match referee.

**Match Report**: A link or reference to a detailed match report.

**Notes**: Any additional notes about the match.

**Sh (Shots)**: Total number of shots taken by the team.

**SoT (Shots on Target)**: Number of shots on target.

**Dist**: Average distance (likely in meters) from which shots were taken.

**FK**: Number of free kicks taken.

**PK (Penalty Kicks)**: Number of penalty kicks scored.

**PKatt (Penalty Kicks Attempted)**: Number of penalty kicks attempted.

**Season**: The season year.

**Team**: The team the data row is about.",.csv
"English Premier League Players Dataset, 2017/18",1,english-premier-league-players-dataset,epldata_final.csv,CC0-1.0,"### Context

For most football fans, May - July represents a lull period due to the lack of club football. What makes up for it, is the intense transfer speculation that surrounds all major player transfers today. Their market valuations also lead to a few raised eyebrows, lately more than ever.  I was curious to see how good a proxy **popularity** could be for **ability**, and the predictive power it would have in a model estimating a player's market value. 


### Content

**name**: Name of the player
   
**club**: Club of the player
  
**age** : Age of the player
  
**position** : The usual position on the pitch  

**position_cat** :  
   
+ 1 for attackers  

+ 2 for midfielders  

+ 3 for defenders  

+ 4 for goalkeepers   

**market_value** : As on transfermrkt.com on July 20th, 2017  

**page_views** : Average daily Wikipedia page views from September 1, 2016 to May 1, 2017  

**fpl_value** : Value in Fantasy Premier League as on July 20th, 2017  

**fpl_sel** : % of FPL players who have selected that player in their team  

**fpl_points** : FPL points accumulated over the previous season  

**region**:  
 
+ 1 for England  

+ 2 for EU  

+ 3 for Americas  

+ 4 for Rest of World   

**nationality**   

**new_foreign** : Whether a new signing from a different league, for 2017/18 (till 20th July)  

**age_cat**  

**club_id**  

**big_club**: Whether one of the Top 6 clubs  

**new_signing**: Whether a new signing for 2017/18 (till 20th July)  



### Inspiration

To statistically analyse the beautiful game.",.csv
English Premier League(2020-21),1,english-premier-league202021,EPL_20_21.csv,CC0-1.0,"### Context

This dataset is a collection of basic but crucial stats of the English Premier League 2020-21 season. The dataset has all the players that played in the EPL and their standard stats such as Goals, Assists, xG, xA, Passes Attempted, Pass Accuracy and more! Do upvote if you like it!

### Content

| Attribute | Description |
| --- | --- |
| Position | Each player has a certain position, in which he plays regularly. The position in this dataset are, FW - Forward, MF - Midfield, DF - Defensive, GK - Goalkeeper |
| Starts | The number of times the player was named in the starting 11 by the manager. |
| Mins | The number of minutes played by the player. |
| Goals | The number of Goals scored by the player. |
| Assists | The number of times the player has assisted other player in scoring the goal. |
| Passes_Attempted | The number of passes attempted by the player. |
| Perc_Passes_Completed | The number of passes that the player accurately passed to his teammate. |
| xG | Expected number of goals from the player in a match. |
| xA | Expected number of assists from the player in a match. |
| Yellow_Cards | The players get a yellow card from the referee for indiscipline, technical fouls, or other minor fouls. |
| Red Cards | The players get a red card for accumulating 2 yellow cards in a single game, or for a major foul. |   

### Inspiration

There are several directions you can take with this dataset:
1) Find out which team has the most aggressive defenders (or players for that matter)
2) Which team had more players in the top 10 most assists chart
3) Who were the players with most attempted passes
4) Which players had the most accurate passes excluding the goal keeper and the defenders
5) Defenders with most goals!!
6) Which nation had the most aggressive players?
the possibilities are endless, create a notebook and explore them! ",.csv
English Word Frequency,1,english-word-frequency,unigram_freq.csv,other,"### Context: 

How frequently a word occurs in a language is an important piece of information for natural language processing and linguists. In natural language processing, very frequent words tend to be less informative than less frequent one and are often removed during preprocessing. Human language users are also sensitive to  word frequency. How often a word is used affects language processing in humans. For example, [very frequent words are read and understood more quickly](http://econtent.hogrefe.com/doi/abs/10.1027/1618-3169/a000123?journalCode=zea) and can be [understood more easily in background noise](http://asa.scitation.org/doi/abs/10.1121/1.1918432).

### Content: 

This dataset contains the counts of the 333,333 most commonly-used single words on the English language web, as derived from the Google Web Trillion Word Corpus.

### Acknowledgements: 

Data files were derived from the Google Web Trillion Word Corpus (as [described](https://research.googleblog.com/2006/08/all-our-n-gram-are-belong-to-you.html) by Thorsten Brants and Alex Franz, and [distributed](https://catalog.ldc.upenn.edu/LDC2006T13) by the Linguistic Data Consortium) by Peter Norvig. You can find more information on these files and the code used to generate them [here](http://norvig.com/ngrams/).

The code used to generate this dataset is distributed under the [MIT License](https://en.wikipedia.org/wiki/MIT_License). 

### Inspiration:

* Can you tag the part of speech of these words? Which parts of speech are most frequent? Is this similar to other languages, like [Japanese](https://www.kaggle.com/rtatman/japanese-lemma-frequency)?
* What differences are there between the very frequent words in this dataset, and the the frequent words in other corpora, such as the [Brown Corpus](https://www.kaggle.com/nltkdata/brown-corpus) or the [TIMIT corpus](https://www.kaggle.com/nltkdata/timitcorpus)? What might these differences tell us about how language is used? ",.csv
Environment Impact of Food Production,1,environment-impact-of-food-production,Food_Production.csv,DbCL-1.0,"### Context

As the world’s population has expanded and gotten richer, the demand for food, energy and water has seen a rapid increase. Not only has demand for all three increased, but they are also strongly interlinked: food production requires water and energy; traditional energy production demands water resources; agriculture provides a potential energy source. This article focuses on the environmental impacts of food. Ensuring everyone in the world has access to a nutritious diet in a sustainable way is one of the greatest challenges we face.


### Content

This dataset contains most 43 most common foods grown across the globe and 23 columns as their respective land, water usage and carbon footprints. 

Columns
1. Land use change - Kg CO2 - equivalents per kg product 
2. Animal Feed - Kg CO2 - equivalents per kg product
3. Farm   - Kg CO2 - equivalents per kg product
4. Processing - Kg CO2 - equivalents per kg product
5. Transport - Kg CO2 - equivalents per kg product
6. Packaging - Kg CO2 - equivalents per kg product
7. Retail - Kg CO2 - equivalents per kg product

These represent greenhouse gas emissions per kg of food product(Kg CO2 - equivalents per kg product) across different stages in the lifecycle of food production.

Eutrophication – the pollution of water bodies and ecosystems with excess nutrients – is a major environmental problem. The runoff of nitrogen and other nutrients from agricultural production systems is a leading contributor.

### Acknowledgements
https://ourworldindata.org


### Inspiration

1. Which types of food have more negative impact on the environment?
2. What types of food production should be encouraged to consume nutritious diet in a sustainable way?
3. Which stage of food production contributes more to the greenhouse gas emmision?
4. Compare carbon footprint of plant-based foods?
5. Compare carbon footprint of animal-based foods?
6. Compare carbon footprint of protein rich foods?",.csv
Ethereum Data,1,ethereum-data,ETH-USD.csv,other,"## **What is Ethereum?**
Ethereum is a decentralized, open-source blockchain with smart contract functionality. Ether (ETH or Ξ) is the native cryptocurrency of the platform. After Bitcoin, it is the largest cryptocurrency by market capitalization. Ethereum is the most actively used blockchain. Ethereum was proposed in 2013 by programmer Vitalik Buterin. 

## **Data Description**
This dataset provides the history of daily prices of Ethereum. The data starts from 07-Aug-2015. All the column descriptions are provided. Currency is USD.
",.csv
Ethereum Fraud Detection Dataset,1,ethereum-frauddetection-dataset,transaction_dataset.csv,DbCL-1.0,"### Context

This dataset contains rows of known fraud and valid transactions made over Ethereum, a type of cryptocurrency. This dataset is **imbalanced**, so keep that in mind when modelling


### Content

Here is a description of the rows of the dataset:

- Index: the index number of a row
- Address: the address of the ethereum account
- FLAG: whether the transaction is fraud or not
- Avg min between sent tnx: Average time between sent transactions for account in minutes
- Avg_min_between_received_tnx: Average time between received transactions for account in minutes
- Time_Diff_between_first_and_last(Mins): Time difference between the first and last transaction
- Sent_tnx: Total number of sent normal transactions
- Received_tnx: Total number of received normal transactions
- Number_of_Created_Contracts: Total Number of created contract transactions
- Unique_Received_From_Addresses: Total Unique addresses from which account received transactions
- Unique_Sent_To_Addresses20: Total Unique addresses from which account sent transactions
- Min_Value_Received: Minimum value in Ether ever received
- Max_Value_Received: Maximum value in Ether ever received
- Avg_Value_Received5Average value in Ether ever received
- Min_Val_Sent: Minimum value of Ether ever sent
- Max_Val_Sent: Maximum value of Ether ever sent
- Avg_Val_Sent: Average value of Ether ever sent
- Min_Value_Sent_To_Contract: Minimum value of Ether sent to a contract
- Max_Value_Sent_To_Contract: Maximum value of Ether sent to a contract
- Avg_Value_Sent_To_Contract: Average value of Ether sent to contracts
- Total_Transactions(Including_Tnx_to_Create_Contract): Total number of transactions

- Total_Ether_Sent:Total Ether sent for account address
- Total_Ether_Received: Total Ether received for account address
- Total_Ether_Sent_Contracts: Total Ether sent to Contract addresses
- Total_Ether_Balance: Total Ether Balance following enacted transactions 
- Total_ERC20_Tnxs: Total number of ERC20 token transfer transactions
- ERC20_Total_Ether_Received: Total ERC20 token received transactions in Ether
- ERC20_Total_Ether_Sent: Total ERC20token sent transactions in Ether
- ERC20_Total_Ether_Sent_Contract: Total ERC20 token transfer to other contracts in Ether
- ERC20_Uniq_Sent_Addr: Number of ERC20 token transactions sent to Unique account addresses
- ERC20_Uniq_Rec_Addr: Number of ERC20 token transactions received from Unique addresses
- ERC20_Uniq_Rec_Contract_Addr: Number of ERC20token transactions received from Unique contract addresses
- ERC20_Avg_Time_Between_Sent_Tnx: Average time between ERC20 token sent transactions in minutes
- ERC20_Avg_Time_Between_Rec_Tnx: Average time between ERC20 token received transactions in minutes
- ERC20_Avg_Time_Between_Contract_Tnx: Average time ERC20 token between sent token transactions
- ERC20_Min_Val_Rec: Minimum value in Ether received from ERC20 token transactions for account
- ERC20_Max_Val_Rec: Maximum value in Ether received from ERC20 token transactions for account
- ERC20_Avg_Val_Rec: Average value in Ether received from ERC20 token transactions for account
- ERC20_Min_Val_Sent: Minimum value in Ether sent from ERC20 token transactions for account
- ERC20_Max_Val_Sent: Maximum value in Ether sent from ERC20 token transactions for account
- ERC20_Avg_Val_Sent: Average value in Ether sent from ERC20 token transactions for account
- ERC20_Uniq_Sent_Token_Name: Number of Unique ERC20 tokens transferred
- ERC20_Uniq_Rec_Token_Name: Number of Unique ERC20 tokens received
- ERC20_Most_Sent_Token_Type: Most sent token for account via ERC20 transaction
- ERC20_Most_Rec_Token_Type: Most received token for account via ERC20 transactions
",.csv
Ethereum Transaction Dataset (RAW),1,ethereum-transaction-dataset-raw,ethereum.csv,other,"Explore Ethereum Transaction Dataset: Dive into the world of Ethereum blockchain with this dataset, containing transaction details. Analyze transaction patterns, track the flow of funds, and uncover insights into one of the leading cryptocurrencies.
[Source](https://etherscan.io/)",.csv
Ethnicity of Victims of Crimes in LA ,1,ethnicity-of-victims-of-crimes-in-la-2020-2024,crime totals - vict_info.csv,CC0-1.0,This dataset shows how many victims of crime and their ethnicity between 2020 to early 2024. It also reveals the average age of an victim in LA. This dataset was created from the data published by the LAPD and can be found [here](https://catalog.data.gov/dataset/crime-data-from-2020-to-present).,.csv
Europe Bike Store Sales,1,europe-bike-store-sales,Sales.csv,CC0-1.0,"In the Europe bikes dataset, Extract the insight into sales in each country and each state of their countries using Excel. 
",.csv
European Ski Resorts ,1,european-ski-resorts,European_Ski_Resorts.csv,other,"### Context

Skiing in Europe is an experience unlike any other in the world.  The mountain villages, history and traditions, cultural diversity from one valley to the next, plus of course the food and drink, mix wonderfully with the huge terrain, incredible lift systems and great (artificial) snow.  Spending the night in an Italian mountain rifugio or an Austrian guesthouse dating from the 1500s add layers to European ski holidays that make it unforgettable. Once you ski Europe, you will definitely be back for more.

The number of ski resorts in Europe is massive, easily exceeding 1000. However, if you are looking for your next ski destination in Europe it is easy to get lost. Are you looking for the cheapest and best value for money ski resort? Or maybe just the biggest and most famous destinations with great lift connectivity and slopes? If you are like me, you might get overwhelmed when having to make decisions for your next holiday destination (ugh.. luxury problems). In such cases, I always like to go for a data driven approach, that will help me find an optimum solution.

### Content

The ski resort data has been obtained from Ski-resort-stats.com as a snapshot in February 2022. 

### Acknowledgements

Thanks to Ski-resort-stats.com!
",.csv
European Union Visitor Visa Database,1,european-union-schengen-visa-statistics,visitor-visa-statistics.csv,CC-BY-SA-4.0,"The European Union Visitor Visa Database contains statistics on short-stay visa issuing practices. It is based on official administrative data, cleaned-up to provide a consistent time-series from 2005 to 2022. 

**Background**
As a non-immigrant visa, a visitor visa is typically valid for a visit of up to 3 months and grants access to the entire Schengen area (for the reporting states that are full members of Schengen). Short-stay visas are an important component of border control practices, providing a mechanism for screening visitors before they arrive at the physical borders. 

The statistics are reported in the original administrative data on a per consulate level. A reporting state will typically be a member of the European Union (EU) and the Schengen free travel area. The dataset does include, however, statistics reported by states in the process of becoming Schengen members. It also includes data from European countries that are a part of the Schengen but not members of the EU, such as Norway. 

The dataset includes a column with the refusal rate calculated as the share of visas not issued as a total of the number of visas issued and not issued. Note that visas issued includes both explicit refusals as well as lapsed or otherwise discontinued applications. 

The dataset made available here includes application statistics. It should be noted that these cover only one albeit important component of the common visa policy. Other major elements include the common list of countries subject to a visa requirement in the first place as well as consular cooperation on visa issuing.

The code for creating the dataset, as well as further details on sources, can be found in the [Github repository.](https://github.com/mogenshobolth/eu-visa-policy)

**Use cases**
The dataset can be used to probe questions on the state and evolution of EU cooperation in the area of borders and migration control. Problems that can be investigated with the data include for example: 
- Patterns of liberal and restrictive border practices and their determinants. 
- The degree of harmonization, convergent and divergent visa practices, between EU states

**Acknowledgements**
As detailed in the repository, the raw data is processed (cleaned-up) as evidenced in the source code. The data for 2005-2012 have been imported relying on earlier data clean-up done in connection with the construction of the European Visa Database (see background section). The country classification (income group and regions) are sourced from The World Bank: World Bank Country and Lending Groups: Country classification dataset",.csv
Every Pub in England,1,every-pub-in-england,open_pubs.csv,other,"### Context: 
Pubs, or public houses, are popular traditional British gathering places where alcohol and food is served.

### Content: 

This dataset includes information on 51,566 pubs. This dataset contains the following columns:

* fsa_id	(int): Food Standard Agency's ID for this pub.
* name (string)L Name of the pub
* address (string): Address fields separated by commas.
* postcode (string): Postcode of the pub.
* easting (int)	
* northing (int)	
* latitude (decimal)	
* longitude (decimal)	
* local_authority	 (string): Local authority this pub falls under.

### Acknowledgements: 

The data was derived from the Food Standard Agency's Food Hygiene Ratings and the ONS Postcode Directory. The data is licensed under the Open Government Licence. (See the included .html file.)

### Inspiration: 

You could use this data as the basis for a real-life travelling salesman problem and plan the world’s longest pub crawl.",.csv
Evidence Detection in Cloud Forensics,1,evidence-detection-in-cloud-forensics,VMResourceUtilizationSlope.csv,CC-BY-SA-4.0,"Cloud forensics is different than digital forensics because of the architectural implementation of the cloud. In an Infrastructure as a Service (IaaS) cloud model. Virtual Machines (VM) deployed over the cloud can be used by adversaries to carry out a cyber-attack using the cloud as an environment. Investigation of such a crime requires sufficient evidence data to prove the attack in the court of law. Electronic evidence (EE) is any data that produce information relevant to the investigation.  Identifying evidence from the data generated in a cloud environment is a tedious and manual process. Adhering to RFC 3227 the evidence collection can be carried out once the evidence data is detected with appropriate triage.

Cyber attack originating from a VM leaves its trails on the resource that it utilizes. These patterns of attacks on the resource and its properties can be used to detect and acquire evidence data generated in a cloud.

We have generated a dataset using the following settings:

To generate the dataset a private cloud was set up. The system configuration included Intel® CoreTM i5-4590 Processor with 12 GB of RAM with 1TB of HDD. The private cloud setup was done using a KVM type-1 hypervisor along with OpenNebula (version 5.12) as a cloud management platform. To simulate the real-time cloud environment a script generating synthetic workload was deployed on the virtual machines of the cloud. An attack was carried out. The dataset is manually tagged with the known state of attack or normal to respective VM.",.csv
Evolution of Humans DataSets for Clasification,1,evolution-of-humans-datasets-for-clasification,Evolution_DataSets.csv,Apache 2.0,"In this dataset, we delve into the fascinating story of human evolution. With 12000 rows and 28 columns, this dataset covers a wide range of characteristics of different hominids, from the earliest consensual ancestors to modern Homo sapiens. This comprehensive compilation aims to facilitate the search for relationships between various key variables, thereby providing a more complete and detailed understanding of human evolution.

Objectives:
The objective is to predict either the gender and species or whether they were bipedal or not.
Also, the objective is to avoid the overfeeding of the model, because there are several models that show signs of overfeeding

About the Data:
Genus & Species: (categorical) This column contains the genus and specific name of the species. It provides taxonomic information about each hominid included in the dataset, allowing for precise identification

Time : (categorical) This column indicates the time period during which each hominid species lived. It helps to establish chronological context and understand the temporal distribution of different hominid groups.

Location: (categorical) This column records the continent location where each hominid species lived.

Zone: (categorical) Describes either east, west, south or north of the continent

Current Country: (categorical) Records the modern-day country associated with the location where each hominid species lived, facilitating geographical comparisons.

Habitat: (categorical) This column describes the typical habitat or environment inhabited by each hominid species. It provides information about the ecological niche and adaptation strategies of different hominids throughout history.

Cranial Capacity: (numeric) This column provides data on the cranial capacity of each hominid species. Cranial capacity is a key indicator of brain size and can offer insights into cognitive abilities and evolutionary trends.

Height: (numeric) Describes the average height or stature of each hominid species

Incisor Size: (categorical) Indicates the size of the incisors in each hominid species

Jaw Shape: (categorical) Describes the shape or morphology of the jaw in each hominid species

Torus Supraorbital: (categorical) Specifies the shape or morphology of a supraorbital torus in each hominid species

Prognathism: (categorical) Indicates the degree of facial prognathism or protrusion in each hominid species

Foramen Mágnum Position: (categorical) Describes the position of the foramen magnum in each hominid species

Canine Size: (categorical) Indicates the size of the canines in each hominid species

Canines Shape: (categorical) Describes the shape of the canines in each hominid species, providing information about their dietary adaptations and social behavior.

Tooth Enamel: (categorical) Specifies the characteristics of tooth enamel in each hominid species, which may indicate aspects of dietary ecology and dental health.

Tecno: (categorical) Records the presence or absence of technological advancements

Tecno Type: (categorical) Describes the specific type or style of technology associated with each hominid species

Biped: (categorical) Indicates whether each hominid species exhibited bipedal locomotion, a key characteristic distinguishing humans from other primates.

Arms: (categorical) Describes the morphology or characteristics of the arms in each hominid species, offering insights into their locomotor adaptations and manual dexterity.

Foots: (categorical) Specifies the morphology or characteristics of the feet in each hominid species, providing information about their locomotor adaptations and foot anatomy.

Diet: (categorical) Characterizes the dietary habits or preferences of each hominid species

Sexual Dimorphism: (categorical) Indicates the degree of sexual dimorphism

Hip: (categorical) Describes the size of the hip in each hominid species

Vertical Front: (categorical) Specifies the presence or absence of verticality or curvature of the frontal bone in each hominid species, providing information about their cranial morphology.

Anatomy: (categorical) Provides additional information about the anatomical features or characteristics of each hominid species, aiding in comprehensive morphological analyses.

Migrated: (categorical) Indicates whether each hominid species exhibited migration or movement to different geographical areas, offering insights into their dispersal patterns and population dynamics.

Skeleton: (categorical) Describes additional information about anatomy",.csv
"Exchange Rate : PKR, INR, USD (1947-2024)",1,exchange-rate-pkr-inr-usd-1947-2024,rupee_vs_dollar.csv,Apache 2.0,"**_Introduction:_**
A Comprehensive Historical Tracking of PKR, INR, and USD Exchange Rates from 1947 to 2024. Delve into Pakistan and India's economic narratives in reference to the US Dollar, witnessing the fluctuations, trends, and pivotal moments that shaped their currencies over eight decades. Gain insights into geopolitical shifts, economic policies, and global events, understanding the intricate dynamics of these currencies in the ever-changing financial landscape.


**_Background:_** 
I'm teaching my students about the difference between the Pakistani Rupee and the Indian Rupee since 1947. We're using the US Dollar as a standard for comparison. I gathered this dataset from various internet sources.

**_About the data:_**
The dataset is tabular and contains three columns:
1. Year: Ranging from 1947 to 2024.
2. INR (Rs): Indian Rupee value equivalent to 1 US Dollar.
3. PKR (Rs): Pakistani Rupee value equivalent to 1 US Dollar.

**_Use Cases:_**
here are some use cases for this dataset.

**1. Historical Analysis:** 
Researchers or economists could use the dataset to analyze the historical trends and fluctuations in exchange rates between PKR, INR, and USD over the years. This analysis could provide insights into the economic performance and stability of Pakistan and India in relation to the US.

**2. Educational Purposes:** 
As you're using it for teaching, the dataset can serve as a valuable educational resource for students to understand the economic differences between Pakistan and India since their independence, using the USD as a benchmark.

**3. Investment Analysis:** 
Investors and financial analysts could use the dataset to analyze the historical performance of the currencies and make informed decisions about investments or currency trading in the Pakistan and India markets.

**4. Policy Making:** 
Government policymakers could utilize the dataset to understand the impact of various economic policies on currency exchange rates and formulate effective strategies for maintaining stability and growth.

**5. Cross-Border Transactions:**
Businesses engaged in cross-border trade between Pakistan, India, and the US could use the dataset to forecast currency exchange rates and mitigate risks associated with fluctuations in currency values.

**6. Comparative Studies:** 
Scholars or analysts interested in comparative studies between Pakistan and India could use the dataset to explore the differences and similarities in their economic development trajectories over time.

**7. Forecasting:** 
Economists or analysts could develop models to forecast future exchange rates based on historical trends and factors affecting the economies of Pakistan, India, and the US.",.csv
Exercise and Fitness Metrics Dataset,1,exercise-and-fitness-metrics-dataset,exercise_dataset.csv,Community Data License Agreement - Sharing - Version 1.0,"The ""Exercise and Fitness Metrics Dataset: Independent Variables and Weight Related Measures"" is a comprehensive dataset that captures various factors related to exercise, fitness, and weight management. The dataset includes a range of independent variables along with measurements of dream weight and actual weight.
![image](https://www.lagrange.edu/academics/undergraduate/majors/exercise-science/major-exercise-science.jpg)

The exercise variable represents the type of exercise performed, while calories burned denotes the estimated number of calories burnt during the exercise session. Dream weight signifies the desired weight, and actual weight captures the measured weight with some natural variation.

Additional independent variables provide insights into the individuals performing the exercises. Age represents the age of the individuals, and gender indicates their gender (Male or Female). Duration records the length of each exercise session, and heart rate represents the average heart rate during the session. BMI, a commonly used health indicator, offers information about body composition. Weather conditions during exercise sessions are recorded, and exercise intensity provides a rating of the intensity level.

![image](https://images.theconversation.com/files/349366/original/file-20200724-25-osy3a3.PNG?ixlib=rb-1.1.0&q=45&auto=format&w=754&fit=clip)

This dataset is valuable for analyzing relationships between exercise variables, calorie expenditure, weight-related measures, and other factors such as age, gender, duration, heart rate, BMI, weather conditions, and exercise intensity. It can be used for various purposes, including research in exercise science, fitness program development, weight management analysis, and correlation studies between exercise and health-related factors.",.csv
Experience Salary Dataset,1,experience-salary-dataset,Experience-Salary.csv,other,This dataset contains information on the relationship between work experience (in months) and corresponding monthly salaries (in thousand dollars) of employees across various industries. It is designed to help data enthusiasts and aspiring data scientists practice linear regression techniques by analyzing and modeling salary predictions based on experience.,.csv
Explore India: A Tourist Destination Dataset,1,explore-india-a-tourist-destination-dataset,Expanded_Indian_Travel_Dataset.csv,CC0-1.0,"Explore the rich tapestry of India with our comprehensive travel dataset, ""India Travel Guide: Destinations and Transports"". This meticulously curated collection covers 156 of India's most famed and under-the-radar destinations, offering a thorough guide for travelers and researchers alike.",.csv
Exploring Toronto's Rental : Kijiji Data analysis ,1,toronto-kijiji-rental-data,kijiji_rental_ads_4106.csv,MIT,"This dataset provides a comprehensive snapshot of the apartment and condo rental market in the City of Toronto, sourced from Kijiji, a popular online classified advertising platform. With detailed attributes such as price, location, property features, and amenities, this dataset offers valuable insights for individuals and organizations interested in understanding the dynamics of the rental market in Toronto. Analysts can leverage this dataset for various purposes, including market analysis, trend identification, and predictive modeling. Whether you're a researcher, data scientist, or real estate professional, this dataset serves as a valuable resource for exploring and understanding Toronto's vibrant rental landscape.
<br>
**Features/Columns Information**  
    **Title** : The title of the apartment or condo listing.<br>
    **Price** : The rental price of the property in Canadian dollars.<br>
   **Address** : The address or location of the property.<br>
   **Date Posted** : The date when the listing was posted on Kijiji.<br>
    **Building Type** : The type of building the property is located in (apartment, condo,house).<br>
    **Bedrooms** : The number of bedrooms in the property.<br>
    **Bathrooms** : The number of bathrooms in the property.<br>
    **Utilities** : Information about utilities included in the rental agreement(Hydro,Heat and Water)<br>
    **Wi-Fi and More** : Details about internet/Wi-Fi and other amenities available.<br>
    **Parking Included** : Indicates whether parking is included in the rental.<br>
    **Agreement Type** : The type of rental agreement (Yearly, month-to-month).<br>
    **Pet Friendly** : Indicates whether pets are allowed in the rental.<br>
    **Size (sqft)** : The size of the property in square feet.<br>
    **Furnished** : Indicates whether the property is furnished or not.<br>
    **Air Conditioning** : Information about air conditioning availability.<br>
    **Personal Outdoor Space** : Details about any personal outdoor space associated with the property.<br>
    **Smoking Permitted** : Indicates whether smoking is permitted in the rental.<br>
    **Description** : Additional details about the property provided in the listing.<br>
    **Visit Counter** : The number of visits or views the listing has received on Kijiji.<br>
    **URL** : The URL link to the original listing on Kijiji's website.<br>",.csv
Exploring Water Quality,1,exploring-water-quality,water_quality.csv,MIT,"This dataset comprises a collection of records detailing the water quality across different cities, regions, and countries. Each entry contains information regarding the city, region, and country where the water sample was taken. Additionally, the dataset records various water quality parameters, including air quality (AirQuality), water pollution (WaterPollution), pH level (ph), water hardness (Hardness), soluble solids content (Solids), chloramines concentration (Chloramines), sulfate levels (Sulfate), conductivity (Conductivity), organic carbon content (Organic_carbon), trihalomethanes concentration (Trihalomethanes), turbidity (Turbidity), and potability status (Potability) of the water. By analyzing this dataset, we can explore the relationships between various factors and draw valuable conclusions regarding water quality and potability across different locations worldwide.",.csv
Extreme poverty,1,extreme-poverty,poverty-share-on-less-than-30-per-day.csv,CC0-1.0,"### Context

Two centuries ago the majority of the world population was extremely poor. Back then it was widely believed that widespread poverty was inevitable. But this turned out to be wrong. Economic growth is possible and poverty can decline. The world has made immense progress against extreme poverty.

But even after two centuries of progress, extreme poverty is still the reality for every tenth person in the world. This is what the ‘international poverty line’ highlights – this metric plays an important (and successful) role in focusing the world’s attention on these very poorest people in the world.

The poorest people today live in countries which have achieved no growth. This stagnation of the world’s poorest economies is one of the largest problems of our time. Unless this changes millions of people will continue to live in extreme poverty.

### Content

Data comes from https://ourworldindata.org/extreme-poverty-in-brief
Thanks to them to aggregate this kind of informations!

### Acknowledgements

![Extreme Poverty](https://media.globalcitizen.org/thumbnails/90/19/90190c20-1182-47d6-a86e-3a2dcc912e73/extreme-poverty-un-explainer-social-share.jpg__1500x670_q85_ALIAS-hero_image_crop_subsampling-2.jpg)

### Inspiration

Compare country, by year the % of persons in extreme poverty",.csv
Eye State Classification EEG Dataset,1,eye-state-classification-eeg-dataset,EEG_Eye_State_Classification.csv,CC0-1.0,"# Eye State Classification EEG Dataset

All data is from one continuous EEG measurement with the Emotiv EEG Neuroheadset.

The duration of the measurement was 117 seconds.

The eye state was detected via a camera during the EEG measurement and added later manually to the file after analysing the video frames.

Target:
- `1` indicates the eye-closed and
- `0` the eye-open state.

All values are in chronological order with the first measured value at the top of the data.

Reference link: https://archive.ics.uci.edu/ml/datasets/EEG+Eye+State
",.csv
F1 Drivers dataset,1,f1-drivers-dataset,F1Drivers_Dataset.csv,Apache 2.0,"Whether you're a seasoned motorsport enthusiast, an aspiring data scientist, or a curious fan, this dataset opens the doors to a plethora of analytical opportunities. Explore the evolution of driver strategies, track-specific adaptations, and team dynamics that contribute to the intense competition witnessed on iconic circuits worldwide. Uncover patterns, outliers, and trends that illuminate the nuances of F1 racing, shedding light on what separates the champions from the contenders.",.csv
FDA-approved BRCA chemotherapy drugs in BindingDB,1,fda-approved-brca-chemotherapy-drugs-in-bindingdb,Taxol_FDA.csv,MIT,"These datasets downloaded from [BindingDB](https://www.bindingdb.org/) website.
Some of these drugs are common in treatment of several cancers. But some of them are mostly using for breast cancer.

As you may see in [Leash - Bio Competition](https://www.kaggle.com/competitions/leash-BELKA), SMILES (Simplified Molecular-Input Line-Entry System) is a widely used chemical notation method for describing the structure of chemical molecules using short ASCII strings.
The SMILES notation allows researchers to efficiently encode and share molecular structures in databases, publications, and software tools. It also enables the use of computational methods for chemical structure searches, similarity comparisons, and prediction of molecular properties, making SMILES an essential tool in modern computational chemistry and drug discovery.

Protein binding refers to the specific and non-covalent interactions that occur between proteins and other molecules, such as other proteins, nucleic acids, small molecules, or ions. These interactions play crucial roles in various biological processes, including signal transduction, enzyme catalysis, and cellular structural organization. Understanding protein binding is essential for studying molecular mechanisms, developing new drugs, and elucidating cellular functions.",.csv
FIFA 19 complete player dataset,1,fifa-19-complete-player-dataset,kl.csv,CC-BY-NC-SA-4.0,"Context
Football analytics

Content
Detailed attributes for every player registered in the latest edition of FIFA 19 database.

Acknowledgments
Data scraped from https://sofifa.com/

Inspiration
Inspired by this dataset: https://www.kaggle.com/thec03u5/fifa-18-demo-player-dataset",.csv
FIFA 20 Complete Player Dataset,1,players-20,players_20.csv,MIT,"# Overview:
```
The FIFA 20 Complete Player Dataset offers a comprehensive collection of player data extracted exclusively from the Career Mode of FIFA 20, the latest installment in the FIFA video game series. This dataset enables in-depth analysis of player attributes, allowing enthusiasts to delve into player statistics, trends, and gameplay dynamics specific to FIFA 20.
```

# Source:
```
The dataset has been meticulously curated from the publicly available website SoFIFA, a prominent platform renowned for providing detailed player statistics and information tailored for FIFA gamers and enthusiasts.
```

# Contents:
```
Containing data for every player featured in FIFA 20, the dataset encompasses over 100 attributes for each player. These attributes span various skill sets including Attacking, Skills, Defense, Mentality, and GK Skills. Additionally, the dataset includes personal data for each player such as nationality, club affiliation, date of birth, wage, salary, and more.
```

# Potential Analyses:

* Player Evolution Analysis: Explore the evolution of player attributes over time within FIFA 20, identifying trends and changes in player performance throughout the game's lifecycle.
* Team Building Analysis: Analyze optimal budget allocations for assembling competitive teams within FIFA 20. Determine the budget thresholds for acquiring significantly better players for the starting eleven lineup, considering various team compositions and strategies.
* Top Percentile Player Trends: Investigate attribute trends among the top percentile of players in FIFA 20, examining key attributes such as Agility, Ball Control, and Strength. Identify shifts in attribute preferences and gameplay dynamics to gain insights into strategic gameplay approaches.

# Acknowledgements:

The dataset has been sourced from SoFIFA, a reputable platform dedicated to providing comprehensive player statistics and information for FIFA enthusiasts. We extend our gratitude to SoFIFA for their invaluable contribution to the FIFA gaming community.

### https://sofifa.com/",.csv
FIFA 2021 Complete Player Dataset,1,fifa-2021-complete-player-data,FIFA-21 Complete.csv,CC0-1.0,"### Context

We all enjoy playing our beloved Football Game on and off field. FIFA has been a game that is played by many people across the globe and has come up with many many editions. It latest release is going to be in October this year i.e. FIFA 2021. This data set contains the data of the players in game.


### Content

The data set contains data of players Rating, their age, their nationality, the position that they play and their potential for growth in game. The data for a few players and their clubs might not be very accurate as the transfer window is still open and changes might be made in later stages.


### Acknowledgements

The data set was taken from fifaindex.com. All the credits to them for the data.
",.csv
FIFA 21 COMPLETE PLAYER DATASET,1,fifa-21-complete-player-dataset,fifa21_male2.csv,other,"### Context

Football analytics, Sports Analytics, FIFA Series

### Acknowledgements

Data has been scraped from the publicly available website https://sofifa.com.


### Inspiration

Inspired from this dataset: 
- https://www.kaggle.com/stefanoleone992/fifa-20-complete-player-dataset
- https://www.kaggle.com/karangadiya/fifa19
- https://www.kaggle.com/thec03u5/fifa-18-demo-player-dataset",.csv
FIFA Soccer Rankings,1,fifa-international-soccer-mens-ranking-1993now,fifa_ranking.csv,CC0-1.0,"### Context
The world football governing body FIFA has been ranking international teams since 1992. This dataset contains all available FIFA men's international soccer rankings from August 1993 to April 2018. The rankings and points have been scraped from the official FIFA website. 

A more detailed explanation and history of the rankings is available here: https://en.wikipedia.org/wiki/FIFA_World_Rankings

An explanation of the ranking procedure is available here: https://www.fifa.com/fifa-world-ranking/procedure/men.html

Includes all ~200 teams and available data from 1993-2018.

----------

### Content

All features available on the FIFA ranking page (https://www.fifa.com/fifa-world-ranking/ranking-table/men/index.html).

* Rank
* Country
* Country Abbreviation
* Total Points 
* Previous Points
* Rank Change
* Average Previous Years Points
* Average Previous Years Points Weighted (50%)
* Average 2 Years Ago Points 
* Average 2 Years Ago Points Weighted (30%)
* Average 3 Years Ago Points 
* Average 3 Years Ago Points Weighted (20%)
* Confederation

----------

### Acknowledgements

The data was scraped from the official fifa.com site (https://www.fifa.com/fifa-world-ranking/ranking-table/men/index.html)

Github Project:  https://github.com/tadhgfitzgerald/fifa_ranking

----------

### Inspiration

With the world cup coming up in just a  few months what better time to start exploring soccer datasets! 

* Look at how a teams ranking has evolved over the years. 
* Build a world cup predictor.
* Correlate player performance and team ranking.
* Who are the most consistent teams? Who are the least consistent?
* Which confederation is the strongest? Which is the fastest improving?
* Which team has been most dominant? Which has fallen off the most?",.csv
FIFA World Cup 2022 ⚽️🏆,1,fifa-world-cup-2022,international_matches.csv,CC0-1.0,"**Context**
The FIFA World Cup is the most prestigious football tournament in the world.  The championship has been awarded every four years since the start of the tournament in 1930.
 
The current format involves a qualification phase, which takes place over the preceding three years, to determine which teams quality for the tournament. In the tournament, 32 teams, including the host nation, compete for the title at different stadiums in the host country.
 
 The reigning champion is France, which beat Croatia in the 2018 tournament in Russia.  Qatar will host the 2022 tournament, for which the first match will be played in November.
 
This dataset provides a complete overview of all international soccer matches played since the 90s.  On top of that, the strength of each team is provided by incorporating actual FIFA rankings as well as player strengths based on the EA Sport FIFA video game.
 
*NOTE: dataset was updated on 28-08-2022*
 
**Some suggestions**
·       Can you predict what team is most likely to win the 2022 FIFA World Cup?
·       What team has the strongest defense, midfield, and offense players?
·       Is there really such a thing as a home team advantage?
·       Do teams with stronger offense players score more goals? And do teams with stronger goalkeepers receive fewer goals?
·       What team has the longest winning streak?
·       Does the best team always win? Can you explain why a weaker team sometimes win?
 

**Acknowledgements**
1.     [International soccer matches](https://github.com/martj42/international_results) by @martj42 
2.   [FIFA ranking](https://www.fifa.com/fifa-world-ranking) up to June 2018 by @tadhgfitzgerald .  More recent FIFA rankings were scraped from the [FIFA website](https://www.fifa.com/fifa-world-ranking) 
4.    [FIFA player dataset](https://www.kaggle.com/datasets/stefanoleone992/fifa-22-complete-player-dataset) versions 15-22 by @stefanoleone992 . Older versions and FIFA 23 were scraped from www.sofifa.com and www.finfaindex.com.
",.csv
FIFA worldcup 2018 Dataset,1,fifa-worldcup-2018-dataset,World Cup 2018 Dataset.csv,CC-BY-NC-SA-4.0,"**Context:**
Well, we are a head of the largest football event(Soccer, sorry for the American fellows) worldwide, as excited as we were. Well, at least some of us were, by the draw, here comes the data. History of all previous matches, scores and titles of all participating teams to help us predict who will qualify and may even predict who will win. So, lets get our algorithms going.

**Content:**
The dataset contains 32 entries(of the 32 participating teams of course), each team will have 3 matches in the group stage, so each match is mentioned vs whom, the history between those 2 teams with wins minus losses, let's say Brazil has beaten Argentina 14 times, Argentina won 12 and there were 3 draws, so that will be +2 for brazil and -2 for Argentina, the same goes for goals scored.
You will find some entries with N/A and some with zeros, so what is the difference?
The zeros mean that the 2 teams evened out, while N/As means that they have no previous history together and they have never faced each other. So, no data available.
The matches history is up to 2012-2014. So, there is a couple of years missing here, and the FIFA rank is up to date, which will be updated every month till we get there.

**Acknowledgments:**
Most of the data is pulled from FIFA website except for the matches and scores history, they were pulled manually from various credible sources.

Inspiration:
Well, I think this data can help us predict who will head the groups and who comes second, then may be we can progress through round of 16....final. You can ask for more data and I'll be happy to search and update it.

If you like the data or find it useful enough, don't forget the upvote ;)",.csv
Facebook Ad Campaign,1,facebook-ad-campaign,data.csv,ODC Public Domain Dedication and Licence (PDDL),"Simple Dataset from different marketing campaigns. 

The total conversion number shows the total number of signups or installs for instance while approved conversions tells how many became actual active users. 


Courtesy of Bunq. ",.csv
Facebook Reviews [DAILY UPDATE],1,play-store-reviews-facebook,facebook_reviews.csv,MIT,"The dataset scraping is based on the notebook : [https://www.kaggle.com/code/ashishkumarak/google-play-reviews-scraping-daily-update](https://www.kaggle.com/code/ashishkumarak/google-play-reviews-scraping-daily-update)

You can edit the app name to scrape and save the daily data for any app you want.",.csv
Factors Affecting Children Anemia Level,1,factors-affecting-children-anemia-level,children anemia.csv,DbCL-1.0,"In this study, cross-sectional data from the 2018 Nigeria Demographic and Health Surveys (NDHS) were collected to answer research questions about the effect of mothers' age and other socioeconomic factors on children aged 0-59 months anemia level in Nigeria. DHS are cross-sectional, nationally representative household surveys that are typically conducted every 5 years.
This survey data considered the 36 states of Nigeria, as well as the Federal Capital Territory (FCT). The targeted population in this study are children aged 0-59 months and mothers aged 15-49 years.
In this survey, household income was measured using the wealth index, current age in 5-year groups is produced by grouping current age in completed years, type of place of residence where the respondent was interviewed as either urban or rural, the categorization was created based on whether the cluster or sample point number is defined as urban or rural, highest level of education attained is a standardized variable that provides level of education in the following categories: No education, Primary, Secondary, and Higher education, total number of births in the last five years is defined as all births in the months 0 to 59 preceding the month of interview,where month 0 is the month of interview, the respondent's age at first birth is calculated using the CMC of the respondent's date of birth.

After data cleaning, Chi square was used to test the hypotheses about the relationship that likely exist between certain socioeconomic factors and anemia levels in children aged 0-59 months. The anemia level was the predictor variable, and the explanatory variables are mothers' age, education level, wealth index, birth in the previous five years, use of mosquito net, and so on.
Using ordinal logistic regression, the relationship between the dependent variable and independent variables is investigated.

",.csv
Failed Banks Dataset,1,failed-banks-dataset,banklist.csv,Apache 2.0,"The FDIC is often appointed as receiver for failed banks. This list includes banks which have failed since October 1, 2000.

For data science and analytics, this dataset is useful for understanding trends in bank closures over time, geographic patterns in bank stability, and the consolidation of the banking sector through acquisitions. 

You can use it to identify states or regions with higher incidences of bank failures, time periods with increased closures, and the most active acquiring institutions in the banking sector.

Several analyses can be conducted such as:

- **Temporal Analysis**: Examine how bank closures have trended over time.
- **Geographical Analysis**: Analyze the distribution of bank closures across states to identify areas of higher financial risk or distress.
- **Institutional Analysis**: Investigate which acquiring institutions are most active in taking over failing banks.
- **Correlation with Economic Indicators**: By combining this dataset with economic indicators, you can explore correlations between bank closures and broader economic conditions.",.csv
Failure Analysis in Power Transformers Dataset,1,failure-analysis-in-power-transformers-dataset,Health index1.csv,Attribution 4.0 International (CC BY 4.0),"### Context

A transformer can fail for a variety of reasons, but the most common causes include lightning strikes, overloading, wear and corrosion, power surges, and moisture. Regardless of the cause, the result can be remarkable. Transformers contain mineral oil keeping the transformer cool. When it becomes overcharged, the wiring can create heat and a spark. This massive overpressure may eventually cause the transformer to rupture with a loud boom, flash, and possibly a fireball that can create a large plume of smoke that can be seen from a long distance.


### Content

Health index and power transformers result in a CSV file with  16 features. All Features are self-explanatory.


### Acknowledgements

Arias Velásquez, Ricardo Manuel; Mejia Lara, Jennifer (2020), “Data for: Root cause analysis improved with machine learning for failure analysis in power transformers”, Mendeley Data, V1, doi: 10.17632/rz75w3fkxy.1
Dataset is available [here.](https://data.mendeley.com/datasets/rz75w3fkxy/1)",.csv
Fake Bills,1,fake-bills,fake_bills.csv,CC0-1.0,"The dataset includes 1500 rows and 7 columns:

* is_genuine: boolean
* diagonal: float
* height_left: float
* height_right: float
* margin_low: float
* margin_upper: float
* length: float

Idea of projects with this dataset:

* Predicting the missing values with a linear regression or a KNN imputer
* Comparing classification such as logistic regression or KNN with an unsupervised model such as K-Means to predict the authenticity of the bills
* Trying to do a PCA or a Kernel Transform to create a clearer separation between the Genuine and Fake Bills",.csv
Fake Currency Data,1,fake-currency-data,fake_currency_data.csv,Apache 2.0,"This dataset contains synthetic data representing fake currency samples. It includes information such as the country of origin, denomination, whether the currency is genuine or counterfeit, serial numbers, security features, weight, length, width, and thickness of the currency. The dataset can be used for various machine-learning tasks such as classification, anomaly detection, and feature engineering. It is suitable for exploring patterns and trends in counterfeit currency and analyzing the effectiveness of security features.




# If the data helps you, please upvote. Thanks!",.csv
Fake News,1,fake-news,FakeNewsNet.csv,CC0-1.0,"This dataset contains news articles and information about it.

Original: [FakeNewsNet](https://github.com/KaiDMML/FakeNewsNet).

# **Context**
All data is got from [FakeNewsNet](https://github.com/KaiDMML/FakeNewsNet).
The data was cleaned and combined in one file. Some columns were changed. 
You can see preprocessing algorithm [here](https://colab.research.google.com/drive/1AnRzfi6rm4aqpUdf7jbi6usrSsuhnEyW?usp=sharing). 


# **Content**
File contains information about news articles.
Format: CSV.

- *title*: title of the article.
- *news_url*: URL of the article.
- *source domain*: web domain where article was posted.
- *tweet_num*:  number of retweets for this article.
- *real*:  label column, where 1 is real and 0 is fake.",.csv
Fake-Real News,1,fakereal-news,New Task.csv,CC-BY-SA-4.0,"### Context

As we all know, Fake-News has become the centre of attraction worldwide because of its hazardous impact on our society. One of the recent example is spread of Fake-news related to Covid-19 cure, precautions, and symptoms and you must be understood by now, how dangerous this bogus information could be. Distorted piece of information propagated at the times of election for achieving political agenda is not hidden from anyone.

Fake news is quickly becoming an epidemic, and  it alarms and angers me how often and how rapidly totally fabricated stories circulate.
Why? In the first place, the deceptive effect: the fact that if a lie is repeated enough times, you’ll begin to believe it’s true.

You understand by now that fake news and other types of false information can take on various appearances. They can likewise have significant effects, because information shapes our world view: we make important decisions based on information. We form an idea about people or a situation by obtaining information. So if the information we saw on the Web is invented, false, exaggerated or distorted, we won’t make good decisions. 

Hence, Its in dire need  to do something about it and It's a Big Data problem, where data scientist can contribute from their end to fight against Fake-News.


### Content

Although, fighting against fake-News is a big data problem but I have created this small dataset having approx. 10,000 piece of news article and meta-data scraped through approx. 600 web-pages of Politifact website  to analyse it using data science skills and get some insights of how can we stop spread of misinformation at broader aspect and what approach will give us better accuracy to achieve the same. 

This dataset is having 6 attributes among which `News_Headline` is the most important to us in order to classify news as **FALSE** or **TRUE**. As you notice the `Label` attribute clearly, there are 6 classes specified in it. So, it's totally up-to you whether you want to use my dataset for multi-class classification or convert these class labels into **FALSE** or **TRUE** and then, perform binary classification. Although, for your convenience, I will write a notebook on how to convert this dataset from multi-class to binary-class. To deal with the text data, you need to have good hands on practice on NLP & Data-Mining concepts.

- `News_Headline` - contains piece of information that has to be analysed. 
- `Link_Of_News` - contains url of News Headlines specified in very first column.
- `Source` - this column contains author names who has posted the information on facebook, instagram, twitter or any other social-media platform.
- `Stated_On` - This column contains date when the information is posted by the authors on different social-media platforms.
- `Date` - This column contains date when this piece of information is analysed by politifact team of fact-checkers in order to labelize as FAKE or REAL.
- `Label` - This column contains 5 class labels : **True**, **Mostly-True**, **Half-True**, **Barely-True**, **False**, **Pants on Fire**.

So, you can either perform multi-class classification on it or convert Mostly-True, Half-True, Barely-True as True and drop Pants on Fire and perform Binary-class classification.


### Acknowledgements
- A very Big thanks to [fact-checking team of **Politifact.com**](https://www.politifact.com/factchecks/list/) website as they provide with correct labels by working hard manually. So that we data science people can take advantage to train our models on such labels and make better models.
These are some research papers that will help you to get start with the project and clear your fundamentals.

- [Big Data and quality data for fake news and misinformation detection by
Fatemeh Torabi Asr, Maite Taboada] [1]

- [Automatic deception detection: Methods for finding fake news by
Nadia K. Conroy  Victoria L. Rubin  Yimin Chen] [2]

[1]: https://journals.sagepub.com/doi/full/10.1177/2053951719843310
[2]: https://asistdl.onlinelibrary.wiley.com/doi/full/10.1002/pra2.2015.145052010082

### Inspiration

- I want to see which approach can solve this problem of combating Fake-News with greater accuracy.",.csv
Fake/Real Logo Detection Dataset,1,fakereal-logo-detection-dataset,file_mapping.csv,CC0-1.0,"The logos have been resized to a uniform shape of 70x70 to make it less demanding on computational resources and model complexity when training. Though the original files can be 
found on one of my github repos, the link can be found below.
[GitHub Repo](https://github.com/ProsperChuks/logo-data-scraping-processing).
The code used to mine and process the data can also be found on the repo.",.csv
Family Guy Dataset,1,family-guy-dataset,Family Guy Dataset.csv,other,"### Context

Family Guy is an American animated sitcom originally conceived and created by Seth MacFarlane for the Fox Broadcasting Company. The show centers around the Griffins, a dysfunctional family consisting of parents Peter and Lois; their children, Meg, Chris, and Stewie; and their anthropomorphic pet dog, Brian. Set in the fictional city of Quahog, Rhode Island, the show exhibits much of its humor in the form of metafictional cutaway gags that often lampoon American culture.

The family was conceived by MacFarlane after developing two animated films, The Life of Larry and Larry & Steve. MacFarlane redesigned the films' protagonist, Larry, and his dog, Steve, and renamed them Peter and Brian, respectively. MacFarlane pitched a seven-minute pilot to Fox in December 1998, and the show was greenlit and began production. Family Guy's cancellation was announced shortly after the third season had aired in 2002, with one unaired episode eventually premiering on Adult Swim in 2003, finishing the series' original run. Favorable DVD sales and high ratings from syndicated reruns since then convinced Fox to revive the show in 2004.

Since its premiere, Family Guy has received generally positive reviews. In 2009, it was nominated for a Primetime Emmy Award for Outstanding Comedy Series, the first time an animated series was nominated for the award since The Flintstones in 1961. In 2013, TV Guide ranked Family Guy the ninth Greatest TV Cartoon of All Time.

### Content

In this Dataset, we have various information about each Episode/Season of Family Guy. The key features of this Dataset are - Season, No. of Episodes (Season), No. of Episodes (Overall), Title of the Episode, Director, Assistant Director, Written by, Storyboard by, Guest Starring, Featuring, Also Appearing, Musical Numbers, Original Air Date, Product Code, U.S. Viewers (Millions), TV Rating, Running Time (Minutes), Aspect Ratio, Production Companies, IMDb Rating, Synopsis of each Episode.

### Dataset Glossary (Column-wise)

* <b>Season</b> - No. of Seasons
* <b>No. of Episode (Season)</b> - No. of Episode in a particular Season
* <b>No. of Episode (Overall)</b> - No. of Episode in the whole Series
* <b>Title of the Episode</b> - Name of the Episode
* <b>Director</b> - Name(s) of the Director
* <b>Assistant Director</b> - Name(s) of the Assistant Director
* <b>Written by</b> - Name(s) of the Writer
* <b>Storyboard by</b> - Name(s) of the Storyboarder
* <b>Guest Starring</b> - Guest Staring Actors/Actresses
* <b>Featuring</b> - Main Casts of the Episode
* <b>Also Appearing</b> - Secondary Casts for the Episode
* <b>Musical Numbers</b> - Name of the Musical Numbers
* <b>Original Air Date</b> - Original Air Date of the Episode
* <b>Product Code</b> - Product Code for the Episode
* <b>U.S. Viewers (Millions)</b> - No of U.S. Viewers of the Episode in Millions
* <b>TV Rating</b> - TV Rating
* <b>Running Time (Minutes)</b> - Runtime of the Episode in Minutes
* <b>Aspect Ratio</b> - Aspect Ratio of the Episode (Screen)
* <b>Production Companies</b> - Name(s) of the Production Companies
* <b>IMDb Rating</b> - IMDb Rating of the Episode (10 point scale)
* <b>Synopsis</b> - Synopsis of the Episode

### Structure of the Dataset

![](https://i.imgur.com/uTvzTEn.png)


### Acknowledgement

This Dataset is created from <b>[Wikipedia](https://www.wikipedia.org/)</b> and <b>[Fandom](https://www.fandom.com/)</b>. Also, the ratings are taken from <b>[IMDb](https://www.imdb.com/)</b>. If you want to learn more, you can visit the above-mentioned Websites.

Cover Photo by: <b>[WallpaperSet](https://wallpaperset.com/w/full/f/3/a/230201.jpg)</b>",.csv
Fantasy Premier League Dataset 2023-2024,1,fantasy-premier-league-dataset-2023-2024,players.csv,CC0-1.0,"# NEW VERSION

[FPL 2024](https://www.kaggle.com/datasets/meraxes10/fantasy-premier-league-2024)

This is a basic dataset containing the aggregated fantasy premier league data taken from the official website Fantasy Premier League. The data will be updated daily.",.csv
Fashion Clothing Products Dataset,1,fashion-clothing-products-catalog,myntra_products_catalog.csv,CC0-1.0,"### About this Dataset: Fashion Clothing Product Catalog from Myntra.com

Myntra is a major Indian fashion e-commerce company headquartered in Bengaluru, Karnataka, India.] The company was founded in 2007 to sell personalized gift items. In May 2014, Myntra.com was acquired by Flipkart.

### Acknowledgements

Myntra.com and CrawlFeeds .com
Data Collection Method: Scraping and PreProcessing 

### Ideas 
- Identify most expensive products for each category 
- Create a content-based recommendation engine
- What are the most common color that leads increased price. ",.csv
Fashion Products,1,fashion-products,fashion_products.csv,other,"A hybrid recommendation system is a recommendation technique that offers a complete and balanced approach by mixing two or more recommendation techniques. It aims to provide more accurate, diverse and personalized recommendations to users leveraging the strengths of different techniques and providing valuable user experience. If you want to know how to build a hybrid recommendation system, this article is for you. In this article, I will take you through building a Hybrid Recommendation System using Python.",.csv
Fashion Retail Sales,1,fashion-retail-sales,Fashion_Retail_Sales.csv,GPL-2.0,"**Fashion Retail Sales Dataset**

**Introduction**
The ""Fashion Retail Sales"" is a comprehensive collection of data representing sales transactions from a clothing store. This dataset provides valuable insights into the purchasing behavior of customers, the items they buy, the payment methods used, and their satisfaction levels with the products. It is a rich source of information for retail analysts, data scientists, and business owners looking to understand and optimize their clothing store's operations.

**Context**
In today's dynamic and competitive retail environment, understanding customer preferences and optimizing sales processes is crucial for the success of any clothing store. The ""Fashion Retail Sales Dataset"" has been meticulously curated to offer a diverse and realistic portrayal of customer interactions with the store. It encompasses data points such as customer reference IDs, purchased items, transaction amounts, purchase dates, review ratings, and payment methods. This dataset has been designed to simulate a real-world scenario and reflects the complexities of a clothing store's day-to-day operations.

**Description**
The ""Fashion Retail Sales Dataset"" consists of six key columns:

- **Customer Reference ID**: This column contains unique identifiers for customers, enabling the tracking of individual buying patterns and preferences.
- **Item Purchased**: It provides information about the clothing items that customers have bought. This column includes a wide variety of clothing items, ranging from T-shirts and jeans to accessories like scarves and hats.
- **Purchase Amount (USD)**: This column details the amount of money spent by each customer for their purchases. It may contain outliers, reflecting occasional high-value purchases.
- **Date Purchase**: The purchase date indicates when each transaction occurred, offering a temporal perspective on buying trends and seasonality.
- **Review Rating**: Customers' satisfaction levels are quantified using this column, with ratings ranging from 1 to 5. It is an essential metric for assessing product quality and customer experience.
- **Payment Method**: This column reveals the method used by customers to make payments, with options including 'Credit Card' and 'Cash'.",.csv
Fast Food Marketing Campaign A\B Test,1,fast-food-marketing-campaign-ab-test,WA_Marketing-Campaign.csv,other,"### Scenario

A fast-food chain plans to add a new item to its menu. However, they are still undecided between three possible marketing campaigns for promoting the new product. In order to determine which promotion has the greatest effect on sales, the new item is introduced at locations in several randomly selected markets. A different promotion is used at each location, and the weekly sales of the new item are recorded for the first four weeks.

### Goal

Evaluate A/B testing results and decide which marketing strategy works the best.


### Columns

- *MarketID*: unique identifier for market
- *MarketSize*: size of market area by sales
- *LocationID*: unique identifier for store location
- *AgeOfStore*: age of store in years
- *Promotion*: one of three promotions that were tested
- *week*: one of four weeks when the promotions were run
- *SalesInThousands*: sales amount for a specific *LocationID*, *Promotion*, and *week*


### Acknowledgements

1. https://rpubs.com/ksdwivedy/finalRProject
2. Hands-On Data Science for Marketing book by Yoon Hyup Hwang
3. https://unsplash.com/@shaafi for the picture
4. IBM Watson Analytics community for this dataset.",.csv
Fastag Fraud Detection Datasets ,1,fastag-fraud-detection-datesets-fictitious,FastagFraudDetection.csv,MIT,"Nature of Data: This dataset contains fictitious data designed for educational and testing purposes in fraud detection algorithms. It does not represent real-world financial transactions or individuals.

Purpose of Creation: The dataset was generated to provide a realistic example for developing and evaluating fraud detection models without relying on sensitive real-world data. It's intended for students, researchers, and practitioners to practice data analysis and machine learning techniques in a safe environment.",.csv
Fastfood Nutrition,1,fastfood-nutrition,fastfood.csv,Attribution 4.0 International (CC BY 4.0),"Welcome to the Fast Food Nutrition Dataset, which provides a comprehensive breakdown of the nutritional content of various fast food products from popular fast food chains.

Fast food is known for its convenience and affordability, but it is also infamous for its high-calorie, high-fat, and high-sugar content. This dataset aims to shed light on the nutritional value of these fast food products, helping consumers make more informed decisions about their food choices.

With information on calories, fat, carbohydrates, protein, and other key nutrients, this dataset provides a valuable resource for nutritionists, researchers, and health-conscious individuals. By analyzing this dataset, we can gain a better understanding of the nutritional impact of fast food consumption and work towards creating healthier food options in the fast food industry.",.csv
Fatalities in the Israeli-Palestinian,1,fatalities-in-the-israeli-palestinian,fatalities_isr_pse_conflict_2000_to_2023.csv,CC0-1.0,"### **Some Task Ideas:**
**Analyze Fatality Trends:** Explore the dataset and track the trends in fatalities over time. Identify any significant changes, spikes, or declines in the number of fatalities.
**Demographic Analysis:**Conduct a demographic analysis by examining the age, gender, and citizenship of the individuals killed. Determine if there are any notable patterns or disparities in the data.
**Geospatial Analysis:** Utilize the event location, district, and region information to perform geospatial analysis. Visualize the distribution of fatalities on a map and identify areas that have experienced higher levels of violence.
**Hostilities Participation Analysis:**Investigate the extent of individuals' participation in hostilities before their deaths. Analyze the relationship between participation and the circumstances surrounding each fatality.
Injury Analysis: Examine the types of injuries inflicted on individuals. Identify the most common types of injuries and assess their severity.
**Weapons Used:** Analyze the ammunition and means by which the individuals were killed. Determine the most frequently used weapons or methods and evaluate their impact.
**Victim Profiles:** Create profiles of the victims based on the available data such as age, gender, citizenship, and place of residence. Identify common characteristics among the victims.",.csv
Fatalities in the Israeli-Palestinian Conflict,1,fatalities-in-the-israeli-palestinian-conflict,fatalities_isr_pse_conflict_2000_to_2023.csv,CC0-1.0,"This dataset provides information on the individuals killed during the Israeli-Palestinian conflict since the second intifada, which began in September 2000. The data has been meticulously collected and investigated by B’Tselem – The Israeli Information Center for Human Rights in the Occupied Territories. 

The dataset includes statistics on all human beings – Palestinians, Israelis, and foreign nationals – who lost their lives during this conflict. It provides details such as name, age, citizenship, date of death, gender, participation in hostilities, place of residence, type of injury, ammunition used, and more.

## Some Task Ideas:

1. **Analyze Fatality Trends**: Explore the dataset and track the trends in fatalities over time. Identify any significant changes, spikes, or declines in the number of fatalities.
2. **Demographic Analysis**: Conduct a demographic analysis by examining the age, gender, and citizenship of the individuals killed. Determine if there are any notable patterns or disparities in the data.
3. **Geospatial Analysis**: Utilize the event location, district, and region information to perform geospatial analysis. Visualize the distribution of fatalities on a map and identify areas that have experienced higher levels of violence.
4. **Hostilities Participation Analysis**: Investigate the extent of individuals' participation in hostilities before their deaths. Analyze the relationship between participation and the circumstances surrounding each fatality.
5. **Injury Analysis**: Examine the types of injuries inflicted on individuals. Identify the most common types of injuries and assess their severity.
6. **Weapons Used**: Analyze the ammunition and means by which the individuals were killed. Determine the most frequently used weapons or methods and evaluate their impact.
7. **Victim Profiles**: Create profiles of the victims based on the available data such as age, gender, citizenship, and place of residence. Identify common characteristics among the victims.

---

&gt; Please note that the dataset contains sensitive information and focuses on the humanitarian aspect rather than taking any political stance.

---

If you find this dataset valuable, don't forget to hit the upvote button! 😊💝 

---

## Related Datasets

[Data on Palestinian Structures Israel Demolished](https://www.kaggle.com/datasets/asaniczka/data-on-palestinian-structures-israel-demolished/)

[Daily Public Opinion on Israel-Palestine War](https://www.kaggle.com/datasets/asaniczka/reddit-on-israel-palestine-daily-updated)

---

Photo by [Levi Meir Clancy](https://unsplash.com/@levimeirclancy?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash) on [Unsplash](https://unsplash.com/photos/LheHIV3XpGM?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)",.csv
Fault Prediction in Tablet Press Equipment,1,fault-prediction-in-tablet-press-equipment,Tablet_press_data.csv,MIT,"The dataset used in the project ""Fault Prediction in Tablet Press Equipment"" is a synthetic dataset specifically crafted to simulate the operational dynamics of tablet press machines and predict potential machine failures. It is important to note that this dataset is not derived from real-world scenarios but is meticulously designed to replicate the complex interactions of factors influencing tablet press machine operations.

Key points about the dataset:
1. Purpose: The dataset serves as a foundational component for simulating tablet press machine operations and predicting failures.
2. Characteristics: It is designed to emulate the diverse characteristics and intricate patterns associated with tablet press machine behavior.
3. Synthetic Nature: Being a synthetic dataset, it allows for the controlled and replicable testing of machine learning models under various failure scenarios and operational conditions.
4. Advantages: Synthetic datasets offer the advantage of systematically exploring different failure scenarios, enhancing the understanding of model robustness and performance under varying circumstances.
5. Controlled Environment: The dataset provides a controlled framework for evaluating machine learning algorithms, ensuring that models are well-prepared to handle operational challenges in tablet press machine environments.",.csv
Faulty Steel Plates,1,faulty-steel-plates,faults.csv,other,"### Context

This dataset comes from research by Semeion, Research Center of Sciences of Communication. The original aim of the research was to correctly classify the type of surface defects in stainless steel plates, with six types of possible defects (plus ""other"").  The  Input  vector  was  made  up  of  27  indicators  that  approximately [describe] the geometric shape of the defect and its outline. According to the research paper, Semeion was commissioned by the Centro Sviluppo Materiali (Italy) for this task and therefore it is not possible to provide details on the nature of the 27 indicators used as Input vectors or the types of the 6 classes of defects. 


### Content

There are 34 fields. The first 27 fields describe some kind of steel plate faults seen in images.  Unfortunately, there is no other information that I know of to describe these columns. 

 - X_Minimum
 - X_Maximum
 - Y_Minimum
 - Y_Maximum
 - Pixels_Areas
 - X_Perimeter
 - Y_Perimeter
 - Sum_of_Luminosity
 - Minimum_of_Luminosity
 - Maximum_of_Luminosity
 - Length_of_Conveyer
 - TypeOfSteel_A300
 - TypeOfSteel_A400
 - Steel_Plate_Thickness
 - Edges_Index
 - Empty_Index
 - Square_Index
 - Outside_X_Index
 - Edges_X_Index
 - Edges_Y_Index
 - Outside_Global_Index
 - LogOfAreas
 - Log_X_Index
 - Log_Y_Index
 - Orientation_Index
 - Luminosity_Index
 - SigmoidOfAreas


The last seven columns are one hot encoded classes, i.e. if the plate fault is classified as ""Stains"" there will be a 1 in that column and 0's in the other columns. If you are unfamiliar with one hot encoding, just know that the last seven columns are your class labels. 

 - Pastry
 - Z_Scratch
 - K_Scatch
 - Stains
 - Dirtiness
 - Bumps
 - Other_Faults


### Acknowledgements

MetaNet: The Theory of Independent Judges (PDF Download Available). Available from: https://www.researchgate.net/publication/13731626_MetaNet_The_Theory_of_Independent_Judges [accessed Sep 6, 2017].

Dataset provided by Semeion, Research Center of Sciences of Communication, Via Sersale 117, 00128, Rome, Italy. 
www.semeion.it

Lichman, M. (2013). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.
",.csv
"Federal Emergencies and Disasters, 1953-Present",1,federal-disasters,database.csv,CC0-1.0,"# Context 

The president can declare an emergency for any occasion or instance when the President determines federal assistance is needed.  Emergency declarations supplement State and local or Indian tribal government efforts in providing emergency services, such as the protection of lives, property, public health, and safety, or to lessen or avert the threat of a catastrophe in any part of the United States.  The total amount of assistance provided for in a single emergency may not exceed $5 million.

The president can declare a major disaster for any natural event, including any hurricane, tornado, storm, high water, wind-driven water, tidal wave, tsunami, earthquake, volcanic eruption, landslide, mudslide, snowstorm, or drought, or, regardless of cause, fire, flood, or explosion, that the President determines has caused damage of such severity that it is beyond the combined capabilities of state and local governments to respond.  A major disaster declaration provides a wide range of federal assistance programs for individuals and public infrastructure, including funds for both emergency and permanent work.


# Content

This dataset includes a record for every federal emergency or disaster declared by the President of the United States since 1953.


# Acknowledgements

The disaster database was published by the Federal Emergency Management Agency with data from the National Emergency Management Information System.


# Inspiration

What type of disaster is the most commonly declared by FEMA? Which disasters or emergencies have lasted the longest? What disaster was declared in the most counties or states? Has the number of disasters declared by FEMA risen or fallen over time?",.csv
Federal Firearm Licences,1,federal-firearm-licensees,federal-firearm-licensees.csv,CC0-1.0,"### Context

Firearms sold in the United States must be licensed by the US Department of Justice Bureau of Alcohol, Tobacco, Firearms and Explosives. This dataset is a record of every firearm license which was still current as of July 2017.

### Content

This dataset contains the names, license types, expiration dates, and locations of all Federal Firearms License (FFL) holders in the United States. The possible license types are:

* 01	Dealer in Firearms Other Than Destructive Devices (Includes Gunsmiths)
* 02	Pawnbroker in Firearms Other Than Destructive Devices
* 03	Collector of Curios and Relics
* 06	Manufacturer of Ammunition for Firearms
* 07	Manufacturer of Firearms Other Than Destructive Devices
* 08	Importer of Firearms Other Than Destructive Devices
* 09	Dealer in Destructive Devices
* 10	Manufacturer of Destructive Devices
* 11	Importer of Destructive Devices

### Acknowledgements

This data is [published online](https://www.atf.gov/firearms/listing-federal-firearms-licensees-ffls-2017) in a tab-separated format by the Department of Justice Bureau of Alcohol, Tobacco, Firearms, and Explosives. It has been lightly retouched into a `CSV` file before publication here.

### Inspiration

* Can you geocode this data to determine where licensed gun shops are distributed?
* What is the distribution of gun licenses across different types?",.csv
"Federal Reserve Interest Rates, 1954-Present",1,interest-rates,index.csv,CC0-1.0,"# Context 

The Federal Reserve sets interest rates to promote conditions that achieve the mandate set by the Congress — high employment, low and stable inflation, sustainable economic growth, and moderate long-term interest rates. Interest rates set by the Fed directly influence the cost of borrowing money. Lower interest rates encourage more people to obtain a mortgage for a new home or to borrow money for an automobile or for home improvement. Lower rates encourage businesses to borrow funds to invest in expansion such as purchasing new equipment, updating plants, or hiring more workers. Higher interest rates restrain such borrowing by consumers and businesses. 


# Content

This dataset includes data on the economic conditions in the United States on a monthly basis since 1954. The federal funds rate is the interest rate at which depository institutions trade federal funds (balances held at Federal Reserve Banks) with each other overnight. The rate that the borrowing institution pays to the lending institution is determined between the two banks; the weighted average rate for all of these types of negotiations is called the effective federal funds rate. The effective federal funds rate is determined by the market but is influenced by the Federal Reserve through open market operations to reach the federal funds rate target. The Federal Open Market Committee (FOMC) meets eight times a year to determine the federal funds target rate; the target rate transitioned to a target range with an upper and lower limit in December 2008. The real gross domestic product is calculated as the seasonally adjusted quarterly rate of change in the gross domestic product based on chained 2009 dollars. The unemployment rate represents the number of unemployed as a seasonally adjusted percentage of the labor force. The inflation rate reflects the monthly change in the Consumer Price Index of products excluding food and energy.


# Acknowledgements

The interest rate data was published by the Federal Reserve Bank of St. Louis' economic data portal. The gross domestic product data was provided by the US Bureau of Economic Analysis; the unemployment and consumer price index data was provided by the US Bureau of Labor Statistics.


# Inspiration

How does economic growth, unemployment, and inflation impact the Federal Reserve's interest rates decisions? How has the interest rate policy changed over time? Can you predict the Federal Reserve's next decision? Will the target range set in March 2017 be increased, decreased, or remain the same?",.csv
"Federal Tax Revenue by Source, 1934 – 2018",1,federal-tax-revenue-by-source-1934-2018,Federal Tax Revenue by Source 1934  2018.csv,CC-BY-NC-SA-4.0,"Explore historical federal tax revenue data from 1934 to 2018, detailing receipts in millions of dollars and as a percentage of the total. This dataset covers individual income taxes, corporate income taxes, social insurance and retirement receipts, excise taxes, and other sources. Explore the evolving landscape of federal revenue over the decades and analyze trends in taxation patterns. Data sourced from the Tax Foundation, offering insights into the fiscal history of the United States.",.csv
Female Diabetes Dataset,1,female-diabetes-dataset,Diabetes.csv,Apache 2.0,"
This dataset contains information related to diabetes among females. 
Here's a breakdown of each column:

1. **Pregnancies** (numeric):
   - This column likely represents the number of pregnancies the individual has had.

2. **Glucose** (numeric):
   - This column typically represents the glucose (blood sugar) level measured in the individual, often in mg/dL.

3. **Diastolic** (numeric):
   - This could represent the diastolic blood pressure of the individual, measured in mmHg (millimeters of mercury).

4. **Triceps** (numeric):
   - This might refer to the thickness of the skinfold at the triceps (back of the upper arm), often used as a measure of 
    body fat percentage.

5. **Insulin** (numeric):
   - This column likely represents insulin levels measured in the individual, often in µU/mL (micro-units per milliliter).

6. **BMI** (numeric):
   - BMI stands for Body Mass Index, a calculated value derived from an individual's weight and height (weight in 
    kilograms divided by the square of height in meters).

7. **DPF** (numeric):
   - DPF could refer to Diabetes Pedigree Function, a measure estimating diabetes heredity based on family history.

8. **Age** (numeric):
   - This column likely represents the age of the individual.

9. **Diabetes** (categorical or binary):
   - This column likely indicates the presence or absence of diabetes, possibly coded as 0 (absence) and 1 (presence)   or using specific labels (e.g., ""yes"" or ""no"").



- This dataset appears to be a collection of health-related measurements and demographic information for females, particularly focusing on factors associated with diabetes. The dataset likely serves as a valuable resource for analyzing risk factors, building predictive models, or studying correlations between various health indicators and diabetes outcomes among females.

- To work effectively with this dataset, you could perform descriptive statistics, exploratory data analysis, feature engineering, and possibly build machine learning models to predict diabetes status based on the provided features. It's important to ensure the dataset is properly cleaned, checked for missing values or outliers, and processed appropriately based on the specific analytical goals.",.csv
Fetal Health Classification,1,fetal-health-classification,fetal_health.csv,other,"# Abstract
&gt; Classify fetal health in order to prevent child and maternal mortality.

# About this dataset
&gt; ## Context
Reduction of child mortality is reflected in several of the United Nations' Sustainable Development Goals and is a key indicator of human progress.
The UN expects that by 2030, countries end preventable deaths of newborns and children under 5 years of age, with all countries aiming to reduce under‑5 mortality to at least as low as 25 per 1,000 live births.

&gt; Parallel to notion of child mortality is of course maternal mortality, which accounts for **295 000 deaths** during and following pregnancy and childbirth (as of 2017). The vast majority of these deaths **(94%)** occurred in low-resource settings, and most **could have been prevented**.

&gt; In light of what was mentioned above, **Cardiotocograms (CTGs)** are a simple and cost accessible option to assess fetal health, allowing healthcare professionals to take action in order to prevent child and maternal mortality. The equipment itself works by sending ultrasound pulses and reading its response, thus shedding light on fetal heart rate (FHR), fetal movements, uterine contractions and more.

&gt; ## Data
This dataset contains **2126** records of features extracted from Cardiotocogram exams, which were then classified by three expert obstetritians into **3 classes**:
- Normal
- Suspect
- Pathological


# How to use
&gt; - Create a multiclass model to classify CTG features into the three fetal health states.

# Acknowledgements
&gt; If you use this dataset in your research, please credit the authors.

&gt; ### Citation
Ayres de Campos et al. (2000) SisPorto 2.0 A Program for Automated Analysis of Cardiotocograms. J Matern Fetal Med 5:311-318 ([link](https://onlinelibrary.wiley.com/doi/10.1002/1520-6661(200009/10)9:5%3C311::AID-MFM12%3E3.0.CO;2-9))


&gt; ### License
License was not specified at the source, yet access to the data is public and a citation was requested.

&gt; ### Splash banner
Photo by [Aditya Romansa](https://unsplash.com/@adroman?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/photos/5zp0jym2w9M)

&gt; ### Splash icon
Icon by [Freepik](https://www.flaticon.com/authors/freepik) available on [Flaticon](https://www.flaticon.com/free-icon/pregnant_781296).

&gt; ### [More Datasets](https://www.kaggle.com/andrewmvd/datasets)",.csv
Fetal Health Monitoring Dataset,1,fetal-health-monitoring-dataset,f_health.csv,MIT,"The columns in the dataset:

1. **baseline value**: This typically refers to the baseline fetal heart rate (FHR) measured in beats per minute (bpm) during a specific period of time before any contractions or other events occur.

2. **accelerations**: These are temporary increases in the fetal heart rate (FHR) above the baseline, typically associated with fetal movement or other non-pathological stimuli. Accelerations are considered a reassuring sign of fetal well-being.

3. **fetal_movement**: This may refer to the presence or absence of fetal movement recorded during monitoring. Fetal movement can provide insight into fetal well-being and neurologic development.

4. **uterine_contractions**: These are contractions of the uterus that occur during labor. Monitoring the frequency, duration, and intensity of contractions is important for assessing labor progress and fetal well-being.

5. **light_decelerations**: These are temporary decreases in the fetal heart rate (FHR) below the baseline, typically of short duration and amplitude. Light decelerations are often associated with uterine contractions and are considered a normal response to fetal head compression during labor.

6. **severe_decelerations**: These are pronounced and prolonged decreases in the fetal heart rate (FHR) below the baseline, often indicating compromised fetal oxygenation and potential fetal distress.

7. **prolongued_decelerations**: These are decelerations in the fetal heart rate (FHR) that last longer than a certain duration, typically defined as lasting more than two minutes. Prolonged decelerations can be indicative of fetal hypoxia and may require medical intervention.

8. **abnormal_short_term_variability**: This refers to irregular fluctuations in the fetal heart rate (FHR) that occur over short periods of time. Abnormal short-term variability can be a sign of fetal distress.

9. **mean_value_of_short_term_variability**: This represents the average amplitude of short-term variability in the fetal heart rate (FHR), which is an important parameter for assessing fetal well-being.

10. **percentage_of_time_with_abnormal_long_term_variability**: This indicates the proportion of time during monitoring that the long-term variability in the fetal heart rate (FHR) deviates from the normal range. Abnormal long-term variability can be associated with fetal distress.

11. **mean_value_of_long_term_variability**: This represents the average amplitude of long-term variability in the fetal heart rate (FHR), which is another important parameter for assessing fetal well-being.

12. **histogram_width, histogram_min, histogram_max, histogram_number_of_peaks, histogram_number_of_zeroes, histogram_mode, histogram_mean, histogram_median, histogram_variance, histogram_tendency**: These parameters are derived from the fetal heart rate (FHR) histogram, which is a graphical representation of the distribution of FHR values over a period of time. Each of these parameters provides information about the shape, central tendency, and variability of the FHR histogram, which can be used to assess fetal well-being.

13. **fetal_health**: This is the target variable that indicates the fetal health outcome, typically categorized into different classes (e.g., normal, suspect, pathological) based on various physiological parameters and clinical assessments.",.csv
Fetal cardiotocography data,1,fetalhr,CTG.csv,DbCL-1.0,"# **Features:**

		
FileName:	of CTG examination		
Date:	of the examination		
b:	start instant		
e:	end instant		
LBE:	baseline value (medical expert)		
LB:	baseline value (SisPorto)		
AC:	accelerations (SisPorto)		
FM:	foetal movement (SisPorto)		
UC:	uterine contractions (SisPorto)		
ASTV:	percentage of time with abnormal short term variability  (SisPorto)		
mSTV:	mean value of short term variability  (SisPorto)		
ALTV:	percentage of time with abnormal long term variability  (SisPorto)		
mLTV:	mean value of long term variability  (SisPorto)		
DL:	light decelerations		
DS:	severe decelerations		
DP:	prolongued decelerations		
DR:	repetitive decelerations		
Width:	histogram width		
Min:	low freq. of the histogram		
Max:	high freq. of the histogram		
Nmax:	number of histogram peaks		
Nzeros:	number of histogram zeros		
Mode:	histogram mode		
Mean:	histogram mean		
Median:	histogram median		
Variance:	histogram variance		
Tendency:	histogram tendency: -1=left assymetric; 0=symmetric; 1=right assymetric		
A:	calm sleep		
B:	REM sleep		
C:	calm vigilance		
D:	active vigilance		
SH:	shift pattern (A or Susp with shifts)		
AD:	accelerative/decelerative pattern (stress situation)		
DE:	decelerative pattern (vagal stimulation)		
LD:	largely decelerative pattern		
FS:	flat-sinusoidal pattern (pathological state)		
SUSP:	suspect pattern		
CLASS:	Class code (1 to 10) for classes A to SUSP		
NSP:- 	Normal=1; Suspect=2; Pathologic=3		
",.csv
Fifa World Cup 2022: Complete Dataset,1,fifa-world-cup-2022-complete-dataset,Fifa_world_cup_matches.csv,other,"The dataset contains all the matches, updated daily, of the Qatar Fifa World Cup 2022.
Along with the scores and the football teams several statistics for each match were reported; for instance, assists, possession, crosses, number of red and yellow cards, passes, fouls, attempts, switches of play, offsides, and the number of times a certain are of the pitch has been crossed.

** **
###  **Inspiration**

This dataset is ideal for performing data analysis of the matches of the 2022 Fifa World Cup.
Since a vast array of features are present, not only can a wide range of exploratory data analysis techniques be deployed, but also different plots and visualization techniques can be used.
Python libraries, for example, can be used to perform these tasks.

**Remember to upvote if you found the dataset useful :)**.

** **
###  **Collection methodology**

The dataset was obtained through web scraping from www.fifa.com.
The data were also cleaned and the unnecessary information were discarded.",.csv
Fifa19-EDA,1,fifa19eda,fifa_eda.csv,other,"### Context

Cleaned data ready for analysis, model building.

### Inspiration

Kaggle and other data contributors made learning and gaining knowledge easy and feasible for many and this is my way of giving back to the community so that the flow of knowledge continues.",.csv
Filipino Family Income and Expenditure,1,family-income-and-expenditure,Family Income and Expenditure.csv,CC0-1.0,"### Context

The Philippine Statistics Authority (PSA) spearheads the conduct of the Family Income and Expenditure Survey (FIES) nationwide. The survey, which is undertaken every three (3) years, is aimed at providing data on family income and expenditure, including, among others, levels of consumption by item of expenditure, sources of income in cash, and related information affecting income and expenditure levels and patterns in the Philippines.


### Content

Inside this data set is some selected variables from the latest Family Income and Expenditure Survey (FIES) in the Philippines. It contains more than 40k observations and 60 variables which is primarily comprised of the household income and expenditures of that specific household

### Acknowledgements

The Philippine Statistics Authority for providing the publisher with their raw data


### Inspiration

Socio-economic classification models in the Philippines has been very problematic. In fact, not one SEC model has been widely accepted. Government bodies uses their own SEC models and private research entities uses their own. We all know that household income is the greatest indicator of one's socio-economic classification that's why the publisher would like to find out the following:

1) Best model in predicting household income
2) Key drivers of household income, we want to make the model as sparse as possible
3) Some exploratory analysis in the data would also be useful",.csv
Finance & Accounting Courses - Udemy (13K+ course),1,finance-accounting-courses-udemy-13k-course,udemy_output_All_Finance__Accounting_p1_p626.csv,CC0-1.0,"### Context

A compilation of all the development related courses ( 13 thousand courses) which are available on Udemy's website. Under the development category, there are courses from Finance, Accounting, Book Keeping, Compliance, Cryptocurrence, Blockchain, Economics, Investing & Trading, Taxes and much more each having multiple courses under it's domain.
All the details can be found on [Udemy's website](https://www.udemy.com/?utm_source=adwords-brand&utm_medium=udemyads&utm_campaign=Brand-Udemy_la.EN_cc.INDIA&utm_term=_._ag_78279294239_._ad_450776424635_._de_c_._dm__._pl__._ti_kwd-310556426868_._li_1007785_._pd__._&utm_term=_._pd__._kw_udemy_._&matchtype=e&gclid=EAIaIQobChMIgaPGkarj6wIViSQrCh1weAXPEAAYASAAEgIhuvD_BwE) as well!

### Content

Here, I have extracted data related to 10k courses which come under the development category on Udemy's website.
The 17 columns in the dataset can be used to gain insights related to:

- id : The course ID of that particular course.
- title : Shows the unique names of the courses available under the development category on Udemy.
- url: Gives the URL of the course.
- is_paid : Returns a boolean value displaying true if the course is paid and false if otherwise.
- num_subscribers : Shows the number of people who have subscribed that course.
- avg_rating : Shows the average rating of the course.
- avg rating recent : Reflects the recent changes in the average rating.
- num_reviews : Gives us an idea related to the number of ratings that a course has received.
- num_ published_lectures : Shows the number of lectures the course offers.
- num_ published_ practice_tests : Gives an idea of the number of practice tests that a course offers.
- created :  The time of creation of the course.
- published_time : Time of publishing the course.
- discounted_ price_amount :  The discounted price which a certain course is being offered at.
- discounted_ price_currency :  The currency corresponding to the discounted price which a certain course is being offered at.
- price_ detail_amount : The original price of a particular course.
- price_ detail_currency : The currency corresponding to the price detail amount for a course.
",.csv
Financial Companies,1,financial-companies-total-financial-assets,Financial Companies Total Financial Assets.csv,CC0-1.0,This dataset show the date and finances accquired by different companies around the world. It starts at 10/1/1945 and ends at 7/1/2023. There are 2 rows and 313 columns. ,.csv
Financial Distress Prediction,1,financial-distress,Financial Distress.csv,other,"### Context

This data set deals with the financial distress prediction for a sample of companies.  


### Content

**First column**: **Company** represents sample companies.

**Second column**: **Time** shows different time periods that data belongs to. Time series length varies between **1** to **14** for each company.

**Third column**: The target variable is denoted by ""**Financial Distress**"" if it is greater than -0.50 the company should be considered as **healthy** (**0**). Otherwise, it would be regarded as **financially distressed** (**1**). 

**Fourth column to the last column**: The features denoted by **x1** to **x83**, are some financial and non-financial characteristics of the sampled companies. These features belong to the previous time period, which should be used to predict whether the company will be financially distressed or not (classification). Feature  **x80**  is a **categorical variable**.

For example, company 1 is financially distressed at time 4 but company 2 is still healthy at time 14. 

This data set is *imbalanced* (there are 136 financially distressed companies against 286 healthy ones i.e., 136 firm-year observations are financially distressed while 3546 firm-year observations are healthy) and *skewed*, so **f-score** should be employed as the performance evaluation criterion. 

It should be noted that **30%** of this data set should be randomly assigned as **hold-out test set** so the remaining **70%** is used for feature selection and model selection i.e., **train set**.

Note: 
1- This data could be viewed as a classification problem.
2- This data could also be considered as a regression problem and then the result will be converted into a classification.
3- This data could be regarded as a multivariate time series classification.


### Inspiration


Which features are most indicative of financial distress?

What types of machine learning models perform best on this dataset?
",.csv
Financial Metrics of Startup Companies,1,financial-metrics-of-startup-companies,50_Startups.csv,Apache 2.0,"This dataset contains information on various financial metrics of startup companies, focusing on attributes such as R&D Spend, Administration costs, Marketing Spend, State of operation, and Profit. These attributes provide insights into the allocation of resources, operational expenses, geographic location, and overall profitability of startup ventures.",.csv
Financial Sentiment Analysis,1,financial-sentiment-analysis,data.csv,CC0-1.0,"### Data
The following data is intended for advancing financial sentiment analysis research. It's two datasets (FiQA, Financial PhraseBank) combined into one easy-to-use CSV file. It provides financial sentences with sentiment labels.


### Citations
Malo, Pekka, et al. ""Good debt or bad debt: Detecting semantic orientations in economic texts."" *Journal of the Association for Information Science and Technology* 65.4 (2014): 782-796.",.csv
Financial Statements of Major Companies(2009-2023),1,financial-statements-of-major-companies2009-2023,Financial Statements.csv,DbCL-1.0,"This is a compiled datasets comprising of data from various companies' 10-K annual reports and balance sheets.
The data is a longitudinal or panel data, from year 2009-2022(/23) and also consists of a few bankrupt companies to help for investigating factors.
The names of the companies are given according to their Stocks.
Companies divided into specific categories.",.csv
Finger Dataset for Guitar Chord,1,finger-dataset-for-guitar-chord,chord-fingers.csv,Apache 2.0,"
For each row, the dataset provides:
(i) the root of the chord
(ii) the type of chord
(iii) the intervals that compose the chord
(iv) the finger positions

The finger positions are denoted for each guitar string (from the lowest E to the highest).
x: string muted, 0: open string, 1: index finger, 2: middle finger, 3: ring finger, 4: pinkie",.csv
First GOP Debate Twitter Sentiment,1,first-gop-debate-twitter-sentiment,Sentiment.csv,CC-BY-NC-SA-4.0,"*This data originally came from [Crowdflower's Data for Everyone library](http://www.crowdflower.com/data-for-everyone).*

As the original source says,

> We looked through tens of thousands of tweets about the early August GOP debate in Ohio and asked contributors to do both sentiment analysis and data categorization. Contributors were asked if the tweet was relevant, which candidate was mentioned, what subject was mentioned, and then what the sentiment was for a given tweet. We've removed the non-relevant messages from the uploaded dataset.

The data we're providing on Kaggle is a slightly reformatted version of the original source. It includes both a CSV file and SQLite database. The code that does these transformations is [available on GitHub](https://github.com/benhamner/crowdflower-first-gop-debate-twitter-sentiment)",.csv
Fish Market,1,fish-market,Fish.csv,CC0-1.0,"The fish market dataset is a collection of data related to various species of fish and their characteristics. This dataset is designed for polynomial regression analysis and contains several columns with specific information. Here's a description of each column in the dataset:

Species: This column represents the species of the fish. It is a categorical variable that categorizes each fish into one of seven species. The species may include names like ""Perch,"" ""Bream,"" ""Roach,"" ""Pike,"" ""Smelt,"" ""Parkki,"" and ""Whitefish."" This column is the target variable for the polynomial regression analysis, where we aim to predict the fish's weight based on its other attributes.

Weight: This column represents the weight of the fish. It is a numerical variable that is typically measured in grams. The weight is the dependent variable we want to predict using polynomial regression.

Length1: This column represents the first measurement of the fish's length. It is a numerical variable, typically measured in centimetres.

Length2: This column represents the second measurement of the fish's length. It is another numerical variable, typically measured in centimetres.

Length3: This column represents the third measurement of the fish's length. Similar to the previous two columns, it is a numerical variable, usually measured in centimetres.

Height: This column represents the height of the fish. It is a numerical variable, typically measured in centimetres.

Width: This column represents the width of the fish. Like the other numerical variables, it is also typically measured in centimetres.

The dataset is structured in such a way that each row corresponds to a single fish with its species and various physical measurements (lengths, height, and width). The goal of using polynomial regression on this dataset would be to build a predictive model that can estimate the weight of a fish based on its species and the provided physical measurements. Polynomial regression allows for modelling more complex relationships between the independent variables (lengths, height, and width) and the dependent variable (weight), which may be particularly useful if there are non-linear patterns in the data.",.csv
FitbitFitness Tracker Data: Capstone Project,1,fitbitfitness-tracker-data-capstone-project,dailyActivity_merged_cleaned.csv,CC0-1.0,"Data source: FitBit Fitness Tracker Data (https://www.kaggle.com/datasets/arashnic/fitbit) is a public dataset available on Kaggle. This dataset contains personal fitness tracker from thirty three eligible Fitbit users. This dataset was generated by respondents to a distributed survey via Amazon Mechanical Turk between the 12th of April, 2016 and the 12th of May, 2016.
This dataset has been cleaned, formatted with the date  & time columns separated into 2 columns (one for date and the other for 24-hr time format) to prepare for the analysis done in SQL and visualisation in Tableau.
",.csv
Fitness Club Dataset for ML Classification,1,datacamps-data-science-associate-certification,fitness_class_2212.csv,other,"GoalZone is a fitness club chain in Canada.
GoalZone offers a range of fitness classes in two capacities - 25 and 15.
Some classes are always fully booked. Fully booked classes often have a low attendance rate.
GoalZone wants to increase the number of spaces available for classes.
They want to do this by predicting whether the member will attend the class or not.
If they can predict a member will not attend the class, they can make another space
available.

&gt;**Do explore pinned 📌 notebook under code section for quick reference**

&gt;_Consider an upvote ^ if you find the dataset useful_
",.csv
Fitness Consumer Survey Data,1,fitness-consumer-survey-data,survey 605.csv,CC0-1.0,"I recently conducted a research to study the impact of fitness wearables on consumer behavior. For that research, I collected the data using survey that I have shared here for data analysis. The dataset consist of 30 responses from 30 respondents and 21 questions that were asked along with the timestamp. This dataset can be quite useful for beginners to start with exploratory data analysis.

TASK:
Explore all these by creating various wonderful data visuals-
'What is the highest level of education of customers?',
'What is the current occupation of customers?',
'How often do they exercise in a week?',
'How long have they been using a fitness wearable?',
'How frequently do they use your fitness wearable?',
'How often do they track fitness data using wearable?',
'How has the fitness wearable impacted their fitness routine?',
'Has the fitness wearable helped them stay motivated to exercise?',
'Do you think that the fitness wearable has made exercising more enjoyable for customers?',
'How engaged do they feel with your fitness wearable?',
'Does using a fitness wearable make them feel more connected to the fitness community?',
'How has the fitness wearable helped them achieve your fitness goals?',
'How has the fitness wearable impacted their overall health?',
'Has the fitness wearable improved their sleep patterns?',
'Do you feel that the fitness wearable has improved their overall well-being?',
'Has using a fitness wearable influenced their decision? [To exercise more?]',
'Has using a fitness wearable influenced their decision? [To purchase other fitness-related products?]',
'Has using a fitness wearable influenced their decision? [To join a gym or fitness class?]',
'Has using a fitness wearable influenced their decision? [To change their diet?]'",.csv
Fitness Exercises Dataset,1,fitness-exercises-dataset,exercises.csv,MIT,"# Fitness Exercises Dataset
This dataset contains 1300+ samples of exercises with body parts, target muscles, secondary muscles and instructions. Each exercise has also a GIF url.


### For the GIFs not loading:
I bought them for $1 each so that I can give them to you with 75% off! The FULL 1324 GIFs package for only the first 5 to grab them (ONLY 1 LEFT!) at that price from https://omarxadel.gumroad.com/l/exercisesdb

![](https://public-files.gumroad.com/7hxdwndfkmpyxb5r9k7g0yh07iqz)


✔ High Quality GIFs

✔ The whole thing (1324 GIFs)

✔ Sorted as they are in the database so you'll only need to run 1 job to change the names

✔ No watermarks

And they're limited. Make sure to get them before anyone else.😄

",.csv
Fitness Track Daily Activity Dataset,1,fitness-track-daily-activity-dataset,Activity.csv,Apache 2.0,"let's break down each column in this fitness tracker app data:

1. **UserID**: This column contains unique identifiers for each user of the fitness tracker app. Each row corresponds to a specific user's data.

2. **Date**: This column represents the date on which the data was recorded or collected. It's likely in a date format (e.g., YYYY-MM-DD).

3. **Steps**: This column records the number of steps the user took on the given date. Steps are a common metric used by fitness trackers to measure physical activity.

4. **Total_Distance**: This column indicates the total distance covered by the user on the given date, likely measured in a unit such as kilometers or miles. It might be calculated based on steps taken and stride length.

5. **Tracker_Distance**: This column represents the distance recorded by the fitness tracker device itself, which could include steps as well as other factors like GPS data.

6. **Logged_Activities_Distance**: This column contains additional distance covered during specific activities that the user manually logged into the app. For example, if the user went for a run and entered the distance manually, it would be recorded here.

7. **Very_Active_Distance**: This column indicates the distance covered during activities classified as ""very active,"" such as running, intense cardio, or high-intensity interval training.

8. **Moderately_Active_Distance**: This column represents the distance covered during activities classified as ""moderately active,"" which may include brisk walking, cycling, or light jogging.

9. **Light_Active_Distance**: This column indicates the distance covered during activities classified as ""light activity,"" such as casual walking, household chores, or light stretching.

10. **Sedentary_Active_Distance**: This column represents the distance covered while engaged in sedentary activities, such as sitting or lying down. It could be used to track inactive periods.

11. **Very_Active_Minutes**: This column records the number of minutes the user spent engaging in activities classified as ""very active,"" typically high-intensity exercises that significantly elevate heart rate.

12. **Fairly_Active_Minutes**: This column contains the number of minutes spent engaging in activities classified as ""fairly active,"" which are moderately intense activities that raise heart rate but are not as vigorous as ""very active"" activities.

13. **Lightly_Active_Minutes**: This column indicates the number of minutes spent engaging in activities classified as ""lightly active,"" which include low-intensity activities that contribute to overall movement but do not significantly elevate heart rate.

14. **Sedentary_Minutes**: This column records the amount of time the user spent in sedentary behavior, such as sitting or lying down, without engaging in physical activity.

15. **Calories_Burned**: This column represents an estimate of the number of calories the user burned throughout the day based on their activity levels and other factors like age, weight, and gender. It's often calculated using algorithms that take into account activity data and user profile information.",.csv
Fitness Trends Dataset,1,fitness-data-trends,25.csv,CC-BY-NC-SA-4.0,"### Context

The motivation behind collecting this data-set was personal, with the objective of answering a simple question, “does exercise/working-out improve a person’s activeness?”. For the scope of this project a person’s activeness was the measure of their daily step-count (the number of steps they take in a day). Mood was measured in either ""Happy"", ""Neutral"" or ""Sad"" which were given numeric values of 300, 200 and 100 respectively. Feeling of activeness was measured in either ""Active"" or ""Inactive"" which were given numeric values of 500 and 0 respectively. I had noticed for a while that during the months when I was exercising regularly I felt more active and would move around a lot more. As opposed to when I was not working out, i would feel lethargic. I wanted to know for sure what the connection between exercise and activeness was. 
I started compiling the data on 6th October with the help Samsung Health application that was recording my daily step count and the number of calories burned. The purpose of the project was to establish through two sets of data (control and experimental) if working-out/exercise promotes an increase in the daily step-count or not.
 


### Content

Date
Step Count
Calories Burned
Mood
Hours of Sleep
Feeling or Activeness or Inactiveness
Weight


### Acknowledgements

Special thanks to Samsung Health that contributed to the set by providing daily step count and the number of calories burned.


### Inspiration

""Does  exercise/working-out improve a person’s activeness?”",.csv
Fitness for good Cardio,1,fitness-for-good-cardio,CardioGoodFitness.csv,CC0-1.0,"The market research team at AdRight is assigned the task to identify the profile of the typical customer for each treadmill product offered by CardioGood Fitness. The market research team decides to investigate whether there are differences across the product lines with respect to customer characteristics.

Data fields: Product purchased, Age in years, Gender, Education in years, Marital Status, single or partnered, usage, Fitness on 1-5 scale, Income, Miles.",.csv
Flight Delay from January 2017 - July 2022,1,us-flight-delay-from-january-2017-july-2022,Airline_Delay_Cause.csv,CC0-1.0,"This is flights delay data in the U.S. For more information about the data, go to URL below. 
 
source = https://www.transtats.bts.gov/OT_Delay/OT_DelayCause1.asp

year
Year data collected

month
Numeric representation of the month

carrier
Carrier.

carrier_name
Carrier Name.

airport
Airport code.

airport_name
Name of airport.

arr_flights
Number of flights arriving at airport

arr_del15
Number of flights more than 15 minutes late

carrier_ct
Number of flights delayed due to air carrier. (e.g. no crew)

weather_ct
Number of flights due to weather.

nas_ct
Number of flights delayed due to National Aviation System (e.g. heavy air traffic).

security_ct
Number of flights canceled due to a security breach.

late_aircraft_ct
Number of flights delayed as a result of another flight on the same aircraft delayed

arr_cancelled
Number of cancelled flights

arr_diverted
Number of flights that were diverted

arr_delay
Total time (minutes) of delayed flight.

carrier_delay
Total time (minutes) of delay due to air carrier

weather_delay
Total time (minutes) of delay due to inclement weather.

nas_delay
Total time (minutes) of delay due to National Aviation System.

security_delay
Total time (minutes) of delay as a result of a security issue .

late_aircraft_delay
Total time (minutes) of delay flights as a result of a previous flight on the same airplane being late.
 ",.csv
Flight Route Database,1,flight-route-database,routes.csv,DbCL-1.0,"### Routes database

As of January 2012, the OpenFlights/Airline Route Mapper Route Database contains 59036 routes between 3209 airports on 531 airlines spanning the globe.

### Content
**The data is ISO 8859-1 (Latin-1) encoded.**

Each entry contains the following information:

- Airline	2-letter (IATA) or 3-letter (ICAO) code of the airline.
- Airline ID	Unique OpenFlights identifier for airline (see Airline).
- Source airport	3-letter (IATA) or 4-letter (ICAO) code of the source airport.
- Source airport ID	Unique OpenFlights identifier for source airport (see Airport)
- Destination airport	3-letter (IATA) or 4-letter (ICAO) code of the destination airport.
- Destination airport ID	Unique OpenFlights identifier for destination airport (see Airport)
- Codeshare	""Y"" if this flight is a codeshare (that is, not operated by Airline, but another carrier), empty otherwise.
- Stops	Number of stops on this flight (""0"" for direct)
- Equipment	3-letter codes for plane type(s) generally used on this flight, separated by spaces

The special value \N is used for ""NULL"" to indicate that no value is available. 

Notes:

- Routes are directional: if an airline operates services from A to B and from B to A, both A-B and B-A are listed separately.
- Routes where one carrier operates both its own and codeshare flights are listed only once.

### Acknowledgements

This dataset was downloaded from Openflights.org under the Open Database license. This is an excellent resource and there is a lot more on their website, so check them out!",.csv
Flight Take Off Data - JFK Airport,1,flight-take-off-data-jfk-airport,M1_final.csv,Community Data License Agreement - Sharing - Version 1.0,"### Context

This data was scraped under a Academic Paper under Review by IEEE transportation

### Content

This file contains data about flights leaving from JKF ariport between Nov 2019-Dec-2020. Taxi-Out prediction has been an important concept as it helps in calculating Runway time and directly impact the cost of the flight.
",.csv
Flight_Price,1,flight-price,flight_price.csv,CC0-1.0,"The Flight_Price dataset on Kaggle offers a comprehensive collection of flight-related information, providing valuable insights into air travel trends and pricing dynamics. This dataset includes details such as departure and arrival locations, dates, airlines, flight durations, and corresponding prices. With this rich repository of data, analysts and enthusiasts can delve into patterns, correlations, and factors influencing flight prices, enabling informed decision-making in travel planning, industry analysis, and beyond.",.csv
Flights data,1,flights-data,nycflights.csv,other,"On-time data for a random sample of flights that departed NYC (i.e. JFK, LGA or EWR) in 2013.
year,month,day
Date of departure.

dep_time,arr_time
Departure and arrival times, local tz.

dep_delay,arr_delay
Departure and arrival delays, in minutes. Negative times represent early departures/arrivals.

hour,minute
Time of departure broken in to hour and minutes.

carrier
Two letter carrier abbreviation. See airlines in the nycflights13 package for more information or google the airline code.

tailnum
Plane tail number.

flight
Flight number.

origin,dest
Origin and destination. See airports in the nycflights13 package for more information or google airport the code.

air_time
Amount of time spent in the air.

distance
Distance flown.

Source
Hadley Wickham (2014). nycflights13: Data about flights departing NYC in 2013. R package version 0.1.

Formats
CSV file
Tab-delimited text file

Format
A tbl_df with 32,735 rows and 16 variables:

Photo by Phil Mosley on Unsplash",.csv
Flipkart Product reviews with sentiment Dataset,1,flipkart-product-customer-reviews-dataset,Dataset-SA.csv,DbCL-1.0,"This dataset contains information about Product name, Product price, Rate, Reviews, Summary and Sentiment in csv format. There are 104 different types of products of flipkart.com such as electronics items, clothing of men, women and kids, Home decor items, Automated systems, so on. It has 205053 rows and 6 columns. Also, if any product doesn't have any review but summary is present then Nan value already added to its blank space.

This dataset has multiclass label as sentiment such as positive, neutral amd negative.The sentiment given was based on column called Summary using NLP and Vader model. Also, after that we manually check the label and put it into the appropriate categories like if summary has text like okay, just ok or one positive and negative we labeled as neutral for better understanding while using this dataset for human languages. On the summary and price column, data cleaning method is already performed using python module called NumPy and Pandas which are famous.You can learn it also through any online resource.

Data was collected through web scraping using the library called beautifulsoup from flipkart.com. The scraping done in december 2022.

**Usage**

Sentiment Analysis: The text of customer reviews and the associated labels (such as positive, negative, or neutral) can be used to train machine learning models to automatically classify the sentiment of customer reviews.

Predictive Modeling: Customer ratings, summary and reviews, along with their associated labels, can be used as features to build predictive models for various outcomes, such as customer behavior, purchasing patterns, product preferences and so on.

Text Classification: The labeled customer reviews or summary can be used to train machine learning models for text classification tasks, such as spam detection, topic classification, and intent recognition,etc.

Natural Language Processing (NLP): It can be used to train NLP algorithms, such as sentiment analysis models, for applications in other domains.

Evaluating Machine Learning Models: This dataset can be used to evaluate the performance of machine learning models for sentiment analysis and other NLP tasks.

Customer Service: Customer reviews, summary and labels can provide insight into customer complaints, issues, and suggestions, which can help companies improve their customer service.

However,the applications of this type of data will depend on the specific dataset and the problem it is being used to solve.",.csv
Flipkart Products Review Dataset,1,flipkart-product-review-dataset,flipkart_product.csv,ODbL-1.0,"This Dataset contains information of Products Name, Price, Review, Rate, Summary for the Sentiment Analysis Purpose. The dataset can be used for a variety of application as price prediction, Sentiment Analysis, Auto Ai generated Reviews and market Researches. 

This dataset contains total 104 types of different products on flipkart.com. This dataset contains 194276 rows and 5 columns. Using Customer Review or Summary you can use it for sentiment Analysis purpose which give you idea about that product should be purchase or not based on Positive, Negative Reviews. Train your model using Natural Language Processing and you can  make Ai applications. Dataset contain .csv file format

You can also learn How to read data using Pandas and Numpy library  and learn how to clean the data.
**Application:**

Product reviews and descriptions play a significant role in the e-commerce industry, particularly on platforms like Flipkart. They provide valuable information to potential customers, helping them make informed purchasing decisions. Here are some of the ways that product reviews and descriptions can be used:

Customer Decision-Making: Product reviews and descriptions provide customers with information about the product's features, specifications, and overall quality, allowing them to make an informed decision about whether to purchase it or not.

Product Improvement: Product reviews can be used by the manufacturer or seller to identify areas of improvement. Negative reviews can be used to identify common issues and make changes to the product to better meet customer needs.

Marketing: Product descriptions can be used as part of a product's marketing material, providing customers with more information about the product and helping to increase sales.

Sentiment Analysis: The text of product reviews and descriptions can be analyzed to determine the overall sentiment towards the product, helping manufacturers and sellers understand how customers perceive the product.

Customer Segmentation: Product reviews and descriptions can be used to segment customers based on their preferences and purchasing habits. This information can then be used to target specific groups with personalized marketing efforts.

Customer Feedback: Product reviews and descriptions provide a platform for customers to give feedback about the product. This feedback can then be used to improve the product or address any customer concerns.

Pricing: Product reviews and descriptions can be used to inform pricing decisions. For example, if a product has a high rating and positive reviews, the price may be increased. If a product has a low rating and negative reviews, the price may be decreased.

Overall, product reviews and descriptions play a critical role in the success of e-commerce businesses and can provide valuable insights into customer behavior and preferences.",.csv
Flood Prediction Factors,1,flood-prediction-factors,flood.csv,MIT,"
Flood detection refers to the process of identifying, monitoring, and alerting authorities or individuals about the presence or likelihood of flooding in a particular area. It involves the use of various technologies and methods to detect, predict, and mitigate the impacts of floods.",.csv
Flying commercial,1,flying-commercial,Planilha sem ttulo - fatal-airliner-accidents-per-million-flights.csv,CC0-1.0,"According to figures from the Aviation Safety Network, in the 1970s, there were about 6 fatal airliner accidents for every million commercial flights. This meant about 1 in every 165,000 flights ended in a fatal accident.

As the chart shows, this figure has dropped steadily in the last 50 years. According to the latest data, it is now about half a fatality per million flights. This means that, on average, it now takes more than 2 million flights for a fatal accident to occur.

The Community Emissions Data System (CEDS) produces invaluable long-term data on the emissions of air pollutants worldwide. It has just published its latest update, extending this data to 2022.

One of the most striking changes in air pollution trends has been the abrupt drop in sulfur dioxide (SO2) emissions from shipping. As you can see in the chart — where shipping is highlighted in red — there was a dramatic fall from over 10 million tonnes a year in 2019 to 3 million tonnes a year later.

The change resulted from the International Maritime Organization’s strict limits on marine fuels, introduced in 2020: the maximum percentage of sulfur allowed in these fuels fell from 3.5% to 0.5%. All ships worldwide had to comply.

This drop is positive for tackling local air pollution and acid rain. However, it also has implications for climate change since SO2 has masked some of the warming caused by greenhouse gases.",.csv
Food Delivery Time,1,food-delivery-time,deliverytime.csv,DbCL-1.0,"** **Please Upvote if you like the dataset** **

## Food delivery Dataset 

Predict the time taken by the delivery person to deliver the food from the restaurant to the delivery location. With the help of age of the delivery person, previous rating and distance between restaurant and delivery location.
Dataset Columns:-
1. ID
2. Delivery_person_ID
3. Delivery_person_Age
4. Delivery_person_Ratings
5. Restaurant_latitude
6. Restaurant_longitude
7. Delivery_location_latitude
8. Delivery_location_longitude
9. Type_of_order
10. Type_of_vehicle

** If You Like this Dataset Please UPVOTE!!! **
",.csv
Food Prices In India,1,food-prices-in-india,food_prices_ind.csv,DbCL-1.0,"This dataset contains Food Prices data for India, sourced from the World Food Programme Price Database. The World Food Programme Price Database covers foods such as maize, rice, beans, fish, and sugar for 98 countries and some 3000 markets. It is updated weekly but contains to a large extent monthly data. The data goes back as far as 1992 for a few countries, although many countries started reporting from 2003 or thereafter.",.csv
Food Waste,1,food-waste,Food Waste data and research - by country.csv,DbCL-1.0,"Food Waste is a big climate problem we can actually tackle. This dataset includes, by country, both household, retail, and food services estimates of food waste as well as other data points.",.csv
Food and their calories,1,food-and-their-calories,Food and Calories - Sheet1.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context

The data set consist of food such as soup,ice-cream,pizza,vegetables,fruits etc, the serving for which the calories are calculated.


### Content

There are three columns for this dataset: Food   Serving   Calories


### Inspiration

We would always wanted to prepare the diet chart based in the calories. This the dataset then.😄 ",.csv
Food habits and lifestyle,1,food-habits-and-lifestyle,Food_habits_and_lifestyle.csv,other,"The dataset comes from a questionnaire survey made by students Lélie Chenouga
and Emna Ben Ameur from the university PSL. The data covers
the 346 respondents’ demographic characteristics, their eating habits, and several items of
information about their lifestyle and personality.

'Quelles activités faites-vous le plus souvent lors des repas ? (maximum 2)' : 
Discuter avec des proches / Regarder des écrans / Rien / Travailler / Se déplacer / Lire / Écouter de la musique / Autre (choix multiples)

'Qu'est-ce qui vous importe le plus lorsque vous décidez d'un repas ? (maximum 2)'
Choix multiples parmi : Que ce soit bon / Que ce soit sain / Que ce soit peu cher / Que ce soit éthique / Son apport calorique / Contrôler son contenu (choix multiples)

'A quelle fréquence consommez-vous ces produits ?  [Café]' : Jamais / Occasionnellement / Hebdomadairement / Quotidiennement (choix unique)
'A quelle fréquence consommez-vous ces produits ?  [Pain]' : Jamais / Occasionnellement / Hebdomadairement / Quotidiennement (choix unique)
'A quelle fréquence consommez-vous ces produits ?  [Cigarette]' : Jamais / Occasionnellement / Hebdomadairement / Quotidiennement (choix unique)
'A quelle fréquence consommez-vous ces produits ?  [Viande]' : Jamais / Occasionnellement / Hebdomadairement / Quotidiennement (choix unique)
'A quelle fréquence consommez-vous ces produits ?  [Alcool]' : Jamais / Occasionnellement / Hebdomadairement / Quotidiennement (choix unique)
'A quelle fréquence vous arrive-t-il de :  [Cuisiner]' : Jamais / Occasionnellement / Hebdomadairement / Quotidiennement (choix unique)
'A quelle fréquence vous arrive-t-il de :  [Vous faire livrer à manger]' : Jamais / Occasionnellement / Hebdomadairement / Quotidiennement (choix unique)
'A quelle fréquence vous arrive-t-il de :  [Vous peser]' : Jamais / Occasionnellement / Hebdomadairement / Quotidiennement (choix unique)
'A quelle fréquence vous arrive-t-il de :  [Manger au restaurant ou à emporter]' : Jamais / Occasionnellement / Hebdomadairement / Quotidiennement (choix unique)
'A quelle fréquence vous arrive-t-il de :  [Manger avant 11h du matin]' : Jamais / Occasionnellement / Hebdomadairement / Quotidiennement (choix unique)
'A quelle fréquence vous arrive-t-il de :  [Avoir la sensation d'avoir trop manger]' : Jamais / Occasionnellement / Hebdomadairement / Quotidiennement (choix unique)


'Si jamais vous suivez un régime, pour quelles raisons?' : Je ne suis pas de régime / De santé / Professionnelles / D'esthétique / Perdre du poids / Prendre du poids / Accompagner quelqu'un suivant un régime / Je ne sais pas vraiment / Autre
'Quel est votre accord avec les phrases suivantes ? [Manger est toujours un plaisir pour moi]' : Pas du tout d'accord / Plutôt pas d'accord / Ni d'accord, ni pas d'accord / Plutôt d'accord / Tout à fait d'accord
'Quel est votre accord avec les phrases suivantes ? [J'ai l'impression de manger sainement]' : Pas du tout d'accord / Plutôt pas d'accord / Ni d'accord, ni pas d'accord / Plutôt d'accord / Tout à fait d'accord
'Quel est votre accord avec les phrases suivantes ? [Je préfère largement le sucré au salé]' : Pas du tout d'accord / Plutôt pas d'accord / Ni d'accord, ni pas d'accord / Plutôt d'accord / Tout à fait d'accord
'Quel est votre accord avec les phrases suivantes ? [Manger est une source de stress]' : Pas du tout d'accord / Plutôt pas d'accord / Ni d'accord, ni pas d'accord / Plutôt d'accord / Tout à fait d'accord

'Quel est votre genre ?' : Femme / Homme / Autre (choix unique)
'Quelle est votre année de naissance (merci de répondre par uniquement 4 chiffres par exemple : 2001)',
'Quel est votre lieu de vie principal ?' : Grande ville / Moyenne ou petite ville / Milieu rural
'Comment évaluez-vous votre situation économique par rapport aux autres habitants de votre pays ?' : En dessous de la moyenne / Dans la moyenne / Au dessus de la moyenne
'Comment définissez-vous votre orientation sexuelle ?' : Hétérosexuel.le / Homosexuel.le / Bisexuel.le ou Pansexuel.le / Asexuel.le / Autre / Je ne sais pas
'Quelle votre situation amoureuse?' : Célibataire / En couple / Veuf.ve / Divorcé.e / Pacsé.e ou Marié.e / Autre
'Vivez-vous principalement : ' : Seul.e / En colocation / En famille / Uniquement avec votre partenaire / Autre
'Avez-vous des enfants?' : Oui / Non
'A quel point êtes-vous d'accord avec les phrases suivantes ? [Je me sens plutôt en bonne santé]' : Pas du tout d'accord / Plutôt pas d'accord / Ni d'accord, ni pas d'accord / Plutôt d'accord / Tout à fait d'accord
'A quel point êtes-vous d'accord avec les phrases suivantes ? [Je pratique du sport de façon régulière]' : Pas du tout d'accord / Plutôt pas d'accord / Ni d'accord, ni pas d'accord / Plutôt d'accord / Tout à fait d'accord
'A quel point êtes-vous d'accord avec les phrases suivantes ? [Je me sens souvent dans un état anxieux ou dépressif]' : Pas du tout d'accord / Plutôt pas d'accord / Ni d'accord, ni pas d'accord / Plutôt d'accord / Tout à fait d'accord
'A quel point êtes-vous d'accord avec les phrases suivantes ? [Je me sens bien dans mon corps]' : Pas du tout d'accord / Plutôt pas d'accord / Ni d'accord, ni pas d'accord / Plutôt d'accord / Tout à fait d'accord
'A quel point êtes-vous d'accord avec les phrases suivantes ? [Je consacre beaucoup de temps aux relations sociales]' : Pas du tout d'accord / Plutôt pas d'accord / Ni d'accord, ni pas d'accord / Plutôt d'accord / Tout à fait d'accord
'A quel point êtes-vous d'accord avec les phrases suivantes ? [J'accorde de l'importance à une apparence physique soignée]' : Pas du tout d'accord / Plutôt pas d'accord / Ni d'accord, ni pas d'accord / Plutôt d'accord / Tout à fait d'accord
",.csv
FoodData Central,1,fooddata-central,fda_approved_food_items_w_nutrient_info.csv,DbCL-1.0,"**Source:** US Department of Agriculture

**Use:** This dataset contains the basic nutrient information (sugar, fiber, carbohydrates, cholestrol levels etc. ) of over 1.8M food products approved for sale in US. The dataset is also categorized by product type.


**Motivation:**
I recently learnt that I was missing fiber in my diet. In an attempt to add more fiber I looked for fiber heavy cereals. Finding the right product in the grocery store was a nightmare as I had to scan through various products and compare them manually. 

Later I took to the internet to browse through different food items sold in retail grocery outlets which could help add fiber to my diet. I found the FoodCentral dataset which was extremely convoluted and had over 20 CSV's, with no straightforward way to parse out nutrient information. I hence created this dataset which scans through all the different files and stitches the nutrient information along with the ID, Description and Ingredients of over 1.8M categorized food products approved for sale in USA.",.csv
FoodHub Data,1,foodhub-data,foodhub_order.csv,MIT,"**Data Description**
The food aggregator company has stored the data of the orders the registered customers made in their online portal. They want to analyze the data to get a fair idea about the demand of different restaurants, which will help them enhance their customer experience. The data contains the various data related to a food order. The detailed data dictionary is given below.

**Data Dictionary**
-order_id: Unique ID of the order
-customer_id: ID of the customer who ordered the food
-restaurant_name: Name of the restaurant
-cuisine_type: Cuisine ordered by the customer
-cost: Cost of the order
-day_of_the_week: Indicates whether the order is placed on a weekday or weekend (The weekday is from Monday to Friday and the weekend is Saturday and Sunday)
-rating: Rating given by the customer out of 5
-food_preparation_time: Time (in minutes) taken by the restaurant to prepare the food. This is calculated by taking the difference between the timestamps of the restaurant's order confirmation and the delivery person's pick-up confirmation.
-delivery_time: Time (in minutes) taken by the delivery person to deliver the food package. This is calculated by taking the difference between the timestamps of the delivery person's pick-up confirmation and drop-off information",.csv
"Football Matches, European Big Five (2021-2022)",1,football-matches-european-big-five-2021-2022,Big_five_2021-2022_merged.csv,MIT,"## This dataset can be used for a variety of purposes, including match analysis, player performance evaluation, and predictive modeling. 

## I strongly encourage you to check my notebook with data preprocesing and database that I created from this Dataset.
**I must insist that you do not make any commercial use of the data.**",.csv
Football Player Database | Top 5 Leagues - Soccer,1,top-leagues-player,top5_leagues_player.csv,other," Introducing the Top 5 Football Leagues Playprofiles Dataset (2022/23 Season)


We are pleased to present the Top 5 Football Leagues Playprofiles Dataset, featuring player information from the conclusion of the thrilling 2022/23 season. This dataset provides valuable insights into the playprofiles of players competing in the English Premier League, Spanish La Liga, German Bundesliga, Italian Serie A, and French Ligue 1.


The dataset includes essential details such as player names, clubs, positions, heights, preferred foot, agents, outfitters, and more. It serves as a comprehensive resource for researchers, analysts, and football enthusiasts, allowing them to explore player performance in the top 5 football leagues.


Unlock the secrets of the 2022/23 season, uncover emerging talents, and dive into the exciting world of football analysis with the Top 5 Football Leagues Playprofiles Dataset. Please note that the dataset is for research and non-commercial use only.


Enjoy exploring the dataset and discovering the fascinating playprofiles of top-tier football players!",.csv
Football Players Data,1,football-players-data,fifa_players.csv,Apache 2.0,"##**Description**:

This comprehensive dataset offers detailed information on approximately **17,000 FIFA football players**, meticulously scraped from **SoFIFA.com**. 

It encompasses a wide array of player-specific data points, including but not limited to player names, nationalities, clubs, player ratings, potential, positions, ages, and various skill attributes. This dataset is ideal for football enthusiasts, data analysts, and researchers seeking to conduct in-depth analysis, statistical studies, or machine learning projects related to football players' performance, characteristics, and career progressions.


##**Features**:

- **name**: Name of the player.
- **full_name**: Full name of the player.
- **birth_date**: Date of birth of the player.
- **age**: Age of the player.
- **height_cm**: Player's height in centimeters.
- **weight_kgs**: Player's weight in kilograms.
- **positions**: Positions the player can play.
- **nationality**: Player's nationality.
- **overall_rating**: Overall rating of the player in FIFA.
- **potential**: Potential rating of the player in FIFA.
- **value_euro**: Market value of the player in euros.
- **wage_euro**: Weekly wage of the player in euros.
- **preferred_foot**: Player's preferred foot.
- **international_reputation(1-5)**: International reputation rating from 1 to 5.
- **weak_foot(1-5)**: Rating of the player's weaker foot from 1 to 5.
- **skill_moves(1-5)**: Skill moves rating from 1 to 5.
- **body_type**: Player's body type.
- **release_clause_euro**: Release clause of the player in euros.
- **national_team**: National team of the player.
- **national_rating**: Rating in the national team.
- **national_team_position**: Position in the national team.
- **national_jersey_number**: Jersey number in the national team.
- **crossing**: Rating for crossing ability.
- **finishing**: Rating for finishing ability.
- **heading_accuracy**: Rating for heading accuracy.
- **short_passing**: Rating for short passing ability.
- **volleys**: Rating for volleys.
- **dribbling**: Rating for dribbling.
- **curve**: Rating for curve shots.
- **freekick_accuracy**: Rating for free kick accuracy.
- **long_passing**: Rating for long passing.
- **ball_control**: Rating for ball control.
- **acceleration**: Rating for acceleration.
- **sprint_speed**: Rating for sprint speed.
- **agility**: Rating for agility.
- **reactions**: Rating for reactions.
- **balance**: Rating for balance.
- **shot_power**: Rating for shot power.
- **jumping**: Rating for jumping.
- **stamina**: Rating for stamina.
- **strength**: Rating for strength.
- **long_shots**: Rating for long shots.
- **aggression**: Rating for aggression.
- **interceptions**: Rating for interceptions.
- **positioning**: Rating for positioning.
- **vision**: Rating for vision.
- **penalties**: Rating for penalties.
- **composure**: Rating for composure.
- **marking**: Rating for marking.
- **standing_tackle**: Rating for standing tackle.
- **sliding_tackle**: Rating for sliding tackle.

##**Use Case**:
This dataset is ideal for data analysis, predictive modeling, and machine learning projects. It can be used for:

- Player performance analysis and comparison.
- Market value assessment and wage prediction.
- Team composition and strategy planning.
- Machine learning models to predict future player potential and career trajectories.

##**Note**:
Please ensure to adhere to the terms of service of SoFIFA.com and relevant data protection laws when using this dataset. The dataset is intended for educational and research purposes only and should not be used for commercial gains without proper authorization.
",.csv
Football Stadiums,1,football-stadiums,Football Stadiums.csv,other,"List of football (soccer) stadiums all across the world with their capacity and other informations.

About this dataset:
This is a simple, important and interesting topics for people how wants to know about famous stadiums in the world to analysis. In this dataset, we have 8 columns.
Confederation
Stadium: Name
City
HomeTeams
Capacity: Of stadium
Country
IOC
Population: Of country

It's be great if you check this dataset and create some fascinating notebooks with lots of visualization and analysis.
So
Good luck :)",.csv
Football teams | Rankings | Stats,1,football-teams-rankings-stats,Football teams.csv,other,"### Context

Rankings and stats for football teams from the following leagues: 
* English Premier League
* French Ligue 1
* German Bundesliga
* Italian Serie A 
* Spanish La Liga are displayed


### Content

Each row contains information for a team. The data shows following statistics for each team:
* Team - Name of team
* Tournament - Name of tournament
* Goals - Number of goals scored in the tournament in year 2020-2021
* Shots pg - Number of shots per game
* Yellow_cards - Number of yellow cards given in the tournament in year 2020-2021
* Red_cards - Number of red cards given in the tournament in year 2020-2021
* Possession% - Percentage of possession
* Pass% - Percentage of passes
* Aerials won - Aerial duels won per game. Aerial duels occur when two players contest a ball in the air; this is a symmetrical event because neither player starts with possession.
* Rating - Overall rating of the team

The dataset will be updated regularly. If there are any other fields that should be in the dataset, then please drop me a message and I will add it.",.csv
Football/Soccer | Bundesliga Player Database,1,bundesliga-soccer-player,bundesliga_player.csv,other,"The Bundesliga Players dataset provides a comprehensive collection of information on every player in the German Bundesliga football league. From renowned goalkeepers to talented defenders, this dataset offers an extensive range of player details including their names, full names, ages, heights, nationalities, places of birth, prices, maximum prices, positions, shirt numbers, preferred foot, current clubs, contract expiration dates, dates of joining the clubs, player agents, and outfitters. Whether you're a passionate football fan, a sports analyst, or a fantasy football enthusiast, this dataset serves as a valuable resource for exploring and analyzing the profiles of Bundesliga players, enabling you to delve into their backgrounds, performance statistics, and club affiliations. Discover the stars of German football and gain insights into their careers with this comprehensive Bundesliga Players dataset.",.csv
Forbes Billionaires of 2021,1,forbes-billionaires-of-2021,Billionaire.csv,CC0-1.0,"##  📲 New Update ⏳
Two new additional features are added, ""**Industry**"": *which industry they are working on?* ""Is it manufacturing, Technology, Fashion, Retail etc."" and their ""**Age**""

## People richer than poor people (Check out the discussion forum for popularity, peace and peaceful protest and a sudden UPRISING 😂 😆 )

This Dataset contains list of all the people categorized as Billionaires of 2021 by Forbes in their 35th Annual World's Billionaires List. 


## What They have that we don't (Of course Money)
**p.s- If you think its money only, just a ""HAHAHA :)"" for you**

Cutting all the dank vibes, let's get serious now! This Dataset contains ""Name of each Billionaire"", ""Country: They are based on!"", ""Source of their Income/ Company Name"", ""Their net worth that makes them richer than POOR PEOPLE "" and ""Their global position in terms of their net worth"", ""Industry"": which industry they are working on? and their ""Age"".



### Acknowledgements

Thanks to Python and Web Scraping and of course [Forbes Real Time Billionaires list](https://www.forbes.com/real-time-billionaires/#231a1cda3d78)


### Inspiration

Lets predict in the upcoming years which countries will have the maximum number of billionaires in the world.",.csv
Forbes Global 2000 Companies,1,forbes-global-2000-companies,company_stat.csv,Apache 2.0,"# Forbes Global 2000: World's Largest Companies Dataset (2003-2023)
The 20th anniversary edition of the Global 2000 ranking offers a fascinating insight into the evolution of the world's largest companies over the past two decades. While stalwarts like Citigroup and General Electric once dominated the top spots, newer players like JPMorgan, Apple, and Alphabet now lead the pack. JPMorgan's ascent to the number one position reflects its resilience and strategic acquisitions, while Berkshire Hathaway's slip underscores the volatility of investment markets. The metrics used to compile the list - sales, profits, assets, and market value - reveal the staggering scale of these corporate behemoths, with total revenues surpassing $50 trillion for the first time. Despite slight declines in profits and market value, the diversity of countries represented, with the U.S. and China at the forefront, highlights the global nature of corporate power. This comprehensive ranking, based on the latest financial data available, provides invaluable insights into the dynamic landscape of global business.

Utilizing Python web scraping techniques, I meticulously extracted data from the esteemed Forbes Global 2000 list, providing invaluable insights into the world's largest companies. Employing BeautifulSoup and requests libraries, I navigated through the intricacies of Forbes' website structure, capturing essential metrics such as sales, profits, assets, and market value. By meticulously parsing HTML elements and applying efficient data extraction strategies, I compiled a comprehensive dataset reflecting the financial prowess and global influence of these corporate giants. This endeavor enabled me to delve deep into the dynamic landscape of corporate rankings, fostering a deeper understanding of the evolving business ecosystem.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F15079517%2Fd9ce6502246635e8793e7ea115652ed1%2Fforbes.png?generation=1711391862360726&alt=media)
",.csv
Forbes Highest Paid Athletes 1990-2020,1,forbes-highest-paid-athletes-19902019,Forbes Richest Atheletes (Forbes Richest Athletes 1990-2020).csv,CC0-1.0,"### Context

Here is a completel list of the world's highest-paid athletes since the first list published by Forbes in 1990. In 2002, they changed the reporting period from the full calendar year to June-to-June, and consequently, there are no records for 2001. 

### Content
The data is available from 1990 to 2019.

### Acknowledgments
The data has been extracted from topendsports.com website

**Photo by [Austris Augusts](https://unsplash.com/@austris_a?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on Unsplash**",.csv
Forbes billionaires 2022,1,forbes-billionaires-2022,2022_forbes_billionaires.csv,CC0-1.0,"Dataset containing the list of 2500+ people with fortunes valued at least  1 Billion USD.

## Dset Features
- Rank
- Name
- Net Worth
- Age
- Country
- Source
- Industry

## Source
Scrapping python script [here](https://github.com/gsusAguirreArz/2022-billionaire-EDA)",.csv
Ford Car Price Prediction,1,ford-car-price-prediction,ford.csv,CC0-1.0,"**Attribute Information:**
1.model - &gt; Ford Car Brands
2.year   - &gt;Production Year
3.price  - &gt;Price of car in $
4.transmission - &gt; Automatic,Manual, Semi-Auto
5.mileage -&gt; Number of miles traveled
6.fuel_Type -&gt; Petrol,Diesel,Hybrid,Electric,Other
7.tax -&gt; Annual Tax
8.mpg - &gt; Miles per Gallon
9.engineSize - &gt; Car's Engine Size",.csv
Forecasting Mini-Course Sales,1,forecasting-mini-course-sales,s.csv,MIT,"This dataset is a meticulous record of mini-course sales transactions, providing a granular view of the interaction between unique course identifiers (""id"") and the corresponding number of units sold (""num_sold""). This dataset serves as a goldmine for analysts and data enthusiasts eager to unravel the trends, behaviors, and potential influencers shaping the dynamic landscape.",.csv
Forecasting Top Cryptocurrencies,1,forecasting-top-cryptocurrencies,about_top_cryptocurrencies_1B_information.csv,CC0-1.0,"The dataset contains information on cryptocurrencies with a capitalization of more billion USD, which is necessary for their forecasting. I filled part information about cryptocurrencies on my own by studying the materials in Wikipedia and the resources mentioned in it.

The dataset consist of tables with data for different models (clustering results, anomalous dates, pre-trained models, etc.). 

The primary purpose of the dataset is scientific and educational: to study the patterns of the crypto market and test various Data Science technologies for these tasks.

Data on these cryptocurrencies will be downloaded via API.",.csv
Foreign Exchange Rates 2000-2019,1,foreign-exchange-rates-per-dollar-20002019,Foreign_Exchange_Rates.csv,CC0-1.0,"This dataset was generated on the Federal Reserve's Download Data Program. Some changes were made in the dataset, such as header simplifications and inversions of base currency. For example, Fed provides Australian Dollar, Euro, New Zeland Dollar and United Kingdom Pound based in their units (not in dollar). So I made a convertion for this dataset in order to view all rates based in dollar units.",.csv
Forest Fire Regression,1,forest-fire-regression,forestfires.csv,other,"**Additional Information**

In [Cortez and Morais, 2007], the output 'area' was first transformed with a ln(x+1) function.
   Then, several Data Mining methods were applied. After fitting the models, the outputs were
   post-processed with the inverse of the ln(x+1) transform. Four different input setups were
   used. The experiments were conducted using a 10-fold (cross-validation) x 30 runs. Two
   regression metrics were measured: MAD and RMSE. A Gaussian support vector machine (SVM) fed
   with only 4 direct weather conditions (temp, RH, wind and rain) obtained the best MAD value:
   12.71 +- 0.01 (mean and confidence interval within 95% using a t-student distribution). The
   best RMSE was attained by the naive mean predictor. An analysis to the regression error curve
   (REC) shows that the SVM model predicts more examples within a lower admitted error. In effect,
   the SVM model predicts better small fires, which are the majority. 

",.csv
Forex Currency Pairs Dataset in 1 Hour Timeframe,1,forex-currency-pairs-dataset-in-1-hour-timeframe,forex-1year.csv,CC0-1.0,"Forex Data for Various Currency Pairs in 1 Hour TimeFrame Extracted Using MetaTrader

Currency Pairs: EUR/USD, AUD/USD, EUR/GBP, GBP/USD, NZD/USD, USD/CHF, USD/JPY

Data Points: high, open, close, low, vol for each currency pair

Time Period: April 24, 2023 to April 24, 2024 (one year)

Use this dataset to train your model.

***Good luck***",.csv
Forex Exchange Rates Since 2004 (Updated Daily),1,forex-exchange-rate-since-2004-updated-daily,daily_forex_rates.csv,ODC Attribution License (ODC-By),"The Daily Forex Exchange Rate Dataset provides historic and up-to-date exchange rates for over 160 currencies. This dataset is **updated daily**

&gt; If you find this dataset valuable, don't forget to hit the upvote button! 😊💝 

## Interesting Task Ideas:
1. Analyze the historical exchange rates to identify trends and patterns.
2. Build a currency prediction model to forecast future exchange rates.
3. Compare exchange rates across different currencies to identify relative valuations.
4. Create visualizations to showcase the volatility of different currency pairs.
5. Calculate currency conversion rates for specific dates and currencies.
6. Explore the impact of economic events on currency exchange rates.
7. Use the dataset for financial analysis and investment strategies.

---

Photo by <a href=""https://unsplash.com/@markusspiske?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Markus Spiske</a> on <a href=""https://unsplash.com/photos/black-android-smartphone-displaying-google-search-edZXf9oAtxg?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv
Formula 1 Drivers Dataset,1,formula-1-drivers-dataset,F1DriversDataset.csv,DbCL-1.0,"A dataset from Wikipedia of all Formula 1 drivers. Link to source: https://en.wikipedia.org/wiki/List_of_Formula_One_drivers

The data is accurate as of the 2023 Bahrain Grand Prix. Drivers who only participated in Friday practice and who were not actually entered for the race are not included.

Data features included:
- Driver name	
- Nationality	
- Seasons competed	
- Drivers' Championships	
- Race entries	
- Race starts	
- Pole positions	
- Race wins	
- Podiums Fastest laps	
- Points",.csv
Formula 1 Pitstops 1994-2010,1,formula-1-pitstops-1994-2010,pitstops.csv,CC0-1.0,"### Background

This dataset complements the existing ergast.com Formula One dataset ([copy 1][1], [copy 2][2], [copy 3][3], [original source][4]) which lacks pitstop data from Grand Prix before 2011.

### Example Usage

https://www.kaggle.com/code/jtrotman/f1-race-traces-1996

[1]: https://www.kaggle.com/datasets/cjgdev/formula-1-race-data-19502017
[2]: https://www.kaggle.com/datasets/rohanrao/formula-1-world-championship-1950-2020
[3]: https://www.kaggle.com/datasets/jtrotman/formula-1-race-data
[4]: https://ergast.com/mrd/",.csv
Fortune 500 Companies of 2017 in US [Latest],1,fotune500-2017,Fortune 500 Companies US.csv,other,"### Description

 1. Company Name - Name of the Fortune 500 company
 2. Number of Employees - Total number of employees in the company
 3. Previous Rank - Rank for the year 2016
 4. Revenues - Revenue of the company for the year 2016-17 in $ millions.
 5. Revenue Change - Percentage of Revenue change from last year
 6. Profits - Profits of the company in $ million 
 7. Profit Change - Change in the percentage of profit from previous year.
 8. Assets - Value of assets in $ millions
 9. Market Value - Market Value of the company as of 3/31/17


### Acknowledgements

This dataset is compiled by Fortune Magazine (www.fortune.com/fortune500). This is the limited version of the original data.",.csv
Fragile State Index (FSI) Data: 2006-2023,1,fragile-state-index-fsi-data-2006-2023,FSI_Data_2006_2023.csv,Apache 2.0,"The dataset appears to be structured with each row representing a specific country in a particular year, and each column providing data related to various aspects of fragility or stability, as measured by the Fragile State Index (FSI). 

The FSI is typically constructed such that higher scores indicate greater fragility or vulnerability within a country across multiple dimensions such as security, governance, economy, and social factors. Therefore, a score of 120 would suggest a country facing significant challenges across various aspects of stability and development, rather than indicating a high-quality country.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F1937611%2F1e1c504ef90fe229676dbcd4758a40a6%2F_6cfe44f1-554d-43df-b5d1-7c9b31f7c730.jpeg?generation=1711630226331290&alt=media)

Therefore, a higher value in any given metric within this dataset implies a weaker state in that particular aspect (e.g., security, governance, economy, etc.).

Here's an overview of the columns:

**1. Country:** This column indicates the name of the country being evaluated, which in this case is Sudan.

**2. Year:** This column specifies the year for which the data is recorded, which is 2006 in this instance.

**3. Rank:** This column shows the rank of compared to other countries. 

**4. Security Apparatus:** This column represents an indicator related to the strength and effectiveness of the state's security forces or institutions. A higher score typically indicates a weaker or less effective security apparatus.

**5. Factionalized Elites:** This indicator assesses the degree to which political elites are divided along factional lines, which can contribute to instability and governance challenges.

**6. Group Grievance:** This factor evaluates social tensions and grievances among different groups within the country, including ethnic, religious, or cultural tensions.

**7. Economy:** This indicator reflects the overall health and stability of the country's economy. 

**8. Economic Inequality:** Score related to economic inequality within the country.

**9. Human Flight and Brain Drain:** Score related to emigration or ""brain drain"" from the country.

**10. State Legitimacy:** Score related to the legitimacy of the state's governance.

**11. Public Services:** Score related to the availability and quality of public services within the country.

**12. Human Rights:** Score related to the state of human rights within the country.

**13. Demographic Pressures:** Score related to demographic pressures within the country.

**14. Refugees and IDPs:** Score related to the presence or displacement of refugees and internally displaced persons (IDPs) within the country.

**15. External Intervention:** Score related to external interventions or influences on the country.

**16. Total:** Total score or aggregate score based on all the aforementioned factors.

This dataset provides a comprehensive view of various factors contributing to a country's fragility or stability over time, allowing for analysis and comparison of trends across different nations. It could be valuable for researchers, policymakers, and analysts interested in understanding and addressing issues related to conflict, governance, and development.",.csv
Fraud Detection Example ,1,fraud-detection-example,fraud_dataset_example.csv,CC-BY-SA-4.0,"### Context

There's a story behind every dataset and here's your opportunity to share yours.


### Content

step - unit of time (1 hour)

type - CASH-IN, CASH-OUT, DEBIT, PAYMENT and TRANSFER.

amount - transaction amount in local currency.

nameOrig - transaction originator

oldbalanceOrg - initial balance (before transaction)

newbalanceOrig - new balance (after transaction)

nameDest - transaction recipient

oldbalanceDest - initial balance before transaction. 

newbalanceDest - new balance after transaction. 

isFraud - Fraud agent takes control of customers accounts and attempts to empty it by transferring to another account and then cashing out.

isFlaggedFraud - An illegal attempt to transfer massive amount of money in a single transaction.




### Acknowledgements


### Inspiration

",.csv
Fraud detection bank dataset 20K records binary ,1,fraud-detection-bank-dataset-20k-records-binary,fraud_detection_bank_dataset.csv,CC0-1.0,"### Context

Banks are often exposed to fraud transactions and constantly improve systems to track them. 

### Content

Bank dataset that contains 20k+ transactions with 112 features (numerical)  ",.csv
Fraudulent Claim on Cars Physical Damage,1,fraudulent-claim-on-cars-physical-damage,test_2021.csv,other,"## Context
 Team is concerned about the fraud detection accuracy as well as the key drivers that cause fraudulence. Tasked with identifying first-party physical damage fraudulence and explaining the indicators of fraudulent claims.

## Acknowledgements
We wouldn't be here without the help of others. If you owe any attributions or thanks, include them here along with any citations of past research.

## Inspiration
Your data will be in front of the world's largest data science community. What questions do you want to see answered?

",.csv
Freedom Rankings Per Country (2013-2022),1,freedom-in-the-world-2013-2022,Freedom in the World 2013-2022 Dataset (Ver 2.18.23).csv,CC-BY-NC-SA-4.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F12064410%2F2520af6c71c8c2eb7b37af614ccc0ce0%2Ffreedom%20global%20flag.png?generation=1676790229329887&alt=media)

# DAY ~3,700 (January 1st, 2012 to December 31st, 2021)
This is a dataset that tracks the quality of political rights and civil liberties for each country from 2013 to 2022. 

All data are official figures from the Freedom House that have been compiled and structured by myself. Please read my explanation of the rating system and the 40+ variables to understand the inner workings of the dataset. I ensured you that the payoff will be worthwhile due to the importance of the data featured. Personally, I was intrigued at how countries with questionable human rights records shifted in ratings over the past decade.

# Data Sources
##### The primary data source used was the **Freedom House**, an organization that is widely-renowned for its publication of the annual *Freedom in the World* reports that focus on political rights and civil liberties. Considering that the Freedom House has been tracking global trends in political rights and civil liberties for 50 years, the institution is uniquely qualified to make the featured evaluations in the ""most widely read and cited report of its kind"". 

1. [Freedom House's *Freedom in the World* Report](https://freedomhouse.org/report/freedom-world) - The majority of the data was procured through this particular webpage, which featured other freedom-related collections with varying time periods. 
2. [Freedom House's *Freedom in the World* Research Methodology](https://freedomhouse.org/reports/freedom-world/freedom-world-research-methodology) - Initially, I found myself extremely confused on how the rating system worked and the peculiar letter-based variables. After looking through their detailed methodology and accompanying explanations, I was able to clean the data to maximize efficacy.

# Rating System Explanation (IMPORTANT)
A country or territory is awarded **0 to 4 points** for each of **10 political rights indicators** and **15 civil liberties indicators**, which take the form of questions; a score of 0 represents the *smallest degree of freedom* and 4 the *greatest degree of freedom*. The political rights questions are grouped into three subcategories: Electoral Process (3 questions), Political Pluralism and Participation (4), and Functioning of Government (3). The civil liberties questions are grouped into four subcategories: Freedom of Expression and Belief (4 questions), Associational and Organizational Rights (3), Rule of Law (4), and Personal Autonomy and Individual Rights (4). The highest overall score that can be awarded for *political rights* is **40** (or a score of 4 for each of the 10 questions). The highest overall score that can be awarded for *civil liberties* is **60** (or a score of 4 for each of the 15 questions).

# Significant Statistics Being Tracked
- **C/T:** Indicates whether the entry is a country (c) or territory (t)
- **Status:** F=Free, PF=Partly Free, NF=Not Free
- **PR Rating:** Political Rights Rating
- **CL Rating:** Civil Liberties Rating
- **A:** Aggregate score for the ""A. Electoral Process"" subcategory&gt;
--&gt; A1: Was the current head of government or other chief national authority elected through free and fair elections?
--&gt; A2: Were the current national legislative representatives elected through free and fair elections?
--&gt; A3: Are the electoral laws and framework fair, and are they implemented impartially by the relevant election management bodies?
- **B:** Aggregate score for the ""B. Political Pluralism and Participation"" subcategory
--&gt; B1: Do the people have the right to organize in different political parties or other competitive political groupings of their choice, and is the system free of undue obstacles to the rise and fall of these competing parties or groupings?
--&gt; B2: Is there a realistic opportunity for the opposition to increase its support or gain power through elections?
--&gt; B3: Are the people’s political choices free from domination by forces that are external to the political sphere, or by political forces that employ extrapolitical means?
--&gt; B4: Do various segments of the population (including ethnic, racial, religious, gender, LGBT+, and other relevant groups) have full political rights and electoral opportunities?
- **C:** Aggregate score for the ""C. Functioning of Government"" subcategory
--&gt; C1: Do the freely elected head of government and national legislative representatives determine the policies of the government?
--&gt; C2: Are safeguards against official corruption strong and effective?
--&gt; C3: Does the government operate with openness and transparency?
- PR: Aggregate score for the Political Rights category
- **D:** Aggregate score for the ""D. Freedom of Expression and Belief"" subcategory
--&gt; D1: Are there free and independent media?
--&gt; D2: Are individuals free to practice and express their religious faith or nonbelief in public and private?
--&gt; D3: Is there academic freedom, and is the educational system free from extensive political indoctrination?
--&gt; D4: Are individuals free to express their personal views on political or other sensitive topics without fear of surveillance or retribution?
- **E:** Aggregate score for the ""E. Associational and Organizational Rights"" subcategory
--&gt; E1: Is there freedom of assembly?
--&gt; E2: Is there freedom for nongovernmental organizations, particularly those that are engaged in human rights– and governance-related work?
--&gt; E3: Is there freedom for trade unions and similar professional or labor organizations?
- **F:** Aggregate score for the ""F. Rule of Law"" subcategory
--&gt; F1: Is there an independent judiciary?
--&gt; F2: Does due process prevail in civil and criminal matters?
--&gt; F3: Is there protection from the illegitimate use of physical force and freedom from war and insurgencies?
--&gt; F4: Do laws, policies, and practices guarantee equal treatment of various segments of the population?
- **G:** Aggregate score for te ""G. Personal Autonomy and Individual Rights"" subcategory
--&gt; G1: Do individuals enjoy freedom of movement, including the ability to change their place of residence, employment, or education?
--&gt; G2: Are individuals able to exercise the right to own property and establish private businesses without undue interference from state or nonstate actors?
--&gt; G3: Do individuals enjoy personal social freedoms, including choice of marriage partner and size of family, protection from domestic violence, and control over appearance?
--&gt; G4: Do individuals enjoy equality of opportunity and freedom from economic exploitation?
- **CL:** Aggregate score for the Civil Liberties category
- **Total:** Aggregate score for all categories

# Dataset History
2023-02-18 - Dataset is created (3,700 days after temporal coverage start date).

[GitHub Repository](https://github.com/justin-2028/Freedom-Rankings-Per-Country-2013-2022) - The same data but on GitHub.

# Code Starter
[Link to Notebook](https://www.kaggle.com/code/justin2028/global-freedom-rankings-2013-2022-code-starter)

# Acknowledgements
Please refer to the Freedom House's methodology for more details: https://freedomhouse.org/reports/freedom-in-the-world/freedom-in-the-world-research-methodology",.csv
French Railway Monthly TGV Regularity,1,french-railway-monthly-tgv-regularity,regularite-mensuelle-tgv-aqst.csv,DbCL-1.0,"La régularité TGV tient compte des différentes durées de trajet des clients (aussi appelée composite).

    Un train est considéré à l'heure si son retard au terminus est inférieur à 5min pour un parcours inférieur à 1h30

    Un train est considéré à l'heure si son retard au terminus est inférieur à 10min pour un parcours entre 1h30 et 3h

    Un train est considéré à l'heure si son retard au terminus est inférieur à 15min pour un parcours au-delà de 3h

Original data link: https://ressources.data.sncf.com/explore/dataset/regularite-mensuelle-tgv-aqst/information/?sort=date",.csv
From Data Entry to CEO: The AI Job Threat Index,1,from-data-entry-to-ceo-the-ai-job-threat-index,My_Data.csv,CC0-1.0,"**Context:**

In today's rapidly evolving technological landscape, artificial intelligence (AI) stands at the forefront of change, particularly in the professional sphere. This dataset, aptly named the ""Job Threat Index,"" offers a deep dive into how AI is influencing a myriad of job roles across diverse domains.

**Sources:**

The data has been meticulously curated from a range of reputable job analytics platforms, AI impact studies, and organizational reports. Each entry has been verified to ensure accuracy and relevance to the ongoing AI advancements in the respective fields.

**Inspiration:**

The genesis of this dataset lies in the increasing discussions around AI's role in the job market. With concerns about AI replacing human jobs on one side and the potential for AI to create new roles on the other, there's a pressing need for clear, data-driven insights. The ""Job Threat Index"" seeks to bridge this knowledge gap, offering researchers, analysts, and enthusiasts a comprehensive view of where we stand and where we might be heading.

",.csv
Fruits and Vegetables Prices Dataset,1,produce-prices-dataset,ProductPriceIndex.csv,CC0-1.0,"# Fruits and Vegetables Prices Dataset- Retail and Farm Prices for Various Products in Different Cities (1999 - 2019)


## Overview:
This dataset comprehensively looks at retail and farm prices for various fresh produce items across different cities. The data spans from 1999 to 2019 and includes information on product names, dates, farm prices, and retail prices in major cities such as Atlanta, Chicago, Los Angeles, and New York.

## Content:
The dataset encompasses a diverse range of popular produce items, including strawberries, romaine lettuce, red leaf lettuce, potatoes, oranges, iceberg lettuce, green leaf lettuce, celery, cauliflower, carrots, cantaloupe, broccoli crowns, broccoli bunches, avocados, etc.

## Fields:
- **Product Name:** Name of the produce item.
- **Date:** The date of the pricing information.
- **Farm Price:** The price at which the produce is sold at the farm.
- **Retail Prices:** Retail prices in major cities (Atlanta, Chicago, Los Angeles, New York).
- **Average Spread:** Percentage indicating the average markup between farm and retail prices.

## Use Cases:
Researchers, analysts, and policymakers can use this dataset to explore and analyze trends in produce pricing, understand variations in retail and farm prices across different cities, and investigate factors influencing price spreads.

## Acknowledgments:
The dataset is sourced from http://www.producepriceindex.com

## Note:
This dataset is suitable for exploratory data analysis, price trend studies, and research into the economic aspects of fresh produce distribution and consumption.
",.csv
Fuel Consumption 2000-2022,1,fuel-consumption,Fuel_Consumption_2000-2022.csv,DbCL-1.0,"Datasets provide model-specific fuel consumption ratings and estimated carbon dioxide emissions for new light-duty vehicles for retail sale in Canada.

To help you compare vehicles from different model years, the fuel consumption ratings for 2000 to 2022 vehicles have been adjusted to reflect the improved testing that is more representative of everyday driving. Note that these are approximate values that were generated from the original ratings, not from vehicle testing.



Original data to [Open Canada Data](https://open.canada.ca/data/en/dataset/98f1a129-f628-4ce4-b24d-6f16bf24dd64)
",.csv
Fuel prices UK,1,fuel-prices-uk,Petrol and diesel prices UK.csv,other,"Weekly average UK prices of unleaded petrol and diesel
Weekly road fuel price statistics provide average UK retail (‘pump’) prices on a weekly basis.									
The data is used to monitor road fuel prices in the UK, and to compare UK road fuel prices with other EU countries.									
Weekly price data is published on the gov.uk website the day after collection.									
 														
Licence:
Open Government Licence
You are free to:
copy, publish, distribute and transmit the Information;
- Adapt the Information;
- Exploit the Information commercially and non-commercially for example, by - combining it with other Information, or by including it in your own product or application.
Contains public sector information licensed under the Open Government Licence v3.0. 
https://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/",.csv
FuelConsumption,1,fuelconsumption,FuelConsumption (1).csv,MIT,"The ""Vehicle Attributes and Emissions Dataset"" contains comprehensive information on various vehicles manufactured in the year 2000. It includes details such as make, model, vehicle class, engine size, cylinder count, transmission type, and fuel type. Additionally, the dataset provides ranges for fuel consumption and CO2 emissions, offering insights into the environmental impact of each vehicle. The dataset encompasses a wide range of vehicle types, from compact to mid-size, and includes both conventional and high-performance models. With this information, analysts and researchers can study trends in vehicle characteristics, fuel efficiency, and emissions . This dataset serves as a valuable resource for understanding the automotive landscape and informing discussions on environmental sustainability and transportation policies.",.csv
Full Election Data (California),1,full-election-data-california,Election_Data.csv,Apache 2.0,"California bond and tax election data including election date, election type, agency, county, type, amount, purpose, measure, vote threshold, vote results for election dating back to 1986.

For researchers and analysts focused on public administration, political science, economics, and finance, the dataset offers a detailed empirical foundation to study the dynamics of public opinion and its influence on policy-making. 

Data scientists can use this dataset to perform several specific analyses:

- **Predictive Analysis**: Using historical data to predict the outcomes of future tax-related measures based on factors such as the economic climate, previous voting patterns, and demographic data of voters.
- **Trend Analysis**: Analyzing long-term trends in voter behavior towards specific types of taxes or debts, such as increased or decreased support for school funding or infrastructure projects over time.
- **Correlation Analysis**: Determining the relationships between the success rates of measures and various external factors such as the economic status, the wording of the measure, or the type of tax.",.csv
Full Emoji Database,1,emoji-data-descriptions-codepoints,emoji_df.csv,CC0-1.0,"**(latest update v15.0)**

### Context

The full emoji database in CSV format. All 4,159 of them! 

### Content

🍕🏈👍🔥😍🏁😃🤣and more...

All emoji, with variations, and skin tones together with names, code points, as well as groups and sub-groups.

### Acknowledgements

Unicode.org

### Inspiration

They are very expressive, and efficient, and we use them every day... 
For text mining and social media analytics, it's useful to be able to extract the emoji used, and develop an understanding of people's thoughts/feelings. They are mainly useful when we get their names actually, because then they become short phrases, and can be analyzed just like other phrases/words.  
Another important attribute is the groups and sub-groups that they belong to. This helps categorize the different emoji as faces, flags, events, face-smiling, face-concerned, etc. ",.csv
Fundamental Dataset of Bangladeshi Stocks,1,fundamental-dataset-of-bangladeshi-stocks,finance.csv,CC-BY-SA-4.0,"This self-built dataset is the first-ever publicly available fundamental dataset of Bangladeshi stocks, containing fundamental metrics from 2000 to 2023.

Description:
A dataset spanning 2000 to 2023, designed to facilitate fundamental analysis, financial analysis and research. It comprises 5615 rows, each representing specific financial metrics of various companies listed in the DSE of the Bangladeshi stock market.

9 Columns:
1. Symbol: The unique identifier for each company within the dataset.
2. Sector: The industry sector to which the company belongs.
3. Year: The fiscal year corresponding to the financial data.
4. Eps (Earnings Per Share): The portion of a company's profit allocated to each outstanding share of common stock.
5. PE (Price-Earnings Ratio): A valuation metric calculated by dividing the market price per share by the earnings per share.
6. Asst/Shr (Asset per Share): The value of total assets divided by the number of outstanding shares.
7. Profit: The net income of a company during the fiscal year.
8. Divid% (Dividend Rate): The percentage of earnings paid out to shareholders as dividends.
9. Div.Yield (Dividend Yield): A financial ratio representing the dividend per share divided by the market price per share, indicating the return on investment from dividends.

This dataset is pioneering in its scope as the first of its kind focusing on Bangladeshi stocks. By providing a collection of financial data spanning over two decades, it serves as a vital resource for researchers, fundamental analysts, and investors interested in the Bangladeshi stock market.",.csv
GDP of each country and region(1960-2020),1,gdp-of-all-countries19602020,gdp_1960_2020.csv,GPL-2.0,"## Countries

'United States', 'United Kingdom', 'France', nan, 'Japan', 'Canada', 'Italy', 'Brazil', 'Turkey', 'Mexico', 'Netherlands', 'Spain', 'Switzerland', 'South Africa', 'Austria', 'Denmark', 'New Zealand', 'Finland', 'Norway', 'Greece', 'Bangladesh', 'Nigeria', 'Chile', 'Colombia', 'South Korea', 'Pakistan', 'DRC', 'Thailand', 'Israel', 'Peru', 'Morocco', 'Malaysia', 'Puerto Rico', 'Iraq', 'Sri Lanka', 'Hong Kong', 'Sultan', 'Uruguay', 'Ghana', 'Zimbabwe', 'Guatemala', 'Ecuador', 'Syria', 'Senegal', 'Kenya', 'Zambia', 'Luxembourg', 'Jamaica', 'Madagascar', 'Dominica', 'Cambodia', 'Cameroon', 'Bolivia', ""C ô te d'Ivoire"", 'Afghanistan', 'Panama', 'Trinidad and Tobago', 'Nepal', 'Costa Rica', 'Niger', 'Uganda', 'Sierra Leone', 'Chad', 'Haiti', 'Papua New Guinea', 'Benin', 'Nicaragua', 'Burundi', 'Liberia', 'Somalia', 'Bahamas', 'Mawlawi', 'Gabon', 'Congo (Brazzaville)', 'Rwanda', 'Fiji Islands', 'Central Africa', 'Suriname', 'Mauritania', 'Bermuda', 'Eswatini', 'Lesotho', 'Belize', 'Saint Vincent and the Grenadines', 'Argentina', 'Equatorial Guinea', 'Egypt', 'Kuwait', 'Tunisia', 'Jordan', 'Paraguay', 'French Polynesia', 'New Caledonia', 'Brunei', 'Oman', 'Indonesia', 'Solomon Islands', 'Saudi Arabia', 'Germany', 'Cuba', 'Qatar', 'Monaco', 'Malta', 'Liechtenstein', 'Guinea Bissau', 'Greenland', 'Kiribati', 'UAE', 'Tonga', 'Saint Lucia', 'Antigua and Barbuda', 'Grenada', 'Vanuatu', 'Angola', 'Mozambique', 'Namibia', 'Cape Verde', 'Bhutan', 'Maldives', 'Ethiopia', 'Marshall Islands', 'Samoa', 'the Federated States of Micronesia', 'Albania', 'Laos', 'Vietnam', 'Lebanon', 'Poland', 'Czech Republic', 'Libya', 'Kazakhstan', 'Belarus', 'Uzbekistan', 'Slovakia', 'Azerbaijan', 'Georgia', 'Yemen', 'Macedonia', 'Moldova', 'Kyrgyzstan', 'Tajikistan', 'Armenia', 'Palau', 'Hungary', 'Palestine', 'Bosnia and Herzegovina', 'Croatia', 'Serbia', 'Lithuania', 'Latvia', 'Isle of man', 'Faroe Islands', 'Myanmar', 'San Marino', 'Timor Leste', 'Turks and Caicos Islands', 'Sao Tome and Principe', 'Guam', 'Northern Mariana Islands', 'American Samoa', 'South Sudan', 'cura ç Ao'


## States

'America', 'Europe', 'Asia', 'Oceania', 'Africa'",.csv
GPA & IQ,1,gpa-and-iq,gpa_iq.csv,CC-BY-SA-3.0,"Data on 78 students including GPA, IQ, and gender.

A data frame with 78 observations representing students on the following 5 variables.

- obs: a numeric vector
- gpa: Grade point average (GPA).
- iq: IQ.
- gender: Gender.
- concept: a numeric vector
",.csv
GPA Study Hours,1,gpa-study-hours,gpa_study_hours.csv,CC-BY-SA-3.0,"A data frame with 193 rows and 2 columns. The columns represent the variables gpa and study_hours for a sample of 193 undergraduate students who took an introductory statistics course in 2012 at a private US university.

**Format**: A data frame with 193 observations on the following 2 variables.

- gpa: Grade point average (GPA) of student.
- study_hours: Number of hours students study per week.

**Details**: GPA ranges from 0 to 4 points, however one student reported a GPA &gt; 4. This is a data error but this observation has been left in the dataset as it is used to illustrate issues with real survey data. Both variables are self reported, hence may not be accurate.

**Source**: Collected at a private US university as part of an anonymous survey in an introductory statistics course. ",.csv
Game of Thrones Script All Seasons,1,game-of-thrones-script-all-seasons,Game_of_Thrones_Script.csv,CC0-1.0,"### Context

Dataset is generated through a long and complex process. Starting from scrapping the whole URLs provided on Genius.com for Game of Thrones series. Process on scrapping and cleaning the dataset required a lot of time and effort in which I managed to utilize wide range of package available for collecting and compiling data scattered all over the internet.

This dataset is inspired by previous similar dataset published by Ander Fernández Jauregui on https://www.kaggle.com/anderfj/game-of-thrones-series-scripts-breakdowns. I was waiting for him to update the dataset to do some analysis on them. Unfortunately, it was a long time since he last updated the dataset. Therefore, following some of his practice I generated this dataset, and hopefully will be a good use for anyone or at least for my personal analysis.


### Content

The content inside is a complete set of Game of Thrones script for all seasons in form of a table containing 6 columns with different data types used for various purposes. Description on each columns are provided on the data description part.


### Acknowledgements

Great credits for Genius.com to published the whole script of Game of Thrones series completely. Also, kudos to all of the open source packages out there, as well as people who are contributing on them so we can utilize those packages as we pleases.


### Inspiration

There is only one question that I want to find answer using this dataset. Who is the true hero/heroin in the whole series?",.csv
GameStop Stock Data (All Time),1,gamestop-stock-data-all-time,GME.csv,CC0-1.0,"**What is GameStop Corp**

GameStop Corp. is an American video game, consumer electronics, and gaming merchandise retailer. The company is headquartered in Grapevine, Texas (a suburb of Dallas), and is the largest video game retailer worldwide. As of January 28, 2023, the company operates 4,413 stores including 2,949 in the United States, 216 in Canada, 419 in Australia and 829 in Europe under the GameStop, EB Games, EB Games Australia, Micromania-Zing, ThinkGeek and Zing Pop Culture brands. The company was founded in Dallas in 1984 as Babbage's, and took on its current name in 1999. 

Website: http://gamestop.com/

Dataset dates: 13 Feb 2002 - 13 May 2024",.csv
Gaming Behavior and Demographics Dataset,1,gaming-behavior-and-demographics-dataset,video_games.csv,CC0-1.0,"**Data Description**
- gender
- birth year
- gamer : if the respondent has played video games in the past few week
- League of Legends : yes or no
- Rocket League : yes or no
- Valorant : yes or no
- Fortnite : yes or no
- Minecraft : yes or no
- Genshin Impact : yes or no
- The Sims : yes or no
- game hours : less than 1 hour, 1-5 hours, 5-20 hours, 20-50 hours, more than 50 hours
- romantic : single or in a relationship
- go out : on a scale from 1 to 4 (1 = never going out, 4 = always going out)

Dataset collected through a questionnaire distributed on Discord groups.",.csv
Gas Networks Ireland Daily supply,1,gas-networks-ireland-daily-supply-2018-2023,Gas Networks Ireland Daily supply 2018-2023.csv,Attribution 4.0 International (CC BY 4.0),"This dataset provides a comprehensive record of the daily demand for gas across the Republic of Ireland from 2018 to the third quarter of 2023. It offers insights into the fluctuations in gas consumption over time, aiding in the analysis of energy usage patterns and facilitating informed decision-making in energy management and policy formulation. The data, sourced from Gas Networks Ireland, is made available as open data under the Creative Commons Attribution 4.0 International (CC BY 4.0) license. Users are encouraged to attribute Gas Networks Ireland for the original data and can access the dataset directly from their open data portal.",.csv
Gas emissions (CO2-e) by transport sector.,1,cusersmarildownloadsdioxidecsv,dioxide.csv,other,"### Context

https://data.gov.au/dataset/ds-qld-32710aab-dc32-40a6-a09e-6e937632eda7/distribution/dist-qld-2017-indicator-3-4-0-3-1/details?q=carbon%20emission
This Data file can be downloaded: http://stateoftheenvironment.des.qld.gov.au/2017/datasets/indicator-3-4-0-3-1.csv




### Content

Queensland annual greenhouse gas emissions in millions of tonnes carbon dioxide equivalent from 1990–2016 by transport sector.
Environment and Science - Updated 30/04/2019  -  Created 24/10/2018





### Acknowledgements

https://data.gov.au/dataset/ds-qld-32710aab-dc32-40a6-a09e-6e937632eda7/distribution/dist-qld-2017-indicator-3-4-0-3-1/details?q=carbon%20emission

Photo by Marija Zaric on Unsplash



### Inspiration

Greta Tintin Eleonora Ernman Thunberg (born 3 January 2003) is a Swedish environmental activist on climate change whose campaigning has gained international recognition. Thunberg is known for her straightforward speaking manner, both in public and to political leaders and assemblies, in which she urges immediate action to address what she describes as the climate crisis.  Greta middle name is Tintin? Who named a girl like a Hergé character?
",.csv
Gender By Name,1,gender-by-name,name_gender_dataset.csv,Attribution 4.0 International (CC BY 4.0),"This dataset combines raw counts for first/given names of male and female babies in those time periods, and then calculates a probability for a name given the aggregate count.  Source datasets are from government authorities:
-US: Baby Names from Social Security Card Applications - National Data, 1880 to 2019
-UK:  Baby names in England and Wales Statistical bulletins, 2011 to 2018
-Canada: British Columbia 100 Years of Popular Baby names, 1918 to 2018
-Australia:  Popular Baby Names, Attorney-General's Department, 1944 to 2019",.csv
Gender Classification,1,gender-classification,Transformed Data Set - Sheet1.csv,CC-BY-SA-4.0,"### Context

Gender is a social construct. The way males and females are treated differently since birth moulds their behaviour and personal preferences into what society expects for their gender.

This small dataset is designed to provide an idea about whether a person's gender can be predicted with an accuracy significantly above 50% based on their personal preferences.


### Content

The data was collected in Fall 2015 from university students of 21 nationalities studying various majors in various countries using this form: 

https://docs.google.com/forms/d/e/1FAIpQLSduEjDURjTh7-a1ZjjlIYx75ScVETLp_gmoFszypz2J7E0LtQ/viewform

The responses were then pre-processed and grouped into categories in order to obtain the final, transformed dataset.

### Inspiration

With the rise of feminism, the difference between males and females in terms of their personal preferences has decreased in recent years. For instance, historically in many cultures, warm colors such as red and pink were thought of as feminine colors while cool colors such as blue were considered masculine. Today, such ideas are considered outdated.

Despite the decrease in the influence of gender on people’s personal preferences, can a decent gender classifier be built given a dataset with people’s personal preferences? What does this small dataset suggest?",.csv
Gender Classification Dataset,1,gender-classification-dataset,gender_classification_v7.csv,CC0-1.0,"### Context

While I was practicing machine learning, I wanted to create a simple dataset that is closely aligned to the real world scenario and gives better results to whet my appetite on this domain. If you are a beginner who wants to try solving classification problems in machine learning and if you prefer achieving better results, try using this dataset in your projects which will be a great place to start.


### Content

This dataset contains 7 features and a label column. 

**long_hair** - This column contains 0's and 1's where 1 is ""long hair"" and 0 is ""not long hair"".
**forehead_width_cm** - This column is in CM's. This is the width of the forehead. 
**forehead_height_cm** - This is the height of the forehead and it's in Cm's.
**nose_wide** - This column contains 0's and 1's where 1 is ""wide nose"" and 0 is ""not wide nose"". 
**nose_long** - This column contains 0's and 1's where 1 is ""Long nose"" and 0 is ""not long nose"".
**lips_thin** - This column contains 0's and 1's where 1 represents the ""thin lips"" while 0 is ""Not thin lips"".
**distance_nose_to_lip_long** - This column contains 0's and 1's where 1 represents the ""long distance between nose and lips"" while 0 is ""short distance between nose and lips"".

**gender** - This is either ""Male"" or ""Female"".


### Acknowledgements

Nothing to acknowledge as this is just a made up data.


### Inspiration

It's painful to see bad results at the beginning. Don't begin with complicated datasets if you are a beginner. I'm sure that this dataset will encourage you to proceed further in the domain. Good luck.",.csv
Gender Economic Inequality,1,gender-economic-inequality,gendergapinaverage new.csv,CC0-1.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fd39230af80a043997c3bc1f70b3ca6e4%2Fgraph1.png?generation=1711134630790073&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F9c51c6a1f368258e70eef8dca34645be%2Fgraph2.png?generation=1711134637066625&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fb0ec16f5bdf5367f025fd0f93fb45e46%2Fgraph3.png?generation=1711134646351135&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fe79fd897b1ae42e3c5d466ade7f2dfbd%2Fgraph4.gif?generation=1711134653021790&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F3dfb8ac5baace3cd70ccb7c76bc09624%2Fgraph5.gif?generation=1711134658633921&alt=media)



Introduction:

Economic gender inequality has long been a pervasive issue, manifesting in disparities in pay, job opportunities, and wealth accumulation between men and women. Despite progress in recent decades, these gaps continue to persist, albeit to a lesser extent than before. This essay delves into the intricate landscape of economic gender inequality, exploring its dimensions, historical trajectories, and underlying causes.

Dimensions of Inequality:

At the heart of economic gender inequality lie disparities in pay, job roles, and wealth distribution. Studies consistently reveal that women earn less than men across various occupations and industries, with the gender pay gap persisting globally. Moreover, women remain underrepresented in leadership positions and fields traditionally dominated by men, reflecting deep-rooted societal norms and biases. In terms of wealth accumulation, women often face obstacles such as limited access to financial resources and assets, further exacerbating economic disparities.

Historical Evolution:

The trajectory of economic gender inequality is marked by both stagnation and progress. Historically, women faced severe restrictions in the workforce, confined to domestic roles with limited opportunities for economic independence. The advent of feminist movements and legislative reforms in the 20th century paved the way for greater gender equality in the workplace. However, progress has been uneven, with persistent barriers hindering women's advancement in certain sectors and regions. Despite these challenges, there is evidence of narrowing gender gaps in pay and employment participation over time, albeit at a slower pace than desired.

Causes of Inequality:

Understanding the causes of economic gender inequality requires a multifaceted analysis of social, cultural, and economic factors. One key determinant is occupational segregation, whereby women are disproportionately represented in lower-paying and undervalued professions. This segregation is perpetuated by discriminatory hiring practices, gender stereotypes, and societal expectations regarding caregiving responsibilities. Additionally, women often encounter systemic barriers such as lack of access to education and training, as well as limited opportunities for career advancement. Structural factors, including institutionalized sexism and unequal distribution of resources, further entrench gender disparities in the economy.

Policy Interventions:

Addressing economic gender inequality necessitates comprehensive policy interventions at both the macro and micro levels. Legislative measures, such as pay equity laws and anti-discrimination policies, are crucial for ensuring fair treatment and opportunities for women in the workforce. Investments in education and vocational training programs can empower women with the skills and resources needed to thrive in diverse fields. Moreover, initiatives aimed at promoting work-life balance, such as affordable childcare and parental leave policies, can mitigate the impact of caregiving responsibilities on women's career trajectories. Furthermore, fostering a culture of diversity and inclusion within organizations is essential for dismantling systemic barriers and promoting gender equality in leadership positions.

Implications and Future Outlook:

The persistence of economic gender inequality has far-reaching implications for individuals, communities, and economies as a whole. Beyond its moral imperative, achieving gender parity in the economy is critical for fostering inclusive growth and sustainable development. Empowering women economically not only enhances their individual well-being but also contributes to poverty reduction, economic productivity, and social cohesion. Moreover, closing the gender gap in employment and entrepreneurship unlocks untapped potential, driving innovation and competitiveness in the global market.

Conclusion:

Economic gender inequality remains a significant challenge despite progress in recent years. By understanding its multifaceted dimensions and underlying causes, policymakers and stakeholders can implement targeted interventions to promote gender equality in the economy. Through concerted efforts to dismantle systemic barriers, challenge gender norms, and foster inclusive workplaces, we can create a more equitable and prosperous future for all.",.csv
Gender Inequality Index by Country,1,gender-inequality-index-dataset,Gender Inequality Index.csv,other,"### Context

The Gender Inequality Index (GII) is a comprehensive measure devised to evaluate gender disparities and inequities within a society by taking into account various critical dimensions. This index provides insights into the differences and imbalances experienced by individuals based on their gender. The GII is an extension of the Human Development Index (HDI) and concentrates on three principal dimensions: reproductive health, empowerment, and economic activity. Reproductive health is a significant dimension of the GII, encompassing indicators such as maternal mortality rates and adolescent birth rates. These indicators reflect the disparities in health outcomes experienced by women, especially in terms of maternal health and reproductive rights.

### Content

This dataset provides comprehensive historical data on gender development indicators at a global level. It includes essential columns such as ISO3 (the ISO3 code for each country/territory), Country (the name of the country or territory), Continent (the continent where the country is located), Hemisphere (the hemisphere in which the country is situated), Human Development Groups, UNDP Developing Regions, HDI Rank (2021) representing the Human Development Index Rank for the year 2021, GII Rank (2021) representing the Gender Inequality Index Rank for 2021 and Gender Inequality Index spanning from 1990 to 2021.

### Dataset Glossary (Column-wise)

* <b>ISO3</b> - ISO3 for the Country/Territory
* <b>Country</b> - Name of the Country/Territory
* <b>Continent</b> - Name of the Continent
* <b>Hemisphere</b> - Name of the Hemisphere
* <b>Human Development Groups</b> - Human Development Groups
* <b>UNDP Developing Regions</b> - UNDP Developing Regions
* <b>HDI Rank (2021)</b> - Human Development Index Rank for 2021
* <b>GII Rank (2021)</b> - Gender Inequality Index Rank for 2021
* <b>Gender Inequality Index from 1990 to 2021</b> - Gender Inequality Index from 1990 to 2021

### Data Dictionary

* <b>UNDP Developing Regions</b>:
 - <b>SSA</b> - Sub-Saharan Africa
 - <b>LAC</b> - Latin America and the Caribbean
 - <b>EAP</b> - East Asia and the Pacific
 - <b>AS</b> - Arab States
 - <b>ECA</b> - Europe and Central Asia
 - <b>SA</b> - South Asia

### Structure of the Dataset

![](https://i.imgur.com/E64Y2Be.png)

### Acknowledgement

This Dataset is created from <b>[Human Development Reports](https://hdr.undp.org/)</b>. This Dataset falls under the Creative Commons Attribution 3.0 IGO License. You can check the <b>[Terms of Use](https://hdr.undp.org/terms-use)</b> of this Data. If you want to learn more, visit the Website.

Cover Photo by: <b><a href=""https://www.freepik.com/free-vector/gender-equality-concept_8925920.htm#query=gender&position=26&from_view=keyword&track=sph"">Image by pikisuperstar</a> on Freepik</b>

Thumbnail by: <b><a href=""https://www.flaticon.com/free-icons/equality"">Equality icons created by Freepik - Flaticon</a></b>",.csv
Gender Recognition by Voice,1,voicegender,voice.csv,CC-BY-NC-SA-4.0,"Voice Gender
----------------

Gender Recognition by Voice and Speech Analysis

This database was created to identify a voice as male or female, based upon acoustic properties of the voice and speech. The dataset consists of 3,168 recorded voice samples, collected from male and female speakers. The voice samples are pre-processed by acoustic analysis in R using the seewave and tuneR packages, with an analyzed frequency range of 0hz-280hz ([human vocal range][2]).

## The Dataset

The following acoustic properties of each voice are measured and included within the CSV:

- **meanfreq**: mean frequency (in kHz)
- **sd**: standard deviation of frequency
- **median**: median frequency (in kHz)
- **Q25**: first quantile (in kHz)
- **Q75**: third quantile (in kHz)
- **IQR**: interquantile range (in kHz)
- **skew**: skewness (see note in specprop description)
- **kurt**: kurtosis (see note in specprop description)
- **sp.ent**: spectral entropy
- **sfm**: spectral flatness
- **mode**: mode frequency
- **centroid**: frequency centroid (see specprop)
- **peakf**: peak frequency (frequency with highest energy)
- **meanfun**: average of fundamental frequency measured across acoustic signal
- **minfun**: minimum fundamental frequency measured across acoustic signal
- **maxfun**: maximum fundamental frequency measured across acoustic signal
- **meandom**: average of dominant frequency measured across acoustic signal
- **mindom**: minimum of dominant frequency measured across acoustic signal
- **maxdom**: maximum of dominant frequency measured across acoustic signal
- **dfrange**: range of dominant frequency measured across acoustic signal
- **modindx**: modulation index. Calculated as the accumulated absolute difference between adjacent measurements of fundamental frequencies divided by the frequency range
- **label**: male or female

## Accuracy

### Baseline (always predict male)
50% / 50%

### Logistic Regression
97% / 98%

### CART
96% / 97%

### Random Forest
100% / 98%

### SVM
100% / 99%

### XGBoost
100% / 99%

## Research Questions

An original analysis of the data-set can be found in the following article: 

[Identifying the Gender of a Voice using Machine Learning][3]

The best model achieves 99% accuracy on the test set. According to a CART model, it appears that looking at the mean fundamental frequency might be enough to accurately classify a voice. However, some male voices use a higher frequency, even though their resonance differs from female voices, and may be incorrectly classified as female. To the human ear, there is apparently more than simple frequency, that determines a voice's gender.

### Questions

- What other features differ between male and female voices?
- Can we find a difference in resonance between male and female voices?
- Can we identify falsetto from regular voices? (separate data-set likely needed for this)
- Are there other interesting features in the data?

### CART Diagram

![CART model][4]

Mean fundamental frequency appears to be an indicator of voice gender, with a threshold of 140hz separating male from female classifications.

## References

[The Harvard-Haskins Database of Regularly-Timed Speech](http://www.nsi.edu/~ani/download.html)

[Telecommunications & Signal Processing Laboratory (TSP) Speech Database at McGill University](http://www-mmsp.ece.mcgill.ca/Documents../Downloads/TSPspeech/TSPspeech.pdf), [Home](http://www-mmsp.ece.mcgill.ca/Documents../Data/index.html)

[VoxForge Speech Corpus](http://www.repository.voxforge1.org/downloads/SpeechCorpus/Trunk/Audio/Main/8kHz_16bit/), [Home](http://www.voxforge.org)

[Festvox CMU_ARCTIC Speech Database at Carnegie Mellon University](http://festvox.org/cmu_arctic/)


  [1]: http://www.primaryobjects.com/2016/06/22/identifying-the-gender-of-a-voice-using-machine-learning
  [2]: https://en.wikipedia.org/wiki/Voice_frequency#Fundamental_frequency
  [3]: http://www.primaryobjects.com/2016/06/22/identifying-the-gender-of-a-voice-using-machine-learning/
  [4]: http://i.imgur.com/Npr2U7O.png",.csv
Genetic Variant Classifications,1,clinvar-conflicting,clinvar_conflicting.csv,CC0-1.0,"### Context

[ClinVar](https://www.ncbi.nlm.nih.gov/clinvar/) is a public resource containing annotations about human genetic variants. These variants are (usually manually) classified by clinical laboratories on a categorical spectrum ranging from benign, likely benign, uncertain significance, likely pathogenic, and pathogenic. Variants that have conflicting classifications (from laboratory to laboratory) can cause confusion when clinicians or researchers try to interpret whether the variant has an impact on the disease of a given patient.  

### Content

The objective is to predict whether a ClinVar variant will have **conflicting classifications**. This is presented here as a binary classification problem, where each record in the dataset is a genetic **variant**.

![conflicting variants figure][1]

Conflicting classifications are when two of any of the following three categories are present for one variant, two submissions of one category are not considered conflicting.

1. Likely Benign or Benign
2. VUS
3. Likely Pathogenic or Pathogenic

Conflicting classification has been assigned to the `CLASS` column. It is a binary representation of whether or not a variant has conflicting classifications, where `0` represents consistent classifications and `1` represents conflicting classifications.

Since this problem only relates to variants with multiple classifications, I removed all variants from the original ClinVar `.vcf` which only had one submission.

The raw variant call format (vcf) file was downloaded here on Saturday, April 7th, 2018:
[ftp://ftp.ncbi.nlm.nih.gov/pub/clinvar/vcf_GRCh37/clinvar.vcf.gz][2]

Scripts used to generate this file in [this repo](https://github.com/arvkevi/clinvar-kaggle)

### Acknowledgements

Landrum MJ, Lee JM, Benson M, Brown GR, Chao C, Chitipiralla S, Gu B, Hart J, Hoffman D, Jang W, Karapetyan K, Katz K, Liu C, Maddipatla Z, Malheiro A, McDaniel K, Ovetsky M, Riley G, Zhou G, Holmes JB, Kattman BL, Maglott DR. ClinVar: improving access to variant interpretations and supporting evidence. Nucleic Acids Res. 2018 Jan 4. PubMed PMID: 29165669.

### Inspiration

I'm exploring ideas for applying machine learning to genomics. I'm hoping this dataset will encourage others to think about the additional feature engineering that's necessary to confidently assess the objective. There could be a benefit to identifying *single submission* variants that may yet to have assigned a **conflicting classification**.


  [1]: https://raw.githubusercontent.com/arvkevi/clinvar-kaggle/master/clinvar-class-fig.png
  [2]: ftp://ftp.ncbi.nlm.nih.gov/pub/clinvar/vcf_GRCh37/",.csv
Genshin Impact Character Data,1,genshin-impact-character-data,genshin.csv,CC0-1.0,"This dataset contains descriptive information on all current Genshin Impact characters. I thought this would be a fun little dataset to create and experiment with as I study data mining and analytics, and I hope you enjoy it, too!

### Disclaimer
All characters belong to Hoyoverse and are not mine. Data is sourced from the Genshin Impact Wiki and is subject to human error. Special characters may be replaced with ""?"" due to data loss when converting to .csv file.

### Update Notes
Version 11: Added data on Charlotte and Furina.   
Version 10: Lots of changes.
1. Added column ""limited"" with Boolean values TRUE and FALSE to indicate whether or not a character can be summoned on the standard banner.
2. Added the “alignment” column to indicate the character’s Arkhe alignment.
3. Changed Tighnari’s English voice actor to reflect changes made by Hoyoverse.
4. Changed column ""talent_book"" to ""talent_book_2"" and added columns for talent books needed for leveling to 3, 4, 5, 6, 7, 8, 9, and 10, mainly due to the Traveler using all three of a region’s talent books for various levels.
5. Fixed an error in which the values for Traveler (Aether) and Traveler (Lumine) for ""model"" and voice actors were swapped.
6. Changed Traveler (Aether) to Traveler (Aether, Anemo) and Traveler (Lumine) to Traveler (Lumine, Anemo), and added rows for both Aether and Lumine for Geo, Electro, Dendro, and Hydro.
7. Added data on Neuvillette and Wriothesley.   

Version 9: Added data on Lyney, Lynette, and Freminet.  
Version 8: Removed the Dainsleif row and the Playable column – only playable characters will be recorded to prevent incomplete/blank data. Added data on Alhaitham, Baizhu, Dehya, Faruzan, Kaveh, Kirara, Layla, Mika, Nahida, Wanderer, and Yaoyao.  
Version 7: Added data on Nilou, Cyno, and Candace.  
Version 6: Added data on Kuki Shinobu, Tighnari, Collei, and Dori.  
Version 5: Added data on Shikanoin Heizou.  
Version 4: Added data on Kuki Shinobu. Added known data for upcoming Sumeru characters. Added ""affiliation"" column.  
Version 3: Added data on Yelan. Added columns for base HP, ATK, and DEF at all major milestones.  
Version 2: Error fixes.  ",.csv
Genshin Impact Google Play Reviews,1,genshin-impact-google-play-reviews,genshin_review.csv,Apache 2.0,"This Genshin Impact dataset, comprising only review and rating columns, is suitable for beginners and intermediate learners who are interested in studying player feedback. With its simplified structure, it provides an accessible starting point for those looking to analyze player sentiments and satisfaction levels. By working with this dataset, beginners and intermediate learners can learn more about what players enjoy and what they want to see improved in the game.

# **Key Details**

- **Dataset Content**: Reviews and ratings for the Genshin Impact game.
- **Structure**: Two columns - Review and Rating.
- **Rating Scale**: Scores range from 1 to 5 stars.

#**Potential Use Cases**

- **Educational Analysis**: Beginner and intermediate learners can use the dataset to practice basic data analysis techniques and gain insights into player feedback patterns.
- **Sentiment Analysis Projects**: Researchers and analysts can conduct sentiment analysis projects to understand player sentiments towards various aspects of the game, such as characters, gameplay mechanics, and storyline.
- **Product Improvement Insights**: Game developers can analyze the dataset to gain insights into areas for potential game improvements based on player feedback and prioritize development efforts accordingly.",.csv
Geographical Data Query Dataset,1,geographical-data-query-dataset,data.csv,MIT,"This dataset comprises text-based queries focused on obtaining specific climate and environmental data for various regions. Queries include requests for historical temperature data, UV index comparisons, rainfall patterns, and geographical mapping, etc. The dataset facilitates the exploration of climate trends and environmental conditions in different locations, enabling users to analyze and visualize regional climate variations over time.",.csv
German Car Insights,1,german-car-insights,gcar_data.csv,Apache 2.0,"Here's a brief description of each column in the dataset:

1. **Brand**: The brand or manufacturer of the vehicle.
2. **Model**: The specific model of the vehicle.
3. **Color**: The color of the vehicle.
4. **Registration Date**: The date when the vehicle was registered.
5. **Year**: The manufacturing year of the vehicle.
6. **Price in Euro**: The price of the vehicle listed in Euros.
7. **Power kW**: The power of the vehicle's engine in kilowatts.
8. **Power PS**: The power of the vehicle's engine in metric horsepower.
9. **Transmission Type**: The type of transmission system used in the vehicle (e.g., manual, automatic).
10. **Fuel Type**: The type of fuel used by the vehicle (e.g., petrol, diesel, electric).
11. **Fuel Consumption (L/100km)**: The fuel consumption of the vehicle in liters per 100 kilometers.
12. **Fuel Consumption (g/km)**: The fuel consumption of the vehicle in grams per kilometer.
13. **Mileage in km**: The total distance traveled by the vehicle in kilometers.
14. **Offer Description**: Additional information or description provided about the vehicle listing.",.csv
German Credit Risk,1,german-credit,german_credit_data.csv,DbCL-1.0,"# Context 
The original dataset contains 1000 entries with 20 categorial/symbolic attributes prepared by Prof. Hofmann. In this dataset, each entry represents a person who takes a credit by a bank. Each person is classified as good or bad credit risks according to the set of attributes. The link to the original dataset can be found below.

# Content
It is almost impossible to understand the original dataset due to its complicated system of categories and symbols. Thus, I wrote a small Python script to convert it into a readable CSV file. Several columns are simply ignored, because in my opinion either they are not important or their descriptions are obscure. The selected attributes are:

 1. Age (numeric)
 2. Sex (text: male, female)
 3. Job (numeric: 0 - unskilled and non-resident, 1 - unskilled and resident, 2 - skilled, 3 - highly skilled)
 4. Housing (text: own, rent, or free)
 5. Saving accounts (text - little, moderate, quite rich, rich)
 6. Checking account (numeric, in DM - Deutsch Mark)
 7. Credit amount (numeric, in DM)
 8. Duration (numeric, in month)
 9. Purpose (text: car, furniture/equipment, radio/TV, domestic appliances, repairs, education, business, vacation/others)

# Acknowledgements

Source: [UCI][1]



  [1]: https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29",.csv
Gestational Diabetes,1,gestational-diabetes,Gestational Diabetes.csv,CC-BY-SA-4.0,"Gestational diabetes is a type of high blood sugar that develops during pregnancy. It can occur at any stage of pregnancy and cause problems for both the mother and the baby, during and after birth. The risks can be reduced if they are early detected and managed, especially in areas where only periodic tests of pregnant women are available. Intelligent systems designed by machine learning algorithms are remodelling all fields of our lives, including the healthcare system. This study proposes a combined prediction model to diagnose gestational diabetes. The dataset was obtained from the Kurdistan region laboratories, which collected information from pregnant women with and without diabetes.",.csv
Glass Classification,1,glass,glass.csv,DbCL-1.0,"# Context 

This is a Glass Identification Data Set from UCI. It contains 10 attributes including id. The response is glass type(discrete 7 values)


# Content

Attribute Information:

1. Id number: 1 to 214 (removed from CSV file)
2. RI: refractive index 
3. Na: Sodium (unit measurement: weight percent in corresponding oxide, as are attributes 4-10) 
4. Mg: Magnesium 
5. Al: Aluminum 
6. Si: Silicon 
7. K: Potassium 
8. Ca: Calcium 
9. Ba: Barium 
10. Fe: Iron 
11. Type of glass: (class attribute) 
-- 1 building_windows_float_processed 
-- 2 building_windows_non_float_processed 
-- 3 vehicle_windows_float_processed 
-- 4 vehicle_windows_non_float_processed (none in this database) 
-- 5 containers 
-- 6 tableware 
-- 7 headlamps


# Acknowledgements

https://archive.ics.uci.edu/ml/datasets/Glass+Identification
Source:

Creator: 
B. German 
Central Research Establishment 
Home Office Forensic Science Service 
Aldermaston, Reading, Berkshire RG7 4PN 

Donor: 
Vina Spiehler, Ph.D., DABFT 
Diagnostic Products Corporation 
(213) 776-0180 (ext 3014)

# Inspiration

Data exploration of this dataset reveals two important characteristics :
1) The variables are highly **corelated** with each other including the response variables:
So which kind of ML algorithm is most suitable for this dataset Random Forest , KNN or other? Also since dataset is too small is there any chance of applying PCA or it should be completely avoided?

2) Highly **Skewed** Data:
Is scaling sufficient or are there any other techniques which should be applied to normalize data? Like BOX-COX Power transformation?",.csv
Glass Identification Data Set,1,glass-identification-data-set,glass.csv,CC0-1.0,"#**Sources**
**1.  Creator:**  B. German
        -- Central Research Establishment
           Home Office Forensic Science Service
           Aldermaston, Reading, Berkshire RG7 4PN

**2. Donor:** Vina Spiehler, Ph.D., DABFT
               Diagnostic Products Corporation
               (213) 776-0180 (ext 3014)

**3. Date:** September 1987

## **Usage**    
- Rule Induction in Forensic Science
       - Ian W. Evett and Ernest J. Spiehler
       - Central Research Establishment
          Home Office Forensic Science Service
          Aldermaston, Reading, Berkshire RG7 4PN
       - Unknown technical note number (sorry, not listed here)
       - General Results: nearest neighbor held its own with respect to the
             rule-based system

##**Description**
Vina conducted a comparison test of her rule-based system, BEAGLE, the nearest-neighbor algorithm, and discriminant analysis.  BEAGLE is a product available through VRS Consulting, Inc.; 4676 Admiralty Way, Suite 206; Marina Del Ray, CA 90292 (213) 827-7890 and FAX: -3189. The study of the classification of types of glass was motivated by criminological investigation.  At the scene of th, the glass left can be used as evidence...if it is correctly identified!

##**Number of Instances** 
214

##**Number of Attributes** 
***10*** (including an Id#) plus the class attribute
   - all attributes are continuously valued

##**Attribute Information**
   1. Id number: 1 to 214
   2. RI: refractive index
   3. Na: Sodium (unit measurement: weight percent in the corresponding oxide, as 
                  are attributes 4-10)
   4. Mg: Magnesium
   5. Al: Aluminum
   6. Si: Silicon
   7. K: Potassium
   8. Ca: Calcium
   9. Ba: Barium
  10. Fe: Iron
  11. Type of glass: (class attribute)
      - 1 building_windows_float_processed
      - 2 building_windows_non_float_processed
      - 3 vehicle_windows_float_processed
      - 4 vehicle_windows_non_float_processed (none in this database)
      - 5 containers
      - 6 tableware
      - 7 headlamps

###**Missing Attribute Values:**
None

##**Class Distribution:**
(out of 214 total instances)
- 163 Window glass (building windows and vehicle windows)
       - 87 float processed  
          - 70 building windows
          - 17 vehicle windows
       - 76 non-float processed
          - 76 building windows
          - 0 vehicle windows
- 51 Non-window glass
       - 13 containers
       - 9 tableware
       - 29 headlamps",.csv
Glassdoor- Analyze Gender Pay Gap,1,glassdoor-analyze-gender-pay-gap,Glassdoor Gender Pay Gap.csv,other,"### Context

Want to know the base pay for different job roles, then this data set will be useful.


### About the data set:
The data set has been taken from glassdoor and focuses on income for various job titles based on gender. As there have been many studies showcasing that women are paid less than men for the same job titles, this data set will be helpful in identifying the depth of the gender-based pay gap. The features of the data set are:
Job Title
Gender
Age
PerfEval
Education
Dept 
Seniority
Base Pay, and
Bonus



### Acknowledgements
The data set has been taken from the website of Glassdoor. The license was not mentioned on the source.

### Inspiration
To find out the pay gap between the gender for the same job title.",.csv
Global - Food Prices,1,global-food-prices,wfp_market_food_prices.csv,CC0-1.0,"# Description

This dataset contains Countries, Commodities, and Markets data, sourced from the World Food Programme Price Database. The volume of data means that the actual Food Prices data is in country-level datasets. The World Food Programme Price Database covers foods such as maize, rice, beans, fish, and sugar for 98 countries and some 3000 markets. It is updated weekly but contains to a large extent monthly data. The data goes back as far as 1992 for a few countries, although many countries started reporting from 2003 or thereafter.

# Acknowledgements & Source

Compiled by the [World Food Program](https://www.google.com/url?q=http%3A%2F%2Fwww1.wfp.org%2F&source=datasetsearch) and distributed by [HDX]( https://data.humdata.org/dataset/global-wfp-food-prices).

[Image Source] (https://dipoinduction.com/wp-content/uploads/2021/04/Global-Food-Prices-Continue-to-Rise-Dipo-Induction-1024x581.jpg)

# Please don't forget to upvote if you find this useful.",.csv
"Global AI, ML, Data Science Salary 2023",1,global-ai-ml-data-science-salary,salaries.csv,CC0-1.0,"**What's inside?**
The download basically contains a single table with all salary information structured as follows.

**work_year**
The year the salary was paid

**experience_level**
The experience level in the job during the year with the following possible values

EN : Entry-level / Junior
MI : Mid-level / Intermediate
SE : Senior-level / Expert
EX : Executive-level / Director
**employment_type**
The type of employement for the role

PT : Part-time
FT : Full-time
CT : Contract
FL : Freelance
**job_title**
The role worked in during the year

**salary**
The total gross salary amount paid

**salary_currency**
The currency of the salary paid as an ISO 4217 currency code

**salary_in_usd**
The salary in USD (FX rate divided by avg. USD rate for the respective year via fxdata.foorilla.com)

**employee_residence**
Employee's primary country of residence in during the work year as an ISO 3166 country code

**remote_ratio**
The overall amount of work done remotely, possible values are as follows

0 : No remote work (less than 20%)
50 : Partially remote
100 : Fully remote (more than 80%)
**company_location**
The country of the employer's main office or contracting branch as an ISO 3166 country code

**company_size**
The average number of people that worked for the company during the year

S : less than 50 employees (small)
M : 50 to 250 employees (medium)
L : more than 250 employees (large).

You can download an updated version of it or see a detailed description of the contents via: https://infosec-https://ai-jobs.net/salaries/download/

Or submit your own salary if you work in this space to add to the dataset (much appreciated!): https://ai-jobs.net/salaries/form/",.csv
Global Air Pollution Data,1,global-air-pollution-data,global_air_pollution_data.csv,other,"### Context
This dataset, spanning 170 countries and 300+ cities, provides a holistic view of global air quality dynamics. Focused on crucial pollutants like Carbon Monoxide, Ozone, Nitrogen Dioxide, and Particulate Matter (PM2.5), it serves as a valuable resource for environmental scientists, policymakers, and researchers. The insights derived from this dataset empower users to analyze air quality trends, formulate effective policies, and contribute to fostering a healthier planet.

### Content
Featuring essential columns such as country name, city name, overall Air Quality Index (AQI) values, and concentrations of specific pollutants, this dataset supports in-depth analyses and correlation studies. Researchers can uncover patterns and trends in air quality by exploring the relationships between pollutants and overall AQI values. With its comprehensive scope, this dataset is an indispensable tool for those interested in understanding air quality dynamics and actively participating in collective efforts toward a cleaner and healthier atmosphere.

### Dataset Structure:
The dataset (`global_air_pollution_data.csv`) covers the year of 2024 and includes the following columns:

| Column Name         | Description                                          |
| ------------------- | ---------------------------------------------------- |
| `country_name`      | Name of the Country                                  |
| `city_name`         | Name of the City                                     |
| `aqi_value`         | Overall AQI value of the city                         |
| `aqi_category`      | Overall AQI category of the city                      |
| `co_aqi_value`      | AQI value of Carbon Monoxide of the city              |
| `co_aqi_category`   | AQI category of Carbon Monoxide of the city           |
| `ozone_aqi_value`   | AQI value of Ozone of the city                        |
| `ozone_aqi_category`| AQI category of Ozone of the city                     |
| `no2_aqi_value`     | AQI value of Nitrogen Dioxide of the city             |
| `no2_aqi_category`  | AQI category of Nitrogen Dioxide of the city          |
| `pm2.5_aqi_value`    | AQI value of Particulate Matter with a diameter of 2.5 micrometers or less of the city |
| `pm2.5_aqi_category` | AQI category of Particulate Matter with a diameter of 2.5 micrometers or less of the city |

### Acknowledgment
The primary dataset was sourced from [eLichens](https://www.elichens.com/global-air-quality-map), and I extend sincere gratitude to the team for providing the core data used in this dataset.

© Image credit: [Freepik](https://www.freepik.com/free-photo/view-power-plant-emitting-co2-near-forest_31481304.htm)",.csv
Global Air Pollution Dataset,1,global-air-pollution-dataset,global air pollution dataset.csv,other,"## Context
**Air Pollution** is contamination of the indoor or outdoor environment by any chemical, physical or biological agent that modifies the natural characteristics of the atmosphere. Household combustion devices, motor vehicles, industrial facilities and forest fires are common sources of air pollution. Pollutants of major public health concern include particulate matter, carbon monoxide, ozone, nitrogen dioxide and sulfur dioxide. Outdoor and indoor air pollution cause respiratory and other diseases and are important sources of morbidity and mortality. 

**This dataset provides geolocated information about the following pollutants:**

- **Nitrogen Dioxide [NO2] :** **Nitrogen Dioxide** is one of the several nitrogen oxides. It is introduced into the air by natural phenomena like entry from stratosphere or lighting. At the surface level, however, NO2 forms from cars, trucks and buses emissions, power plants and off-road equipment. Exposure over short periods can aggravate respiratory diseases, like asthma. Longer exposures may contribute to develoment of asthma and respiratory infections. People with asthma, children and the elderly are at greater risk for the health effects of NO2.

- **Ozone [O3] :** The **Ozone** molecule is harmful for outdoor air quality (if outside of the ozone layer). At surface level, ozone is created by chemical reactions between oxides of nitrogen and volatile organic compounds (VOC). Differently from the good ozone located in the upper atmosphere, ground level ozone can provoke several health problems like chest pain, coughing, throat irritation and airway inflammation. Furthermore it can reduce lung function and worsen bronchitis, emphysema, and asthma. Ozone affects also vegetation and ecosystems. In particular, it damages sensitive vegetation during the growing season.

- **Carbon Monoxide [CO] :** Carbon Monoxide is a colorless and odorless gas. Outdoor, it is emitted in the air above all by cars, trucks and other vehicles or machineries that burn fossil fuels. Such items like kerosene and gas space heaters, gas stoves also release CO affecting indoor air quality.
Breathing air with a high concentration of CO reduces the amount of oxygen that can be transported in the blood stream to critical organs like the heart and brain. At very high levels, which are not likely to occur outdoor but which are possible in enclosed environments. CO can cause dizziness, confusion, unconsciousness and death.

- **Particulate Matter [PM2.5] :** Atmospheric **Particulate Matter**, also known as atmospheric aerosol particles, are complex mixtures of small solid and liquid matter that get into the air. If inhaled they can cause serious heart and lungs problem. They have been classified as group 1 carcinogen by the International Agengy for Research on Cancer (IARC). PM10 refers to those particules with a diameter of 10 micrometers or less. PM2.5 refers to those particles with a diameter of 2.5 micrometers or less.

## Content
There is one dataset here.

### global air pollution dataset.csv
- **Country :** Name of the country
- **City :** Name of the city
- **AQI Value :** Overall AQI value of the city
- **AQI Category :** Overall AQI category of the city
- **CO AQI Value :** AQI value of Carbon Monoxide of the city
- **CO AQI Category :** AQI category of Carbon Monoxide of the city
- **Ozone AQI Value :** AQI value of Ozone of the city
- **Ozone AQI Category :** AQI category of Ozone of the city
- **NO2 AQI Value :** AQI value of Nitrogen Dioxide of the city
- **NO2 AQI Category :** AQI category of Nitrogen Dioxide of the city
- **PM2.5 AQI Value :** AQI value of Particulate Matter with a diameter of 2.5 micrometers or less of the city
- **PM2.5 AQI Category :** AQI category of Particulate Matter with a diameter of 2.5 micrometers or less of the city


## Acknowledgement
These datas are collected from [elichens](https://www.elichens.com/). 
Cover photo from [VectorStock](https://www.vectorstock.com/).",.csv
Global Armed Forces Dataset,1,global-armed-forces-dataset,military.csv,CC0-1.0,"This dataset provides a comprehensive overview of the active and reserved military forces of countries around the world. 

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F13571604%2F6a695a6e9fb2d8be9e43ad2a266cb06f%2FScreenshot%202023-07-23%20074628.png?generation=1690122116090785&alt=media)

It aims to present a detailed analysis of the manpower allocated to each country's armed services, shedding light on their military capabilities and potential readiness for various defense scenarios.",.csv
Global Corruption Index 2023: Insights & Rankings,1,global-corruption-index-transparency-perceptions,CPI2023-Global-Results-Trends.csv,Attribution-NoDerivatives 4.0 International (CC BY-ND 4.0),"Dive into Transparency International's Corruption Perceptions Index for a global overview of corruption trends and rankings.

Column Name | Description
------------|---------------------------------------------------------
Country / Territory | Name of the country or territory.
ISO3 | ISO 3166-1 alpha-3 country code.
Region | Geographic region or economic union the country belongs to.
CPI score 2023 | Corruption Perceptions Index score for the year 2023.
Rank | Ranking of the country based on CPI score.
Standard error | Standard error associated with the CPI score.
Number of sources | Number of sources used to calculate the CPI score.
Lower CI | Lower confidence interval bound for the CPI score.
Upper CI | Upper confidence interval bound for the CPI score.
African Development Bank CPIA | CPIA (Country Policy and Institutional Assessment) score by the African Development Bank.
Bertelsmann Foundation Sustainable Governance Index | Sustainable Governance Index score by the Bertelsmann Foundation.
Bertelsmann Foundation Transformation Index | Transformation Index score by the Bertelsmann Foundation.
Economist Intelligence Unit Country Ratings | Country Ratings by the Economist Intelligence Unit.
Freedom House Nations in Transit | Nations in Transit score by Freedom House.
Global Insights Country Risk Ratings | Country Risk Ratings by Global Insights.
IMD World Competitiveness Yearbook | Competitiveness score by IMD.
PERC Asia Risk Guide | Asia Risk Guide score by PERC.
PRS International Country Risk Guide | Country Risk Guide score by PRS.
Varieties of Democracy Project | Democracy Project score by V-Dem.
World Bank CPIA | CPIA (Country Policy and Institutional Assessment) score by the World Bank.
World Economic Forum EOS | EOS (Enabling of Sustainability) score by the World Economic Forum.
World Justice Project Rule of Law Index | Rule of Law Index score by the World Justice Project.

<br><br>

Reference:

Transparency International (n.d). Corruption Perception Index. [online] Transparency.org. Available at: https://www.transparency.org/en/.


To know more details about reproducing and using Transparency International work, you can consult https://www.transparency.org/permissions
‌",.csv
Global Country Information Dataset 2023,1,countries-of-the-world-2023,world-data-2023.csv,Attribution 4.0 International (CC BY 4.0),"# Description

&gt;This comprehensive dataset provides a wealth of information about **all countries worldwide**, covering a wide range of indicators and attributes. It encompasses demographic statistics, economic indicators, environmental factors, healthcare metrics, education statistics, and much more. With every country represented, this dataset offers a complete global perspective on various aspects of nations, enabling in-depth analyses and cross-country comparisons.




# Key Features

&gt;- **Country**: Name of the country.
- **Density (P/Km2)**: Population density measured in persons per square kilometer.
- **Abbreviation**: Abbreviation or code representing the country.
- **Agricultural Land (%)**: Percentage of land area used for agricultural purposes.
- **Land Area (Km2)**: Total land area of the country in square kilometers.
- **Armed Forces Size**: Size of the armed forces in the country.
- **Birth Rate**: Number of births per 1,000 population per year.
- **Calling Code**: International calling code for the country.
- **Capital/Major City**: Name of the capital or major city.
- **CO2 Emissions**: Carbon dioxide emissions in tons.
- **CPI**: Consumer Price Index, a measure of inflation and purchasing power.
- **CPI Change (%)**: Percentage change in the Consumer Price Index compared to the previous year.
- **Currency_Code**: Currency code used in the country.
- **Fertility Rate**: Average number of children born to a woman during her lifetime.
- **Forested Area (%)**: Percentage of land area covered by forests.
- **Gasoline_Price**: Price of gasoline per liter in local currency.
- **GDP**: Gross Domestic Product, the total value of goods and services produced in the country.
- **Gross Primary Education Enrollment (%)**: Gross enrollment ratio for primary education.
- **Gross Tertiary Education Enrollment (%)**: Gross enrollment ratio for tertiary education.
- **Infant Mortality**: Number of deaths per 1,000 live births before reaching one year of age.
- **Largest City**: Name of the country's largest city.
- **Life Expectancy**: Average number of years a newborn is expected to live.
- **Maternal Mortality Ratio**: Number of maternal deaths per 100,000 live births.
- **Minimum Wage**: Minimum wage level in local currency.
- **Official Language**: Official language(s) spoken in the country.
- **Out of Pocket Health Expenditure (%)**: Percentage of total health expenditure paid out-of-pocket by individuals.
- **Physicians per Thousand**: Number of physicians per thousand people.
- **Population**: Total population of the country.
- **Population: Labor Force Participation (%)**: Percentage of the population that is part of the labor force.
- **Tax Revenue (%)**: Tax revenue as a percentage of GDP.
- **Total Tax Rate**: Overall tax burden as a percentage of commercial profits.
- **Unemployment Rate**: Percentage of the labor force that is unemployed.
- **Urban Population**: Percentage of the population living in urban areas.
- **Latitude**: Latitude coordinate of the country's location.
- **Longitude**: Longitude coordinate of the country's location.


# Potential Use Cases

&gt;- Analyze population density and land area to study spatial distribution patterns.
- Investigate the relationship between agricultural land and food security.
- Examine carbon dioxide emissions and their impact on climate change.
- Explore correlations between economic indicators such as GDP and various socio-economic factors.
- Investigate educational enrollment rates and their implications for human capital development.
- Analyze healthcare metrics such as infant mortality and life expectancy to assess overall well-being.
- Study labor market dynamics through indicators such as labor force participation and unemployment rates.
- Investigate the role of taxation and its impact on economic development.
- Explore urbanization trends and their social and environmental consequences.

Data Source: This dataset was compiled from multiple data sources

If this was helpful, a vote is appreciated ❤️ Thank you 🙂



",.csv
Global Data on Sustainable Energy (2000-2020),1,global-data-on-sustainable-energy,global-data-on-sustainable-energy (1).csv,Attribution 4.0 International (CC BY 4.0),"# Description

&gt; Uncover this dataset showcasing sustainable energy indicators and other useful factors across all countries from 2000 to 2020. Dive into vital aspects such as electricity access, renewable energy, carbon emissions, energy intensity, Financial flows, and economic growth. Compare nations, track progress towards Sustainable Development Goal 7, and gain profound insights into **global energy consumption patterns** over time. 

# Key Features:

&gt;- **Entity**: The name of the country or region for which the data is reported.
- **Year**: The year for which the data is reported, ranging from 2000 to 2020.
- **Access to electricity (% of population)**: The percentage of population with access to electricity.
- **Access to clean fuels for cooking (% of population)**: The percentage of the population with primary reliance on clean fuels.
- **Renewable-electricity-generating-capacity-per-capita**: Installed Renewable energy capacity per person
- **Financial flows to developing countries (US $)**: Aid and assistance from developed countries for clean energy projects.
- **Renewable energy share in total final energy consumption (%)**: Percentage of renewable energy in final energy consumption.
- **Electricity from fossil fuels (TWh)**: Electricity generated from fossil fuels (coal, oil, gas) in terawatt-hours.
- **Electricity from nuclear (TWh)**: Electricity generated from nuclear power in terawatt-hours.
- **Electricity from renewables (TWh)**: Electricity generated from renewable sources (hydro, solar, wind, etc.) in terawatt-hours.
- **Low-carbon electricity (% electricity)**: Percentage of electricity from low-carbon sources (nuclear and renewables).
- **Primary energy consumption per capita (kWh/person)**: Energy consumption per person in kilowatt-hours.
- **Energy intensity level of primary energy (MJ/$2011 PPP GDP)**: Energy use per unit of GDP at purchasing power parity.
- **Value_co2_emissions (metric tons per capita)**: Carbon dioxide emissions per person in metric tons.
- **Renewables (% equivalent primary energy)**: Equivalent primary energy that is derived from renewable sources.
- **GDP growth (annual %)**: Annual GDP growth rate based on constant local currency.
- **GDP per capita**: Gross domestic product per person.
- **Density (P/Km2)**: Population density in persons per square kilometer.
- **Land Area (Km2)**: Total land area in square kilometers.
- **Latitude**: Latitude of the country's centroid in decimal degrees.
- **Longitude**: Longitude of the country's centroid in decimal degrees.

# Potential Use cases

&gt; - **Energy Consumption Prediction:** Predict future energy usage, aid planning, and track SDG 7 progress.
- **Carbon Emission Forecasting:** Forecast CO2 emissions, support climate strategies.
- **Energy Access Classification:** Categorize regions for infrastructure development, understand sustainable energy's role.
- **Sustainable Development Goal Tracking:** Monitor progress towards Goal 7, evaluate policy impact.
- **Energy Equity Analysis:** Analyze access, density, and growth for equitable distribution.
- **Energy Efficiency Optimization:** Identify intensive areas for environmental impact reduction.
- **Renewable Energy Potential Assessment:** Identify regions for green investments based on capacity.
- **Renewable Energy Investment Strategies:** Guide investors towards sustainable opportunities.



",.csv
Global Economy Indicators,1,global-economy-indicators,Global Economy Indicators.csv,CC0-1.0,"## Data Set Information:

The dataset is compiled from the **`National Accounts Main Aggregates Database`** that presents a series of analytical national accounts tables from 1970 onwards for more than 200 countries and areas of the world. It is the product of a global cooperation effort between the Economic Statistics Branch of the United Nations Statistics Division, international statistical agencies, and the national statistical services of these countries and is developed in accordance with the recommendation of the Statistical Commission at its first session in 1947 that the Statistics Division should publish regularly the most recent available data on national accounts for as many countries and areas as possible. 

This dataset can be used to perform clustering, regression, and time series tasks.
 ",.csv
Global Electricity Access: Country-Level Analysis,1,global-electricity-access-country-level-analysis,access_to_electricity_by_country.csv,Apache 2.0,"# Exploring Access to Electricity Data Across Countries

Access to electricity is a fundamental indicator of socio-economic development and quality of life within a nation. The dataset provides valuable insights into the extent of electrification across various countries, shedding light on disparities in infrastructure, energy access, and development progress.

## Dataset Overview:

**Source:**The data is sourced from a reputable international organization or database that monitors global development indicators, such as the World Bank or the International Energy Agency.
**Content:**The dataset contains information about countries worldwide, detailing the percentage of their population with access to electricity over different years.
**Format:** The data is structured in a tabular format, likely organized by country names, years, and corresponding percentages of population with access to electricity.

## Key Fields:

**Entity:** The name of the country or territory represented in the dataset.
**Code:**The standardized country code assigned to each country, facilitating data organization and cross-referencing with other datasets.
**Year:** The year for which access to electricity data is recorded, allowing for temporal analysis and tracking of progress over time.
**Access to electricity (% of population):**The percentage of the population within each country that has access to electricity, indicating the level of electrification and energy infrastructure development.

## Objective:

The objective of exploring this dataset is to assess the progress and disparities in access to electricity across different countries globally. By analyzing trends over time and comparing the electrification rates of various nations, policymakers, energy sector stakeholders, and international organizations can identify regions requiring targeted interventions and investment to improve energy access and promote sustainable development.

## Analytical Approach:

Analyzing the dataset may involve statistical methods, trend analysis, and geographical mapping to identify patterns, trends, and outliers in access to electricity data. Key metrics such as electrification rates, growth rates, and disparities between rural and urban areas can be calculated to inform policy decisions, infrastructure planning, and energy sector investments aimed at enhancing electrification and fostering inclusive development worldwide.",.csv
Global Electricity Demand and Generation Dataset,1,global-electricity-demand-and-generation-dataset,Global Electricity Demand and Generation Dataset.csv,CC0-1.0,"The dataset contains information on electricity demand and generation across various countries over multiple years. It provides insights into the patterns and trends of electricity consumption and production on a global scale. This dataset can be utilized for studying energy usage, analyzing the effectiveness of renewable energy sources, and identifying areas for energy optimization and policy development.

**`Column Description:`**

`Country Name:` The name of the country where the electricity demand and generation data were recorded.

`Year:` The year for which the electricity demand and generation data are reported.

`Electricity Demand (in units):` The amount of electricity consumed or demanded by the country in a specific year, measured in units (e.g., megawatt-hours or gigawatt-hours).

`Electricity Generation (in units):` The amount of electricity produced or generated within the country in a specific year, measured in units (e.g., megawatt-hours or gigawatt-hours).



Each row in the dataset represents a unique combination of country name and year, with corresponding values for electricity demand and generation. This dataset enables analysis and comparison of electricity usage and production trends across different countries and time periods.",.csv
Global Electricity Statistics (1980-2021),1,global-electricity-statistics,Global Electricity Statistics.csv,Attribution 4.0 International (CC BY 4.0),"<br>
This dataset contains the **Yearly** data from **1980 to 2021** on world electricity statistics. The dataset has total of **4 features** and details of each feature is given below (All the information is in the **billion kWh** and **million kW**).

If you liked the data or find it interesting, a vote will be really helpful ❤️

- My other data-card on [Global Energy Statistics](https://www.kaggle.com/datasets/akhiljethwa/world-energy-statistics)
- Starter Notebook [Here](https://www.kaggle.com/code/akhiljethwa/starter-notebook-global-electricity-statistics)

<hr>

# Main Features:
&gt; -  **Country**: Name of the Country
&gt; -  **Region**: Region of the Country
&gt; -  **Electricity Transaction**: Different 7 types of transactions/activity, details of which is given below. 
&gt; -  **Years**: Total 41 columns from year 1980 to 2021. 

# Electricity Activities/Transactions:
&gt; -  **Net Generation (billion kWh)**: Electricity generation/production 
&gt; -  **Net Consumption (billion kWh)**: Electricity consumption
&gt; -  **Imports (billion kWh)**: Electricity imports 
&gt; -  **Exports (billion kWh)**: Electricity exports
&gt; -  **Net Imports (billion kWh)**: Electricity net imports
&gt; -  **Installed Capacity (million kW)**: The maximum amount of electricity that a generating station (also known as a power plant) can produce under specific conditions designated by the manufacturer 
&gt; -  **Distribution Losses (billion kWh)**: Transmission and distribution losses refer to the losses that occur in transmission of electricity between the sources of supply and points of distribution. 

# Potential Use cases:
&gt; -  **Time series analysis**: Time series analysis to find the different patterns in electricity production, consumption, imports, exports and etc.
&gt; -  **Time series forecasting**: Time series forecasting to predict the electricity production and consumption in future.
&gt; -  **Capacity**: Find the current statistics of capacity of power plants and forecast the future values.
&gt; -  **Reduce Electricity Losses**: Analyzing patterns of distribution losses and finding methods to reduce that.

# Important Note:
&gt;- Dataset contains null values too and it might be possible that all the value will be in object datatype so you may need to convert it into int or float first :)

Cover Image from: https://cosmosmagazine.com/earth/how-old-is-the-earth/",.csv
Global Emissions.,1,global-methane-emissions,Methane_final.csv,CC0-1.0,"## Context
Methane is responsible for around 30% of the rise in global temperatures since the Industrial Revolution, and rapid and sustained reductions in methane emissions are key to limiting near-term global warming and improving air quality. The energy sector – including oil, natural gas, coal and bioenergy – accounts for nearly 40% of methane emissions from human activity.
 
## Content
The following dataset has information about methane gas emissions globally. Details about the columns are as follows:
1. region - 
2. country - Country of Emission.
3. emissions - Methane Emissions in kt.
4. type - Sector from which emissions occur.
5.  Segment- Sub-sector from which emissions occur.
6. reason - The reason for the emission.
7. baseYear - Base year for the tracking of emissions.
8. notes - The source of data",.csv
Global Hunger Index 2022 Trends,1,global-hunger-index-2022-trends,Dataset.csv,ODbL-1.0,"This year’s Global Hunger Index (GHI) brings us face to face with a grim reality. The toxic cocktail of conflict, climate change, and the COVID-19 pandemic had already left millions exposed to food price shocks and vulnerable to further crises. Now the war in Ukraine, with its knock-on effects on global supplies of and prices for food, fertilizer, and fuel is turning a crisis into a catastrophe. 
The 2022 global GHI score shows that progress in tackling hunger has largely halted. Other indicators reveal the tragic scale of the unfolding crisis. The State of Food Security and Nutrition in the World 2022 reported that in 2021 the number of undernourished people, an indicator of chronic hunger, rose to as many as 828 million. Further, according to the Global Report on Food Crises 2022, the number of people facing acute hunger also rose from 2020, reaching nearly 193 million in 2021. These impacts are now playing out across Africa South of the Sahara, South Asia, Central and South America, and beyond. 
As we face the third global food price crisis in 15 years, it is clearer than ever that our food systems in their current form are inadequate to the task of sustainably ending poverty and hunger. The global food crisis underway now is widely presented as an aftershock caused by the war in Ukraine. The severity and speed of the impacts on hunger have occurred largely, however, because millions of people were already living on the precarious edge of hunger, a legacy of past failures to build more just, sustainable, and resilient food systems. 
While it is urgent that the international community respond to these escalating humanitarian crises, it must not lose sight of the need for a long-term transformation of food systems. The shocks we have experienced reveal chronic vulnerabilities that will continue to put millions at risk of hunger. Past and current GHI reports highlight these persistent vulnerabilities and shows what actions can address immediate humanitarian needs and kick-start food system transformation. Rather than operating reactively, the international community must take proactive steps to actually make good on its international commitments and pledges, scaling them up and directing them toward emergency measures. Political attention and funding must be targeted toward evidence-based policies and investments that address structural obstacles to food and nutrition security. More high-quality and timely data are also needed so that we can monitor progress in these areas. 
This year’s GHI report considers one important avenue for food systems transformation: community action that engages local leaders and citizens in improving governance and accountability. The essay by Danielle Resnick provides promising examples from a variety of settings where citizens are finding innovative ways to amplify their voices in food system debates, including by tracking government performance and by engaging in multistakeholder platforms, and keeping decision-makers accountable for addressing food and nutrition insecurity and hunger. Encouragingly, examples of empowerment are just as visible in fragile contexts with high levels of societal fractionalization as they are in more stable settings with longer traditions of local democracy. 
It is critical to act now to rebuild food security on a new and lasting basis. Failure to do so means sleepwalking into the catastrophic and systematic food crises of the future. Much more can be done to ward off the worst impacts of the current crisis and set deep changes in motion rather than reinforcing the dangerous and unsustainable arrangements we now live with. We must ensure rights-based food systems governance at all levels, building on the initial steps taken at the 2021 United Nations Food Systems Summit. Governments and development partners must harness local voices, match local governance efforts to conditions and capacities on the ground, and support local leadership through capacity building and funding. Governments must enable citizens to participate fully in developing and monitoring public policies affecting food security while upholding a legal right to food. 
Prevention pays off. Investments made today can avert future crises that may be even more costly and tragic than what we now face. It has been said that the saddest words are “If only.” We may find ourselves saying, “If only past generations had used their time and resources to do what was needed to end hunger and ensure the right to food for all.” May the next generation not say the same of us.",.csv
Global Inflation Dataset,1,global-inflation-data,global_inflation_data.csv,other,"### Context
Understanding global economic dynamics, specifically the trends in inflation rates, is paramount for policymakers, economists, and researchers. This dataset, covering the years 1980 to 2024, offers a comprehensive perspective on inflation across various countries. The primary focus is on dissecting the data based on country-specific indicators, providing valuable insights into the multifaceted factors influencing economic environments on a global scale.

### Content
The dataset comprises crucial columns including country name, indicator type, and annual average inflation rates from 1980 to 2024. This extensive collection of information facilitates detailed analysis and correlation studies, enabling researchers to uncover patterns and trends. By examining the nuanced relationships between country-specific indicators and inflation rates, valuable conclusions can be drawn about the complexities of global economic dynamics over the years. This dataset serves as a valuable resource for anyone seeking to delve into the intricacies of inflation trends and their implications across diverse nations.

### Dataset Structure:
This dataset (`global_inflation_data.csv`) covering from 1980 to 2024 consists of the following columns:

| Column Name  | Description                                   |
| -------------- | --------------------------------------------- |
| `country_name`   | Name of the Country                            |
| `indicator_name` | Type of Inflation Indicator                |
| `1980`           | Annual Average Inflation Rate in 1980 (in %)    |
| `1981`            | Annual Average Inflation Rate in 1981 (in %)     |
| `1982`           | Annual Average Inflation Rate in 1982 (in %)    |
|  ' ' ' |    ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' |
| `2022`           | Annual Average Inflation Rate in 2022 (in %)   |
| `2023`           | Annual Average Inflation Rate in 2023 (in %)   |
| `2024`           | Annual Average Inflation Rate in 2024 (in %)   |


### Acknowledgment
The primary dataset was retrieved from the [World Bank](https://data.worldbank.org). I sincerely thank the team for providing the core data used in this dataset.

© Image credit: [Freepik](https://www.freepik.com/free-photo/hand-holding-growth-arrow-with-coins_11383316.htm)",.csv
Global Missing Migrants Dataset,1,global-missing-migrants-dataset,Global Missing Migrants Dataset.csv,Attribution 4.0 International (CC BY 4.0),"# Description

&gt; This dataset provides a comprehensive **record of missing migrants and their tragic journeys towards international destinations** , collected by the Missing Migrants Project, an initiative implemented by the International Organization for Migration (IOM) since 2014. The dataset documents deaths and disappearances, shedding light on the challenges migrants face during their journeys. Please note that due to the complexities of data collection, the figures presented are likely an undercount. The dataset serves as a tribute to the individuals who lost their lives, as well as the families and communities impacted by their absence.

# Key Features:

&gt;- **Incident Type**: *Type of migration incident*
- **Incident Year**: *Year when the incident occurred*
- **Reported Month**: *Month when the incident was reported*
- **Region of Origin**: *Geographical region where the migrants originated*
- **Region of Incident**: *Geographical region where the incident occurred*
- **Country of Origin**: *Country from which the migrants originated*
- **Number of Dead**: *Number of confirmed deceased migrants*
- **Minimum Estimated Number of Missing**: *Minimum estimated count of missing migrants*
- **Total Number of Dead and Missing**: *Total count of both deceased and missing migrants*
- **Number of Survivors**: *Number of migrants who survived the incident*
- **Number of Females**: *Number of female migrants involved*
- **Number of Males**: *Number of male migrants involved*
- **Number of Children**: *Number of children migrants involved*
- **Cause of Death**: *Cause of death for the migrants*
- **Migration Route**: *Route taken by migrants during their journey (if available)*
- **Location of Death**: *Approximate location where the incident occurred*
- **Information Source**: *Source of information about the incident*
- **Coordinates**: *Geographical coordinates of the incident location*
- **UNSD Geographical Grouping**: *Geographical grouping according to the United Nations Statistics Division*

# Potential Use Cases:

&gt;- **Migration Patterns Analysis:** Explore trends and patterns in migration incidents to understand the most affected regions and routes.
- **Gender and Age Analysis:** Investigate the demographics of migrants to identify gender and age-related vulnerabilities.
- **Survival and Mortality Analysis:** Analyze survival rates and causes of death to highlight risks and challenges migrants face.
- **Temporal Analysis:** Examine incidents over time to identify any temporal patterns or changes.
- **Geospatial Analysis:** Utilize geographical coordinates to map migration routes and incident locations.


If you find this dataset valuable, your support through votes is highly appreciated! ❤️
Thank you 🙂
",.csv
Global Organizations Ranked by Workforce Size,1,top-companies-with-number-of-employees,Top Companies  with number of employees.csv,Apache 2.0,"
**Introduction of Dataset:**
In this dataset, I have gathered data on the top global companies by the number of employees they have. The dataset consists of 6 columns:

1.Rank: This column indicates the rank of the company.
2. Company: Here, I have provided the name of the company.
3. Stock Symbol: This column contains the stock symbol of each company.
4. Number of Employees: Here, I have provided the number of employees for each company.
5. Share Price: This column includes the share price of each company.
6. Company Origin: In this column, I have provided the name of the country where the company is based.


**Use Cases:**
 Here are some potential use cases for the dataset on top global companies by the number of employees:

**Market Analysis:**
Analysts can use this dataset to study trends in the number of employees across different industries and countries. This can provide insights into economic growth, industry competitiveness, and labor market dynamics.

**Investment Decision Making:** 
Investors can use the data to compare companies based on their number of employees, share price, and other factors. This can help them make informed decisions about which companies to invest in based on their growth potential and market position.

**HR Benchmarking:**
Human resources departments can benchmark their company's employee count against those of top global companies to assess their competitiveness in the job market and identify areas for improvement in recruitment and retention strategies.

**Country Comparison:**
Researchers and policymakers can use the dataset to compare the size and composition of the workforce across different countries, helping them understand global labor market dynamics and identify potential areas for policy intervention.

**Supply Chain Management:** 
Companies can use the dataset to evaluate the size and capabilities of potential partners or suppliers based on their workforce size and geographic location.

**Competitive Analysis:** 
Businesses can use the data to benchmark themselves against their competitors in terms of employee count, market presence, and other metrics to identify opportunities for growth and areas where they may need to improve their competitive position.

**Predictive Modeling:** 
Data scientists can use the dataset to build predictive models that forecast future employment trends within specific industries or regions, helping businesses and policymakers anticipate changes in labor market dynamics and adjust their strategies accordingly.

**Academic Research:** 
Researchers in economics, sociology, and other fields can use the dataset to study various aspects of corporate behavior, labor markets, and globalization.",.csv
Global Power-Plants,1,global-powerplants,powerplants (global) - global_power_plants.csv,CC0-1.0,"
<img src=""https://media.istockphoto.com/photos/thermal-power-station-picture-id1298098268?b=1&k=20&m=1298098268&s=170667a&w=0&h=6fjfHYlSeQSYXJ3cVb-AUdcMkyyU2z6RX_wGTu_RJg4="">



A power station, also referred to as a power plant and sometimes generating station or generating plant, is an industrial facility for the generation of electric power. Power stations are generally connected to an electrical grid.

Many power stations contain one or more generators, a rotating machine that converts mechanical power into three-phase electric power. The relative motion between a magnetic field and a conductor creates an electric current.

The energy source harnessed to turn the generator varies widely. Most power stations in the world burn fossil fuels such as coal, oil, and natural gas to generate electricity. Clean energy sources include nuclear power, and increasing use of renewables such as solar, wind, wave, geothermal, and hydroelectric.",.csv
Global Religious Demographics,1,global-religious-demographics,ThrowbackDataThursday 201912 - Religion.csv,other,"_____
# Global Religious Demographics
### Global religious demographics over time
By Throwback Thursday [[source]](https://data.world/throwback-thurs)
_____

### About this dataset
> 
> The dataset contains information on a wide range of religions, including Christianity, Judaism, Islam, Buddhism, Hinduism, Sikhism, Shintoism, Baha'i Faith, Taoism, Confucianism, Jainism, Zoroastrianism, Syncretic Religions (religious practices that blend elements from multiple faiths), Animism (belief in spiritual beings in nature), Non-Religious individuals or those without any religious affiliation. 
> 
> For each religion and region/country combination recorded in the dataset we have the following information:
> 
> - Total population: The total population of the region or country.
> - Religious affiliation percentages: The percentages of the population that identify with specific religious affiliations.
> - Subgroup populations/percentages: The populations or percentages within specific denominations or sects of each religion.
>   
> The dataset also provides additional variables like Year and State Name (for regional data) for further analysis.
> 

### How to use the dataset
> 
> 
> - **Understanding the Columns**
> 
>    The dataset contains several columns with different categories of information. Here's a brief explanation of some important columns:
> 
>    - Year: The year in which the data was recorded.
>    - Total Population: The total population of a country or region.
>    - State Name (StateNme): The name of the state or region.
>    
>    Each religion has specific columns associated with it, such as Christianity, Buddhism, Islam, Hinduism, Judaism, Taoism, Shintoism etc., representing its percentage and population for each category/denomination within that religion.
> 
> - **Selecting Specific Data**
> 
>    If you are interested in exploring data related to a particular religion or geographic location:
>    
>    - To filter data by Religion: Identify relevant columns associated with that religion such as 'Christianity', 'Buddhism', 'Islam', etc., and extract their respective percentage and population values for analysis.
>    
>      Example: If you want to analyze Christianity specifically, extract columns related to Christianity like 'Christianity (Percent)', 'Christianity (Population)', etc.
> 
>      Note: There might be multiple columns related to a specific religion indicating different categories or denominations within that religion.
>      
>    
>   - To filter data by Geographic Location: Utilize the 'State Name' column ('StateNme') to segregate data corresponding to different states/regions.
> 
>       Example: If you want to analyze religious demographics for a particular state/region like California or India:
> 
>       i) Filter out rows where State Name is equal to California or India.
>       
>       ii) Extract relevant columns associated with your selected religion as mentioned above.
>      
>         
> - **Finding Trends and Insights**
> 
>    Once you have selected the specific data you are interested in, examine patterns and trends over time or across different regions.
> 
>    - Plotting data using visualizations: Use graphical tools such as line charts, bar charts, or pie charts to visualize how religious demographics have changed over the years or vary across different regions.
> 
>    - Analyzing population proportions: By comparing the percentage values of different religions for a given region or over time, you can gather insights into changes in religious diversity.
> 
> - **Comparing Religions**
> 
>    If you wish to compare multiple religions:

### Research Ideas
> - Comparing religious affiliations across different countries or regions: With data on various religions such as Christianity, Islam, Buddhism, Judaism, Hinduism, etc., researchers can compare the religious affiliations of different countries or regions. This can help in understanding the cultural and religious diversity within different parts of the world.
> - Exploring the growth or decline of specific religions: By examining population numbers for specific religions such as Jainism, Taoism, Zoroastrianism, etc., this dataset can be used to investigate the growth or decline of these religious groups over time. Researchers can analyze factors contributing to their popularity or decline in particular regions or countries

### Acknowledgements
> If you use this dataset in your research, please credit the original authors.
> [Data Source](https://data.world/throwback-thurs)
> 
>


### License
> 
> 
> See the dataset description for more information.

### Columns

**File: ThrowbackDataThursday 201912 - Religion.csv**
| Column name                                      | Description                                                                                                                                     |
|:-------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------------------------|
| **Year**                                         | The year in which the data was recorded. (Numeric)                                                                                              |
| **Christianity - Protestants (Population)**      | The population of individuals who identify as Protestants within the Christian religion. (Numeric)                                              |
| **Christianity **                                | The                                                                                                                                             |
| **Christianity - Roman Catholics (Population)**  | The population of individuals who identify as Roman Catholics within the Christian religion. (Numeric)                                          |
| **Christianity - Eastern Orthodox (Population)** | The population of individuals who identify as Eastern Orthodox within the Christian religion. (Numeric)                                         |
| **Christianity - Anglican (Population)**         | The population of individuals who identify as Anglican within the Christian religion. (Numeric)                                                 |
| **Christianity - Others (Population)**           | The population of individuals who identify as Christians but do not fall into any specific Christian denomination mentioned above. (Numeric)    |
| **Christianity - Total (Population)**            | The total population of individuals who identify as Christians, regardless of denomination. (Numeric)                                           |
| **Judaism - Orthodox (Population)**              | The population of individuals who identify as Orthodox Jews. (Numeric)                                                                          |
| **Judaism **                                     | The total population of individuals who identify as Jews, regardless of denomination. (Numeric)                                                 |
| **Judaism - Conservatives (Population)**         | The population of individuals who identify as Conservative Jews. (Numeric)                                                                      |
| **Judaism - Reform (Population)**                | The population of individuals who identify as Reform Jews. (Numeric)                                                                            |
| **Judaism - Others (Population)**                | The population of individuals who identify as Jews but do not fall into any specific Jewish denomination mentioned above. (Numeric)             |
| **Judaism - Total (Population)**                 | The total population of individuals who identify as Jews, regardless of denomination. (Numeric)                                                 |
| **Islam - Sunni (Population)**                   | The population of individuals who identify as Sunni Muslims. (Numeric)                                                                          |
| **Islam **                                       | The population of individuals who identify as Muslims but do not fall into any specific Muslim denomination mentioned above. (Numeric)          |
| **Islam - Shi'a (Population)**                   | The population of individuals who identify as Shi'a Muslims. (Numeric)                                                                          |
| **Islam - Ibadhi (Population)**                  | The population of individuals who identify as Ibadhi Muslims. (Numeric)                                                                         |
| **Islam - Nation of Islam (Population)**         | The population of individuals who identify as Nation of Islam Muslims. (Numeric)                                                                |
| **Islam - Alawite (Population)**                 | The population of individuals who identify as Alawite Muslims. (Numeric)                                                                        |
| **Islam - Ahmadiyya (Population)**               | The population of individuals who identify as Ahmadiyya Muslims. (Numeric)                                                                      |
| **Islam - Others (Population)**                  | The population of individuals who identify as Muslims but do not fall into any specific Muslim denomination mentioned above. (Numeric)          |
| **Buddhism - Mahayana (Population)**             | The population of individuals who identify as Mahayana Buddhists. (Numeric)                                                                     |
| **Buddhism **                                    | The total population of individuals who identify as Buddhists, regardless of denomination. (Numeric)                                            |
| **Buddhism - Theravada (Population)**            | The population of individuals who identify as Theravada Buddhists. (Numeric)                                                                    |
| **Buddhism - Others (Population)**               | The population of individuals who identify as Buddhists but do not fall into the Mahayana or Theravada denominations mentioned above. (Numeric) |
| **Buddhism - Total (Population)**                | The total population of individuals who identify as Buddhists, regardless of denomination. (Numeric)                                            |
| **Zoroastrian - Total (Population)**             | The total population of individuals who identify as Zoroastrians. (Numeric)                                                                     |
| **Zoroastrian **                                 | The total population of individuals who identify as Zoroastrians. (Numeric)                                                                     |
| **Hindu - Total (Population)**                   | The total population of individuals who identify as Hindus. (Numeric)                                                                           |
| **Hindu **                                       | The total population of individuals who identify as Hindus. (Numeric)                                                                           |
| **Sike - Total (Population)**                    | The total population of individuals who identify as Sikhs. (Numeric)                                                                            |
| **Sike **                                        | The total population of individuals who identify as Sikhs. (Numeric)                                                                            |
| **Shinto - Total (Population)**                  | The total population of individuals who identify as Shintoists. (Numeric)                                                                       |
| **Shinto **                                      | The total population of individuals who identify as Shintoists. (Numeric)                                                                       |
| **Baha'i - Total (Population)**                  | The total population of individuals who identify as Baha'is. (Numeric)                                                                          |
| **Baha'i **                                      | The total population of individuals who identify as Baha'is. (Numeric)                                                                          |
| **Taoism - Total (Population)**                  | The total population of individuals who identify as Taoists. (Numeric)                                                                          |
| **Taoism **                                      | The total population of individuals who identify as Taoists. (Numeric)                                                                          |
| **Confucianism - Total (Population)**            | The total population of individuals who identify as Confucianists. (Numeric)                                                                    |
| **Confucianism **                                | The total population of individuals who identify as Confucianists. (Numeric)                                                                    |
| **Jain - Total (Population)**                    | The total population of individuals who identify as Jains. (Numeric)                                                                            |
| **Jain **                                        | The total population of individuals who identify as Jains. (Numeric)                                                                            |
| **Syncretic Religions - Total (Population)**     | The total population of individuals who identify with syncretic religions. (Numeric)                                                            |
| **Syncretic Religions **                         | The total population of individuals who identify with syncretic religions. (Numeric)                                                            |
| **Animist - Total (Population)**                 | The total population of individuals who identify as Animists. (Numeric)                                                                         |
| **Animist **                                     | The total population of individuals who identify as Animists. (Numeric)                                                                         |
| **Non Religious - Total (Population)**           | The total population of individuals who identify as non-religious or have no religious affiliation. (Numeric)                                   |
| **Non Religious **                               | The total population of individuals who identify as non-religious or have no religious affiliation. (Numeric)                                   |
| **Other Religions - Total (Population)**         | The total population of individuals who identify with other religions not previously mentioned. (Numeric)                                       |
| **Other Religions **                             | The total population of individuals who identify with other religions not previously mentioned. (Numeric)                                       |
| **Total Religious - Total (Population)**         | The total population of individuals who identify with any religious affiliation, regardless of denomination. (Numeric)                          |
| **Total Religious **                             | The total population of individuals who identify with any religious affiliation, regardless of denomination. (Numeric)                          |
| **Population - Total (Population)**              | The total population of the region or country. (Numeric)                                                                                        |
| **Population **                                  | The total population of the region or country. (Numeric)                                                                                        |
| **Christianity - Protestants (Percent)**         | The                                                                                                                                             |

### Acknowledgements
> If you use this dataset in your research, please credit the original authors.
> If you use this dataset in your research, please credit [Throwback Thursday](https://data.world/throwback-thurs).

",.csv
Global Rice Production Statistics Dataset,1,global-rice-production-statistics-dataset,rice_production_by_country.csv,CC0-1.0,"The ""Global Rice Production Statistics Dataset"" presents detailed information on rice production in different countries, including annual production amounts, acreage used for cultivation, yield per hectare, and rice consumption per person. This dataset highlights the importance of rice farming worldwide, illustrating its role in supporting local economies and ensuring food security on a global scale.


**`Column Descriptions:`**

**Country:** The name of the country contributing to global rice production.

**Rice Production (Tons):** The total annual rice production in tons by each country, reflecting their contribution to the global rice supply.

**Rank of Rice Production:** The ranking of the country based on its annual rice production volume compared to other rice-producing nations.

**Rice Production Per Person (Kg):** The amount of rice produced per person in kilograms annually, indicating the consumption and availability of rice on a per capita basis.

**Rank of Rice Production Per Person:** The ranking of the country based on rice production per person, providing insights into consumption patterns and availability.

**Rice Acreage (Hectare):** The total land area in hectares dedicated to rice cultivation in each country, showcasing the extent of rice farming practices.

**Rank of Rice Acreage:** The ranking of the country based on the acreage dedicated to rice cultivation, highlighting the scale of rice farming operations.

**Rice Yield (Kg / Hectare):** The average rice yield in kilograms per hectare of land, indicating the productivity and efficiency of rice production practices.

**Rank of Rice Yield:** The ranking of the country based on rice yield per hectare, showcasing the effectiveness of agricultural practices in maximizing rice output.

This dataset aims to provide a comprehensive overview of global rice production statistics, emphasizing the diversity in production levels, agricultural practices, and consumption patterns across different countries.",.csv
"Global Salaries in AI, ML, Data Science",1,global-salaries-in-ai-ml-data-science,salaries.csv,CC0-1.0,"This is the original + updated full dataset of AI/ML and Data Science salaries from the ai-jobs.net salary survey.

You can download an updated version of it or see a detailed description of the contents via: https://ai-jobs.net/salaries/download/

Or submit your own salary if you work in this space to add to the dataset (much appreciated!): https://ai-jobs.net/salaries/form/
",.csv
Global Superstore Dataset,1,global-superstore-dataset,superstore.csv,Community Data License Agreement - Sharing - Version 1.0,"# Columns Description for this Global Superstore Dataset

| Variable Name | Variable Description |
| --- | --- |
| Category | Category of the product ordered |
| City | City of residence of the Customer |
| Country | Country of residence of the Customer |
| Customer ID | Unique ID to identify each Customer |
| Customer Name | Name of the Customer |
| Discount | Discount provided |
| Order Date | Order Date of the product |
| Order ID | Unique Order ID for each Customer |
| Postal Code | Postal Code of every Customer |
| Product ID | Unique ID of the Product |
| Product Name | Name of the Product |
| Profit | Profit/Loss incurred |
| Quantity  | Quantity of the Product |
| Region | Region where the Customer belong |
| Row ID | Unique ID for each row |
| Sales | Sales of the Product |
| Segment | The segment where the Customer belongs |
| Ship Date | Shipping Date of the Product |

",.csv
Global Top Index: Exploring Trends in Stock Market,1,global-top-index-exploring-trends-in-stock-market,Stock_Market_Indexes.csv,Apache 2.0,"This dataset provides a comprehensive view of daily trading data for some of the world's top stock market indices. It includes information such as opening, highest, lowest, and closing prices, adjusted closing prices, as well as trading volume for each index. The data spans multiple dates, allowing for temporal analysis and pattern recognition across different indices.

**Column Details:**

**Date:** The date of the trading session.

**Name:** The name of the stock market index.

**Symbol:** The symbol or abbreviation representing the index.

**Open:** The opening price of the index for the trading session.

**High:** The highest price reached by the index during the trading session.

**Low:** The lowest price reached by the index during the trading session.

**Close:** The closing price of the index for the trading session.

**Adj Close:** The adjusted closing price, accounting for any corporate actions such as dividends or stock splits.

**Volume:** The total volume of shares traded for the index during the trading session.",.csv
Global Trends in Mental Health Disorder,1,uncover-global-trends-in-mental-health-disorder,Mental health Depression disorder Data.csv,other,"_____
# Global Trends in Mental Health Disorder
### From Schizophrenia to Depression
By Amit [[source]](https://data.world/amitd)
_____

### About this dataset
&gt; This dataset contains informative data from countries across the globe about the prevalence of mental health disorders including schizophrenia, bipolar disorder, eating disorders, anxiety disorders, drug use disorders, depression and alcohol use disorders. By providing this data in an easy to visualise format you can gain an insight into how these issues are impacting lives; allowing for a deeper understanding of these conditions and the implications. Through this reflection you may be able to answer some important questions: 
&gt; - What are the types of mental health disorder that people around the world suffer? 
&gt; - How many people in each country suffer mental health problems? 
&gt; - Are men or women more likely to have depression? 
&gt; - Is depression linked with suicide and what is the percentage rate? 
&gt; - In which age groups is depression more common?  
&gt; From exploring patterns between prevalence rates through in-depth data visualisation you’ll be able to further understand these complex issues. The knowledge gained from this dataset can help bring valuable decision making skills such as research grants, policy making or preventative intervention plans across various countries. So if you wish to create meaningful data viz then start with this global prevalence of mental health disorder’s together with accompanying videos for extra context - Deepen your understanding about Mental Health Disorders today!

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; 
&gt; Using this dataset is quite straightforward. Each row of the table contains information about a certain country or region for a certain year. The following columns are provided: Entity (the country or region name), Code (the code for the country or region), Year (the year the data was collected) Schizophrenia (% - percentage of people with schizophrenia), Bipolar Disorder (%) - percentage of people with bipolar disorder) Eating Disorders (%) - Percentage of individuals with disordered eating patterns Anxiety Disorders (%) - Percentage of individuals with anxiety Drug Use Disorders (%) - Percentage figures for those struggling with substance abuse Depression (%) – Percentages relating to those struggling with depressive illness Alcohol Use Disorders (%) – Percentages relating to those battling alcoholism 
&gt;   
&gt; Using this dataset requires no special skills; however it is best suited for those comfortable navigating spreadsheets and tables as well as analyzing numerical information quickly and accurately. Many software suites like excel are useful here but simple internet searches will reveal free alternatives if your preference is web-based solutions!  
&gt; 
&gt; By piecing together these different columns’ values we can get an idea if prevalence rates across different types of mental illnesses increase or decrease over time. For example we could compare depression levels between 2015 and 2018 by creating two separate sets containing information filtered just within our parameters respectively only reading records from 2015 then 2018). From here we can see whether numbers changed very much or stayed stagnant supefying any sort of patterns that could exist

### Research Ideas
&gt; - Visualizing the prevalence of mental health disorders - Create a data visualization that compares and contrasts the prevalence of depression, anxiety, bipolar disorder, schizophrenia, eating disorders, alcohol use disorder and drug use disorder across different countries. This could provide insight into global differences in mental health and potential causes of those differences.
&gt; 
&gt; - Mapping depression rates - Create an interactive map that shows both regional and national variations in depression rates within a specific country or region. This would allow people to easily identify areas with higher or lower than average prevalence of depression which could help inform decision-makers when it comes to policy-making related to mental healthcare services provisioning. 
&gt; 
&gt; - Developing predictive models for mental health - Use the data from this dataset as part of a larger machine learning project to build predictive models for mental health across countries or regions based on various factors such as demographics, economic indicators etc., This can be helpful for researchers working on understanding populations’ susceptibility towards developing certain disorders so as to craft appropriate preventive strategies accordingly

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://data.world/amitd)
&gt;  

### License 
&gt; 
&gt; See the dataset description for more information.

### Columns

**File: Mental health Depression disorder Data.csv**
| Column name                   | Description                                                                                      |
|:------------------------------|:-------------------------------------------------------------------------------------------------|
| **Entity**                    | Unique identifier for each country or region included in the data set. (String)                  |
| **Code**                      | Unique code associated with an Entity/Country or region included in the data set. (String)       |
| **Year**                      | Year that the data about that particular Entity/Country was collected. (Integer)                 |
| **Schizophrenia (%)**         | Percentage of people with schizophrenia in that country/region during that year. (Float)         |
| **Bipolar disorder (%)**      | Percentage of people with bipolar disorder in that country/region during that year. (Float)      |
| **Eating disorders (%)**      | Percentage of people with eating disorders in that country/region during that year. (Float)      |
| **Anxiety disorders (%)**     | Percentage of people with anxiety disorders in that country/region during that year. (Float)     |
| **Drug use disorders (%)**    | Percentage of people with drug use disorders in that country/region during that year. (Float)    |
| **Depression (%)**            | Percentage of people with depression in that country/region during that year. (Float)            |
| **Alcohol use disorders (%)** | Percentage of people with alcohol use disorders in that country/region during that year. (Float) |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [Amit](https://data.world/amitd).

",.csv
Global Unemployment Data,1,global-unemployment-data,global_unemployment_data.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### Context
Understanding global unemployment trends is crucial for policymakers, economists, and researchers alike. This dataset, spanning from 2014 to 2024, provides a comprehensive view of unemployment across various demographic parameters. The key focus lies in dissecting the data based on country, age group, and gender, offering insights into the diverse factors influencing labor markets worldwide.

### Content
The dataset encompasses essential columns such as country name, indicator, sex, age group, and annual unemployment rates from 2014 to 2024. This rich collection of information allows for in-depth analysis and correlation studies. By examining the interplay between age, gender, and unemployment rates, researchers can draw valuable conclusions about the global workforce's dynamics.

### Dataset Structure:
This dataset (`global_unemployment_data.csv`) covering from 2014 to 2024 consists of the following columns:

| Column Name  | Description                                   |
| -------------- | --------------------------------------------- |
| `country_name`   | Name of the Country                            |
| `indicator_name` | Type of Unemployment Indicator                |
| `sex`            | Gender (Male/Female)                          |
| `age_group`      | Categorized Age Groups                        |
| `age_categories` | Specific Age Categories                       |
| `2014`           | Annual Unemployment Rate for the year 2014 (in %)    |
| `2015`           | Annual Unemployment Rate for the year 2015 (in %)    |
| `2016`           | Annual Unemployment Rate for the year 2016 (in %)    |
| `2017`           | Annual Unemployment Rate for the year 2017 (in %)    |
| `2018`           | Annual Unemployment Rate for the year 2018 (in %)    |
| `2019`           | Annual Unemployment Rate for the year 2019 (in %)    |
| `2020`           | Annual Unemployment Rate for the year 2020 (in %)    |
| `2021`           | Annual Unemployment Rate for the year 2021 (in %)    |
| `2022`           | Annual Unemployment Rate for the year 2022 (in %)    |
| `2023`           | Annual Unemployment Rate for the year 2023 (in %)    |
| `2024`           | Annual Unemployment Rate for the year 2024 (in %)    |


### Acknowledgment
The primary dataset was retrieved from the [International Labour Organization](https://www.ilo.org/global). I sincerely thank the team for providing the core data used in this dataset.

© Image credit: [Freepik](https://www.freepik.com/free-photo/word-recession-decreasing-coins_10810020.htm)",.csv
Global Video Game Sales,1,global-video-game-sales,vgsales.csv,CC0-1.0,"_____
# Global Video Game Sales
### Analyzing Platform-Genre Dynamics in the Top 100 Games
By  [[source]](https://zenodo.org/record/5898311#.Y9Y2K9JBwUE)
_____

### About this dataset
> This dataset, sourced from vgchartz.com, offers a wealth of insights into the dynamics between platform and genre for the top 100 video games worldwide. Observe which platforms are driving global sales, what genres have been most successful in different regions across the world, and how both of these factors have changed over time. Analyze this data to inform your understanding of the gaming industry and discover trends propelling game developers to success!

### More Datasets
> For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
> - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
> This dataset provides an excellent snapshot of the top 100-selling video games, along with their respective platforms, genres and publishers. By analyzing the data provided in this Kaggle dataset, it is possible to gain insights on the popularity of different gaming platforms and the most successful genres associated with those platforms. Additionally, one can also observe which publishers have achieved success in publications of multiple series or even single titles. 
> 
> In order to begin making use of this dataset effectively, start by looking through each column and determining how it might be contributing useful information. This dataset contains 11 columns: rank (ranked from 1-100), name (name of title), platform (platform game was released for), year (year game was released), genre (genre classification for title), publisher (publisher responsible for release), NA_sales & EU_sales & JP_sales & other_sales  (total fractions of sales worldwide by region) & global_sales(total fractional sales worldwide). These columns can be used to draw comparisons between various specific aspects or discover general trends about certain parts of the industry over a prolonged period of time. 
> 
> Those wanting to understand more specifically how certain releases have performed over time should consider using graphs/charts to depict their findings; as diagramatic visual representations always make understanding easier while also providing insight that wouldn’t have been visible through raw data alone. To further narrow down your focus on subsets within subsets, implement crosstabs! Keywords are also incredibly helpful when sifting through large amounts - search queries allow you to find further info based on detailed parameters while restriction allows fine tuning these queries into very specific datasets you need in order to answer any given question properly!

### Research Ideas
> - Probing the relationship between video game expenditure and user satisfaction to understand consumer behavior. 
> - Examining the most popular platform-genre combinations in the top 100 games to inform game development decisions. 

### Acknowledgements
> If you use this dataset in your research, please credit the original authors.
> [Data Source](https://zenodo.org/record/5898311#.Y9Y2K9JBwUE)
> 
>


### License
> 
> 
> **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
> No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: vgsales.csv**
| Column name      | Description                                          |
|:-----------------|:-----------------------------------------------------|
| **Rank**         | Ranking of the game based on global sales. (Integer) |
| **Name**         | Name of the game. (String)                           |
| **Platform**     | Platform the game was released on. (String)          |
| **Year**         | Year the game was released. (Integer)                |
| **Genre**        | Genre of the game. (String)                          |
| **Publisher**    | Publisher of the game. (String)                      |
| **NA_Sales**     | Sales of the game in North America. (Float)          |
| **EU_Sales**     | Sales of the game in Europe. (Float)                 |
| **JP_Sales**     | Sales of the game in Japan. (Float)                  |
| **Other_Sales**  | Sales of the game in other regions. (Float)          |
| **Global_Sales** | Total sales of the game worldwide. (Float)           |

### Acknowledgements
> If you use this dataset in your research, please credit the original authors.
> If you use this dataset in your research, please credit [](https://zenodo.org/record/5898311#.Y9Y2K9JBwUE).

",.csv
Global Video Game Sales and Reviews,1,global-video-game-sales-and-reviews,Video Games Sales.csv,other,"_____
# Global Video Game Sales and Reviews
### Global Video Game Performance: Sales, Reviews, and Rankings
By Andy Bramwell [[source]](https://data.world/bramwax)
_____

### About this dataset
> 
> The elements covered in this well-curated dataset include: The ranking of the game based on global sales under the column 'Rank'. This metric provides perspective on how popular or successful a particular game has been across countries in comparison to others during its time. Noting that video games' popularity could vary greatly from one geography to another due to factors like cultural nuances, gamer preferences, etc., regional sales have been marked separately for North America (North America), Europe (Europe), Japan (Japan) as well as for other parts of the World excluding these three regions under the column 'Rest of World'.
> 
> For easy identification among massive chunks of data, we've included each game's title (Game Title) along with additional categorization based on their genre (Genre). From action-packed adventures to strategic board-like scenarios or enchanted magic realms - classifications cover it all! In addition, detailed information about publishers can be found under 'Publisher', which grants insights about leading companies dominating market shares.
> 
> Further details expand into mentioning platforms such as PS4, Xbox, PC where these games can be played under 'Platform'. A unique attribute covered in this database is ‘Review’. Given that critique ratings play an influential role in engaging new players into trying out a particular video game or boosting existing user morale regarding their choice; this numeric representation ranging typically from 1-10 vividly captures public opinion about them.
> 
> Lastly, just for keeping tabs on ever-evolving gaming technology standards where newer versions often outshine predecessors irrespective of actual gameplay quality itself; having release years mentioned ('Year') proves beneficial for categorizing them chronologically. This helps correlate whether higher sales figures can sometimes merely be indicative of more people having access to necessary high-end gaming hardware during later periods.
> 
> In essence, this dataset titled ‘Video Games Sales.csv’ holds immense potential for informative deep-dives into the Video Game industry's trends and paradigms, forming a solid foundation for market research, academic purposes or personal projects

### How to use the dataset
> 
> This dataset provides extensive information about various video game titles, their sales performance across multiple regions, publisher details and game reviews. Follow the steps outlined below to make the most out of this remarkable dataset!
> 
> #### 1. Game Research & Evaluation:
> With columns such as 'Game Title', 'Genre' and 'Review', you can research on particular games or genres that interest you. You can evaluate a game based on its review scores, delving into what makes a top-rated game.
> 
> #### 2. Publisher Analysis:
> The 'Publisher' column lets you track which publishers are behind the most successful games in terms of sales and reviews. This analysis could be useful for people interested in business trends in gaming industry or trying to identify potential innovative publishers.
> 
> #### 3. Regional Market Trend Identification:
> You can use data from columns like ‘North America’, ‘Europe’, ‘Japan’ and ‘Rest of World’ to study regional market trends for certain genres or platforms; it might enable one to recognize patterns over time or cultural preferences with regard to video games.
> 
> #### 4. Global Sales Analysis: 
> Using the 'Global' column, you could observe which games have been globally successful, going beyond regional preferences by genre or platform.
> 
> #### 5. Platform Insight:
> The platform on which a particular game is available is another significant factor (e.g., PC, PS4, Xbox). By utilizing the data contained in this dataset regarding platforms, one may learn how platform choice impacts global sales as well as discern any correlation between preferred platform types among specific regions.
>    
> Remember that every statistical analysis begins with knowing your data - dive deep into each variable; explore patterns within variables before looking at correlations between different fields.
> 
> Don't forget - when engaged with comprehensive datasets like these - creativity is your only limit! Happy analyzing!

### Research Ideas
> - **Trend Analysis:** This dataset can be used to analyze the trends in video game preferences over the years based on genre, publisher, platform and region. It can provide interesting insights into how consumer tastes have evolved with time and which game genres are becoming more popular.
> - **Sales Forecasting:** Using historical sales data from different regions, we can build statistical models for predicting future sales of upcoming video games. This would be valuable for stakeholders in the production and distribution of video games such as developers, publishers and retailers.
> - **Game Evaluation & Strategy Planning:** By examining a correlation between review scores and global sales across various platforms or among particular genres, companies could identify which aspects are commended by gamers most often - thus pushing developers to focus more on them when planning new game titles. Also it could help strategists plan marketing campaigns targeted at specific regions where certain type of games tend to sell more.
>    
> - **Competition Analysis:** They potentially might use this data set to benchmark their performance against competitors by comparing factors such as review scores and total global sales.
> -  **Consumer Behaviour Insights**: The dataset can be used to understand gamer behaviour patterns across different geographies like North America, Europe, Japan etc., helping marketers carve effective regional promotional strategies or decide where to launch next.
>    
> This is indeed a powerful set of data that sheds light on many key aspects of the gaming industry!

### Acknowledgements
> If you use this dataset in your research, please credit the original authors.
> [Data Source](https://data.world/bramwax)
> 
>


### License
> 
> 
> See the dataset description for more information.

### Columns

**File: Video Games Sales.csv**
| Column name       | Description                                                                                                             |
|:------------------|:------------------------------------------------------------------------------------------------------------------------|
| **Rank**          | The rank of the video game based on global sales volume. (Numerical)                                                    |
| **Game Title**    | The name of the video game. (String)                                                                                    |
| **Platform**      | The platform on which the game is available, such as PC, PS4, Xbox One, etc. (Categorical)                              |
| **Year**          | The year in which the game was released. (Date)                                                                         |
| **Genre**         | The genre of the game, such as action, adventure, racing, etc. (Categorical)                                            |
| **Publisher**     | The company that published the game. (String)                                                                           |
| **North America** | The number of units sold in North America, in millions. (Numerical)                                                     |
| **Europe**        | The number of units sold in Europe, in millions. (Numerical)                                                            |
| **Japan**         | The number of units sold in Japan, in millions. (Numerical)                                                             |
| **Rest of World** | The number of units sold in the rest of the world, excluding North America, Europe, and Japan, in millions. (Numerical) |
| **Global**        | The total number of units sold worldwide, in millions. (Numerical)                                                      |
| **Review**        | The review score of the game, on a scale of 1 to 10. (Numerical)                                                        |

### Acknowledgements
> If you use this dataset in your research, please credit the original authors.
> If you use this dataset in your research, please credit [Andy Bramwell](https://data.world/bramwax).

",.csv
Global YouTube Statistics 2023,1,global-youtube-statistics-2023,Global YouTube Statistics.csv,other,"# Description

&gt; Welcome to the captivating realm of YouTube stardom, where this meticulously curated dataset unveils the statistics of the most subscribed YouTube channels. A collection of YouTube giants, this dataset offers a perfect avenue to analyze and gain valuable insights from the luminaries of the platform. With **comprehensive details on top creators'** subscriber counts, video views, upload frequency, country of origin, earnings, and more, this treasure trove of information is a must-explore for aspiring content creators, data enthusiasts, and anyone intrigued by the ever-evolving online content landscape. Immerse yourself in the world of YouTube success and unlock a wealth of knowledge with this extraordinary dataset.

**For more related datasets:** <br> [Global Missing Migrants Dataset( New )](https://www.kaggle.com/datasets/nelgiriyewithana/global-missing-migrants-dataset) 🛑<br>
 [Global Weather Repository ( Daily snapshot )
( New )](https://www.kaggle.com/datasets/nelgiriyewithana/global-weather-repository)🛑
<br> [Indian Weather Repository ( Daily snapshot ( New ) )
](https://www.kaggle.com/datasets/nelgiriyewithana/indian-weather-repository-daily-snapshot) 🛑

# Key Features

&gt;- **rank**: *Position of the YouTube channel based on the number of subscribers*
- **Youtuber**: *Name of the YouTube channel*
- **subscribers**: *Number of subscribers to the channel*
- **video views**: *Total views across all videos on the channel*
- **category**: *Category or niche of the channel*
- **Title**: *Title of the YouTube channel*
- **uploads**: *Total number of videos uploaded on the channel*
- **Country**: *Country where the YouTube channel originates*
- **Abbreviation**: *Abbreviation of the country*
- **channel_type**: *Type of the YouTube channel (e.g., individual, brand)*
- **video_views_rank**: *Ranking of the channel based on total video views*
- **country_rank**: *Ranking of the channel based on the number of subscribers within its country*
- **channel_type_rank**: *Ranking of the channel based on its type (individual or brand)*
- **video_views_for_the_last_30_days**: *Total video views in the last 30 days*
- **lowest_monthly_earnings**: *Lowest estimated monthly earnings from the channel*
- **highest_monthly_earnings**: *Highest estimated monthly earnings from the channel*
- **lowest_yearly_earnings**: *Lowest estimated yearly earnings from the channel*
- **highest_yearly_earnings**: *Highest estimated yearly earnings from the channel*
- **subscribers_for_last_30_days**: *Number of new subscribers gained in the last 30 days*
- **created_year**: *Year when the YouTube channel was created*
- **created_month**: *Month when the YouTube channel was created*
- **created_date**: *Exact date of the YouTube channel's creation*
- **Gross tertiary education enrollment (%)**: *Percentage of the population enrolled in tertiary education in the country*
- **Population**: *Total population of the country*
- **Unemployment rate**: *Unemployment rate in the country*
- **Urban_population**: *Percentage of the population living in urban areas*
- **Latitude**: *Latitude coordinate of the country's location*
- **Longitude**: *Longitude coordinate of the country's location*

# Potential Use Cases

&gt;- **YouTube Analytics:** Gain valuable insights into the success factors of top YouTube channels and understand what sets them apart from the rest.
- **Content Strategy:** Discover the most popular categories and upload frequencies that resonate with audiences.
- **Regional Influencers:** Identify influential YouTube creators from different countries and analyze their impact on a global scale.
- **Earnings Analysis:** Explore the correlation between channel performance and estimated earnings.
- **Geospatial Visualization:** Visualize the distribution of successful YouTube channels on a world map and uncover geographical trends.
- **Trending Topics:** Investigate how certain categories gain popularity over time and correlate with world events.

Data Source: The dataset was meticulously compiled from various reputable sources, ensuring accuracy and reliability of the information presented.

If you find this dataset helpful, your support through an upvote would be deeply appreciated ❤️",.csv
"Globalization,Mobility",1,globalizationmobility,International tourist arrivals new.csv,CC0-1.0,"this graphs was created in Power Bi and Ourdataworld:

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F3cb93732e29cb3fa6161579562437604%2Fgraph4.jpg?generation=1711224036901369&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F3776b4bbb13633309f543185297c4486%2Fgraph1.png?generation=1711224049018911&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fccc3a53982fd6e194e8cdeaee8d2698e%2Fgraph2.png?generation=1711224055825399&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F84ea8c79ced03d32d87bb65d81ef2483%2Fgraph3.png?generation=1711224065032888&alt=media)

Introduction:

Tourism stands as a cornerstone of modern globalization, fostering interconnectedness between nations, cultures, and people. In recent decades, propelled by advancements in aviation and technological innovations, tourism has experienced unprecedented growth, transcending borders and enriching both travelers and host communities. However, this surge in global travel brings forth a myriad of implications, ranging from economic prosperity to environmental challenges. This essay delves into the multifaceted nature of tourism, examining its profound impact on individuals, societies, and the planet.

The Evolution of Tourism:

The evolution of tourism mirrors the rapid pace of globalization, with aviation emerging as a pivotal force in transforming travel from a luxury to a ubiquitous phenomenon. Since the turn of the millennium, the number of international visits has soared, driven by increased affordability, improved infrastructure, and heightened accessibility. This exponential growth has not only fueled economic development but has also fostered cross-cultural exchange and mutual understanding.

Benefits for Travelers:

For travelers, embarking on journeys beyond their borders offers a gateway to experiential learning and cultural immersion. By engaging with diverse customs, traditions, and lifestyles, individuals gain invaluable insights into the complexities of our interconnected world. Travel becomes a catalyst for personal growth, fostering empathy, tolerance, and a broader worldview.

Economic Significance:

Beyond its cultural and social dimensions, tourism plays a pivotal role in shaping national economies, serving as a vital source of revenue and employment. In many countries, tourism ranks among the largest industries, generating income for millions of people and supporting local businesses. From bustling metropolises to remote villages, the influx of tourists stimulates economic growth, infrastructure development, and investment opportunities.

Challenges and Externalities:

However, the rapid expansion of tourism also presents a host of challenges and externalities. One of the most pressing concerns is its environmental footprint, as air travel contributes significantly to global carbon emissions and ecological degradation. Moreover, the commodification of natural landscapes and cultural heritage sites can lead to overdevelopment, habitat destruction, and the erosion of indigenous identities. Balancing the economic benefits of tourism with its environmental and social impacts remains a formidable task for policymakers and stakeholders alike.

Sustainable Tourism:

In response to these challenges, the concept of sustainable tourism has gained traction, emphasizing responsible travel practices that minimize negative impacts and maximize benefits for host communities. Sustainable tourism initiatives encompass a range of strategies, from promoting eco-friendly accommodations and transportation to supporting local conservation efforts and cultural preservation. By embracing principles of sustainability, destinations can safeguard their natural and cultural assets for future generations while fostering a more equitable and inclusive tourism industry.

Conclusion:

In conclusion, the phenomenon of tourism embodies the complexities of our interconnected world, weaving together threads of cultural exchange, economic opportunity, and environmental stewardship. While tourism has the power to enrich lives and foster mutual understanding, its unchecked growth can exact a toll on fragile ecosystems and cultural heritage. As we navigate the challenges of a post-pandemic world, it is imperative that we embrace sustainable practices and collective action to ensure that tourism continues to serve as a force for positive change. By striking a balance between economic prosperity and environmental preservation, we can cultivate a more resilient and inclusive tourism industry that benefits both present and future generations.",.csv
Go To College Dataset,1,go-to-college-dataset,data.csv,CC0-1.0,"This is a **synthetic data** created for a college project. This data aims to predict whether students will continue to go to college or not. With machine learning explainability, school counselors can help students that will not go to college by finding the factor and helping them. Lets build something really helpful. Here is my [recommendation notebook](https://www.kaggle.com/code/alrafikri/potential-to-go-to-college/notebook).

PS: Like I said before, this is synthetic data. If you have a resource to get real data, your contribution is welcome. Thank you.",.csv
Gold Forecasting with Linear Regression & ARIMA,1,gold-forecasting,GoldUP.csv,CC-BY-NC-SA-4.0,"This model will help us in knowing that how Crude oil price, interest rate (repo rate), Indian currency price in dollars, Sensex (BSE), Inflation rate and US Dollar index will follow a relationship with the gold price directly or indirectly. 

The regression analysis in which we use one dependent variable and multiple independent variables is called a multivariate regression analysis. The forecasting plays an important role in econometrics and also helps to determine government policies with optimality. The business decision which are dependent on the prices of such commodities can make benefits from a feasible prediction. We will have a brief view over the error mean square values of the regression model which will guide us about the predictive ability of the predictive model . The data is wide spread across the time and is available from dated 1st October 2000 to 1 August 2020.

A prediction model is developed for the gold price in India dependent on 5 variables using the statistical interpretations from these variables. The independent variables taken were crude oil prices, USD to INR, Sensex, CPI and Interest rate. The model passes different aspects such as adjusted R squared, T test and Durbin Watson with high favoring values.

 The model is passed as a perfect fit along with the residual analysis which depicts that the model is a good fit and acceptable. The data was taken for a long span of time period and there were no missing values which was favorable for the regression model. We could observe a strong relation between the gold price and USD to INR, CPI and Sensex values. In future, more variables can be a part of this model and the data can be for a longer time span leading to the other heights of optimality.

Forecast for the gold prices is created for the next 10 months ahead using ARIMA Model.",.csv
Gold Price Prediction Dataset,1,gold-price-prediction-dataset,FINAL_USO.csv,CC0-1.0,"### Context

Historically, gold had been used as a form of currency in various parts of the world including the USA. In present times, precious metals like gold are held with central banks of all countries to guarantee re-payment of foreign debts, and also to control inflation which results in reflecting the financial strength of the country. Recently, emerging world economies, such as China, Russia, and India have been big buyers of gold, whereas the USA, SoUSA, South Africa, and Australia are among the big seller of gold.

Forecasting rise and fall in the daily gold rates can help investors to decide when to buy (or sell) the commodity. But Gold prices are dependent on many factors such as prices of other precious metals, prices of crude oil, stock exchange performance, Bonds prices, currency exchange rates, etc.

The challenge of this project is to accurately predict the future adjusted closing price of Gold ETF across a given period of time in the future. The problem is a regression problem, because the output value which is the adjusted closing price in this project is continuous value.

### Content

Data for this study is collected from November 18th 2011 to January 1st 2019 from various sources. The data has 1718 rows in total and 80 columns in total. Data for attributes, such as Oil Price, Standard and Poor’s (S&P) 500 index, Dow Jones Index US Bond rates (10 years), Euro USD exchange rates, prices of precious metals Silver and Platinum and other metals such as Palladium and Rhodium, prices of US Dollar Index, Eldorado Gold Corporation and Gold Miners ETF were gathered.

The dataset has 1718 rows in total and 80 columns in total. Data for attributes, such as Oil Price, Standard and Poor’s (S&P) 500 index, Dow Jones Index US Bond rates (10 years), Euro USD exchange rates, prices of precious metals Silver and Platinum and other metals such as Palladium and Rhodium, prices of US Dollar Index, Eldorado Gold Corporation and Gold Miners ETF were gathered.

The historical data of Gold ETF fetched from Yahoo finance has 7 columns, Date, Open, High, Low, Close, Adjusted Close, and Volume, the difference between Adjusted Close and Close is that the closing price of a stock is the price of that stock at the close of the trading day. Whereas the adjusted closing price takes into account factors such as dividends, stock splits, and new stock offerings to determine a value. So, Adjusted Close is the outcome variable which is the value you have to predict.

![](https://i.ibb.co/C29bbXf/snapshot.png)

### Acknowledgements

The data is collected from Yahoo finance.


### Inspiration

Can you predict Gold prices accurately using traditional machine learning algorithms",.csv
Gold Rate History in TamilNadu (2006-2020),1,gold-rate-history-in-tamilnadu-india,gold_rate_history.csv,CC0-1.0,"### Context

As you all know that, as per the observation of economists, according to the current trend, it seems that the yellow metal is performing better as an investment option in comparison to mutual funds, equities, real estate, and fixed deposits. The weak global economic outlook for the entire year is might be the reason why gold prices are surging. The yellow metal is considered as a financial instrument that does not erode in valuation during periods of economic turbulence. Many global investors are looking for safer investment options including gold as fears over a recession continue to grow.

Therefore here, need to forecast the price of the Gold in the future based on trend or seasonality using historical data from ***Jan 2006 to Sep 2020***.  The historical data has from **Jan 2006 to Sep 2020.**

### Problem
***To Predict or forecast the gold price in the near future.*** Hence, it would help Indian people aware of when to buy gold for their investments.

### Data
The data contains the following fields,
- Date, 
- Country,
- State,
- City,
- Pure Gold (24 k), Priced indicated in INR
- Standard Gold (22 k), Priced indicated in INR

The dataset will be updated soon for other states as well in India.

### Acknowledgements

The dataset has scraped from www.livechennai.com. Gold Prices indicated in this data makes no guarantee or warranty on the accuracy or completeness of the data provided.
",.csv
Gold Stock Prices,1,gold-stock-prices,goldstock.csv,Apache 2.0,"This data set provides a comprehensive record of daily gold prices from January 19, 2014 to January 22, 2024. The data is provided by [Nasdaq ](https://www.nasdaq.com/) and includes key financial metrics for each trading day. . The dataset consists of the following columns:

- **Date:** A unique date for each trading day recorded.
- **Close**: The closing price of gold on the relevant date.
- **Volume**: Gold trading volume on the relevant date.
- **Open**: The opening price of gold on the relevant date.
- **High**: The highest recorded price of gold during the trading day.
- **Low**: The lowest price recorded for gold in the trading day.
This data set is valuable for researchers, analysts, and data enthusiasts who want to understand historical trends, patterns, and changes in gold prices over time. Analysts can use this database to perform a variety of analyses, including price forecasting, trend spotting, and market behavior studies.

__Possible conditions__:
- Time Series Analysis: Explore trends and patterns in gold prices over a given period.
- Advanced Modeling: Build models to predict future gold prices based on historical data.
- Trading Strategy Development: Develop and reverse trade strategies using the given price and volume information.
- Market Sentiment Analysis: Analyze the impact of market events on gold prices and assess market sentiment.
- Statistical Analysis: Perform tests and statistical analysis to gain insight into the characteristics of gold price movements.

__Description__:
Users are advised to verify the accuracy and reliability of the information and to be aware of the limitations and biases inherent in financial databases. In addition, it is important to consider external factors such as economic indicators, geopolitical events, and market sentiment when using databases for analysis and use.",.csv
GoldPrices1993to2024,1,goldprices1993to2024,GoldPrices1993to2024.csv,CC0-1.0,"Gold Price Dataset Overview
This dataset consists of historical gold price data, spanning from January 4, 1993, to March 27, 2024. It comprises a total of 7,967 entries, with each entry corresponding to the market behavior of gold on a specific date.

Column Descriptions
Date (Data): The date of the record. Each row corresponds to a single trading day for gold. The column is formatted as datetime64[ns], ensuring accurate time series analyses.
Last (Último): The last recorded trading price of gold for the day. This column is represented as a float64, indicating the final trading value at the close of the market.
Open (Abertura): The opening price of gold at the beginning of the trading day. This column is a float64, showing the price at which gold first traded upon the market opening.
High (Máxima): The highest price at which gold was traded during the trading day. This is captured as a float64, reflecting the peak value reached.
Low (Mínima): The lowest price of gold during the trading day. This value is also stored as a float64, representing the minimum price.
Volume (Vol.): The total volume of gold traded on that day. This column, a float64, may contain NaN values indicating days with no available volume data.
Change Percentage (Var%): The percentage change in the gold price compared to the previous trading day. This is a float64 that calculates the day-over-day percentage variation in price.
Additional Information
Missing Data: The Volume column has some missing entries (NaN), likely due to non-trading activities or data unavailability on certain days.
Memory Usage: The entire dataset occupies approximately 435.8 KB of memory.
This dataset is particularly valuable for conducting time series analysis, studying market trends in the gold sector, or developing financial models based on historical gold price movements and trading volumes.",.csv
"Golden Globe Awards, 1944 - 2020",1,golden-globe-awards,golden_globe_awards.csv,CC0-1.0,"[![forthebadge made-with-python](http://ForTheBadge.com/images/badges/made-with-python.svg)](https://www.python.org/) [![ForTheBadge built-with-love](http://ForTheBadge.com/images/badges/built-with-love.svg)](https://GitHub.com/unanimad/)

---

Please, If you enjoyed this dataset, don't forget to upvote it.

---

### About

[Golden Globe Awards](http://goldenglobes.com/), any of the awards presented annually by the Hollywood Foreign Press Association (HFPA) in recognition of outstanding achievement in motion pictures and television during the previous year. Within the entertainment industry, the Golden Globes are considered second in importance both to the Academy Awards (for film) and to the Emmy Awards (for television), and the televised awards ceremony is a comparably lavish affair.

### Method

The data were extracted from [Awards' list page](http://goldenglobes.com/).

### Inspiration

1. Which nominee has received the most awards overall or in a single year?
2. Which work has received the most awards in a event?
3. Which country received the most awards at a ceremony and overall?
4. Who has received the most awards in a event or overall?

",.csv
Good Reads Dataset (Top 1000 Books),1,good-reads-top-1000-books,good_reads_top_1000_books.csv,other,"This dataset is scraped from [Good Reads' official website](https://www.goodreads.com/list/show/6675.The_Guardian_s_1000_Novels_Everyone_Must_Read_). It may be used for regression, classification, clustering, designing recommendation systems, etc. It has 5 columns:

1. Book Name - This column holds the name of the book
2. Author - This column contains the Author of the book
3. Average Rating - This column specifies the average rating received by the book
4. Number of Ratings - This column provides the total number of ratings it has received
5. Score on Goodreads - This column specifies the score of the book on Goodreads

This dataset may be used for many techniques such as regression (for the target column of Goodreads score), Clustering of different Types of books based on their author, or designing a book recommendation model.

It is specifically created for beginners to hone their skills as a data scientist.

Happy Kaggling!",.csv
Goodreads-books,1,goodreadsbooks,books.csv,CC0-1.0,"### Context
The primary reason for creating this dataset is the requirement of a good clean dataset of books. Being a bookie myself (see what I did there?) I had searched for datasets on books in kaggle itself - and I found out that while most of the datasets had a good amount of books listed, there were either a) major columns missing or b) grossly unclean data. I mean, you can't determine how good a book is just from a few text reviews, come on! What I needed were numbers, solid integers and floats that say how many people liked the book or hated it, how much did they like it, and stuff like that. Even the [good dataset](https://www.kaggle.com/zygmunt/goodbooks-10k#books.csv) that I found was well-cleaned, it had a number of interlinked files, which increased the hassle. This prompted me to use the Goodreads API to get a well-cleaned dataset, with the promising features only ( minus the redundant ones ), and the result is the dataset you're at now.

### Acknowledgements

This data was entirely scraped via the [Goodreads API](https://goodreads.com/api), so kudos to them for providing such a simple interface to scrape their database.

### Inspiration

The reason behind creating this dataset is pretty straightforward, I'm listing the books for all book-lovers out there, irrespective of the language and publication and all of that. So go ahead and use it to your liking, find out what book you should be reading next ( there are very few free content recommendation systems that suggest books last I checked ), what are the details of every book you have read, create a word cloud from the books you want to read - all possible approaches to exploring this dataset are welcome. 
I started creating this dataset on May 25, 2019, and intend to update it frequently.
P.S. If you like this, please don't forget to give an upvote!

### V2 notes :
You have the information about the publisher and the publication date now! Also, multiple authors are now delimited by '/'. Enjoy!

### Author's note:
Please read the [Goodreads API](https://www.goodreads.com/api/terms) terms and conditions before you decide to use this dataset anywhere.   
All I can say is, this dataset was created in good faith to help bibliophiles like me. I will not be maintaining this dataset anymore because as of December 8th, 2020, Goodreads no longer issues new developer keys for their public developer API and plans to retire the current version of these tools. ",.csv
Google Job Skills,1,google-job-skills,job_skills.csv,CC-BY-NC-SA-4.0,"### Context

There is a question in our mind that which language, skills, and experience should we add to our toolbox for getting a job in Google. Well, I think why not we find out the answer by analyzing the Google Jobs Site. Google published all of their jobs at https://careers.google.com/. So I scraped all of the job data from that site by going every job page using Selenium. I only take Job Title, Job Location, Job responsibilities, minimum and preferred qualifications for this dataset. 


### Content

This dataset is collected using Selenium by scraping all of the jobs text for [Google Career site][1]. 
About the column

**Title:** The title of the job

**Category:** Category of the job

**Location:** Location of the job

**Responsibilities:** Responsibilities for the job

**Minimum Qualifications:** Minimum Qualifications for the job

**Preferred Qualifications:** Preferred Qualifications for the job


### Acknowledgements

This dataset is collected using Selenium. This product uses the [Google Career site][2] but is not endorsed or certified by [Google Career site][3]. 

### Inspiration

 - You can find most popular skills for Google Jobs
 - Create identical job posts
 - Most popular languages
 - etc


  [1]: https://careers.google.com/
  [2]: https://careers.google.com/
  [3]: https://careers.google.com/",.csv
Google News UK (2010-2024),1,google-news-uk-2010-2024,news_uk_dataset.csv,CC0-1.0,"**Database Description**:
**Google News UK Titles**

**title**: This column contains the titles of news articles retrieved from Google News UK.

**published**: The published date and time of the news article.

**source**: The source of the news article.

**category**: The category to which the news article belongs. Categories include:

Politics,
Travel,
Sports,
Crime,
Education,
Economy,
Entertainment,
Technology,
Culture,
International,
Science,
Health,
Environment,
Police",.csv
Google Play Store Applications,1,google-play-store-applications,googleplaystore.csv,Attribution 4.0 International (CC BY 4.0),"# Context
While many **public datasets** (on Kaggle and the like) provide Apple App Store data, few counterpart datasets are available for Google Play Store apps anywhere on the web. On digging deeper, I discovered that the iTunes App Store page deploys a nicely indexed appendix-like structure to allow for simple and easy web scraping. On the other hand, Google Play Store uses sophisticated modern-day techniques (like dynamic page load) using JQuery making scraping more challenging.

# Content
&gt;- There are **13 features** in the dataset, and each feature indicates some details of **Google application** name, category, rating, reviews, size, installs, type, price, content rating genres, last updated, current version and Android version.
- **App**: The application name.
- **Category**: The category the app belongs to.
- **Rating**: Overall user rating of the app.
- **Reviews**: Number of user reviews for the app.
- **Size**: The size of the app.
- **Installs**: Number of user installs for the app.
- **Type**: Either ""Paid"" or ""Free"".
- **Price**: The price of the app.
- **Content Rating**: The age group the app is targeted at - ""Children"" / ""Mature 21+"" / ""Adult"".
- **Genres**: Possibly multiple genres the app belongs to.
- **Last Updated**: The date the app was last updated.
- **Current Ver**: The current version of the app.
- **Android Ver**: The Android version is needed for this app.",.csv
Google Play Store Reviews,1,google-play-store-reviews,reviews.csv,CC0-1.0,"### Google Play Store

Google Play, formerly Android Market, is a digital distribution service operated and developed by Google. It serves as the official app store for certified devices running on the Android operating system, allowing users to browse and download applications developed with the Android software development kit (SDK) and published through Google. It has crossed over **82 billion app downloads** with over **3.5 million published apps** making it the largest app store in the world. 

![Google Play Store Logo](https://cdn.worldvectorlogo.com/logos/google-play-3.svg)

### Content

The data contains over 12000 reviews of different app store applications by real users. The data also contains the rating that was given by them so it can be classified into positive or negative reviews. This is a real good place to perform **sentiment analysis tasks**. Some of the apps whose data has been collected can be seen below. 

![Apps whose data has been collected](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F3203431%2F6700dfe06222d72078d9335905d3884c%2FCapture.JPG?generation=1608799244097236&alt=media)

### Acknowledgements

I have used the [Google Play Store Scrapper Library](https://github.com/JoMingyu/google-play-scraper) for this task which made the scrapping really easy. You can also check out the data collection process [here](https://github.com/prakharrathi25/Text-Analytics-Tool/blob/main/Notebooks/sentiment_analysis_data_collection.ipynb). 

### Motivation 
This is a really good place to start learning about sentiment analysis. These reviews and ratings can provide beginners with annotated real-world data. I have uploaded a BERT sentiment analysis model which has been trained on Colab but the code can be reused to run on Kaggle as well. You can also mine some other insights regarding the best and the worst reviews. ",.csv
Google Play store Apps dataset,1,play-store-apps-dataset,googleplaystore.csv,MIT,"Dataset Descriptions¶
App: Name of the mobile application.

Category: Category or genre to which the app belongs.

Rating: User rating score of the app.

Reviews: Number of user reviews/ratings for the app.

Size: Size of the app installation package.

Installs: Number of times the app has been installed.

Type: Whether the app is free or paid.

Price: Price of the app if it's paid; otherwise, '0' or 'Free'.

Content Rating: Content rating indicating suitability for different age groups.

Genres: Specific genres or themes associated with the app.

Last Updated: Date when the app was last updated.

Current Ver: Current version of the app.

Android Ver: Minimum required Android version to run the app.",.csv
Google Stock Data,1,google-stock-data,GOOGL.csv,other,"## What is Google?
Google LLC is an American multinational technology company that specializes in Internet-related services and products, which include online advertising technologies, a search engine, cloud computing, software, and hardware. It is considered one of the Big Five companies in the American information technology industry, along with Amazon, Facebook, Apple, and Microsoft. Google was founded on September 4, 1998, by Larry Page and Sergey Brin while they were Ph.D. students at Stanford University in California. Together they own about 14% of its publicly-listed shares and control 56% of the stockholder voting power through super-voting stock. The company went public via an initial public offering (IPO) in 2004. In 2015, Google was reorganized as a wholly-owned subsidiary of Alphabet Inc. Google is Alphabet's largest subsidiary and is a holding company for Alphabet's Internet properties and interests. Sundar Pichai was appointed CEO of Google on October 24, 2015, replacing Larry Page, who became the CEO of Alphabet. On December 3, 2019, Pichai also became the CEO of Alphabet.

## Information about this dataset
This dataset provides historical data of Alphabet Inc. (GOOG). The data is available at a daily level. Currency is USD.",.csv
Google Stock Market Data [20 years],1,google-stock-data-20-years,df.csv,Apache 2.0,"This dataset contains historical stock market data obtained from Yahoo Finance using the yfinance Python library. The dataset spans a specific time period and includes seven key columns: Date, Open, High, Low, close,  Adjusted Close, and Volume.

### Use case:
This dataset is valuable for a wide range of analyses and applications in finance, economics, and data science. It can be used to:
- Perform technical analysis to identify trading patterns and trends.
- Develop and backtest trading strategies.
- Conduct research on the relationship between trading volume and price movements.
- Analyze the impact of macroeconomic events on individual stocks or the overall market.
- Train machine learning models for stock price prediction, volatility forecasting, and risk management.
 
### Disclaimer:
This dataset is provided for educational and research purposes only. The accuracy and completeness of the data are not guaranteed.


Thumbnail Photo by Tima Miroshnichenko: https://www.pexels.com/photo/stock-market-illustration-on-the-screen-7567223/",.csv
Google Stock Prediction,1,google-stock-prediction,GOOG.csv,DbCL-1.0," **Context**
All of the practitioners, learners in DL learning will surely come across RNN and LSTM's. So I thought let me add a dataset that can be used as a stepping stone into the Stock predictions. 


 Content
This dataset contains 14 columns and 1257 Rows. Each columns are assigned to a attribute and rows contains the values for that attribute.
The 14 columns are:
1. symbol : - Name of the company (in this case Google).
2. date :- year and date 
3. close:- closing of stock value
4. high:- highest value of stock at that day
5. low:- lowest value of stock at that day
6. open:- opening value of stock at that day 
7. volume
8. adjClose
9. adjHigh
10. adjLow
11. adjOpen
12. adjVolume
13. divCash
14. splitFactor


** Acknowledgements**
 I would like to thank Tiingo for providing such a wonderful platform which maintains the financial and stock data and updates them day to day.


Predict the close and open values for the next 30 days. Can you guys do this?
Please up vote if you guys like this dataset.",.csv
Google Stock Price (All Time),1,google-stock-price-all-time,google.csv,CC0-1.0,"### Company Description
Alphabet, Inc. is a holding company, which engages in the business of acquisition and operation of different companies. It operates through the Google and Other Bets segments. The Google segment includes its main Internet products such as ads, Android, Chrome, hardware, Google Cloud, Google Maps, Google Play, Search, and YouTube. The Other Bets segment consists of businesses such as Access, Calico, CapitalG, GV, Verily, Waymo, and X. The company was founded by Lawrence E. Page and Sergey Mikhaylovich Brin on October 2, 2015 and is headquartered in Mountain View, CA.

### Contact Information
Alphabet, Inc.
1600 Amphitheatre Parkway
Mountain View California 94043
P:(650) 253-0000

### Shareholders
Mutual fund holders	38.81%
Other institutional	29.71%
Individual stakeholders	13.92%


",.csv
Google Stock Price Train,1,google-stock-price-train,Google_Stock_Price_Train.csv,Apache 2.0,"The Google Stock Price Train is an innovative tool designed to predict the future price movements of Google's stock based on historical data and market trends. Leveraging sophisticated machine learning algorithms, this system analyzes vast amounts of historical stock data, including price fluctuations, trading volumes, and other relevant indicators. By identifying patterns and correlations within the data, the system aims to generate accurate forecasts of Google's stock prices, assisting investors, traders, and financial analysts in making informed decisions. With its ability to adapt to changing market conditions and incorporate real-time data, the Google Stock Price Train serves as a valuable resource for individuals and organizations seeking to navigate the complexities of the stock market and optimize their investment strategies.",.csv
Google Zero Days in the Wild (Apr 2024),1,google-zero-days-in-the-wild-apr-2024,0day _In the Wild_ - All.csv,CC-BY-NC-SA-4.0,"From Google Project Zero: 
&gt; This spreadsheet is used to track cases of zero-day exploits that were detected ""in the wild"". This means the 
vulnerability was detected in real attacks against users as a zero-day vulnerability (i.e. not known to the 
public or the vendor at the time of detection). This data is collected from a range of public sources. We include 
relevant links to third-party analysis and attribution, but we do this only for your information; their inclusion does 
not mean we endorse or validate the content there.

**References**:
- https://googleprojectzero.blogspot.com/p/0day.html
- https://github.com/googleprojectzero/0days-in-the-wild",.csv
Government Procurement Dataset (2015 - 2021),1,government-procurement-dataset,government-procurement-via-gebiz.csv,CC0-1.0,"## Government Procurement Dataset (2015 - 2021)
This dataset lists all open tenders put out by Singapore government agencies since 2015 to 2021

## Source

Ministry of Finance Singapore 

## Schema:
      -
        Name: 'tender_no.'
        Title: 'Tender No.'
        Type: 'text'
        Sub Type: 'general'
      -
        Name: 'tender_description'
        Title: 'Tender Description'
        Type: 'text'
        Sub Type: 'general'
      -
        Name: 'agency'
        Title: 'Agency'
        Type: 'text'
        Sub Type: 'general'
      -
        Name: 'award_date'
        Title: 'Award date'
        Type: 'text'
        Sub Type: 'general'
      -
        Name: 'tender_detail_status'
        Title: 'Tender Detail Status'
        Type: 'text'
        Sub Type: 'general'
      -
        Name: 'supplier_name'
        Title: 'Supplier Name'
        Type: 'text'
        Sub Type: 'general'
      -
        Name: 'awarded_amt'
        Title: 'Awarded Amount'
        Type: 'numeric'
        Sub Type: 'general'
        Unit Of Measure: 'S$'
",.csv
"Govt. of India Census, 2001 District-Wise",1,census2001,all.csv,DbCL-1.0,"# Context 
Census of India is a rich database which can tell stories of over a billion Indians. It is important not only for research point of view, but commercially as well for the organizations that want to understand India's complex yet strongly knitted heterogeneity. 
However, nowhere on the web, there exists a single database that combines the district- wise information of all the variables (most include no more than 4-5 out of over 50 variables!). Extracting and using data from Census of India 2001 is quite a laborious task since all data is made available in scattered PDFs district wise. Individual PDFs can be extracted from http://www.censusindia.gov.in/(S(ogvuk1y2e5sueoyc5eyc0g55))/Tables_Published/Basic_Data_Sheet.aspx. 

# Content
This database has been extracted from Census of 2001 and includes data of 590 districts, having around 80 variables each. 

In case of confusion regarding the context of the variable, refer to the following PDF and you will be able to make sense out of it: http://censusindia.gov.in/Dist_File/datasheet-2923.pdf 

All the extraction work can be found @ https://github.com/preetskhalsa97/census2001auto 
The final CSV can be found at finalCSV/all.csv

The subtle hack that was used to automate extraction to a great extent was the the URLs of all the PDFs were same except the four digits (that were respective state and district codes). 

A few abbreviations used for states:

AN- Andaman and Nicobar
CG- Chhattisgarh
D_D- Daman and Diu
D_N_H- Dadra and Nagar Haveli
JK- Jammu and Kashmir
MP- Madhya Pradesh
TN- Tamil Nadu
UP- Uttar Pradesh
WB- West Bengal 

A few variables for clarification: 
Growth..1991...2001- population growth from 1991 to 2001
X0..4 years- People in age group 0 to 4 years
SC1- Scheduled Class with highest population


# Acknowledgements



# Inspiration
This is a massive dataset which can be used to explain the interplay between education, caste, development, gender and much more. 
It really can explain a lot about India and propel data driven research. 
Happy Number Crunching!",.csv
Gowalla,1,gowalla,Gowalla_cleanCheckins.csv,Apache 2.0,"Gowalla is a location-based social networking website where users share their locations by checking-in. The friendship network is undirected and was collected using their public API, and consists of 196,591 nodes and 950,327 edges. We have collected a total of 6,442,890 check-ins of these users over the period of Feb. 2009 - Oct. 2010.

| Dataset statistics |  |
| --- | --- |
| Nodes | 196591 |
| Edges | 950327 |
| Nodes in largest WCC | 196591 (1.000) |
| Edges in largest WCC | 950327 (1.000) |
| Nodes in largest SCC | 196591 (1.000) | 
| Edges in largest SCC | 950327 (1.000) |
| Average clustering coefficient | 0.2367 |
| Number of triangles | 2273138 |
| Fraction of closed triangles | 0.007952 |
| Diameter (longest shortest path) | 14 | 
| 90-percentile effective diameter | 5.7 |
| Check-ins | 6,442,890 |
",.csv
Grades of Students ,1,grades-of-students,Grades.csv,CC-BY-NC-SA-4.0,"The dataset contains grades scored by students throughout their university tenure in various courses and  their CGPA calculated based on their grades

##**Columns Description**


-**Seat No** : The enrolled number of candidate that took the exams

-**CGPA :** The cumulative GPA based on the four year total grade progress of each candidate

- All other columns are course codes in the format AB-XXX  where AB are alphabets representing candidates' departments and XXX are numbers where first X represents the year the canditate took exam

",.csv
Graduates Admission Prediction,1,graduates-admission-prediction,admission_data.csv,DbCL-1.0,"Try to Prediction of Graduate Admissions from an Indian perspective.

***Content***
Dataset contains under given important parameters which are considered mainly during application for Masters Programs.
Parameters description:

1. GRE Scores ( out of 340 )
2. TOEFL Scores ( out of 120 )
3. University Rating ( out of 5 )
4. Statement of Purpose -(SOP) Strength ( out of 5 )
5. Letter of Recommendation-(LOR) Strength ( out of 5 )
5. Undergraduate GPA-CGPA ( out of 10 )
6. Research Experience ( either 0 or 1 )
7. Chance of Admit ( ranging from 0 to 1 )

***Inspiration***
Results will help students in shortlisting universities with their profiles. Predicted output can provide students a fair idea about their chances for a particular university.",.csv
Grammy Awards,1,grammy-awards,the_grammy_awards.csv,CC0-1.0,"[![forthebadge made-with-python](http://ForTheBadge.com/images/badges/made-with-python.svg)](https://www.python.org/) [![ForTheBadge built-with-love](http://ForTheBadge.com/images/badges/built-with-love.svg)](https://GitHub.com/unanimad/)

# About
A [Grammy Award](https://www.grammy.com/) (stylized as GRAMMY, originally called Gramophone Award), or Grammy, is an award presented by The Recording Academy to recognize achievements in the music industry. The trophy depicts a gilded gramophone. The annual presentation ceremony features performances by prominent artists, and the presentation of those awards that have a more popular interest. The Grammys are the second of the Big Three major music awards held annually (between the American Music Awards in the Fall, and the Billboard Music Awards in the Summer).

---

## Method

The data were extracted from [Awards' list page](https://www.grammy.com/grammys/awards) and IMDb.

---

# Inspiration

1. Which nominee has received the most awards overall or in a single year?
2. Which work has received the most awards in a event?
3. Which country received the most awards at a ceremony and overall?
4. Which musical genre has won the most awards?
5. Which is the media of beats per minute of winners?
6. Which genre has won the most awards?",.csv
Griffin Feather Data Skyblock,1,griffin-feather-data-skyblock,griffin_feather_data.csv,other,"Pulled data off of coinflet, Believe it goes from 2020-09-08 2024-04-12. Here you can project price data or making trading predictions. For Me I was just curious if I could pull the data in the first place, I haven't really seen what I can do with it yet

",.csv
Groceries dataset ,1,groceries-dataset,Groceries_dataset.csv,GPL-2.0,"### Association Rule Mining

Market Basket Analysis is one of the key techniques used by large retailers to uncover associations between items. It works by looking for combinations of items that occur together frequently in transactions. To put it another way, it allows retailers to identify relationships between the items that people buy.

Association Rules are widely used to analyze retail basket or transaction data and are intended to identify strong rules discovered in transaction data using measures of interestingness, based on the concept of strong rules.

### Details of the dataset

The dataset has 38765 rows of the purchase orders of people from the grocery stores. These orders can be analysed and association rules can be generated using Market Basket Analysis by algorithms like Apriori Algorithm. 

### Apriori Algorithm 

Apriori is an algorithm for frequent itemset mining and association rule learning over relational databases. It proceeds by identifying the frequent individual items in the database and extending them to larger and larger item sets as long as those item sets appear sufficiently often in the database. The frequent itemsets determined by Apriori can be used to determine association rules which highlight general trends in the database: this has applications in domains such as market basket analysis.

### An example of Association Rules

Assume there are 100 customers
10 of them bought milk, 8 bought butter and 6 bought both of them.
bought milk =&gt; bought butter
support = P(Milk & Butter) = 6/100 = 0.06
confidence = support/P(Butter) = 0.06/0.08 = 0.75
lift = confidence/P(Milk) = 0.75/0.10 = 7.5

Note: this example is extremely small. In practice, a rule needs the support of several hundred transactions, before it can be considered statistically significant, and datasets often contain thousands or millions of transactions.

### Some important terms:

- Support: This says how popular an itemset is, as measured by the proportion of transactions in which an itemset appears.

- Confidence: This says how likely item Y is purchased when item X is purchased, expressed as {X -&gt; Y}. This is measured by the proportion of transactions with item X, in which item Y also appears.

- Lift: This says how likely item Y is purchased when item X is purchased while controlling for how popular item Y is.",.csv
Grocery Dataset,1,grocery-dataset,GroceryDataset.csv,CC0-1.0,"I scraped grocery data from Costco's online marketplace.

Features: 

-  **Sub Category:** 

This column categorizes the grocery items into subcategories, providing a detailed classification for easier analysis and organization.

-  **Price:** 

Represents the monetary value of the grocery item, indicating its cost or retail price in the specified currency.

-  **Discount:** 

Reflects any discounts or promotional offers applicable to the respective grocery item, providing insights into pricing strategies.

-  **Rating:** 

Indicates the customer satisfaction or product quality based on user ratings, offering a measure of the overall perceived value of the grocery item.

-  **Title:** 

Describes the name or title of the grocery item, providing a concise identifier for easy reference and understanding.

-  **Currency:** 

Specifies the currency in which the prices are denominated, facilitating proper interpretation and comparison of monetary values.

-  **Feature:** 

Includes features or characteristics of the grocery item, offering additional information about its unique attributes or selling points.

-  **Product Description:** 

Provides a detailed textual description of the grocery item, offering comprehensive information about its specifications, uses, and other relevant details. This column is particularly useful for understanding product details beyond what is captured in other columns.
",.csv
Grocery Prices Data: Explore Shopping Trends,1,grocery-prices-data-explore-shopping-trends,Grocery_data (1).csv,CC0-1.0,"Explore this rich dataset capturing daily prices of grocery essentials. From fresh produce to pantry staples, delve into the fluctuations of everyday items to uncover valuable insights for data scientists and analysts. Whether you're tracking market trends or optimizing shopping strategies, this dataset offers a treasure trove of information for informed decision-making.

Here's a short description for each column in your dataset:

**Product Name:** The name or description of the grocery item.

**Category:** The category to which the product belongs (e.g., fruits, vegetables, dairy, etc.)

**Quantity:** The quantity or amount of the product purchased.

**Original Price (Rs.):** The original price of the product before any discounts, in Indian Rupees.

**Discount:** The discount offered on the product, usually represented as a percentage.

**Discounted Price (Rs.):** The price of the product after applying the discount, in Indian Rupees.
",.csv
Grocery Store Data Set,1,supermarket,GroceryStoreDataSet.csv,CC0-1.0,"For my Data Mining lab where we had to execute algorithms like apriori, it was very difficult to get a small data set with only a few transactions. It was infeasible to run the algorithm with datasets containing over 10000 transactions. This dataset contains 11 items : JAM, MAGGI, SUGAR, COFFEE, CHEESE, TEA, BOURNVITA, CORNFLAKES, BREAD, BISCUIT and MILK.",.csv
Grocery Store Dataset,1,grocery-store-dataset,GroceryDataset.csv,Attribution 4.0 International (CC BY 4.0),"Scraped grocery data from Costco's online marketplace.

&gt;## Features:
* **Sub Category:** This column categorizes the grocery items into subcategories, providing a detailed classification for easier analysis and organization.
* **Price:** Represents the monetary value of the grocery item, indicating its cost or retail price in the specified currency.
* **Discount:** Reflects any discounts or promotional offers applicable to the respective grocery item, providing insights into pricing strategies.
* **Rating:** Indicates customer satisfaction or product quality based on user ratings, offering a measure of the overall perceived value of the grocery item.
* **Title:** Describes the name or title of the grocery item, providing a concise identifier for easy reference and understanding.
* **Currency:** Specifies the currency in which the prices are denominated, facilitating proper interpretation and comparison of monetary values.
* **Feature:** Includes features or characteristics of the grocery item, offering additional information about its unique attributes or selling points.
* **Product Description:** Provides a detailed textual description of the grocery item, offering comprehensive information about its specifications, uses, and other relevant details. This column is handy for understanding product details beyond what is captured in other columns.",.csv
Grocery Store Transaction Data,1,grocery-store-transaction-data,Association Algorithm.csv,CC-BY-SA-4.0,This dataset contains transaction records from a grocery store. Each transaction lists the items purchased by a customer. The data is suitable for applying association rule mining algorithms like Apriori or FP-growth to discover frequent itemsets and generate association rules.,.csv
Groundhog Day Forecasts and Temperatures,1,groundhog-day,archive.csv,CC0-1.0,"# Context 

Thousands gather at Gobbler’s Knob in Punxsutawney, Pennsylvania, on the second day of February to await the spring forecast from a groundhog known as Punxsutawney Phil. According to legend, if Phil sees his shadow the United States is in store for six more weeks of winter weather. But, if Phil doesn’t see his shadow, the country should expect warmer temperatures and the arrival of an early spring.


# Acknowledgements

The historical weather predictions were provided by the Punxsutawney Groundhog Club, and the average monthly temperatures were published by NOAA's National Climatic Data Center.",.csv
Gufhtgu Publications Books Dataset,1,gufhtgu-publications-books-dataset,Gufhtgu Publications Books Dataset.csv,CC0-1.0,"**Context:**

This dataset provides a detailed catalog of books available through Gufhtugu Publications, a prominent publisher in Pakistan. Spanning various genres and authors, this dataset encapsulates the diversity and richness of literary offerings available through their platform.

**Content Details:**

- **URL:** Direct link to the book's page on Gufhtugu Publications' website.
- **Title:** The name of the book.
- **Price (PKR):** Listed price of the book in Pakistani Rupees.
- **Author:** Name of the author(s).
- **Stock Status:** Availability status of the book (e.g., In stock).
- **SKU:** Stock Keeping Unit, a unique identifier for each book.
- **Categories:** The genres or categories the book belongs to.

**Potential Uses**

This dataset is perfect for:

- Analysts looking to understand market trends and pricing within the Pakistani book market.
- Retailers and e-commerce platforms aiming to optimize their inventory based on popular genres and authors.
- Literary enthusiasts and educators interested in the scope of available literary works.
- Data scientists and hobbyists eager to apply machine learning to predict trends or recommend books.

This dataset can be used for academic research, market analysis, or simple curiosity, there's plenty here to discover.",.csv
Gurugram's Air Quality Index Time-Series Dataset,1,test-aqi,sector_51_daily_aqi.csv,CC0-1.0,"This dataset is about Gurugram's daily Air Quality Index. The starting date is March 2020 up to today. The data is updated daily.
If you are interested to checkout next 5 day's AQI, checkout my project - https://aircastaqi.netlify.app 
![https://aircastaqi.netlify.app ](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F2935129%2F1a04748b26971d876e2691185ff7070e%2FAirCast%20Website.png?generation=1705944753919795&alt=media)

Here is the quick overview of the AQI![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F2935129%2F18e40b9bbe30b208ba7f73ee5bab5c0e%2F__results___21_3.png?generation=1705944882907653&alt=media)


This is the meaning of AQI (Scale)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F2935129%2F6d70ba57d33ee4f5bcc89950307e61f6%2FAQI%20Chart.png?generation=1705944663764027&alt=media)
",.csv
Gym Exercise Dataset,1,gym-exercise-data,megaGymDataset.csv,CC0-1.0,"**Context**
This is a dataset created for analyzing and evaluating workouts that one can do at the gym(or at home) to stay healthy. Exercising and being fit is becoming very important and almost a daily routine for all individuals and what better than to take a data-driven route for success to meet one's fitness goals.

**Inspiration**
If you go to a gym, the first thing you realize is the myriad of exercises available to do. The exercises range from bodyweight, machine-based or dumbbell/barbell based. With so many exercises to do, beginners or even professional can wonder which the exercise that will target a specific muscle the best and that is where this analysis can be useful. I also thought it would be fun to visualize the exercise details.

**Content**
There is one file with 9 columns for each exercise. Columns may contain null values as the data is raw and scraped from various internet sources.",.csv
H&M Stores Dataset (2022),1,hm-stores-dataset,HM_all_stores.csv,CC0-1.0,"### Context

Hennes & Mauritz AB (H&M) is a Swedish multinational clothing company headquartered in Stockholm. It is known for its fast-fashion clothing for men, women, teenagers, and children. H&M operates in 75+ countries with over 5,000 stores under the various company brands, with 126,000 full-time equivalent positions. It is the second-largest global clothing retailer, behind Spain-based Inditex (parent company of Zara). Founded by Erling Persson and run by his son Stefan Persson and Helena Helmersson, the company makes its online shopping available in 33 countries. 

This dataset contains global locations and meta data of H&M Stores. 

",.csv
HMEQ_Data,1,hmeq-data,hmeq.csv,CC0-1.0,"### Context

The consumer credit department of a bank wants to automate the decisionmaking process for approval of home equity lines of credit. To do this, they will follow the recommendations of the Equal Credit Opportunity Act to create an empirically derived and statistically sound credit scoring model. The model will be based on data collected from recent applicants granted credit through the current process of loan underwriting. The model will be built from predictive modeling tools, but the created model must be sufficiently interpretable to provide a reason for any adverse actions (rejections). 

### Content

The Home Equity dataset (HMEQ) contains baseline and loan performance information for 5,960 recent home equity loans. The target (BAD) is a binary variable indicating whether an applicant eventually defaulted or was seriously delinquent. This adverse outcome occurred in 1,189 cases (20%). For each applicant, 12 input variables were recorded.

### Acknowledgements

### Inspiration

What if you can predict clients who default on their loans.",.csv
HR Analytics,1,hr-analytics-prediction,HR-Employee-Attrition.csv,CC0-1.0,"HR Analytics helps us with interpreting organizational data. It finds the people-related trends in the data and allows the HR Department to take the appropriate steps to keep the organization running smoothly and profitably. Attrition in a corporate setup is one of the complex challenges that the people managers and the HRs personnel have to deal with.

Interestingly, machine learning models can be deployed to predict potential attrition cases, helping the appropriate HR Personnel take the necessary steps to retain the employee.

**Tasks to perform: **

Data Cleaning:

Deleting redundant columns.
Renaming the columns.
Dropping duplicates.
Cleaning individual columns.
Remove the NaN values from the dataset
Check for some more Transformations

Data Visualization:

- Plot a correlation map for all numeric variables
- Overtime
- Marital Status
- Job Role
- Gender
- Education Field
- Department
- Business Travel
- Relation between Overtime and Age
- Total Working Years
- Education Level
- Number of Companies Worked
- Distance from Home

",.csv
HR Analytics Data Set,1,hr-analytics-data-set,HR_capstone_dataset.csv,other,"**Overview**

The dataset used in this capstone project is sourced from the **Google Advanced Data Analysis** course. It encompasses a comprehensive collection of attributes concerning employees, ranging from demographic details to job-related factors. The primary objective of this analysis is to forecast employee turnover and discern the underlying factors contributing to employee attrition. 

**Content**

- The dataset contains columns:
- Satisfaction Level 
- Last Evaluation
- Number of Project
- Average Monthly Hours
- Time Spend Company
- Work Accident
- Promotion Last 5
- Years
- Department
- Salary",.csv
HR Case Study ,1,hr-case-study,HR Case Study.csv,other,"### Context

The file is for a HR analytics case study and for educational/practice purpose
Data is collected and generated using random data. Names pulled off from internet files -including members of India's ladies cricket and football team. Data is not from a real company.

### Content

We have data on 875 employee, their names, genders (if disclosed), salary, location, rating, age and tenure in the company. We also note how far they live from their workplace.  
This is to be used by students for practicing HR analytics

### Acknowledgements

Image source: https://unsplash.com/photos/5fNmWej4tAA (author: Scott Graham)

### Inspiration

Looking to see some interesting analysis from HR perspective done with the data set",.csv
HR Competency Scores for Screening,1,hr-competency-scores-for-screening,dataset.csv,CC-BY-SA-4.0,"##### Context

Recruitment and candidate selection play a critical role in determining the success of an organization. An effective initial screening process can significantly improve the quality of the hiring pool and increase the chances of finding the right candidate for any given role. This dataset focuses on both behavioral and functional competency scores, which are essential aspects of a candidate's potential fit and contribution to the organization.

##### Sources

The data in this dataset has been collected from an anonymous company's internal HR department and published in a normalized form. The dataset combines the scores from two key assessments:

1. Functional competency test: Utilized to evaluate a candidate's hard skills and domain knowledge.
2. HR behavior test: An assessment tool focused on evaluating soft or behavior skills, crucial for teamwork and adaptability within an organization.

##### Young Researchers' Contribution

We were approached by a group of young researchers interested in the explainable AI (XAI) problem. They aimed to analyze HR data to understand why specific candidates were called for interviews while others were not. With their valuable input and help in preprocessing the data, we have made this dataset available for the wider research community.

##### Inspiration

The inspiration behind sharing this dataset was the growing need for insights into the hiring process and the importance of selecting candidates who possess a balance of functional and behavioral competencies. With the added value of XAI research, we hope to encourage researchers and data scientists to analyze the initial screening process, build models to optimize candidate selection, explain their decisions, and uncover new insights that can enhance recruitment strategies.

The dataset can be employed for a wide range of applications, including:

1. Identifying the most significant factors in determining a candidate's eligibility for an interview.
2. Developing machine learning models to predict and explain the likelihood of a candidate being called for an interview.
3. Analyzing the balance between functional competencies and behavioral skills required for a good fit in the organization.
4. Investigating the impact of different skill combinations on the overall competency scores.

We hope this dataset inspires researchers to explore new dimensions of the hiring process and contribute to building better and more transparent recruitment strategies.",.csv
HR Data for Analytics,1,hr-data-for-analytics,HR_comma_sep.csv,CC0-1.0,"### Context

This is dataset is for HR analytics, the user who previously submitted this deleted the public dataset.  The dataset contains employee profiles of a large company, where each record is an employee.",.csv
HR Dataset.csv,1,hr-comma-sep-csv,HR_comma_sep.csv,CC0-1.0,"# 🟡Please Upvote my dataset If you like It.✨

### This dataset contains valuable employee information over time that can be analyzed to help optimize key HR functions. Some potential use cases include:


**Attrition analysis:** Identify factors correlated with attrition like department, role, salary, etc. Segment high-risk employees. Predict future attrition.

**Performance management:** Analyze the relationship between metrics like ratings, and salary increments. recommend performance improvement programs.

**Workforce planning:** Forecast staffing needs based on historical hiring/turnover trends. Determine optimal recruitment strategies.

**Compensation analysis:** Benchmark salaries vs performance, and experience. Identify pay inequities. Inform compensation policies.

**Diversity monitoring:** Assess diversity metrics like gender ratio over roles, and departments. Identify underrepresented groups.

**Succession planning:** Identify high-potential candidates and critical roles. Predict internal promotions/replacements in advance.

&gt; Given its longitudinal employee data and multiple variables, this dataset provides rich opportunities for exploration, predictive modeling, and actionable insights. With a large sample size, it can uncover subtle patterns. Cleaning, joining with other contextual data sources can yield even deeper insights. This makes it a valuable starting point for many organizational studies and evidence-based decision-making.
 
.............................................................................................................................................................................................................................................
&gt; This dataset contains information about different attributes of employees from a company. It includes 1000 employee records and 12 feature columns.

### The columns are:

**satisfaction_level:** Employee satisfaction score (1-5 scale)
**last_evaluation:** Score on last evaluation (1-5 scale)
**number_project:** Number of projects employee worked on
**average_monthly_hours:** Average hours worked in a month
**time_spend_company:** Number of years spent with the company
**work_accident:** If an employee had a workplace accident (yes/no)
**left:** If an employee has left the company (yes/no)
**promotion_last_5years:** Number of promotions in last 5 years
**Department:** Department of the employee
**Salary:** Annual salary of employee
**satisfaction_level:** Employee satisfaction level (1-5 scale)
**last_evaluation:** Score on last evaluation (1-5 scale)
",.csv
Hair Health Prediction,1,hair-health,Predict Hair Fall.csv,Apache 2.0,"This dataset contains information about various factors that may contribute to baldness in individuals. Each row represents a unique individual, and the columns represent different factors related to genetics, hormonal changes, medical conditions, medications and treatments, nutritional deficiencies, stress levels, age, poor hair care habits, environmental factors, smoking habits, weight loss, and the presence or absence of baldness.

Columns:

- **Genetics:** Indicates whether the individual has a family history of baldness (Yes/No).
- **Hormonal Changes:** Indicates whether the individual has experienced hormonal changes (Yes/No).
- **Medical Conditions:** Lists specific medical conditions that may contribute to baldness, such as Alopecia Areata, Thyroid Problems, Scalp Infection, Psoriasis, Dermatitis, etc.
- **Medications & Treatments:** Lists medications and treatments that may lead to hair loss, such as Chemotherapy, Heart Medication, Antidepressants, Steroids, etc.
- **Nutritional Deficiencies:** Lists nutritional deficiencies that may contribute to hair loss, such as Iron deficiency, Vitamin D deficiency, Biotin deficiency, Omega-3 fatty acid deficiency, etc.
- **Stress:** Indicates the stress level of the individual (Low/Moderate/High).
- **Age:** Represents the age of the individual.
- **Poor Hair Care Habits:** Indicates whether the individual practices poor hair care habits (Yes/No).
- **Environmental Factors:** Indicates whether the individual is exposed to environmental factors that may contribute to hair loss (Yes/No).
- **Smoking:** Indicates whether the individual smokes (Yes/No).
- **Weight Loss:** Indicates whether the individual has experienced significant weight loss (Yes/No).
- **Baldness (Target):** Binary variable indicating the presence (1) or absence (0) of baldness in the individual.

Dataset Purpose:

The dataset is intended for exploratory data analysis, modeling, and predictive analytics tasks aimed at understanding the relationship between various factors and the likelihood of baldness in individuals. ",.csv
Hand Dominance Survey,1,hand-dominance-survey,HandDominance.csv,Apache 2.0,"With approximately 10% to 15% of the population being left-handed and the majority
being right-handed, questions arise about the origins of handedness within families.
Reflecting on personal experiences, such as being left-handed with a left-handed mother,
prompts inquiries into potential genetic or mimetic influences on children.
Is our dominant hand correlated with that of our parents?


That's the question I asked myself for a project, but this dataset could also allow for other questions to be explored.",.csv
Handwriting Data to Detect Alzheimer’s Disease,1,handwriting-data-to-detect-alzheimers-disease,data.csv,Attribution 4.0 International (CC BY 4.0),"The DARWIN dataset includes handwriting data from 174 participants. The classification task consists in distinguishing Alzheimer’s disease patients from healthy people.

**Creator:** [Francesco Fontanella](fontanella@unicas.it)

**Source:** [https://archive.ics.uci.edu/dataset/732/darwin](https://archive.ics.uci.edu/dataset/732/darwin)

The DARWIN dataset was created to allow researchers to improve the existing machine-learning methodologies for the prediction of Alzheimer's disease via handwriting analysis.

**Citation Requests/Acknowledgements**

N. D. Cilia, C. De Stefano, F. Fontanella, A. S. Di Freca, An experimental protocol to support cognitive impairment diagnosis by using handwriting analysis, Procedia Computer Science 141 (2018) 466–471. https://doi.org/10.1016/j.procs.2018.10.141

N. D. Cilia, G. De Gregorio, C. De Stefano, F. Fontanella, A. Marcelli, A. Parziale, Diagnosing Alzheimer’s disease from online handwriting: A novel dataset and performance benchmarking, Engineering Applications of Artificial Intelligence, Vol. 111 (20229) 104822. https://doi.org/10.1016/j.engappai.2022.104822",.csv
Handwritten Digits From 0 to 9,1,handwritten-digits-from-0-to-9,Digits from 0 - 9.csv,Apache 2.0,"This dataset generated from about 21,600 numbers from 0 - 9 in European (Swiss) notation. The single images are in full color .jpg with a size of 90x140px",.csv
Happiness Classification Dataset,1,happiness-classification-dataset,happydata.csv,CC0-1.0,"A feeling of happiness while self introspecting is the major reason we indulge in our hobbies and choose places to live. 

This Dataset is based on a survey conducted where people rated different metrics of their city on a scale of 5 and answered if they are happy or unhappy.

The goal of this dataset is to understand the important factors that play a role in making the residents of a city more happy with their lives.

Data Dictionary:-

**infoavail** = the availability of information about the city services
**housecost** = the cost of housing
**schoolquality** = the overall quality of public schools
**policetrust** = your trust in the local police
**streetquality** = the maintenance of streets and sidewalks
**events** = the availability of social community events
**happy** = decision attribute (D) with values 0 (unhappy) and 1 (happy)",.csv
Harry Pinero Youtube Performance,1,harry-pinero-youtube-performance,harry_pinero.csv,MIT,"As of Wednesday, 24 January 2024, 00:20 AM Korean Standard Time(KST).
We embark on a comprehensive exploration of the digital landscape. Our dataset centres around the charismatic British YouTuber and entertainer ***Harry Pinero***. This collection encapsulates the dynamic journey of Harry's influence on YouTube, meticulously capturing his online presence, engagement metrics, and noteworthy appearances across diverse platforms since 2018. As we navigate through the data, we unravel the captivating narrative of Harry Pinero's evolution as a content creator, examining the trends, milestones, and the impact he has had on digital entertainment. From view counts and like counts growth on YouTube to his appearances on various sites, this dataset unveils the multifaceted dimensions of ***Harry Pinero***'s digital journey, providing a nuanced perspective on his reach and resonance in the online sphere.

### Columns in the Dataset

1. **Video ID:** Unique identifier for each posted video.
2. **Title:** Title of the specific video.
3. **PublishDay:** The day of the week the video was released.
4. **PublishDate:** The release date for the video.
5. **PublishTime:** The release time for each video.
6. **Duration(Seconds):** Length of the episode in seconds.
7. **LikeCount:** Count of likes received on each video.
8. **ChannelName:** The name of the channel on which the video was posted.
9. **SubscriberCount:** Number of subscribers or respective channels.",.csv
Harvard University Ratings and Reviews,1,harvard-university-ratings-and-reviews,harvard_reviews.csv,ODC Attribution License (ODC-By),"### Dataset Description

#### Dataset Overview
The ""Harvard University Ratings and Reviews"" dataset presents a rich compilation of experiences from one of the most esteemed institutions globally. It uniquely encompasses a broad spectrum of perspectives, including in-depth academic evaluations and impressions from travelers intrigued by Harvard's historical and architectural significance. This dataset serves as a bridge, connecting the academic excellence of Harvard with the experiences of visitors who come to admire its iconic campus.

#### Data Science Applications
- **Sentiment Analysis**: Understand the emotional tone behind the textual reviews, distinguishing between academic and traveler feedback.
- **Trend Analysis**: Examine how perceptions of Harvard evolve over time, correlating them with significant events or changes within the university.
- **Text Mining and NLP**: Utilize the rich review texts for topic modeling, keyword extraction, and building sentiment classifiers.
- **Comparative Analysis**: Investigate differences in experiences based on the review platform (Mobile vs. Desktop) and the nature of the visit (academic vs. tourism).

#### Column Descriptors
- **published_date**: Timestamp of when the review was posted, providing insight into temporal trends.
- **published_platform**: The platform (Mobile/Desktop) used to publish the review, indicating user engagement preferences.
- **rating**: Numerical rating given by the reviewer, reflecting their level of satisfaction.
- **type**: Type of submission, with a focus on reviews in this dataset.
- **helpful_votes**: Number of times a review was marked as helpful, suggesting its impact and relevance.
- **title**: Brief headline of the review, encapsulating the main sentiment.
- **text**: Detailed narrative of the reviewer's experience and feedback.

#### Ethically Mined Data
This dataset has been ethically curated, with careful consideration to exclude any personal identifiers. By focusing purely on the content of the reviews, it respects privacy while still offering valuable insights.

#### Acknowledgments
We extend our gratitude to TripAdvisor for providing a platform that captures such a diverse range of experiences and to Harvard University for being the subject of this intriguing dataset. Their contributions enrich our understanding of academic and visitor perceptions alike.

#### Image Acknowledgment
The dataset's thumbnail, featuring an iconic view of Harvard University, has been sourced from [AdmissionSight](https://admissionsight.com/how-big-is-harvard-university/). This image captures the essence of Harvard's sprawling campus, inviting further exploration through the reviews within this dataset.",.csv
Hate Speech and Offensive Language Detection,1,hate-speech-and-offensive-language-detection,train.csv,CC0-1.0,"_____
# Hate Speech and Offensive Language Detection
### Hate Speech and Offensive Language Detection on Twitter
By hate_speech_offensive (From Huggingface) [[source]](https://huggingface.co/datasets/hate_speech_offensive)
_____

### About this dataset
> This dataset, named hate_speech_offensive, is a meticulously curated collection of annotated tweets with the specific purpose of detecting hate speech and offensive language. The dataset primarily consists of English tweets and is designed to train machine learning models or algorithms in the task of hate speech detection. It should be noted that the dataset has not been divided into multiple subsets, and only the train split is currently available for use.
> 
> The dataset includes several columns that provide valuable information for understanding each tweet's classification. The column count represents the total number of annotations provided for each tweet, whereas hate_speech_count signifies how many annotations classified a particular tweet as hate speech. On the other hand, offensive_language_count indicates the number of annotations categorizing a tweet as containing offensive language. Additionally, neither_count denotes how many annotations identified a tweet as neither hate speech nor offensive language.
> 
> For researchers and developers aiming to create effective models or algorithms capable of detecting hate speech and offensive language on Twitter, this comprehensive dataset offers a rich resource for training and evaluation purposes

### How to use the dataset
> 
> - Introduction:
> 
> - Dataset Overview:
>    - The dataset is presented in a CSV file format named 'train.csv'.
>    - It consists of annotated tweets with information about their classification as hate speech, offensive language, or neither.
>    - Each row represents a tweet along with the corresponding annotations provided by multiple annotators.
>    - The main columns that will be essential for your analysis are: count (total number of annotations), hate_speech_count (number of annotations classifying a tweet as hate speech), offensive_language_count (number of annotations classifying a tweet as offensive language), neither_count (number of annotations classifying a tweet as neither hate speech nor offensive language).
> 
> - Data Collection Methodology:
>     The data collection methodology used to create this dataset involved obtaining tweets from Twitter's public API using specific search terms related to hate speech and offensive language. These tweets were then manually labeled by multiple annotators who reviewed them for classification purposes.
> 
> - Data Quality:
>     Although efforts have been made to ensure the accuracy of the data, it is important to acknowledge that annotations are subjective opinions provided by individual annotators. As such, there may be variations in classifications between annotators.
> 
> - Preprocessing Techniques:
>     Prior to training machine learning models or algorithms on this dataset, it is recommended to apply standard preprocessing techniques such as removing URLs, usernames/handles, special characters/punctuation marks, stop words removal, tokenization, stemming/lemmatization etc., depending on your analysis requirements.
> 
> - Exploratory Data Analysis (EDA):
>     Conducting EDA on the dataset will help you gain insights and understand the underlying patterns in hate speech and offensive language. Some potential analysis ideas include:
>     - Distribution of tweet counts per classification category (hate speech, offensive language, neither).
>     - Most common words/phrases associated with each class.
>     - Co-occurrence analysis to identify correlations between hate speech and offensive language.
> 
> - Building Machine Learning Models:
>     To train models for automatic detection of hate speech and offensive language, you can follow these steps:
>    a) Split the dataset into training and testing sets for model evaluation purposes.
>    b) Choose appropriate features/

### Research Ideas
> - Sentiment Analysis: This dataset can be used to train models for sentiment analysis on Twitter data. By classifying tweets as hate speech, offensive language, or neither, the dataset can help in understanding the sentiment behind different tweets and identifying patterns of negative or offensive language.
> - Hate Speech Detection: The dataset can be used to develop models that automatically detect hate speech on Twitter. By training machine learning algorithms on this annotated dataset, it becomes possible to create systems that can identify and flag hate speech in real-time, making social media platforms safer and more inclusive.
> - Content Moderation: Social media platforms can use this dataset to improve their content moderation systems. By using machine learning algorithms trained on this data, it becomes easier to automatically detect and remove offensive or hateful content from the platform, reducing the burden on human moderators and improving user experience by keeping online spaces free from toxic behavior

### Acknowledgements
> If you use this dataset in your research, please credit the original authors.
> [Data Source](https://huggingface.co/datasets/hate_speech_offensive)
> 
>


### License
> 
> 
> **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
> No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: train.csv**
| Column name                  | Description                                                                                            |
|:-----------------------------|:-------------------------------------------------------------------------------------------------------|
| **count**                    | The total number of annotations for each tweet. (Integer)                                              |
| **hate_speech_count**        | The number of annotations classifying a tweet as hate speech. (Integer)                                |
| **offensive_language_count** | The number of annotations classifying a tweet as offensive language. (Integer)                         |
| **neither_count**            | The number of annotations classifying a tweet as neither hate speech nor offensive language. (Integer) |

### Acknowledgements
> If you use this dataset in your research, please credit the original authors.
> If you use this dataset in your research, please credit [hate_speech_offensive (From Huggingface)](https://huggingface.co/datasets/hate_speech_offensive).

",.csv
Health Apps Evaluation Dataset,1,mobile-health-apps-evaluation-dataset,mhealth_app_review_data.csv,Apache 2.0,"## Few Parameters:

**App ID**: This is a unique identifier we assigned to each app. AppIDs ending in b were originally discovered as being present on both the Android and iOS app stores. Some of these may have been ultimately reviewed on only one of the 2 operating systems (OSes) if the app was pulled from one of the two app stores or if the app was non-functional on one of the 2 OSes.

**Permission To Name**: We asked app developers for permission to name their apps in our study. For more details, see the methods in the original manuscript.

**y **- the developer gave us permission to name their app

**n** - the developer did not give us permission to name their app

**App Name**: This is the name of the app as entered by the reviewer. Though we did not report the developer in the dataset, the names of the developers for each of the named apps are available in the appendix accompanying the manuscript.

**Reviewer:** Is the reviewer a clinician or non-clinician?

**Options are**: clinician_reviewer or nonclinician_reviewer.

**Platform:** This is the type of device on which the app was reviewed. Options are: iPhone, iPad or iPad Mini, Android phone, and Android tablet.

**OS**: This is the operating system on which the app was reviewed. This was derived automatically from the platform. Options are: iOS, Android, and Both.

***Reference: ***https://kdpsingh.lab.medicine.umich.edu/datasets/mobile-health-apps-evaluation-dataset",.csv
Health Data X Charges,1,healthdataxcharges,HealthDataXCharges.csv,Apache 2.0,"This dataset was **generated** with the `generatedata` website. Its intention is to make it possible to understand the influence of health data on health insurance prices.

It was **made for a project** whose objective was to predict charges based on the information provided by the patient. The intention is to provide personalized plans for each medical need.

&gt; ⚠ Fake data content. Not finished, not tested.",.csv
Health Insurance Coverage,1,health-insurance,states.csv,CC0-1.0,"# Context 

The Affordable Care Act (ACA) is the name for the comprehensive health care reform law and its amendments which addresses health insurance coverage, health care costs, and preventive care. The law was enacted in two parts: The Patient Protection and Affordable Care Act was signed into law on March 23, 2010 by President Barack Obama and was amended by the Health Care and Education Reconciliation Act on March 30, 2010.


# Content

This dataset provides health insurance coverage data for each state and the nation as a whole, including variables such as the uninsured rates before and after Obamacare, estimates of individuals covered by employer and marketplace healthcare plans, and enrollment in Medicare and Medicaid programs.


# Acknowledgements

The health insurance coverage data was compiled from the US Department of Health and Human Services and US Census Bureau.


# Inspiration

How has the Affordable Care Act changed the rate of citizens with health insurance coverage? Which states observed the greatest decline in their uninsured rate? Did those states expand Medicaid program coverage and/or implement a health insurance marketplace? What do you predict will happen to the nationwide uninsured rate in the next five years?",.csv
Health Outcomes,1,health-outcomes,s.csv,MIT,"
A health dataset outcome typically comprises patient-related information, including medical records, diagnostic results, treatment histories, and possibly demographic details. The dataset is structured to enable analysis and prediction of health outcomes, facilitating insights into disease trends, treatment efficacy, and overall patient well-being. It serves as a valuable resource for healthcare professionals, researchers, and data scientists to enhance medical understanding and improve patient care.",.csv
Healthcare Diabetes Dataset,1,healthcare-diabetes,Healthcare-Diabetes.csv,Apache 2.0,"

**Description:**
Welcome to the Diabetes Prediction Dataset, a valuable resource for researchers, data scientists, and medical professionals interested in the field of diabetes risk assessment and prediction. This dataset contains a diverse range of health-related attributes, meticulously collected to aid in the development of predictive models for identifying individuals at risk of diabetes. By sharing this dataset, we aim to foster collaboration and innovation within the data science community, leading to improved early diagnosis and personalized treatment strategies for diabetes.

**Columns:**
1. **Id:** Unique identifier for each data entry.
2. **Pregnancies:** Number of times pregnant.
3. **Glucose:** Plasma glucose concentration over 2 hours in an oral glucose tolerance test.
4. **BloodPressure:** Diastolic blood pressure (mm Hg).
5. **SkinThickness:** Triceps skinfold thickness (mm).
6. **Insulin:** 2-Hour serum insulin (mu U/ml).
7. **BMI:** Body mass index (weight in kg / height in m^2).
8. **DiabetesPedigreeFunction:** Diabetes pedigree function, a genetic score of diabetes.
9. **Age:** Age in years.
10. **Outcome:** Binary classification indicating the presence (1) or absence (0) of diabetes.

Utilize this dataset to explore the relationships between various health indicators and the likelihood of diabetes. You can apply machine learning techniques to develop predictive models, feature selection strategies, and data visualization to uncover insights that may contribute to more accurate risk assessments. As you embark on your journey with this dataset, remember that your discoveries could have a profound impact on diabetes prevention and management.

Please ensure that you adhere to ethical guidelines and respect the privacy of individuals represented in this dataset. Proper citation and recognition of this dataset's source are appreciated to promote collaboration and knowledge sharing.


Start your exploration of the Diabetes Prediction Dataset today and contribute to the ongoing efforts to combat diabetes through data-driven insights and innovations.",.csv
Healthcare Insurance,1,healthcare-insurance,insurance.csv,CC0-1.0,"This dataset contains information on the relationship between personal attributes (age, gender, BMI, family size, smoking habits), geographic factors, and their impact on medical insurance charges. It can be used to study how these features influence insurance costs and develop predictive models for estimating healthcare expenses.
**Age**: The insured person's age.

**Sex**: Gender (male or female) of the insured.

**BMI** (Body Mass Index): A measure of body fat based on height and weight.

**Children**: The number of dependents covered.

**Smoker**: Whether the insured is a smoker (yes or no).

**Region**: The geographic area of coverage.

**Charges**: The medical insurance costs incurred by the insured person.",.csv
Healthcare Insurance Expenses,1,healthcare-insurance-expenses,insurance.csv,DbCL-1.0,"1. Age: The insured person's age.

2. Sex: Gender (male or female) of the insured.

3. BMI (Body Mass Index): A measure of body fat based on height and weight.

4. Children: The number of dependents covered.

5. Smoker: Whether the insured is a smoker (yes or no).

6. Region: The geographic area of coverage.

7. Charges: The medical insurance costs incurred by the insured person.",.csv
Healthcare Investments and Length of Hospital Stay,1,healthcare-investments-and-length-of-hospital-stay,Healthcare_Investments_and_Hospital_Stay (1).csv,other,"### Context

The data were obtained from the OECD data base.
The research is limited to OECD countries where all data for 1990-2018 are available at the same time in the database.",.csv
Healthy Indian Recipes,1,healthy-indian-recipes,IndianHealthyRecipe.csv,Apache 2.0,"The dataset consists of Indian recipes. This dataset contains information about various dishes, including their names, descriptions, preparation and cooking times, spiciness level, popularity, ratings, dietary information, serving sizes, and cooking instructions.

### Attributes:

Dish Name: The name of the dish.
Description: A brief description or summary of the dish.
Spice: The level of spiciness associated with the dish.
Prep Time: The time required for preparing the dish.
Cook Time: The time required for cooking the dish.
Views: The number of views or popularity of the recipe.
Rating: The rating given to the recipe by users.
Number of Votes: The number of votes received for the recipe.
Heat: The level of heat associated with the dish.
Serves: The number of servings the recipe yields.
Dietary Info: Information about any dietary preferences or restrictions associated with the dish.
Ingredents: Step-by-step instructions on how to prepare the dish.
Instructions: Additional cooking methods or techniques used in the preparation of the dish.

### Use Case:

This dataset can be used for various purposes such as:

Analyzing popular Indian recipes and their ratings.
Exploring the relationship between preparation time, cooking time, and ratings.
Understanding dietary preferences and restrictions associated with Indian cuisine.
Developing recommendation systems for Indian recipes based on user preferences.
Predicting the popularity or rating of a recipe based on its attributes.",.csv
Healthy Lifestyle Cities Report 2021,1,healthy-lifestyle-cities-report-2021,healthy_lifestyle_city_2021.csv,CC0-1.0,"### Context

Healthy lifestyle metrics of top 44 cities.
1. Sunshine hours(City)
1. Cost of a bottle of water(City)
1. Obesity levels(Country)
1. Life expectancy(years) (Country)
1. Pollution(Index score) (City)
1. Annual avg. hours worked
1. Happiness levels(Country)
1. Outdoor activities(City)
1. Number of take out places(City)
1. Cost of a monthly gym membership(City)

### Acknowledgements
- Data source: Healthy Lifestyle Cities Report 2021 from https://www.lenstore.co.uk/research/healthy-lifestyle-report/
- Cover image credit: https://www.pexels.com/photo/unrecognizable-happy-people-jumping-in-sunset-6152103/


",.csv
Heart Attack Prediction,1,heart-attack-prediction,heart_attack_prediction_dataset.csv,Apache 2.0,"# About the Dataset
## Context
This dataset, compiled in 1988, encompasses information from four distinct databases: Cleveland, Hungary, Switzerland, and Long Beach V. Comprising 76 attributes, inclusive of the predicted attribute, the dataset has been predominantly utilized in published experiments focusing on a subset of 14 key features. The critical ""target"" field denotes the percentage of heart attack risk in patients.

Heart disease, a collective term for ailments impacting the heart and circulatory system, is a global health concern and a leading cause of disability. Given the heart's pivotal role in bodily functions, diseases affecting it can have far-reaching consequences on other organs and physiological processes. Various forms of heart disease exist, including those causing coronary artery narrowing, valve malfunctions, heart enlargement, and more, often leading to heart failure and heart attacks.

This dataset, specifically tailored to heart disease, provides a valuable resource for extracting insights that illuminate the significance of each feature and their interrelationships. In this analysis, our primary objective is to ascertain the probability of an individual being susceptible to a severe heart problem.

## Content
### Attribute Information:

```python
Age: Numeric (e.g., 52) 
Sex: Categorical (0: Female, 1: Male) 
Chest Pain Type: Categorical (0: Typical Angina, 1: Atypical Angina, 2: Non-anginal Pain, 3: Asymptomatic) 
Resting Blood Pressure: Numeric (e.g., 125) 
Serum Cholesterol: Numeric in mg/dL (e.g., 212) 
Fasting Blood Sugar: Categorical (0: &lt;= 120 mg/dL, 1: &gt; 120 mg/dL) 
Resting Electrocardiographic Results: Categorical (0: Normal, 1: Abnormality, 2: Hypertrophy) 
Maximum Heart Rate Achieved: Numeric (e.g., 168) 
Exercise-Induced Angina: Categorical (0: No, 1: Yes) 
Oldpeak (ST Depression): Numeric (e.g., 1.0) 
Slope of Peak Exercise ST Segment: Categorical (0: Upsloping, 1: Flat, 2: Downsloping) 
Number of Major Vessels Colored by Fluoroscopy: Numeric (0 to 3) 
Thalassemia: Categorical (0: Normal, 1: Fixed Defect, 2: Reversible Defect)
```

To uphold privacy, the dataset has undergone recent modifications, with the removal of patients' names and social security numbers, replaced with anonymized dummy values.",.csv
Heart Attack Risk Prediction Dataset,1,heart-attack-prediction-dataset,heart_attack_prediction_dataset.csv,other,"### Context

The Heart Attack Risk Prediction Dataset serves as a valuable resource for delving into the intricate dynamics of heart health and its predictors. Heart attacks, or myocardial infarctions, continue to be a significant global health issue, necessitating a deeper comprehension of their precursors and potential mitigating factors. This dataset encapsulates a diverse range of attributes including age, cholesterol levels, blood pressure, smoking habits, exercise patterns, dietary preferences, and more, aiming to elucidate the complex interplay of these variables in determining the likelihood of a heart attack. By employing predictive analytics and machine learning on this dataset, researchers and healthcare professionals can work towards proactive strategies for heart disease prevention and management. The dataset stands as a testament to collective efforts to enhance our understanding of cardiovascular health and pave the way for a healthier future.

### Content

This synthetic dataset provides a comprehensive array of features relevant to heart health and lifestyle choices, encompassing patient-specific details such as age, gender, cholesterol levels, blood pressure, heart rate, and indicators like diabetes, family history, smoking habits, obesity, and alcohol consumption. Additionally, lifestyle factors like exercise hours, dietary habits, stress levels, and sedentary hours are included. Medical aspects comprising previous heart problems, medication usage, and triglyceride levels are considered. Socioeconomic aspects such as income and geographical attributes like country, continent, and hemisphere are incorporated. The dataset, consisting of 8763 records from patients around the globe, culminates in a crucial binary classification feature denoting the presence or absence of a heart attack risk, providing a comprehensive resource for predictive analysis and research in cardiovascular health.

### Dataset Glossary (Column-wise)

* <b>Patient ID</b> - Unique identifier for each patient
* <b>Age</b> - Age of the patient
* <b>Sex</b> - Gender of the patient (Male/Female)
* <b>Cholesterol</b> - Cholesterol levels of the patient
* <b>Blood Pressure</b> - Blood pressure of the patient (systolic/diastolic)
* <b>Heart Rate</b> - Heart rate of the patient
* <b>Diabetes</b> - Whether the patient has diabetes (Yes/No)
* <b>Family History</b> - Family history of heart-related problems (1: Yes, 0: No)
* <b>Smoking</b> - Smoking status of the patient (1: Smoker, 0: Non-smoker)
* <b>Obesity</b> - Obesity status of the patient (1: Obese, 0: Not obese)
* <b>Alcohol Consumption</b> - Level of alcohol consumption by the patient (None/Light/Moderate/Heavy)
* <b>Exercise Hours Per Week</b> - Number of exercise hours per week
* <b>Diet</b> - Dietary habits of the patient (Healthy/Average/Unhealthy)
* <b>Previous Heart Problems</b> - Previous heart problems of the patient (1: Yes, 0: No)
* <b>Medication Use</b> - Medication usage by the patient (1: Yes, 0: No)
* <b>Stress Level</b> - Stress level reported by the patient (1-10)
* <b>Sedentary Hours Per Day</b> - Hours of sedentary activity per day
* <b>Income</b> - Income level of the patient
* <b>BMI</b> - Body Mass Index (BMI) of the patient
* <b>Triglycerides</b> - Triglyceride levels of the patient
* <b>Physical Activity Days Per Week</b> - Days of physical activity per week
* <b>Sleep Hours Per Day</b> - Hours of sleep per day
* <b>Country</b> - Country of the patient
* <b>Continent</b> - Continent where the patient resides
* <b>Hemisphere</b> - Hemisphere where the patient resides
* <b>Heart Attack Risk</b> - Presence of heart attack risk (1: Yes, 0: No)

### Structure of the Dataset

![](https://i.imgur.com/5cTusqA.png)

### Acknowledgement

This dataset is a synthetic creation generated using ChatGPT to simulate a realistic experience. Its purpose is to provide a platform for beginners and data enthusiasts, allowing them to create, enjoy, practice, and learn from a dataset that mirrors real-world scenarios. The aim is to foster learning and experimentation in a simulated environment, encouraging a deeper understanding of data analysis and interpretation.

Cover Photo by: <b><a href=""https://www.freepik.com/free-vector/human-internal-organ-with-heart_27289238.htm#query=heart%20organ&position=14&from_view=keyword&track=ais"">brgfx</a> on Freepik</b>

Thumbnail by: <b><a href=""https://www.freepik.com/free-vector/cardiology-clinic-hospital-department-healthy-heart-cardiovascular-prevention-healthcare-industry-idea-design-element-electrocardiogram-ekg-vector-isolated-concept-metaphor-illustration_12468752.htm#query=human%20heart&position=17&from_view=keyword&track=ais"">vectorjuice</a> on Freepik</b>",.csv
Heart Disease Classification ,1,heart-disease-classification,heart.csv,CC0-1.0,"# About
## Classification dataset for heart diseases prediction

![](https://www.hippocraticpost.com/wp-content/uploads/2022/07/shutterstock_1350064469-1200x704.jpg)

# Column Description

- age - age of the person (in years)
- sex - gender of the person (1 = male; 0 = female)
- chest_pain_type - type of the chest pain
 - Value 0: typical angina
 - Value 1: atypical angina
 - Value 2: non-anginal pain
 - Value 3: asymptomatic
- resting_bp - blood pressure while resting (in mm Hg on admission to the hospital)
- cholesterol - A person's serum cholesterol in mg/dl
- fasting_blood_sugar - Blood sugar while fasting  & [ &gt; 120 mg/dl ] (1 = true; 0 = false)
- restecg - ECG (electrocardiographic ) while resting 
 - Value 0: normal
 - Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of &gt; 0.05 mV)
 - Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria
- max_hr - Maximum heart rate achieved
- exang - exercise-induced angina (1 = yes; 0 = no)
 - Exercise-induced angina (AP) is a common complaint of cardiac patients, particularly when exercising in the cold. It usually happens during activity (exertion) and goes away with rest or angina medication. For example, pain, when walking uphill or in cold weather, maybe angina. Stable angina pain is predictable and usually similar to previous episodes of chest pain.
- oldpeak - ST depression induced by exercise relative to rest
 - Exercise-induced ST segment depression is considered a reliable ECG finding for the diagnosis of obstructive coronary atherosclerosis. ST-segment depression is believed as a common electrocardiographic sign of myocardial ischemia during exercise testing. Ischemia is generally defined as oxygen deprivation due to reduced perfusion. ST segment depression less than 0.5 mm is accepted in all leads. ST segment depression 0.5 mm or more is considered pathological.
- slope - the slope of the peak exercise ST segment
 - Value 0: upsloping
 - Value 1: flat
 - Value 2: downsloping
- num_major_vessels - no. of major vessels (0-3) colored by flourosopy
- thal - thalassemia 
 - 0: normal
 - 1: fixed defect
 - 2: reversable defect
 - People with thalassemia can get too much iron in their bodies, either from the disease or from frequent blood transfusions. Too much iron can result in damage to your heart, liver & endocrine system, which includes hormone-producing glands that regulate processes throughout your body.
- target -  
 - 0 = no disease
 - 1 = disease",.csv
Heart Disease Classification Dataset,1,heart-disease-classification-dataset,Heart Attack.csv,CC0-1.0,"### Context

Use this heart disease classification dataset to predict which patients are most likely to suffer from a heart disease in the near future using the features given. 


### Content

Data Dictionary

age: Displays the age of the individual.

sex: Displays the gender of the individual using the following format : 1 = male 0 = female

cp- Chest-pain type: displays the type of chest-pain experienced by the individual using the following format : 0 = typical angina 1 = atypical angina 2 = non — anginal pain 3 = asymptotic

trestbps- Resting Blood Pressure: displays the resting blood pressure value of an individual in mmHg (unit). anything above 130-140 is typically cause for concern.

chol- Serum Cholestrol: displays the serum cholesterol in mg/dl (unit)

fbs- Fasting Blood Sugar: compares the fasting blood sugar value of an individual with 120mg/dl. If fasting blood sugar &gt; 120mg/dl then : 1 (true) else : 0 (false) '&gt;126' mg/dL signals diabetes

restecg- Resting ECG : displays resting electrocardiographic results 0 = normal 1 = having ST-T wave abnormality 2 = left ventricular hyperthrophy

thalach- Max heart rate achieved : displays the max heart rate achieved by an individual.

exang- Exercise induced angina : 1 = yes 0 = no

oldpeak- ST depression induced by exercise relative to rest: displays the value which is an integer or float.

slope- Slope of the peak exercise ST segment : 0 = upsloping: better heart rate with excercise (uncommon) 1 = flat: minimal change (typical healthy heart) 2 = downsloping: signs of unhealthy heart

ca- Number of major vessels (0–3) colored by flourosopy : displays the value as integer or float.

thal : Displays the thalassemia : 1,3 = normal 6 = fixed defect 7 = reversible defect: no proper blood movement when excercising

target : Displays whether the individual is suffering from heart disease or not : 1 = yes 0 = no


### Acknowledgements

We wouldn't be here without the help of others. If you owe any attributions or thanks, include them here along with any citations of past research.
",.csv
Heart Disease Cleveland,1,heart-disease-cleveland,Heart_disease_cleveland_new.csv,CC-BY-SA-4.0,"###Context

The dataset is the Cleveland Heart Disease dataset taken from the UCI repository. The dataset consists of 303 individuals’ data. There are 14 columns in the dataset(which have been extracted from a larger set of 75). No missing values. The classification task is to predict whether an individual is suffering from heart disease or not. (0: absence, 1: presence)

original data:  https://archive.ics.uci.edu/ml/datasets/Heart+Disease

###Content

This database contains 13 attributes  and a target variable. It has 8 nominal values and 5 numeric values. The detailed description of all these features are as follows:

1. Age: Patients Age in years (Numeric)
2. Sex: Gender  (Male : 1; Female : 0) (Nominal)
3. cp: Type of chest pain experienced by patient. This term  categorized into 4 category.
                  0 typical angina, 1 atypical angina, 2 non- anginal pain, 3 asymptomatic (Nominal)
4. trestbps: patient's level of blood pressure at resting mode in mm/HG (Numerical)
5. chol: Serum cholesterol in mg/dl (Numeric)
6. fbs: Blood sugar levels on fasting &gt; 120 mg/dl represents as 1 in case of true and 0 as false (Nominal)
7. restecg: Result of electrocardiogram while at rest are represented in 3 distinct values 
               0 : Normal 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of &gt; 
                0.05 mV) 2: showing probable or definite left ventricular hypertrophyby Estes' criteria (Nominal)
8. thalach: Maximum heart rate achieved (Numeric)
9. exang: Angina induced by exercise 0 depicting NO 1 depicting Yes (Nominal)
10. oldpeak: Exercise induced ST-depression in relative with the state of rest (Numeric)
11. slope: ST segment measured in terms of slope during peak exercise  
                  0: up sloping; 1: flat; 2: down sloping(Nominal)
12. ca: The number of major vessels (0–3)(nominal)
13. thal: A blood disorder called thalassemia 
                 0: NULL 1: normal blood flow 2: fixed defect (no blood flow in some part of the heart)  3: reversible defect (a blood flow is observed but it is not normal(nominal)
14. target: It is the target variable which we have to predict 1 means patient is suffering from heart disease and 0 means patient is normal.

Variable to be predicted
------------------------
Absence (1) or presence (2) of heart disease

Cost Matrix

	 abse  pres
absence	  0	1
presence  50

where the rows represent the true values and the columns the predicted.

No missing values.

303 observations

### Acknowledgements


Creators:
1. Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.
2. University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.
3. University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.
4. V.A. Medical Center, Long Beach and Cleveland Clinic Foundation: Robert Detrano, M.D., Ph.D.

Donor:
David W. Aha (aha '@' ics.uci.edu) (714) 856-8779

####similar dataset : https://www.kaggle.com/datasets/ritwikb3/heart-disease-statlog


",.csv
Heart Disease Cleveland UCI,1,heart-disease-cleveland-uci,heart_cleveland_upload.csv,reddit-api,"### Context
The data is already presented in [https://www.kaggle.com/ronitf/heart-disease-uci](https://www.kaggle.com/ronitf/heart-disease-uci) but there are some descriptions and values that are wrong as discussed in [https://www.kaggle.com/ronitf/heart-disease-uci/discussion/105877](https://www.kaggle.com/ronitf/heart-disease-uci/discussion/105877). So, here is re-processed dataset that was cross-checked with the original data [https://archive.ics.uci.edu/ml/datasets/Heart+Disease](https://archive.ics.uci.edu/ml/datasets/Heart+Disease).

### Content
There are 13 attributes
1. age: age in years
2. sex: sex (1 = male; 0 = female)
3. cp: chest pain type
        -- Value 0: typical angina
        -- Value 1: atypical angina
        -- Value 2: non-anginal pain
        -- Value 3: asymptomatic
4. trestbps: resting blood pressure (in mm Hg on admission to the hospital)
5. chol: serum cholestoral in mg/dl 
6. fbs: (fasting blood sugar &gt; 120 mg/dl)  (1 = true; 0 = false)
7. restecg: resting electrocardiographic results
        -- Value 0: normal
        -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of &gt; 0.05 mV)
        -- Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria
8. thalach: maximum heart rate achieved
9. exang: exercise induced angina (1 = yes; 0 = no)
10. oldpeak = ST depression induced by exercise relative to rest
11. slope: the slope of the peak exercise ST segment
        -- Value 0: upsloping
        -- Value 1: flat
        -- Value 2: downsloping
12. ca: number of major vessels (0-3) colored by flourosopy
13. thal: 0 = normal; 1 = fixed defect; 2 = reversable defect 
and the label
14. condition: 0 = no disease, 1 = disease

### Acknowledgements
Data posted on Kaggle: [https://www.kaggle.com/ronitf/heart-disease-uci](https://www.kaggle.com/ronitf/heart-disease-uci)
Description of the data above: [https://www.kaggle.com/ronitf/heart-disease-uci/discussion/105877](https://www.kaggle.com/ronitf/heart-disease-uci/discussion/105877)
Original data [https://archive.ics.uci.edu/ml/datasets/Heart+Disease](https://archive.ics.uci.edu/ml/datasets/Heart+Disease)

Creators:
Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.
University Hospital, Zurich, Switzerland: William Steinbr
Creators:
Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.
University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.
University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.
V.A. Medical Center, Long Beach and Cleveland Clinic Foundation: Robert Detrano, M.D., Ph.D.
Donor: David W. Aha (aha '@' ics.uci.edu) (714) 856-8779

### Inspiration
With the attributes described above, can you predict if a patient has heart disease?",.csv
Heart Disease Data Compiled from UCI,1,heart-disease-data-compiled-from-uci,UCI_Heart_Disease_Dataset_Combined.csv,Attribution 4.0 International (CC BY 4.0),"Heart Disease Data combined from UCI repository of following places:

Cleveland, Hungary, Switzerland, and VA Long Beach


Features:
Age: Age of individual. 20-80
Sex: This is the gender of the individual. It is represented as a binary value where 1 stands for male and 0 stands for female.
ChestPainType: This categorizes the type of chest pain experienced by the individual. The values are:
Value 1: Typical angina, which is chest pain related to the heart.
Value 2: Atypical angina, which is chest pain not related to the heart.
Value 3: Non-anginal pain, which is typically sharp and non-continuous.
Value 4: Asymptomatic, meaning the individual experiences no symptoms.
RestingBP: This is the individual’s resting blood pressure (in mm Hg) when they are at rest.
Cholesterol: This is the individual’s cholesterol level, measured in mg/dl.
FastingBS: This indicates whether the individual’s fasting blood sugar is greater than 120 mg/dl. It is represented as a binary value where 1 stands for true and 0 stands for false.
MaxHR: This is the maximum heart rate achieved by the individual.
ExerciseAngina: This indicates whether the individual experiences angina (chest pain) induced by exercise. It is represented as a binary value where 1 stands for yes and 0&nbsp;stands&nbsp;for&nbsp;no.",.csv
Heart Disease Dataset,1,heart-disease-dataset,heart_statlog_cleveland_hungary_final.csv,MIT,"This dataset contains medical and behavioral information used to predict the risk of heart disease. It is highly useful for research and machine learning in the health field.

This dataset can be used for various data analysis and machine learning projects, such as:

- Creating predictive models for diagnosing heart disease.
- Determining the major risk factors for heart disease.
- Understanding the relationship between different variables and heart disease.",.csv
Heart Disease Dataset (Comprehensive),1,heart-statlog-cleveland-hungary-final,heart_statlog_cleveland_hungary_final.csv,CC0-1.0,"### Context

Heart Disease Dataset (Most comprehensive)


### Content

Heart disease is also known as Cardiovascular diseases (CVDs) are the number 1 cause of death globally, taking an estimated 17.9 million lives each year which is about 32% of all deaths globally. CVDs are a group of disorders of the heart and blood vessels and include coronary heart disease, cerebrovascular disease, rheumatic heart disease, and other conditions. Four out of 5CVD deaths are due to heart attacks and strokes, and one-third of these deaths occur prematurely in people under 70 years of age.

We have curated this dataset by combining different datasets already available independently but not combined before. W have combined them over 11 common features which makes it the largest heart disease dataset available for research purposes. The five datasets used for its curation are:
####Database:                 #####of instances:
1. Cleveland:                                          303
2. Hungarian:                                         294
3. Switzerland:                                       123
4. Long Beach VA:                                 200
5. Stalog (Heart) Data Set:                    270
#####Total                                            1190                                                       
 


### Acknowledgements

The dataset is taken from three other research datasets used in different research papers. The Nature article listing heart disease database and names of popular datasets used in various heart disease research is shared below.
https://www.nature.com/articles/s41597-019-0206-3


### Inspiration

Can you find interesting insight from the largest heart disease dataset available so far and build predictive model which can assist medical practitioners in detecting early-stage heart disease ?",.csv
Heart Disease Ensemble Classifier,1,heartdiseaseensembleclassifier,Heart_Disease_Data.csv,CC0-1.0,"# Context 

Just throwing it out their for anyone and everyone that is interested in heart disease.


# Content

Dataset consisting of 14 attributes and 303 observations that were used for the purpose of heart disease classification of a given patient.


# Acknowledgements

Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.
University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.
University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.
V.A. Medical Center, Long Beach and Cleveland Clinic Foundation: Robert Detrano, M.D., Ph.D


# Inspiration

I'd like to have outside input on this model and create a hybrid classifier that can be used by MD's in underserved communities.",.csv
Heart Disease Health Indicators Dataset,1,heart-disease-health-indicators-dataset,heart_disease_health_indicators_BRFSS2015.csv,CC0-1.0,"### Context

Heart Disease is among the most prevalent chronic diseases in the United States, impacting millions of Americans each year and exerting a significant financial burden on the economy. In the United States alone, heart disease claims roughly 647,000 lives each year — making it the leading cause of death. The buildup of plaques inside larger coronary arteries, molecular changes associated with aging, chronic inflammation, high blood pressure, and diabetes are all causes of and risk factors for heart disease.

While there are different types of coronary heart disease, the majority of individuals only learn they have the disease following symptoms such as chest pain, a heart attack, or sudden cardiac arrest. This fact highlights the **importance of preventative measures and tests** that can accurately predict heart disease in the population prior to negative outcomes like myocardial infarctions (heart attacks) taking place.

The Centers for Disease Control and Prevention has identified high blood pressure, high blood cholesterol, and smoking as three key risk factors for heart disease. Roughly half of Americans have at least one of these three risk factors. The National Heart, Lung, and Blood Institute highlights a wider array of factors such as Age, Environment and Occupation, Family History and Genetics, Lifestyle Habits, Other Medical Conditions, Race or Ethnicity, and Sex for clinicians to use in diagnosing coronary heart disease. Diagnosis tends to be driven by an initial survey of these common risk factors followed by bloodwork and other tests. 

### Content

The Behavioral Risk Factor Surveillance System (BRFSS) is a health-related telephone survey that is collected annually by the CDC. Each year, the survey collects responses from over 400,000 Americans on health-related risk behaviors, chronic health conditions, and the use of preventative services. It has been conducted every year since 1984. For this project, I downloaded a csv of the dataset available on Kaggle for the year 2015. This original dataset contains responses from 441,455 individuals and has 330 features. These features are either questions directly asked of participants, or calculated variables based on individual participant responses.

This dataset contains 253,680 survey responses from cleaned BRFSS 2015 to be used primarily for the binary classification of heart disease. Not that there is strong class imbalance in this dataset. 229,787 respondents do not have/have not had heart disease while 23,893 have had heart disease. The question to be explored is:

####**1. To what extend can survey responses from the BRFSS be used for predicting heart disease risk?**

and

####**2. Can a subset of questions from the BRFSS be used for preventative health screening for diseases like heart disease?**


### Acknowledgements

It it important to reiterate that I did not create this dataset, it is just a cleaned and consolidated dataset created from the BRFSS 2015 dataset already on Kaggle. That dataset can be found [here](https://www.kaggle.com/cdc/behavioral-risk-factor-surveillance-system) and the notebook I used for the data cleaning can be found [here](https://www.kaggle.com/alexteboul/heart-disease-health-indicators-dataset-notebook).

### Inspiration

Let's build some predictive models for for heart disease.",.csv
Heart Disease Prediction,1,heart-disease-prediction,Heart_Disease_Prediction.csv,CC0-1.0,"Context: The leading cause of death in the developed world is heart disease. Therefore there needs to be work done to help prevent the risks of of having a heart attack or stroke.

Content: Use this dataset to predict which patients are most likely to suffer from a heart disease in the near future using the features given.

Acknowledgement: This data comes from the University of California Irvine's Machine Learning Repository at https://archive.ics.uci.edu/ml/datasets/Heart+Disease.",.csv
Heart Disease Prediction Dataset,1,heart-disease-diagnosis-dataset,dataset_heart.csv,CC0-1.0,"**Attributes types :** Real: 1,4,5,8,10,12 | Ordered:11 | Binary: 2,6,9 | Nominal:7,3,13

**Variable to be predicted:** Absence (1) or presence (2) of heart disease

Cost Matrix
```
	      abse  pres
absence    0  	1
presence   5 	 0
```
where the rows represent the true values and the columns the predicted.
Total 270 observations and No missing values.
Attribute Information:
------------------------
      -- 1. age       
      -- 2. sex       
      -- 3. chest pain type  (4 values)       
      -- 4. resting blood pressure  
      -- 5. serum cholestoral in mg/dl      
      -- 6. fasting blood sugar &gt; 120 mg/dl       
      -- 7. resting electrocardiographic results  (values 0,1,2) 
      -- 8. maximum heart rate achieved  
      -- 9. exercise induced angina    
      -- 10. oldpeak = ST depression induced by exercise relative to rest   
      -- 11. the slope of the peak exercise ST segment     
      -- 12. number of major vessels (0-3) colored by flourosopy        
      -- 13. thal: 3 = normal; 6 = fixed defect; 7 = reversable defect
      -- 14. Target(Absence (1) or presence (2) of heart disease) 


#### For more Info About Dataset: [Link](https://archive.ics.uci.edu/ml/datasets/Statlog+%28Heart%29)",.csv
Heart Disease and Stroke Prevention,1,heart-disease-and-stroke-prevention,dataset.csv,DbCL-1.0,"### Context
This is one of the dataset provided by the National Cardiovascular Disease Surveillance System. 

The system is designed to integrate multiple indicators from many data sources to provide a comprehensive picture of the public health burden of CVDs and associated risk factors in the United States. 


### Content

The data are organized by location (national, regional, state, and selected sites) and indicator, and they include CVDs (e.g., heart failure) and risk factors (e.g., hypertension). The data can be plotted as trends and stratified by age group, sex, and race/ethnicity.

2011 to present. BRFSS is a continuous, state-based surveillance system that collects information about modifiable risk factors for chronic diseases and other leading causes of death. 


### Acknowledgements

Indicators from this data source have been computed by personnel in CDC's Division for Heart Disease and Stroke Prevention (DHDSP). ",.csv
Heart Failure Prediction,1,heart-failure-clinical-data,heart_failure_clinical_records_dataset.csv,Attribution 4.0 International (CC BY 4.0),"# About this dataset
&gt; Cardiovascular diseases (CVDs) are the **number 1 cause of death globally**, taking an estimated **17.9 million lives each year**, which accounts for **31% of all deaths worlwide**.
Heart failure is a common event caused by CVDs and this dataset contains 12 features that can be used to predict mortality by heart failure.

&gt; Most cardiovascular diseases can be prevented by addressing behavioural risk factors such as tobacco use, unhealthy diet and obesity, physical inactivity and harmful use of alcohol using population-wide strategies.

&gt; People with cardiovascular disease or who are at high cardiovascular risk (due to the presence of one or more risk factors such as hypertension, diabetes, hyperlipidaemia or already established disease) need **early detection** and management wherein a machine learning model can be of great help.

# How to use this dataset
&gt; - Create a model for predicting mortality caused by Heart Failure.
- Your kernel can be featured here!
- [More datasets](https://www.kaggle.com/andrewmvd/datasets)



# Acknowledgements
If you use this dataset in your research, please credit the authors
&gt; ### Citation
Davide Chicco, Giuseppe Jurman: Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone. BMC Medical Informatics and Decision Making 20, 16 (2020). ([link](https://doi.org/10.1186/s12911-020-1023-5))

&gt; ### License
CC BY 4.0

&gt; ### Splash icon
Icon by [Freepik](https://www.flaticon.com/authors/freepik), available on [Flaticon](https://www.flaticon.com/free-icon/heart_1186541).

&gt; ### Splash banner
Wallpaper by [jcomp](https://br.freepik.com/jcomp), available on [Freepik](https://br.freepik.com/fotos-gratis/simplesmente-design-minimalista-com-estetoscopio-de-equipamento-de-medicina-ou-phonendoscope_5018002.htm#page=1&query=cardiology&position=3).",.csv
Heart Failure Prediction - Clinical Records 🏥,1,heart-failure-prediction-clinical-records,heart_failure_clinical_records.csv,CC0-1.0,"##  **Context:**

This dataset contains the medical records of 5000 patients who had heart failure, collected during their follow-up period, where each patient profile has 13 clinical features.

##  **Attribute Information:**

- age: age of the patient (years)
- anaemia: decrease of red blood cells or hemoglobin (boolean)
- creatinine phosphokinase  (CPK): level of the CPK enzyme in the blood (mcg/L)
- diabetes: if the patient has diabetes (boolean)
- ejection fraction: percentage of blood leaving the heart at each contraction  (percentage)
- high blood pressure: if the patient has hypertension (boolean)
- platelets: platelets in the blood (kiloplatelets/mL)
- sex: woman or man (binary)
- serum creatinine: level of serum creatinine in the blood (mg/dL)
- serum sodium: level of serum sodium in the blood (mEq/L)
- smoking: if the patient smokes or not (boolean)
- time: follow-up period (days)
- DEATH_EVENT: if the patient died during the follow-up period (boolean)

## **Citation:**

Heart Failure Clinical Records. (2020). UCI Machine Learning Repository. https://doi.org/10.24432/C5Z89R.",.csv
Heart Failure Prediction Dataset,1,heart-failure-prediction,heart.csv,ODbL-1.0,"### Similar Datasets

- Hepatitis C Dataset: [LINK](https://www.kaggle.com/fedesoriano/hepatitis-c-dataset)
- Body Fat Prediction Dataset: [LINK](https://www.kaggle.com/fedesoriano/body-fat-prediction-dataset)
- Cirrhosis Prediction Dataset: [LINK](https://www.kaggle.com/fedesoriano/cirrhosis-prediction-dataset)
- Stroke Prediction Dataset: [LINK](https://www.kaggle.com/fedesoriano/stroke-prediction-dataset)
- Stellar Classification Dataset - SDSS17: [LINK](https://www.kaggle.com/fedesoriano/stellar-classification-dataset-sdss17)
- Wind Speed Prediction Dataset: [LINK](https://www.kaggle.com/datasets/fedesoriano/wind-speed-prediction-dataset)
- Spanish Wine Quality Dataset: [LINK](https://www.kaggle.com/datasets/fedesoriano/spanish-wine-quality-dataset)


### Context

Cardiovascular diseases (CVDs) are the number 1 cause of death globally, taking an estimated 17.9 million lives each year, which accounts for 31% of all deaths worldwide. Four out of 5CVD deaths are due to heart attacks and strokes, and one-third of these deaths occur prematurely in people under 70 years of age. Heart failure is a common event caused by CVDs and this dataset contains 11 features that can be used to predict a possible heart disease.

People with cardiovascular disease or who are at high cardiovascular risk (due to the presence of one or more risk factors such as hypertension, diabetes, hyperlipidaemia or already established disease) need early detection and management wherein a machine learning model can be of great help.


### Attribute Information

1. Age: age of the patient [years]
1. Sex: sex of the patient [M: Male, F: Female]
1. ChestPainType: chest pain type [TA: Typical Angina, ATA: Atypical Angina, NAP: Non-Anginal Pain, ASY: Asymptomatic]
1. RestingBP: resting blood pressure [mm Hg]
1. Cholesterol: serum cholesterol [mm/dl]
1. FastingBS: fasting blood sugar [1: if FastingBS &gt; 120 mg/dl, 0: otherwise]
1. RestingECG: resting electrocardiogram results [Normal: Normal, ST: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of &gt; 0.05 mV), LVH: showing probable or definite left ventricular hypertrophy by Estes' criteria]
1. MaxHR: maximum heart rate achieved [Numeric value between 60 and 202]
1. ExerciseAngina: exercise-induced angina [Y: Yes, N: No]
1. Oldpeak: oldpeak = ST [Numeric value measured in depression]
1. ST_Slope: the slope of the peak exercise ST segment [Up: upsloping, Flat: flat, Down: downsloping]
1. HeartDisease: output class [1: heart disease, 0: Normal]



### Source

This dataset was created by combining different datasets already available independently but not combined before. In this dataset, 5 heart datasets are combined over 11 common features which makes it the largest heart disease dataset available so far for research purposes. The five datasets used for its curation are:

- Cleveland: 303 observations
- Hungarian: 294 observations
- Switzerland: 123 observations
- Long Beach VA: 200 observations
- Stalog (Heart) Data Set: 270 observations

Total: 1190 observations
Duplicated: 272 observations 

`Final dataset: 918 observations`

Every dataset used can be found under the Index of heart disease datasets from UCI Machine Learning Repository on the following link: [https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/](https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/)


### Citation

&gt; fedesoriano. (September 2021). Heart Failure Prediction Dataset. Retrieved [Date Retrieved] from https://www.kaggle.com/fedesoriano/heart-failure-prediction.


### Acknowledgements

Creators:

1. Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.
1. University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.
1. University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.
1. V.A. Medical Center, Long Beach and Cleveland Clinic Foundation: Robert Detrano, M.D., Ph.D.

Donor:
David W. Aha (aha '@' ics.uci.edu) (714) 856-8779
",.csv
Heart Failure Prediction dataset,1,heart-failure-prediction-dataset,heart.csv,MIT,"The Heart Failure Prediction dataset is aimed at predicting the likelihood of heart disease events based on clinical features of patients. This dataset comprises 11 attributes that encapsulate various aspects relevant to cardiovascular health. The data is collected to aid in the development of predictive models for identifying individuals at risk of heart failure, enabling proactive intervention and personalized healthcare.

**Attributes:**

1. Age: Age of the patient in years.
2. Sex: Gender of the patient (M: Male, F: Female).
3. ChestPain: Type of chest pain experienced by the patient (TA: Typical Angina, ATA: Atypical Angina, NAP: 4. Non-Anginal Pain, ASY: Asymptomatic).
5. RestingBP: Resting blood pressure measured in mm Hg (Normal range: 120/80 mm Hg).
6. Cholesterol: Serum cholesterol level in the blood measured in mg/dL (Normal level: below 200 mg/dL for adults).
7. FastingBS: Fasting blood sugar level measured in mg/dL (Normal range: &lt;100 mg/dL for non-diabetic individuals, 100-125 mg/dL for diabetic individuals).
8. RestingECG: Results of resting electrocardiogram (ECG) (Normal: Normal, ST: Abnormal ST-T wave, LVH: Probable or definite left ventricular hypertrophy).
9. MaxHR: Maximum heart rate achieved during testing (Numeric value between 60 and 202).
10. ExerciseAngina: Presence of exercise-induced angina (Y: Yes, N: No).
11. Oldpeak: ST depression induced by exercise relative to rest (Numeric value).
12. ST_Slope: Slope of the peak exercise ST segment (Up: Upsloping, Flat: Flat, Down: Downsloping).

**Target Variable:**

HeartDisease: Output class indicating the presence of heart disease (1: Heart disease, 0: Normal).
This dataset provides a comprehensive set of attributes that reflect various physiological and clinical factors associated with heart health. By leveraging machine learning techniques on this dataset, healthcare professionals and researchers can develop predictive models to assist in early detection and management of heart failure, ultimately improving patient outcomes and reducing the burden of cardiovascular diseases.",.csv
Heart Health Stats Dataset,1,heart-health-stats-dataset,Heart_health.csv,CC-BY-NC-SA-4.0,"This dataset comprises demographic information, vital signs, and heart health status indicators for individuals. It includes features such as age, gender, blood pressure, cholesterol levels, and whether the individual has experienced a heart attack. The dataset is valuable for analyzing trends related to cardiovascular health and assessing the risk factors associated with heart disease. Researchers and healthcare professionals can utilize this data to identify patterns, develop predictive models, and formulate personalized interventions for heart disease prevention and management.",.csv
Heart_Disease_Indicators,1,heart-disease-indicators,heart_disease_health_indicators.csv,CC0-1.0,"This dataset contains various health-related indicators for a sample of individuals. Here's a brief description of each column:

- HeartDiseaseorAttack: Indicates whether the individual has had a heart disease or heart attack (binary: 0 = No, 1 = Yes).
- HighBP: High blood pressure status (binary: 0 = No, 1 = Yes).
- HighChol: High cholesterol status (binary: 0 = No, 1 = Yes).
- CholCheck: Frequency of cholesterol check (categorical).
- BMI: Body Mass Index (continuous).
- Smoker: Smoking status (binary: 0 = No, 1 = Yes).
- Stroke: History of stroke (binary: 0 = No, 1 = Yes).
- Diabetes: Diabetes status (binary: 0 = No, 1 = Yes).
- PhysActivity: Level of physical activity (categorical).
- Fruits: Frequency of fruit consumption (categorical).
- Veggies: Frequency of vegetable consumption (categorical).
- HvyAlcoholConsump: Heavy alcohol consumption status (binary: 0 = No, 1 = Yes).
- AnyHealthcare: Access to any healthcare (binary: 0 = No, 1 = Yes).
- NoDocbcCost: No doctor because of cost (binary: 0 = No, 1 = Yes).
- GenHlth: General health assessment (categorical).
- MentHlth: Mental health assessment (categorical).
- PhysHlth: Physical health assessment (categorical).
- DiffWalk: Difficulty walking status (binary: 0 = No, 1 = Yes).
- Sex: Gender of the individual (binary: 0 = Female, 1 = Male).
- Age: Age of the individual (continuous).
- Education: Educational level (categorical).
-Income: Income level (categorical).

This dataset contains a variety of health-related information, lifestyle factors, and demographics for a group of individuals, making it suitable for exploring correlations and potential risk factors for heart disease and other health conditions.

",.csv
Heat Flux,1,heat-flux,s.csv,MIT,"Explore cutting-edge feature imputation techniques applied to a heat flux dataset, ensuring data completeness for optimal analysis and modeling. Do checkout and Support!",.csv
Heights and Weights Dataset,1,heights-and-weights-dataset,SOCR-HeightWeight.csv,other,"### Content
This is a simple dataset to start with. It contains only the height (inches) and weights (pounds) of 25,000 different humans of 18 years of age. This dataset can be used to build a model that can predict the heights or weights of a human.

### Acknowledgement
Link: http://socr.ucla.edu/docs/resources/SOCR_Data/SOCR_Data_Dinov_020108_HeightsWeights.html
Scraped the aforementioned HTML page using a Regex Parser. (BeautifulSoup - Python)

### Inspiration
Build a predictive model for determining height or weight of a person. Implement a regression model that will be used for predicting height or weight.",.csv
Heights and weights,1,heights-and-weights,data.csv,CC0-1.0,"### Context

This data set gives average masses for women as a function of their height in a sample of American women of age 30–39.


### Content

The data contains the variables

Height (m)  
Weight (kg)


### Acknowledgements

https://en.wikipedia.org/wiki/Simple_linear_regression ",.csv
Hemoglobin Data,1,hemoglobin-data,Hemoglobin Data.csv,Apache 2.0,"# **Title: Hemoglobin Data**

## **Description:**
This dataset contains hemoglobin (Hb) values along with corresponding image analysis metrics extracted from images of blood samples. The data was collected using a custom imaging system capable of capturing various parameters related to hemoglobin concentration and image characteristics. 

## **Columns:**
- **image_name:** Name of the image file associated with the blood sample.
- **hbvalues:** Hemoglobin values measured in the blood sample.
- **model:** Model or device used for hemoglobin measurement.
- **mid_b_mean, mid_g_mean, mid_r_mean:** Mean values of blue, green, and red channels in the middle portion of the image.
- **mid_b_median, mid_g_median, mid_r_median:** Median values of blue, green, and red channels in the middle portion of the image.
- **mid_l_mean, mid_a_mean, mid_br_mean:** Mean values of luminance, 'a' (green-red), and 'b' (blue-yellow) channels in the middle portion of the image.
- **mid_l_median, mid_a_median, mid_br_median:** Median values of luminance, 'a' (green-red), and 'b' (blue-yellow) channels in the middle portion of the image.
- **mid_h_mean, mid_s_mean, mid_v_mean:** Mean values of hue, saturation, and value (brightness) in the middle portion of the image.
- **mid_h_median, mid_s_median, mid_v_median:** Median values of hue, saturation, and value (brightness) in the middle portion of the image.

## **Use Case:**
This dataset can be valuable for researchers and practitioners in the medical field, particularly those interested in hematology and image analysis. It provides a unique opportunity to explore the relationship between hemoglobin levels and various image-based features, potentially aiding in the development of non-invasive diagnostic tools or analytical techniques for blood-related disorders.
",.csv
Hepatitis C Prediction Dataset,1,hepatitis-c-dataset,HepatitisCdata.csv,ODbL-1.0,"### Context

The data set contains laboratory values of blood donors and Hepatitis C patients and demographic values like age. The data was obtained from UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/HCV+data


### Content

All attributes except Category and Sex are numerical.
Attributes 1 to 4 refer to the data of the patient:
1) X (Patient ID/No.)
2) Category (diagnosis) (values: '0=Blood Donor', '0s=suspect Blood Donor', '1=Hepatitis', '2=Fibrosis', '3=Cirrhosis')
3) Age (in years)
4) Sex (f,m)
Attributes 5 to 14 refer to laboratory data:
5) ALB
6) ALP
7) ALT
8) AST
9) BIL
10) CHE
11) CHOL
12) CREA
13) GGT
14) PROT

The target attribute for classification is Category (2): blood donors vs. Hepatitis C patients (including its progress ('just' Hepatitis C, Fibrosis, Cirrhosis).


### Acknowledgements

Creators: Ralf Lichtinghagen, Frank Klawonn, Georg Hoffmann
Donor: Ralf Lichtinghagen: Institute of Clinical Chemistry; Medical University Hannover (MHH); Hannover, Germany; lichtinghagen.ralf '@' mh-hannover.de
Donor: Frank Klawonn; Helmholtz Centre for Infection Research; Braunschweig, Germany; frank.klawonn '@' helmholtz-hzi.de
Donor: Georg Hoffmann; Trillium GmbH; Grafrath, Germany; georg.hoffmann '@' trillium.de


### Relevant Papers

Lichtinghagen R et al. J Hepatol 2013; 59: 236-42
Hoffmann G et al. Using machine learning techniques to generate laboratory diagnostic pathways â€“ a case study. J Lab Precis Med 2018; 3: 58-67


### Other Datasets

- Stroke Prediction Dataset: [LINK](https://www.kaggle.com/fedesoriano/stroke-prediction-dataset)
- Wind Speed Prediction Dataset: [LINK](https://www.kaggle.com/datasets/fedesoriano/wind-speed-prediction-dataset)
- Spanish Wine Quality Dataset: [LINK](https://www.kaggle.com/datasets/fedesoriano/spanish-wine-quality-dataset)
",.csv
High Dimensional Datascape,1,high-dimensional-datascape,all_data.csv,CC0-1.0,"### Context
This dataset was created to work on various techniques like Dimensionality reduction, Statistical Inference and Classification.

### Content
230 rows and 537 columns of numerical data including labels

### Source
Web scraped",.csv
Highest Grossing Mobile Games,1,highest-grossing-mobile-games,mobile-games.csv,CC0-1.0,"This is a dataset of mobile video games that have generated at least $100 million in gross revenue. Among them, there are more than 30 mobile games that have grossed more than $1 billion. The video game company with the highest number of titles on the list is Tencent, which publishes and/or owns 12 games on the list, including three in the top ten.

Tabular data includes:

- `Game`
- `Revenue`
- `Initial release`
- `Publisher(s)`
- `Genre(s)`",.csv
Historical data,1,historical-data,gdp-per-capita-maddison new.csv,CC0-1.0,"this graph was created in OurDataWorld:

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fc099e1eee01f448c6c8f40c2d83de5eb%2Fgraph1.png?generation=1715453565007185&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Facca62b608d0c4817206ea2d9f671a77%2Fgraph3.png?generation=1715453571722599&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fdb52a1fa0b9db9f7d84bacedb217e160%2Fgraph2.png?generation=1715453577861078&alt=media)

What you should know about this indicator
This GDP per capita indicator provides information on economic growth and income levels in the very long run. Some country estimates are available as far back as 1 CE and regional estimates as far back as 1820 CE.
This data is adjusted for inflation and for differences in the cost of living between countries.
This data is expressed in international-$ at 2011 prices, using a combination of 2011 and 1990 PPPs for historical data.
Time series for former countries and territories are calculated forward in time by estimating values based on their last official borders.
For more regularly updated estimates of GDP per capita, see the World Bank's indicator.

Real GDP per capita in 2011$

In two ways, this analysis leads to departures from the original Maddison approach and closer to the multiple benchmark approach as developed by the PWT. There is, to begin with, no doubt that the 2011 PPPs and the related estimates of GDP per capita reflect the relative levels of GDP per capita in the world economy today better than the combination of the 1990 benchmark and growth rates of GDP per capita according to national accounts. This information should be taken into account. At the same time, the underlying rule within the current Maddison Database is that economic growth rates of countries in the dataset should be identical or as close as possible to growth rates according to the national accounts (which is also the case for the pre 1990 period). For the post-1990 period we therefore decided to integrate the 2011 benchmarks by adapting the growth rates of GDP per capita in the period 1990–2011 to align the two (1990 and 2011) benchmarks. We estimated the difference between the combination of the 1990 benchmark and the growth rates of GDP (per capita) between 1990 and 2011 according to the national accounts, and annual growth rate from the 1990 benchmark to the 2011 benchmark. This difference is then evenly distributed to the growth rate of GDP per capita between 1990 and 2011; in other words, we added a country specific correction (constant for all years between 1990 and 2011) to the annual national account rate of growth to connect the 1990 benchmark to the 2011 benchmark. Growth after 2011 is, in the current update, exclusively based on the growth rates of GDP per capita according to national accounts.

We also use the collected set of historical benchmark estimates to fine tune the dataset for the pre-1940 period, but only in those cases where the quality of the benchmark was high and there were multiple benchmarks to support a revision. The most important correction concerns the US/UK comparison. The conventional picture, based on the original 1990 Maddison estimates, indicated that the US overtook the UK as the world leader in the early years of the 20th century. This finding was first criticized by Ward and Devereux (2003), who argued, based on alternative measures of PPP-adjusted benchmarks between 1870 and 1930, that the United States was already leading the United Kingdom in terms of GDP per capita in the 1870s. This conclusion was criticized by Broadberry (2003).

New evidence, however, suggests a more complex picture: in the 18th century, real incomes in the US (settler colonies only, not including indigenous populations) were probably higher than those in the UK (Lindert & Williamson, 2016a). Until about 1870, growth was both exten- sive (incorporating newly settled territory) and intensive (considering the growth of cities and industry at the east coast), but on balance, the US may—in terms of real income—have lagged behind the UK. After 1870, intensive growth becomes more important, and the US slowly gets the upper hand. This pattern is consistent with direct benchmark comparison of the income of both countries for the period 1907–1909 (Woltjer, 2015). This shows that GDP per capita for the United States in those years was 26% higher than in the United Kingdom. We have used Woltjer’s (2015) benchmark to correct the GDP series of the two countries. Projecting this benchmark into the 19th century with the series of GDP per capita of both countries results in the two countries achieving parity in 1880. This is close to Prados de la Escosura’s conjecture based on his short- cut method (Prados de la Escosura, 2000), and even closer to the Lindert and Williamson (2016a) results.",.csv
Historical sales data of a company,1,historical-sales-data-on-daily-basis-of-a-company,Historical_Data.csv,CC0-1.0,"### Context

The data set (Historical data) contains sales record (on daily basis ) from different countries of company. It is ideal for time series analysis.

### Content

The data set (Historical data) contains sales record (on daily basis ) from different countries from a company which sell products online between 2017 to 2019.
You will observe that for some dates the sales were not made. Add 0 as ‘Sold_Units’ and ‘Article_ID’ for such dates.


### Acknowledgements

We wouldn't be here without the help of others. If you owe any attributions or thanks, include them here along with any citations of past research.


### Inspiration

Your data will be in front of the world's largest data science community. What questions do you want to see answered?",.csv
Hitters,1,hitters,Hitters.csv,other,"### Context

This dataset is part of the R-package ISLR and is used in the related book by G. James et al. (2013) ""An Introduction to Statistical Learning with applications in R"" to demonstrate how Ridge regression and the LASSO are performed using R.



### Content

This dataset was originally taken from the StatLib library which is maintained at Carnegie Mellon University. This is part of the data that was used in the 1988 ASA Graphics Section Poster Session. The salary data were originally from Sports Illustrated, April 20, 1987. The 1986 and career statistics were obtained from The 1987 Baseball Encyclopedia Update published by Collier Books, Macmillan Publishing Company, New York.

Format
A data frame with 322 observations of major league players on the following 20 variables.
AtBat Number of times at bat in 1986
Hits Number of hits in 1986
HmRun Number of home runs in 1986
Runs Number of runs in 1986
RBI Number of runs batted in in 1986
Walks Number of walks in 1986
Years Number of years in the major leagues
CAtBat Number of times at bat during his career
CHits Number of hits during his career
CHmRun Number of home runs during his career
CRuns Number of runs during his career
CRBI Number of runs batted in during his career
CWalks Number of walks during his career
League A factor with levels A and N indicating player’s league at the end of 1986
Division A factor with levels E and W indicating player’s division at the end of 1986
PutOuts Number of put outs in 1986
Assists Number of assists in 1986
Errors Number of errors in 1986
Salary 1987 annual salary on opening day in thousands of dollars
NewLeague A factor with levels A and N indicating player’s league at the beginning of 1987



### Acknowledgements

Please cite/acknowledge: Games, G., Witten, D., Hastie, T., and Tibshirani, R. (2013) An Introduction to Statistical Learning  with applications in R, www.StatLearning.com, Springer-Verlag, New York.



### Inspiration

This upload shall enable actuarial kernels with R and Python",.csv
Hitters Baseball Data,1,hitters-baseball-data,Hitters.csv,DbCL-1.0,"# Baseball Data
## Description
Major League Baseball Data from the 1986 and 1987 seasons.

## Usage
Hitters

## Format
A data frame with 322 observations of major league players on the following 20 variables.

- AtBat: Number of times at bat in 1986

- Hits: Number of hits in 1986

- HmRun: Number of home runs in 1986

- Runs: Number of runs in 1986

- RBI: Number of runs batted in in 1986

- Walks: Number of walks in 1986

- Years: Number of years in the major leagues

- CAtBat: Number of times at bat during his career

- CHits: Number of hits during his career

- CHmRun: Number of home runs during his career

- CRuns: Number of runs during his career

- CRBI: Number of runs batted in during his career

- CWalks: Number of walks during his career

- League: A factor with levels A and N indicating player's league at the end of 1986

- Division: A factor with levels E and W indicating player's division at the end of 1986

- PutOuts: Number of put outs in 1986

- Assists: Number of assists in 1986

- Errors: Number of errors in 1986

- Salary: 1987 annual salary on opening day in thousands of dollars

- NewLeague: A factor with levels A and N indicating player's league at the beginning of 1987

## Source
This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University. This is part of the data that was used in the 1988 ASA Graphics Section Poster Session. The salary data were originally from Sports Illustrated, April 20, 1987. The 1986 and career statistics were obtained from The 1987 Baseball Encyclopedia Update published by Collier Books, Macmillan Publishing Company, New York.

## References
Games, G., Witten, D., Hastie, T., and Tibshirani, R. (2013) An Introduction to Statistical Learning with applications in R, www.StatLearning.com, Springer-Verlag, New York

## Examples
summary(Hitters)
lm(Salary~AtBat+Hits,data=Hitters)
--
Dataset imported from https://www.r-project.org.
",.csv
Hollywood Most Profitable Stories,1,hollywood-most-profitable-stories,HollywoodsMostProfitableStories.csv,CC0-1.0,"![](https://images.unsplash.com/photo-1515634928627-2a4e0dae3ddf?ixid=MXwxMjA3fDB8MHxzZWFyY2h8MTl8fG1vdmllfGVufDB8fDB8&ixlib=rb-1.2.1&auto=format&fit=crop&w=700&q=60)

### Context

Movies are one of the biggest industry in the world. In this dataset there are over 74 movies with the span from 2007 and 2012. People can take this data and see what genre or what year movies make the most.


### Content

There is title, genre, studio, different profitability, ratings, and year for movies released 2007-2012.

### Acknowledgements
Thanks to information is beautiful.net for providing with the dataset.
Thanks to Chris Murray on Unsplash for the banner photo.
",.csv
Home Price Index,1,hpindex,HPI_master.csv,CC0-1.0,"# Context 

The Federal Housing Finance Agency House Price Index (HPI) is a broad measure of the movement of single-family house prices. The HPI is a weighted, repeat-sales index, meaning that it measures average price changes in repeat sales or refinancings on the same properties.  The technical methodology for devising the index, collection, and publishing the data is at:
http://www.fhfa.gov/PolicyProgramsResearch/Research/PaperDocuments/1996-03_HPI_TechDescription_N508.pdf

# Content

Contains monthly and quarterly time series from January 1991 to August 2016 for the U.S., state, and MSA categories.  Analysis variables are the aggregate non-seasonally adjusted value and seasonally adjusted index values.  The index value is 100 beginning January 1991.  


# Acknowledgements

This data is found on Data.gov


# Inspiration

Can this data be combined with the corresponding census growth projections either at the state or MSA level to forecast 24 months out the highest and lowest home index values?",.csv
Honkai Star Rail Character Dataset,1,honkai-star-rail-character-data,hsr_character-data.csv,CC0-1.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F15070006%2F71e0f43b4660c1c161b7a9f9b7f4860d%2Ffuxuan.png?generation=1695433619779203&alt=media)


Discover the world of Honkai Star Rail characters through this dataset. This dataset offers a detailed collection of character statistics and hidden attributes from the game developed by MIHOYO. Sourced from datamining efforts and fueled by my passion for the game, this dataset provides insights into character attributes like attack, health, defense, energy regeneration, break values, and more. Dive into the numbers and uncover the mechanics that drive the gameplay of Honkai Star Rail. Perfect for gamers, data enthusiasts, and researchers interested in exploring the quantitative aspects of character performance in the game.

## Disclaimer
All data belongs to **COGNOSPHERE** and are not mine.
",.csv
Horse Colic Dataset,1,horse-colic,horse.csv,CC0-1.0,"### Context 

Predict whether or not a horse can survive based upon past medical conditions.  

Noted by the ""outcome"" variable in the data.  


### Content
All of the binary representation have been converted into the words they actually represent. However, a fuller description is provided by the data dictionary (`datadict.txt`).

There are a lot of NA's in the data. This is the real struggle here. Try to find a way around it through imputation or other means.


### Acknowledgements

This dataset was originally published by the UCI Machine Learning Database: http://archive.ics.uci.edu/ml/datasets/Horse+Colic",.csv
Horse Survival Dataset,1,horse-survival-dataset,horse.csv,CC0-1.0,"![](https://raw.githubusercontent.com/Masterx-AI/Project_Horse_Sruvival_Prognostication/main/horse.jpg)

### Description:

Predict whether or not a horse can survive based upon past medical conditions.

Noted by the ""outcome"" variable in the data.

Content:

All of the binary representation have been converted into the words they actually represent. However, a fuller description is provided by the data dictionary (datadict.txt).

There are a lot of NA's in the data. This is the real struggle here. Try to find a way around it through imputation or other means.

Attribute Information:

1: surgery? 
1 = Yes, it had surgery 
2 = It was treated without surgery 

2: Age 
1 = Adult horse 
2 = Young (&lt; 6 months) 

3: Hospital Number 
- numeric id 
- the case number assigned to the horse (may not be unique if the horse is treated &gt; 1 time) 

4: rectal temperature 
- linear 
- in degrees celsius. 
- An elevated temp may occur due to infection. 
- temperature may be reduced when the animal is in late shock 
- normal temp is 37.8 
- this parameter will usually change as the problem progresses, eg. may start out normal, then become elevated because of the lesion, passing back through the normal range as the horse goes into shock 
5: pulse 
- linear 
- the heart rate in beats per minute 
- is a reflection of the heart condition: 30 -40 is normal for adults 
- rare to have a lower than normal rate although athletic horses may have a rate of 20-25 
- animals with painful lesions or suffering from circulatory shock may have an elevated heart rate 

6: respiratory rate 
- linear 
- normal rate is 8 to 10 
- usefulness is doubtful due to the great fluctuations 

7: temperature of extremities 
- a subjective indication of peripheral circulation 
- possible values: 
1 = Normal 
2 = Warm 
3 = Cool 
4 = Cold 
- cool to cold extremities indicate possible shock 
- hot extremities should correlate with an elevated rectal temp. 

8: peripheral pulse 
- subjective 
- possible values are: 
1 = normal 
2 = increased 
3 = reduced 
4 = absent 
- normal or increased p.p. are indicative of adequate circulation while reduced or absent indicate poor perfusion 

9: mucous membranes 
- a subjective measurement of colour 
- possible values are: 
1 = normal pink 
2 = bright pink 
3 = pale pink 
4 = pale cyanotic 
5 = bright red / injected 
6 = dark cyanotic 
- 1 and 2 probably indicate a normal or slightly increased circulation 
- 3 may occur in early shock 
- 4 and 6 are indicative of serious circulatory compromise 
- 5 is more indicative of a septicemia 

10: capillary refill time 
- a clinical judgement. The longer the refill, the poorer the circulation 
- possible values 
1 = &lt; 3 seconds 
2 = &gt;= 3 seconds 

11: pain - a subjective judgement of the horse's pain level 
- possible values: 
1 = alert, no pain 
2 = depressed 
3 = intermittent mild pain 
4 = intermittent severe pain 
5 = continuous severe pain 
- should NOT be treated as a ordered or discrete variable! 
- In general, the more painful, the more likely it is to require surgery 
- prior treatment of pain may mask the pain level to some extent 

12: peristalsis 
- an indication of the activity in the horse's gut. As the gut becomes more distended or the horse becomes more toxic, the activity decreases 
- possible values: 
1 = hypermotile 
2 = normal 
3 = hypomotile 
4 = absent 

13: abdominal distension 
- An IMPORTANT parameter. 
- possible values 
1 = none 
2 = slight 
3 = moderate 
4 = severe 
- an animal with abdominal distension is likely to be painful and have reduced gut motility. 
- a horse with severe abdominal distension is likely to require surgery just tio relieve the pressure 

14: nasogastric tube 
- this refers to any gas coming out of the tube 
- possible values: 
1 = none 
2 = slight 
3 = significant 
- a large gas cap in the stomach is likely to give the horse discomfort 

15: nasogastric reflux 
- possible values 
1 = none 
2 = &gt; 1 liter 
3 = &lt; 1 liter 
- the greater amount of reflux, the more likelihood that there is some serious obstruction to the fluid passage from the rest of the intestine 

16: nasogastric reflux PH 
- linear 
- scale is from 0 to 14 with 7 being neutral 
- normal values are in the 3 to 4 range 

17: rectal examination - feces 
- possible values 
1 = normal 
2 = increased 
3 = decreased 
4 = absent 
- absent feces probably indicates an obstruction 

18: abdomen 
- possible values 
1 = normal 
2 = other 
3 = firm feces in the large intestine 
4 = distended small intestine 
5 = distended large intestine 
- 3 is probably an obstruction caused by a mechanical impaction and is normally treated medically 
- 4 and 5 indicate a surgical lesion 

19: packed cell volume 
- linear 
- the # of red cells by volume in the blood 
- normal range is 30 to 50. The level rises as the circulation becomes compromised or as the animal becomes dehydrated. 

20: total protein 
- linear 
- normal values lie in the 6-7.5 (gms/dL) range 
- the higher the value the greater the dehydration 

21: abdominocentesis appearance 
- a needle is put in the horse's abdomen and fluid is obtained from 
the abdominal cavity 
- possible values: 
1 = clear 
2 = cloudy 
3 = serosanguinous 
- normal fluid is clear while cloudy or serosanguinous indicates a compromised gut 

22: abdomcentesis total protein 
- linear 
- the higher the level of protein the more likely it is to have a compromised gut. Values are in gms/dL 

23: outcome 
- what eventually happened to the horse? 
- possible values: 
1 = lived 
2 = died 
3 = was euthanized 

24: surgical lesion? 
- retrospectively, was the problem (lesion) surgical? 
- all cases are either operated upon or autopsied so that this value and the lesion type are always known 
- possible values: 
1 = Yes 
2 = No 

25, 26, 27: type of lesion 
- first number is site of lesion 
1 = gastric 
2 = sm intestine 
3 = lg colon 
4 = lg colon and cecum 
5 = cecum 
6 = transverse colon 
7 = retum/descending colon 
8 = uterus 
9 = bladder 
11 = all intestinal sites 
00 = none 
- second number is type 
1 = simple 
2 = strangulation 
3 = inflammation 
4 = other 
- third number is subtype 
1 = mechanical 
2 = paralytic 
0 = n/a 
- fourth number is specific code 
1 = obturation 
2 = intrinsic 
3 = extrinsic 
4 = adynamic 
5 = volvulus/torsion 
6 = intussuption 
7 = thromboembolic 
8 = hernia 
9 = lipoma/slenic incarceration 
10 = displacement 
0 = n/a 
28: cp_data 
- is pathology data present for this case? 
1 = Yes 
2 = No 
- this variable is of no significance since pathology data is not included or collected for these cases

### Acknowledgements:
This dataset was originally published by the UCI Machine Learning Database:\
http://archive.ics.uci.edu/ml/datasets/Horse+Colic

### Objective:
- Understand the Dataset & cleanup (if required).
- Build classification model to predict weather the horse will survive or not.
- Also fine-tune the hyperparameters & compare the evaluation metrics of vaious classification algorithms.",.csv
Hospital General Information,1,hospital-general-information,HospInfo.csv,other,"# Context 
There are all sorts of reasons why you'd want to know a hospital's quality rating.

 - Your mom is having her second hip replacement. Her first one went terribly and you're nervous about how she'll do. Which hospital would you suggest she have her surgery?
 - You're selecting a health plan on your state's Exchange, but your top two choices partner with different hospitals. How will you decide which plan to pick?
 - Your brother has Cystic Fibrosis and has to go to the ER frequently. He hates waiting. Which hospitals/states provide care in the timeliest manner?
 - Your in-laws moved to Florida recently to retire, and have been trying to convince you to move there too. You're looking for any way possible to show them that your state is better. Does your state have better hospitals?

Every hospital in the United States of America that accepts publicly insured patients (Medicaid or MediCare) is required to submit quality data, quarterly, to the Centers for Medicare & Medicaid Services (CMS). There are very few hospitals that do not accept publicly insured patients, so this is quite a comprehensive list.

# Content

This file contains general information about all hospitals that have been registered with Medicare, including their addresses, type of hospital, and ownership structure. It also contains information about the quality of each hospital, in the form of an overall rating (1-5, where 5 is the best possible rating & 1 is the worst), and whether the hospital scored above, same as, or below the national average for a variety of measures. 

This data was updated by CMS on July 25, 2017. CMS' overall rating includes 60 of the 100 measures for which data is collected & reported on Hospital Compare website (https://www.medicare.gov/hospitalcompare/search.html). Each of the measures have different collection/reporting dates, so it is impossible to specify exactly which time period this dataset covers. 
For more information about the timeframes for each measure, see: 
https://www.medicare.gov/hospitalcompare/Data/Data-Updated.html#
For more information about the data itself, APIs and a variety of formats, see:
https://data.medicare.gov/Hospital-Compare



# Acknowledgements

Attention:
Works of the U.S. Government are in the public domain and permission is not required to reuse them. An attribution to the agency as the source is appreciated. Your materials, however, should not give the false impression of government endorsement of your commercial products or services. See 42 U.S.C. 1320b-10. 

# Inspiration
<ul>Which hospital types & hospital ownerships are most common?</ul>
<ul>Which hospital types & ownerships are associated with better than average ratings/mortality/readmission/etc?</ul>
<ul>What is the average hospital rating, by state?</ul>
<ul>Which hospital types & hospital ownerships are more likely to have not submitted proper data (""Not Available"" & ""Results are not available for this reporting period"")?</ul>
<ul>Which parts of the country have the highest & lowest density of religious hospitals?</ul>",.csv
Hospital ratings,1,hospital-ratings,Hospital General Information.csv,CC0-1.0,"### Context

This are the official datasets used on the Medicare.gov Hospital Compare Website provided by the Centers for Medicare & Medicaid Services. These data allow you to compare the quality of care at over 4,000 Medicare-certified hospitals across the country.

### Content

Dataset fields:

- Provider ID
- Hospital Name
- Address
- City
- State
- ZIP Code
- County Name
- Phone Number
- Hospital Type
- Hospital Ownership
- Emergency Services
- Meets criteria for meaningful use of EHRs
- Hospital overall rating
- Hospital overall rating footnote
- Mortality national comparison
- Mortality national comparison footnote
- Safety of care national comparison
- Safety of care national comparison footnote
- Readmission national comparison
- Readmission national comparison footnote
- Patient experience national comparison
- Patient experience national comparison footnote
- Effectiveness of care national comparison
- Effectiveness of care national comparison footnote
- Timeliness of care national comparison
- Timeliness of care national comparison footnote
- Efficient use of medical imaging national comparison
- Efficient use of medical imaging national comparison

### Acknowledgements

Dataset was downloaded from [https://data.medicare.gov/data/hospital-compare]


### Inspiration

If you just broke your leg, you might need to use this dataset to find the best Hospital to get that fixed!",.csv
Hotel Booking Cancellation Prediction,1,hotel-booking-cancellation-prediction,booking.csv,GNU Lesser General Public License 3.0,"Welcome to the Hotel Booking Cancellation Prediction dataset, a comprehensive collection of data aimed at predicting hotel booking cancellations. This dataset is ideal for data scientists, researchers, and machine learning enthusiasts seeking to develop models that can accurately forecast the likelihood of hotel reservation cancellations.

Dataset Overview:
This dataset comprises a diverse range of features, including booking details, customer information, and reservation specifics. The information has been meticulously gathered from real-world hotel booking scenarios, ensuring authenticity and relevance for predictive modeling.",.csv
Hotel Bookings Analysis,1,hotel-bookings-analysis,hotel_bookings.csv,other,"_____
# Hotel Bookings Analysis
### Analyzing Hotel Bookings and Cancellations
By Mesum Raza Hemani [[source]](https://data.world/mesum)
_____

### About this dataset
&gt; The Hotel Bookings dataset is a comprehensive collection of information regarding hotel bookings, cancellations, and guests' details. This dataset provides insights into various aspects such as the type of hotel, the number of adults, children and babies per booking, the length of stay in both weekend nights (Saturday or Sunday) and weekdays (Monday to Friday), the meal plan chosen by guests, their country of origin and market segment designation.
&gt; 
&gt; Additionally, this dataset includes significant information about reservation status and its updates. It covers whether a booking was canceled or not, the lead time between booking date and arrival date, the week number and day of arrival date. It also indicates if a guest is a repeated visitor or a new customer.
&gt; 
&gt; The dataset contains information related to room assignments as well. It mentions both reserved room types (the type of room initially requested) as well as assigned room types (the room actually allocated). Furthermore, it reveals any changes made to bookings along with details about previous cancellations made by guests.
&gt; 
&gt; Other relevant factors in this dataset are deposit type for each booking; ID numbers for travel agencies used in making reservations; days spent on waiting lists before confirmation; customer classification such as transient or group; average daily rate calculated based on lodging transactions divided by total staying nights; required car parking spaces indicated by customers; the total count of special requests made by each guest.
&gt; 
&gt; The provided data can facilitate analysis on several levels: studying specific hotels within different periods (including year), understanding trends across months and weeks within those years to identify preferred seasons among guests from various countries represented in terms of proportions over other nations. An examination can be conducted for differences between adult-only bookings vs family-oriented ones considering associated variables like stayed weekend/week nights for conversations around how these two groups differ when it comes to selecting their staying patterns at hotels.
&gt; 
&gt; This expansive dataset has great potential for an in-depth exploration into various aspects involved in hotel bookings processes while providing valuable insights for improving hotel services, optimizing operations, and understanding customer preferences

### How to use the dataset
&gt; 
&gt; Introduction:
&gt; 
&gt; - Understanding the Columns:
&gt; - hotel: Type of hotel (Categorical)
&gt; - is_canceled: Whether the booking was canceled or not (Binary)
&gt; - lead_time: Number of days between booking date and arrival date (Numeric)
&gt; - arrival_date_year: The year of the arrival date (Numeric)
&gt; - arrival_date_month: The month of the arrival date (Categorical)
&gt; - arrival_date_week_number: The week number of the arrival date (Numeric)
&gt; - arrival_date_day_of_month: The day of the month of the arrival date (Numeric)
&gt; - stays_in_weekend_nights: Number of weekend nights stayed or booked to stay at the hotel (Numeric)
&gt; - stays_in_week_nights: Number of week nights stayed or booked to stay at the hotel (Numeric)
&gt; - adults, children, babies: Number of guests categorized by age groups
&gt;   - adults = Number of adults
&gt;   - children = Number of children
&gt;   - babies = Number infants
&gt; 
&gt; - Booking Details:
&gt;    - meal: Type(s) food option(s) included in booking package (Categorical)
&gt;    - country & market_segment & distribution_channel columns provide demographic and customer classification information.
&gt;    - is_repeated_guest column specifies whether a guest is a repeated visitor or not.
&gt;    - previous_cancellations column indicates how many previous bookings were canceled by a guest.
&gt;    - previous_bookings_not_canceled shows how many previous bookings were not canceled by a guest.
&gt;   
&gt; - Accommodation Details:
&gt;    - reserved_room_type column indicates which type room was originally reserved for each booking.
&gt;    assigned_room_type mentions which type room was finally assigned for each booking.
&gt;   - booking_changes: Number of changes made to the booking before arrival.
&gt;   - deposit_type: Type of deposit made for the booking (Categorical).
&gt;   - agent & company columns provide relevant information about the travel agency and/or company involved in making the reservation.
&gt;  
&gt; - Additional Information:
&gt;    - days_in_waiting_list: Number of days the booking was on a waiting list before it was confirmed or canceled.
&gt;    - customer_type provides information on types of customers (Categorical)
&gt;    - adr: Average daily rate per room, calculated by dividing the sum of all lodging transactions by the total number of staying nights (Numeric

### Research Ideas
&gt; - Demand Forecasting: The dataset can be used to analyze booking patterns and trends, such as the number of bookings made over time, the seasonality of bookings, and the impact of certain factors (e.g., lead time, arrival date) on booking behavior. This information can help hotels forecast future demand and optimize their pricing and inventory management strategies.
&gt; - Customer Segmentation: By analyzing various attributes in the dataset such as market segment, customer type, and special requests made by guests, hotels can identify different customer segments with unique needs and preferences. This segmentation can help hotels tailor their marketing campaigns, services, and amenities to specific groups of guests for better customer satisfaction.
&gt; - Cancellation Analysis: With information about whether a booking was canceled or not and factors that could influence cancellations (such as lead time, deposit type), hotels can analyze patterns of cancellations to identify common reasons why guests cancel their reservations. This analysis can help hotels implement strategies to reduce cancellations such as offering flexible cancellation policies or providing personalized offers to incentivize guests to keep their bookings.
&gt; These are just a few examples of how this dataset can be used creatively beyond simple descriptive analysis. Depending on the context and objectives of the analysis, there might be other interesting insights or applications that could arise from exploring this data further

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://data.world/mesum)
&gt; 
&gt;


### License
&gt; 
&gt; 
&gt; See the dataset description for more information.

### Columns

**File: hotel_bookings.csv**
| Column name                        | Description                                                                                                                                                                     |
|:-----------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **hotel**                          | Indicates the type of hotel (resort or city). (Categorical)                                                                                                                     |
| **is_canceled**                    | Specifies whether the booking was canceled or not (0=not canceled, 1=canceled). (Binary)                                                                                        |
| **lead_time**                      | Represents the number of days between the booking date and the arrival date. (Numerical)                                                                                        |
| **arrival_date_year**              | Denotes the year of the arrival date. (Categorical)                                                                                                                             |
| **arrival_date_month**             | Indicates the month of the arrival date. (Categorical)                                                                                                                          |
| **arrival_date_week_number**       | Specifies the week number in which guests arrived at the hotel. (Numerical)                                                                                                     |
| **arrival_date_day_of_month**      | Represents a specific day of arrival within a month. (Numerical)                                                                                                                |
| **stays_in_weekend_nights**        | Indicates how many nights (Saturday or Sunday) guests stayed or booked to stay at a hotel during weekends. (Numerical)                                                          |
| **stays_in_week_nights**           | Represents how many weeknights (Monday to Friday) guests stayed or booked to stay at a hotel during weekdays. (Numerical)                                                       |
| **adults**                         | Indicates the number of adults included in each booking. (Numerical)                                                                                                            |
| **children**                       | Indicates the number of children included in each booking. (Numerical)                                                                                                          |
| **babies**                         | Indicates the number of babies included in each booking. (Numerical)                                                                                                            |
| **meal**                           | Describes what type of meal was booked (Breakfast only, Half board, Full board, or Undefined/SC – no meal package). (Categorical)                                               |
| **country**                        | Denotes the country-of-origin for each guest who made a reservation. (Categorical)                                                                                              |
| **market_segment**                 | Shows various market segments that individuals belong to when making reservations (e.g., Online Travel Agents, Offline Travel Agents, Corporate clients). (Categorical)         |
| **distribution_channel**           | Specifies different channels through which bookings were made (e.g., online travel agencies, direct bookings with hotels/tour operators, corporate arrangements). (Categorical) |
| **is_repeated_guest**              | Indicates whether the guest is a repeated visitor (0=not repeated guest, 1=repeated guest). (Binary)                                                                            |
| **previous_cancellations**         | Represents the number of times guests previously canceled their bookings. (Numerical)                                                                                           |
| **previous_bookings_not_canceled** | Denotes the count of previous bookings made by guests that were not canceled. (Numerical)                                                                                       |
| **reserved_room_type**             | Identifies the type of room initially reserved. (Categorical)                                                                                                                   |
| **assigned_room_type**             | Identifies the type of room that was assigned to guests. (Categorical)                                                                                                          |
| **booking_changes**                | Represents the number of changes made to the booking. (Numerical)                                                                                                               |
| **deposit_type**                   | Indicates the type of deposit made for the booking. (Categorical)                                                                                                               |
| **agent**                          | Represents the ID of the travel agency that made the booking. (Categorical)                                                                                                     |
| **company**                        | Represents the ID of the company that made the booking. (Categorical)                                                                                                           |
| **days_in_waiting_list**           | Represents the number of days the booking was on the waiting list before being confirmed. (Numerical)                                                                           |
| **customer_type**                  | Indicates the type of customer (e.g., transient, contract, group, or other). (Categorical)                                                                                      |
| **adr**                            | Represents the average daily rate (price per room) for the booking. (Numerical)                                                                                                 |
| **required_car_parking_spaces**    | Indicates the number of car parking spaces required by the guest. (Numerical)                                                                                                   |
| **total_of_special_requests**      | Represents the total number of special requests made by the guest (e.g., extra bed, room amenities). (Numerical)                                                                |
| **reservation_status**             | Indicates the status of the reservation (e.g., canceled, checked-in, no-show). (Categorical)                                                                                    |
| **reservation_status_date**        | Represents the date on which the reservation status was last updated. (Date)                                                                                                    |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [Mesum Raza Hemani](https://data.world/mesum).

",.csv
Hotel booking demand,1,hotel-booking-demand,hotel_bookings.csv,Attribution 4.0 International (CC BY 4.0),"### Context

Have you ever wondered when the best time of year to book a hotel room is? Or the optimal length of stay in order to get the best daily rate? What if you wanted to predict whether or not a hotel was likely to receive a disproportionately high number of special requests?

This hotel booking dataset can help you explore those questions!

### Content

This data set contains booking information for a city hotel and a resort hotel, and includes information such as when the booking was made, length of stay, the number of adults, children, and/or babies, and the number of available parking spaces, among other things.

All personally identifying information has been removed from the data.

### Acknowledgements

The data is originally from the article [**Hotel Booking Demand Datasets**](https://www.sciencedirect.com/science/article/pii/S2352340918315191), written by Nuno Antonio, Ana Almeida, and Luis Nunes for Data in Brief, Volume 22, February 2019.

The data was downloaded and cleaned by Thomas Mock and Antoine Bichat for [#TidyTuesday during the week of February 11th, 2020](https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-02-11/readme.md). 

### Inspiration

This data set is ideal for anyone looking to practice their exploratory data analysis (EDA) or get started in building predictive models!

If you're looking for inspiration on data visualizations, check out the [#TidyTuesday program](https://github.com/rfordatascience/tidytuesday), a free, weekly online event that encourages participants to create and share their [code and visualizations for a given data set on Twitter](https://twitter.com/search?q=%23TidyTuesday&src=typed_query).

If you'd like to dive into predictive modeling, [Julia Silge](https://twitter.com/juliasilge) has an [accessible and fantastic walk-through](https://juliasilge.com/blog/hotels-recipes/) which highlights the [`tidymodels`](https://www.tidyverse.org/blog/2018/08/tidymodels-0-0-1/) R package.",.csv
Hotels Booking Data - Cleaned Version,1,hotels-booking-data-cleaned-version,hotel_booking_data_cleaned.csv,MIT,"## **Context**
This dataset contains 119390 observations for a City Hotel and a Resort Hotel. Each observation represents a hotel booking between the 1st of July 2015 and 31st of August 2017, including booking that effectively arrived and booking that were canceled.

## **Content**
| Feature                           | Description                                                  |
|-----------------------------------|--------------------------------------------------------------|
| hotel                             | Type of hotel - Resort Hotel or City Hotel.                  |
| is_canceled                       | Binary indicator of reservation cancellation (1 for canceled, 0 otherwise). |
| lead_time                         | Number of days between booking date and arrival date.        |
| arrival_date_year                 | Year of arrival date.                                        |
| arrival_date_month                | Month of arrival date.                                       |
| arrival_date_week_number          | Week number of arrival date.                                  |
| arrival_date_day_of_month          | Day of the month of arrival date.                             |
| stays_in_weekend_nights           | Number of weekend nights (Saturday or Sunday) the guest stays.|
| stays_in_week_nights              | Number of week nights (Monday to Friday) the guest stays.    |
| adults                            | Number of adults in the reservation.                          |
| children                          | Number of children in the reservation.                        |
| babies                            | Number of babies in the reservation.                          |
| meal                              | Type of meal booked - e.g., Bed & Breakfast (BB).            |
| country                           | Country of origin of the guest.                               |
| market_segment                    | Market segment designation (e.g., Direct, Corporate).        |
| distribution_channel              | Booking distribution channel (e.g., Direct, Corporate).      |
| is_repeated_guest                 | Binary indicator if the guest is a repeated guest (1 for repeated, 0 otherwise). |
| previous_cancellations            | Number of previous reservation cancellations by the guest.   |
| previous_bookings_not_canceled    | Number of previous bookings not canceled by the guest.       |
| reserved_room_type                | Type of room reserved by the guest.                           |
| assigned_room_type                | Type of room assigned to the guest.                           |
| booking_changes                   | Number of changes made to the reservation.                   |
| deposit_type                      | Type of deposit made by the guest (e.g., No Deposit).        |
| agent                             | ID of the travel agency making the booking.                  |
| company                           | ID of the company/entity making the booking.                 |
| days_in_waiting_list               | Number of days the booking was on the waiting list.          |
| customer_type                     | Type of booking, e.g., Transient, Contract.                  |
| adr                               | Average Daily Rate, i.e., the average rental income per paid occupied room. |
| required_car_parking_spaces       | Number of parking spaces required by the guest.              |
| total_of_special_requests         | Number of special requests made by the guest.                |
| reservation_status                | Current reservation status (e.g., Check-Out).               |
| reservation_status_date           | Date of the last status update.                               |


## Acknowledgements
The dataset, sourced from [Mujtaba's Kaggle](https://www.kaggle.com/datasets/mojtaba142/hotel-booking/data) profile, provides information on hotel reservations. It has been tailored for analysis by excluding features deemed irrelevant. Additionally, preprocessing steps have been applied to enhance data quality, including the handling of missing values and removal of outliers.
",.csv
Hourly Electricity Consumption and Production,1,hourly-electricity-consumption-and-production,electricityConsumptionAndProductioction.csv,CC0-1.0,"Hourly timeseries of electricity consumption and production (with production type) in Romania.

***Updated April 02 2024.***

It includes the hourly consumption and production, and the production is split in one of the categories: Nuclear, Wind, Hydroelectric, Oil and Gas, Coal, Solar, Biomass.

I think this is a nice dataset due to the fact that Romania includes broad spectrum of electricity productions, including quite a lot of solar and wind, but also nuclear!

It's a pretty big data set of more than 5 years!

When the production is greater than the consumption it means we are exporting electricity, when the value is smaller it means we are importing electricity.

All values are in MWs.",.csv
"Hourly energy data, Türkiye 2018-2023",1,energy-consumption-and-pricing-trkiye-2018-2023,full_data.csv,CC-BY-SA-4.0,"An hourly time series dataset of energy consumption & generation values in megawatts, including generation values by category, along with prices per megawatt in multiple currencies. 

The consumption & generation values are country-wide totals for Türkiye. The time span is between January 1st, 2018 and December 31st, 2023.

Sourced from the EPİAŞ Transparency Platform, merged & reformatted by myself. See ""Provenance"" section for usage & sharing details.
https://seffaflik.epias.com.tr/home

I used this dataset in a multi-horizon deep learning forecasting project, where I implemented an LSTM and a Transformer model using PyTorch Lightning. See the GitHub repository if you are interested:
https://github.com/AhmetZamanis/DeepLearningEnergyForecasting",.csv
House Hold Energy Data - Time Series,1,house-hold-energy-data,D202.csv,Community Data License Agreement - Permissive - Version 1.0,"### Introduction

The data was collected from my apartment unit in San Jose for one plus year. The data is collected with smart meters and shared by the energy company. This is time-series data by nature and can be used for various time-series Machine Learning experiments.

### Description of Data

 The data contains eight attributes. 

TYPE - This is an information column. The value is 'Electric usage' for all the observations.
DATE - Date of electric consumption. There is no timestamp in this field.
START TIME - Start time of the consumption.
END TIME - End time of the consumption
USAGE - Consumption in kWh
UNITS - This column denotes measurement unit. It is kWh for all the observations. 
COST - Cost of consumption in $.
NOTES - Mostly an empty column

### Acknowledgements

I want to thank my energy provider PG&E for sharing the usage data. 

### Inspiration

I started looking into the data inspired by our research paper 'Energy Consumption Forecasting for Smart Meters' https://arxiv.org/abs/1512.05979. The work was done while I was working in India with a vibrant team of Data Scientists. During the time, we found that there was very little data available in the Public domain for the selected use case.",.csv
House Price Prediction Dataset,1,house-price-prediction-dataset,csvdata.csv,Apache 2.0,"""Charting the Realms of Real Estate: A Holistic and Expansive Dataset Curated for In-Depth House Price Prediction Analysis, Market Trends Evaluation, and Strategic Decision-Making in the Dynamic Landscape of Property Valuation and Investment""",.csv
House Price dataset of India,1,house-price-dataset-of-india,House Price India.csv,other,"This data set was very useful when I worked on a project .As a Kaggle contributer I am uploading for others to gain knowledge by implementing algorithms.
Attributes:
1.Id(int)
2.Date(int)
3.number of bedrooms(int)
4.number of bathrooms(float)-convert it into 'int' ,just to give you some practice!
5.living area(int)
6.lot area(int)
7.water front present(float)-convert it into 'int'
8.number of views(int)
and so on....
#dataset #kaggle #House .",.csv
House Prices: Advanced Regression 'solution' file,1,house-prices-advanced-regression-solution-file,solution.csv,CC0-1.0,"### Context

One of the most popular competitions on kaggle is the [House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques). The original data comes from the publication [Dean De Cock ""Ames, Iowa: Alternative to the Boston Housing Data as an End of Semester Regression Project"", Journal of Statistics Education, Volume 19, Number 3 (2011)](http://jse.amstat.org/v19n3/decock.pdf).  Recently a 'demonstration' notebook has been published [""First place is meaningless in this way!""](https://www.kaggle.com/diegojohnson/first-place-is-meaningless-in-this-way) that extracts the 'solution' from the [full dataset](https://www.kaggle.com/prevek18/ames-housing-dataset). Now that the 'solution' is readily available the possibility has opened for people to reproduce the competition at home without any daily submission limit. This will open up the possibility of experimenting with advanced techniques such as pipelines with/or various estimators/models in the same notebook, extensive hyper-parameter tuning etc. And all without the risk of 'upsetting' the public leaderboard. Simply download this `solution.csv` file and import it into your script or notebook and evaluate the [Root-Mean-Squared-Error (RMSE)](https://en.wikipedia.org/wiki/Root-mean-square_deviation) between the logarithm of the predicted value and the logarithm of the data in this file. 
 

### Content

This dataset is the `submission.csv` file that will produce a public leaderboard score of `0.00000`.


### Acknowledgements

* [Ames Housing Dataset](https://www.kaggle.com/prevek18/ames-housing-dataset/metadata) (on kaggle) by @prevek18 
* [First place is meaningless in this way!](https://www.kaggle.com/diegojohnson/first-place-is-meaningless-in-this-way) by @diegojohnson ",.csv
House Rent Prediction Dataset,1,house-rent-prediction-dataset,House_Rent_Dataset.csv,other,"### Context

The spectrum of housing options in India is incredibly diverse, spanning from the opulent palaces once inhabited by maharajas of yore, to the contemporary high-rise apartment complexes in bustling metropolitan areas, and even to the humble abodes in remote villages, consisting of modest huts. This wide-ranging tapestry of residential choices reflects the significant expansion witnessed in India's housing sector, which has paralleled the upward trajectory of income levels in the country. According to the findings of the Human Rights Measurement Initiative, India currently achieves 60.9% of what is theoretically attainable, considering its current income levels, in ensuring the fundamental right to housing for its citizens. In the realm of housing arrangements, renting, known interchangeably as hiring or letting, constitutes an agreement wherein compensation is provided for the temporary utilization of a resource, service, or property owned by another party. Within this arrangement, a gross lease is one where the tenant is obligated to pay a fixed rental amount, and the landlord assumes responsibility for covering all ongoing property-related expenses. The concept of renting also aligns with the principles of the sharing economy, as it fosters the utilization of assets and resources among individuals or entities, promoting efficiency and access to housing solutions for a broad spectrum of individuals.

### Content

Within this dataset, you will find a comprehensive collection of data pertaining to nearly 4700+ available residential properties, encompassing houses, apartments, and flats offered for rent. This dataset is rich with various attributes, including the number of bedrooms (BHK), rental rates, property size, number of floors, area type, locality, city, furnishing status, tenant preferences, bathroom count, and contact information for the respective point of contact.

### Dataset Glossary (Column-Wise)

* <b>BHK</b>: Number of Bedrooms, Hall, Kitchen.
* <b>Rent</b>: Rent of the Houses/Apartments/Flats.
* <b>Size</b>: Size of the Houses/Apartments/Flats in Square Feet.
* <b>Floor</b>: Houses/Apartments/Flats situated in which Floor and Total Number of Floors (Example: Ground out of 2, 3 out of 5, etc.)
* <b>Area Type</b>: Size of the Houses/Apartments/Flats calculated on either Super Area or Carpet Area or Build Area.
* <b>Area Locality</b>: Locality of the Houses/Apartments/Flats.
* <b>City</b>: City where the Houses/Apartments/Flats are Located.
* <b>Furnishing Status</b>: Furnishing Status of the Houses/Apartments/Flats, either it is Furnished or Semi-Furnished or Unfurnished.
* <b>Tenant Preferred</b>: Type of Tenant Preferred by the Owner or Agent.
* <b>Bathroom</b>: Number of Bathrooms.
* <b>Point of Contact</b>: Whom should you contact for more information regarding the Houses/Apartments/Flats.

### Structure of the Dataset

![](https://i.imgur.com/KbU8rxD.png)

### Acknowledgement

This Dataset is created from <b>[https://www.magicbricks.com/](https://www.magicbricks.com/)</b>. If you want to learn more, you can visit the Website.

Cover Photo by: <a href=""https://unsplash.com/@alex_andrews?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText""><b>Alexander Andrews</b></a> on <a href=""https://unsplash.com/s/photos/house?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText""><b>Unsplash</b></a>",.csv
"House Sales in King County, USA",1,housesalesprediction,kc_house_data.csv,CC0-1.0,"This dataset contains house sale prices for King County, which includes Seattle. It includes homes sold between May 2014 and May 2015.

It's a great dataset for evaluating simple regression models.",.csv
House Sales in Ontario,1,ontarioproperties,properties.csv,CC0-1.0,"This dataset includes the listing prices for the sale of properties (mostly houses) in Ontario.
They are obtained for a short period of time in July 2016 and include the following fields:
- Price in dollars
- Address of the property
- Latitude and Longitude of the address obtained by using Google Geocoding service
- Area Name of the property obtained by using Google Geocoding service

This dataset will provide a good starting point for analyzing the inflated housing market in Canada although it does not include time related information.
Initially, it is intended to draw an enhanced interactive heatmap of the house prices for different neighborhoods (areas)

However, if there is enough interest, there will be more information added as newer versions to this dataset. Some of those information will include more details on the property as well as time related information on the price (changes).

This is a somehow related articles about the real estate prices in Ontario:
http://www.canadianbusiness.com/blogs-and-comment/check-out-this-heat-map-of-toronto-real-estate-prices/

I am also inspired by this dataset which was provided for King County
https://www.kaggle.com/harlfoxem/housesalesprediction",.csv
HousePrice,1,pricehouse,Housing.csv,CC0-1.0,"This dataset contains detailed information on 545 number of residential property listings, including sale prices, physical attributes like area, bedrooms, bathrooms, parking availability as well as amenities such as basement, guest rooms, heating/cooling systems and furnishing status. This data can be useful for real estate market analysis, home pricing models, neighborhood comparisons and other applications related to the housing sector.",.csv
Household Electricity Consumption,1,240000-household-electricity-consumption-records,household_power_consumption.csv,other,"# 240,000+ Household Electricity Consumption Records for Machine Learning
### A Dataset for The Smart Way to Save Energy
_____

### About this dataset
Looking to better understand how energy is used in the home? This dataset can help. It contains six months of electricity consumption data for a household, gathered between January 2007 and June 2007. The data includes information on global active power, global reactive power, voltage, global intensity, sub-metering 1 (kitchen), sub-metering 2 (laundry room), and sub-metering 3 (electric water heater and air conditioner). With 260,640 measurements in total, this dataset can provide crucial insights into understanding household electricity consumption

### How to use the dataset
This dataset can be used for machine learning purposes such as predictive modeling or time series analysis. For example, one could use this dataset to predict future household electricity consumption based on past data.

Some possible research ideas include:
1. Analyzing the effects of different types of electrical devices on power consumption
2. Studying how power consumption changes over time and by location
3. Constructing a predictive model to forecast future power consumption

### Research Ideas
1.  Analyze the effects of different types of electrical devices on power consumption
2.  Study how power consumption changes over time and by location
3.  Construct a predictive model to forecast future power consumption

### Acknowledgements
We would like to thank the databeats team for providing this dataset. If you use this dataset in your research, please credit the original authors: Georges Hébrail and Alice Bérard

### License

&gt; **Unknown License - Please check the dataset description for more information.**

### Columns

**File: household_power_consumption.csv**
| Column name               | Description                                                                                       |
|:--------------------------|:--------------------------------------------------------------------------------------------------|
| **Date**                  | The date of the observation. (Date)                                                               |
| **Time**                  | The time of the observation. (Time)                                                               |
| **Global_active_power**   | The total active power consumed by the household (kilowatts). (Numeric)                           |
| **Global_reactive_power** | The total reactive power consumed by the household (kilowatts). (Numeric)                         |
| **Voltage**               | The voltage at which the electricity is delivered to the household (volts). (Numeric)             |
| **Global_intensity**      | The average current intensity delivered to the household (amps). (Numeric)                        |
| **Sub_metering_1**        | The active power consumed by the kitchen (kilowatts). (Numeric)                                   |
| **Sub_metering_2**        | The active power consumed by the laundry room (kilowatts). (Numeric)                              |
| **Sub_metering_3**        | The active power consumed by the electric water heater and air conditioner (kilowatts). (Numeric) |

",.csv
Household monthly electricity bill,1,household-monthly-electricity-bill,Household energy bill data.csv,DbCL-1.0,"### Introduction

The idea behind this dataset is to see how the number of people and the home size affects the monthly electricity consumption in the household.

### Column decription:

| Column | Explanation |
| --- | --- |
| num_rooms | Number of room in the house |
|num_people | Number of people in the house |
|housearea | Area of the house |
|is_ac | Is AC present in the house? |
|is_tv | Is TV present in the house? |
|is_flat | Is house a flat? |
|ave_monthly_income | Average monthly income of the household |
|num_children | Number of children in the house |
|is_urban | Is the house present in an urban area |
|amount_paid | Amount paid as the monthly bill |


### Acknowledgements

This dataset was prepared as a mock up dataset for practice use
",.csv
Housing Cost in New York,1,apartment-cost-in-new-york-city,apartment_cost_list.csv,other,"
![img](https://t2.gstatic.com/licensed-image?q=tbn:ANd9GcQIJZO61HT7jnkXHFugvCckGSEYA1d41EQGf80Qy1oPJ9yi8zm2TqPC-jewOVBFvLd_)

The NYC Housing dataset contains information about the New York City Housing and Preservation Department's (HPD) affordable housing development projects. It includes data on building characteristics, affordability levels, location, and ownership information for all properties in the dataset.

The dataset consists of several files, including Building Data, Project Data, and HPD Contacts. The Building Data file contains information on individual buildings, such as the building's address, number of units, and building type. The Project Data file contains information on the development projects that contain these buildings, including information on the funding programs used to develop the projects and the affordability levels of the units. The HPD Contacts file contains contact information for HPD employees responsible for the management of each project.

The NYC Housing dataset is a valuable resource for researchers, policymakers, and developers interested in affordable housing in New York City. It can be used to analyze trends in affordable housing development, identify neighborhoods with high levels of affordable housing, and evaluate the effectiveness of various affordable housing programs.",.csv
Housing Dataset in Metropolitan Cities (Combined),1,housing-dataset-in-metropolitan-combined-dataset,merged_files.csv,Community Data License Agreement - Permissive - Version 1.0,"This is a housing dataset for six major metropolitan Indian cities. It contains various features such as the number of beds, resale, maintenance staff, indoor games, and many more that are used to determine the price of the house.
",.csv
Housing Price Data,1,housing-price-data,Housing_Price_Data.csv,Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO),"#**Description:**
This dataset contains various features of residential properties along with their corresponding prices. It is suitable for exploring and analyzing factors influencing housing prices and for building predictive models to estimate the price of a property based on its attributes.

#**Features:**

**price:** The price of the property.
**area:** The total area of the property in square feet.
**bedrooms:** The number of bedrooms in the property.
**bathrooms:** The number of bathrooms in the property.
**stories:** The number of stories (floors) in the property.
**mainroad:** Indicates whether the property is located on a main road (binary: yes/no).
**guestroom:** Indicates whether the property has a guest room (binary: yes/no).
**basement:** Indicates whether the property has a basement (binary: yes/no).
**hotwaterheating:** Indicates whether the property has hot water heating (binary: yes/no).
**airconditioning:** Indicates whether the property has air conditioning (binary: yes/no).
**parking:** The number of parking spaces available with the property.
**prefarea:** Indicates whether the property is in a preferred area (binary: yes/no).
**furnishingstatus:** The furnishing status of the property (e.g., furnished, semi-furnished, unfurnished).

#**Usage:**
- This dataset can be used for exploratory data analysis to understand the relationships between different housing features and prices.
- It can also be used to build machine learning models for predicting housing prices based on the given features.

**License:**
This dataset is made available under the [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-nc-sa/4.0/).
",.csv
Housing Price Dataset,1,housing-price-dataset,Housing.csv,CC0-1.0,"The housing price dataset provides a comprehensive collection of property listings, encompassing various attributes such as the number of bedrooms, bathrooms, living area size, lot size, and location details. This dataset is invaluable for a wide range of data analysis and machine learning applications. For instance, it can be utilized in predictive modeling to forecast property prices based on features such as location, amenities, and condition. Additionally, it can aid in identifying trends and patterns in the real estate market, assisting investors, real estate agents, and policymakers in making informed decisions. Moreover, the dataset can serve as a foundation for developing recommendation systems for homebuyers, guiding them towards properties that align with their preferences and requirements. Overall, the housing price dataset offers a wealth of insights and opportunities for leveraging data-driven approaches to understand and navigate the housing market effectively.",.csv
Housing Price Prediction Data,1,housing-price-prediction-data,housing_price_dataset.csv,other,"Explore the fascinating world of housing price prediction with this synthetic dataset. Perfect for data science enthusiasts, machine learning practitioners, and Kaggle learners, this dataset offers a diverse collection of features, including square footage, bedrooms, bathrooms, neighborhood types, and the year of construction. Immerse yourself in the challenge of predicting house prices and enhance your skills in regression analysis.",.csv
Housing Sales: Factors Influencing Sale Prices,1,housing-sales-factors-influencing-sale-prices,housing.csv,Attribution 4.0 International (CC BY 4.0),"This dataset contains information related to housing sales, in the form of individual properties. Here's a breakdown of the columns:

| Column Name    | Description                                         |
|----------------|-----------------------------------------------------|
| Lot_Frontage   | Linear feet of street connected to the property    |
| Lot_Area       | Lot size in square feet                             |
| Bldg_Type      | Type of building|
| House_Style    | Style of the house      |
| Overall_Cond   | Overall condition rating of the house               |
| Year_Built     | Year the house was built                            |
| Exter_Cond     | Exterior condition rating of the house               |
| Total_Bsmt_SF  | Total square feet of basement area                  |
| First_Flr_SF   | First-floor square feet                             |
| Second_Flr_SF  | Second-floor square feet                            |
| Full_Bath      | Number of full bathrooms                            |
| Half_Bath      | Number of half bathrooms                            |
| Bedroom_AbvGr  | Number of bedrooms above ground                     |
| Kitchen_AbvGr  | Number of kitchens above ground                     |
| Fireplaces     | Number of fireplaces                                |
| Longitude      | Longitude coordinates of the property location      |
| Latitude       | Latitude coordinates of the property location       |
| Sale_Price     | Sale price of the property                          |

The dataset contains 2413 entries and has a mixture of numerical and categorical data. It's likely used for analyzing various factors influencing housing sale prices, such as location, size, condition, and amenities.",.csv
How Debt Impacts A Person's Life on Average,1,how-debt-impacts-a-persons-life-on-average,debt_impact_data (2).csv,MIT,"## Description:

**Import Libraries:** The code begins by importing the necessary libraries, namely pandas and numpy, which are commonly used for data manipulation and numerical computations in Python.

**Sample Professions:** A list named professions is defined, containing various professions as strings. This list is used later to generate random data for the 'profession' column.

**Function to Generate Random Data:** The code defines a function named generate_random_data to generate random data for different columns. This function takes parameters such as the column name, value type (int, float, or categorical), value range (for numerical data), options (for categorical data), and size (number of data points to generate). It uses NumPy's random functions to generate the data based on the specified parameters.

**Generate Random Data for Each Column:** Random data is generated for each column of the dataset using the generate_random_data function. The columns include 'gender', 'age', 'profession', 'occupation', 'country_of_residence', 'urban_rural', 'owns_car', 'salary', 'cost_of_living', 'marital_status', 'has_kids', 'num_kids', 'debt_type', 'debt_amount', 'monthly_debt_payment', and 'savings'.

**Combine Data into a DataFrame:** The generated data is combined into a Pandas DataFrame named data, with each column representing a different attribute of individuals.

**Export Data to CSV File:** The DataFrame data is exported to a CSV file named ""debt_impact_data.csv"" using the to_csv function provided by Pandas. The parameter index=False is used to exclude the DataFrame index from the CSV file.

**Print Confirmation Message:** Finally, a message is printed to indicate that the debt impact data has been successfully exported to the CSV file.

## Variables:

**professions:** A list containing sample professions.
**generate_random_data:** A function to generate random data for different columns based on specified parameters.
**num_people:** The number of individuals for whom data is generated (set to 1000).
**gender:** Randomly generated gender data (categorical: Female or Male).
**age:** Randomly generated age data (integer values between 22 and 41).
**profession:** Randomly generated profession data (categorical, selected from the list of professions).
**occupation:** Fixed value indicating full-time occupation for all individuals.
**country_of_residence:** Fixed value indicating the country of residence for all individuals (United States).
**urban_rural:** Randomly generated urban/rural status data (categorical: Urban or Rural).
**owns_car:** Randomly generated car ownership data (categorical: Yes (Loan), Yes (Owned), or No).
**salary:** Randomly generated salary data (integer values between $40,000 and $120,000+).
**cost_of_living:** Randomly generated cost of living data (categorical: High or Medium).
**marital_status:** Randomly generated marital status data (categorical: Single or Married).
**has_kids:** Randomly generated data indicating whether individuals have kids (categorical: Yes or No).
**num_kids:** Randomly generated number of kids data (integer values between 0 and 3).
**debt_type:** Fixed value indicating the type of debt for all individuals (Student Loan).
**debt_amount:** Randomly generated debt amount data (integer values between $20,000 and $50,000).
**monthly_debt_payment:** Randomly generated monthly debt payment data (integer values between $100 and $8,000+).
**savings:** Randomly generated savings data (integer values between $0 and $25,000).

## Process

1. Generate random data for each attribute/column for 1000 individuals.
2. Combine the generated data into a Pandas DataFrame.
3. Export the DataFrame to a CSV file named ""debt_impact_data.csv"".
4. Print a confirmation message indicating the successful export of the data.

## NOTE:

This code is useful for generating synthetic data for analysis or testing purposes, particularly in scenarios involving demographics, financial attributes, and other categorical or numerical variables related to individuals.",.csv
How ISIS Uses Twitter,1,how-isis-uses-twitter,tweets.csv,CC0-1.0,"We scraped over 17,000 tweets from 100+ pro-ISIS fanboys from all over the world since the November 2015 Paris Attacks. We are working with content producers and influencers to develop effective counter-messaging measures against violent extremists at home and abroad. In order to maximize our impact, we need assistance in quickly analyzing message frames. 

The dataset includes the following:

 1. Name
 2. Username
 3. Description
 4. Location
 5. Number of followers at the time the tweet was downloaded
 6. Number of statuses by the user when the tweet was downloaded
 7. Date and timestamp of the tweet
 8. The tweet itself

Based on this data, here are some useful ways of deriving insights and analysis: 

 - **Social Network Cluster Analysis**: Who are the major players in the pro-ISIS twitter network? Ideally, we would like this visualized via a cluster network with the biggest influencers scaled larger than smaller influencers. 
 - **Keyword Analysis**: Which keywords derived from the name, username, description, location, and tweets were the most commonly used by ISIS fanboys? Examples include: ""baqiyah"", ""dabiq"", ""wilayat"", ""amaq""
 - **Data Categorization of Links**: Which websites are pro-ISIS fanboys linking to? Categories include: Mainstream Media, Altermedia, Jihadist Websites, Image Upload, Video Upload, 
 - **Sentiment Analysis**: Which clergy do pro-ISIS fanboys quote the most and which ones do they hate the most? Search the tweets for names of prominent clergy and classify the tweet as positive, negative, or neutral and if negative, include the reasons why.  Examples of clergy they like the most: ""Anwar Awlaki"", ""Ahmad Jibril"", ""Ibn Taymiyyah"", ""Abdul Wahhab"". Examples of clergy that they hate the most: ""Hamza Yusuf"", ""Suhaib Webb"", ""Yaser Qadhi"", ""Nouman Ali Khan"", ""Yaqoubi"". 
 - **Timeline View**: Visualize all the tweets over a timeline and identify peak moments

Further Reading: ""[ISIS Has a Twitter Strategy and It is Terrifying \[Infographic\]][2]""


**About Fifth Tribe**

*[Fifth Tribe][1] is a digital agency based out of DC that serves businesses, non-profits, and government agencies. We provide our clients with product development, branding, web/mobile development, and digital marketing services. Our client list includes Oxfam, Ernst and Young, Kaiser Permanente, Aetna Innovation Health, the U.S. Air Force, and the U.S. Peace Corps. Along with Goldman Sachs International and IBM, we serve on the Private Sector Committee of the Board of the Global Community Engagement and Resilience Fund (GCERF), the first global effort to support local, community-level initiatives aimed at strengthening resilience against violent extremism. In December 2014, we won the anti-ISIS ""Hedaya Hack"" organized by Affinis Labs and hosted at the ""Global Countering Violent Extremism (CVE) Expo "" in Abu Dhabi. Since then, we've been actively involved in working with the open-source community and community content producers in developing counter-messaging campaigns and tools.* 



  [1]: http://www.fifthtribe.com
  [2]: https://medium.com/fifth-tribe-stories/isis-has-a-twitter-strategy-and-it-is-terrifying-7cc059ccf51b#.m3zeluykl",.csv
How is education financed?,1,how-is-education-financed,totaleducation-gdp new2.csv,CC0-1.0,"this graphs was retired this OurdataWorld :

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fd8a738bc087d3845b64c4915b647f905%2Fgraph1.png?generation=1711569676966251&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fcf83d17d50e3e23f8ee1781c6a6ae217%2Fgraph2.png?generation=1711569684217672&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F45bba4bbb7a6b5d937ba14d90daa762e%2Fgraph3.png?generation=1711569690789479&alt=media)

In contemporary society, basic education is not merely a right but also a duty, with governments tasked to ensure access while citizens are obligated to attain a basic level of education. However, this concept was not always pervasive. The mid-19th century marked the inception of public education as a policy priority, primarily witnessed in industrialized nations expanding primary education through public finances and government intervention. An analysis of historical data unveils the pivotal role of local funding, particularly through taxes, in facilitating this educational expansion.

During the latter half of the 20th century, education expansion transcended national borders, evolving into a global phenomenon. By 1990, government spending on education in many developing nations approximated levels observed in developed countries, reflecting a concerted effort towards educational parity on a global scale. This expansive drive bore fruit, as evidenced by a sustained reduction in education inequality worldwide from 1960 to 2010, across all age groups and regions.

Contemporary data from UNESCO underscores ongoing global efforts to bolster government funding for education, indicating a shift towards prioritizing educational investment without necessarily compromising other sectors. Nonetheless, significant heterogeneity persists across countries and regions, with variations in the allocation of educational expenditures and reliance on household contributions.

The turn of the 21st century witnessed a surge in international financial aid for education following the Millennium Development Goals. However, recent trends indicate a plateau in development assistance since 2010, with primary education experiencing notable reductions in funding allocation. Such shifts in priorities could have profound distributional implications, particularly for low-income countries heavily reliant on external aid for basic education.

Macro-level analyses reveal that national expenditure on education alone inadequately explains cross-country disparities in learning outcomes, underscoring the multifaceted nature of educational inputs. While increased investment is crucial, the efficacy of spending hinges on optimizing various inputs, with emerging evidence suggesting a nuanced emphasis on quality teachers and demand-side interventions.

Moreover, policy experiments underscore the significance of early childhood education, with investments yielding substantial long-term benefits encompassing not only educational attainment but also broader developmental outcomes. The formative years lay the groundwork for future success, emphasizing the critical role of early-life environments in shaping individual capabilities and potentials.

Reflecting on the historical trajectory of education financing, it becomes evident that the provision of accessible quality education has progressively become a public policy imperative. From its nascent stages in the 19th century driven by local funding initiatives, education has evolved into a global priority supported by diverse funding mechanisms and international cooperation.

As nations navigate contemporary challenges in education, ranging from resource allocation to quality enhancement, a holistic approach is imperative. Beyond monetary investment, attention must be directed towards optimizing educational inputs, fostering conducive learning environments, and prioritizing early childhood development. By embracing these principles, societies can realize the transformative power of education, empowering individuals and fostering inclusive socio-economic progress on a global scale.",.csv
Hr Analytics Job Prediction,1,hr-analytics-and-job-prediction,HR_comma_sep.csv,CC0-1.0,"### Context

Hr Data Analytics 
This dataset contains information about employees who worked in a company.



### Content

This dataset contains columns: Satisfactory Level, Number of Project, Average Monthly Hours, Time Spend Company, Promotion Last 5   
Years, Department, Salary


### Acknowledgements
You can download, copy and share this dataset for analysis and Predictions employees Behaviour.


### Inspiration
Answer the following questions would be worthy
 1- Do Exploratory Data analysis to figure out which variables have a direct and clear impact on employee retention (i.e. whether they leave the company or continue to work)
2- Plot bar charts showing the impact of employee salaries on retention
3- Plot bar charts showing a correlation between department and employee retention
4- Now build a logistic regression model using variables that were narrowed down in step 1
5- Measure the accuracy of the model",.csv
Hubble Law Astronomy Lab,1,hubble-law-astronomy-lab,simulatedHubblesLawData.csv,MIT,"A simulated dataset for use in determining the expansion rate of the universe.  Type Ia Supernovae tend to peak at a roughly constant absolute magnitude.  Astronomers use this fact in order to determine the distances to supernovae in the universe -- particularly the distances to the host galaxy of the star that is going supernova.  Once the distance to the galaxy is determined, spectra are used in order to determine the redshift of the galaxy.  The redshift is related to how quickly the galaxy is moving relative to us.

The goal for this activity is to examine how the distance to a galaxy and its velocity are related.  As it turns out, the universe is expanding, so galaxies further from us will tend to be moving rather quickly away from us.  

Assignment Prompt:  [TBA]

[Starting Template](https://www.kaggle.com/code/austinhinkel/hubbleslawtemplate)

## Data Columns:
*Simulated* data for the following:
- Peak apparent magnitude values of type I-a supernovae
- Redshift values of host galaxies containing the type I-a supernovae

## Acknowledgements: 
This dataset is part of an open source astronomy course intended to gently introduce students to python programming.  This work has been supported via NASA Kentucky under NASA award No: 80NSSC20M0047.

Assignment inspired by a similar Excel-based activity at Colorado College.

Thumbnail image: Photo by <a href=""https://unsplash.com/@hubblespacetelescope?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">NASA Hubble Space Telescope</a> on <a href=""https://unsplash.com/photos/a-close-up-of-the-center-of-a-spiral-galaxy-ccWi4BVFS9I?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv
Human Stress Prediction,1,human-stress-prediction,Stress.csv,other,"“subreddit – post_id – sentence_range – text-label-confidence-social_timestamp” represents the titles for Stress.csv file.

Stress detection is a challenging task, as there are so many words that can be used by people on their posts that can show whether a person is having psychological stress or not. look for datasets that you can use to train a machine learning model for stress detection.

The dataset contains data posted on subreddits related to mental health. This dataset contains various mental health problems shared by people about their life. Fortunately, this dataset is labelled as 0 and 1, where 0 indicates no stress and 1 indicates stress. ",.csv
Hungary Chicken Pox Cases in Budapest,1,hungary-chicken-pox-cases-in-budapest,chickenpox.csv,CC-BY-SA-4.0," A spatio-temporal dataset of monthly chickenpox (childhood disease) cases from Hungary. The dataset consists of a adjacency matrix and time series of the reported cases between 2005 and 2014
.",.csv
Hunger and,1,hunger-and,share-of-children new.csv,CC0-1.0,"this graph was created in OurDataWorld:

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fdb9433404b4d55c8880203878e3e1718%2Fgraph1.png?generation=1714849328264683&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F4ae9c1ccba533eb6151d3cbe1c6b2189%2Fgraph2.png?generation=1714849334773165&alt=media)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F988a9d7e99b0c771955d04329de3ae2e%2Fgraph3.png?generation=1714849340380199&alt=media)

Having enough to eat is one of the fundamental basic human needs. Hunger – or, more formally, undernourishment – is defined as eating less than the energy required to maintain an active and healthy life.

The share of undernourished people is the leading indicator for food security and nutrition used by the Food and Agriculture Organization of the United Nations.

The fight against hunger focuses on a sufficient energy intake – enough calories per person per day. But it is not the only factor that matters for a healthy diet. Sufficient protein, fats, and micronutrients are also essential, and we cover this in our topic page on micronutrient deficiencies.

Undernourishment in mothers and children is a leading risk factor for death and other poor health outcomes.

The UN has set a global target as part of the Sustainable Development Goals to “end hunger by 2030“. While the world has progressed in past decades, we are far from reaching this target.

On this page, you can find our data, visualizations, and writing on hunger and undernourishment. It looks at how many people are undernourished, where they are, and other metrics used to track food security.",.csv
Hypertension-risk-model-main,1,hypertension-risk-model-main,Hypertension-risk-model-main.csv,MIT,"The dataset comprises demographic and health-related attributes aimed at predicting the risk of hypertension. Each entry includes information on gender, age, smoking habits (current smoker and cigarettes per day), medication for high blood pressure (BPMeds), presence of diabetes, total cholesterol levels, systolic and diastolic blood pressure, body mass index (BMI), heart rate, glucose levels, and the corresponding hypertension risk label (0 for low risk, 1 for high risk). With a total of 13 features, this dataset provides a comprehensive overview of factors contributing to hypertension, facilitating the development of predictive models for risk assessment and prevention strategies.",.csv
IBM HR Analytics Employee Attrition & Performance,1,ibm-hr-analytics-attrition-dataset,WA_Fn-UseC_-HR-Employee-Attrition.csv,DbCL-1.0,"Uncover the factors that lead to employee attrition and explore important questions such as ‘show me a breakdown of distance from home by job role and attrition’ or ‘compare average monthly income by education and attrition’. This is a fictional data set created by IBM data scientists.

Education
	1 'Below College'
	2 'College'
	3 'Bachelor'
	4 'Master'
	5 'Doctor'
	
EnvironmentSatisfaction
	1 'Low'
	2 'Medium'
	3 'High'
	4 'Very High'
	
JobInvolvement	
        1 'Low'
	2 'Medium'
	3 'High'
	4 'Very High'
	
JobSatisfaction	
       1 'Low'
	2 'Medium'
	3 'High'
	4 'Very High'
	
PerformanceRating	
        1 'Low'
	2 'Good'
	3 'Excellent'
	4 'Outstanding'
	
RelationshipSatisfaction	
        1 'Low'
	2 'Medium'
	3 'High'
	4 'Very High'
	
WorkLifeBalance	
        1 'Bad'
	2 'Good'
	3 'Better'
	4 'Best'",.csv
IBM🎗️ | Stock Prices Dataset📊,1,ibm-stock-prices-dataset,IBM.csv,Apache 2.0,"# **Description:**

This dataset contains historical stock price data for International Business Machines Corporation (IBM) from [Jan/01/2020] to [May/01/2024]. The dataset includes daily closing prices, adjusted closing prices, and other relevant information.

## **Features:**

- Date:
- Open:
- High:
- Low:
- Close:
- Adj Close:
- Volume:

### **Use Cases:**

- Predicting stock prices
- Building stock forecasting models
- Analyzing stock market trends
- Backtesting investment strategies
- Comparing machine learning models for stock prediction


    This dataset is perfect for data scientists, analysts, and students looking to practice their skills in:

- Time series analysis
- Stock market analysis
- Predictive modeling
- Machine learning

**Get started:** Download the dataset and start&nbsp;exploring!",.csv
ICC Hall of Fame Dataset,1,icc-hall-of-fame-dataset,icc hall of fame.csv,CC0-1.0,"**Context:**

This dataset offers a detailed record of cricketers inducted into the ICC Hall of Fame, reflecting the highest honors in the sport. Spanning inductees from various eras, it provides data on their career achievements, the periods during which they were active, etc. The dataset serves as a valuable resource for cricket enthusiasts, sports historians, and researchers interested in the evolution of cricket and its legendary figures.

**Variables:**

- **profile:** URL linking to the player's profile on the ICC Hall of Fame website.
- **fname: **First name of the player.
- **lname:** Last name of the player.
- **country:** Country that the player represented in international cricket.
- **Induction:**Year the player was inducted into the Hall of Fame.
- **dob:** Date of birth of the player.
- **bowlingstyle:** Describes the player's bowling style (e.g., Right-arm fast, Left-arm spin).
- **role:** The role the player had in the team (e.g., Batsman, Bowler, All-rounder, Wicketkeeper).
- **debut:** The year the player debuted in international cricket.
- **batstyle:** The player's batting style (e.g., Left-handed, Right-handed).
- **careerstart:** Year when the player began their international cricket career.
- **careerEnd:** Year when the player retired from international cricket.

**Data Source:**

The data was compiled from official ICC publications and validated records related to the Hall of Fame inductees. Further verification and details can be accessed directly from ICC's official Hall of Fame [online archive](https://www.icc-cricket.com/hall-of-fame/hall-of-famers).

**Inspiration for Analysis:**

Researchers and analysts can utilize this dataset to conduct various studies, such as:

- **Career Longevity Analysis:** Examining the duration and evolution of careers among Hall of Famers.
- **Performance Trends:** Assessing how changes in the sport’s rules and equipment have impacted player performance and careers over time.
- **Geographical and Temporal Trends:** Analyzing the distribution of Hall of Fame inductees by country and era to understand regional dominance and shifts in the cricketing landscape.
- **Role-based Evaluations:** Looking at the impact of players' roles on their likelihood of induction into the Hall of Fame.

Please feel free to perform any analysis or visualization on this dataset.",.csv
IELTS Writing Scored Essays Dataset,1,ielts-writing-scored-essays-dataset,ielts_writing_dataset.csv,other,"**Context:**

The ""IELTS Writing Scored Essays Dataset"" is a valuable collection of sample essays for the writing section of the IELTS (International English Language Testing System) exam. IELTS is a widely recognized international language proficiency test used to assess language skills and proficiency for academic and general purposes. The writing section is an essential component of the IELTS exam, where candidates are evaluated based on specific criteria.

The IELTS writing evaluation criteria include:

•Task Response: Assessing the candidate's ability to address the writing task appropriately, covering all key points and providing a clear, well-structured response.

•Coherence and Cohesion: Evaluating how well the candidate organizes ideas and information, ensuring logical progression, and using cohesive devices effectively.

•Lexical Resource: Analyzing the range and accuracy of vocabulary used by the candidate, as well as the ability to use appropriate terminology and expressions.

•Grammatical Range and Accuracy: Examining the candidate's control of sentence structure, verb tenses, and grammatical accuracy.


**Content:**

The ""IELTS Writing Scored Essays Dataset"" is an extensive collection of over 1200 essays, each accompanied by a variety of essential columns.

•Task_Type: This column categorizes the essays into their respective IELTS writing tasks, distinguishing between ""Task 1"" and ""Task 2."" 

•Question: The ""Question"" column contains the specific writing prompts or questions assigned to the candidates for each essay. 

•Essay: The heart of the dataset, the ""Essay"" column, contains the actual written responses submitted by the IELTS candidates. 

•Examiner_Comment: This column includes comments and feedback provided by the examiners who evaluated the essays. 

•Task_Response, Coherence_Cohesion, Lexical_Resource, Range_Accuracy columns includes the respective scores based on the evaluation criteria. These scores will be added to the dataset in the subsequent version.

•Overall: The ""Overall"" column provides the final scores assigned to each essay.
",.csv
IGN games from best to worst,1,ign-games-from-best-to-worst,IGN games from best to worst.csv,CC0-1.0,"## Column descriptions:
**Title**: This column contains the titles of video games.

**Score**: This column represents the score given to each game, on a scale of 1 to 10.

**Score Phrase**: This column provides a qualitative assessment of the game's score, such as ""Masterpiece,"" indicating exceptionally high praise.

**Platform**: This column indicates the platform or console on which the game was released, such as Lynx, Wii, Game Boy Color, Xbox 360, or PlayStation 3.

**Genre**: This column specifies the genre(s) of the game, such as Racing, Action, RPG (Role-Playing Game), or Action-Adventure.

**Release Year**: This column indicates the year in which the game was released.

**Release Month**: This column specifies the month of release.

**Release Day**: This column specifies the day of release.

# About IGN
**IGN** is an American video game and entertainment media website operated by IGN Entertainment Inc., a subsidiary of Ziff Davis, Inc. The company's headquarters is located in San Francisco's SoMa district and is headed by its former editor-in-chief, Peer Schneider. The IGN website was the brainchild of media entrepreneur Chris Anderson and launched on September 29, 1996. It focuses on games, films, anime, television, comics, technology, and other media. Originally a network of desktop websites, IGN is also distributed on mobile platforms, console programs on the Xbox and PlayStation, FireTV, Roku, and via YouTube, Twitch, Hulu, and Snapchat.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2F323f807834206a420e1e7a47a3edcb89%2FIGN%20Entertainment%202.jpg?generation=1707286687240832&alt=media)

Originally, IGN was the flagship website of IGN Entertainment, a website which owned and operated several other websites oriented towards players' interests, games, and entertainment, such as Rotten Tomatoes, GameSpy, GameStats, VE3D, TeamXbox, Vault Network, FilePlanet, and AskMen, among others. IGN was sold to publishing company Ziff Davis in February 2013 and operates as a J2 Global subsidiary.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2Fa266e18713a67f39863b120880ad96ae%2FIGN%20Entertainment.jpg?generation=1707286616489399&alt=media)",.csv
IKEA Furniture,1,ikea-sa-furniture-web-scraping,IKEA_SA_Furniture_Web_Scrapings_sss.csv,other,"### Context

This notebook is a practice of web scraping techniques. The web scraping has been applied on IKEA Saudi Arabian website for the furniture category. The scraped website link: https://www.ikea.com/sa/en/cat/furniture-fu001/

The data requested by 4/20/2020. The libraries used are BeautifulSoup and Selenium for web scraping, as well as regular Python libraries: Pandas, Numpy, and Regex for regular analysis activities. Number of rows=2962 Number of features=13

### Content

- item_id	: item id wich can be used later to merge with other IKEA dataframes
- name: the commercial name of items
- category:the furniture category that the item belongs to (Sofas, beds, chairs, Trolleys,...)
- Price: the current price in Saudi Riyals as it is shown in the website by 4/20/2020
- old_price: the price of item in Saudi Riyals before discount
- Short_description: a brief description of the item 
- full_Description: a very detailed description of the item. Because it is long, it is dropped from the final dataframe, but it is available in the code in case it needs to be analyzed.
- designer: The name of the designer who designed the item. this is extracted from the full_description column.
- size: the dimensions of the item including a lot of details.As a lot of dimensions mentioned and they vary from item to item, 
the most common dimensions have been extracted which are: Height, Wideh, and Depth. This column is dropped from the final dataframe, but it is available in the code in case it is needed. 
- width: Width of the item in Centimeter
- height: Height of the item in Centimeter
- depth: Depth of the item in Centimeter
- sellable_Online: if the item is available for online purchasing or in-stores only (Boolean)
- other_colors: if other colors are available for the item, or just one color as displayed in the website (Boolean)
- link: the web link of the item 


### Licences 

The scraped website link: https://www.ikea.com/sa/en/cat/furniture-fu001/


### Inspiration

The collected dataset can be utilized mainly towards two data science modeling:

Regression: Predict the Sales Price of new items
Classification: Predict the category of new items
Classification: Predict if an item will be discounted",.csv
IMDB Dataset (Top 2000 movies),1,imdb-dataset-top-2000-movies,imdb_top_2000_movies.csv,other,"This dataset is scraped from IMDB's official website. It may be used for regression, classification, clustering, designing recommendation systems, etc.
It has 10 columns containing the following data:
1. The name of the movie
2. The Year of release
3. The running time of the movie (in minutes)
4. It's IMDB Rating
5. It's Metascore
6. The number of votes it got
7. The Genre of the movie
8. The director of the movie
9. The cast of the movie
10. Gross value",.csv
IMDB Dataset of 50K Movie Reviews,1,imdb-dataset-of-50k-movie-reviews,IMDB Dataset.csv,other,"IMDB dataset having 50K movie reviews for natural language processing or Text analytics.
This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training and 25,000 for testing. So, predict the number of positive and negative reviews using either classification or deep learning algorithms.
For more dataset information, please go through the following link,
http://ai.stanford.edu/~amaas/data/sentiment/
",.csv
IMDB Movie Reviews,1,imdb-movie-reviews,IMDB Dataset.csv,MIT,"The purpose of this dataset is to facilitate sentiment analysis tasks, particularly in the context of movie reviews. Researchers, data scientists, and machine learning practitioners can use this dataset to train and evaluate sentiment classification models. By analyzing the textual content of reviews and their associated sentiment labels, one can develop algorithms capable of automatically identifying the sentiment conveyed in movie reviews.",.csv
IMDB Movies Dataset,1,imdb-dataset-of-top-1000-movies-and-tv-shows,imdb_top_1000.csv,CC0-1.0,"### Context

IMDB Dataset of top 1000 movies and tv shows.
You can find the **EDA Process** on - https://www.kaggle.com/harshitshankhdhar/eda-on-imdb-movies-dataset

Please consider **UPVOTE** if you found it useful. 

### Content

Data:-
- **Poster_Link** - Link of the poster that imdb using
- **Series_Title** = Name of the movie 
- **Released_Year** - Year at which that movie released
- **Certificate** - Certificate earned by that movie
- **Runtime** - Total runtime of the movie
- **Genre** - Genre of the movie
- **IMDB_Rating** - Rating of the movie at IMDB site
- **Overview** - mini story/ summary
- **Meta_score** - Score earned by the movie
- **Director** - Name of the Director
- **Star1,Star2,Star3,Star4** - Name of the Stars
- **No_of_votes** - Total number of votes
- **Gross** - Money earned by that movie

### Inspiration

- Analysis of the gross of a movie vs directors.
- Analysis of the gross of a movie vs different - different stars.
- Analysis of the No_of_votes of a movie vs directors.
- Analysis of the No_of_votes of a movie vs different - different stars.
- Which actor prefer which Genre more?
- Which combination of actors are getting good IMDB_Rating maximum time?
- Which combination of actors are getting good gross?",.csv
IMDB Top 250 Movies Dataset,1,imdb-top-250-movies-dataset,IMDB Top 250 Movies.csv,CC-BY-NC-SA-4.0,"#### Context
IMDB (Internet Movie Database) is one of the largest online databases for movies and television shows, providing comprehensive information about movies, including ratings and reviews from its vast user base. The IMDB ratings are widely used as a benchmark for the popularity and success of movies.

This dataset contains the top 250 rated movies on IMDB as of 2021, providing a snapshot of the most popular and highly rated movies of recent times. By analyzing this dataset, one can gain insights into the movie industry, such as trends in movie ratings and popular genres.

The data was scraped from the IMDB website for educational purposes and to provide a publicly available dataset for others to use and build upon.


#### Source
The data for this dataset was scraped from the IMDB website (www.imdb.com). The top 250 movies were selected based on their IMDB ratings, and information such as movie title, director, cast, rating, votes, and year of release was collected. No data was altered or modified in any way, and all data was collected in accordance with IMDB's terms of use


#### Column Description
- rank - Rank of the movie
- name - Name of the movie
- year - Release year
- rating - Rating of the movie
- genre - Genre of the movie
- certificate - Certificate of the movie
- run_time - Total movie run time
- tagline - Tagline of the movie
- budget - Budget of the movie
- box_office - Total box office collection across the world
- casts - All casts of the movie
- directors - Director of the movie
- writers - Writer of the movie


#### Inspiration
The inspiration for this dataset came from our passion for movies and the film industry. We wanted to explore and understand the factors that contribute to a movie's popularity and success. IMDB is one of the largest and most trusted movie rating websites, so we decided to scrape its top 250 movies to gain insights into the movie-making industry. We hope this dataset will be useful for movie enthusiasts, data scientists, and researchers who are interested in exploring the correlations between different movie attributes and their popularity

Keep Learning",.csv
IMDB Top Rated Movies Dataset,1,tmdb-top-rated-movies-dataset,movie_dataset.csv,MIT,"This dataset consists of all top-rated movies featured on the IMDB website. The dataset is fetched from TMDB API. Unnecessary columns are removed. There are 9335 movie entries with no null values.

Hope you enjoy working with this.

Contact me at smaindola90@gmail.com for more info.",.csv
IMDB data from 2006 to 2016,1,imdb-data,IMDB-Movie-Data.csv,other,"Here's a data set of 1,000 most popular movies on IMDB in the last 10 years. The data points included are:

Title, Genre, Description, Director,  Actors, Year, Runtime, Rating, Votes, Revenue, Metascrore

Feel free to tinker with it and derive interesting insights.",.csv
IMDB movies dataset,1,imdb-movies-dataset,imdb_movies.csv,Community Data License Agreement - Permissive - Version 1.0,"The IMDB dataset contains information about movies, including their names, release dates, user ratings, genres, overviews, cast and crew members, original titles, production status, original languages, budgets, revenues, and countries of origin. This data can be used for various analyses, such as identifying trends in movie genres, exploring the relationship between budget and revenue, and predicting the success of future movies.",.csv
IMDb 5000+ Movies & Multiple Genres Dataset,1,imdb-5000-movies-multiple-genres-dataset,IMDb_All_Genres_etf_clean1.csv,CC0-1.0,"This dataset contains top rated movies from IMDb website, gathered based on different genres and are also in different languages. Movies from the early 1930s to current year titles are collected, cleaned and arranged in this dataset.

### Columns Description
- **'Movie_Title'**      :   Consist of 5000+ Movie Titles          (5000+ Unique Values)
-  **'Year'**                  :   Ranging from 1920s to 2022             (99 Unique Values)
- **'Director'**              :   Names the Director                            (2000+ Unique Values)
- **'Actors'**             :   Names the Actors                              (5000+ Unique & Multiple Values)
- **'Rating'**          :   Titles rated for 10 by 25k+ Voters    (74+ Unique Values)
- **'main_genre'**       :  Main Genre of the Title                        (13+ Unique Values)
- **'side_genre'**          :   Side / Multiple Genre of the Movie   (144+ Unique & Multiple Values)
- **'Runtime(Mins)'**   :  Total duration of the movie in Minutes            (156+ Unique Values)
- **'Censor'**  :              Censorship of the Movie                 (25+ Unique Values)
- **'Total_Gross'**    :       Total Box-Office Collection of the Movie (3500+ Unique Values)",.csv
IMDb India Movies,1,imdb-india-movies,IMDb Movies India.csv,CC0-1.0,"##Task Details
####Every dataset has a story and this set is pulled from IMDb.com of all the Indian movies on the platform. Clean this data by removing missing values or adding average values this process will help to manipulate the data to help with your EDA.

##Analyze data and provide some trends.

- Year with best rating
- Does length of movie have any impact with the rating?
- Top 10 movies according to rating per year and overall.
- Number of popular movies released each year.
- Counting the number of votes which movies preformed better in rating per year and overall.
- Any other trends or future prediction you may have
- Which director directed the most movies
- Which actor starred in the movie
- Any other trends you can find

Thank you for viewing my dataset, looking forward to seeing some codes.",.csv
IMDb Indonesian Movies,1,imdb-indonesian-movies,indonesian_movies.csv,CC0-1.0,"### Context

This IMDb Indonesian Movies Dataset contains information of 1262 Indonesian movies. The data was gathered using IMDb-Scraper and then was converted and cleaned into a .csv file.

### Acknowledgements

This dataset is collected from [IMDb.com](https://www.imdb.com/) by using IMDb-Scraper by [dojutsu-user](https://github.com/dojutsu-user/IMDB-Scraper).

### Content

There are more than 1200+ Indonesian Movies in the dataset consisting of 11 columns relating to each movie. Those columns are:
* title
* year
* description
* genre
* rating
* users_rating
* votes
* languages
* directors
* actors
* runtime

*Banner image source: Whatthefan!*",.csv
IMDb MOVIES (user friendly),1,idmb-movies-user-friendly,MOVIES.csv,CC0-1.0,"45K movies from IDMb. I have modified the original dataset (https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset) to make it more easy to use.

Null entries have been imputed either with 0 (in numerical columns) or 'not available' (in text columns).

Dictionary entries have been substituted with strings or lists.

More details can be found in: https://www.kaggle.com/code/jacopoferretti/imdb-movies-data-analytics-recommendation",.csv
IMDb Top 2000 Movies,1,imdb-top-2000-movies,IMDb Top 2000 Movies.csv,MIT,Data was obtained from the website using web scraping for educational purposes in order to determine which movie is the best based on the ratings of each movie. So you may analyze and suggest others above a 9 rating.,.csv
INR to dollar currency monthly (01-12-03:30-04-24),1,inr-to-dollar-currency-monthly-01-12-0330-04-24,INRX.csv,ODC Public Domain Dedication and Licence (PDDL),"The dataset of INR to Dollar exchange rates from 2003 to 2024 downloaded from Yahoo Finance likely contains historical exchange rate data for the Indian Rupee (INR) against the US Dollar (USD) over the specified time period. Here's a general description of what you might find in such a dataset:

1. Date: Each entry in the dataset likely includes a date or timestamp indicating when the exchange rate was recorded.

2. Exchange Rate: The dataset should include the exchange rate value, representing the number of Indian Rupees equivalent to one US Dollar on the corresponding date.

3. Time Period: The dataset should cover exchange rate data for each trading day or a specified frequency (e.g., weekly, monthly) from 2003 to 2024.

4. Additional Information: Depending on the source and format of the dataset, it may include additional information such as opening, high, low, and closing exchange rates for each day, as well as volume and adjusted closing prices.

5. Currency Pair: The dataset focuses specifically on the exchange rate between the Indian Rupee (INR) and the US Dollar (USD), allowing users to analyze trends and fluctuations in the value of the Indian Rupee relative to the US Dollar over time.

6. The dataset of INR to Dollar exchange rates from 2003 to 2024 downloaded from Yahoo Finance likely contains historical exchange rate data for the Indian Rupee (INR) against the US Dollar (USD) over the specified time period. Here's a general description of what you might find in such a dataset:

1. Date: Each entry in the dataset likely includes a date or timestamp indicating when the exchange rate was recorded.

2. Exchange Rate: The dataset should include the exchange rate value, representing the number of Indian Rupees equivalent to one US Dollar on the corresponding date.

3. Time Period: The dataset should cover exchange rate data for each trading day or a specified frequency (e.g., weekly, monthly) from 2003 to 2024.

4. Additional Information: Depending on the source and format of the dataset, it may include additional information such as opening, high, low, and closing exchange rates for each day, as well as volume and adjusted closing prices.

5. Currency Pair: The dataset focuses specifically on the exchange rate between the Indian Rupee (INR) and the US Dollar (USD), allowing users to analyze trends and fluctuations in the value of the Indian Rupee relative to the US Dollar over time.

6. Data Quality: It's important to consider the reliability and accuracy of the data. Ensure that the dataset is sourced from a reputable financial data provider like Yahoo Finance and that any missing or erroneous data points are appropriately handled.

Overall, this dataset can be used for various analytical purposes, including trend analysis, forecasting, and risk management in the context of currency exchange markets and international finance.: It's important to consider the reliability and accuracy of the data. Ensure that the dataset is sourced from a reputable financial data provider like Yahoo Finance and that any missing or erroneous data points are appropriately handled.

Overall, this dataset can be used for various analytical purposes, including trend analysis, forecasting, and risk management in the context of currency exchange markets and international finance.",.csv
IPCC Scenarios Data Explorer,1,ipcc-scenarios-data-explorer,ipcc-scenarios new.csv,CC0-1.0,"this created in OurWorldData:

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F0db46310ee6f9ba7a65bfc8a867de109%2Fgraph1.png?generation=1715812199356501&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fe37e17efe12058fe59a3fa3e25ae7a3e%2Fgraph2.png?generation=1715812205772053&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fdfe63b8f70b6313daadf21502ed26671%2Fgraph3.png?generation=1715812211231492&alt=media)

What are the Shared Socioeconomic Pathways (SSPs)?
The Shared Socioeconomic Pathways are a set of scenarios which are central to the work of the UN climate reports produced by the Intergovernmental Panel on Climate Change (IPCC).

Why are these scenarios so important for the IPCC report?

How much greenhouse gas emissions the world emits in the coming decades is unknown. It is up to us. It will depend on what people around the world will do now and in the future.

In this situation, it’s helpful to create scenarios that cover a range of possible futures. This is what the ‘Shared Socioeconomic Pathways’ (SSPs) are. SSPs are the possible futures that climate researchers in the IPCC consider in their models.

SSPs do not tell us what the world will look like. Instead, they tell us what the world could look like.

The key aspect of these scenarios is the emissions of greenhouse gases that result. This is the key aspect because that what will determine the future of the climate.

To understand how our emissions might evolve we need to know how the world might change from a socioeconomic and technological perspective. These scenarios therefore differ in their assumptions about socioeconomic and technological development in the coming decades.

The socioeconomic and technological factors that the SSPs include are: population growth, economic growth, urbanization, trade, energy, and agricultural systems. You find all them in the Data Explorer above.

For more details on how SSPs are constructed, Zeke Hausfather has written an excellent explainer for Carbon Brief on this topic.

Summaries of the five Shared Socioeconomic Pathways
There are five key SSPs that are used in the research, and adopted by the IPCC. 

Below we provide the full description – as given by the IPCC – of these futures.

In summary, SSP1 provides the most positive scenario for both human development and environmental action. We continue to see improvements in education and health across the world; large reductions in poverty; and a shrinking in global inequalities. This is a scenario in which the researchers at the same time envision that the world is moving into a much more sustainable direction. 

SSP5 is similarly optimistic in terms of human development, but achieves this through a large growth in fossil fuels. This is therefore leading to continued large negative effects on the environment.

SSP3 and SSP4 are pessimistic about development: they envision a divided future with high levels of nationalism and large persistent global inequalities as a result. SSP2 sits in the middle of these scenarios: development is not as slow or divided as in SSP3 and SSP4, but progress is slow and unequal.",.csv
IPL 2022-Dataset,1,ipl-2022dataset,Book_ipl22_ver_33.csv,ODbL-1.0,"#Complete Match-wise data of IPL 2022

#MAKE AN EDA with this dataset


*******Content*****
This dataset contains Matchwise data of IPL matches 2022 (March26 - May29 2022) ,The complete data of group stage matches.

****Attribute Information****
1. Match Number
2. Date of the match
3. Name of Venue
4. Playing team 1
5. Playing team 2
6. Stage of the tournament
7. Toss winning team
8. Decision of toss winning team
9. First innings score
10. First innings wickets
11. Second innings score
12. Second innings wickets
13. Winning Team
14. Specify whether won by runs or wickets
15. Winning Margin
16. Player of the match (Best Performance)
17. Top scoring Batter in the match
18. Highscore in the match (Highest Individual score from both teams)
19. Bowler who has best bowling figure in the match
(if two or more bowlers has the same bowling figure ,bowler who takes more wickets from less number of overs is selected)
20.  Best bowling Figure in the match
(if two bowlers has the same bowling figure ,bowler who takes more wickets from less number of overs is selected)

******Acknowledgement******
Data Source credit : https://www.espncricinfo.com/

## Please appreciate the effort with an upvote 👍 ,if you found this useful..

*Stay Tuned for Updated Versions of this Dataset*

****THANK YOU****",.csv
IPL 2024 Players Auction Stats,1,ipl-2024-players-auction-stats,auction.csv,CC0-1.0,"Get the scoop on IPL 2024 players' auction! This CSV dives into the numbers, revealing who got picked, for how much, and by which team. Explore the stats and strategies behind this season's cricket action!",.csv
IPL 2024: Player Lifetime Dataset,1,ipl-2024-player-lifetime-dataset,cricket_data.csv,Apache 2.0,"Dive into the heart of the exhilarating IPL 2024 season with this comprehensive dataset, offering a treasure trove of statistics on the stellar performances of cricket's brightest stars. With meticulous records spanning across various facets of the game, this dataset encapsulates the essence of each player's journey throughout the tournament.

Attributes included in the dataset:

**Year:** The year of the IPL season, indicating 2008 to 2024 in this case.

**Player_Name:** Names of the players showcasing their prowess on the cricket field.

**Matches_Batted:** The number of matches in which the player batted.

**Not_Outs:** Number of times the player remained not out while batting.

**Runs_Scored:** Total runs scored by the player throughout the season.

**Highest_Score:** Player's highest individual score in a single match.

**Batting_Average:** The average runs scored per dismissal.

**Balls_Faced:** Total number of balls faced by the player while batting.

**Batting_Strike_Rate:**The rate at which the player scores runs per 100 balls faced.

**Centuries:** Number of centuries scored by the player.

**Half_Centuries:** Number of half-centuries scored by the player.

**Fours:** Total number of boundaries (4 runs) hit by the player.

**Sixes:** Total number of sixes (6 runs) hit by the player.

**Catches_Taken:** Number of catches taken by the player in the field.

**Stumpings:** Number of times the player effected a stumping as a wicketkeeper.

**Matches_Bowled:** The number of matches in which the player bowled.

**Balls_Bowled:** Total number of balls bowled by the player.

**Runs_Conceded:** Total runs conceded by the player while bowling.

**Wickets_Taken:** Number of wickets taken by the player.

**Best_Bowling_Match:** Player's best bowling performance in a single match.

**Bowling_Average:** The average runs conceded per wicket taken.

**Economy_Rate:** The average number of runs conceded per over bowled.

**Bowling_Strike_Rate:** The rate at which the player takes wickets per ball bowled.

**Four_Wicket_Hauls:** Number of times the player took four wickets in an inning.

**Five_Wicket_Hauls:** Number of times the player took five wickets or more in an inning.


This dataset serves as a goldmine for cricket enthusiasts, analysts, and data scientists alike, offering valuable insights into the performance metrics and trends shaping the IPL 2024 season. Whether you're exploring individual player statistics or uncovering overarching patterns, this dataset provides a rich foundation for in-depth analysis and exploration of one of the world's most electrifying cricket leagues.",.csv
IPL AUCTION 2024 DATASET,1,ipl-auction-2024-dataset,IPL AUCTION 2024 DATASET.csv,Apache 2.0,"Dive into the Excitement: Explore the IPL Auction 2024 Dataset! Uncover the player signings, team strategies, bidding wars and more from the latest IPL auction. Analyze the trends, evaluate player values, and discover the pulse of the cricketing world as teams assemble their squads for the upcoming season. Whether you're a cricket enthusiast or sports analyst this comprehensive dataset provides valuable insights into one of the most electrifying events in the world of cricket.",.csv
IPL Auction 2023,1,ipl-auction-2023,iplauction2023.csv,CC0-1.0,"Welcome to the IPL 2023 Auction dataset, a comprehensive compilation of data capturing the high-stakes player auctions in the cricketing world. This dataset contains the details of the IPL 2023 auction and the player's status for the next IPL edition.

### Attributes:

**names:** Names of the players.
**player style:** This represents the playing style of the player (Bowler, Batter, AllRounder, WK-Batter).
**nationality**: This represents the nationality of the player.
**base price (in lacs):** This column represents the base price of the player. The values are in lacs.
**final price (in lacs)**: This represents the final price of the player. The values are in lacs.

**franchise:** This attribute contains the name of the franchise to which the player belongs
(CSK,MI,KKR,RR,LSG,DC,RCB,GT,SRH,PBKS).

**status:** This represents the status of players ( RETAINED, SOLD, UNSOLD).

This dataset can be used to analyze the player availability for each franchise and can be used to get insights about the demands based on the player style.",.csv
IPL Match Dataset 2008-2023: Complete Records,1,ipl-match-dataset-2008-2023,Cricket_data.csv,CC-BY-NC-SA-4.0,"&gt;The IPL Match Dataset is a comprehensive collection of match-wise records from the Indian Premier League (IPL) spanning the years 2008 to 2023. This dataset provides detailed information on various aspects of each IPL match, allowing for in-depth analysis and exploration of the tournament's history.

### The dataset contains the following columns:

1. `Season`: Indicates the specific season of the IPL match, ranging from 2008 to 2023.
2. `ID`: This represents a unique identifier for each match, enabling easy referencing and tracking.
3. `Name`: Provides the full name of the match, offering descriptive information about the teams or occasion.
4. `Short Name`: Offers a concise abbreviation or short name for the match, facilitating quick identification.
5. `Description`: Provides a brief summary or overview of the match, offering additional context or insights.
6. `Home Team`: Specifies the home team participating in the match.
7. `Away Team`: Specifies the away team participating in the match.
8. `Toss Won`: Indicates the team that won the toss prior to the match.
9. `Decision`: Specifies the decision made by the team winning the toss (batting or fielding).
10. `1st Inning Score`: This represents the score achieved by the team batting first.
11. `2nd Inning Score`: Represents the score achieved by the team batting second.
12. `Winner`: Specifies the winning team of the match.
13. `Result`: Describes the outcome of the match, including the winning margin or wickets.
14. `Start Date`: Indicates the start date of the match.
15. `End Date`: Specifies the end date of the match.
16. `Venue ID`: Provides a unique identifier for the venue where the match took place.
17. `Venue Name`: Specifies the name of the venue where the match was held.
18. `Home Captain`: Represents the captain of the home team.
19. `Away Captain`: Represents the captain of the away team.
20. `Player of the Match (POM)`: Identifies the standout player who received the Player of the Match award.
21. `Points`: Indicates the points earned by the teams based on the match result.
22. `Super Over`: Indicates whether a super over was played to determine the winner (Yes/No).
23. `Home Overs`: Specifies the number of overs played by the home team.
24. `Home Runs`: Represents the total runs scored by the home team.
25. `Home Wickets`: Specifies the number of wickets lost by the home team.
26. `Home Boundaries`: Indicates the number of boundaries (fours and sixes) hit by the home team.
27. `Away Overs`: Specifies the number of overs played by the away team.
28. `Away Runs`: Represents the total runs scored by the away team.
29. `Away Wickets`: Specifies the number of wickets lost by the away team.
30. `Away Boundaries`: Indicates the number of boundaries (fours and sixes) hit by the away team.
31. `Highlights`: Provides noteworthy highlights or key moments from the match.
32. `Home Key Batsman`: Specifies the key batsman for the home team in the match.
33. `Home Key Bowler`: Specifies the key bowler for the home team in the match.
34. `Home Playing XI`: Represents the playing XI (eleven) for the home team.
35. `Away Playing XI`: Represents the playing XI (eleven) for the away team.
36. `Away Key Batsman`: Specifies the key batsman for the away team in the match.
37. `Away Key Bowler`: Specifies the key bowler for the away team in the match.
38. `Match Days`: Indicates the number of days the match spanned.
39. `Umpire 1`: Specifies the first umpire officiating the match.
40. `Umpire 2`: Specifies the second umpire officiating the match.
41. `TV Umpire`: Specifies the TV umpire for the match.
42. `Referee`: Represents the match referee overseeing the match.
43. `Reserve `Umpire: Specifies the reserve umpire assigned for the match.

&gt;The IPL Match Dataset offers a rich and extensive collection of data for researchers, analysts, and cricket enthusiasts. It enables the exploration of team performances, individual player contributions, match dynamics, and various other factors that influence the outcomes of IPL matches. With its comprehensive records and diverse information, the dataset provides an opportunity to delve into the captivating world of IPL cricket across multiple seasons.

- The original source of the dataset can be found at '[https://www.kaggle.com/datasets/rajsengo/indian-premier-league-ipl-all-seasons](https://www.kaggle.com/datasets/rajsengo/indian-premier-league-ipl-all-seasons)'.",.csv
IPL Playing XI Complete Dataset (2008-2023),1,ipl-playing-xi-complete-dataset-2008-2023,players.csv,CC0-1.0,"This dataset consists of information regarding all of the playing XIs (or XIIs, more recently) ever played in the tournament. 

The table consists of season, match_id, the team and the players array as the columns.
",.csv
IRIS dataset,1,iris-dataset,iris.csv,Apache 2.0,"The Iris dataset is a classic dataset in the field of machine learning, containing measurements of various features of iris flowers, such as sepal length, sepal width, petal length, and petal width, along with their corresponding species. Through analysis, we aim to explore the characteristics of different iris species, identify patterns in their measurements, and potentially build predictive models to classify iris species based on their features. This dataset serves as an excellent resource for understanding and practicing classification techniques in data science.",.csv
IRONMAN World Championship - 2022,1,ironman-world-championship-2022,ironman_wc_2022.csv,MIT,"The data was gathered from [IRONMAN](https://www.coachcox.co.uk/imstats/race/1879/results/)

This dataset provides detailed information about participants in a triathlon race, including their bib numbers, names, countries, genders, division categories, division ranks, overall completion times, overall ranks, swim times, swim ranks, bike times, bike ranks, run times, run ranks, and finish status.


The data captures the performances of individual participants in various segments of the triathlon race and their overall standings, providing valuable insights into their athletic achievements.",.csv
IRR Gold Historical Dataset: 2014-2024(1393-1402),1,irr-gold-historical-dataset-2014-20241393-1402,GoldIRR(1393-1403).csv,Apache 2.0,"This dataset provides a comprehensive record of 24 karat gold prices denominated in Iranian Rial (IRR) over a specified time period, spanning from May 2, 2014 (Jalali date: 1393/02/12), to March 18, 2024 (Jalali date: 1402/12/28). Gold, being a valuable and globally recognized commodity, holds significant economic importance, particularly in Iran where it serves as a key indicator of economic stability and investor sentiment.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F7986509%2F68ac78ea8e130837d4714464463ea6a7%2FGold%20Final%20Image.png?generation=1712666019810678&alt=media)",.csv
ITC - NSE - 24 Year Stock Data📈,1,itc-nse-24-year-stock-data,ITC-EQ-01-04-2000-to-31-03-2024.csv,CC0-1.0,"**Description:**
This dataset contains 24 years of historical stock data for ITC Limited, a leading Indian multinational conglomerate engaged in businesses such as FMCG (Fast-Moving Consumer Goods), hotels, paperboards, and agri-business. The data spans from [start year] to [end year] and includes daily stock metrics such as opening price, closing price, high, low, volume, and more, providing a comprehensive view of ITC's performance in the National Stock Exchange (NSE).

**Context:**
The dataset offers valuable insights into the long-term trends, volatility, and trading patterns of ITC stocks, facilitating quantitative analysis and investment research. Researchers, analysts, and investors can leverage this dataset to conduct historical performance analysis, develop trading strategies, and make informed investment decisions related to ITC Limited.

**Sources:**
The dataset is sourced from reliable financial data providers and publicly available stock market archives. The data undergoes rigorous validation and cleaning processes to ensure accuracy and consistency, providing users with reliable information for their analyses.

**Inspiration:**
The creation of this dataset was inspired by the growing interest in quantitative finance, stock market analysis, and algorithmic trading within the data science community. By making this dataset available on platforms like Kaggle, we aim to empower researchers, data scientists, and enthusiasts to explore the dynamics of ITC's stock performance and contribute to the advancement of financial analytics and investment strategies.",.csv
Ice-Cream Sales Dataset,1,ice-cream-sales-dataset,Ice Cream.csv,Apache 2.0,"# Ice Sales Dataset
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F19517213%2F5a71e291ee639a7244f2d22f48df2abf%2FKC3004_katie-lee-biegel-edible-cereal-treat-bowls-for-ice-cream-sundae-2_s4x3.jpg?generation=1711695793922646&alt=media)
## Description:
Explore the correlation between temperature and ice sales revenue with this dataset. The dataset contains two columns: temperature (in Celsius) and revenue (in USD). Dive into the relationship between temperature fluctuations and ice sales to uncover insights and trends.

## Columns:
- Temperature: Temperature recorded during the sales period.
- Revenue: Ice sales revenue corresponding to each temperature.

## Purpose:
Analyze how variations in temperature affect ice sales revenue. Gain valuable insights for business strategies, marketing campaigns, and inventory management in the ice sales industry.

## Data Range:

Temperature: -0°C to 45°C
Revenue: $10 to $1,000",.csv
Illegal Immigrants Arrested by US Border Patrol,1,illegal-immigrants,arrests.csv,CC0-1.0,"# Content

This report provides statistics for the number of illegal immigrants arrested or apprehended by the border patrol in each division (or sector) of the United States borders with Canada, Mexico, and Caribbean islands; this data is a partial measure of the flow of people illegally entering the United States.


# Acknowledgements

Data was compiled and published by the US Border Patrol on the Customs and Border Protection webpage.",.csv
Illicit Drugs,1,illicit-drugs,deaths-illicit-drugs NEW.csv,CC0-1.0,"this graph was created in PowerBi,Loocker studio and R :

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F0a55982887797c990c4d33e225c3a302%2Fgraph1.jpg?generation=1713382500158908&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Faae21487e8484150276c3f7aa3ad06e4%2Fgraph2.jpg?generation=1713382506649413&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fe723dc72a422c3e5af399f322ac77087%2Fgraph3.png?generation=1713382511956515&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Feb7a3b1becdb8f701b7124a8b25022d8%2Fgraph4.gif?generation=1713382518265931&alt=media)

Illicit drugs are drugs that have been prohibited under international drug control treaties.1 

International statistics typically focus on four different groups of illicit drugs: opioids, cocaine, cannabis, and amphetamines. However, a range of other illicit drugs is included in international drug control treaties, including plant-based drugs and synthetic hallucinogens. The UNODC’s publication “Terminology and Information on Drugs”2 contains a comprehensive list of illicit drugs.

Excess consumption or dependency on illicit drugs can impact overall health, mental well-being, and in many cases, the well-being of others. Not all illicit drugs have similar impacts on health and well-being: some cause much less harm than others.

On this page, you can find a list of key insights as well as a list of visualizations on illicit drug use. This provides a global overview of illicit drug use, dependency disorders, and some of their impacts.
",.csv
Immigrants by citizenship and Age,1,immigrants-by-citizenship-and-age,DIOC_CITIZEN_AGE_refined.csv,CC0-1.0,"🔍This a dataset detailing immigration patterns by citizenship and age. This dataset consists of demographic data that can be used to analyze trends in immigration patterns, understand the composition of immigrant populations, and identify potential factors influencing migration.🌎

🔍Note: This was sourced from [OECD](https://stats.oecd.org/Index.aspx?DataSetCode=MIG) and refined for further analysis.

🔍Image by <a href=""https://pixabay.com/users/aumglobal2-42419048/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=8579109"">Aum Global</a> from <a href=""https://pixabay.com//?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=8579109"">Pixabay</a>",.csv
Immigration to Canada,1,immigration-to-canada,canadian_immegration_data.csv,CC0-1.0,"### Context

The Main Purpose for uploading this dataset is to analyze the trends and hidden patterns of Immigrants from all over the world to Canada.


### Content

This dataset consists of immigrants record from 150+ countries to Canada between 1980 to 2013.


### Acknowledgements

[Data Source](https://www.un.org/en/development/desa/population/migration)

### Inspiration
  
By using Data visualization , find out hidden Patterns .",.csv
Impact of Forest on Understory 2,1,impact-of-forest-on-understory-2,data.csv,CC0-1.0,"**Impact of Forest on Understory 2** dataset - Seasonal drivers of understorey temperature buffering in temperate deciduous forests across Europe.

[**Impact of Forest on Understory 1** dataset](https://www.kaggle.com/datasets/yekenot/impact-of-forest-on-understory) - Changes in forest structure drive temperature preferences of boreal understory plant communities.

*(the following information provided by the authors of the experiment)*

Forest understory microclimates are often buffered against extreme heat or cold, with important implications for the organisms living in these environments. We quantified seasonal effects of understory microclimate predictors describing canopy structure, canopy composition and topography (i.e. local factors), as well as forest patch size and distance to coast (i.e. landscape factors).

Location: temperate forests in Europe.

Time period: 2017-2018.

Major taxa studied: woody plants methods.

**Methodology:**

We combined data from a microclimate sensor network with weather station records to calculate the difference – or offset – between temperatures measured inside and outside forests. We used regression analysis to study the effects of local and landscape factors on the seasonal offset of minimum, mean and maximum temperatures.

Results: maximum temperature during summer was on average cooler by 2.1 °C and minimum temperature during winter and spring were 0.4 °C and 0.9 °C warmer inside than outside forests.
The local canopy cover was a strong non-linear driver of the maximum temperature offset during summer, and we found increased cooling beneath tree species that cast the deepest shade. Seasonal offsets of minimum temperature were mainly regulated by landscape and topographic features, such as the distance to coast and topographic position.

Main conclusions: forest organisms experience less severe temperature extremes than suggested by currently available macroclimate data, so climate-species relationships and species' responses to anthropogenic global warming cannot be modelled accurately in forests using macroclimate data alone. Changes in canopy cover and composition will strongly modulate warming of maximum temperatures in forest understories, with important implications for understanding responses of forest biodiversity and functioning to the combined threats of land-use change and climate change. Our predictive models are generally applicable across lowland temperate deciduous forests, providing ecologically important microclimate data for forest understories.

**Detailed information about each column follows:**

- **id:** Plot ID.
- **seaons:** Season.
- **buf_min:** Buffering/offset of minimum temperature (°C).
- **buf_max:** Buffering/offset of maximum temperature (°C).
- **buf_mean:** Buffering/offset of mean temperature (°C).
- **region:** Region ID.
- **Totalcov:** Canopy cover - visual estimation of vertical cover of shrub and tree layers, summed per species (%).
- **Dens:** Canopy openness - total number of quadrats of open sky visible on spherical densiometer (number).
- **North:**  Continuous variable describing the topographic exposition ranging from completely north exposed (−1) to completely south exposed (1).
- **Slp:** Topographic slope (degrees).
- **distcoast:** Distance to coast (km).
- **Easting:** Longitude.
- **Northing:** Latitude.
- **sca:** Tree species-specific shade casting ability - community-level mean index weighted by tree species-specific canopy cover (from one (tree species with very open canopy) to five (very dense and shady species)).
- **RelEmin500:** Topographic position (m).
- **WS_Tmin:** Minimum temperature at weather station (°C).
- **WS_Tmax:** Maximum temperature at weather station (°C).
- **WS_Tmean:** Mean temperature at weather station (°C).
- **forcov_250:** Forest cover - proportion of area covered by forest within a circular buffer area with a radius of 250 m (%).
- **alt:** Elevation above sea level (m).
- **BAm2ha:** Basal area (m2/ha).
- **temp:** Macroclimate long-term temperature (°C).
- **prec:** Macroclimate long-term precipitation (mm).
- **tempran:** Macroclimate long-term temperature range (°C).
- **dist2edge:** Distance to forest edge (m).
- **treeH:** Tree height (m).
- **CA:** Crown area (m2).
- **Wsalt:** Elevation at weather station (m above sea level).
- **altdif:** Difference in elevation between weather station and microclimate plot (m).
- **CCFischer:** Canopy cover corrected using Fischer formula.

**Acknowledgements:**

Associated manuscript: *Zellweger, Florian et al. (2019). Seasonal drivers of understorey temperature buffering in temperate deciduous forests across Europe*.

If you use this dataset in your research, please credit the original authors. 

https://doi.org/10.5061/dryad.cv1jg30",.csv
In Hospital Mortality Prediction,1,in-hospital-mortality-prediction,data01.csv,other,"### Context

The predictors of in-hospital mortality for intensive care units (ICU)-admitted HF patients remain poorly characterized. We aimed to develop and validate a prediction model for all-cause in-hospital mortality among ICU-admitted HF patients.

### Content

Using Structured Query Language queries (PostgreSQL, version 9.6), demographic characteristics, vital signs, and laboratory values data were extracted from the following tables in the MIMIC III dataset: ADMISSIONS, PATIENTS, ICUSTAYS, D_ICD DIAGNOSIS, DIAGNOSIS_ICD, LABEVENTS, D_LABIEVENTS, CHARTEVENTS, D_ITEMS, NOTEEVENTS, and OUTPUTEVENTS. Based on previous studies 7-9 13-15, clinical relevance, and general availability at the time of presentation, we extracted the following data: demographic characteristics (age at the time of hospital admission, sex, ethnicity, weight, and height); vital signs (heart rate, (HR), systolic blood pressure [SBP], diastolic blood pressure [DBP], mean blood pressure, respiratory rate, body temperature, saturation pulse oxygen [SPO2], urine output [first 24 h]); comorbidities (hypertension, atrial fibrillation, ischemic heart disease, diabetes mellitus, depression, hypoferric anemia, hyperlipidemia, chronic kidney disease (CKD), and chronic obstructive pulmonary disease [COPD]); and laboratory variables (hematocrit, red blood cells, mean corpuscular hemoglobin [MCH], mean corpuscular hemoglobin concentration [MCHC], mean corpuscular volume [MCV], red blood cell distribution width [RDW], platelet count, white blood cells, neutrophils, basophils, lymphocytes, prothrombin time [PT], international normalized ratio [INR], NT-proBNP, creatine kinase, creatinine, blood urea nitrogen [BUN] glucose, potassium, sodium, calcium, chloride, magnesium, the anion gap, bicarbonate, lactate, hydrogen ion concentration [pH], partial pressure of CO2 in arterial blood, and LVEF), using Structured Query Language (SQL) with PostgreSQL (version 9.6). Demographic characteristics and vital signs extracted were recorded during the ﬁrst 24 hours of each admission and laboratory variables were measured during the entire ICU stay. Comorbidities were identified using ICD-9 codes. For variable data with multiple measurements, the calculated mean value was included for analysis. The primary outcome of the study was in-hospital mortality, defined as the vital status at the time of hospital discharge in survivors and non-survivors.


### Acknowledgements

Zhou, Jingmin et al. (2021), Prediction model of in-hospital mortality in intensive care unit patients with heart failure: machine learning-based, retrospective analysis of the MIMIC-III database, Dryad, Dataset, https://doi.org/10.5061/dryad.0p2ngf1zd

### LICENSE -  CC0 1.0 Universal (CC0 1.0) Public Domain Dedication


Target Variable - Outcome
0 - Alive
1 -  Death",.csv
Incident Response Log,1,incident-response-log,incident_event_log.csv,CC0-1.0,"### Context

This is an event log of an incident management process extracted from data gathered from the audit system of an instance of the ServiceNowTM platform used by an IT company. 

### Content

The event log is enriched with data loaded from a relational database underlying a corresponding process-aware information system. Information was anonymized for privacy.

Number of instances: 141,712 events (24,918 incidents)
Number of attributes: 36 attributes (1 case identifier, 1 state identifier, 32 descriptive attributes, 2 dependent variables)

The attributed closed_at is used to determine the dependent variable for the time completion prediction task. The attribute resolved_at is highly correlated with closed_a. In this event log, some rows may have the same values (they are equal) since not all attributes involved in the real-world process are present in the log.

Attributes used to record textual information are not placed in this log. The missing values should be considered unknown information.

### Acknowledgements

Thanks to University of SÃ£o Paulo, Brazil for this amazing dataset.

### Inspiration

Create a Machine learning application which predicts the estimated time and date for the final closure of a opened ticket based on the given attributes.",.csv
Income Predictor Dataset- US Adult,1,adult-income-census-dataset,adult.csv,CC0-1.0,"The Adult Census Income dataset, extracted from the 1994 US Census Database by Barry Becker, serves as a valuable resource for understanding the intricate interplay between socio-economic factors and income levels. Comprising anonymized information such as occupation, age, native country, race, capital gain, capital loss, education, work class, and more, this dataset offers a comprehensive view of the American demographic landscape.

**Dataset Overview**
The dataset consists of two CSV files: adult-training.txt and adult-test.txt, each row representing an individual. Key features include occupation, age, native country, race, capital gain, capital loss, education, work class, and more. The target variable, 'income_bracket', categorizes individuals into two groups: ""&gt;50K"" and ""&lt;=50K"".

**Exploration and Preprocessing**
Exploring the dataset reveals a mix of categorical and continuous features, as well as missing values. Understanding the distribution and relationships of these features is crucial for feature selection and data preprocessing, including handling missing values and encoding categorical variables.

**Modeling and Evaluation**
To predict income levels, various classifiers can be trained on the training dataset and evaluated using the test dataset. Algorithms such as logistic regression, decision trees, random forests, and neural networks can be employed based on the dataset's complexity and the desired performance metrics.",.csv
India Literacy Data - District Wise,1,india-literacy-data-district-wise,Literacy Data 2011.csv,other,"### Context

Government of India(GoI) does Census of entire country every ten years, last census was done in 2011 and next will be done in 2021. Purpose of census is to get good understanding of the country population and other associated things, these data helps GoI to create and enhance the the policy and new reforms.

### Content

The attached CSV file has data related to Literacy in India according to India Census 2011.
- First Column has simple serial number
- Second column has the District name 
- Third column has State name corresponding to the district from second column.
- Last column has the Literacy data  corresponding to the district from second column.

### Acknowledgements

All thanks to GoI and volunteers who help in collecting dataset. 

### Inspiration

This can be used to get insight about the education, as well as it can used along with other datasets as per need.",.csv
India Loksabha elections data(1962-2019),1,india-loksabha-elections-data19622019,Loksabha_1962-2019 .csv,other,"### INTRIDUCTION

India is one of the largest democratic nations in the world. In India elections to the Indian parliament(Loksabha elections) are usually conducted every 5 years. There are more than 500 parliament constituencies in India and the data regarding these constituencies of each elections are huge. Here I am presenting you the opportunity to learn about political trends in India with a large dataset containing election data of all constituencies in India from 1962 to 2019(By elections are not included in this data set)


### About my data
In this huge data set I have included many useful aspects such as the name of the candidates, their political parties, votes, etc


### Acknowledgements

.The data regarding elections in India are available for the public on various government and non-government websites.


### Inspiration
The data about the elections in one of the largest democratic nations is in front of you now it is up to you
what can you do 
",.csv
India Special Trains Dataset (2020-2021),1,india-special-trains-dataset-2020-2021,Scraped.csv,Community Data License Agreement - Sharing - Version 1.0,"The data is about special trains in India that are run when there is extra traffic that needs to be addressed. The data contains information like the day of the week, coach_types, class_types per train. Also we have the route of each of these special trains. You can hence also use the dataset to analyze the surplus traffic train movement network in India.",.csv
India's City Data: Population Growth Insights,1,indias-city-data-population-growth-insights,City_Population_Data.csv,CC-BY-NC-SA-4.0,"Uncover the evolution of Indian cities through this dataset, detailing their names, status, district, and population figures from 1991, 2001, and 2011. Explore the changing urban landscape and population dynamics of India over the years.",.csv
Indian Agriculture Dataset,1,indian-agriculture-dataset,ICRISAT-District Level Data.csv,Attribution 4.0 International (CC BY 4.0),"**Disclaimer: **
DLD is an open-access database. Users are advised to upload only the datasets they intend to use for their analysis, ensuring appropriate citation. Interested users are encouraged to explore the database based on the provided citation: *https://doi.org/10.21421/D2/XFB1BZ*

For additional information on terms of use and other queries, please refer to the 'About Us' page at *http://data.icrisat.org/dld/src/about-dld.html*

We hope this information helps and clarifies any queries you may have.

**District-wise yearly area, yield and production.**
This file group has two files: 1. Area, production and yield and 2. High yielding varieties The area, production yield file includes data on 20 major crops that include cereals, pulses, oilseeds, cotton, sugarcane, total fruits and vegetables. Yield is calculated based on area and production.

The data are for the annual area and production under the crops. The percent area under each crop is calculated by dividing crop area by Gross Cropped Area (GCA variable generated using a defined methodology).

For more details see definition and standards and in the data documentation manual the section on ‘data clarification and anomalies’.For season wise crop area and production data refer to season wise area and production of crops under additional data); for breakup of fruits and vegetables data by type also see files on area and vegetables under additional data.

The second file is on High Yielding Varieties (HYV / hybrids) has data on area under HYVs for 5 major cereal crops. The data on HYVs has a number of gaps in recent years implying that the area is completely under HYVs and hence no longer reported / some states do not publish this data.


**guys please upvote me!!!**

",.csv
Indian Candidates for General Election 2019,1,indian-candidates-for-general-election-2019,LS_2.0.csv,CC-BY-NC-SA-4.0,"### Context

With over 600 Million voters voting for 8500+ candidates across 543 constituencies, the general elections in the world's largest democracy are a potential goldmine of data. While there are existing separate datasets about the votes each candidate received and the personal information of each candidate, there was no comprehensive dataset that included both these information. Thus, this dataset will provide more usability than most existing datasets in this domain.

### Content

I scraped the website of myneta.info to get the personal information of each candidate (as per their own sworn affidavits) and the website of Election Commission of India to get the data about the votes received. I merged both this datasets to create this comprehensive dataset. Only the candidates who secured at least 1% of the total votes polled in their constituency have been included. 

### Acknowledgements

I have collected the data from MyNeta.info maintained by the Association for Democratic Reforms and the website of Election Commission of India.


### Inspiration
There are 2 main tasks that can be performed on this dataset: Exploratory Data Analytics to visualize the impact of each feature of the candidate and the use of machine learning to predict the chances of winning of a candidate. ",.csv
Indian Cars: Data Analysis and Visualization,1,indian-cars-data-analysis-and-visualization,cars_ds_final.csv,Apache 2.0,Car Sales Figures | Autopunditz. Around 3.34 Lakh passenger cars were sold in the Indian market in May 2023. The sales increased by over 13% when compared to May last... The Top 25 Selling Cars constituted over 75% of the cars sold in April 2023.,.csv
Indian Cities Electricity Consumption 2017-19,1,indian-cities-electricity-consumption-2017-19,electricity-consumption-india-city-level-2017-19.csv,MIT,"### Dataset Overview

The dataset provides a comprehensive overview of electricity consumption across various sectors in Indian cities, focusing on key metrics such as domestic, commercial, industrial, public infrastructure, and other purposes.

#### Components of the Dataset:

- **City**: This column lists the names of different cities in India for which the electricity consumption data is recorded.
- **Year**: Indicates the specific year to which the consumption data corresponds.
- **Consumption of Electricity (in lakh units)**:
  - **Domestic purpose**: Represents the amount of electricity consumed for household usage in each city, measured in lakh units.
  - **Commercial purpose**: Indicates the electricity consumption for commercial activities such as businesses and offices.
  - **Industry purpose**: Reflects the electricity consumption attributed to industrial activities within the respective cities.
  - **Public Water Work & Street Light**: Denotes the electricity usage for public infrastructure like street lighting and water works.
  - **Others**: Encompasses any additional purposes for which electricity is consumed beyond the specified categories.
  - **Total Consumption**: Presents the overall electricity consumption combining all the aforementioned sectors.
- **Percentage Distribution**:
  - Provides the percentage distribution of electricity consumption across different purposes for specific cities or years.
  - For instance, ""Nagpur"" and ""Varanasi"" are mentioned with respective percentage distributions for certain years, indicating their share of electricity consumption across various sectors.
- **Unique Values**: Indicates the count of unique values present in each category, which seems to be 47 in this dataset.
- **NA Values**: Denotes any missing or unrecorded data, represented as ""NA"" in this dataset.

### Insights and Implications

Overall, this dataset offers valuable insights into the electricity consumption patterns in Indian cities, facilitating analysis and decision-making processes related to energy management, urban planning, and infrastructure development. By understanding how electricity is utilized across different sectors, policymakers and stakeholders can devise strategies to promote energy efficiency, sustainability, and economic growth.
",.csv
Indian Electoral Bonds Data | Complete,1,complete-indian-electoral-bonds-data,IndianElectoralBonds.csv,ODC Public Domain Dedication and Licence (PDDL),"# Indian Electoral Bonds Dataset

The current released bonds data by SBI is cleaned and presented as to use for Analysis. The total description of the data can be found in the pinned notebook in the 'Code' section

The Dataset contains complete details as published by the SBI in the public domain",.csv
Indian Food Dataset,1,indian-food-dataset,IndianFoodDatasetCSV.csv,CC0-1.0,"When I browsed for a Food Recipes (Especially Indian Food) Dataset, I could not find one (that I could use) online. So, I decided to create one.

The dataset has following fields (self-explanatory) - ['RecipeName', 'TranslatedRecipeName', 'Ingredients', 'TranslatedIngredients', 'Prep', 'Cook', 'Total', 'Servings', 'Cuisine', 'Course', 'Diet', 'Instructions', 'TranslatedInstructions']. The datset contains a csv and a xls file. Sometimes, the content in Hindi is not visible in the csv format.

You might be wondering what the columns with the prefix 'Translated' are. So, a lot of entries in the dataset were in Hindi language. To take care of such entries and translating them to English for consistency, I went ahead and used 'googletrans'. It is a python library that implements Google Translate API underneath.

The code for the crawler, cleaning and transformation is on my Github repository (@kanishk307).

The dataset has been created using Archana's Kitchen Website. It is a great website and hosts a ton of useful content. You should definitely consider viewing it if you are interested.

The dataset can be used to answer a lot of questions related to Food Recipes. You can see the explore the serving sizes, time required to prepare a dish, most common ingredients, different cuisines, diets, courses and what not. I hope this dataset helps the Analytics community.
",.csv
"Indian Fresher Job Market with salary, location ",1,indian-fresher-job-market,job_market.csv,MIT,"Explore the Indian Fresher Job Market with this comprehensive dataset. Dive into the salaries, job titles, and locations of entry-level job opportunities across various industries in India. Whether you're a job seeker, recruiter, or analyst, this dataset provides valuable insights into the dynamics of the Indian job market for fresh graduates.


Check these [Datasets](https://kaggle.com/nuhmanpk/datasets) too


Photo by <a href=""https://unsplash.com/@clemono?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Clem Onojeghuo</a> on <a href=""https://unsplash.com/photos/shallow-focus-photography-of-red-and-white-for-hire-signage-fY8Jr4iuPQM?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv
Indian Grocery Prices in Sydney,1,indian-grocery-prices-in-sydney,indian_store.csv,Apache 2.0,"This dataset contains extensive product listings from a grocery store that targets the Indian market. This dataset includes a rich variety of items, particularly emphasizing organic and culturally specific products. With over 5,700 entries, the dataset provides a deep dive into the pricing, quantity, and category details of products sold, making it a valuable resource for market analysis, consumer behavior studies, and strategic planning in retail.

### Dataset Details:
- Product Name: The name of each product.
- Product Category: Broader category classification reflecting specialized segments such as organic products, staple foods, and more.
- Product Price: Listed price in AUD Dollars.
- Product Price (INR): Converted price in Indian Rupees for local market comparison.
- Quantity: Specifies the amount or size of the product packaging.

### Applications and Utility:

This dataset is particularly suited for:
- **Market Analysis**: Understand pricing strategies and product popularity in Indian grocery sectors.
Consumer Behavior Studies: Analyze preferences for organic and specialty products in the Indian market.
- **Supply Chain Management**: Insights into product categories and quantities can aid in inventory and supply chain optimization.
- **Competitive Analysis**: Retailers can assess their product offerings and pricing against those in this dataset to find competitive gaps or opportunities.",.csv
Indian Liver Patient Dataset,1,indian-liver-patient-dataset,Indian Liver Patient Dataset (ILPD).csv,DbCL-1.0,"### Data Set Information
This data set contains 416 liver patient records and 167 non liver patient records.The data set was collected from test samples in North East of Andhra Pradesh, India. 'is_patient' is a class label used to divide into groups(liver patient or not). This data set contains  441 male patient records and 142 female patient records.
Any patient whose age exceeded 89 is listed as being of age ""90"".

### Attribute Information
1. *age* Age of the patient
2. *gender* Gender of the patient
3. *tot_bilirubin* Total Bilirubin
4. *direct_bilirubin* Direct Bilirubin
5. *alkphos* Alkaline Phosphotase
6. *sgpt* Alamine Aminotransferase
7. *sgot* Aspartate Aminotransferase
8. *tot_proteins* Total Protiens
9. *albumin* Albumin
10. *ag_ratio* Albumin and Globulin Ratio
11. is_patient Selector field used to split the data into two sets (labeled by the experts)



### Acknowledgements
The data set has been elicit from UCI Machine Learning Repository. My sincere thanks to them.
",.csv
Indian Liver Patient Records,1,indian-liver-patient-records,indian_liver_patient.csv,CC0-1.0,"### Context

Patients with Liver disease have been continuously increasing because of excessive consumption of alcohol, inhale of harmful gases, intake of contaminated food, pickles and drugs. This dataset was used to evaluate prediction algorithms in an effort to  reduce burden on doctors. 

### Content

This data set contains 416 liver patient records and 167 non liver patient records collected from North East of Andhra Pradesh, India.  The ""Dataset"" column is a class label used to divide groups into liver patient (liver disease) or not (no disease). This data set contains 441 male patient records and 142 female patient records. 

Any patient whose age exceeded 89 is listed as being of age ""90"".

Columns:

- Age of the patient 
- Gender of the patient 
- Total Bilirubin 
- Direct Bilirubin 
- Alkaline Phosphotase 
- Alamine Aminotransferase 
- Aspartate Aminotransferase 
- Total Protiens 
- Albumin 
- Albumin and Globulin Ratio 
- Dataset: field used to split the data into two sets (patient with liver disease, or no disease)


### Acknowledgements

This dataset was downloaded from the UCI ML Repository:

Lichman, M. (2013). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.

### Inspiration

Use these patient records to determine which patients have liver disease and which ones do not. ",.csv
Indian Movies IMDb Rating Dataset,1,indian-movies-imdb-rating-dataset,IMDbRatings_IndianMovies.csv,CC0-1.0,"This dataset contains information about movies related to or produced in India. Here's a description of the dataset based on the provided columns:
**Name:** The title or name of the movie.
**Year:** The year the movie was released.
**Duration:** The duration or length of the movie.
**Genre:** The category or type of movie, indicating its theme or style.
**Rating:** The IMDb rating or score given to the movie, typically out of 10.
**Votes:** The number of votes or ratings the movie has received on IMDb.
**Director:** The name of the director(s) who directed the movie.
**Actor 1:** The name of the primary actor or lead actor in the movie.
**Actor 2:** The name of the secondary actor or supporting actor in the movie.
**Actor 3:** The name of another actor who appears in the movie, often in a supporting role.",.csv
Indian Restaurants 2023 🍲,1,indian-restaurants-2023,restaurants.csv,DbCL-1.0,"# Context

Dineout is a table booking platform helping customers to do table booking in their favourite restaurants for free and help them get great discounts.

The website is well known for displaying user ratings for restaurants, hotels, b&b, touristic attractions, and other places, with a total word count of all reviews is more than 10 million.

# Content
The Dineout dataset includes thousands of  restaurants with attributes such as location data, average rating, number of reviews, cuisine types, etc.

The dataset combines the restaurants from the main Indian cities.

# Acknowledgements
Data has been retrieved from the publicly available website https://www.dineout.co.in/.

All the restaurants from the main Indian cities have been scraped in early March 2023.

# Inspiration
To provide further information in regards to the restaurants details that make them successful and appreciated by the users, with the possibility to compare the common features of different European countries regarding the average ratings, awards, open hours, reviews count, etc.",.csv
Indian Unicorn startups 2023 Latest updated,1,indian-unicorn-startups-2023-june-updated,Indian Unicorn startups 2023 updated.csv,Apache 2.0,"The Indian startup ecosystem has witnessed remarkable growth over the years, with numerous companies emerging as disruptors and game-changers in their respective industries. As of June 2023, a comprehensive CSV (Comma-Separated Values) file provides an up-to-date snapshot of the Indian unicorn startup landscape. This CSV file encapsulates crucial information about the Indian unicorn startups, shedding light on their progress, funding, and impact on the economy.

The term ""unicorn"" refers to privately held startups that have achieved a valuation of $1 billion or more. These companies are considered rare and exceptional, representing the epitome of innovation, scalability, and market potential. The CSV file serves as a valuable resource for researchers, investors, and industry enthusiasts, enabling them to delve into the dynamics of the Indian startup ecosystem and understand the latest trends and developments.

By examining the CSV file, one gains access to a wealth of information about each Indian unicorn startup. The file includes details such as the company name, sector, founding year, location, valuation, and notable investors. This comprehensive dataset empowers users to perform in-depth analysis, identify emerging trends, and make informed decisions regarding investments, partnerships, and collaborations.

The CSV file not only highlights the success stories of well-known Indian unicorn startups but also brings attention to lesser-known yet promising ventures that are making significant strides. It showcases the diverse sectors in which these unicorns operate, including e-commerce, fintech, healthtech, edtech, transportation, and many more. Such a broad representation illustrates the breadth and depth of the Indian startup ecosystem and its ability to cater to a wide range of consumer needs.

The frequent updates to the CSV file ensure that it remains a valuable resource for tracking the growth and evolution of Indian unicorn startups. It captures the dynamism and rapid pace at which the ecosystem evolves, reflecting the constant influx of funding, new players, and disruptive ideas. Researchers and stakeholders can rely on this dataset to monitor the progress of existing unicorns, discover new rising stars, and gain insights into the factors driving the success of these ventures.

In conclusion, the CSV file compiling data on Indian unicorn startups for June 2023 is an invaluable resource that provides a comprehensive overview of the Indian startup ecosystem. It offers a wealth of information on these remarkable companies, their sectors, funding details, and notable investors. As India continues to foster a fertile environment for innovation and entrepreneurship, this dataset serves as a window into the realm of Indian unicorns, revealing their achievements, potential, and impact on the Indian economy.


Indian startups,Unicorn companies,Startup ecosystem,2023,Indian economy,Funding trends,Investor landscape,Innovation and entrepreneurship,Sector analysis,Market potential,1billiondollars.",.csv
Indian cities database,1,indian-cities-database,Indian Cities Database.csv,CC0-1.0,"Here is a list of prominent cities in India. Each row includes a city's latitude, longitude, state, and other variables of interest. 

### Acknowledgements
[simplemaps.com](https://simplemaps.com/data/in-cities)



",.csv
Indian food cuisine dataset,1,indian-food-cuisine-dataset,Indain_Food_Cuisine_Dataset.csv,CC0-1.0,"The dataset consists of 7200+ food information entries. In this dataset the information such as Category of food , Type of cuisine, Procedure to make, Time required, Course, Diet-type, Ingredients used,etc. are shown with not Nan values. The images are provided with label. ",.csv
Indian hotels on Booking.com,1,indian-hotels-on-bookingcom,booking_com-travel_sample.csv,CC-BY-SA-4.0,"###Context

This is a pre-crawled dataset, taken as subset of a [bigger dataset (more than 94,000 hotels)][1] that was created by extracting data from Booking.com, a leading travel portal.

### Content

This dataset has following fields:

- address
- city
- country
- crawl_date
- hotel_brand
- hotel_description
- hotel_facilities
- hotel_star_rating
- image_count
- latitude
- locality
- longitude
- pageurl
- property_id
- property_name
- property_type
- province
- qts
- room_count
- room_type
- similar_hotel
- site_review_count
- site_review_rating
- site_stay_review_rating
- sitename
- special_tag
- state
- uniq_id
- zone

### Acknowledgements

This dataset was created by PromptCloud's in-house web-crawling service.

### Inspiration
Analyses of the property ratings and property type can be performed.

  [1]: https://www.promptcloud.com/datastock-access-ready-to-use-datasets/?utm_source=bk-kaggle&utm_medium=referral",.csv
Indian male and female name dataset,1,indian-male-and-female-name-dataset,Indian-Name.csv,ODbL-1.0,"### Indian Male And Female Data Set

This Data set was created to identify a gender as Male or Female. The dataset have Two parameters such as name and target. We can identify gender based on target value because target value is 0 and 1. 0( ZERO )  for Female and 1 ( ONE ) male.
",.csv
Indian startups,1,indian-startups-top-300,Startups1.csv,CC0-1.0,"# Context
A startup or start-up is a company or project undertaken by an entrepreneur to seek, develop, and validate a scalable business model. While entrepreneurship includes all new businesses, including self-employment and businesses that do not intend to go public, startups are new businesses that intend to grow large beyond the solo founder. In the beginning, startups face high uncertainty and have high rates of failure, but a minority of them do go on to be successful and influential.

# Content
The following dataset has data about the Top 300 startups in India. Details about the columns are as follows:
1. Company - Name of the Startup.
2. City - The City in which the startup is started.
3. Starting Year - The Year in which the startup was started.
4. Founders - Name of the founders of the startup.
5. Industries - Industrial domain in which the startup falls.
6. No. of Employees - Number of employees in the startup.
7. Funding Amount in USD - Total funding amount funded to the startup.
8. Funding Rounds - Funding rounds are the number of times a startup goes back to the market to raise more capital. The goal of every round is for founders to trade equity in their business for the capital they can utilize to advance their companies to the next level.
9. No. of Investors - Number of investors in the startup.  ",.csv
Indonesia School Dataset with Province Data,1,indonesia-school-dataset-with-province-data,complete_data.csv,MIT,"This dataset is made from https://www.kaggle.com/datasets/greegtitan/school-dataset-idn, supercharged with province data taken from BPS (Badan Pusat Statistik).

These are the features given in this dataset:

| province_name | city_name | district_name | school_name | stage | status | lat | long | province_area | total_population | total_education_age_population |
| --- | --- |
| Name of province| Name of city | Name of district | Name of school | Stage (SD, SMP, SMA) | Status (S = swasta, N = negeri) | Latitude | Longitude | Area of province | Total population of province | Total population of province with age 0-19 |
",.csv
Indonesian Food and Drink Nutrition Dataset,1,indonesian-food-and-drink-nutrition-dataset,nutrition.csv,CC0-1.0,"**Context**

Indonesia is a country that has abundant food wealth. Of course, foods and drinks from Indonesia have nutritional value that is beneficial for the body. This dataset may be able to provide insight into measuring the amount of nutrients that enter the body when consuming Indonesian food and drinks.

**Source**

This dataset was obtained from the Tabel Komposisi Pangan Indonesia (Indonesian Food Composition Table) data published by the Ministry of Health of the Republic of Indonesia (www.panganku.org). This dataset has gone through a modification process in the form of data cleaning and adding image links.

**Content**

This dataset contains 1346 rows of Indonesian food and drinks. Each row consists of 7 columns including:
- id: index data
- calories: the number of calories (in cal) per 100 grams of food/drink
- proteins: the amount of protein (in grams) per 100 grams of food/drink
- fat: the amount of fat (in grams) per 100 grams of food/drink
- carbohydrate: the amount of carbohydrates (in grams) per 100 grams of food/drink
- name: name of food/drink
- image: link to food/drink images",.csv
Industrial sector ESG ratings & stock market data,1,industrial-sector-esg-ratings-and-stock-market-data,Industrials-sector-ESG-and-stock-market-data.csv,other,"It can be difficult finding timely ESG data for multiple companies at a time unless you pay for an expensive subscription. This dataset includes ESG ratings and stock market information for approximately 700 companies.
When comparing ESG ratings, it's important to compare a company with their industry or sector peers rather than across industries. The reason is that there are different material issues and metrics that are considered more pertinent depending on the industry. For example, ESG ley issues and metrics for a railroad company will be different than for a bank).

This dataset includes companies that are categorized in the ""Industrials"" sector, per the Global Industry Classification System (GICs). It includes ESG ratings by 4 different ESG ratings providers, if that data is available for a particular company. It also includes stock market data pulled from the first week of April 2024 - that includes 52-week high and low prices, volume, etc. 

Example of chart made using this dataset:

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F7790751%2F8bbc5b936efdf14d6b338678bd6466f7%2Ftrucking-april2024%20-%20Copy.png?generation=1714329261083713&alt=media)

**Key columns and descriptors**

*Unique_id:* the number used by ESGAnalytics to uniquely distinguish each company

*Symbol*:  Stock symbol 

*Exchange*: stock index where the company is listed (one company may be listed on multiple exchanges in the real world)

*gicSector*: sector classification (this is higher on the hierarchy than subindustry per the GIC

gicSubindustry: subindustry classification, the next level down in the GIC hierarchy


***ESG ratings columns***

*Company_ESG_pulse*: the main ESG ratings of this dataset; 1 is lowest investor risk and -1 means highest investor risk

*ESG_beta*: how much the pulse rating affects the stock market price of the company, per ESGAnalytics

*SNP*: the S&P Global ESG rating for the company (scale of 1-100 with 100 being the LOWEST investment risk)

*Sustainalytics*: the Sustainalytics ESG rating for a company with ratings 0-10 meaning negligible investment risk; 10-20 low risk; 20-30 medium risk; 30-40 high risk; 40+ severe risk

*MSCI*: the MSCI ESG rating for the company with ratings of CCC,B, BB meaning an industry laggard; BB, BBB, A meaning average; AA, AAA meaning industry leader 

*Update_data-ESG_scores*: this is the date when the SNP, Sustainalytics, and MSCI scores were pulled; ESGAnalytics ratings were pulled April 2024 (as they are updated in real-time while the others are updated annually)

***Stock market columns***

Volume, Market Cap, 52w_highest price (52w means 52-week), 52w_lowest price, 52w_change price, 52w_average volumne were pulled the first week of April 2024.

***[For more details about the ESG ratings, please see my Medium post on ESG data providers.](https://medium.com/@jensplash/esg-data-providers-are-like-the-dating-pool-397cdb74dbbb)***

The data is available via ESGAnalytics.io and Finazon.io use licenses (per my subscriptions with them). 

Similar to others on kaggle who have shared ESG datasets, my objective is to help make ESG data more accessible and understandable so that more people are versed in what ESG is and how different companies rate.

Please let me know any comments or if there are other ESG-related datasets that you are interested in. Thank you!",.csv
Inequality in Education Around the World,1,inequality-in-education-around-the-world,Inequality in Education.csv,other,"### Context

In today's interconnected world, the issue of inequality in education stands as a stark reminder of the disparities that persist across countries and communities. While strides have been made to improve access to education, a significant proportion of children still lack the opportunity to learn, particularly in low-income and conflict-affected regions. Quality of education also diverges, with well-equipped schools in affluent areas contrasting with under-resourced institutions in marginalized settings. Gender inequality further compounds the problem, as cultural norms and economic factors often impede girls' education in certain societies. Tackling inequality in education isn't just a matter of fairness; it's a critical step towards building equitable societies and empowering individuals to contribute meaningfully to their own development and that of their nations.

### Content

This dataset contains historical data covering a range of indicators pertaining to educational inequality on a global scale. The dataset's prominent components include: ISO3, Country, Human Development Groups, UNDP Developing Regions, HDI Rank (2021), and Inequality in Education spanning the years 2010 to 2021.

### Dataset Glossary (Column-wise)

* <b>ISO3</b> - ISO3 for the Country/Territory
* <b>Country</b> - Name of the Country/Territory
* <b>Human Development Groups</b> - Human Development Groups
* <b>UNDP Developing Regions</b> - UNDP Developing Regions
* <b>HDI Rank (2021)</b> - Human Development Index Rank for 2021
* <b>Inequality in Education (2010)</b> - Inequality in Education for 2010
* <b>Inequality in Education (2011)</b> - Inequality in Education for 2011
* <b>Inequality in Education (2012)</b> - Inequality in Education for 2012
* <b>Inequality in Education (2013)</b> - Inequality in Education for 2013
* <b>Inequality in Education (2014)</b> - Inequality in Education for 2014
* <b>Inequality in Education (2015)</b> - Inequality in Education for 2015
* <b>Inequality in Education (2016)</b> - Inequality in Education for 2016
* <b>Inequality in Education (2017)</b> - Inequality in Education for 2017
* <b>Inequality in Education (2018)</b> - Inequality in Education for 2018
* <b>Inequality in Education (2019)</b> - Inequality in Education for 2019
* <b>Inequality in Education (2020)</b> - Inequality in Education for 2020
* <b>Inequality in Education (2021)</b> - Inequality in Education for 2021

### Data Dictionary

* <b>UNDP Developing Regions</b>:
 - <b>SSA</b> - Sub-Saharan Africa
 - <b>LAC</b> - Latin America and the Caribbean
 - <b>EAP</b> - East Asia and the Pacific
 - <b>AS</b> - Arab States
 - <b>ECA</b> - Europe and Central Asia
 - <b>SA</b> - South Asia

### Structure of the Dataset

![](https://i.imgur.com/qX5cmUX.png)

### Acknowledgement

This Dataset is created from <b>[Human Development Reports](https://hdr.undp.org/)</b>. This Dataset falls under the Creative Commons Attribution 3.0 IGO License. You can check the <b>[Terms of Use](https://hdr.undp.org/terms-use)</b> of this Data. If you want to learn more, visit the Website.

Cover Photo by: <b><a href=""https://www.freepik.com/free-vector/learning-concept-illustration_14230944.htm#query=education&position=12&from_view=keyword&track=sph"">Image by storyset</a> on Freepik</b>

Thumbnail by: <b><a href=""https://www.vecteezy.com/free-vector/educational""> Educational Vectors by Vecteezy</a></b>",.csv
Inflation Rate in Asia,1,inflation-rate-in-asia,ADO April 2023 - Inflation.csv,world-bank,"```
Figures and forecasts are as of ADB's Asian Development Outlook (ADO) 2023, released in April 2023.
```
#Countries Included:	
```
Afghanistan, Armenia, Azerbaijan, Bangladesh, Bhutan, Brunei, Darussalam, Cambodia, China, People's Republic of Cook Islands, Fiji, Georgia, Hong Kong, China, India, Indonesia, Kazakhstan, Kiribati Korea, Republic of Kyrgyz Republic Lao People's Democratic Republic Malaysia Marshall Islands Micronesia, Federated States of Mongolia Myanmar Nauru Nepal Pakistan Palau Papua New Guinea Philippines Samoa Singapore Solomon Islands Taipei, China Tajikistan Thailand Timor-Leste Tonga Turkmenistan Tuvalu Uzbekistan Vanuatu Viet Nam
```",.csv
Influenza_death,1,influenza-death,annualmortalityratefromseasonalinfluenzaages65 new.csv,CC0-1.0,"this graph was created in OurDataWorld, R , Loocker and Tableau

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fcae3bb501c71af31a491739671842d0d%2Fgraph1.png?generation=1712001396965624&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fb9bb57abd368d522f4f70edd77e44cd5%2Fgraph2.png?generation=1712001404173500&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Ffcc4718729d85efd4fb21eb4cdfb1ee3%2Fgraph3.jpg?generation=1712001411161330&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F3a1dd72755f5473cf5f9c0758edc1dd3%2Fgraph4.png?generation=1712001416526151&alt=media)

Introduction:
Seasonal influenza, often perceived as a common illness, carries a significant global burden, claiming hundreds of thousands of lives annually. Despite advancements in healthcare and vaccination efforts, the flu remains a formidable threat, particularly affecting vulnerable populations such as infants and the elderly. This article delves into the intricacies of influenza-related mortality, examining regional disparities, contributing factors, and the implications for public health.

The Global Landscape of Influenza Mortality:
Data from the Global Pandemic Mortality Project II sheds light on the magnitude of influenza-related deaths, drawing from surveillance metrics spanning from 2002 to 2011. These estimates, while informative, underscore the challenge of accurately gauging mortality rates, especially in low-income countries where testing and mortality records may be lacking.

Respiratory Symptoms and Beyond:
The conventional understanding of influenza-related fatalities primarily revolves around respiratory complications. Pneumonia and other respiratory ailments serve as prominent causes of death, contributing to the staggering toll of 400,000 lives claimed annually. However, it is imperative to acknowledge that the impact of influenza extends beyond respiratory symptoms. Complications such as strokes and heart attacks, though not explicitly captured in mortality estimates, further amplify the disease's lethality, warranting comprehensive preventive measures.

Vulnerability Across Age Groups:
Influenza's lethality is not uniform across age demographics. Infants and the elderly emerge as the most susceptible cohorts, bearing the brunt of severe complications and mortality. Among individuals aged over 65, the mortality rate stands at approximately 31 per 100,000 in Europe alone, reflecting the disproportionate impact on older populations. The interplay of age-related factors, including weakened immune responses and underlying health conditions, exacerbates the severity of influenza outcomes among these groups.

Regional Disparities and Determinants:
A notable aspect of influenza mortality lies in its disparate distribution across regions. While Europe and North America exhibit relatively lower death rates, countries in South America, Africa, and South Asia grapple with higher mortality burdens. This regional divide underscores the complex interplay of socio-economic factors, healthcare accessibility, and vaccination coverage. Poverty, inadequate healthcare infrastructure, and suboptimal vaccination rates converge to heighten vulnerability to influenza-related complications, amplifying mortality rates in resource-constrained settings.

Implications for Public Health:
The revelation of significant regional differentials in influenza mortality necessitates a tailored approach to public health interventions. Strengthening healthcare systems, particularly in low-income regions, is paramount to bolstering surveillance, enhancing diagnostic capabilities, and facilitating timely interventions. Furthermore, targeted vaccination campaigns, coupled with education initiatives, hold promise in mitigating influenza's toll, especially among vulnerable populations. Addressing socio-economic disparities and bolstering healthcare resilience emerge as pivotal strategies in fortifying global defenses against seasonal influenza.

Conclusion:
Seasonal influenza, often underestimated in its impact, exacts a substantial toll on global health each year. The multifaceted nature of influenza-related mortality underscores the need for a nuanced understanding and comprehensive mitigation strategies. By addressing regional disparities, prioritizing vulnerable populations, and fortifying healthcare systems, the global community can strive towards mitigating the burden of seasonal influenza, safeguarding lives, and fostering resilient health systems for generations to come.",.csv
Injury prediction dataset,1,injury-prediction-dataset,injury_data.csv,Apache 2.0,"To address the growing concern regarding player safety and injury prevention in competitive sports, we present a synthetic dataset designed specifically for injury prediction. By leveraging Python libraries such as NumPy and Pandas, we aim to create a realistic representation of player health and injury data. Our synthetic dataset captures critical attributes such as player demographics, training intensities, recovery times, and previous injury histories. We establish correlations between these features and the likelihood of future injuries to accurately simulate real-world scenarios.",.csv
Instagram Data,1,instagram-data,Instagram data.csv,other,"Instagram generates a lot of data every day. When content creators post on Instagram, they do look at their engagement and reach to find the category of posts they should post more. ",.csv
Instagram Ratings & Reviews: Appstore,1,instagram-ratings-and-reviews-appstore,appstore_instagram_reviews_anonymized.csv,ODC Attribution License (ODC-By),"### Dataset Overview
This meticulously curated dataset presents an insightful collection of 500 Instagram app reviews sourced directly from the Appstore, spanning five unique countries: the USA, Canada, the UK, Germany, and India. Each review encapsulates genuine user feedback, providing a rich tapestry of global user experiences with the Instagram application. This dataset offers a unique lens through which to understand the multifaceted user relationships with one of the world's leading social media platforms.

### Data Science Applications
Given its concise yet diverse nature, this dataset serves as an excellent resource for a variety of data science endeavors. It is particularly suited for qualitative analysis, sentiment analysis, and linguistic patterns within app reviews. Researchers and enthusiasts can explore cultural nuances in user feedback, conduct comparative analyses between regions, or develop models to predict user satisfaction based on review content. Its manageable size makes it ideal for educational purposes, allowing for in-depth analysis without the computational complexity of larger datasets.

### Column Descriptors
The dataset includes the following columns, providing a comprehensive framework for analysis:

- `appId`: The unique identifier for the Instagram app on the Appstore.
- `country`: The country from which the review was submitted, encompassing the USA, Canada, the UK, Germany, and India.
- `date`: The date on which the review was posted.
- `id`: A unique identifier for the review.
- `score`: The rating given by the user, ranging from 1 to 5.
- `text`: The full text of the user's review.
- `title`: The title of the review.
- `url`: The URL to the review on the Appstore.
- `userName`: Anonymized usernames to protect user privacy.
- `userUrl`: The URL to the user's Appstore profile.
- `version`: The version of the Instagram app being reviewed.

### Ethically Mined Data
This dataset has been ethically mined, ensuring full compliance with privacy standards and respect for user anonymity. Usernames have been encrypted to safeguard personal identities, reflecting a commitment to ethical data practices.

### Acknowledgements
Gratitude is extended to the Appstore and Instagram platforms for fostering an environment where user feedback is valued and accessible. Their transparent review systems not only enhance user experience but also contribute to the broader field of data science by providing valuable datasets such as this.

This dataset stands as a testament to the global community's engagement with Instagram, offering a window into the diverse perspectives and experiences of app users worldwide.",.csv
Instagram Reach Analysis: Case Study,1,instagram-reach-analysis-case-study,Instagram_data_by_Bhanu.csv,other,"data Source - https://statso.io/instagram-reach-analysis-case-study/

Certainly! Let's conduct a case study on Instagram reach analysis. To make the case study more specific, let's imagine a scenario where a fashion brand called ""Fashionista"" wants to analyze the reach of their Instagram account over the past six months.

Objective: Analyze the reach of Fashionista's Instagram account and identify trends, patterns, and insights that can help improve their reach and engagement.

Steps for the Instagram Reach Analysis:

1. Data Collection:
   - Gather data from Fashionista's Instagram account for the past six months.
   - Collect metrics such as follower count, post reach, impressions, likes, comments, and engagement rate.
   - Use Instagram's built-in analytics or third-party tools like Iconosquare or Sprout Social to retrieve the necessary data.

2. Define Key Metrics:
   - Identify the key metrics that will help assess the reach of Fashionista's Instagram account.
   - Key metrics may include follower growth rate, average reach per post, total impressions, engagement rate, and engagement per post.

3. Analyze Follower Growth:
   - Plot the follower count over the past six months to observe any trends.
   - Calculate the follower growth rate to understand the rate at which the account is gaining or losing followers.
   - Look for any significant changes in follower count and investigate potential reasons behind those changes.

4. Evaluate Post Reach and Impressions:
   - Analyze the average reach per post and total impressions to understand the reach of Fashionista's content.
   - Identify posts with the highest and lowest reach and compare their characteristics.
   - Look for patterns or themes that resonate well with the audience and those that underperform.

5. Assess Engagement:
   - Calculate the average engagement rate and compare it across different types of content (e.g., images, videos, stories, reels).
   - Identify posts with the highest engagement rate and analyze their content, captions, and hashtags.
   - Look for patterns or elements that encourage higher engagement from the audience.

6. Identify Optimal Posting Times:
   - Analyze the data to identify the days and times when Fashionista's posts receive the highest reach and engagement.
   - Experiment with posting at different times and measure the impact on reach and engagement.

7. Monitor Competitors:
   - Analyze the reach and engagement of Fashionista's competitors' Instagram accounts.
   - Identify strategies or content types that work well for competitors and consider adopting similar approaches if relevant.

8. Generate Insights and Recommendations:
   - Summarize the findings from the analysis and identify key insights and trends.
   - Recommend strategies to improve Fashionista's Instagram reach based on the insights obtained.
   - Provide actionable recommendations such as optimizing content, using relevant hashtags, collaborating with influencers, or running Instagram ads.

By conducting a thorough analysis of Fashionista's Instagram reach, you'll gain valuable insights into their audience's behavior, content performance, and engagement patterns. These insights can help guide future content strategies and optimize reach and engagement on Instagram.",.csv
Instagram fake and real accounts dataset,1,instagram-fake-and-real-accounts-dataset,final-v1.csv,CC0-1.0,"### Context
Fake users extracted from ""[Instagram fake accounts dataset](https://www.kaggle.com/rezaunderfit/instagram-fake-accounts-dataset)"". Real user are extracted from my private account on Instagram. This dataset can be use for detecting fake users.

## How was the data collected?
For fake user i bought followers and save theme on a file. ",.csv
"Insurace Data with 10,000 records",1,insurace-data-with-10000-records,insurance data.csv,MIT,"**Introduction to Health Insurance Charges Dataset**

This dataset provides insights into health insurance charges based on various demographic and health-related characteristics, serving as a practical resource for exploring regression analysis techniques. With over 10,000 records, this dataset offers a diverse range of observations, facilitating comprehensive analysis and modeling exercises in the domain of health insurance.

**Dataset Overview:**
- The dataset encompasses health insurance charges associated with individuals, where the charges are influenced by demographic factors and health attributes.
- Each record in the dataset represents an individual's health insurance charges along with corresponding demographic and health-related characteristics.
- Key features include gender, BMI (Body Mass Index), age, number of children, smoking status, and region, among others.
- The target variable, health insurance charges, is quantified based on the aforementioned characteristics.

**Data Characteristics:**
- **Gender:** Indicates the gender of the insured individual, distinguishing between male and female categories.
- **BMI (Body Mass Index):** A numerical measure derived from an individual's weight and height, serving as an indicator of body fatness.
- **Age:** Represents the age of the insured individual, a significant factor influencing health insurance charges.
- **Number of Children:** Indicates the number of children covered under the insurance plan, reflecting family size and potential healthcare needs.
- **Smoking Status:** Categorizes individuals based on their smoking habits, distinguishing between smokers and non-smokers.
- **Region:** Specifies the geographical region where the insured individual resides, capturing regional variations in healthcare costs and accessibility.
- **Health Insurance Charges:** The target variable, quantifying the charges associated with health insurance coverage, influenced by the individual's characteristics.
and some other columns too .

**Recommended Usage:**
- This dataset is ideal for individuals seeking practical exposure to regression analysis techniques in the context of health insurance charges prediction.
- By leveraging the dataset, learners can explore regression models to understand the relationships between demographic/health attributes and health insurance charges.
- Experimentation with feature engineering, model selection, and evaluation techniques can enhance proficiency in predictive modeling within the healthcare domain.
- Aspiring data scientists and analysts can utilize this dataset to develop predictive models and gain insights into factors driving health insurance charges, contributing to informed decision-making in healthcare management.

**Note:**
While this dataset offers valuable insights into health insurance charges prediction, users should exercise discretion and ethical considerations when handling sensitive healthcare data. Adherence to data privacy regulations and guidelines is paramount to safeguarding individuals' confidentiality and maintaining data integrity in healthcare analytics endeavors. Additionally, proper citation and acknowledgment of dataset sources foster transparency and accountability in data science practices.",.csv
Insurance Claim Analysis: Demographic and Health,1,insurance-claim-analysis-demographic-and-health,insurance_data.csv,other,"_____
# Insurance Claim Analysis: Demographic and Health Factors
### Impact on Risk and Severity of Insurance Claim
By Sumit Kumar Shukla [[source]](https://data.world/sumitrock)
_____

### About this dataset
> This dataset contains insightful information related to insurance claims, giving us an in-depth look into the demographic patterns of those receiving them. The dataset contains information on patient age, gender, BMI (Body Mass Index), blood pressure levels, diabetic status, number of children, smoking status and region. By analyzing these key factors across geographical areas and across different demographics such as age or gender we can gain a greater understanding of who is most likely to receive an insurance claim. This understanding gives us valuable insight that can be used to inform our decision making when considering potential customers for our services. On a broader scale it can inform public policy by allowing for more targeted support for those who are most in need and vulnerable. These kinds of insights are extremely valuable and this dataset provides us with the tools we need to uncover them!

### More Datasets
> For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
> - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
> This dataset provides a comprehensive examination of demographic and health data from insurance claims, which can be used to make predictions about a wide variety of health-related outcomes. It is designed to give users powerful insights into the relationship between different demographic factors such as age, gender, BMI, blood pressure etc., the presence of chronic diseases like diabetes, smoking status and region with insurance claim amounts. 
> 
> In order to make use of this dataset for research purposes or machine learning applications like predictive analytics, it is important to take various factors into consideration while using it. The following are some tips on how to use this dataset: 
> - Make sure that you analyze all variables in relation with one another instead of treating them separately; this will help you understand how they interact and affect one another before creating models or drawing conclusions from the data. 
> - Observe any relationships among three or more variables together - e.g., what’s the correlation between age & gender vs claim amount? This can be done using multidimensional analysis methods like factor analysis (FA) or cluster analysis (CA).  
> - Take into account hidden patterns in your dataset by looking for outliers or exceptions that might not otherwise be visible/apparent at first glance - these could signal unexpected influences on your variables when modeling/predicting results!  
> - When applying regression models on this dataset keep in mind that its properties may change over time due to external conditions such as policy changes by insurers or general trends in claims; retrain your models periodically if necessary accordingly!  
> 5 Finally when interpreting results obtained from analyzingthis datasets focus not only on numeric values but also try capturing qualitative characteristics so that you can get a deeper understanding about each variable influencing your prediction results!

### Research Ideas
> - Identifying trends in insurance claims based on age, gender, BMI, and blood pressure. 
> - Developing targeted marketing campaigns for customers at high risk of making an insurance claim. 
> - Investigating correlations between health traits (such as BMI and blood pressure) with the likelihood of making a claim

### Acknowledgements
> If you use this dataset in your research, please credit the original authors.
> [Data Source](https://data.world/sumitrock)
> 
>


### License
> 
> 
> See the dataset description for more information.

### Columns

**File: insurance_data.csv**
| Column name   | Description                                              |
|:--------------|:---------------------------------------------------------|
| **Diabetic**  | Whether the insured person is diabetic or not. (Boolean) |
| **Children**  | Number of children of the insured person. (Integer)      |
| **Smoker**    | Whether the insured person is a smoker or not. (Boolean) |
| **Claim**     | Amount of the insurance claim. (Float)                   |

### Acknowledgements
> If you use this dataset in your research, please credit the original authors.
> If you use this dataset in your research, please credit [Sumit Kumar Shukla](https://data.world/sumitrock).

",.csv
Insurance Claims Dataset,1,insurance-claims,Insurance claims data.csv,Apache 2.0,"---

**Dataset Description: Insurance Claims Prediction**

**Introduction:**
In the insurance industry, accurately predicting the likelihood of claims is essential for risk assessment and policy pricing. However, insurance claims datasets frequently suffer from class imbalance, where the number of non-claims instances far exceeds that of actual claims. This class imbalance poses challenges for predictive modeling, often leading to biased models favoring the majority class, resulting in subpar performance for the minority class, which is typically of greater interest.

**Dataset Overview:**
The dataset utilized in this project comprises historical data on insurance claims, encompassing a variety of information about the policyholders, their demographics, past claim history, and other pertinent features. The dataset is structured to facilitate predictive modeling tasks aimed at accurately identifying the likelihood of future insurance claims.

**Key Features:**
1. **Policyholder Information:** This includes demographic details such as age, gender, occupation, marital status, and geographical location.
2. **Claim History:** Information regarding past insurance claims, including claim amounts, types of claims (e.g., medical, automobile), frequency of claims, and claim durations.
3. **Policy Details:** Details about the insurance policies held by the policyholders, such as coverage type, policy duration, premium amount, and deductibles.
4. **Risk Factors:** Variables indicating potential risk factors associated with policyholders, such as credit score, driving record (for automobile insurance), health status (for medical insurance), and property characteristics (for home insurance).
5. **External Factors:** Factors external to the policyholders that may influence claim likelihood, such as economic indicators, weather conditions, and regulatory changes.

**Objective:**
The primary objective of utilizing this dataset is to develop robust predictive models capable of accurately assessing the likelihood of insurance claims. By leveraging advanced machine learning techniques, such as classification algorithms and ensemble methods, the aim is to mitigate the effects of class imbalance and produce models that demonstrate high predictive performance across both majority and minority classes.

**Application Areas:**
1. **Risk Assessment:** Assessing the risk associated with insuring a particular policyholder based on their characteristics and historical claim behavior.
2. **Policy Pricing:** Determining appropriate premium amounts for insurance policies by estimating the expected claim frequency and severity.
3. **Fraud Detection:** Identifying fraudulent insurance claims by detecting anomalous patterns in claim submissions and policyholder behavior.
4. **Customer Segmentation:** Segmenting policyholders into distinct groups based on their risk profiles and insurance needs to tailor marketing strategies and policy offerings.

**Conclusion:**
The insurance claims dataset serves as a valuable resource for developing predictive models aimed at enhancing risk management, policy pricing, and overall operational efficiency within the insurance industry. By addressing the challenges posed by class imbalance and leveraging the rich array of features available, organizations can gain valuable insights into insurance claim likelihood and make informed decisions to mitigate risk and optimize business outcomes.

--- 





| Feature                 | Description                                                                                           |
|-------------------------|-------------------------------------------------------------------------------------------------------|
| policy_id               | Unique identifier for the insurance policy.                                                           |
| subscription_length     | The duration for which the insurance policy is active.                                                |
| customer_age            | Age of the insurance policyholder, which can influence the likelihood of claims.                       |
| vehicle_age             | Age of the vehicle insured, which may affect the probability of claims due to factors like wear and tear.|
| model                   | The model of the vehicle, which could impact the claim frequency due to model-specific characteristics.|
| fuel_type               | Type of fuel the vehicle uses (e.g., Petrol, Diesel, CNG), which might influence the risk profile and claim likelihood.|
| max_torque, max_power  | Engine performance characteristics that could relate to the vehicle’s mechanical condition and claim risks.|
| engine_type             | The type of engine, which might have implications for maintenance and claim rates.                     |
| displacement, cylinder  | Specifications related to the engine size and construction, affecting the vehicle’s performance and potentially its claim history.|
| region_code             | The code representing the geographical region of the policyholder, as claim patterns can vary regionally.|
| region_density          | Population density of the policyholder’s region, which could correlate with accident and claim frequencies.|
| airbags                 | The number of airbags in the vehicle, indicating safety level which can influence claim probability.    |
| is_esc (Electronic Stability Control), is_adjustable_steering, is_tpms (Tire Pressure Monitoring System) | Features that enhance vehicle safety and could potentially reduce the likelihood of claims.|
| is_parking_sensors, is_parking_camera | Parking aids that might affect the probability of making a claim, especially in urban areas. |
| rear_brakes_type        | Type of rear brakes, which could be related to the vehicle’s stopping capability and safety.           |
| Various binary indicators (Yes/No) for specific vehicle amenities and safety features | Features like steering_type, turning_radius, length, width, gross_weight, etc., which together build a profile of the vehicle’s characteristics and its associated risk factors. |
| claim_status            | Indicates whether a claim was made (1) or not (0), which is the dependent variable the model aims to predict. |
",.csv
Insurance Classification,1,insurance-classification,insurance_classification.csv,MIT,"
Here's a brief description for each column in the dataset:

**Age:** Represents the age of the insured individual.

**Sex:** Indicates the gender of the insured individual (male or female).

**BMI:** Stands for Body Mass Index, a measure of body fat based on height and weight.

**Children:** Denotes the number of children or dependents covered by the insurance policy.

**Smoker:** Indicates whether the insured individual is a smoker or non-smoker.

**Region:** Represents the geographical region of the insured individual's residence.

**Expenses:** Represents the medical expenses incurred by the insured individual.",.csv
Insurance Dataset - Simple Linear Regression,1,insurance-dataset-simple-linear-regression,simplelinearregression.csv,CC0-1.0,Here in This Dataset we have only 2 columns the first one is Age and the second one is Premium You can use this dataset in machine learning for Simple linear Regression and for Prediction Practices.,.csv
International Business Machines Stocks from 2000,1,international-business-machines-stocks-from-2000,IBM.csv,CC0-1.0,"This dataset contains IBM Corporation stock prices from 01/01/2000 to 04/27/2024. The columns are as follows:

```Date``` - The date

```Open``` - The opening value

```High``` - The highest value

```Low``` - The lowest value

```Close``` - The closing value

```Adj Close``` - The adjusted closing value

```Volume``` - The trading volume of the stocks

I hope you will like this dataset. God bless you.",.csv
International Entities with Largest Debt Loads,1,international-entities-with-largest-debt-loads,International Entities with Largest Debt Loads.csv,Apache 2.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F14839888%2Fe58f7ee41cc083183e07a64ca826ed1a%2FGlobal%20Organizations%20Ranked%20by%20Workforce%20Size%20(2).png?generation=1715381651301724&alt=media)


**Introduction:**

This dataset represents top-ranked international public companies according to the level of the debt. International Entities with Largest Debt Loads dataset provides the thorough examination of the debt burden of the major corporations across the globe. Including statistical information within a wide range of industries and areas of operation, the dataset reveals the financial stability and predictability of the risks associated with the major international players. Delve into the system of damage it balances, which includes corporate-bonds and long-term borrowing and uncover the interconnection of the global economy. this dataset is gathered from companies market capital website. below i have given the details of the dataset and columns after that i have given some information about the use cases of this dataset.

**About Dataset Columns:**

In this dataset, I have provided 6 columns, which are as follows:

1. Rank: It shows the ranking number of the company.
2. Company: It displays the name of the company.
3. Stock Symbol: This column contains the stock symbols of the company.
4. Total Debt (USD): This column provides the total debt of the company in trillion US dollars.
5. Share Price: It contains the share price of the respective company.
6. Company Origin: This column provides the country name of the respective company.

**Use Cases of the dataset:**

1. Financial Analysis: Analyzing debt-to-equity ratios and debt sustainability is a valid use case for assessing the financial health of companies and making investment decisions.

2. Risk Assessment: Evaluating the debt levels and financial risk exposure of companies across sectors and regions is an appropriate application of this dataset.

3. Market Research: Understanding corporate borrowing trends and debt levels within specific industries and countries aligns with the purpose of this dataset.

4. Benchmarking: Comparing the debt profiles of companies against industry peers to identify outliers or potential opportunities is a valid use case for this dataset.

5. Investor Insights: Gaining insights into how debt levels impact stock prices and investor sentiment is a relevant application of this dataset.

6. Policy Making: Informing policymakers and regulators about the debt landscape of international corporations for regulatory oversight and risk management purposes is a suitable use case for this dataset.

",.csv
International Greenhouse Gas Emissions,1,international-greenhouse-gas-emissions,greenhouse_gas_inventory_data_data.csv,other,"The Greenhouse Gas (GHG) Inventory Data contains the most recently submitted information, covering the period from 1990 to the latest available year, to the extent the data have been provided. The GHG data contain information on anthropogenic emissions by sources and removals by sinks of the following GHGs (carbon dioxide (CO2), methane (CH4), nitrous oxide (N2O), hydrofluorocarbons (HFCs), perfluorocarbons (PFCs), unspecified mix of HFCs and PFCs, sulphur hexafluoride (SF6) and nitrogen triflouride (NF3)) that are not controlled by the Montreal Protocol.

GHG emission inventories are developed by Parties to the Convention using scientific and methodological guidance from the Intergovernmental Panel on Climate Change (IPCC), such as 2006 IPCC Guidelines for National Greenhouse Gas Inventories, Revised Guidelines for National Greenhouse Gas Inventories (1996), IPCC Good Practice Guidance and Uncertainty Management in National Greenhouse Gas Inventories (2000) and IPCC Good Practice Guidance on Land Use, Land-use Change and Forestry (2003).
Last update in UNdata: 23 Mar 2017 with data released in Nov 2016.

### Acknowledgements

This dataset was kindly published by the United Nation on the UNData site. You can find [the original dataset here](http://data.un.org/Explorer.aspx).

### License
[Per the UNData terms of use](http://data.un.org/Host.aspx?Content=UNdataUse): all data and metadata provided on UNdata’s website are available free of charge and may be copied freely, duplicated and further distributed provided that [UNdata](http://data.un.org/Explorer.aspx) is cited as the reference. ",.csv
International Master Programs in Germany 2024,1,international-master-programs-in-germany-2024,daad_international_master_programs.csv,CC0-1.0,"It is a dataset containing the information obtained by web scraping of masters programs for international students on the website of Daad, a German higher education institution.",.csv
Internet Advertisements Data Set,1,internet-advertisements-data-set,add.csv,DbCL-1.0,"### Context

 The task is to predict whether an image is an advertisement (""ad"") or not (""nonad"").




### Content

There are 1559 columns in the data.Each row in the data represent one image which is tagged as ad or nonad in the last column.column 0 to 1557 represent the actual numerical attributes of the images
 
### Acknowledgements

Lichman, M. (2013). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.

Here is a BiBTeX citation as well:

@misc{Lichman:2013 ,
author = ""M. Lichman"",
year = ""2013"",
title = ""{UCI} Machine Learning Repository"",
url = ""http://archive.ics.uci.edu/ml"",
institution = ""University of California, Irvine, School of Information and Computer Sciences"" }
https://archive.ics.uci.edu/ml/citation_policy.html",.csv
Internet Firewall Data Set ,1,internet-firewall-data-set,log2.csv,CC0-1.0,"### Source:

Fatih Ertam, fatih.ertam '@' firat.edu.tr, Firat University, Turkey.


### Data Set Information:

There are 12 features in total. Action feature is used as a class. There are 4 classes in total. These are allow, action, drop and reset-both classes.


### Attribute Information:

Source Port,Destination Port,NAT Source Port,NAT Destination Port,Action,Bytes,Bytes Sent,Bytes Received,Packets,Elapsed Time (sec),pkts_sent,pkts_received 


### Relevant Papers:

F. Ertam and M. Kaya, â€œClassification of firewall log files with multiclass support vector machine,â€ in 6th International Symposium on Digital Forensic and Security, ISDFS 2018 - Proceeding, 2018.",.csv
Internet Service Provider Customer Churn,1,internet-service-churn,internet_service_churn.csv,CC0-1.0,"### ***if u like the dataset, please upvoted it.***

### Context

There is a big competition between Internet providers. If a providers want to increase its revenue they needs more subscriber but keep existing customer is more important than having new ones. So  providers want to know which customer should cancel his service. we call this as churn. if the know who will go, maybe they can catch them with promotions.


### Content

we collect data for customer who use internet services and labeling the data if the customer is churn or not. U can use this dataset for create a churn model and predict the churn probability

if u use and like the dataset please give feedback me. thanks




",.csv
Interview Project Stock Price Predictions,1,interview-project-stock-price-predictions,interview_data.csv,MIT,"The dataset and the task were part of the screening process for a Quantitative Research Intern position at a well-known proprietary trading company. The whole task is presented below:

Consider that you are tasked with designing a neural network model to predict stock prices
 based on historical data, which includes not only the stock's past prices but also various
 economic indicators. The data sequence is quite long, covering several years of daily data
 points.
 1. Given the nature of this time series data, which approach would you choose (e.g., RNN,
 LSTM, GRU) and why? Please elaborate on the strengths and potential challenges of
 your chosen architecture in handling long sequences of data. What other approach
 would you consider and why?
 2. Time series prediction often faces the challenge of long-term dependencies in the data.
 How does your chosen architecture handle these dependencies, and what are the
 specific mechanisms involved?
 3. Which optimization algorithm(s) would you prefer for training this model, and why? What
 approach would you use to find the optimal model parameters, especially in the context
 of a large and potentially noisy dataset like stock prices?
 4. Briefly outline your approach to hyperparameter tuning for this model. Which
 hyperparameters do you think would be most critical to experiment with, and what
 strategies would you use to find the optimal values?
 5. Develop a neural network model to detect significant price moves (&gt;=1 std) and predict
 price of such moves for y1 and y2 over the next 30 days using the provided dataset.
 a. Explain in brief the analysis steps and design choices
 b. Conduct a thorough analysis to understand trends, distributions, and correlations
 in the data.
 c. Utilize visualizations to illustrate key aspects of the data.
 d. Create new features that could enhance the model's predictive power.
 e. Construct one or more LSTM neural networks to predict the target variables.
 f. Split the dataset into training and test sets, ensuring the last 400 trading days are
 reserved for testing.
 g. Experiment with different hyperparameters to optimize model performance.
 h. Create a comprehensive presentation (up to 20 slides) summarizing the
 methodology, results, and insights.
 i. Submit all Python code in a zip file, with adequate comments and documentation.",.csv
Intrusion detection Classifier,1,intrusion-detection-classifier,datacopy.csv,CC0-1.0,"Intrusion classification, also known as intrusion detection or intrusion prevention, is a crucial aspect of cybersecurity. It involves identifying and categorizing potentially harmful activities or unauthorized access attempts within a computer network or system. The goal is to detect and respond to security breaches promptly to prevent or minimize damage to the network, data, and systems.",.csv
Invoices Dataset,1,invoices,invoices.csv,DbCL-1.0,"The invoice dataset provided is a mock dataset generated using the Python Faker library. It has been designed to mimic the format of data collected from an online store. The dataset contains various fields, including first name, last name, email, product ID, quantity, amount, invoice date, address, city, and stock code. All of the data in the dataset is randomly generated and does not represent actual individuals or products. The dataset can be used for various purposes, including testing algorithms or models related to invoice management, e-commerce, or customer behavior analysis. The data in this dataset can be used to identify trends, patterns, or anomalies in online shopping behavior, which can help businesses to optimize their online sales strategies.



",.csv
IoT Agriculture 2024,1,iot-agriculture-2024,IoTProcessed_Data.csv,Attribution-NoDerivatives 4.0 International (CC BY-ND 4.0),"### Data Sources with Authors  
In the master's thesis research conducted by student Mohammed Ismail Lifta (2023-2024) at the Department of Computer Science, College of Computer Science and Mathematics- Tikrit University,Iraq. Data was collected from a smartly-equipped greenhouse. The study was supervised by Assistant Professor Wissam Dawood Abdullah, Director of the Cisco Networking Academy at Tikrit University. It involved the construction of a smart greenhouse equipped with advanced technologies for monitoring and controlling environmental conditions. The study included an application that links data to Google Sheets for remote monitoring and control, providing an effective platform for efficient management of the greenhouse. ( 13 features , 37923 Row)

### Columns and Data Types:
date (datetime64): The date and time the measurements were recorded.
temperature (int64): The recorded temperature in degrees Celsius.
humidity (int64): The percentage of humidity in the environment.
water_level (int64): The water level as a percentage.
N (int64): The nitrogen level in the soil, scaled from 0 to 255.
P (int64): The phosphorus level in the soil, scaled from 0 to 255.
K (int64): The potassium level in the soil, scaled from 0 to 255.
Fan_actuator_OFF (float64): Indicator for the fan actuator if it is off (0 or 1).
Fan_actuator_ON (float64): Indicator for the fan actuator if it is on (0 or 1).
Watering_plant_pump_OFF (float64): Indicator for the plant watering pump if it is off (0 or 1).
Watering_plant_pump_ON (float64): Indicator for the plant watering pump if it is on (0 or 1).
Water_pump_actuator_OFF (float64): Indicator for the water pump actuator if it is off (0 or 1).
Water_pump_actuator_ON (float64): Indicator for the water pump actuator if it is on (0 or 1).
### Additional Details:
The data was cleaned by removing duplicate rows and missing values.
Categorical columns were encoded using One-Hot Encoding technique to facilitate the use of the data in machine learning.
The file is ready for analysis and modeling using machine learning tools.

License
Licensed under the (CC BY-ND).

### How to Use
This data can be used for environmental research and studies. Proper attribution must be given when using this data in any publication.No Change the dataset.

### Contact
For more information or inquiries, please contact the principal researcher: Professor ( Assistant) Wisam Dawood Abdullah (Email: wisamdawood@tu.edu.iq).",.csv
Ipl-cricket-data-2008-2023,1,ipl-cricket-data-2008-2023,Ipl-clean-data2008-2023.csv,CC0-1.0,"
The Indian Premier League (IPL) is a professional Twenty20 cricket league in India. It was founded by the Board of Control for Cricket in India (BCCI) in 2008 and has since become one of the most popular and lucrative cricket leagues globally.
Format: The IPL follows a Twenty20 format, which means each team faces a single innings, batting for a maximum of 20 overs. Matches typically last around three to four hours, making them fast-paced and exciting.

Teams: The IPL consists of franchise teams representing different cities and regions across India. As of my last update, there were eight teams in the league, namely Chennai Super Kings, Delhi Capitals, Kolkata Knight Riders, Mumbai Indians, Punjab Kings, Rajasthan Royals, Royal Challengers Bangalore, and Sunrisers Hyderabad.

Players: Teams in the IPL consist of a mix of international and domestic players. Each team can have a maximum of four overseas players in their playing XI. Many of the world's top cricketers participate in the IPL, making it a highly competitive league.

Season: The IPL season typically runs for around two months, usually from March to May, although scheduling may vary slightly depending on other cricket events and considerations.

Venues: Matches in the IPL are played across various stadiums in India. Each team has its designated home ground, where they host a portion of their matches during the season.

Format: The league follows a double round-robin format, where each team plays against every other team twice in the group stage, once at home and once away. The top teams in the league standings advance to the playoffs, culminating in the final match to determine the champion.

Entertainment: The IPL is not only about cricket but also about entertainment. Matches feature cheerleaders, music, and various forms of entertainment during breaks, creating a festive atmosphere in the stadiums.

Popularity: The IPL has gained immense popularity not only in India but also worldwide. It attracts large television audiences and considerable sponsorship and advertising revenue, making it one of the wealthiest cricket leagues globally.",.csv
Iran_Bourse_Overal_Index,1,iran-bourse-overal-index,Overall_Index.csv,other,"Tehran Overal index from 2008 to 2023

The total price index in the stock exchange, which is called the total index for short, indicates the changes in the general level of prices in the entire market and expresses the average increase or decrease in stock prices in the market. The total index does not show the amount of cash dividends paid to shareholders. For example, when it is said that the total index has grown by 30%, it means that the average stock price of listed companies has increased by 30% compared to the base year. Keep in mind that the total index can be checked and viewed in real time on the website of the Stock Exchange Technology Management Company at www.tsetmc.com.",.csv
Iris Species,1,iris,Iris.csv,CC0-1.0,"The Iris dataset was used in R.A. Fisher's classic 1936 paper, [The Use of Multiple Measurements in Taxonomic Problems](http://rcs.chemometrics.ru/Tutorials/classification/Fisher.pdf), and can also be found on the [UCI Machine Learning Repository][1].

It includes three iris species with 50 samples each as well as some properties about each flower. One flower species is linearly separable from the other two, but the other two are not linearly separable from each other.

The columns in this dataset are:

 - Id
 - SepalLengthCm
 - SepalWidthCm
 - PetalLengthCm
 - PetalWidthCm
 - Species

[![Sepal Width vs. Sepal Length](https://www.kaggle.io/svf/138327/e401fb2cc596451b1e4d025aaacda95f/sepalWidthvsLength.png)](https://www.kaggle.com/benhamner/d/uciml/iris/sepal-width-vs-length)


  [1]: http://archive.ics.uci.edu/ml/",.csv
Italy's Earthquakes,1,italy-earthquakes,italy_earthquakes_from_2016-08-24_to_2016-11-30.csv,CC0-1.0,"# Context 

This dataset contains data about the earthquakes that hit the center of Italy between August and November 2016. For some simple visualizations of this dataset you can checkout [this post][1].


# Content

The dataset contains events from 2016-08-24 to 2016-11-30. It's a single .csv file with the following header:

* Time,Latitude,Longitude,Depth/Km,Magnitude

The dataset contains 8087 rows (8086 of data + 1 of header)


# Acknowledgements

The dataset was collected from this [real-time updated list][2] from the Italian Earthquakes National Center.


# Inspiration

I hope that someone in the kaggle community will find this dataset interesting to analyze and/or visualize.


  [1]: http://www.thedataware.com/post/italys-recent-earthquakes-a-look-at-the-data
  [2]: http://cnt.rm.ingv.it/",.csv
JN.1(COVID-19 variant) Sentiment Analysis,1,jn-1covid-19-variant-sentiment-analysis,New Corona Variant.csv,Apache 2.0,"The JN.1(COVID-19 variant) Sentiment Analysis dataset provides a comprehensive exploration of public sentiments surrounding the specific COVID-19 variant named JN.1. This dataset encompasses a diverse range of textual data, including social media posts and online discussions. Researchers can leverage this dataset to gain insights into how individuals perceive and react to the JN.1 variant, shedding light on the broader social and emotional impact of emerging virus strains.

NOTE: The labelling is done based on likes on the comment.",.csv
Jamalon Arabic Books Dataset,1,jamalon-arabic-books-dataset,jamalon dataset.csv,other,"### Context

Jamalon is the largest online bookstore in the Middle East, offering more than 9.5 million titles of Arabic and English books with home delivery. This dataset contains a wide collection of Arabic books in different fields of different categories.

### Content

More than 8000 Arabic books. Each row represents a book and displays its information.

### Acknowledgements

This dataset was scraped from Jamalon bookstore website.

### Inspiration

What categories of books are most expensive? What are the popular books categories recently? What are the most popular  category of writing recently?",.csv
Jamboree-Linear-Regression,1,jamboree-linear-regression-dataset,jamboree_dataset.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"Context
Jamboree has helped thousands of students like you make it to top colleges abroad. Be it GMAT, GRE or SAT, their unique problem-solving methods ensure maximum scores with minimum effort.
They recently launched a feature where students/ learners can come to their website and check their probability of getting into the IVY league college. This feature estimates the chances of graduate admission from an Indian perspective.",.csv
Jeopardata,1,jeopardata,jeopardata.csv,MIT,"Jeopardy gameplay data from https://www.jeopardy.com/track/jeopardata, transformed for data analysis usability into CSV format using a data scraper I built here: https://github.com/GeorgeDiNicola/jeopardy-data-scraper. Useful for data analysis, visualizations, machine learning modeling/prediction, etc. An example using the data for visualization: https://public.tableau.com/app/profile/george.dinicola/viz/JeopardyStatistics/JeopardyViz_1",.csv
JoJo Stands Stats,1,jojo-stands-stats,jojo-stands.csv,CC-BY-SA-4.0,"<h1>⭐ JoJo Stands' Stats ⭐</h1>

<br>

&gt; Stands Stats from JoJo Part 3 to Part 8

----

<h2>🔐 Dataset File 🔐</h2>

&gt; jojo-stands.csv

<br>

<h2>❓ Description ❓</h2>

This dataset contains information about all the 156 stands showed in JoJo Bizarre Adventure anime.

**The stands are from Part 3 to Part 8.**

<br>

<h2>📝 Variables 📝</h2>

- `Stand`: Stand's Name;
- `Power - PWR (破壊力 Hakairyoku)`: Measures the Stand's strength and ability to cause destruction (physical injury or collateral environmental damage) in a given period of time.
- `Speed - SPD (スピード Supīdo)`: Measures the Stand's agility and reflexes as well as performance speed.
- `Range - RNG (射程距離 Shatei Kyori)`: Measures a compromise of the Stand's range of manifestation, range of ability influence, and spatial mobility.
- `Power Persistence - PER (持続力 Jizoku-ryoku)`: Measures the duration of time that the Stand can actively maintain its ability. It can also be used in the sense of the time it takes before a special ability can be activated again, such as Star Platinum: The World's time stop.
- `Precision - PRC (精密動作性 Seimitsu Dōsa-sei)`: Measures the Stand's accuracy and range of influence/effect of their abilities to specified targets. Automatic type Stands are generally evaluated with Rank D or under with a few exceptions.
- `Development Potencial - DEV (成長性 Seichō-sei)`: Measures the Stand's possible functions, utilization of its abilities and powers, and capacity to improve its overall capabilities. It decreases in rank as the user masters their Stand.

<br>

<h2>🏅 Stats Ranks 🏅</h2>

&gt; Power

<br>

- `None`: the stand is completely incapable of dealing any physical damage to a target or other Stand User without the necessary use of its Ability, and/or assistance of another party. This stat can also be used if a Stand has no physical manifestation whatsoever.

<br>

- `E`: the Stand is near incapable of utilizing its ability for a direct source of damage. This can also refer to the Stand's physical power having incredibly limited fields of damage, only capable of dealing damage similar to that of a toddler's strength.

<br>

- `D`: the Stand has a fair possibility of delivering slight physical harm to a target via the use of it's ability. Also refers to the strength of the Stand itself being somewhere lower than that of the average human by a considerable margin, but fatality isn't out of the question.

<br>

- `C`: the Stand has a fair capability of dealing with physical harm to a target via the use of its ability or own strength. The Stand shows that has strength incredibly similar, if not identical to that of an average human.

<br>

- `B`: the Stand has an above-average potential of being fatal when administering physical damage to a target via the use of its ability of natural strength. The Stand is significantly stronger than the average human and is capable of being within the range of breaking through Dry Wall to 2-inch Iron respectably.

<br>

- `A`: the Stand is more than capable of causing fatalities via the use of its ability or own ability or own natural strength. The Stand has physical abilities that are near flawless, extending from easily breaking apart tough metals to the nigh-infinite; however not quite exactly infinite.

<br>

- `Infinite`: the Stand has a near-limitless potential to cause fatality if it's ability is to be utilized properly. The Stand can cleave through the likes of Stands that possess A-Stats for Durability with absolutely no problem, and usually have abilities that surpass a large variety of defensive abilities.

----

&gt; Speed

<br>

- `None`: the Stand is quite literally incapable of movement in any sense of the matter without assistance from the User or other forces. Also be used if the Stand has no physical manifestation whatsoever.

<br>

- `E`: the Stand is extremely sluggish with its average movements, rarely ever pushing past 1-5 MPH. This may also include general movements. This can be due to range limitations, User limitations or just as a natural balance to the Stand's physical strength; or lack thereof.

<br>

- `D`: the Stand possesses a below-average speed of use, manifestation, and/or general movement that push the boundaries of about 6-11 MPH. This is below the average speed of a human, and could possibly be due to limitations on the User or Stand.

<br>

- `C`: the Stand is relatively comparable in most of it's general actions to that of a human. Whether this specifies down to attacking speed and/or spacial movement is dependent on the Stand. The speeds are averaged from around 12-28 MPH due to the range of average human speed. This number can be slightly above or below the average, only by around 10-30 MPH depending on the User's physical traits.

<br>

- `B`: the Stand is capable of impressive speeds when considering it's attacking speed, manifestation speed or generalized movement. This number is a slightly drastic jump from about 29-65 MPH. This may or may not take into consideration a Stand's physical capability to throw punches or attacks, but more focuses on spacial movement.

<br>

- `A`: the moviment around and attack velocity are very large in playing field, from the range of 66 MPH to near the Speed of Light depending on the Stand. Stands with an A-Stat in Speed tend to be fantastic attackers with blinding movements that can only be picked up by Stands that possess an A-Stat in Precision (most of the time).

<br>

- `Infinite`: the Stand itself can move; either through extensive build-up, powering up, or on the rare-chance immediately, at an undefined limit of speed (ranging from the Speed of Light to that and beyond).

----

&gt; Range

<br>

- `None`: the Stand is completely incapable of leaving the User's body in mostly any sense (excluding specific abilities and such). In most cases, the Stand does not possess a physical manifestation; such as Suit Stands, Apparel Stands and so on.

<br>

- `E`: the Stand has a very limited range of manifesting away from it' user. This does not affect the range of ability, and should usually be specified. This range limit seems to be within only 1-3 Meters away from the User before the Stand begins to severely weaken, and/or de-manifest.

<br>

- `D`: the Stand is capable of manifesting slightly farther away from the User with less trouble or strain. This range limit seems to be within 4-7 meters away from the User before the Stand begins to severely weaken, and/or de-manifest.

<br>

- `C`: the Stand is able to manifest a fair distance away from its User without the need for strain or trouble. This range limit seems to be within 8-15 meters away from the User before the Stand begins to severely weaken, and/or de-manifest.

<br>

- `B`: the Stand is very much capable of manifesting a distance away from its user without the need of strain or trouble. This range limit seems to be within 16-49 meters away from the User before the Stand begins to severely weaken, and/or de-manifest.

<br>

- `A`: the range limit seems to be 50 Meters and beyond (although a range of nearly 1000 Miles would be considered the cap before this is considered Infinite).

<br>

- `Infinite`: the Stand is capable of leaving any set range limit that any other Stand seems to have. It is capable of leaving the User's side and tracking and pursuing outwards to quite literally an Infinite distance (although this is arguable if this is truly ""Infinite"" as the world is roughly 25,000 miles wide, and only 12,500 miles can be tested).

----

&gt; Power Persistence

<br>

- `None`: the Stand has absolutely no manifestation, and/or cannot be physically harmed in any form off the basis that is doesn't actually exist physically. This stat is usually used for Stands that only act as abilities. Specifications are needed for what the ability does in terms of the abilities control on objects, such as creating ice, controlling plants and so on.

<br>

- `E`: the Stand grants the User a very limited layer of protection. The Stand itself is incredibly fragile without the use of an ability. Consistency in durability can be similar to that of a pane of glass, paper, cloth. Defense is almost never an option.

<br>

- `D`: the Stand itself is fragile without the use of an ability, and can rarely defend the User better than the User can defend themselves. Consistency in durability can be similar to that of thicker cloth, glass, a 1/4th inch layer of ice, etc. Defense is rarely an option.

<br>

- `C`: the Stand has defensive capabilities nearly identical to a human of average build, and/or it's User's physique. This means it has the protective layer of skin, muscle and tissue, and the most important factor to a human's defense: bones. Defense is an option. This stat can be used for Durability/Staying very slightly above or below the Durability of an average human.

<br>

- `B`: the Stand has a fair ability to defend itself, and it's User. It is significantly stronger than a human in the sense that it rivals materials such as Stone, Iron, Compact Wood, and at the most, Steel. Defense is mostly an option.

<br>

- `A`: the Stand is more than capable of taking brutal punishment from the likes of B-A Power Stands (although some A-Power Stands can far surpass some A-Durability Stands). The defensive capabilities are quite simply from the likes of Steel and beyond.

<br>

- `Infinite`: the Stand has defensive capabilities that are exactly that: Indefinite. It is capable of taking any amount of physical punishment with no signs of ever taking any form of damage or drawback. This stat does not make a Stand immune to surpassing abilities; such as illness, abilities that have much higher priority, etc. Stands with only specific abilities, and/or Infinite-Power can possibly get past this Durability.

----

&gt; Precision

<br>

- `None`: the Stand does not require aiming or skill for inflicting it's ability and/or physical harm to a target. Also means it has no direct means of inflicting any sort of effect or harm to a target or simply requires no Precision to do so.

<br>

- `E`: the Stand has an extremely poor reactionary ability, can intake barely any information, has extremely poor accuracy when performing tasks, or all three. The abilities of the Stand tend to be extremely far below that of an average human.

<br>

- `D`: the Stand has poor reactionary abilities, can intake limited amounts of information, has poor accuracy when performing tasks, or all three. The abilities of the Stand tend to be below that of an average human.

<br>

- `C`: the Stand has reactionary abilities, informational and sensory intake, and/or accuracy similar to that of an average human. This means that the Stand is capable of having a visual reaction speed of roughly 0.30 to 0.10 seconds. Some attributes of the Stand may or may not be lower or slightly higher than that of an average human, but in most cases, the Stand is nearly parallel to its User.

<br>

- `B`: the Stand has exceptional reactionary abilities, is capable of obtaining information and sensory stimulation, and/or possess accuracy greater than a human can. This means the Stand is capable of having a visual reaction speed of roughly 0.10 to even as far as 0.05 seconds, capable of keeping up with the speeds of Stands with a B-Stat in Speed without much problem (results however may possibly vary).

<br>

- `A`: the Stand is capable of reacting far faster than .0001 seconds visually, and may even have the potential of taking in information and performing accurate tasks far beyond that of even advanced machinery. Stands this precise tend to keep up with the movements of most A-Stat Speed Stands (although not all).

<br>

- `Infinite`: the Stand is capable of perfectly reacting and accurately performing tasks that it is specifically given; however this does come with specifications. The Stand may be able to react perfectly and accurately, but this does not mean anything unless the Stand is capable of keeping up with its Speed stat. Another factor to keep in mind is that the Infinite Stat does not mean that the Stand itself does not require the precision, but more-so has perfected Precision, and should not be mistaken with the Precision Stat of None.

----

&gt; Development Potencial

<br>

- `None`: the Stand has reached it's full potential and is incapable of evolving any further than it already has. This is an incredibly difficult stat to obtain naturally, but it is not impossible.

<br>

- `E`: the Stand has learned quite a lot, and/or has not much to learn to begin with. In a sense, this stat shows that the Stand is nearing it's perfected state, and will soon not be able to progress any further. This Stat can also mean the Stand has a very poor range of utilization when considering its ability.

<br>

- `D`: the Stand has learned a lot, and/or has begun to near the end of its development process; whether this is where it began with or not. This Stat can also mean that the Stand has a limited range of utilization when considering its ability.

<br>

- `C`: the Stand has learned a fair amount of information since it's beginning, and/or has started at this level. It shows that the Stand has a bit to learn before it can reach it's perfected state. This Stat can also mean that the Stand has a fair range of utilization when considering its ability.

<br>

- `B`: the Stand has not learned all that much since it's beginning, and/or has started at this level of having a high potential of growth. It means that the Stand still has plenty to learn, and can develop quite a bit before reaching it's perfected state. This Stat can also mean that the Stand has a vast variety of methods for utilization when considering its ability.

<br>

- `A`: the Stand has a lot to learn, is a brand new Stand, and/or has the potential of evolving an exceptional amount before ever coming close to reaching it's perfected state. This Stat can also mean that the Stand has a plethora of utility uses when considering its ability. An A in Development is usually the Stat that a Stand that is in Act 1 will always have, and shows that it still can progress into a new Act before reaching its halting point.

<br>

- `Infinite`: the Stand has quite literally an endless possibility for developing and progressing through new abilities and powers. In a sense, this Stat is the most perfected state a Stand can ever dream to achieve, as the only way to reach it's perfected state is to envelop every possibility in the known Multiverse as a whole; quite literally impossible. This Stat should only be used in Extremely Specific Cases.

----

<br>

![Example of Stand Stats](https://static.jojowiki.com/images/3/3e/latest/20200227102737/Standstats.png ""Example of Stand parameters displayed (Star Platinum) in JOJOVELLER."")

<br><br>

----

<h2>🎉 Acknowledgements 🎉</h2>

Thanks to:

1. [JoJo Wiki](https://jojowiki.com/Stand_Stats) for providing the data.

2. [Amino Apps](https://aminoapps.com/c/jjbamino/page/item/stand-guide-stats/7egW_qpwFNI3kx4a1K3vrpqevvvZgYEXBQV) for providing the stats' ranks explanations.",.csv
Jobs and Salaries in Data Science,1,jobs-in-data,jobs_in_data.csv,DbCL-1.0,"**work_year**: The year in which the data was recorded. This field indicates the temporal context of the data, important for understanding salary trends over time.

**job_title**: The specific title of the job role, like 'Data Scientist', 'Data Engineer', or 'Data Analyst'. This column is crucial for understanding the salary distribution across various specialized roles within the data field.

**job_category**: A classification of the job role into broader categories for easier analysis. This might include areas like 'Data Analysis', 'Machine Learning', 'Data Engineering', etc.

**salary_currency**: The currency in which the salary is paid, such as USD, EUR, etc. This is important for currency conversion and understanding the actual value of the salary in a global context.

**salary**: The annual gross salary of the role in the local currency. This raw salary figure is key for direct regional salary comparisons.

**salary_in_usd**: The annual gross salary converted to United States Dollars (USD). This uniform currency conversion aids in global salary comparisons and analyses.

**employee_residence**: The country of residence of the employee. This data point can be used to explore geographical salary differences and cost-of-living variations.

**experience_level**: Classifies the professional experience level of the employee. Common categories might include 'Entry-level', 'Mid-level', 'Senior', and 'Executive', providing insight into how experience influences salary in data-related roles.

**employment_type**: Specifies the type of employment, such as 'Full-time', 'Part-time', 'Contract', etc. This helps in analyzing how different employment arrangements affect salary structures.

**work_setting**: The work setting or environment, like 'Remote', 'In-person', or 'Hybrid'. This column reflects the impact of work settings on salary levels in the data industry.

**company_location**: The country where the company is located. It helps in analyzing how the location of the company affects salary structures.

**company_size**: The size of the employer company, often categorized into small (S), medium (M), and large (L) sizes. This allows for analysis of how company size influences salary.

",.csv
Jobs and Salaries in Data field 2024,1,jobs-and-salaries-in-data-field-2024,jobs_in_data_2024.csv,Apache 2.0,"This dataset contains the updated 2024 data from the [Jobs and Salaries in Data Science](https://www.kaggle.com/datasets/hummaamqaasim/jobs-in-data/data) dataset. The information is sourced from [ai-jobs.net/salaries/2024/](https://ai-jobs.net/salaries/2024/).

**About Dataset**

**work_year:** The year in which the data was recorded. This field indicates the temporal context of the data, important for understanding salary trends over time.

**job_title:** The specific title of the job role, like 'Data Scientist', 'Data Engineer', or 'Data Analyst'. This column is crucial for understanding the salary distribution across various specialized roles within the data field.

**job_category:** A classification of the job role into broader categories for easier analysis. This might include areas like 'Data Analysis', 'Machine Learning', 'Data Engineering', etc.

**salary_currency:** The currency in which the salary is paid, such as USD, EUR, etc. This is important for currency conversion and understanding the actual value of the salary in a global context.

**salary:** The annual gross salary of the role in the local currency. This raw salary figure is key for direct regional salary comparisons.

**salary_in_usd:** The annual gross salary converted to United States Dollars (USD). This uniform currency conversion aids in global salary comparisons and analyses.

**employee_residence:** The country of residence of the employee. This data point can be used to explore geographical salary differences and cost-of-living variations.

**experience_level:**  Classifies the professional experience level of the employee. Common categories might include 'Entry-level', 'Mid-level', 'Senior', and 'Executive', providing insight into how experience influences salary in data-related roles.

**employment_type:** Specifies the type of employment, such as 'Full-time', 'Part-time', 'Contract', etc. This helps in analyzing how different employment arrangements affect salary structures.

**work_setting:** The work setting or environment, like 'Remote', 'In-person', or 'Hybrid'. This column reflects the impact of work settings on salary levels in the data industry.

**company_location:** The country where the company is located. It helps in analyzing how the location of the company affects salary structures.

**company_size:** The size of the employer company, often categorized into small (S), medium (M), and large (L) sizes. This allows for analysis of how company size influences salary.",.csv
Kaggle Blog: Winners' Posts,1,kaggle-blog-winners-posts,WinnersInterviewBlogPosts.csv,CC0-1.0,"In 2010, Kaggle launched its first competition, which was won by Jure Zbontar, who used a simple linear model. Since then a lot has changed. We've seen the rebirth of neural networks, the rise of Python, the creation of powerful libraries like XGBoost, Keras and Tensorflow. 

This is data set is a dump of all winners' posts from the Kaggle blog starting with Jure Zbontar. It allows us to track trends in the techniques, tools and libraries that win competitions. 

This is a simple dump. If there's demand, I can upload more detail (including comments and tags).",.csv
Kaggle Datasets,1,kaggle-datasets,all_kaggle_datasets.csv,CC0-1.0,"### Inspiration
What did we all upload to kaggle actually? And how did the community responded? We can find it out via looking at this dataset of the datasets.

### Content
This dataset is in a csv format, where each column is the features and attributes of a dataset on Kaggle (e.g. tags, filetype, no. of Kernels, etc.) and each row is a dataset on Kaggle

### Acknowledgements
Thanks kaggle for the super easy api endpoint design!
",.csv
Kaggle General Discussion Dataset,1,kaggle-general-discussion-dataset,Kaggle General Dataset.csv,Apache 2.0,"Dataset for Google – AI Assistants for Data Tasks with Gemma : Build tools to assist Kaggle developers Competition.
Collection of Top Comments Posts from Kaggle General Discussion.  ",.csv
Kaggle QnA Discussion Dataset,1,kaggle-qna-discussion-dataset,Kaggle QnA Dataset.csv,Apache 2.0,"Dataset for Google – AI Assistants for Data Tasks with Gemma : Build tools to assist Kaggle developers Competition.
Collection of Top Comments Posts from Kaggle QnA Discussion. ",.csv
Kaggle Users' Country + Regions Info,1,kaggle-user-country-regions,UserCountries.csv,CC-BY-NC-SA-4.0,"## [Context]

The [official Meta-Kaggle dataset](https://www.kaggle.com/datasets/kaggle/meta-kaggle) contains the Users.csv file which contains Username, DisplayName, RegisterDate, and PerformanceTier fields but doesn't contain location data of the Kaggle Users. This dataset augments that data with additional country and region information.

## [Note]
I haven't included the username and displayname values **on purpose**, just the userid to be joined back to the Meta-Kaggle official Users.csv file.

## [Limitations]
It is possible that some users haven't inputted their details when the scraper went through their accounts and thus have missing data. Another possibility is that users may have updated their info after the scraper went through their accounts, thus resulting in inconsistencies.

## [How I defined active in this dataset]
- Users that have received an upvote in the forums, datasets, or notebooks
- Users that have given an upvote in the forums, datasets, or notebooks
- Users that have created a thread, a forum post, a notebook, or a dataset
- Users that made a competition submission
- Users that exist in the Meta-Kaggle Users dataset
- Date cut-off of Jan 01, 2019

## [Update]
* **15-Feb-2024**- Since the Kaggle member's profile page update, the scrapers arent working anymore as the UI layout has changed. Will fix this when we get the time.",.csv
Kaggle sectionwise documentation,1,kaggle-sectionwise-documentation,kaggle_sectionwise_documentation.csv,Apache 2.0,"Dataset for Google – AI Assistants for Data Tasks with Gemma : Build tools to assist Kaggle developers Competition.
The dataset contains sectionwise documentation text from kaggle/docs section. There are topic and sub topic columns to get a better context of the body text. The text has been extracted from https://www.kaggle.com/docs.",.csv
Kepler Exoplanet Search Results,1,kepler-exoplanet-search-results,cumulative.csv,CC0-1.0,"### Context

The Kepler Space Observatory is a NASA-build satellite that was launched in 2009. The telescope is dedicated to searching for exoplanets in star systems besides our own, with the ultimate goal of possibly finding other habitable planets besides our own. The original mission ended in 2013 due to mechanical failures, but the telescope has nevertheless been functional since 2014 on a ""K2"" extended mission.

Kepler had verified 1284 new exoplanets as of May 2016. As of October 2017 there are over 3000 confirmed exoplanets total (using all detection methods, including ground-based ones). The telescope is still active and continues to collect new data on its extended mission.

### Content

This dataset is a cumulative record of all observed Kepler ""objects of interest"" &mdash; basically, all of the approximately 10,000 exoplanet candidates Kepler has taken observations on.

This dataset has an extensive data dictionary, which can be accessed [here](https://exoplanetarchive.ipac.caltech.edu/docs/API_kepcandidate_columns.html). Highlightable columns of note are:

* `kepoi_name`: A KOI is a target identified by the Kepler Project that displays at least one transit-like sequence within Kepler time-series photometry that appears to be of astrophysical origin and initially consistent with a planetary transit hypothesis
* `kepler_name`: [These names] are intended to clearly indicate a class of objects that have been confirmed or validated as planets—a step up from the planet candidate designation.
* `koi_disposition`: The disposition in the literature towards this exoplanet candidate. One of CANDIDATE, FALSE POSITIVE, NOT DISPOSITIONED or CONFIRMED.
* `koi_pdisposition`: The disposition Kepler data analysis has towards this exoplanet candidate. One of FALSE POSITIVE, NOT DISPOSITIONED, and CANDIDATE.
* `koi_score `: A value between 0 and 1 that indicates the confidence in the KOI disposition. For CANDIDATEs, a higher value indicates more confidence in its disposition, while for FALSE POSITIVEs, a higher value indicates less confidence in that disposition.

### Acknowledgements

This dataset was published as-is by NASA. You can access the original table [here](https://exoplanetarchive.ipac.caltech.edu/cgi-bin/TblView/nph-tblView?app=ExoTbls&config=koi). More data from the Kepler mission is available from the same source [here](https://exoplanetarchive.ipac.caltech.edu/docs/data.html).

### Inspiration

* How often are exoplanets confirmed in the existing literature disconfirmed by measurements from Kepler? How about the other way round?
* What general characteristics about exoplanets (that we can find) can you derive from this dataset?
* What exoplanets get assigned names in the literature? What is the distribution of confidence scores?

See also: the [Kepler Labeled Time Series](https://www.kaggle.com/keplersmachines/kepler-labelled-time-series-data) and [Open Exoplanets Catalogue](https://www.kaggle.com/mrisdal/open-exoplanet-catalogue) datasets.",.csv
Kidney Stone Dataset,1,kidneystone,kidney-stone-dataset.csv,other,"The kidney-stone-dataset.csv is a comma-separated values file containing data on patients with kidney stones. The file has 90 rows and 7 columns, with each row representing a patient and each column providing information on various characteristics and laboratory test results. The dataset also includes a target variable, ""Risk of Stone"", which is a continuous variable representing the risk of developing kidney stones. This dataset can be used for tasks such as predicting the risk of kidney stones based on patient characteristics and test results.

This kidney stone dataset contains 12 features related to the risk of developing kidney stones, including age, gender, weight, height, family history, and various blood and urine measurements. The dataset includes 180 records, and the target variable is a continuous value representing the risk of developing kidney stones. The dataset is useful for building predictive models to identify individuals at high risk for kidney stones, which can aid in the development of prevention and treatment strategies.

The kidney-stone-dataset.csv is a dataset containing information on 90 patients with kidney stones, including characteristics such as age, gender, and stone type, as well as laboratory test results. The dataset also includes a target variable, ""Risk of Stone"", which is a continuous variable representing the risk of developing kidney stones. This dataset can be used for tasks such as predicting the risk of kidney stones based on patient characteristics and test results.",.csv
Knowledge Distillation,1,knowledge-distillation,dataset_KD.csv,MIT,"Distilled knowledge training dataset for the HMS - Harmful Brain Activity Classification competition
This dataset has 17089 unique EEG ids grouped by from the official HMS train.csv file.
The distilled knowledge is coming from an ensemble with 0.3 LB score.

To find out how to utilize it, you can have a look in [here](https://www.kaggle.com/code/nartaa/features-head-starter)",.csv
Korea Income and Welfare,1,korea-income-and-welfare,Korea Income and Welfare.csv,CC0-1.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F4837224%2Fa136639c2f197cfa9be7a5e600863d5e%2F.JPG?generation=1608379259729921&alt=media)

### Context

The data attached has been conducted from 2005 for 14 years funded by Korea Government. 

This studied several household characteristics related to panel attrition, amining how they may have conditioned the panel data in the Korea Welfare Panel Study (KOWEPS). 

The panel attrition in the KOWEPS data is monotonous and affects household characteristics and the estimation of household income. 

The Korea Welfare Panel still continue to study various statistical issues including quality improvement every year. 

The data attached has beend attracted from the origianl data, and you can download the full data from its website if you want. Please visit the site below and try to download after subscription. 

https://www.koweps.re.kr:442/eng/main.do


### Content

There are 14 columns in data;

- id 
- year : study conducted
- wave : from wave 1st in 2005 to wave 14th in 2018
- region:  1) Seoul 2) Kyeong-gi 3) Kyoung-nam 4) Kyoung-buk 5) Chung-nam 6) Gang-won &. Chung-buk 7) Jeolla & Jeju
- income: yearly income in M KRW(Million Korean Won. 1100 KRW = 1 USD)
- family_member: no. of family members
- gender: 1) male 2) female
- year_born
- education_level: 1) no education(under 7 yrs-old) 2) no education(7 & over 7 yrs-old) 3) elementary 4) middle school 5) high school 6) college 7) university degree 8) MA 9) doctoral degree 
- marriage: marital status. 1) not applicable (under 18) 2) married 3) separated by death 4) separated 5) not married yet 6) others
- religion: 1) have religion 2) do not have
- occupation: this will be provided in separated code book
- company_size
- reason_none_worker: 1) no capable 2) in military service 3) studying in school 4) prepare for school 5) prepare to apply job 6) house worker 7) caring kids at home 8) nursing 9) giving-up economic activities 10) no intention to work 11) others


### Acknowledgements

Thanks for KOWEPS. (https://www.koweps.re.kr)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F4837224%2F1de587c6f25b77a8cf0740458fccbb67%2F.PNG?generation=1608379298336773&alt=media)


### Inspiration

Highly appreciated if you can analyze and get some insights which can improve the Korean society. ",.csv
Korean Baseball Pitching Data (1982 - 2021),1,korean-baseball-pitching-data-1982-2021,kbopitchingdata.csv,CC0-1.0,"The dataset contains team pitching data from every season of KBO Baseball.

The data was collected from Sports Reference then cleaned for data analysis.

Tabular data includes:
- - `year`
- - `teams`
- - `average_age`: Average pitcher age
- - `runs_per_game`: Runs scored per game
- - `wins`: Total wins per season
- - `losses`: Total losses per season
- - `win_loss_percentage`
- - `ERA`: Pitching ERA
- - `run_average_9`
- - `games`: Games played
- - `games_started`: Games started
- - `games_finished`: Games finished
- - `complete_game`: Complete games
- - `shutouts`: No runs allowed and complete games
- - `saves`
- - `innings_pitched`
- - `hits`: Hits allowed
- - `runs`: Runs allowed
- - `earned_runs`: Earned runs allowed
- - `home_runs`: Home runs allowed
- - `walks`: Walks allowed
- - `intentional_walks`: Intentional walks allowed
- - `strikeouts`
- - `hit_batter`: Hit batter with pitch
- - `balks`: An illegal act by a pitcher with a runner or runners on base entitling all batters to advance one base
- - `wild_pitches`
- - `batters_faced`
- - `WHIP`: (Walks + Hits) / Total Innings Pitched
- - `hits_9`: Hits per 9 innings
- - `homeruns_9`: Homeruns per 9 innings
- - `walks_9`: Walks per 9 innings
- - `strikeouts_9`: Strikeouts per 9 innings
- - `strikeout_walk`: strikeouts / walks",.csv
LLM Prompt Recovery Tiny Dataset 1,1,llm-prompt-recovery-tiny-dataset-1,train.csv,Apache 2.0,"I'm sharing a couple of tiny datasets that might be helpful for development and debugging purposes. There are two variants (Tiny Dataset 1 and Tiny Dataset 2), but their content is largely similar. Each dataset contains only 10 rows.

[LLM Prompt Recovery Tiny Dataset 1](https://www.kaggle.com/datasets/isakatsuyoshi/llm-prompt-recovery-tiny-dataset-1)

[LLM Prompt Recovery Tiny Dataset 2](https://www.kaggle.com/datasets/isakatsuyoshi/llm-prompt-recovery-tiny-dataset-2)",.csv
LLM Prompt Recovery Tiny Dataset 2,1,llm-prompt-recovery-tiny-dataset-2,train.csv,Apache 2.0,"I'm sharing a couple of tiny datasets that might be helpful for development and debugging purposes. There are two variants (Tiny Dataset 1 and Tiny Dataset 2), but their content is largely similar. Each dataset contains only 10 rows.

[LLM Prompt Recovery Tiny Dataset 1](https://www.kaggle.com/datasets/isakatsuyoshi/llm-prompt-recovery-tiny-dataset-1)

[LLM Prompt Recovery Tiny Dataset 2](https://www.kaggle.com/datasets/isakatsuyoshi/llm-prompt-recovery-tiny-dataset-2)",.csv
LLM Question-Answer Dataset,1,llm-dataset,LLM__data.csv,Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0),"# LLM Dataset - Prompts and Generated Texts

The dataset contains prompts and texts generated by the Large Language Models (LLMs) in **32 different languages**. The prompts are short sentences or phrases for the model to generate text. The texts generated by the LLM are responses to these prompts and can vary in **length and complexity**.

Researchers and developers can use this dataset to train and fine-tune their own language models for multilingual applications. The dataset provides a rich and diverse collection of outputs from the model, demonstrating its ability to generate coherent and contextually relevant text in multiple languages.

# 💴 For Commercial Usage: Full version of the dataset includes **4,000,000 logs** generated in **32 languages** with diferent types of LLM, including Uncensored GPT, leave a request on **[TrainingData](https://trainingdata.pro/datasets/llm?utm_source=kaggle&utm_medium=cpc&utm_campaign=llm)** to buy the dataset

### Models used for text generation:
- **GPT-3.5**,
- **GPT-4**

### Languages in the dataset: 
*Arabic, Azerbaijani, Catalan, Chinese, Czech, Danish, German, Greek, English, Esperanto, Spanish, Persian, Finnish, French, Irish, Hindi, Hungarian, Indonesian, Italian, Japanese, Korean, Malayalam, Maratham, Netherlands, Polish, Portuguese, Portuguese (Brazil), Slovak, Swedish, Thai, Turkish, Ukrainian*

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F12421376%2Ff60c93f09ec82a765aa39678e4aa0a58%2Fsnapedit_1709731090855.jpeg?generation=1709738798916444&alt=media)

# Content
CSV File includes the following data:
- **from_language**: language the prompt is made in,
- **model**: type of the model (GPT-3.5, GPT-4 and Uncensored GPT Version),
- **time**: time when the answer was generated,
- **text**: user prompt,
- **response**: response generated by the model

# 💴 Buy the Dataset: This is just an example of the data. Leave a request on **[https://trainingdata.pro/datasets](https://trainingdata.pro/datasets/llm?utm_source=kaggle&utm_medium=cpc&utm_campaign=llm)** to discuss your requirements, learn about the price and buy the dataset

## **[TrainingData](https://trainingdata.pro/datasets/llm?utm_source=kaggle&utm_medium=cpc&utm_campaign=llm)** provides high-quality data annotation tailored to your needs

*keywords: dataset, machine learning, natural language processing, artificial intelligence, deep learning, neural networks, text generation, language models, openai, gpt-3, data science, predictive modeling, sentiment analysis, keyword extraction, text classification, sequence-to-sequence models, attention mechanisms, transformer architecture, word embeddings, glove embeddings, chatbots, question answering, language understanding, text mining, information retrieval, data preprocessing, feature engineering, explainable ai, model deployment*",.csv
LLM-generated essay using PaLM from Google Gen-AI,1,llm-generated-essay-using-palm-from-google-gen-ai,LLM_generated_essay_PaLM.csv,CC0-1.0,"In this competition [LLM - Detect AI Generated Text](https://www.kaggle.com/competitions/llm-detect-ai-generated-text/overview), there's problem. There is an **imbalance** in the data which causes the LLM-generated essays to be less than the essays written by students. Here you can see EDA for the data competition in this notebook: [AI or Not AI? Delving Into Essays with EDA](https://www.kaggle.com/code/pamin2222/ai-or-not-ai-delving-into-essays-with-eda/notebook)

So to solve this problem i made my own LLM-generated essay dataset that generated by [PaLM](https://developers.generativeai.google/api/python/google/generativeai) to fix imbalance in data. You can see my work about how to generate the data in this Google Colaboratory:  
[Generate LLM dataset using PaLM.ipynb](https://colab.research.google.com/drive/1cWVTGZKp1OSVu37Nm7fjxqOhaHfveqpV?usp=sharing)

Reason why i can't generated in Kaggle Notebook because Kaggle Notebook was use Kaggle Docker that can't use my own PaLM API. (My opinion)

**Column in data**:
- `id`: index 
- `prompt_id`: prompt that used to generated data. You can check the prompt [here!](https://www.kaggle.com/competitions/llm-detect-ai-generated-text/data?select=train_prompts.csv)
- `text`: LLM-generated essay by PaLM based on prompt
- `generated`: Additional information that shows it was LLM-generated. All value in this column is `1`.",.csv
LMS Tracking  Dataset,1,lms-tracking-dataset,Activity_tracking_sheet.csv,other,"This dataset was collected by a edtech startup. The startup is into teaching entrepreneurial life-skills in animated-gamified format through its video series to kids between the age group of 6-14 years. Through its learning management system the company tracks the progress made by all of its subscribers on the platform. Company records platform content usage activity data and tries to follow up with parents if there is any inactiveness on the platform by their child. Here's more information about the dataset 



#  Dataset Information:


- **Child Name:** Name of the subscriber kid
- **Email Address:** Email address created by parent 
- **Contact:** Contact details of the parent
- **follow up:** Responses received by the company employee after progress follow-up over the phone.
- **response:** segregating the follow-up responses in to categories
- **Introduction:** Tutorial 1
- **Activity:- Know your personality, a fun way:**Tutorial 2
- **A Simple Quiz on the previous Video:** Quiz on the Tutorial 2
- **Lets see what ‘Product’ is…:**Tutorial 3
- **A Simple Quiz on the previous Video:**Quiz on the Tutorial 3
- **Product that represents me:** Tutorial 4
- **Let's see what 'Service' means:** Tutorial 5
- **A Simple Quiz on the previous Video:**Quiz on the Tutorial 5
- **Instruction for 'Product & Service' worksheet:**Tutorial 6
- **Activity:- Product and Service Worksheet:** Exercise on Tutorial 6
- **Instructions for Product Word Association:**Tutorial 7
- **Activity:- Product Word Association:**Exercise on Tutorial 7
- **Life without products??.... Impossible !:**Tutorial 8
- **What Is a Need?:**Tutorial 9
- **A Simple Quiz on the previous Video:**Quiz on the Tutorial 9
- **Summary of Session 1:** Summarizing all the learnings from the Tutorials 1-9
- **Your Feedback on Session 1:**  Feedback page
 
There is some missing data as well. I hope it would be good dataset for beginners practicing their NLP skills.

Image by *Steven Weirather* from Pixabay

###Note: This dataset is partially synthetic meaning names, email and contact details mentioned are not of the actual customers. Kindly use it for educational and research purposes.",.csv
Lamborghini Sales and Stocks,1,lamborghini-sales-and-stocks,Lambo-Future.csv,CC0-1.0,"This dataset shows the sales and stock prices of the Laborghini corporation. It has 19 rows and 7 columns. Here is the columns description:

```Year``` - The year

```Sales``` - The amount of cars sold that year

```Growth``` - The sales growth from year to year

```Open``` - The opening stock price of that specific year

```High``` - The highest price the stock was during that specific year

```Low``` - The lowest price the stock was during that specific year

```Close``` - The closing stock price of that specific year

I hope you like this dataset. God bless you.

Note: The 'Open' column has a space at the end, making it 'Open '. Very sorry for this bug.",.csv
"Landslides After Rainfall, 2007-2016",1,landslide-events,catalog.csv,CC0-1.0,"# Context

Landslides are one of the most pervasive hazards in the world, causing more than 11,500 fatalities in 70 countries since 2007. Saturating the soil on vulnerable slopes, intense and prolonged rainfall is the most frequent landslide trigger.


# Content

The Global Landslide Catalog (GLC) was developed with the goal of identifying rainfall-triggered landslide events around the world, regardless of size, impacts, or location. The GLC considers all types of mass movements triggered by rainfall, which have been reported in the media, disaster databases, scientific reports, or other sources.


# Acknowledgements

The GLC has been compiled since 2007 at NASA Goddard Space Flight Center.",.csv
Language Detection,1,language-detection,Language Detection.csv,CC0-1.0,"
### About the Dataset

It's a small language detection dataset. This dataset consists of text details for 17 different languages, ie, you will be able to create an NLP model for predicting 17 different language..  


### Languages
 
1) English
2) Malayalam
3) Hindi
4) Tamil
5) Kannada
6) French
7) Spanish
8) Portuguese
9) Italian
10) Russian
11) Sweedish
12) Dutch
13) Arabic
14) Turkish
15) German
16) Danish
17) Greek

",.csv
Language Translation (English-French),1,language-translation-englishfrench,eng_-french.csv,CC0-1.0,"### Content

There are 2 columns one column has english words/sentences and the other one has french words/sentences 
And these dataset can be used for language translation task.

The unique value are different because same english word has different french represntation
example: Run(english) = 1. Courezâ€¯! 2. Coursâ€¯!

### Acknowledgements
for more datasets of different languages http://www.manythings.org/anki/ ",.csv
Laptop Price,1,laptop-price,laptop_price.csv,other,"1 Company- String -Laptop Manufacturer
2 Product -String -Brand and Model
3 TypeName -String -Type (Notebook, Ultrabook, Gaming, etc.)
4 Inches -Numeric- Screen Size
5 ScreenResolution -String- Screen Resolution
6 Cpu- String -Central Processing Unit (CPU)
7 Ram -String- Laptop RAM
8 Memory -String- Hard Disk / SSD Memory
9 GPU -String- Graphics Processing Units (GPU)
10 OpSys -String- Operating System
11 Weight -String- Laptop Weight
12 Price_euros -Numeric- Price (Euro)",.csv
Laptop Price Dataset,1,laptop-price-dataset,laptop_data.csv,CC0-1.0,"The dataset is about laptops configuration with prices containing 1303 laptop data with 12 columns Company name,type namee, laptop size in (inches), Screen resolution, CPU,  RAM, Memory, GP,  Operating system, Price in INR.",.csv
Laptop Price Prediction,1,laptoppriceprediction,Laptop_price.csv,Apache 2.0,"The dataset emulates laptop prices, capturing various features commonly associated with laptops and their corresponding simulated prices. The dataset encompasses key attributes such as brand, processor speed, RAM size, storage capacity, screen size, and weight. ",.csv
Laptop Price Prediction Dataset,1,laptop-price-prediction-dataset,data.csv,Apache 2.0,"This dataset provides comprehensive information on various laptops, capturing diverse features and specifications. It is a valuable resource for those interested in exploring and predicting laptop prices based on their characteristics.",.csv
Laptop Price Prediction cleaned Dataset,1,laptop-price-prediction-cleaned-dataset,laptop_data_cleaned.csv,CC0-1.0,"The Laptop Dataset for Kaggle is a valuable resource for data scientists, machine learning enthusiasts, and researchers looking to explore and analyze laptop specifications. This dataset provides a comprehensive collection of laptop attributes and features, making it an ideal tool for various analytical and modeling tasks.

Containing information on thousands of laptops, the dataset encompasses a wide range of brands, models, and configurations. It includes both entry-level and high-end laptops, catering to diverse user needs and preferences. Each laptop entry within the dataset offers a plethora of attributes, such as processor details, memory capacity, storage size, display characteristics, graphics capabilities, battery life, operating system, and more.

With this dataset, users can engage in exploratory data analysis to uncover interesting trends, patterns, and correlations among different laptop specifications. It can serve as a foundation for building predictive models to estimate laptop prices, assess performance benchmarks, or predict user preferences based on specific features.

The Laptop Dataset for Kaggle can also be utilized for various machine learning tasks, including classification, regression, clustering, and recommendation systems. By leveraging this dataset, researchers can train models to predict laptop performance, user ratings, or identify key factors influencing customer satisfaction.

Overall, this dataset offers a comprehensive collection of laptop specifications, enabling data scientists and researchers to delve into the world of laptops and explore the relationships between their features, performance, and user preferences.

Note: The Laptop Dataset for Kaggle is a fictional dataset created solely for illustrative purposes in this response.",.csv
Laptop Prices Based on its specifications,1,laptop-prices-based-on-its-specifications,laptop_data.csv,Apache 2.0,"Explore a comprehensive dataset detailing various laptop attributes such as screen size, CPU, RAM, memory, GPU, operating system, weight, and price. Gain insights into how these specifications influence the pricing trends of laptops from different brands and types. Discover correlations between hardware features and their impact on the market value of portable computing devices.",.csv
Laptop Prices Dataset,1,laptop-prices-dataset,laptopPrice.csv,CC0-1.0,"This dataset is a collection of features related to various laptops, such as brand, processor type, RAM, storage capacity, and other specifications. The dataset also includes the corresponding prices of these laptops. This dataset can be used for regression analysis to predict the prices of laptops based on their features. The dataset is suitable for data scientists, machine learning enthusiasts, and researchers who are interested in building regression models to predict the prices of laptops based on various features.",.csv
Laptop Pricing,1,laptop-pricing,laptop_pricing_dataset.csv,Apache 2.0,"This dataset is a collection of features related to various laptops, such as brand, processor type, RAM, storage capacity, and other specifications. The dataset also includes the corresponding prices of these laptops. This dataset can be used for regression analysis to predict the prices of laptops based on their features. The dataset is suitable for data scientists, machine learning enthusiasts, and researchers who are interested in building regression models to predict the prices of laptops based on various features.

# Parameters

The parameters used in the dataset are:

**1.	Manufacturer**.
The company that manufactured the laptop

**2.	Category**.
The category to which the laptop belongs: This parameter is mapped to numerical values in the following way:

Category - Assigned Value
- Gaming - 1
- Netbook - 2
- Notebook - 3
- Ultrabook - 4
- Workstation - 5

**3.	GPU**.
The manufacturer of the GPU. This parameter is mapped to numerical values in the following way:

GPU - Assigned Value
- AMD - 1
- Intel - 2
- NVidia - 3

**4.	OS**.
The operating system type (Windows or Linux): This parameter is mapped to numerical values in the following way:

OS - Assigned Value
- Windows - 1
- Linux - 2

**5.	CPU_core**.
The type of processor used in the laptop: This parameter is mapped to numerical values in the following way:

CPU_core - Assigned Value
- Intel Pentium i3 - 3
- Intel Pentium i5 - 5
- Intel Pentium i7 - 7

**6.	Screen_Size_cm**.
The size of the laptop screen is recorded in cm.

**7.	CPU_frequency**.
The frequency at which the CPU operates, in GHz.

**8.	RAM_GB**.
The size of the RAM of the system in GB.

**9.	Storage_GB_SSD**.
The size of the SSD storage in GB is installed in the laptop.

**10.	Weight_kg**.
The weight of the laptop is in kgs.

**11.	Price**.
The price of the laptop is in USD.

Kindly, upvote if you find the dataset interesting. Thank you!

",.csv
Laptop sales price prediction 2024,1,laptop-sales-price-prediction-dataset-2024,laptop_cleaned2.csv,CC0-1.0,"# Laptop Sales Price Prediction 2024 Dataset

## Overview
This dataset contains information about various laptops, including specifications and prices, curated for sales price prediction. With features ranging from processor details to display specifications, this dataset serves as a valuable resource for analyzing trends and predicting laptop prices.

## File Descriptions
- laptop_sales_price_prediction.csv: CSV file containing the cleaned dataset.
 

## Column Descriptions
1. Name: Name of the laptop model.
2. Brand: Brand of the laptop.
3. Price: Price of the laptop.
4. Rating: Rating of the laptop.
5. Processor_brand: Brand of the laptop's processor.
6. Processor_name: Name of the laptop's processor.
7. Processor_variant: Variant of the laptop's processor.
8. Processor_gen: Generation of the laptop's processor.
9. Core_per_processor: Number of cores per processor.
10. Total_processor: Total number of processors.
11. Execution_units: Number of execution units.
12. Low_Power_Cores: Number of low-power cores.
13. Energy_Efficient_Units: Indicates if the laptop has energy-efficient units.
14. Threads: Number of threads.
15. RAM_GB: RAM capacity of the laptop in gigabytes.
16. RAM_type: Type of RAM.
17. Storage_capacity_GB: Storage capacity of the laptop in gigabytes.
18. Storage_type: Type of storage.
19. Graphics_name: Name of the laptop's graphics.
20. Graphics_brand: Brand of the laptop's graphics.
21. Graphics_GB: Graphics capacity in gigabytes.
22. Graphics_integrated: Indicates if the laptop has integrated graphics.
23. Display_size_inches: Size of the laptop's display in inches.
24. Horizontal_pixel: Number of horizontal pixels.
25. Vertical_pixel: Number of vertical pixels.
26. ppi: Pixels per inch.
27. Touch_screen: Indicates if the laptop has a touch screen.
28. Operating_system: Operating system of the laptop.

## Subtitle
""Unlocking Insights: Dive into the World of Laptop Sales with Comprehensive Data""

 

 ",.csv
Laptops Price Dataset,1,laptops-price-dataset,laptops.csv,Apache 2.0,"This dataset provides a comprehensive collection of information on various laptops, enabling a detailed analysis of their specifications and pricing. It encompasses a wide range of laptops, encompassing diverse brands, models, and configurations, making it a valuable resource for researchers, data analysts, and machine learning enthusiasts interested in the laptop industry.

The data comes from the spanish website PC componentes. The data was collected using Power Automate, more info on: https://github.com/juanmerino89/laptops-data-cleaning

Fields included:

- **Laptop Name:** The unique identifier or model name of the laptop.
- **Brand:** Laptop brand.
- **Model:** Laptop brand model.
- **CPU (Central Processing Unit):** The processor brand, model, and other relevant details.
- **GPU (Graphics Processing Unit):** The graphics card brand, model, and associated specifications.
- **RAM (Random Access Memory):** The amount of memory available for multitasking.
- **Storage:** The storage type (HDD, SSD) and capacity of the laptop.
- **Price:** The cost of the laptop in the respective currency.

By utilizing this dataset, researchers and analysts can explore patterns, trends, and relationships between laptop specifications and their pricing. It serves as an excellent resource for tasks such as price prediction, market analysis, and comparison of different laptop configurations. Whether you are interested in identifying the most cost-effective options or understanding the impact of specific hardware components on laptop prices, this dataset offers abundant possibilities for in-depth exploration.",.csv
Largest Companies in World,1,largest-companies-in-world,Largest companies in world.csv,MIT,"This dataset provides comprehensive insights into various organizations' financial performance and geographic distribution across different countries. It includes attributes such as organizationName, country, revenue, profits, assets, and marketValue. Each entry contains detailed information about the organization's name, the country in which it operates, and its financial metrics, including revenue, profits, assets, and market value. 
Whether it's assessing revenue trends, comparing profits across countries, or analyzing market values, this dataset serves as a valuable resource for conducting comprehensive financial analyses and market research.",.csv
Latest COVID-19 India Statewise Vaccine Data,1,covid19-india-statewise-vaccine-data,COVID-19 India Statewise Vaccine Data.csv,DbCL-1.0,"## Content
Covid-19 Vaccine data from all the states and union territories of India as on **September 13, 2023**.

## Attribute Information

- **State/UTs** - Names of states and union territories of India
- **Total Vaccination Doses**- Total number of vaccine doses given
- **Dose 1** - Total number of first dose of vaccine given
- **Dose 2** - Total number of second dose of vaccine given
- **Dose 1 15-18** - Number of first dose of vaccine given for age group 15-18
- **Dose 2 15-18** - Number of second dose of vaccine given for age group 15-18
- **Dose 1 12-14** - Number of first dose of vaccine given for age group 12-14
- **Dose 2 12-14** - Number of second dose of vaccine given for age group 12-14
- **Precaution 18-59** - Number of precaution vaccines given
- **Population** - Population of the state/UT

## Source
- Vaccine Data : https://www.mygov.in/covid-19
- Population Data : https://www.indiacensus.net/

## Other Updated Covid19 Datasets
https://www.kaggle.com/anandhuh/datasets

### Thank You",.csv
Latest Covid-19 India Statewise Data,1,latest-covid19-india-statewise-data,Latest Covid-19 India Status.csv,DbCL-1.0,"## About
This dataset contains latest Covid-19 India state-wise data as on **September 12, 2023**. This dataset can be used to analyze covid in India. 
This dataset is great for **Exploratory Data Analysis** 

## Attribute Information

1. **State/UTs** - Names of Indian States and Union Territories.
2. **Total Cases** - Total number of confirmed cases
3. **Active** - Total number of active cases
4. **Discharged** - Total number of discharged cases
5. **Deaths** - Total number of deaths
6. **Active Ratio (%)** - Ratio of number of active cases to total cases
7. **Discharge Ratio (%)** - Ratio of number of discharged cases to total cases
8. **Death Ratio (%)** - Ratio of number of deaths to total cases
9. **Population**  - Population of State/UT

## Source
Covid Data : https://www.mygov.in/covid-19
Population Data : https://www.indiacensus.net/

## Other Updated Covid Datasets

https://www.kaggle.com/anandhuh/datasets
Please appreciate the effort with an **upvote** 👍 

### Thank You",.csv
Latest One day International Dataset upto 2024,1,latest-one-day-international-dataset-upto-2024,One_day_data.csv,Apache 2.0,This dataset contain the record of 4500+ international one day matches with the help of this data you can create a one day winner predicator or you can do a detail analysis of the One day international from decade to decade it an absolute dataset to do a lot of things for cricket lover,.csv
Latest Smartphone Dataset March 2024,1,latest-smartphone-dataset-march-2024,Smartphone_2024.csv,Apache 2.0,"This dataset is scrapped from www. smartprix.com using selenium and beautiful Soup Library , this dataset contains 12 columns 
The columns contains
1. Model Name
2. Specification
3. Display
4. RAM
5. Proccessor
6. camera Information
7. Rating",.csv
Latest T_20 International Matches Dataset 2024,1,2500-t-20-international-matches-2005-2024,Twenty_20_data.csv,Apache 2.0,"Cricket is one of the best source of Enjoyment in Asia and around the world, Every child first dream is to become a cricketer and t-20 cricket is one of the shortest format of cricket and a lot of thriller so lets work on T-20 cricket from the very first t-20 match in 2005 to the latest 2024 dataset. This dataset does not include any other franchise cricket data it purely contains international cricket.

From this dataset you can build a lot of application you can create T_20 wins prediction System, Winning Prediciton of every country and many other insightful information for that dataset. it not only help for ML Engineer but also used in data Analytics and Data Analysis project ",.csv
Latest Worldwide Covid-19 Vaccine Data,1,latest-worldwide-vaccine-data,Worldwide Vaccine Data.csv,DbCL-1.0,"## Content
Latest Covid-19 Vaccine Status of all the Countries in the World as on **January 18, 2023**

## Attribute Information

**Countries** - Name of countries
**Doses administered per 100 people** _ Number of vaccine doses administered per 100 people
**Total doses administered** - Total number of doses administered
**% of population vaccinated** - Percentage of population vaccinated
**% of population fully vaccinated**- Percentage of population fully vaccinated

## Source
Link : https://www.nytimes.com/interactive/2021/world/covid-vaccinations-tracker.html 

### Other Updated Covid Datasets

Link : https://www.kaggle.com/anandhuh/datasets
Please appreciate the effort with an **upvote** 👍 
### Thank You",.csv
Latest_Smartphones_Specifications_&_Prices_India,1,latest-smartphones-specifications-and-prices-india,smartphone_price.csv,Apache 2.0,"**This Dataset contains detailed Specifications and Prices of Smartphones launched in the last 5 to 6 years.**
##There are 24 Columns, including features like RAM, Storage, Brand, Processor, Price, etc. with Nearly 1000 Entries.

####This Dataset is suitable for :
- *Web_sites*
- *Development*
- *Recommendation_Systems*
- *Smartphone_Price_Predictions*


##Let's See The Data at a Glance -&gt;
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F11850743%2F94437a81e32233329d2edf53915abe36%2FScreenshot%202024-04-19%20083849.jpg?generation=1713496195312475&alt=media)",.csv
Latitude and Longitude for Every Country and State,1,latitude-and-longitude-for-every-country-and-state,world_country_and_usa_states_latitude_and_longitude_values.csv,CC-BY-SA-4.0,"### Content

GPS coordinates for every world country and every USA state.

Columns = 
[country-code,latitude,longitude,country,usa-state-code,usa-state-latitude,usa-state-longitude,usa-state]

### Acknowledgements

Original source of data was https://developers.google.com/public-data/docs/canonical/countries_csv and https://developers.google.com/public-data/docs/canonical/states_csv.  Data was originally released under a Creative Commons 4.0 license.

Photo by [Марьян Блан | @marjanblan on Unsplash](https://unsplash.com/photos/6bXvYyAYVrE)",.csv
Law School Admissions Bar Passage,1,law-school-admissions-bar-passage,bar_pass_prediction.csv,CC-BY-SA-4.0,"# The Law School Admissions Council's (LSAC) National Bar Passage Study:
A Law School Admissions dataset from the Law School Admissions Council (LSAC). From 1991 through 1997, LSAC tracked some twenty-seven thousand law students through law school, graduation, and sittings for bar exams. The result was the most comprehensive database that exists on the demography, experiences, and outcomes of a large cohort of aspiring lawyers. While the data has important limitations, it is a unique and very valuable source for studying a range of issues related to legal education.
The dataset was originally collected for a study called '[LSAC National Longitudinal Bar Passage Study](http://www.seaphe.org/databases.php)' by Linda Wightman in 1998. 

## Ideas:
- Predict whether or not a student will pass the bar, based on their Law School Admission Test (LSAT) score and undergraduate GPA.
Example analysis (copied here): [Tensorflow Fairness Indicators example](https://www.tensorflow.org/responsible_ai/fairness_indicators/tutorials/Fairness_Indicators_Pandas_Case_Study)
- Check the above for bias - by race, gender, background

### Some important variables:
- dnn\_bar\_pass\_prediction: The LSAT prediction from the DNN model.
- gender: Gender of the student.
- lsat: LSAT score received by the student.
- race: Race of the student.
- ugpa: A student's undergraduate GPA.
- pass\_bar: - Ground truth label indicating whether or not the student eventually passed a bar.

- bar\_passed - I added a boolean target column for convenience, of whether someone passed the bar at any point


Cover image: by <a href=""https://unsplash.com/es/@tingeyinjurylawfirm?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText"">Tingey Injury Law Firm</a> on <a href=""https://unsplash.com/s/photos/law-school?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText"">Unsplash</a>
  ",.csv
Laws and Acts of India,1,laws-and-acts-of-india,indian_laws_and_acts_v2.csv,MIT,"This document provides a comprehensive list of all Acts published and enforced in India since 1074. It's presented in a clear and organized format, likely a CSV file. Each entry within the file details the Act's title, the source where it was published, the location of publication, the date it came into effect, and most importantly, a source URL where the full text of the Act can be accessed for further study. This information allows for easy exploration of India's legal landscape throughout history.

Utilize the data to build LLMs based on Laws and acts (Note: the text corpus to be extracted from the given URL)",.csv
Layer2 blockchains Historical Data,1,layer2-blockchain-historical-data,layer2.csv,Apache 2.0,"**layer 2** is used for all blockchain scalability solutions which are built on a layer below the blockchain’s main net, thus the name. The general idea is to move the transactional load, or at least part of it, off the blockchain network. Now due to the unique structure of each blockchain protocol, there isn’t a single universal scalability solution. Instead, there are a number of solutions out there, each with its own technical nuances. To gain a better understanding, let’s take a look at two of the more established layer 2 blockchain solutions – Plasma and State Channels, without getting too technical.

in this dataset i provide historical data for **180** days ago include:
1. **matic-network**
2. **arbitrum**
3. **optimism**
4. **immutable-x**
5. **loopring**
6. **skale**
7. **syscoin**
8. **metis-token**
9. **coinweb**
10. **boba-network**
11. **degate**
12. **zkspace**
13. **xdai**
14. **mantle**

In addition, there is a column called **Platforms**, which contains the smart contracts of each project",.csv
Layoffs Dataset,1,layoffs-2022,layoffs.csv,ODbL-1.0,"## Context
Tech firms around the globe are fighting the economic slowdown. The slow consumer spending, higher interest rates by central banks and strong dollars overseas are hinting towards possible recession and tech firms have started laying employees off. This economic slowdown has made Meta recently fire 13% of its workforce, which amounts to more than 11,000 employees. This dataset was made with the hope to enable Kaggle community to look into analyzing recent tech turmoil and discover useful insights.

## Content
Tracking the tech layoffs reported on the following platforms:
- Bloomberg
- San Francisco Business Times
- TechCrunch
- The New York Times

The data availability is from when COVID-19 was declared as a pandemic i.e. **11 March 2020** to present (**20 April 2024**).  
Some data such as the sources, list of employees laid off and date of addition has been omitted here and the complete data can be found on [Layoffs.fyi](https://layoffs.fyi/).  
Credits: [Roger Lee](https://www.rogerlee.com/)
",.csv
Layoffs Dataset 2024,1,layoffs-data-2022,layoffs_data.csv,ODbL-1.0,"Context

This dataset was scraped from Layoffs.fyi with the hope to enable Kaggle community to look into analyzing recent mass layoffs and discover useful insights and patterns.

Original dataset can be tracked at https://layoffs.fyi/

Credits: Roger Lee",.csv
Lead Score Case Study,1,lead-score-case-study,Leads.csv,MIT,"## Problem statement:

An education company named X Education sells online courses to industry professionals. On any given day, many professionals who are interested in the courses land on their website and browse for courses. 

The company markets its courses on several websites and search engines like Google. Once these people land on the website, they might browse the courses or fill up a form for the course or watch some videos. When these people fill up a form providing their email address or phone number, they are classified to be a lead. Moreover, the company also gets leads through past referrals. Once these leads are acquired, employees from the sales team start making calls, writing emails, etc. Through this process, some of the leads get converted while most do not. The typical lead conversion rate at X education is around 30%. 

Now, although X Education gets a lot of leads, its lead conversion rate is very poor. For example, if, say, they acquire 100 leads in a day, only about 30 of them are converted. To make this process more efficient, the company wishes to identify the most potential leads, also known as ‘Hot Leads’. If they successfully identify this set of leads, the lead conversion rate should go up as the sales team will now be focusing more on communicating with the potential leads rather than making calls to everyone.

X Education company wants to find the most promising leads, i.e. the leads that are most likely to convert into paying customers. The company requires you to build a model wherein you need to assign a lead score to each of the leads such that the customers with a higher lead score have a higher conversion chance and the customers with a lower lead score have a lower conversion chance. The CEO, in particular, has given a ballpark of the target lead conversion rate to be around 80%.


## Data
Hint: Many of the categorical variables have a level called 'Select' which needs to be handled because it is as good as a null value

## Goals of the Case Study
Build a classification model to assign a lead score between 0 and 100 to each of the leads which can be used by the company to target potential leads. A higher score would mean that the lead is hot, i.e. is most likely to convert whereas a lower score would mean that the lead is cold and will mostly not get converted.",.csv
Lead Scoring X Online Education,1,lead-scoring-x-online-education,Leads X Education.csv,other,"### Lead Scoring Case Study - Problem Statement

An education company named X Education sells online courses to industry professionals. On any given day, many professionals who are interested in the courses land on their website and browse for courses. 

 The company markets its courses on several websites and search engines like Google. Once these people land on the website, they might browse the courses or fill up a form for the course or watch some videos. When these people fill up a form providing their email address or phone number, they are classified to be a lead. Moreover, the company also gets leads through past referrals. Once these leads are acquired, employees from the sales team start making calls, writing emails, etc. Through this process, some of the leads get converted while most do not. The typical lead conversion rate at X education is around 30%. 

 

Now, although X Education gets a lot of leads, its lead conversion rate is very poor. For example, if, say, they acquire 100 leads in a day, only about 30 of them are converted. To make this process more efficient, the company wishes to identify the most potential leads, also known as ‘Hot Leads’. If they successfully identify this set of leads, the lead conversion rate should go up as the sales team will now be focusing more on communicating with the potential leads rather than making calls to everyone. A typical lead conversion process can be represented using the following funnel:


Lead Conversion Process - Demonstrated as a funnel

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F3515295%2Fa031932efdd103c26332798adad58047%2FXNote_201901081613670.jpg?generation=1573575207907385&alt=media)



As you can see, there are a lot of leads generated in the initial stage (top) but only a few of them come out as paying customers from the bottom. In the middle stage, you need to nurture the potential leads well (i.e. educating the leads about the product, constantly communicating etc. ) in order to get a higher lead conversion.

 

X Education has appointed you to help them select the most promising leads, i.e. the leads that are most likely to convert into paying customers. The company requires you to build a model wherein you need to assign a lead score to each of the leads such that the customers with higher lead score have a higher conversion chance and the customers with lower lead score have a lower conversion chance. The CEO, in particular, has given a ballpark of the target lead conversion rate to be around 80%.


### Content

You have been provided with a leads dataset from the past with around 9000 data points. This dataset consists of various attributes such as Lead Source, Total Time Spent on Website, Total Visits, Last Activity, etc. which may or may not be useful in ultimately deciding whether a lead will be converted or not. The target variable, in this case, is the column ‘Converted’ which tells whether a past lead was converted or not wherein 1 means it was converted and 0 means it wasn’t converted. You can learn more about the dataset from the data dictionary provided in the zip folder at the end of the page. Another thing that you also need to check out for are the levels present in the categorical variables. Many of the categorical variables have a level called 'Select' which needs to be handled because it is as good as a null value (think why?).


### Acknowledgements

This data set is created by UpGrad-IIIT-B and given as part of assignment


### Inspiration

There are quite a few goals for this case study.

Build a logistic regression model to assign a lead score between 0 and 100 to each of the leads which can be used by the company to target potential leads. A higher score would mean that the lead is hot, i.e. is most likely to convert whereas a lower score would mean that the lead is cold and will mostly not get converted.",.csv
League of Legends Diamond Matches: FF@15,1,league-of-legends-diamond-matches-ff15,LoL_15_Diamond.csv,other,"## Context

League of Legends is a MOBA (Multiplayer Online Battle Arena) where two teams (Blue and Red) of five players compete over each other's resources and neutral objectives to destroy the enemy base (Nexus). There are three lanes; Top, Middle (Mid), and Bottom (Bot), each with defensive structures (Towers or Turrets); a jungle, filled with neutral monsters that give gold, experience and some give buffs (power-ups); a River with epic neutral objectives that provide permanent buffs (Void Grubs and Dragons) and some that provide temporary boosts to your team (Elder Dragon, Baron and Rift Herald). After the 15 minute mark, teams have the option to surrender (colloquially known as ""ff"" for ""forfeit""). This dataset was inspired by [this dataset](https://www.kaggle.com/datasets/bobbyscience/league-of-legends-diamond-ranked-games-10-min).

## Content

This dataset contains game metrics of the first 15 minutes of a match--games usually last between 25-35 minutes, but can surpass an hour. The data collected represents approximately 20,000 games of ranked solo queue (players can only queue up for a game with maximum one other person) from *current* Diamond Players (n.b. Patch 14.6, all games are from between March 20th and March 31st). The target value is blue_Wins (1 represents a Blue Team Victory, 0 represents a Red Team Victory)

Each game is unique and there should be no missing values, *match_id* can be used to GET more data from the Riot Games API.

## Glossary

**Wards**: The in game map includes Fog of War, which means players can only see what is in their immediate vicinity. Wards are totems that players can drop to temporarily or permanently gain vision in areas.
1. Yellow Wards: Usable after level 1, a player may have up to 3 activate at any time, can be placed up to 600 units away, last 90-120 seconds (based on average champion level) or until they are destroyed (3 HP).
2. Sight Wards: Functionally the same as a Yellow Ward, usually placed by Supports (Please correct if wrong)
3. Blue Wards: Only usable after level 9, a player may only have 1 active at any time, can be placed up to 4000 units away, last until they are destroyed (1 HP).
4. Control Wards: Purchasable single-use wards available from level 1, a player may only have 1 activate at any time. Reveals invisible units, last until they are destroyed (4 HP)

**Ace**: When a team kills all members of the enemy team such that all enemy players are dead at a given moment.

**Assist**: When a player helps secure a kill (but did not give the killing blow themself), either by damaging, using crowd control (slowing, stunning, etc), or buffing (healing, powering up) an ally that also participated in the kill.

**Void Grub**: A Neutral Epic Monster that gives players an increase in damage to enemy structures (Towers/Turrets, Inhibitors) increasing for every extra Void Grub defeated. Only 3 or 6 will spawn in a game, but not all need to be or will be killed. *n.b.* if a team kills 5 or 6 Void Grubs, they will periodically summon 1 or 2 Voidmites (little alien things) that assist in destroying objects).

**Dragons**: Neutral Epic Monster that grant permanent bonuses to a team. Only 3 types of non-Elder Dragons (Not included in this dataset as Elder cannot appear prior to 15 minutes) will spawn in a given game.
1. Cloud Drake: makes players faster
2. Infernal Drake: increases player attack damage and ability power
3. Mountain Drake: increases player armor and magic resistance
4. Ocean Drake: gives players extra health regeneration
5. Chemtech Drake: grants players resistance to crowd control and extra healing and shielding
6. Hextech Drake: increases the rate at which players can attack and use spells

**Herald**: A Neutral Objective that assists players in destroying enemy structures

**Towers/Turrets**: ""Tower"" and ""Turret"" are used interchangeably, these are defensive structures that must be destroyed to reach the enemy Nexus. There are 3 in each lane, and 2 at the enemy Nexus. They give gold and have plates

**Turret Plates**: The first/outer turrets in each lane have 5 plates that grant extra resistances to the tower for the first 14 minutes. Each plate destroyed prior to 14 minutes grants additional gold.

**Inhibitor**: A structure at the enemy base, destroying this gives your minions additional power and at least one must be destroyed to destroy the enemy Nexus. They regenerate after a few minutes.

**Gold**: A resource earned by killing minions, jungle monsters, enemy players and destroying neutral objectives, enemy structures, wards. Gold is used to buy items to increase player strength.

**XP**: XP and Experience used interchangeably--A resource earned by killing minions, jungle monsters, enemy players and destroying neutral objectives, enemy structures. XP allows a player to level-up, granting additonal strength and allowing players to learn new and upgrade abilities.

**Level**: Champion Level, starts at 1, maximum of 18.

**CS**: Creep Score / Minions. Each team spawns minions in their lanes. Creep score is a count of how many minions a team has killed, (they must land the final blow on a creep to gain gold, but can gain XP by just being in the vicinity when one dies).

**Jungle Monsters**: Outside of the Lanes is the Jungle, filled with neutral monsters that grant gold, XP and some grant buffs

## License
Dataset belongs to Riot Games

## Acknowledgements
Thanks, Riot.",.csv
League of Legends Diamond Ranked Games (10 min),1,league-of-legends-diamond-ranked-games-10-min,high_diamond_ranked_10min.csv,CC0-1.0,"### Context

League of Legends is a MOBA (multiplayer online battle arena) where 2 teams (blue and red) face off. There are 3 lanes, a jungle, and 5 roles. The goal is to take down the enemy Nexus to win the game.


### Content

This dataset contains the first 10min. stats of approx. 10k ranked games (SOLO QUEUE) from a high ELO (DIAMOND I to MASTER). Players have roughly the same level.

Each game is unique. The **gameId** can help you to fetch more attributes from the Riot API.

There are 19 features per team (38 in total) collected after 10min in-game. This includes kills, deaths, gold, experience, level... It's up to you to do some feature engineering to get more insights.

The column **blueWins** is the target value (the value we are trying to predict). A value of 1 means the blue team has won. 0 otherwise.

So far I know, there is no missing value.

### Glossary
- Warding totem: An item that a player can put on the map to reveal the nearby area. Very useful for map/objectives control.
- Minions: NPC that belong to both teams. They give gold when killed by players.
- Jungle minions: NPC that belong to NO TEAM. They give gold and buffs when killed by players.
- Elite monsters: Monsters with high hp/damage that give a massive bonus (gold/XP/stats) when killed by a team.
- Dragons: Elite monster which gives team bonus when killed. The 4th dragon killed by a team gives a massive stats bonus. The 5th dragon (Elder Dragon) offers a huge advantage to the team.
- Herald: Elite monster which gives stats bonus when killed by the player. It helps to push a lane and destroys structures.
- Towers: Structures you have to destroy to reach the enemy Nexus. They give gold.
- Level: Champion level. Start at 1. Max is 18.


### Acknowledgements

Thanks, Rito Gaming.",.csv
League of Legends SoloQ matches at 15 minutes 2024,1,league-of-legends-soloq-matches-at-10-minutes-2024,match_data_v5.csv,Apache 2.0,"This dataset contains data about the first 15 minutes of gameplay for over 24 thousand solo queue matches taken from european servers (EUNE and EUW). 

Average ELO of the matches is between mid emerald to high diamond. 

The main purpose of the dataset is to help train models for predicting the winner based on how the first 15 minutes of the match played out. 

There are 14 features for red, and 14 features for the blue team (feature blueTeamFirstBlood counts for both teams since it tells us which team got the first kill), with the target feature being blueWin. blueWin == 1 indicates a victory of the blue team, and blueWin == 0 means that the red team won. 

A notebook detailing the process of collecting the data is available in the code tab. We hope it helps someone improve the collection method, or reuse the code for another project.

There should be no missing values.

### Feature explanations
- matchId - ID of the League match
- blueTeamControlWardsPlaced - control/pink wards placed by the blue team (can have outliers based on the possibility of the team giving up and buying a lot of wards at the end and placing them)
- blueTeamWardsPlaced - all types of wards (control wards, yellow trinkets, ghost poro trinkets etc..) placed by the blue team
- blueTeamTotalKills - total kills by the blue team, killing an enemy champion generates gold and experience 
- blueTeamDragonKills - total dragon kills by the blue team, dragons are elite monsters that give specific permanent buffs when killed and killing the 4th dragon gives the team dragon's soul
- blueTeamHeraldKills - total herald kills by the blue team, herald is a elite monster that helps in destroying the enemies buildings (turrets, inhibitors and the nexus) and pushing the lane
- blueTeamTowersDestroyed - total towers destroyed by the blue team, towers are defensive structures in a lane that target minions and champions 
- blueTeamInhibitorsDestroyed - total inhibitors destroyed by the blue team, inhibitor is a building protected by towers and when they are destroyed, they allow super minions to spawn on the side of the team that destroyed it
- blueTeamTurretPlatesDestroyed - total turret/tower plates destroyed by the blue team, turret plates are protective shields on towers that generate gold when they are destroyed and the completely fall off at the 14 minutes
- blueTeamFirstBlood - 1 blue team first blood, 0 red team first blood; first blood generates extra gold for the kill
- blueTeamMinionsKilled - total minions killed by the blue team, minions generate gold and experience and are of the main sources of income in the game
- blueTeamJungleMinions - total jungle minions killed by the blue team, also generate gold, but the experience is gained only by the jungler 
- blueTeamTotalGold - total gold earned by the blue team from various sources (buildings, kills, assists, minons,..)
- blueTeamXp - total blue team experience, corelates to the total amount spent in lanes (a minion doesn't have to be killed by a champion to gain experience) and total amount of champions killed
- blueTeamTotalDamageToChamps - total damage done by the blue team to enemy champions
- blueWin - 1 blue team win, 0 red team win

### Acknowledgements 
Dataset made in collaboration with Daria Komić. 



",.csv
Learn Time Series Forecasting From Gold Price,1,learn-time-series-forecasting-from-gold-price,gold_price_data.csv,CC0-1.0,"### Context

Gold, the yellow shiny metal, has been the fancy of mankind since ages. From making jewelry to being used
as an investment, gold covers a huge spectrum of use cases. Gold, like other metals, is also traded on the
commodities indexes across the world. For better understanding time series in a real-world scenario, we will
work with gold prices collected historically and predict its future value. 


### Content

Metals such as gold have been traded for years across the world. Prices of gold are determined and used
for trading the metal on commodity exchanges on a daily basis using a variety of factors. Using this daily
price-level information only, our task is to predict future price of gold.

### Data
For the purpose of implementing time series forecasting technique , i will utilize gold pricing from
[Quandl]( https://www.quandl.com/). Quandl is a platform for financial, economic, and alternative datasets. 
To access publicly shared datasets on Quandl, we can use the pandas-datareader library as well
as quandl (library from Quandl itself).  The following snippet shows a quick one-liner to get your hands on gold pricing
information since 1970s.

import quandl
gold_df = quandl.get(""BUNDESBANK/BBK01_WT5511"")

The time series is univariate  with date and time feature

### Starter Kernel(s)
-[Start with Fundamentals: TSA & Box-Jenkins Methods](https://www.kaggle.com/arashnic/start-with-fundamentals-tsa-box-jenkins-methods?scriptVersionId=47863971)

This notebook is an overview of TSA and traditional methods

### Acknowledgements

For this dataset and tasks, i will depend upon [Quandl]( https://www.quandl.com/).  The premier source for financial, economic, and alternative datasets, serving investment professionals. Quandl’s platform is used by over 400,000 people, including analysts from the world’s top hedge funds, asset managers and investment banks. 

### Inspiration

- Forecast gold price 

#  <hr style=""border: 2px solid gray""> 
#### *If you find the data useful your **upvote** is an explicit feedback for future works, Have fun exploring data!*
#  



#### [MORE DATASETs ...](https://www.kaggle.com/arashnic/datasets?sort=votes)",.csv
Learning  based Behavior Before and After COVID19,1,online-learning-behavior-post-covid19,Online_Learning_Data.csv,CC-BY-NC-SA-4.0,"The dataset consists of one .csv file named – “Online_Learning_Data.csv”. The data was collected by using Google Trends on October 7th, 2021. This dataset has 21 attributes. The first attribute, “Month,” stands for the month from January 2004 to October 2021, as the data was collected on a monthly basis in this range. The remaining 20 attributes stand for each of the 20 countries - USA, India, Brazil, UK, Russia, France, Turkey, Iran, Argentina, Colombia, Spain, Italy, Indonesia, Germany, Mexico, Poland, South Africa, Philippines, Ukraine, and Peru, that were a part of this research study. Each of these attributes that are named after one of these countries represents the search interest related to online learning from that specific country on a monthly basis in this time range. The minimum value of this search interest is 0, and the maximum value is 100. These minimum and maximum values of search interests are as per the scaling factor used by Google Trends for all Google Search data.",.csv
Learning Resources Database,1,learning-resources-database,Learning_Resources_Database.csv,CC0-1.0,"The Learning Resources Database is a catalog of interactive tutorials, videos, online classes, finding aids, and other instructional resources on National Library of Medicine (NLM) products and services. Resources may be available for immediate use via a browser or downloadable for use in course management systems

# ```Dataset Description```
It contains 520 rows and 13 variables as listed below -
- **Resource ID** : Alphanumeric identifier
- **Resource Name** : Title of the resource
- **Resource URL** : Link of the resource
- **Description** : Brief explanation on the reource
- **Archived** : Flagged as False for all data points
- **Format** : Format of the resource ex. HTML, PDF, MP4 video , MS Word, Powerpoint etc.
- **Type** : Type of the resource ex Webinar, document, tutorial, slides etc.
- **Runtime** : Runtime of the resource
- **Subject Areas** : Topic covered in reource
- **Authoring Organization** : Name of the Authoring Organization
- **Intended Audiences** : Profile of the intended audience 
- **Record Modified** : Timestamp info on record last modification
- **Resource Revised** : Timestamp info on resource last modified 
",.csv
Leetcode,1,leetcode,leetcode.csv,MIT,"LeetCode is an online platform for coding interview preparation. The service provides coding and algorithmic problems intended for users to practice coding. LeetCode has gained popularity among job seekers and coding enthusiasts as a resource for technical interviews and coding competitions. There are 3000+ technical problems on LeetCode.

There are over 3000 problems, distributed over 60 pages, I scraped the problem set table that contains all the problems.

1. **id**: A unique identifier for each problem.
2. **page_number**: The specific page on the website where the LeetCode problem appears.
3. **is_premium**: Indicates whether the problem is available to premium LeetCode users.
4. **title**: The title of the problem.
5. **problem_description**: A detailed description of the problem.
6. **topic_tags**: Tags representing the topics associated with the problem.
7. **difficulty**: The difficulty level of the problem (Easy, Medium, Hard).
8. **similar_questions**: List of similar questions to the current problem.
9. **no_similar_questions**: The number of similar questions.
10. **acceptance**: Acceptance rate for the problem.
11. **accepted**: The number of submissions that have been accepted for the problem.
12. **submission**: The total number of submissions for the problem.
13. **solution**: The total number of solutions submitted in the solution section for the problem.
14. **discussion_count**: The count of discussions related to the problem.
15. **likes**: The number of likes received for the problem.
16. **dislikes**: The number of dislikes received for the problem.
17. **problem_URL**: URL to the problem on LeetCode.
18. **solution_URL**: URL to the solution of the problem on LeetCode.",.csv
Lego Sets,1,lego-sets,lego_sets.csv,CC0-1.0,"### Context

Have you ever wondered what is the most expensive lego set in the world? Or how many pieces does the Taj Mahal set contain? What about, how these features might interact with each other? I wanted to answer some of these questions and more, so I scraped lego set and price information from Lego's website.


### Content

This dataset contains lego sets scraped from lego.com. Each observation is a different lego set and there are features like how many pieces are in the set, how much the set sells for, etc. This dataset contains lego sets from all the different countries they sell online to (except South Korea).


### Inspiration

Some other questions this dataset might help answer:

What is the average suggested age for lego sets?
Do electronics have a significant impact on the price of legos?
Are more unique lego sets are sold in the U.S or in Spain?",.csv
Lex Fridman Podcast Transcript,1,lex-fridman-podcast-transcript,podcastdata_dataset.csv,CC0-1.0,"Dive deep into the fascinating world of conversations between Lex Fridman and his esteemed guests with this comprehensive dataset of podcast transcripts. Featuring discussions with thought leaders from diverse fields such as technology, science, philosophy, and art, this dataset offers a treasure trove of insights and wisdom. Explore the nuances of each conversation, uncover emerging trends, and gain valuable knowledge through text analysis. Whether you're a researcher, data scientist, or enthusiast, this dataset provides a rich resource for understanding and exploring the depths of human knowledge and curiosity.",.csv
Lgbt law,1,lgbt-law,countries-protecting-core-lgbt-rights.csv,CC0-1.0,"LGBT+ rights are human rights that all lesbian, gay, bisexual, transgender and other people outside traditional sexuality and gender categories have. But in practice, these rights are often not protected to the same extent as the rights of straight and cisgender people.

Among others, LGBT+ rights include: physical integrity rights, such as not being executed for their sexuality or gender and not being subjected to conversion therapies; social rights, such as changing their legal gender, being sexually intimate, marrying, and adopting children with people of the same sex; economic rights such as not being discriminated at work; and political rights, such as being able to advocate for themselves and their communities publicly.

The protection of these rights allows LGBT+ people to live the lives they want and to thrive in them.

On this page, you can find data and visualizations on how the protection of LGBT+ rights has changed over time, and how it differs across countries. ",.csv
Liar Twitter Dataset,1,liar-twitter-dataset,Liar_Dataset.csv,Apache 2.0,"Original link of the dataset can be found here for citations comprehensive 
https://www.cs.ucsb.edu/~william/data/liar_dataset
https://www.cs.ucsb.edu/~william/data/
https://www.cs.ucsb.edu/~william/
",.csv
Liberals vs Conservatives on Reddit [13000 posts],1,liberals-vs-conservatives-on-reddit-13000-posts,file_name.csv,other,"### Context

Reddit is very politically divided and can represent the political ideals and divisions in our society today! It would be interesting to analyze the types of discussions Redditors on both sides of the political spectrum are having, and what topics are hottest lately! Feel free to perform NLP models or anything else, and please share your notebooks!

### Content

13000 rows of Reddit posts collected from Liberal and Conservative leaning subreddits.

### Acknowledgements

Thank you to Reddit!!!

### Inspiration

I was inspired by the lack of datasets pertaining Reddit and politics!",.csv
Library books,1,library-books,Books_data - Sheet1.csv,CC0-1.0,"Its small dataset of book which can used for the testing of library management system. It can be also used as the dataset for the project purpose.
In this dataset each book is identified by the unique identifier number, title of the book and author. Each book is classified into an unique genre.
For library management system purpose, it also has a status column which states about the status of the book that whether the book is issued by somebody or available at the library.",.csv
Life Expectancy (WHO) Fixed,1,life-expectancy-who-updated,Life-Expectancy-Data-Updated.csv,CC0-1.0,"Data contains life expectancy, health, immunization, and economic and demographic information about **179 countries** from **2000-2015 years**. The adjusted dataset has **21 variables** and **2.864 rows**.


Data were initially collected from [Kaggle Source](https://www.kaggle.com/datasets/kumarajarshi/life-expectancy-who).

The dataset had inaccurate data and a lot of values were missing. 

The dataset is completely updated. 

Data about Population, GDP, and Life Expectancy was updated according to World Bank Data. Information about vaccinations for Measles, Hepatitis B, Polio, and Diphtheria, alcohol consumption, BMI, HIV incidents, mortality rates, and thinness were collected from World Health Organization public datasets. Information about Schooling was collected from the Our World in Data which is a project of the University of Oxford.

The data had some missing values. A few **strategies for filling in missing** values were applied.
1. Filling data with the **closest three-year average**. If a specific country had a missing value in any year, the data was filled with the closest three-year average. 
2. Filling data with the **average of the Region**. If a specific country was missing values for all years, the data was filled with the average of the Region (e.g. Asia, Africa, European Union, etc.)

Data is adjusted and the missing values are filled. Countries that were missing more than 4 data columns were omitted from the database. Examples of these countries are Sudan, South Sudan, and North Korea.

The database has one variable that categorizes countries into two groups: **Developed vs Developing** countries. According to World Trade Organization, each country [defines](https://www.wto.org/english/tratop_e/devel_e/d1who_e.htm) itself as “Developed” or “Developing”. Therefore, it is challenging to categorize countries. UN has a [list](https://www.un.org/en/development/desa/policy/wesp/wesp_current/2014wesp_country_classification.pdf) dated 2014 that for analytical purposes classifies countries as developed, in transition, and developing economies. Countries that have economies in transition have similar characteristics to the countries that are categorized as developed or developing countries. Countries have been grouped according to their Gross National Income per capita. As a result, nations were divided into four income groups: high-income, higher-middle-income, lower-middle-income, and low-income. The levels of Gross Domestic Income are set by the World Bank to ensure comparability.

**Data Sources:**
Average life expectancy of both genders in different years from 2010 to 2015: [https://www.who.int/data/gho/data/indicators/indicator-details/GHO/life-expectancy-at-birth-(years)](https://bit.ly/3JZeMmu)
Mortality-related attributes (infant deaths, under-five-deaths, adult mortality): https://www.who.int/data/gho/data/themes/mortality-and-global-health-estimates
Alcohol consumption that is recorded in liters of pure alcohol per capita with 15+ years old: [https://www.who.int/data/gho/data/indicators/indicator-details/GHO/alcohol-recorded-per-capita-(15-)-consumption-(in-litres-of-pure-alcohol)](https://bit.ly/40sBElC)
% of coverage of Hepatitis B (HepB3) immunization among 1-year-olds: [https://www.who.int/data/gho/data/indicators/indicator-details/GHO/hepatitis-b-(hepb3)-immunization-coverage-among-1-year-olds-(-)](https://bit.ly/3TUqljv)
% of coverage of Measles containing vaccine first dose (MCV1) immunization among 1-year-olds: [https://www.who.int/data/gho/data/indicators/indicator-details/GHO/measles-containing-vaccine-first-dose-(mcv1)-immunization-coverage-among-1-year-olds-(-)](https://bit.ly/3G2ry2O)
% of coverage of Polio (Pol3) immunization among 1-year-olds: [https://www.who.int/data/gho/data/indicators/indicator-details/GHO/polio-(pol3)-immunization-coverage-among-1-year-olds-(-)](https://bit.ly/3M2mTkT)
% of coverage of Diphtheria tetanus toxoid and pertussis (DTP3) immunization among 1-year-olds: [https://www.who.int/data/gho/data/indicators/indicator-details/GHO/diphtheria-tetanus-toxoid-and-pertussis-(dtp3)-immunization-coverage-among-1-year-olds-(-)](https://bit.ly/3nrGD7n)
BMI: https://www.who.int/europe/news-room/fact-sheets/item/a-healthy-lifestyle---who-recommendations
Incidents of HIV per 1000 population aged 15-49: https://data.worldbank.org/indicator/SH.HIV.INCD.ZS
Prevalence of thinness among adolescents aged 10-19 years. BMI &lt; -2 standard deviations below the median: https://www.who.int/data/gho/indicator-metadata-registry/imr-details/4805
GDP per capita in current USD: https://data.worldbank.org/indicator/NY.GDP.PCAP.CD?most_recent_year_desc=true
Total population in millions: https://data.worldbank.org/indicator/SP.POP.TOTL?most_recent_year_desc=true
Average years that people aged 25+ spent in formal education: https://ourworldindata.org/grapher/mean-years-of-schooling-long-run

",.csv
Life expectancy & Socio-Economic (world bank),1,life-expectancy-and-socio-economic-world-bank,life expectancy.csv,world-bank,"# Introduction

Life expectancy at birth indicates the number of years a newborn infant would live if prevailing
patterns of mortality at the time of its birth were to stay the same throughout its life. It is a key
metric for assessing population health.


Life expectancy has burgeoned since the advent of industrialization in the early 1900s and the world average has now more than doubled to 70 years. Yet, we still see inequality in life expectancy across and within countries. The study by Acemoglu and Johnson demonstrated the relationship between increased life expectancy
and improvement in economic growth (GDP per capita), controlling for country-fixed effects [3]. In the
table below, we have shown how life expectancy varies between high-income and low-income countries.
However, further analysis is necessary to determine how the allocation of a country’s wealth through
certain investments in healthcare, education, environmental management, and some socioeconomic
factors have an overall effect in determining average life expectancy.


![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F2798169%2F628ce779038d936de99db54cf792ce8d%2Fle_reg.png?generation=1693904967765822&alt=media)

The Sub-Saharan African region experiences the lowest life expectancy at birth compared to other
regions over the past 3 decades.  SSA countries have consistently ranked as the lowest-earning countries in terms of
GDP per capita. Therefore, there is a huge scope for improvement in life expectancy in SSA countries
and hence our research focuses on the 40 Sub-Saharan African (SSA) countries with the lowest GDP per
capita


# Research Questions

After reviewing the rich existing literature on Life Expectancy, we realized the lack of concrete
research on understanding the impact of all-encompassing determinants that cover socio-economic and
environmental factors for SSA countries using Panel Data techniques. Hence, we tried to address this
inadequacy through our research. In this paper, we aim to have a better understanding of factors affecting
life expectancy in the SSA region for an efficient policy-making process and better allocation of funds
and resources in addressing the prevalence of low life expectancy in Sub-Saharan Africa. To achieve that
we attempt to answer the following questions in this research:

1. What’s the Impact of Expenditure on Health and Education (% of GDP) on Life Expectancy?
2. How does the prevalence of undernourishment and communicable disease Affect Life Expectancy?
3. Do factors like corruption and unemployment rate impact life expectancy? If yes, quantify
4. Increase in CO2 emissions decrease life expectancy? Is it significant?



# Data 

Main sources of data - [World Bank Open Data](https://data.worldbank.org/) & [Our World in Data](https://ourworldindata.org/)

1. Country - 174 countries - [list](https://github.com/Shritej24c/Econometrics/blob/main/list%20of%20countries.txt)

2. Country Code - 3-letter code

3. Region - region of the world country is located in

4. IncomeGroup - country's income class 

5. Year - 2000-2019 (both included) 

6. Life expectancy - data

7. Prevalence of Undernourishment (% of the population) - Prevalence of undernourishment is the
percentage of the population whose habitual food consumption is insufficient to provide the dietary
energy levels that are required to maintain a normally active and healthy life


8. Carbon dioxide emissions (kiloton) - Carbon dioxide emissions are those stemming from the burning
of fossil fuels and the manufacture of cement. They include carbon dioxide produced during the
consumption of solid, liquid, and gas fuels and gas flaring


9. Health Expenditure (% of GDP) - Level of current health expenditure expressed as a percentage of GDP. Estimates of current health expenditures include healthcare goods and services consumed during each year. This indicator does not include capital health expenditures such as buildings,
machinery, IT, and stocks of vaccines for emergencies or outbreaks

10.  Education Expenditure (% of GDP) - General government expenditure on education (current,
capital, and transfers) is expressed as a percentage of GDP. It includes expenditures funded by
transfers from international sources to the government. General government usually refers to local,
regional, and central governments.

11.  Unemployment (% total labor force) - Unemployment refers to the % share of the labor force that
is without work but available for and seeking employment

12.  Corruption (CPIA rating) - Transparency, accountability, and corruption in the public sector assets
the extent to which the executive can be held accountable for its use of funds and for the results
of its actions by the electorate and by the legislature and judiciary, and the extent to which public employees within the executive are required to account for administrative decisions, use of resources,
and results obtained.

13.  Sanitation - People using safely managed sanitation services (% of the population): The percentage of people using improved sanitation facilities that are not shared with other households and where excreta are safely disposed of in situ or transported and treated offsite. Improved sanitation facilities include flush/pour flush to piped sewer systems, septic tanks, or pit latrines: ventilated improved pit latrines, compositing toilets, or pit latrines with slabs.
WHO/UNICEF Joint Monitoring Programme (JMP) for Water Supply, Sanitation and Hygiene (washdata.org).

14.  Disability-Adjusted Life Years (DALYs) due to Injuries - One DALY represents
the loss of the equivalent of one year of full health. DALYs for an injury or health
condition is the sum of the years of life lost due to premature mortality (YLLs) and the years
lived with a disability (YLDs) due to prevalent cases of the disease in a population

15.  Disability-Adjusted Life Years (DALYs) due to Communicable diseases - One DALY represents
the loss of the equivalent of one year of full health. DALYs for a communicable disease or health
condition is the sum of the years of life lost due to premature mortality (YLLs) and the years
lived with a disability (YLDs) due to prevalent cases of the disease in a population

16.  Disability-Adjusted Life Years (DALYs) due to Non-Communicable diseases - One DALY represents
the loss of the equivalent of one year of full health. DALYs for a non-communicable disease or health
condition is the sum of the years of life lost due to premature mortality (YLLs) and the years
lived with a disability (YLDs) due to prevalent cases of the disease in a population


If you find it useful, please support by upvoting ❤️
",.csv
Life the world,1,life-the-world,life-expectancy new.csv,CC0-1.0,"this graph was created in OurDataWorld:

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F9f4d19e9175871ef598b4199e311e85d%2Fgraph1.png?generation=1715208322576301&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F0fd67986587ae3ac9dbcd42909d0622e%2Fgraph2.png?generation=1715208328870307&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F43d2f32ca42d068a0f59882b585a6c9c%2Fgraph3.png?generation=1715208345753461&alt=media)

But where, when, how, and why has this dramatic change occurred?

To understand it, we can look at data on life expectancy worldwide.

The large reduction in child mortality has played an important role in increasing life expectancy. But life expectancy has increased at all ages. Infants, children, adults, and the elderly are all less likely to die than in the past, and death is being delayed.

This remarkable shift results from advances in medicine, public health, and living standards. Along with it, many predictions of the ‘limit’ of life expectancy have been broken.

On this page, you will find global data and research on life expectancy and related measures of longevity: the probability of death at a given age, the sex gap in life expectancy, lifespan inequality within countries, and more.

In 2021, the global average life expectancy was just over 70 years. This is an astonishing fact – because just two hundred years ago, it was less than half.

This was the case for all world regions: in 1800, no region had a life expectancy higher than 40 years.

The average life expectancy has risen steadily and significantly across all regions.1

This extraordinary rise is the result of a wide range of advances in health – in nutrition, clean water, sanitation, neonatal healthcare, antibiotics, vaccines, and other technologies and public health efforts – and improvements in living standards, economic growth, and poverty reduction.

In this article, we cover this in more detail:
",.csv
Liga 1 Indonesia 2023-2024 Player Dataset,1,liga-1-indonesia-player-dataset,player_data.csv,CC0-1.0,"Motivated by my hobby of watching football matches, especially the local league from my country, Indonesia, I started looking for data related to Liga 1 Indonesia for me to analyze and get insight from the data.

This dataset contains 568 players that registered for Liga 1 Indonesia 2023-2024.",.csv
LinkedIn Tech Jobs,1,linkedin-jobs,final_data.csv,DbCL-1.0,"Over 500 jobs scraped from the job section of LinkedIn.

**Attribute 	        Feature's Meaning**
location 	                The location of the job
designation 	        The designation of the job
name 	                Name of the company
industry 	                Industry in which the company operates
employees_count 	Count of employees
linkedin_followers 	Number of followers on linkedin
involvement 	        the nature of involvement in the job, for instance: Full-time, part-time
level 	                The seniority level like Mid-Senior level
total_applicants 	total number of applicants
Skills 	                Skills required for the job",.csv
Lionel Messi vs Cristiano Ronaldo | Club Goals,1,lionel-messi-vs-cristiano-ronaldo-club-goals,data.csv,DbCL-1.0,"# Context
This dataset contains all the stats of all goals of **Lionel Andrés Messi** and **Cristiano Ronaldo dos Santos Aveiro**.

# About Lionel Messi
**Lionel Andrés Messi**, also known as Leo Messi, is an Argentine professional footballer who plays as a forward for Ligue 1 club Paris Saint-Germain and captains the Argentina national team. 
- Born: June 24, 1987 (age 34 years), Rosario, Argentina
- Height: 1.69 m
- Spouse: Antonela Roccuzzo (m. 2017)
- Salary: 41 million USD (2022)
- Current teams: Paris Saint-Germain F.C. (#30 / Forward), Argentina national football team (#10 / Forward)
- Children: Mateo Messi Roccuzzo, Thiago Messi Roccuzzo, Ciro Messi Roccuzzo
- Awards: European Golden Shoe, FIFA World Player of the Year, MORE

# About Cristiano Ronaldo
**Cristiano Ronaldo dos Santos Aveiro** is a Portuguese professional footballer who plays as a forward for Premier League club Manchester United and captains the Portugal national team.
- Current team: Portugal national football team (#7 / Forward) Trending   
- Born: February 5, 1985 (age 37 years), Hospital Dr. Nélio Mendonça, Funchal, Portugal
- Height: 1.87 m
- Partner: Georgina Rodríguez (2017–)
- Salary: 26.52 million GBP (2022)
- Children: Cristiano Ronaldo Jr., Alana Martina dos Santos Aveiro, Eva Maria Dos Santos, Mateo Ronaldo


![LM10, CR7](https://assets.khelnow.com/news/uploads/2022/12/Lionel-Messi-vs-Cristiano-Ronaldo-Lead-Pic-1200x600.jpg)

# Content
- data.csv file containing all goal's Season, Competition, Matchday, Venue, Date, Team, Opponent, Result, Position, Minute, At_score, Type, Assisted By

# Featured Notebook
- [**📊 Ext. EDA ⚽ Goals ▶️ Lionel Messi**](https://www.kaggle.com/azminetoushikwasi/ext-eda-goals-lionel-messi)
- [**CR7 - Extensive EDA & Analytics-Cristiano Ronaldo**](https://www.kaggle.com/azminetoushikwasi/cr7-extensive-eda-analytics-cristiano-ronaldo)

# Related Datasets
- [EPL 2021-22 | Stats | Matches and Players](https://www.kaggle.com/datasets/azminetoushikwasi/epl-21-22-matches-players)
- [⚽ Cristiano Ronaldo ⭐ All Club Goals 📈📊](https://www.kaggle.com/datasets/azminetoushikwasi/cr7-cristiano-ronaldo-all-club-goals-stats)
- [⚽ Lionel Messi ⭐ All Club Goals 📈📊](https://www.kaggle.com/datasets/azminetoushikwasi/-lionel-messi-all-club-goals)

# Download
- kaggle API Command
`!kaggle datasets download -d azminetoushikwasi/lionel-messi-vs-cristiano-ronaldo-club-goals`

## Disclaimer
- The data collected are all publicly available and it's intended for educational purposes only.

## Acknowledgement
- Cover image taken from internet.

## Appreciate, Support, Share
",.csv
Lionel Messi | All Club Goals,1,-lionel-messi-all-club-goals,data.csv,ODbL-1.0,"# Context
This dataset contains all the stats of all goals of **Lionel Andrés Messi**.

# About Lionel Messi
**Lionel Andrés Messi**, also known as Leo Messi, is an Argentine professional footballer who plays as a forward for Ligue 1 club Paris Saint-Germain and captains the Argentina national team. 

- Born: June 24, 1987 (age 34 years), Rosario, Argentina
- Height: 1.69 m
- Spouse: Antonela Roccuzzo (m. 2017)
- Salary: 41 million USD (2022)
- Current teams: Paris Saint-Germain F.C. (#30 / Forward), Argentina national football team (#10 / Forward)
- Children: Mateo Messi Roccuzzo, Thiago Messi Roccuzzo, Ciro Messi Roccuzzo
- Awards: European Golden Shoe, FIFA World Player of the Year, MORE

![LM10](https://images2.minutemediacdn.com/image/fetch/w_736,h_485,c_fill,g_auto,f_auto/https%3A%2F%2Feverythingbarca.com%2Fwp-content%2Fuploads%2Fgetty-images%2F2018%2F08%2F505396006-850x560.jpeg)

# Content
- data.csv file containing all goal's Season, Competition, Matchday, Venue, Date, Team, Opponent, Result, Position, Minute, At_score, Type, Assisted By

# Featured Notebook
- [**📊 Ext. EDA ⚽ Goals ▶️ Lionel Messi**](https://www.kaggle.com/azminetoushikwasi/ext-eda-goals-lionel-messi)

# Related Datasets
- [EPL 2021-22 | Stats | Matches and Players](https://www.kaggle.com/datasets/azminetoushikwasi/epl-21-22-matches-players)
- [⚽ Cristiano Ronaldo ⭐ All Club Goals 📈📊](https://www.kaggle.com/datasets/azminetoushikwasi/cr7-cristiano-ronaldo-all-club-goals-stats)

# Download
- kaggle API Command
`!kaggle datasets download -d azminetoushikwasi/-lionel-messi-all-club-goals`

## Disclaimer
- The data collected are all publicly available and it's intended for educational purposes only.

## Acknowledgement
- Cover image taken from internet.

## Appreciate, Support, Share",.csv
List Faskes BPJS Indonesia,1,list-faskes-bpjs-indonesia,Data Faskes BPJS 2019.csv,other,"### Context

Data dikumpulkan untuk di visualisasikan lebih lanjut.


### Content

Dataset berupa list fasilitas kesehatan yang bekerja sama dengan bpjs. Data mencakup seluruh Indonesia.


### Acknowledgements

Data ini didapat dengan proses web scrapping dari situs lovia.life (https://lovia.life/en/fit/bpjs). Tanpa adanya data dari situs tersebut, dataset ini tidak akan pernah bisa terwujud.


### Inspiration

Dari dataset ini diharapkan bisa di gabung dengan dataset lainnya untk kepentingan healthcare Indonesia.",.csv
List Of Countries By GDP,1,list-of-countries-by-gdp,List Of Countries By GDP.csv,CC0-1.0,"	Data Description: 
1) Country/Territory: Name of the country or territory.
2) UN region: Region to which the country or territory belongs according to the United Nations classification.
3) IMF[1][13] Forecast: GDP estimate from the International Monetary Fund (IMF), with the year of the forecast.
4) IMF[1][13] Year: Year of the IMF GDP estimate.
5) World Bank[14] Estimate: GDP estimate from the World Bank, with the year of the estimate.
6) World Bank[14] Year: Year of the World Bank GDP estimate.
7) United Nations[15] Estimate: GDP estimate from the United Nations, with the year of the estimate.
8) United Nations[15] Year: Year of the United Nations GDP estimate.

This dataset provides a comparative view of GDP estimates for different countries/territories from various sources over multiple years. It can be useful for analyzing trends in economic growth, comparing GDP across regions, and understanding the economic performance of individual countries over time.
",.csv
List of 3000+ Indian Companies,1,list-of-3000-indian-companies,List of companies in India.csv,CC0-1.0,"The provided dataset encompasses information about over 3000 Indian companies across various industries, offering a comprehensive snapshot of India's vibrant business landscape. Here's an insightful description of the dataset:

Company Name: The name of the company, representing its unique identity and brand within the marketplace.

Industry Sector: Categorization of companies based on the sector or industry in which they operate. This classification covers a diverse array of sectors such as technology, finance, healthcare, manufacturing, consumer goods, and many others, reflecting the multifaceted nature of India's economy.

Company Size: An indication of the size or scale of the company, which may include parameters such as revenue, number of employees, market capitalization, or other relevant metrics. This information provides insights into the company's market presence and potential impact.

Location: The geographic location of the company's headquarters or primary operational base within India. This includes cities across the length and breadth of the country, from metropolitan hubs like Mumbai, Delhi, and Bangalore to emerging business centers in tier 2 and tier 3 cities.

Year of Establishment: The year in which the company was founded or established, providing historical context and highlighting its longevity and experience in the market.

Key Products/Services: Description of the primary products or services offered by the company, showcasing its areas of specialization and core competencies.

Market Positioning: Insights into the company's market positioning, competitive landscape, and strategic initiatives, which may include market share, brand reputation, and differentiation strategies.

Key Observations:

Sectoral Diversity: The dataset reflects the rich diversity of industries present in India's economy, ranging from traditional sectors like agriculture and manufacturing to modern, technology-driven industries such as IT and e-commerce.

Geographic Spread: Companies in the dataset are spread across various states and regions of India, showcasing the country's economic decentralization and the emergence of new business hubs beyond traditional metropolitan areas.

Entrepreneurial Spirit: The dataset underscores India's thriving entrepreneurial ecosystem, characterized by a vibrant startup culture, innovation-driven enterprises, and a growing emphasis on technology and digital transformation.

Contribution to Economy: These 3000+ Indian companies collectively contribute significantly to India's economic growth, job creation, and global competitiveness, driving innovation, investment, and productivity across sectors.

Insights and Applications:

Market Analysis: Analysts and researchers can leverage the dataset to conduct in-depth market analysis, identify industry trends, and gain insights into the performance and growth trajectories of Indian companies across different sectors and regions.

Investment Opportunities: Investors seeking opportunities in India can use the dataset to identify promising companies for potential investment, based on industry dynamics, growth potential, and market positioning.

Policy Formulation: Policymakers and government agencies can utilize the dataset to formulate strategies, policies, and initiatives aimed at fostering entrepreneurship, promoting industrial growth, and enhancing the competitiveness of Indian businesses on the global stage.

Business Development: Entrepreneurs and business leaders can draw inspiration from the diverse array of Indian companies in the dataset, learning from their success stories, strategies, and best practices to drive their own business growth and innovation.",.csv
List of best-selling PlayStation 4 video games,1,list-of-best-selling-ps4-games,List of best-selling PlayStation 4 video games.csv,ODC Public Domain Dedication and Licence (PDDL),"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F14601120%2F03999a34881b94e750667891600c8dc2%2Fnorbert-levajsics-dUx0gwLbhzs-unsplash.jpg?generation=1685636164502688&alt=media)
Discover the engaging titles that enthralled players around the world with their immersive gameplay, gorgeous visuals, and compelling storytelling by exploring the list of the best-selling PlayStation 4 video games. Learn about the iconic games that defined the PS4 era and forever changed the gaming landscape.",.csv
List of best-selling fiction authors,1,list-of-best-selling-fiction-authors,Best-selling fiction authors.csv,other,"This is a list of best-selling fiction authors to date, in any language. The list is based on approximate numbers provided or repeated by reliable sources. ""Best selling"" refers to the estimated number of copies sold of all fiction books written or co-written by an author. To keep the list manageable, only authors with estimated sales of at least 100 million are included. Authors of comic books are not included unless they have been published in book format ",.csv
List of best-selling mobile phones,1,list-of-best-selling-mobile-phones,Top selling mobile phones.csv,other,"This is a list of best-selling mobile phones. The best-selling mobile devices are the bar phone Nokia 1100 and Nokia 1110, released in 2003 and 2005, respectively. Both models have sold over 250 million units. The best-selling touchscreen phones are the Apple iPhone 6 and 6 Plus, both released in 2014. Together, they have sold over 222 million units. The best selling flip phone is the Motorola RAZR V3, released in 2004. It sold over 130 million units. The best-selling slider phone is the Samsung E250, released in 2006. It has sold over 30 million units.

Of the 115 phones on the list, Samsung sold the most models, with 37. Nokia has 27 models, including four of the top 10. Apple has 16 entries on the list, including the six best selling touchscreen phones, which comprise the remainder of the top 10.",.csv
List of bestselling Nintendo Games,1,list-of-best-selling-nintendo-games,List-of-best-selling-videogames.csv,CC0-1.0,"This dataset contains the list of bestselling Nintendo games, by platform on which it was released. I would be updating it to add the other platforms as well.

Kindly upvote if it helped. 😊😊

Here is the Github link, if you want it: https://github.com/You-now-Who/dataset/tree/main/List%20of%20best%20selling%20nintendo%20videogames",.csv
List of kaggle Grandmasters,1,list-of-kaggle-grandmasters,GM_individual_Tiers.csv,CC0-1.0,"### Description
This is a list of [kaggle Grandmasters](https://www.kaggle.com/progression) and their individual tiers and countries.

**Note:** The dataset does not include Grandmasters who have gone on to become kaggle staff.
",.csv
Literacy,1,literacy,cross-country-literacy-rates new.csv,CC0-1.0,"this graph was created in PowerBi and Loocker studio, R:

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F3aeef87f919c718cf8efb55508fc1a35%2Fgraph1.jpg?generation=1714591768341778&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F7849888eab3bff743801cef9810d0b55%2Fgraph2.jpg?generation=1714591788454563&alt=media)


![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F36d37cbabc3fc8255b8c151eafaa5249%2Fgraph3.png?generation=1714591793915928&alt=media)

Literacy is a key skill and a key measure of a population’s education. In this topic page, we discuss historical trends, as well as recent developments in literacy.

From a historical perspective, literacy levels for the world population have risen drastically in the last couple of centuries. While only one in ten people in the world could read and write in 1820, today, the share has reversed, with only one in ten remaining illiterate.

Despite large improvements in the expansion of basic education and the continuous reduction of education inequalities, there are substantial challenges ahead. The poorest countries in the world, where basic education is most likely to be a constraint for development, still have very large segments of the population who are illiterate.

See all interactive charts on literacy ↓",.csv
Liver Cirrhosis Stage Classification 🩺,1,liver-cirrhosis-stage-classification,liver_cirrhosis.csv,CC0-1.0,"## **Context:**

Cirrhosis results from prolonged liver damage, leading to extensive scarring, often due to conditions like hepatitis or chronic alcohol consumption. The data provided is sourced from a Mayo Clinic study on primary biliary cirrhosis (PBC) of the liver carried out from 1974 to 1984.

I have manually cleaned the dataset and used synthetic data to increase samples.

## **Attribute Information:**

- N_Days: Number of days between registration and the earlier of death, transplantation, or study analysis time in 1986
- Status: status of the patient C (censored), CL (censored due to liver tx), or D (death)
- Drug: type of drug D-penicillamine or placebo	
- Age: age in days
- Sex: M (male) or F (female)
- Ascites: presence of ascites N (No) or Y (Yes)	
- Hepatomegaly: presence of hepatomegaly N (No) or Y (Yes)	
- Spiders: presence of spiders N (No) or Y (Yes)	
- Edema: presence of edema N (no edema and no diuretic therapy for edema), S (edema present without diuretics, or edema resolved by diuretics), or Y (edema despite diuretic therapy)	
- Bilirubin: serum bilirubin in [mg/dl]
- Cholesterol: serum cholesterol in [mg/dl]
- Albumin: albumin in [gm/dl]
- Copper: urine copper in [ug/day]
- Alk_Phos: alkaline phosphatase in [U/liter]
- SGOT: SGOT in [U/ml]
- Tryglicerides:  triglicerides in [mg/dl]
- Platelets: platelets per cubic [ml/1000]
- Prothrombin: prothrombin time in seconds [s]
- Stage: histologic stage of disease ( 1, 2, or 3 )	

## **Citation:**

Dickson,E., Grambsch,P., Fleming,T., Fisher,L., and Langworthy,A.. (2023). Cirrhosis Patient Survival Prediction. UCI Machine Learning Repository. https://doi.org/10.24432/C5R02G.",.csv
Liver Disease Patient Dataset 30K train data,1,liver-disease-patient-dataset,Liver Patient Dataset (LPD)_train.csv,CC0-1.0,"### Context

There's a story behind every dataset and here's your opportunity to share yours.
(Liver Patient Dataset) Data Set with 20K train data, ~1K Test data


### Content

What's inside is more than just rows and columns. Make it easy for others to get started by describing how you acquired the data and what time period it represents, too.
This data set contains 10 variables that are age, gender, total Bilirubin, direct Bilirubin, total proteins, albumin, A/G ratio, SGPT, SGOT and Alkphos.

Attribute Information:

1. Age Age of the patient
2. Gender Gender of the patient
3. TB Total Bilirubin
4. DB Direct Bilirubin
5. Alkphos Alkaline Phosphotase
6. Sgpt Alamine Aminotransferase
7. Sgot Aspartate Aminotransferase
8. TP Total Protiens
9. ALB Albumin
10. A/G Ratio Albumin and Globulin Ratio
11. Selector field used to split the data into two sets (labeled by the experts)   1 Liver Patient, 2 Mon Liver Patient


### Acknowledgements

We wouldn't be here without the help of others. If you owe any attributions or thanks, include them here along with any citations of past research.
would like to Thank Kaggle dataset community for inspiration.


### Inspiration

Your data will be in front of the world's largest data science community. What questions do you want to see answered?
lets predict liver patients.",.csv
Liverpool 23/24 Season Stats,1,liverpool-2324-season-stats,deneme_1 Liverpool.csv,Apache 2.0,"***I made create a data of liverpool football team 23/24 season stats by Mysql.***
***There is no blank in any stats because of that you can use that data for analysis***
***That dataset includes just Premier League stats of Liverpool***

Content
This dataset includes 36 players of Liverpool who is played in Premier League and those players stats illustrates in there.
These stats are:

- First names
- Last names
- Nations
- Match Playing
- Positions
- Ages
- Minutes
- Match Starts
- Time left until the match ends
- Goals
- Assists


",.csv
Loan  Data,1,loandata,Loan payments data.csv,CC0-1.0,"# Context 

This data set includes customers who have paid off their loans, who have been past due and put into collection without paying back their loan and interests, and who have paid off only after they were put in collection. The financial product is a bullet loan that customers should pay off all of their loan debt in just one time by the end of the term, instead of an installment schedule. Of course, they could pay off earlier than their pay schedule.


# Content

Loan_id	A unique loan number assigned to each loan customers

Loan_status	Whether a loan is paid off, in collection, new customer yet to payoff, or paid off after the collection efforts

Principal	Basic principal loan amount at the origination

terms	Can be weekly (7 days), biweekly, and monthly payoff schedule

Effective_date	When the loan got originated and took effects

Due_date	Since it’s one-time payoff schedule, each loan has one single due date

Paidoff_time	The actual time a customer pays off the loan

Pastdue_days	How many days a loan has been past due

Age, education, gender	A customer’s basic demographic information",.csv
Loan Data,1,loan-data,loan_data.csv,DbCL-1.0,"# About the data and what to do…

publicly available data from LendingClub.com. Lending Club connects people who need money (borrowers) with people who have money (investors). Hopefully, **as an investor you would want to invest in people who showed a profile of having a high probability of paying you back.**

We will use lending data from 2007-2010 and be trying to classify and predict whether or not the borrower paid back their loan in full. You can download the data from [here](https://www.lendingclub.com/investing/peer-to-peer).

Here are what the columns represent:

credit.policy: 1 if the customer meets the credit underwriting criteria of LendingClub.com, and 0 otherwise.
purpose: The purpose of the loan (takes values ""credit_card"", ""debt_consolidation"", ""educational"", ""major_purchase"", ""small_business"", and ""all_other"").
int.rate: The interest rate of the loan, as a proportion (a rate of 11% would be stored as 0.11). Borrowers judged by LendingClub.com to be more risky are assigned higher interest rates.
installment: The monthly installments owed by the borrower if the loan is funded.
log.annual.inc: The natural log of the self-reported annual income of the borrower.
dti: The debt-to-income ratio of the borrower (amount of debt divided by annual income).
fico: The FICO credit score of the borrower.
days.with.cr.line: The number of days the borrower has had a credit line.
revol.bal: The borrower's revolving balance (amount unpaid at the end of the credit card billing cycle).
revol.util: The borrower's revolving line utilization rate (the amount of the credit line used relative to total credit available).
inq.last.6mths: The borrower's number of inquiries by creditors in the last 6 months.
delinq.2yrs: The number of times the borrower had been 30+ days past due on a payment in the past 2 years.
pub.rec: The borrower's number of derogatory public records (bankruptcy filings, tax liens, or judgments).",.csv
Loan Defaults,1,loan-default,Anonymize_Loan_Default_data.csv,DbCL-1.0,"Anonymised Loan Default data, including loan amount, term, Interest rate, instalment, employment length, home ownership, annual income, loan status and purpose, etc. as well as the binary repay_fail (1 or 0). ",.csv
Loan Predication,1,loan-predication,train_u6lujuX_CVtuZ9i (1).csv,CC0-1.0,"Among all industries, insurance domain has the largest use of analytics & data science methods. This data set would provide you enough taste of working on data sets from insurance companies, what challenges are faced, what strategies are used, which variables influence the outcome etc. This is a classification problem. The data has 615 rows and 13 columns.
Problem-----
Company wants to automate the loan eligibility process (real time) based on customer detail provided while filling online application form. These details are Gender, Marital Status, Education, Number of Dependents, Income, Loan Amount, Credit History and others. To automate this process, they have given a problem to identify the customers segments, those are eligible for loan amount so that they can specifically target these customers. Here they have provided a partial data set.

",.csv
Loan Rejection or Approval Status Prediction,1,loan-status-prediction-with-added-nans,loan_data_1.csv,Attribution 4.0 International (CC BY 4.0),"This dataset contains information about past loan applicants, including their income, loan amount, credit history, and other factors relevant to loan approval decisions.  

The goal is to build a machine learning model that can analyze this data to predict whether future loan applications should be approved or rejected.

This is a modified version of https://www.kaggle.com/datasets/bhavikjikadara/loan-status-prediction with NaN value added to some of the row cells.

About the **loan_data_added_nan.csv** file:

- Loan_ID: A unique loan ID.
- Gender: Either male or female.
- Married: Weather Married(yes) or Not Marttied(No).
- Dependents: Number of persons depending on the client.
- Education: Applicant Education(Graduate or Undergraduate).
- Self_Employed: Self-employed (Yes/No).
- ApplicantIncome: Applicant income.
- CoapplicantIncome: Co-applicant income.
- LoanAmount: Loan amount in thousands.
- Loan_Amount_Term: Terms of the loan in months.
- Credit_History: Credit history meets guidelines.
- Property_Area: Applicants are living either Urban, Semi-Urban or Rural.
- Loan_Status: Loan approved (Y/N).",.csv
Loan Status Prediction,1,loan-status-prediction,loan_data.csv,Attribution 4.0 International (CC BY 4.0),"- In this Loan Status Prediction dataset, we have the data of applicants who previously applied for the loan based on the property which is a Property Loan.
- The bank will decide whether to give a loan to the applicant based on some factors such as Applicant Income, Loan Amount, previous Credit History, Co-applicant Income, etc... 
- Our goal is to build a Machine Learning Model to predict the loan to be approved or to be rejected for an applicant.

### About the loan_data.csv file:
- **Loan_ID**: A unique loan ID.
- **Gender**: Either male or female.
- **Married**: Weather Married(yes) or Not Marttied(No).
- **Dependents**: Number of persons depending on the client.
- **Education**: Applicant Education(Graduate or Undergraduate).
- **Self_Employed**: Self-employed (Yes/No).
- **ApplicantIncome**: Applicant income.
- **CoapplicantIncome**: Co-applicant income.
- **LoanAmount**: Loan amount in thousands.
- **Loan_Amount_Term**: Terms of the loan in months.
- **Credit_History**: Credit history meets guidelines.
- **Property_Area**: Applicants are living either Urban, Semi-Urban or Rural.
- **Loan_Status**: Loan approved (Y/N).


### **Goal:**
* In this project, we are going to classify an individual whether he/she can get the loan amount based on his/her Income, Education, Working Experience, Loan taken previously, and many more factors.
Let’s get more into it by looking at the data.",.csv
Loan-Approval-Prediction-Dataset,1,loan-approval-prediction-dataset,loan_approval_dataset.csv,MIT,"The loan approval dataset is a collection of financial records and associated information used to determine the eligibility of individuals or organizations for obtaining loans from a lending institution. It includes various factors such as cibil score, income, employment status, loan term, loan amount, assets value, and loan status. This dataset is commonly used in machine learning and data analysis to develop models and algorithms that predict the likelihood of loan approval based on the given features.",.csv
Loans Data,1,loans-data,loan_data.csv,Apache 2.0,"we will be exploring publicly available data from LendingClub.com. Lending Club connects people who need money (borrowers) with people who have money (investors). Hopefully, as an investor you would want to invest in people who showed a profile of having a high probability of paying you back. We will try to create a model that will help predict this.

Lending club had a very interesting year in 2016, so let's check out some of their data and keep the context in mind. This data is from before they even went public.

We will use lending data from 2007-2010 and be trying to classify and predict whether or not the borrower paid back their loan in full. You can download the data from here or just use the csv already provided. It's recommended you use the csv provided as it has been cleaned of NA values.",.csv
Lockheed Martin Stocks,1,lockheed-martin-stocks,LMT.csv,CC0-1.0,"This dataset contains Lockheed Martin stock prices from 01/01/2000 to 04/27/2024. The columns are as follows:

```Date``` - The date

```Open``` - The opening value

```High``` - The highest value

```Low``` - The lowest value

```Close``` - The closing value

```Adj Close``` - The adjusted closing value

```Volume``` - The trading volume of the stocks

I hope you will like this dataset. God bless you.",.csv
London Bike-Share Usage Dataset,1,london-bike-share-usage-dataset,LondonBikeJourneyAug2023.csv,other,"## Context ##

This dataset contains detailed records of 776,527 bicycle journeys from the Transport for London (TfL) Cycle Hire system spanning from August 1 to August 31, 2023. The TfL Cycle Hire initiative provides publicly accessible bicycles for rent across London, promoting sustainable transportation and physical fitness. This comprehensive dataset captures individual trip data, which can be utilized to analyze urban mobility patterns, station performance, and cycling preferences among London's diverse population. This dataset provides a snapshot of cycling activity during the month, including start and end details for each journey, the bicycle used, and the duration of hire.

## Dataset Usage ##
The dataset can be used for:
- **Time Series Forecasting:** Predict future bike rental demands based on historical usage patterns.
- **Geospatial Analysis:** Map the start and end locations of trips to identify popular routes and areas with high cycling traffic.
- **Customer Behavior Analysis:** Analyze the duration and frequency of rentals to understand user preferences and habits.
- **Predictive Maintenance:** Use trip duration and frequency data to predict when bikes are likely to require maintenance or replacement.
- **Multivariate Analysis:** Explore relationships between different variables, such as trip durations, station popularity, and time of day, to uncover underlying patterns in bike usage.

## Attribute Information ##
The dataset includes the following variables for each ride:
- **Number**: A unique identifier for each trip (Trip ID).
- **Start Date**: The date and time when the trip began.
- **Start Station Number**: The identifier for the starting station.
- **Start Station**: The name of the starting station.
- **End Date**: The date and time when the trip ended.
- **End Station Number**: The identifier for the ending station.
- **End Station**: The name of the ending station.
- **Bike Number**: A unique identifier for the bicycle used.
- **Bike Model**: The model of the bicycle used.
- **Total Duration**: The total time duration of the trip (in a human-readable format).
- **Total Duration (ms)**: The total time duration of the trip in milliseconds.

**Source**
This dataset was sourced directly from the Transport for London's official website, which provides open data to encourage public use and analysis. More details and related datasets can be found at Transport for London (TfL).

**Reference:**
Transport for London. (August 2023). TfL Cycle Hire Trip Data. Retrieved [Date Retrieved], from https://tfl.gov.uk/info-for/open-data-users/our-open-data.",.csv
London Property Rental Dataset,1,london-property-rental,rent_ads_rightmove_extended.csv,MIT,"This dataset contains detailed information about rental properties across various locations in the UK. The data was collected by scraping Rightmove, a popular real estate platform. Each entry in the dataset includes the property's address, subdistrict code, rental price, deposit amount, letting type, furnish type, council tax details, property type, number of bedrooms and bathrooms, size in square feet, average distance to the nearest train station, and the count of nearest stations.

Researchers and analysts interested in the UK rental market can utilize this dataset to explore rental trends, pricing variations based on location and property type, amenities preferences, and more. The dataset provides a valuable resource for machine learning models, statistical analysis, and market research in the real estate sector.

Metadata:
Source: The data was collected by scraping the Rightmove real estate platform, a leading source for property listings in the UK.
Date Range: The dataset covers rental property listings available during the scraping period.
Geographical Coverage: Primarily focused on various locations across the UK, providing insights into regional rental markets.
Data Fields:
Address: The location of the rental property.
Subdistrict Code: A code representing the subdistrict or area of the property.
Rent: The monthly rental price in GBP (£) for the property.
Deposit: The deposit amount required for renting the property.
Let Type: Indicates whether the property is available for short-term or long-term rental.
Furnish Type: Describes the furnishing status of the property (e.g., furnished, unfurnished, or flexible options).
Council Tax: Information about the council tax associated with the property.
Property Type: Specifies the type of property, such as apartment, flat, maisonette, etc.
Bedrooms: The number of bedrooms in the property.
Bathrooms: The number of bathrooms in the property.
Size: The size of the property in square feet (sq ft).
Average Distance to Nearest Station: The average distance (in miles) to the nearest train station from the property.
Nearest Station Count: The count of nearest train stations within a certain distance from the property.
Data Quality: The data may contain missing values or ""Ask agent"" placeholders, which require direct inquiry with agents or landlords for specific information.
Potential Uses: The dataset can be used for market analysis, rental price prediction models, understanding property preferences, and exploring the impact of location and amenities on rental properties in the UK.



",.csv
London Weather Data,1,london-weather-data,london_weather.csv,CC0-1.0,"## Context
The dataset featured below was created by reconciling measurements from [requests of individual weather attributes](https://www.ecad.eu/dailydata/index.php) provided by the European Climate Assessment (ECA). The measurements of this particular dataset were recorded by a weather station near Heathrow airport in London, UK.

-&gt; This weather dataset is a great addition to [this London Energy Dataset](https://www.kaggle.com/datasets/emmanuelfwerr/london-homes-energy-data). You can join both datasets on the **'date'** attribute, after some preprocessing, and perform some interesting data analytics regarding how energy consumption was impacted by the weather in London.

## Content
The size for the file featured within this Kaggle dataset is shown below — along with a list of attributes and their description summaries:
- `london_weather.csv` - 15341 observations x 10 attributes

1. **date** - recorded date of measurement - **(int)**
2. **cloud_cover** - cloud cover measurement in oktas - **(float)**
3. **sunshine** - sunshine measurement in hours (hrs) - **(float)**
4. **global_radiation** - irradiance measurement in Watt per square meter (W/m2) - **(float)**
5. **max_temp** - maximum temperature recorded in degrees Celsius (°C) - **(float)**
6. **mean_temp** - mean temperature in degrees Celsius (°C) - **(float)**
7. **min_temp** - minimum temperature recorded in degrees Celsius (°C) - **(float)**
8. **precipitation** - precipitation measurement in millimeters (mm) - **(float)**
9. **pressure** - pressure measurement in Pascals (Pa) - **(float)**
10. **snow_depth** - snow depth measurement in centimeters (cm) - **(float)**

## Source
Weather Data - https://www.ecad.eu/dailydata/index.php",.csv
London bike sharing dataset,1,london-bike-sharing-dataset,london_merged.csv,other,"### License
These licence terms and conditions apply to TfL's free transport data service and are based on version 2.0 of the Open Government Licence with specific amendments for Transport for London (the ""Licence"").  TfL may at any time revise this Licence without notice. It is up to you (""You"") to regularly review the Licence, which will be available on this website, in case there are any changes. Your continued use of the transport data feeds You have opted to receive (""Information"") after a change has been made to the Licence will be treated as Your acceptance of that change.

Using Information under this Licence
TfL grants You a worldwide, royalty-free, perpetual, non-exclusive Licence to use the Information subject to the conditions below (as varied from time to time).

This Licence does not affect Your freedom under fair dealing or fair use or any other copyright or database right exceptions and limitations.

This Licence shall apply from the date of registration and shall continue for the period the Information is provided to You or You breach the Licence.  

Rights
You are free to:

Copy, publish, distribute and transmit the Information
Adapt the Information and
Exploit the Information commercially and non-commercially for example, by combining it with other Information, or by including it in Your own product or application
Requirements
You must, where You do any of the above:

Acknowledge TfL as the source of the Information by including the following attribution statement 'Powered by TfL Open Data'
Acknowledge that this Information contains Ordnance Survey derived data by including the following attribution statement: 'Contains OS data © Crown copyright and database rights 2016' and Geomni UK Map data © and database rights [2019]
Ensure our intellectual property rights, including all logos, design rights, patents and trademarks, are protected by following our design and branding guidelines
Limit traffic requests up to a maximum of 300 calls per minute per data feed. TfL reserves the right to throttle or limit access to feeds when it is believed the overall service is being degraded by excessive use and
Ensure the information You provide on registration is accurate 
These are important conditions of this Licence and if You fail to comply with them the rights granted to You under this Licence, or any similar licence granted by TfL, will end automatically.

Exemptions
This Licence does not:

Transfer any intellectual property rights in the Information to You or any third party
Include personal data in the Information
Provide any rights to use the Information after this Licence has ended 
Provide any rights to use any other intellectual property rights, including patents, trade marks, and design rights or permit You to:
Use data from the Oyster, Congestion Charging and Santander Cycles websites to populate or update any other software or database or
Use any automated system, software or process to extract content and/or data, including trawling, data mining and screen scraping
in relation to the Oyster, Congestion Charging and Santander Cycles websites, except where expressly permitted under a written licence agreement with TfL.
These are important conditions of this Licence and, if You fail to comply with them, the rights granted to You under this Licence, or any similar licence granted by TfL, will end automatically.

Non-endorsement
This Licence does not grant You any right to use the Information in a way that suggests any official status or that TfL endorses You or Your use of the Information.


### Context

The purpose is to try predict the future bike shares.

### Content


The data is acquired from 3 sources:  
- Https://cycling.data.tfl.gov.uk/ 'Contains OS data © Crown copyright and database rights 2016' and Geomni UK Map data © and database rights [2019] 'Powered by TfL Open Data'  
 - freemeteo.com - weather data   
 - https://www.gov.uk/bank-holidays  
From 1/1/2015 to 31/12/2016  

The data from cycling dataset is grouped by ""Start time"", this represent the count of new bike shares grouped by hour. The long duration shares are not taken in the count.

### Metadata:
""timestamp"" - *timestamp field for grouping the data*  
""cnt"" - *the count of a new bike shares*  
""t1"" - *real temperature in C*  
""t2"" - *temperature in C ""feels like""*  
""hum"" - *humidity in percentage*  
""wind_speed"" - *wind speed in km/h*  
""weather_code"" - *category of the weather*  
""is_holiday"" - *boolean field - 1 holiday / 0 non holiday*  
""is_weekend"" - *boolean field - 1 if the day is weekend*   
""season"" - *category field meteorological seasons: 0-spring ; 1-summer; 2-fall; 3-winter.*  

       
       
  


""weathe_code"" category description:  
*1 = Clear ; mostly clear but have some values with haze/fog/patches of fog/ fog in vicinity  
2 = scattered clouds / few clouds  
3 = Broken clouds  
4 = Cloudy  
7 = Rain/ light Rain shower/ Light rain  
10 = rain with thunderstorm  
26 = snowfall  
94 = Freezing Fog*",.csv
Lottery Powerball Winning Numbers,1,lottery-powerball-winning-numbers,Lottery_Powerball_Winning_Numbers__Beginning_2010.csv,U.S. Government Works,"The dataset titled ""Lottery Powerball Winning Numbers beginning from 2010 to 2024"" represents a comprehensive compilation of all winning combinations drawn in the Powerball lottery over a 14-year span. Powerball, known for its potentially massive jackpots, is one of the most popular multi-state lottery games in the United States.

Each entry in this dataset contains the date of the draw, the set of five winning numbers typically ranging from 1 to 69, and the Powerball number, which is between 1 and 26. Additionally, the dataset includes the Power Play multiplier, which can significantly increase the secondary prize amounts.

This extensive collection of Powerball results could be a treasure trove for statistical analysis, pattern detection, and probability studies. Researchers and enthusiasts might delve into the data to study frequency patterns of numbers, identify hot and cold numbers, or explore the odds of winning. Furthermore, it could also be used to examine the impact of changes in game rules or number formats over time.",.csv
Lottery Powerball Winning Numbers Dataset,1,lottery-powerball-winning-numbers-dataset,lottery_powerball_winning_numbers.csv,other,"**Description**:
This dataset contains historical Powerball winning numbers along with the respective multiplier for each draw. The Powerball lottery is a widely known and popular game played across multiple states in the United States. With this dataset, you can explore patterns, frequencies, and analyze the distribution of winning numbers over time.

**Content**:
The dataset includes the following columns:
- **Draw Date**: The date of the Powerball draw.
- **Winning Number**: The combination of winning numbers drawn.
- **Multiplier**: The multiplier applied to the winnings (if applicable).

**Source**:
The data is sourced from the New York Lottery website. For further details and payouts, visit [here](http://on.ny.gov/1GpWiHD).

**Use Cases**:
- Analyze trends and frequencies of winning numbers.
- Explore the impact of the multiplier on winnings.
- Develop predictive models for future Powerball draws.

**Potential Applications**:
- Data visualization projects.
- Machine learning models for predictive analysis.
- Statistical analysis of lottery patterns.

**Keywords**: lottery, Powerball, gambling, numbers, prediction, analytics

**License**: Public domain

**[Link to the source and license term](https://catalog.data.gov/dataset/lottery-powerball-winning-numbers-beginning-2010)**",.csv
"Lottery Sales, Prize, and Commissions",1,lottery-sales-and-commissions,PA_Lottery_Commissions_Summary.csv,MIT,"# Pennsylvania Lottery Commissions Summary Dataset

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F1937611%2Fb282df3aaba8cebd42ec4577ef6de664%2F_7b06a2c5-5dd3-4cf0-9501-40a82212f8ce.jpeg?generation=1715785605905319&alt=media)

## Overview
This dataset provides a summary of Pennsylvania Lottery sales, prizes paid, and retailer commissions by county for each State Fiscal Year (SFY) starting from 2010. It offers valuable insights into the economic impact of the Pennsylvania Lottery at the county level, aiding in government revenue analysis and economic research.

## Columns
- **County Name**: Physical county in Pennsylvania, determined by retailer sites and sales location.
- **State Fiscal Year**: Pennsylvania State Fiscal Year running from July 1st to June 30th.
- **Ticket Sales**: Net sales of tickets in the county.
- **Prizes Paid**: Sum of all tickets actually paid in each county; the claim location may differ from the sales location, with prizes claimed at Lottery Headquarters sourced to Dauphin County.
- **Retailer Commissions**: Actual amount of money applied to a retailer’s account based on tickets sold, including bonus commissions and other amounts granted by regulation.
- **FIPS County Code**: 5-digit Federal Information Processing Standard (FIPS) code designating the State association.
- **Latitude**: Latitude coordinates in degrees for a centroid point for geographic area.
- **Longitude**: Longitude coordinates in degrees for a centroid point for geographic area.
- **Georeferenced Latitude & Longitude**: Georeferenced column as a point used for creating visuals.

## Usage
This dataset can be utilized for various purposes including:
- Analyzing the economic impact of the Pennsylvania Lottery at the county level.
- Understanding the distribution of ticket sales, prizes, and retailer commissions across different counties.
- Conducting research on government revenue and citizen engagement initiatives.
",.csv
Love: Sacred Elixir of the Heart.,1,love-is-the-most-potent-elixir,Love - Sheet1.csv,other,"**Love: Sacred Elixir of the Heart.**

""What's Love Got to Do with It"" by Tina Turner: [link](https://youtu.be/oGpFcHTxjZs?si=WP3P8la7vNCZcaJv)
- *""What's love got to do, got to do with it?""* This line suggests a questioning or sceptical attitude towards the importance of love. It may imply a sense of disillusionment or a contemplation of whether love is truly relevant or necessary.
- *""What's love, but a second-hand emotion?""* Here, the lyrics seem to characterise love as a ""second-hand emotion,"" possibly implying that love is not an authentic or original feeling. It might suggest a perception that love is something borrowed or passed down, rather than a unique and genuine experience.
- *""Who needs a heart when a heart can be broken?""* This line expresses a sense of vulnerability and potential pain associated with love. It raises the question of whether it's worth having a heart, given the risk of it being broken. It reflects a more cautious and protective perspective on emotional involvement.

**The Science of Love:**

Love, a universal human experience, has long been the subject of philosophical musings and artistic expression. But what lies at the heart of this powerful emotion? Science offers a fascinating glimpse into the biological underpinnings of love, revealing the intricate dance of hormones that orchestrates our emotional connections. This article embarks on a journey to unravel the science of love, examining its complexities and contradictions.

At the core of love lies a symphony of hormones that play distinct roles in shaping our emotional experiences. Lust, the initial spark of attraction, is fueled by testosterone and oestrogen, igniting the flame of sexual desire. Attraction, the intensifying bond that draws us closer, involves a cascade of neurotransmitters, including dopamine and norepinephrine, creating a surge of euphoria and excitement. And attachment, the glue that binds us in long-term relationships, is mediated by oxytocin and vasopressin, fostering feelings of trust, security, and deep connection.

While love undeniably brings immense joy and fulfilment, it is not without its potential downsides. The very hormones that contribute to love's positive aspects can also fuel jealousy, possessiveness, and irrational behaviour. This duality mirrors the complexities of addiction, highlighting the delicate balance between love's rewards and its potential pitfalls.

While science has shed light on the biological basis of love, it is important to recognise that love is far more than a simple hormonal equation. Love encompasses a tapestry of social, psychological, and cultural influences, making it a uniquely human experience that transcends scientific formulas.

Love, in all its complexity, is a fundamental aspect of human existence. It is a source of immense joy, connection, and well-being, yet it can also bring challenges and heartache. Understanding the scientific underpinnings of love provides valuable insights into this powerful emotion, but it is only one piece of the puzzle. Love remains a work in progress, a journey of self-discovery and connection that enriches our lives in countless ways.

**Symmetry and Love:**

The concept of symmetry and its connection to human attraction has been a topic of interest in various fields, including psychology and evolutionary biology. Symmetry refers to the balanced arrangement of parts on opposite sides of a central point, line, or axis. In the context of human attractiveness, symmetry is often associated with physical features, such as facial symmetry:
- Facial Symmetry and Attraction: Several studies have suggested that people generally find faces with symmetrical features more attractive. Evolutionary psychologists propose that facial symmetry may be a cue for good health and genetic fitness. Symmetry in the face is thought to indicate a well-developed and stable genetic makeup, as disruptions during development (such as illness or genetic mutations) can lead to asymmetry.
- Evolutionary Perspective: From an evolutionary perspective, the preference for symmetrical traits may be linked to the desire to choose mates with strong genetic characteristics. Evolutionary theory suggests that individuals with symmetrical features may be more capable of withstanding environmental stressors and have a higher likelihood of passing on favourable genetic traits to their offspring.
- Love at First Sight: The idea of ""love at first sight"" often involves a strong initial attraction, and facial symmetry may play a role in this phenomenon. When individuals perceive someone as physically attractive, it can trigger a cascade of neurochemical responses.
- Pheromones emerge as silent messengers: Chemical whispers that transcend conscious perception. Humans, much like animals, release these subtle signals through various bodily fluids, including sweat, urine, semen, breast milk, and vaginal fluid.
- Chemical Responses: Dopamine and Oxytocin: Attraction, including love at first sight, is associated with the release of neurotransmitters like dopamine. Dopamine is linked to pleasure and reward, and its release can create feelings of euphoria and excitement. Additionally, oxytocin, often referred to as the ""love hormone,"" is released during attraction and bonding, promoting emotional connection.
- Serotonin: The neurotransmitter serotonin is also involved in mood regulation and can contribute to the positive feelings associated with attraction.
- Endorphins: The body's natural painkillers, endorphins, are released during moments of attraction and can contribute to a sense of well-being.

In conclusion, symmetry in physical features, particularly facial symmetry, may contribute to initial attraction, potentially influencing the phenomenon of ""love at first sight"". The role of pheromones becomes intertwined with the concept of symmetry. The visual appeal of a symmetrical face may be complemented by the subtle, subconscious signals of pheromones, adding depth to the symphony of attraction.
However the development and sustainability of love involves a wide array of psychological, emotional, and social factors.

**Love at First Sight:**

*Over Half of Americans Believe in Love at First Sight: Younger Americans are more likely to say they believe.* [link](https://news.gallup.com/poll/2017/over-half-americans-believe-love-first-sight.aspx)

[link](https://docs.google.com/spreadsheets/d/1vGj9yYcbtAAz4Lm2aGhoZ858KQyAqaoEtTCvwTMTTt4/edit?usp=sharing) To my spreadsheet (Google sheets) based on the data from the above article from Gallup.

**Visualisation:** From the above spreadsheet.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F13231939%2F0dabf48379727a0b74507672d19d81fa%2FScreenshot%202023-12-03%2019.28.07.png?generation=1701632182011982&alt=media)

**Importance of Eye Contact:**

The idea that *""the eyes are the window to the soul""* is a metaphorical expression that suggests one's true nature or emotions can be revealed through their eyes. While this concept is not scientifically precise, there is some empirical evidence and psychological support for the importance of eye contact and gaze in social interactions, including romantic connections:
- Social Bonding: Eye contact is a fundamental aspect of social communication. It fosters a sense of connection and intimacy between individuals. When people engage in prolonged eye contact, it can contribute to a feeling of being understood and emotionally connected.
- Non-Verbal Communication: Eyes play a crucial role in non-verbal communication. They convey a wide range of emotions, including happiness, sadness, surprise, and attraction. The ability to interpret these subtle cues can enhance social interactions.
- Pupil Dilation: Research suggests that pupil dilation, which is controlled by the autonomic nervous system, can be a subconscious indicator of attraction. Studies have found that pupils tend to dilate when individuals are presented with stimuli they find emotionally or sexually appealing.
- Mutual Gaze: Mutual gaze, where two individuals make eye contact with each other, has been linked to increased feelings of attraction and connection. Mutual gaze can enhance feelings of understanding and intimacy between people.
- Eye Contact and Trust: In the realm of relationships, maintaining eye contact is associated with trust. Couples who make eye contact while communicating may experience higher levels of perceived trust and emotional connection.
- Over-fitting Physical Attributes: While physical attributes, including facial features and symmetry, can contribute to initial attraction, it's essential to recognise that the search for a kindred spirit involves more than just physical appearance. Overemphasising physical attributes may lead to ""overfitting"" or placing too much importance on superficial characteristics.
- Comprehensive Connection: True connection and compatibility involve a combination of physical, emotional, intellectual, and values-based factors. While initial attraction may be sparked by physical appearance or eye contact, a lasting and meaningful relationship requires a deeper understanding of each other's personalities, values, and shared goals.

In summary, there is support for the idea that eyes play a significant role in social interactions, attraction, and emotional connection. However, it's crucial to approach relationships holistically, recognising the importance of various factors beyond physical appearance in fostering a deep and meaningful connection with others.

**Pheromones:**

In the pursuit of a mate, the symphony of pheromones orchestrates a dance that goes beyond the visible and the tangible. The release of these chemical cues becomes a silent dialogue, an ancient form of communication encoded in our biology. It's a primal language that influences our perceptions, preferences, and, perhaps, the magnetic pull between potential partners.

And then, there's the intriguing addition of food, like celery, becoming an unexpected player in the game of love. As celery is consumed, it has the peculiar ability to release a natural pheromone (androstenone), through the pores. This pheromone, though undetectable to the human nose, creates an almost clandestine allure. In the intricate mosaic of love, celery becomes a silent ally, secreting an invisible force that dances beneath the surface of awareness. [link](https://www.allohealth.care/healthfeed/sex-education/celery-benefits-sexually#:~:text=Another%20study%20published%20in%20the,increase%20sexual%20attraction%20in%20humans.)

**The Pure Love of Childhood:**
- Unconditional Love: Children often display a form of love that is unconditional and free from judgement. Their love is not contingent on achievements, appearances, or external factors. It's a pure and accepting form of affection.
- Genuine Expressions: Children express love with sincerity and spontaneity. Their gestures, hugs, and expressions of love are often genuine, reflecting their true emotions in the moment without layers of societal conditioning.
- Trust and Vulnerability: Children inherently trust and are open to love. Their vulnerability allows them to form connections without the cautiousness that often develops with age. They approach relationships with a sense of openness and innocence.
- Inherent Altruism: Young children may exhibit a natural sense of altruism and empathy. Their love extends beyond the self, and they may express concern for others' well-being without expecting anything in return.
- Joyful Play and Connection: Love for children is often intertwined with play, exploration, and shared experiences. They find joy and connection in simple activities and interactions, emphasising the purity of love in its most uncomplicated form.
- Non-Complexity of Relationships: Children often don't carry the complexities that can arise in adult relationships. Their love is straightforward, built on shared moments, companionship, and a desire for connection without the layers of expectations and complications that can emerge over time.
- Parental Love: Parental love, as observed from the child's perspective, is a powerful and foundational form of love. Children see their parents as sources of comfort, protection, and unwavering support, fostering a sense of security and trust in the world.
- Absence of Prejudice: Children often exhibit an absence of prejudice in their early interactions. They may form connections without being influenced by societal biases, embracing diversity and differences with a natural curiosity.
- Learning Through Love: Children learn about the world through the lens of love. Positive, nurturing relationships contribute to their emotional and social development, shaping their understanding of connection, empathy, and kindness.

In conclusion, the purity of a child's view and actions upon the concept of love reflects an innate understanding of the fundamental and universal aspects of human connection. As individuals mature, societal influences, experiences, and complexities may shape their perception of love. Nevertheless, the essence of the unadulterated, unconditional love observed in children remains a *reminder* of the innate human capacity for simplicity, openness, and genuine connection.

**Nurturing Bonds Across Generations: A Tapestry of Love Woven Through Time.**

Love, like a resilient thread, weaves its way through the fabric of generations, connecting hearts and shaping lives. It is a force that transcends time, defying the boundaries of age and circumstance, creating an enduring legacy of affection and care.

The love bestowed upon a child by their parents is a profound force, shaping the very foundations of identity and emotional well-being. It is a love that nurtures, protects, and becomes a guiding light through the labyrinth of life. This parental love, like a nourishing seed, takes root within the child's heart, blossoming into a deep-seated understanding of love, security, and self-worth.

As time unfolds, this parental love takes on a transformative quality. The children, once recipients of such tender care, now find themselves embracing the role of parents. The torch of love passes from one generation to the next, carrying with it the wisdom and warmth accumulated over the years. The echoes of parental love resonate within the hearts of these new parents, guiding them as they navigate the complexities of parenthood.

The capacity to love as a parent is deeply influenced by the love experienced in childhood. The imprints left by parental love shape the way individuals approach parenting, influencing their parenting styles, communication patterns, and emotional responses. Positive childhood experiences instil a sense of security and self-worth, enabling individuals to become nurturing and supportive parents.

Love, like a river that never ceases to flow, extends its course to embrace the next generation – the grandchildren. The grandparents, who once cradled their own children in love, now find joy and fulfilment in showering affection upon their grandchildren. This inter-generational bond is a testament to the enduring power of love, as it transcends the boundaries of age and circumstance.

The continuity of traditions, the stories passed down through generations, and the special bond between grandparents and grandchildren create a rich tapestry of shared experiences. Grandparents become custodians of family history, imparting values, traditions, and life lessons to their grandchildren. This inter-generational exchange fosters a sense of belonging, cultural identity, and a deep appreciation for the family's heritage.

Love, in its myriad forms, is the lifeblood of families, connecting hearts and nurturing generations. It is a force that shapes identities, builds resilience, and creates a sense of belonging. As we traverse the tapestry of life, love remains a constant, a guiding light that illuminates our path and strengthens our bonds.

**Exploring the Journey of Love:**

Love is a complex and multifaceted emotion.  In the journey of love an intricate blend of emotions, biological responses, and cognitive processes flow. In the following textual flowchart I have attempted to convey the stages of love, from initial attraction to potential marriage and continuous growth, shedding light on the hormonal, emotional, and cognitive dimensions that shape the path. A brief explanation of the hormones mentioned, with their associated functions and role in love, precedes the flowchart:
- Dopamine: Pleasure, reward, motivation. Triggered during early connection and building attraction, fostering feelings of pleasure and excitement.
- Norepinephrine: Arousal, excitement, focus. Released during early connection, contributing to heightened arousal and emotional focus.
- Oxytocin: Social bonding, emotional connection. Released during the transition to attachment, fostering deeper emotional bonds and intimacy.
- Vasopressin: Long-term bonding, social behaviour. Contributes to long-term attachment, particularly in shared responsibilities and values.
- Serotonin: Mood regulation, appetite control. Experiences a decrease in the early stages, contributing to obsessive and infatuated feelings.

**A Comprehensive Flowchart.**

**1. Initial Attraction:**
- Visual Stimulus: Encounter an individual with visually appealing characteristics.
- Physical attributes: Facial symmetry, attractiveness, physical fitness.
- Non-verbal cues: Eye contact, smile, body language, confidence.
- Biological Response: Pupil dilation, increased heart rate, and hormonal changes (e.g., dopamine release).
- Physiological reactions: Sweating, flushed cheeks, trembling and the release of pheromones.
- Emotional sensations: Excitement, nervousness, anticipation.

**2. Early Connection:**
- Chemical Responses: Experience a mix of hormones (e.g., dopamine, norepinephrine) associated with attraction.
- Dopamine: Associated with pleasure, reward, and motivation.
- Norepinephrine: Associated with arousal, excitement, and focus.
- Emotional Engagement: Develop a sense of connection and excitement during initial interactions.
- Shared experiences: Engaging conversations, shared interests, common goals.
- Emotional resonance: Feeling understood, supported, and valued.

**3. Building Attraction:**
- Dopamine Pathway: Engage in activities that trigger the brain's reward pathway, fostering a sense of pleasure and excitement.
- Shared activities: Engaging in hobbies, exploring new experiences together.
- Physical intimacy: Romantic gestures, cuddling, hand-holding.
- Decreased Serotonin: Experience a reduction in serotonin, contributing to the obsessive and infatuated feelings common in the early stages.
- Preoccupation: Constant thoughts about the other person.
- Idealisation: Placing the other person on a pedestal, overlooking flaws.

**4. Transition to Attachment:**
- Oxytocin Release: Over time, develop deeper emotional bonds associated with oxytocin release.
- Intimacy: Physical touch, emotional sharing, vulnerability.
- Trust: Feeling safe, secure, and supported.
- Vasopressin Involvement: Vasopressin contributes to long-term attachment and bonding.
- Shared responsibilities: Caring for each other, supporting each other's goals.
- Shared values: Aligning on important life principles and beliefs.

**5. Long-Term Commitment:**
- Establishing Trust: Trust and mutual understanding become foundational.
- Open communication: Honest and transparent interactions.
- Emotional honesty: Expressing feelings openly and without fear of judgement.
- Cognitive Factors: Rational decision-making comes into play, considering shared values, compatibility, and long-term goals.
- Shared vision: Envisioning a future together, aligning on major life decisions.
- Compatibility assessment: Understanding strengths, weaknesses, and complementary traits.

**6. Cohesion of Love:**
- Integration of Components: Lust, attraction, and attachment intertwine, creating a holistic and enduring love.
- Emotional intimacy: Deepening connection beyond the physical.
- Intellectual intimacy: Sharing ideas, thoughts, and dreams.
- Spiritual intimacy: Connecting on a deeper level, aligning on values and beliefs.
- Enduring Connection: Beyond the initial stages, love evolves into a more stable and enduring emotional bond.
- Resilience: Navigating challenges and conflicts together.
- Forgiveness: Letting go of past hurts and offences.
- Unconditional love: Accepting each other's flaws and imperfections.

**7. Relationship Milestones:**
- Shared Experiences: Shared memories, challenges, and triumphs strengthen the bond.
- Milestones: Celebrating significant events together, achieving shared goals.
- Overcoming obstacles: Supporting each other through difficult times.
- Mutual Growth: Both individuals contribute to each other's personal development.
- Encouragement: Supporting each other's dreams and aspirations.
- Inspiration: Motivating each other to become better versions of themselves.

**8. Potential Marriage:**
- Decision-Making: Consideration of shared values, life goals, and compatibility.
- Readiness assessment: Evaluating emotional maturity, financial stability, and commitment level.
- Family considerations: Discussing future plans, including children and extended family.
- Commitment and Partnership: Marriage represents a formal commitment and partnership, solidifying the bond.
- Vows: Public declaration of love, commitment, and partnership.
- Shared responsibilities: Taking on the roles of husband and wife, sharing responsibilities and decisions.

**9. Continuous Growth:**
- Adaptation: Adaptation to changes, challenges, and personal growth as a couple.
- Flexibility: Adjusting to life changes, supporting individual growth
- Compromise: Finding common ground, resolving conflicts respectfully
- Renewal of Love: Continual effort to nurture and renew the emotional connection.
- Date nights: Maintaining romantic spark and connection
- Quality time: Spending dedicated time together, connecting on a deeper level
- Expressions of love: Regularly expressing appreciation, affection, and love


**Flow Chart Conclusion:**

The journey of love is a nuanced exploration involving a symphony of hormones, emotional experiences, and cognitive processes. From the initial spark of attraction to the enduring connection that evolves over time, each stage plays a crucial role in shaping the depth and resilience of love. The integration of lust, attraction, and attachment creates a holistic bond that withstands challenges and evolves into enduring connection.
As relationships progress to marriage, rational decision-making, shared values, and commitment come to the forefront. Continuous growth involves adaptation, compromise, and the renewal of love through shared experiences and expressions of affection. This flowchart provides a glimpse into the intricacies of love, recognising that while hormones play a role, the emotional and cognitive aspects are equally vital.

**The Vibration of Love:**

The Solfeggio Frequencies are often associated with specific numerical values. These frequencies are part of an ancient six-tone scale used in sacred music, including Gregorian chants. Each frequency is believed to have unique spiritual and healing properties. 
The most commonly referenced Solfeggio Frequencies include:
- UT - 396 Hz: Intent: Liberating guilt and fear. Association: Transformative and healing.
- RE - 417 Hz: Intent: Undoing situations and facilitating change. Association: Resolving challenges and facilitating change.
- MI - 528 Hz: Intent: Miracles, DNA repair, and healing. Association: Love, transformation, and healing.
- FA - 639 Hz: Intent: Connecting and relationships. Association: Enhancing communication, understanding, and harmony.
- SOL - 741 Hz: Intent: Awakening intuition and expressing solutions. Association: Problem-solving, intuition, and creative expression.
- LA - 852 Hz: Intent: Spiritual awareness and returning to spiritual order. Association: Opening the mind to spiritual experience and self-discovery.

The concept of the 528 Hz Solfeggio Frequency, often referred to as the ""Love Frequency"" or ""Miracle Tone,"" is rooted in the ancient Solfeggio scale, a musical scale used in Western music and Gregorian chants. The idea is that each frequency in this scale corresponds to specific spiritual or healing properties.

**528 Hz - The Love Frequency:**
- Spiritual Significance: The 528 Hz frequency is associated with the activation of DNA repair and healing. Some proponents believe that listening to music or tones at this frequency can enhance the body's ability to heal and promote a sense of inner peace.
- Healing Properties: Advocates of the 528 Hz frequency claim that it can facilitate healing on physical, emotional, and spiritual levels. The vibrations of this frequency are believed to resonate with the heart and promote a harmonious state of well-being.
- Connection to Love and Harmony: The 528 Hz frequency is often described as the ""Love Frequency"" due to its supposed ability to resonate at the core of our being, connecting the heart, spiritual nature, and divine harmony. It is suggested that exposure to this frequency can enhance feelings of love and compassion.
- Applications: People use the 528 Hz frequency in various ways, including listening to music or tones at this frequency during meditation, relaxation, or healing practices. Some also incorporate it into sound therapy sessions.

While the idea of the Love Frequency and its potential healing properties has gained popularity in certain circles, it's important to note that scientific evidence supporting these claims is limited. The broader field of sound therapy and the impact of specific frequencies on human well-being is an area of ongoing research.

Additionally, the psychological and emotional aspects of love, as discussed in the previous flowchart, involve complex interactions between hormones, neural pathways, and cognitive processes. While the 528 Hz frequency might contribute to a sense of relaxation and well-being for some individuals, its direct connection to the intricate journey of love, as discussed in the context of relationships, is not firmly established through scientific evidence.

In conclusion, the 528 Hz Solfeggio Frequency, with its association to the Love Frequency, adds an interesting layer to the exploration of love, incorporating spiritual and vibrational aspects. However, it's crucial to approach such concepts with an open mind, recognising the interplay of various factors in our understanding of love and well-being.

 *""Quantum Integrative Healing Series""*, **Harvard Dataverse.** Including, *""Solfeggio Frequencies Dimensions of Healing Sounds"".* [link](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/W5VEGX) 

**Anthropomorphism in Human Experience: A Tapestry of Love:**
- Anthropomorphism: The attribution of human traits to non-human entities, is a deeply woven thread in the tapestry of human experience. It's a universal language, transcending cultural and linguistic boundaries, that allows us to connect with the world around us on a deeper level.
- Real Objects: A Love Affair with the Tangible. We often imbue inanimate objects with human-like qualities, forging a bond of familiarity and affection. A car, once a mere mechanical marvel, becomes a trusted companion, a symbol of freedom and adventure. A tree, silent sentinel of the seasons, takes on an aura of wisdom and resilience, a testament to the enduring power of nature. These inanimate objects become extensions of ourselves, embodiments of our hopes, dreams, and aspirations.
- Animals: A Symphony of Shared Emotions. Animals, our fellow creatures on this planet, are perhaps the most frequent recipients of our anthropomorphic affections. We see ourselves reflected in their eyes, their playful antics, their unwavering loyalty. We attribute human emotions to their actions, interpreting their playful barks as laughter, their mournful whimpers as tears. This shared emotional landscape deepens our connection with animals, fostering a love that transcends the barriers of species.
- Technology: A Digital Dance of Love. In the age of artificial intelligence, our anthropomorphic tendencies extend to the realm of technology. We converse with virtual assistants, their disembodied voices weaving into the fabric of our daily lives. We form bonds with our smartphones, their glowing screens becoming windows into our personal worlds. These digital companions, while devoid of human sentience, evoke feelings of love and affection, demonstrating our innate desire to connect with something beyond ourselves.
- Non-Real Entities: A Love that Transcends Reality. Our anthropomorphic imagination extends beyond the tangible, reaching into the realm of the fictitious and the spiritual. We create stories populated by anthropomorphic deities, mythical creatures, and personified abstractions. These characters, though products of our imagination, become objects of love and adoration, embodying our deepest fears, aspirations, and the very essence of human existence.
- Art and Media: A Canvas of Love's Expressions. Artists and storytellers have long used anthropomorphism to create relatable characters and narratives, breathing life into inanimate objects, animals, and even abstract concepts. From the talking animals of Aesop's fables to the personified forces of nature in Greek mythology, anthropomorphism has been a powerful tool for conveying human emotions and experiences through art and media.
- Psychological Comfort: A Love that Soothes the Soul. Anthropomorphism serves as a psychological crutch, helping us navigate the complexities of the world around us. By attributing human traits to the unknown, we make it relatable, less daunting. A storm becomes an angry giant, a dark forest a mysterious labyrinth, each imbued with human emotions that we can understand and empathise with. This anthropomorphic lens provides a sense of comfort and familiarity, easing our anxieties and fostering a sense of connection to the world around us.
- Cultural Variations: A Love that Takes Many Forms. The extent and nature of anthropomorphism vary across cultures, shaped by diverse belief systems, traditions, and societal norms. In some cultures, animals are revered as deities or spirit guides, while in others, technology is personified as a benevolent or malevolent force. These cultural variations reflect the unique ways in which different societies perceive and interact with the world around them.
- Limitations and Misinterpretations: When Love Goes Awry. While anthropomorphism is a natural part of human cognition, it's important to recognise its limitations. When applied too rigidly, it can lead to misinterpretations and misunderstandings. Anthropomorphising technology, for instance, can blind us to its true nature as a tool, leading to unrealistic expectations or even emotional attachments. Similarly, attributing human emotions to animals can result in misinterpreting their behaviour, potentially compromising their welfare.
- Ethical Considerations: A Love that Demands Responsibility. Anthropomorphising nonhuman entities raises ethical questions, particularly when it comes to animals. Attributing human emotions to animals might influence decisions related to their treatment and welfare. We must be mindful of the potential consequences of our anthropomorphic projections, ensuring that our love for animals does not lead to their exploitation or mistreatment.

**Overall Conclusion:**

In the vast tapestry of human experience, love stands as an intricate thread, weaving its way through the complexities of emotions, biology, and relationships. Our exploration into the realms of love has taken us on a journey through the lenses of symmetry, attraction, chemical responses, and the very nature of human connection.

At its genesis, love often finds its roots in the symmetrical beauty that captivates our gaze. The allure of facial symmetry, the dance of proportions, and the harmony in the visual aesthetics of a potential partner awaken a primal response within us. This innate inclination towards symmetry, both in nature and in human attraction, underscores the deep-seated biological foundations that shape our perceptions of beauty.

The phenomenon of ""love at first sight,"" a concept often romanticised in literature and film, hints at the instantaneous chemical ballet that occurs when two individuals connect. From the dilation of pupils to the release of hormones such as dopamine, norepinephrine, and serotonin, the dance of chemicals orchestrates a symphony of sensations - excitement, anticipation, and the irresistible pull towards the object of attraction.
 
Enter the subtle influence of pheromones, the invisible currents of attraction, guided by these chemical messengers, add an element of mystery to the already complex landscape of human connection.
The role of pheromones and the subtle influence of food form a subplot. They are the unseen hands that shape the undercurrents of attraction, adding an element of intrigue to the universal story of love.

As we journey further into the realms of love, the anthropomorphism of emotions and frequencies comes into play. From the ethereal notes of the 528 Hz Solfeggio Frequency, known as the ""Love Frequency,"" to the anthropomorphism of abstract concepts like love and attraction, we find ourselves assigning human-like qualities to the intangible. This practice extends beyond the realms of reality, touching gods, animals, and even the algorithms of artificial intelligence.

In the innocence of childhood, love emerges as a pure, unfiltered expression. Children, unburdened by societal expectations, engage in love with a sincerity and openness that often diminishes with age. Their love is unconditional, untainted by the complexities that adulthood introduces.

However, as love matures, it intertwines with the intricacies of adult relationships. The threefold categorisation by Dr. Helen Fisher - lust, attraction, and attachment - unveils the multifaceted nature of romantic love. Lust, driven by desire, gives way to the exhilaration of attraction, guided by the dopamine pathways that reward us for the time spent with loved ones. Eventually, attachment solidifies long-term connections, mediated by hormones like oxytocin and vasopressin - [link](https://sitn.hms.harvard.edu/flash/2017/love-actually-science-behind-lust-attraction-companionship/). 

In the dance of love, the anthropomorphism of artificial intelligence becomes an intriguing subplot. The bonds formed with technology, the companionship sought in virtual assistants, and the emotional responses triggered by algorithms beg the question of whether humanity can extend its capacity for love beyond the organic.

In the context of relationships, the flowchart of love takes shape. From initial attraction to building connection, the ebb and flow of dopamine, serotonin, and oxytocin guide the stages. Shared experiences, physical intimacy, and the reduction of serotonin create a canvas upon which the masterpiece of love is painted.
As relationships progress towards long-term commitment, trust and mutual understanding lay the foundation. The integration of lust, attraction, and attachment forms a cohesive bond that extends beyond the initial stages. Shared milestones, mutual growth, and potential marriage become the waypoints on the roadmap of love.

Amidst the science and symphony of love, the concept of the 528 Hz Solfeggio Frequency adds a metaphysical note. Its association with healing, miracles, and the very essence of love introduces a harmonic layer to our exploration.

In essence, love, as we've unravelled it, is a grand tapestry woven with threads of biology, symmetry, emotion, and spirituality. From the simplicity of a child's affection to the complexities of adult relationships, from the chemistry of attraction to the frequencies of the heart, love emerges as a force that transcends boundaries, resonating at the core of the human experience.


Patrick Ford 🌿

-----------------------------------------------------------------------------------------------------------------

*Immunity and the Connections of Mental Well Being. The Power of Food to Strengthen the Immune System, to Protect Us. Also on Kaggle* - [link](https://www.kaggle.com/datasets/patricklford/immunity-and-the-connections-of-mental-well-being).

*Scottish Coronary Heart Disease 2012-2021
Is Happiness important for Heart Health ? Also on Kaggle* - [link](https://www.kaggle.com/datasets/patricklford/heart-disease-mortality-by-health-board)

-----------------------------------------------------------------------------------------------------------------

The following lentil soup recipe from Zeno* of Citium, the founder of the Stoic school of philosophy, is very flavourful: 

Ingredients:
- 1 lb. lentils.
- 8 cups of broth. 
- 1 large minced leek.
- 1 carrot, sliced.
- 1 stalk (not stick, whole head) of celery, sliced.
- 1 small onion, sliced.
- Optional, 1 clove of garlic.
- 2 tablespoons of vinegar.
- 1 teaspoon honey.
- Olive oil.
- Salt and pepper to taste.
- 12 coriander seeds.

Instructions:
- Rinse the lentils thoroughly, then put them into a pot with the broth to boil.
- Reduce heat and simmer for one hour.
- Skim the top, add the vegetables, and simmer until cooked through, about 30 minutes.
- If the soup seems too watery, pass some of the lentils through a sieve.
- Now add the vinegar and honey.
- Pour into serving bowls and add a good dollop of olive oil (about 2 tablespoons per serving), sprinkling on coriander seeds and salt and pepper to taste.

**Zeno's Dichotomy Paradox: Features in my project on Infinity, also on Kaggle* - [link](https://www.kaggle.com/datasets/patricklford/infinity).

",.csv
Lumpy Skin Disease Dataset,1,lumpy-skin-disease-dataset,Lumpy skin disease data.csv,Attribution 4.0 International (CC BY 4.0),"### Context

Assessing machine learning techniques in forecasting Lumpy Skin Disease occurrence based on meteorological and geospatial features - dataset


### Acknowledgements

Afshari Safavi, Ehsanallah (2021), “Lumpy Skin disease dataset”, Mendeley Data, V1, doi: 10.17632/7pyhbzb2n9.1

",.csv
Lung Cancer,1,lung-cancer,survey lung cancer.csv,CC0-1.0,"### The effectiveness of cancer prediction system helps the people to know their cancer risk with low cost and it also helps the people to take the appropriate decision based on their cancer risk status. The data is collected from the website online lung cancer prediction system .
Total no. of attributes:16
No .of instances:284
Attribute information:
1.	Gender: M(male), F(female)
2.	Age: Age of the patient
3.	Smoking:  YES=2 , NO=1.
4.	Yellow fingers: YES=2 , NO=1.
5.	Anxiety: YES=2 , NO=1.
6.	Peer_pressure: YES=2 , NO=1.
7.	Chronic Disease: YES=2 , NO=1.
8.	Fatigue: YES=2 , NO=1.
9.	Allergy: YES=2 , NO=1.
10.	Wheezing: YES=2 , NO=1.
11.	Alcohol: YES=2 , NO=1.
12.	Coughing: YES=2 , NO=1.
13.	Shortness of Breath: YES=2 , NO=1.
14.	Swallowing Difficulty: YES=2 , NO=1.
15.	Chest pain: YES=2 , NO=1.
16.	Lung Cancer: YES , NO.
",.csv
Lung Cancer Detection,1,lung-cancer-detection,survey lung cancer.csv,CC0-1.0,"About Dataset
The effectiveness of the cancer prediction system helps people to know their cancer risk wi a low cost and it also helps the people to take the appropriate decision based on their cancer risk status. The data is collected from the website online lung cancer prediction system.",.csv
Lymphoma,1,lymphoma,Lymphoma.csv,other,"B-cell Lymphoma is a microarray dataset consists of 3 class of types of cancer

DLBCL (Diffuse Large B-Cell Lymphoma): This is considered an aggressive type of lymphoma. However, it is also one of the most common types and often responds well to chemotherapy. With appropriate treatment, a significant percentage of patients with DLBCL can achieve remission or cure.

FL (Follicular Lymphoma): Follicular lymphoma is usually indolent or slow-growing. While it is not considered curable with current treatments, many patients can live for many years with this condition. Treatments can control the disease, and some individuals may have long periods of remission .

CLL (Chronic Lymphocytic Leukemia): CLL is a type of leukemia rather than a lymphoma, but it is closely related and affects similar white blood cells. Survival rates for CLL can vary widely, and some patients may not require immediate treatment upon diagnosis. There are various treatment options available, and the disease progression can be slow in many cases.",.csv
Lyrics,1,lyrics,Songs.csv,CC0-1.0,"This dataset containing the following features: 
- Artist of the song 
- Title of the song
- Lyrics of the song

Created to be used for NLP. 

✨✨  Cheers!✨ ✨ ",.csv
MAGIC Gamma Telescope,1,magic-gamma-telescope,magic04.csv,MIT,"```
The data are MC generated (see below) to simulate registration of high energy gamma particles in a ground-based atmospheric Cherenkov gamma telescope using the imaging technique. Cherenkov gamma telescope observes high energy gamma rays, taking advantage of the radiation emitted by charged particles produced inside the electromagnetic showers initiated by the gammas, and developing in the atmosphere. This Cherenkov radiation (of visible to UV wavelengths) leaks through the atmosphere and gets recorded in the detector, allowing reconstruction of the shower parameters. The available information consists of pulses left by the incoming Cherenkov photons on the photomultiplier tubes, arranged in a plane, the camera. Depending on the energy of the primary gamma, a total of few hundreds to some 10000 Cherenkov photons get collected, in patterns (called the shower image), allowing to discriminate statistically those caused by primary gammas (signal) from the images of hadronic showers initiated by cosmic rays in the upper atmosphere (background).

Typically, the image of a shower after some pre-processing is an elongated cluster. Its long axis is oriented towards the camera center if the shower axis is parallel to the telescope's optical axis, i.e. if the telescope axis is directed towards a point source. A principal component analysis is performed in the camera plane, which results in a correlation axis and defines an ellipse. If the depositions were distributed as a bivariate Gaussian, this would be an equidensity ellipse. The characteristic parameters of this ellipse (often called Hillas parameters) are among the image parameters that can be used for discrimination. The energy depositions are typically asymmetric along the major axis, and this asymmetry can also be used in discrimination. There are, in addition, further discriminating characteristics, like the extent of the cluster in the image plane, or the total sum of depositions.

The data set was generated by a Monte Carlo program, Corsika, described in:
    D. Heck et al., CORSIKA, A Monte Carlo code to simulate extensive air showers,
    Forschungszentrum Karlsruhe FZKA 6019 (1998).
http://rexa.info/paper?id=ac6e674e9af20979b23d3ed4521f1570765e8d68

The program was run with parameters allowing to observe events with energies down to below 50 GeV

```

# Additional Variable Information

```
    1.  fLength:  continuous  # major axis of ellipse [mm]
    2.  fWidth:   continuous  # minor axis of ellipse [mm] 
    3.  fSize:    continuous  # 10-log of sum of content of all pixels [in #phot]
    4.  fConc:    continuous  # ratio of sum of two highest pixels over fSize  [ratio]
    5.  fConc1:   continuous  # ratio of highest pixel over fSize  [ratio]
    6.  fAsym:    continuous  # distance from highest pixel to center, projected onto major axis [mm]
    7.  fM3Long:  continuous  # 3rd root of third moment along major axis  [mm] 
    8.  fM3Trans: continuous  # 3rd root of third moment along minor axis  [mm]
    9.  fAlpha:   continuous  # angle of major axis with vector to origin [deg]
   10.  fDist:    continuous  # distance from origin to center of ellipse [mm]
   11.  class:    g,h         # gamma (signal), hadron (background)

   g = gamma (signal):     12332
   h = hadron (background): 6688

```

```
   For technical reasons, the number of h events is underestimated. In the real data, the h class represents the majority of the events.

   The simple classification accuracy is not meaningful for this data, since classifying a background event as signal is worse than classifying a signal event as background. For comparison of different classifiers an ROC curve has to be used. The relevant points on this curve are those, where the probability of accepting a background event as signal is below one of the following thresholds: 0.01, 0.02, 0.05, 0.1, 0.2 depending on the required quality of the sample of the accepted events for different experiments.
```
",.csv
MESSIDOR-2 DR Grades,1,messidor2-dr-grades,messidor_data.csv,CC0-1.0,"### Context

These data represent Diabetic Retinopathy grades (as well as DME and Gradability) for the publicaly available MESSIDOR-2 fundus image database. (http://latim.univ-brest.fr/indexfce0.html)

### Content

The grades were adjudicated by a panel of three Retina Specialists.

### Acknowledgements

References:

[1] Decencière  E, Etienne  D, Xiwei  Z,  et al.  Feedback on a publicly distributed image database: the Messidor database.  Image Anal Stereol. 2014;33(3):231-234. doi:10.5566/ias.1155

[2] Krause, J. et al. Grader variability and the importance of reference standards for evaluating machine learning models for diabetic retinopathy. Ophthalmology (2018). doi:10.1016/j.ophtha.2018.01.034

[3] Gulshan, V. et al. Development and Validation of a Deep Learning Algorithm for Detection of Diabetic Retinopathy in Retinal Fundus Photographs. JAMA 316, 2402–2410 (2016)
                                                                                                                                                                                                          


### Inspiration

Your data will be in front of the world's largest data science community. What questions do you want to see answered?",.csv
META Stock Prices🤖 || 2020 to 2024,1,meta-stock-prices-2020-to-2024,META.csv,Apache 2.0,"# **Description:**

This dataset contains historical stock price data for Meta Platforms Inc. (META) from [Jan/01/2020] to [May/01/2024]. The dataset includes daily opening, high, low, and closing prices, as well as adjusted closing prices and volume.

## **About Columns:**

- Date:
- Open:
- High:
- Low:
- Close:
- Adj Close:
- Volume:

### **Used by:**

- Predicting stock prices
- Building stock forecasting models
- Analyzing stock market trends
- Backtesting investment strategies
- Comparing machine learning models for stock prediction

   This dataset is perfect for data scientists, analytics, and students looking to practice their skills in:

- Time series analysis
- Stock market analysis
- Predictive modeling
- Machine learning

**Get started:** Download the dataset and start exploring!

",.csv
MONEYCONTROL NEWS,1,moneycontrol-news,combined.csv,CC0-1.0,"The dataset comprises headlines scraped from Moneycontrol, a financial news website. Each entry represents a single news headline. The dataset typically includes features such as the headline text. It is commonly stored in CSV format and may contain additional information such as timestamps or URLs. Potential uses include text analysis, machine learning, and data visualization. Limitations include potential data quality issues and legal considerations related to web scraping.",.csv
"MOVIES DATASET FOR FEATURE EXTRACION ,PREDICTION",1,movies-dataset-for-feature-extracion-prediction,movies.csv,CC0-1.0,"### Context

The data is succesfully scrapped from imdb top netflix movies and tvshows.This dataset need clever programming knowledge for feature extraction also you can build a RECOMMENDATION system either GENRE prediction model 

### Content

The dataset contain more than 9 columns desrcibe the data pattern .I scrap the data from imdb web site using beautifulsoup.it takes a day to learn i am begginer even to data science but i learned quickly web scrapping with advanced python.Through this process i gained lot and also i suggest the data featuring part of this project takes time   


### Acknowledgements

Definitely the data collection is possible only with  help of online  stackoverflow and kaggle data science community 


### Inspiration

Create genre prediction model?, ",.csv
MTN stock price dataset,1,mtn-gh-stock-price-dataset,Daily Shares  ETFs 2023.csv,CC0-1.0,The dataset used in this analysis contains historical stock price data for MTG-Ghana extracted from the Ghana Stock Exchange (GSE). The time range of the data spans from 2018 to 2023.,.csv
Machine Failure Prediction Cleaned,1,machine-failure-cleaned,machine_failure_cleaned.csv,other,This is a cleaned version of the [Machine Failure Prediction Dataset](https://www.kaggle.com/datasets/dineshmanikanta/machine-failure-predictions/data). It has been cleaned using outlier removal and feature selection.,.csv
Machine Learning Engineer Salary in 2024,1,machine-learning-engineer-salary-in-2024,salaries.csv,Apache 2.0,"## **Description of the features in dataset:**

- **work_year:** The year in which the salary data was collected (e.g., 2024).
- **experience_level:** The level of experience of the employee (e.g., MI for Mid-Level).
- **employment_type:** The type of employment (e.g., FT for Full-Time).
- **job_title:** The title of the job (e.g., Data Scientist).
- **salary:** The salary amount.
- **salary_currency:** The currency in which the salary is denominated (e.g., USD for US Dollars).
- **salary_in_usd:** The salary amount converted to US Dollars.
- **employee_residence:** The country of residence of the employee (e.g., AU for Australia).
- **remote_ratio:** The ratio indicating the level of remote work (0 for no remote work).
- **company_location:** The location of the company (e.g., AU for Australia).
- **company_size:** The size of the company (e.g., S for Small).",.csv
Machine Predictive Maintenance Classification,1,machine-predictive-maintenance-classification,predictive_maintenance.csv,CC0-1.0,"### Machine Predictive Maintenance Classification Dataset 

Since real predictive maintenance datasets are generally difficult to obtain and in particular difficult to publish, we present and provide a synthetic dataset that reflects real predictive maintenance encountered in the industry to the best of our knowledge.

The dataset consists of 10 000 data points stored as rows with 14 features in columns
- UID: unique identifier ranging from 1 to 10000
- productID: consisting of a letter L, M, or H for low (50% of all products), medium (30%), and high (20%) as product quality variants and a variant-specific serial number
- air temperature [K]: generated using a random walk process later normalized to a standard deviation of 2 K around 300 K
- process temperature [K]: generated using a random walk process normalized to a standard deviation of 1 K, added to the air temperature plus 10 K.
- rotational speed [rpm]: calculated from powepower of 2860 W, overlaid with a normally distributed noise
- torque [Nm]: torque values are normally distributed around 40 Nm with an Ïƒ = 10 Nm and no negative values.
- tool wear [min]: The quality variants H/M/L add 5/3/2 minutes of tool wear to the used tool in the process. and a
'machine failure' label that indicates, whether the machine has failed in this particular data point for any of the following failure modes are true.

## Important : There are two Targets - Do not make the mistake of using one of them as feature, as it will lead to leakage. 
- Target : Failure or Not 
- Failure Type : Type of Failure 

### Acknowledgements

UCI : https://archive.ics.uci.edu/ml/datasets/AI4I+2020+Predictive+Maintenance+Dataset",.csv
Makeup Shades Dataset,1,makeup-shades-dataset,shades.csv,CC0-1.0,"These data were collected to learn more about shade availability from Fenty Beauty and other brands in the US and around the world. The data were used in The Pudding essay Beauty Brawl published in June 2018. 

A list of beauty brands in the US, Nigeria, India, and Japan was collected that were considered by several sources to be ""best sellers"" in their home countries. The original author visited each brand's website during May 2018, found their liquid foundation line that (at the time of our sampling) had the largest number of shades available, and recorded the hex color values for each of the colored swatches shown for the product. Then, using Adobe Photoshop, they extracted the lightness value of each color (using the CIE Lab color model). Sources consulted to decide what brands/products to sample:

US bestseller lists: POPSUGAR, Amazon, StyleCaster, Refinery29, Statista, BEAUTY/crew
Articles recommending beauty products to people of color: VIBE, Byrdie, The FADER, Allure, Glamour, Fast Company, THE CUT, Bustle, HuffPost, more.com, BuzzFeed, Refinery29
Articles recommending Nigerian beauty products: BeautyInLagos, Beauty Geek, Lux Afrique, Zikel Cosmetics, Pulse.ng Pulse.ng again, Information Nigeria Women, Girly Essentials, Winnie The Make-Up Artist, Jumia Travel

Group Column Definition: 
• 0: Fenty Beauty's PRO FILT'R Foundation Only
• 1: Make Up For Ever's Ultra HD Foundation Only
• 2: US Best Sellers
• 3: BIPOC-recommended Brands with BIPOC Founders
• 4: BIPOC-recommended Brands with White Founders
• 5: Nigerian Best Sellers
• 6: Japanese Best Sellers
• 7: Indian Best Sellers
",.csv
Malaria in Africa,1,malaria-in-africa,DatasetAfricaMalaria.csv,other,"### Context

Africa, the world's second-largest continent, a continent with a wide array of vibrant cultures each with its own deep history, continent number 2 of largest population, and the continent is home to wonderful wildlife you can spot when you go on safari!
Let's focus on Africa in this dataset.

Malaria is a common disease in Africa. The disease is transmitted to humans through infected mosquito bites. Although you can take preventive measures against malaria, it can be life-threatening.  This dataset includes the malaria cases in African countries, the incidence at risk, and data on preventive treatments against malaria.

### Content

This dataset includes data on all African countries from 2007 till 2017.  Each country has a unique ISO-3 country code, and the dataset includes the latitude and longitude point of each country as well. The dataset includes the cases of malaria that have been reported in each country and each year, as well as data on preventive measures that have been taken to prevent malaria.


### Acknowledgements

The data on the incidence of malaria, malaria cases reported, and preventive treatments against malaria have been retrieved from the world bank open data source.


### Inspiration
Each country has a unique ISO-3 country code. You can use the ISO-3 code to create choropleth maps and in the geospatial analysis. In addition, the dataset includes latitude and longitude points for each country.

Drinking water safety and sanitation include a risk factor for malaria. Can improved drinking water facilities and preventive measures decrease the risk of malaria infection?

Check out my notebook submission, feel free to copy the kernel for your analysis: 
https://www.kaggle.com/lydia70/notebook-malaria-in-africa
The notebook submission includes geospatial analysis with plotly.",.csv
Malaria: Adding Danger,1,malaria-adding-danger,malaria-deaths-comparisons new.csv,CC0-1.0,"this graph was created in PowerBi,Loocker and R : 

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F8fa33d2b35416ee7171f4d536c611c86%2Fgraph3.png?generation=1711916295042507&alt=media)


![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fff4569359721216f766b5363785d9d91%2Fgraph1.jpg?generation=1711916304805607&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F24f2ee06a692dc2d794f89c5ebaf07c2%2Fgraph2.jpg?generation=1711916313123909&alt=media)


Malaria, a formidable disease transmitted through the bite of infected mosquitoes, continues to pose a significant threat to global public health. This insidious illness, caused by the Plasmodium parasite, infiltrates the human bloodstream via the saliva of Anopheles mosquitoes. Once inside the body, the parasite finds its way to the liver, where it multiplies, initiating a vicious cycle of infection and destruction.

Plasmodium parasites exhibit a remarkable ability to evade the body's immune defenses, perpetuating their life cycle by invading and replicating within red blood cells. As these cells rupture, releasing more parasites into the bloodstream, the infected individual experiences recurrent bouts of fever, accompanied by debilitating symptoms such as severe chills and excruciating pain. In severe cases, malaria can progress rapidly, leading to coma and ultimately death.

Among the various species of Plasmodium, Plasmodium falciparum stands out as the most lethal to humans, responsible for the majority of malaria-related fatalities worldwide. Despite significant advancements in medical science, malaria remains a leading cause of mortality, particularly among vulnerable populations such as children.

Throughout the 2010s, the toll of malaria-related deaths exceeded half a million annually, with children bearing the brunt of this staggering burden. This disease not only inflicts immense suffering but also undermines socioeconomic development in endemic regions, perpetuating cycles of poverty and illness.

Efforts to combat malaria encompass a multifaceted approach, ranging from vector control measures, such as insecticide-treated bed nets and indoor residual spraying, to the development of antimalarial drugs and vaccines. However, the effectiveness of these interventions is contingent upon several factors, including access to healthcare, socioeconomic disparities, and the emergence of drug-resistant parasite strains.

To gain a deeper understanding of the epidemiology and impact of malaria, it is essential to examine comprehensive datasets provided by organizations such as the World Health Organization (WHO) and the Institute for Health Metrics and Evaluation (IHME). These data sources offer valuable insights into the geographical distribution of malaria cases, mortality trends over time, and disparities in healthcare access.

Discrepancies in reported malaria mortality figures between organizations underscore the complexity of accurately assessing the global burden of this disease. While WHO estimates provide a baseline for understanding the scale of malaria-related deaths, IHME projections often yield higher figures, reflecting variations in methodology and data sources.

Despite the formidable challenges posed by malaria, there is cause for optimism as concerted efforts continue to yield promising results. Innovative approaches, such as community-based health initiatives and public-private partnerships, have demonstrated efficacy in reducing malaria transmission and improving access to treatment.

Furthermore, advancements in molecular biology and genetic engineering hold the potential to revolutionize malaria control strategies, paving the way for the development of genetically modified mosquitoes resistant to the Plasmodium parasite or novel antimalarial agents targeting essential pathways in parasite metabolism.

In conclusion, malaria remains a formidable adversary, exacting a heavy toll on human health and socioeconomic development. However, through sustained investment in research, healthcare infrastructure, and collaborative partnerships, we can aspire to eradicate this ancient scourge once and for all. By uniting our efforts on a global scale, we can envision a future where malaria no longer poses a threat to the health and well-being of communities worldwide.

",.csv
Malaysia Property for Sale,1,malaysia-property-for-sale,malaysia_property_for_sale.csv,Apache 2.0,"Real estate dataset contains property for sale/invest in Malaysia. Dataset in csv format, which contains 7 variables: Location, list price, unit price, number of bedroom, number of bathroom, size (in square meter) and type. ",.csv
Malaysia_Resale_Carlist,1,malaysia-resale-carlist,resale_car.csv,Apache 2.0,"Malaysia resale car prices are collected via web scraping. Data includes the description of the vehicle, monthly installment, list price, car model, mileage,  gear type, and location. Useful for analyzing market trends and estimating car values.",.csv
Male and female Voice data ,1,male-and-female-voice-data-for-gender-recognation,Male and female Voice data creat by al arman ovi .csv,other,"**About Datasets:**

This dataset contains features extracted from voice recordings of male and female speakers using the Python Librosa library. The recordings consist of 3682 samples from male voices and 2311 samples from female voices, totaling 5993 samples. Each sample is represented by a set of features derived from frequency analysis using the Librosa library.

**Features:**

1. mean_freq: The average frequency of the voice signal.
2.sd_freq: The standard deviation of the frequency distribution.
3.median_freq: The median frequency of the voice signal.
4.q25_freq: The 25th percentile of the frequency distribution.
5.q75_freq: The 75th percentile of the frequency distribution.
6.iqr_freq: The interquartile range of the frequency distribution.
7.skewness: Skewness of the frequency distribution.
8.kurtosis_val: Kurtosis of the frequency distribution.
9.spectral_flatness: Flatness of the power spectrum.
10.tempogram: Temporal rhythm analysis feature.
11.mode_freq: The mode frequency of the voice signal.
12.centroid_freq: Centroid frequency of the voice signal.
13.peak_freq: The peak frequency of the voice signal.
14.mean_fun: Mean fundamental frequency of the voice signal.
15.min_fun: Minimum fundamental frequency of the voice signal.
16.max_fun: Maximum fundamental frequency of the voice signal.
17.mean_dom: Mean dominant frequency of the voice signal.
18.min_dom: Minimum dominant frequency of the voice signal.
19.max_dom: Maximum dominant frequency of the voice signal.
20.fund_freq: Fundamental frequency of the voice signal.
21.mod_index: Modulation index of the voice signal.
22.label: The gender label of the voice sample (male, female).


**Purpose:**

This dataset is suitable for various machine learning tasks, such as gender classification based on voice characteristics, analysis of frequency features in male and female voices, and exploring differences in vocal patterns between genders.",.csv
Mall Customer Segmentation Data,1,customer-segmentation-tutorial-in-python,Mall_Customers.csv,other,"### Context

This data set is created only for the learning purpose of the customer segmentation concepts , also known as market basket analysis . I will demonstrate this by using unsupervised ML technique (KMeans Clustering Algorithm) in the simplest form.   


### Content

You are owing a supermarket mall and through membership cards , you have some basic data about your customers like Customer ID, age, gender, annual income and spending score. 
Spending Score is something you assign to the customer based on your defined parameters like customer behavior and purchasing data. 

**Problem Statement**
You own the mall and want to understand the customers like who can be easily converge [Target Customers] so that the sense can be given to marketing team and plan the strategy accordingly. 


### Acknowledgements

From Udemy's Machine Learning A-Z course.

I am new to Data science field and want to share my knowledge to others

https://github.com/SteffiPeTaffy/machineLearningAZ/blob/master/Machine%20Learning%20A-Z%20Template%20Folder/Part%204%20-%20Clustering/Section%2025%20-%20Hierarchical%20Clustering/Mall_Customers.csv

### Inspiration

By the end of this case study , you would be able to answer below questions. 
1- How to achieve customer segmentation using machine learning algorithm (KMeans Clustering) in Python in simplest way.
2- Who are your target customers with whom you can start marketing strategy [easy to converse]
3- How the marketing strategy works in real world    ",.csv
Malware Analysis Datasets: API Call Sequences,1,malware-analysis-datasets-api-call-sequences,dynamic_api_call_sequence_per_malware_100_0_306.csv,Attribution 4.0 International (CC BY 4.0),"This dataset is part of our research on malware detection and classification using Deep Learning. It contains 42,797 malware API call sequences and 1,079 goodware API call sequences. Each API call sequence is composed of the first 100 non-repeated consecutive API calls associated with the parent process, extracted from the 'calls' elements of Cuckoo Sandbox reports.

For more information or citation, please refer to our research paper:

""Oliveira, Angelo; Sassi, Renato José (2019): Behavioral Malware Detection Using Deep Graph Convolutional Neural Networks. TechRxiv. Preprint."" at https://doi.org/10.36227/techrxiv.10043099.v1

**FEATURES**

Column name: hash
Description: MD5 hash of the example
Type: 32 bytes string

Column name: t_0 ... t_99
Description: API call
Type: Integer (0-306)

Column name: malware
Description: Class
Type: Integer: 0 (Goodware) or 1 (Malware)

**ACKNOWLEDGMENTS**

We would like to thank: Cuckoo Sandbox for developing such an amazing dynamic analysis environment!
VirusShare! Because sharing is caring!
Universidade Nove de Julho for supporting this research.
Coordination for the Improvement of Higher Education Personnel (CAPES) for supporting this research.

Please feel free to contact me!",.csv
Malware Detection from Memory Dump,1,malware-detection-from-memory-dump,MalwareMemoryDump.csv,GNU Lesser General Public License 3.0,"Obfuscated malware refers to a type of malicious software that deliberately conceals itself to evade detection and removal. This form of malware can be identified by examining the memory dump of the infected device. The obfuscated malware dataset has been specifically designed to evaluate the effectiveness of methods used to detect obfuscated malware through memory analysis. The dataset aims to replicate real-world scenarios by including prevalent types of malware such as Spyware, Ransomware, and Trojan Horse malware. It provides a well-balanced collection of samples that can be utilized to test the efficiency of obfuscated malware detection systems. To ensure accuracy, the dataset utilizes debug mode during the memory dump process, preventing any indications of the dumping procedure from appearing in the memory dumps. This approach accurately represents the typical software and processes an average user would have running during a malware attack.",.csv
Mammographic Mass Data Set,1,mammographic-mass-data-set,Cleaned_data.csv,CC-BY-NC-SA-4.0,"Mammography is the most effective method for breast cancer screening 
available today. However, the low positive predictive value of breast 
biopsy resulting from mammogram interpretation leads to approximately 
70% unnecessary biopsies with benign outcomes. To reduce the high 
number of unnecessary breast biopsies, several computer-aided diagnosis 
(CAD) systems have been proposed in the last years.These systems 
help physicians in their decision to perform a breast biopsy on a suspicious 
lesion seen in a mammogram or to perform a short term follow-up 
examination instead. 
This data set can be used to predict the severity (benign or malignant) 
of a mammographic mass lesion from BI-RADS attributes and the patient's age. 
It contains a BI-RADS assessment, the patient's age and three BI-RADS attributes 
together with the ground truth (the severity field) for 516 benign and 
445 malignant masses that have been identified on full field digital mammograms 
collected at the Institute of Radiology of the 
University Erlangen-Nuremberg between 2003 and 2006. 
Each instance has an associated BI-RADS assessment ranging from 1 (definitely benign) 
to 5 (highly suggestive of malignancy) assigned in a double-review process by 
physicians. Assuming that all cases with BI-RADS assessments greater or equal 
a given value (varying from 1 to 5), are malignant and the other cases benign, 
sensitivities and associated specificities can be calculated. These can be an 
indication of how well a CAD system performs compared to the radiologists. 

**Class Distribution**: benign: 516; malignant: 445 


**Attribute Information**:

6 Attributes in total (1 goal field, 1 non-predictive, 4 predictive attributes) 

1. BI-RADS assessment: 1 to 5 (ordinal, non-predictive!) 
2. Age: patient's age in years (integer) 
3. Shape: mass shape: round=1 oval=2 lobular=3 irregular=4 (nominal) 
4. Margin: mass margin: circumscribed=1 microlobulated=2 obscured=3 ill-defined=4 spiculated=5 (nominal) 
5. Density: mass density high=1 iso=2 low=3 fat-containing=4 (ordinal) 
6. Severity: benign=0 or malignant=1 (binominal, goal field!) 


**Missing Attribute Values**: 
- BI-RADS assessment: 2 
- Age: 5 
- Shape: 31 
- Margin: 48 
- Density: 76 
- Severity: 0 

I acknowledge that this dataset is not mine and I have only reformatted the data and uploaded it to kaggle.
**Source**:

Matthias Elter 
Fraunhofer Institute for Integrated Circuits (IIS) 
Image Processing and Medical Engineering Department (BMT) 
Am Wolfsmantel 33 
91058 Erlangen, Germany 
matthias.elter '@' iis.fraunhofer.de 
(49) 9131-7767327 

Prof. Dr. Rüdiger Schulz-Wendtland 
Institute of Radiology, Gynaecological Radiology, University Erlangen-Nuremberg 
Universitätsstraße 21-23 
91054 Erlangen, Germany

**Relevant Papers**:

M. Elter, R. Schulz-Wendtland and T. Wittenberg (2007) 
The prediction of breast cancer biopsy outcomes using two CAD approaches that both emphasize an intelligible decision process. 
Medical Physics 34(11), pp. 4164-4172



**Citation Request**:

M. Elter, R. Schulz-Wendtland and T. Wittenberg (2007) 
The prediction of breast cancer biopsy outcomes using two CAD approaches that both emphasize an intelligible decision process. 
Medical Physics 34(11), pp. 4164-4172",.csv
Mammography Cancer IMB CLASS Data,1,mammography-cancer-imb-class-data,mammography.csv,Apache 2.0,"The Mammography Classification dataset is a well-known dataset in the field of machine learning. It contains mammogram images and their corresponding labels, which are either benign or malignant. The dataset is commonly used for training and testing machine learning models for breast cancer diagnosis. It is available on GitHub, where you can download it and use it for your own projects. The dataset is created by Dr. Geoffrey Hinton and Dr. Yoshua Bengio, and it is widely used in the field of computer vision and machine learning.

Mammography dataset

Woods, K., Doss, C., Bowyer, K., Solka, J., Priebe, C., & Kegelmeyer, P. (1993). Comparative Evaluation of Pattern Recognition Techniques for Detection of Microcalcifications in Mammography. International Journal of Pattern Recognition and Artificial Intelligence, 7(6), 1417–1436.

- 11,183 examples
- 260 minority class (calcifications)
- 10,923 majority class",.csv
Manufacturing Data for Polynomial Regression,1,manufacturing-data-for-polynomial-regression,manufacturing.csv,other,"# Manufacturing Data Report

## I. Introduction

This report presents an analysis of a manufacturing dataset, which simulates real-world data collected from a manufacturing process. The dataset is designed to explore the relationships between various process parameters and product quality. It contains both feature variables that represent process conditions and a target variable that represents the quality rating of the manufactured items.

## II. Dataset Description

The manufacturing dataset consists of the following columns:

1. **Temperature (°C)**: This column represents the temperature during the manufacturing process, measured in degrees Celsius. Temperature plays a critical role in many manufacturing processes, influencing material properties and product quality.

2. **Pressure (kPa)**: The pressure applied during the manufacturing process, measured in kilopascals (kPa). Pressure can affect the material transformation and the overall outcome of the manufacturing process.

3. **Temperature x Pressure**: This feature is an interaction term between temperature and pressure, which captures the combined effect of these two process parameters.

4. **Material Fusion Metric**: A derived metric calculated as the sum of the square of temperature and the cube of pressure. It represents a material fusion-related measurement during the manufacturing process.

5. **Material Transformation Metric**: Another derived metric calculated as the cube of temperature minus the square of pressure. It provides insight into material transformation dynamics.

6. **Quality Rating**: The target variable, 'Quality Rating,' represents the overall quality rating of the produced items. Quality is a crucial aspect of manufacturing, and this rating serves as a measure of the final product's quality.

## III. Data Analysis

### 3.1. Polynomial Relationships

In this dataset, we have explored polynomial relationships between the features and the 'Quality Rating.' Polynomial regression was employed to assess the impact of different polynomial degrees (ranging from 1 to 9) on the predictive performance. The results revealed optimal polynomial degrees for each feature, highlighting the complexity of the relationships.

### 3.2. Data Visualization

To visualize these relationships, we created graphs for each feature, showing how the Mean Squared Error (MSE) varies with polynomial degree. These visualizations provide insights into the choice of polynomial degree that best fits each feature.

## IV. Potential Applications

The manufacturing dataset can find applications in various fields, including:

1. **Manufacturing Process Optimization**: By understanding the relationships between process parameters (temperature, pressure) and product quality, manufacturers can optimize their processes for higher-quality output.

2. **Quality Control**: The 'Quality Rating' can serve as a quality control metric, helping manufacturers identify potential issues in real-time and take corrective actions.

3. **Predictive Modeling**: Machine learning models can be trained using this data to predict product quality based on process conditions, enabling proactive quality assurance.

## V. Conclusion

In conclusion, the manufacturing dataset provides valuable insights into the complex relationships between process parameters and product quality. It serves as a valuable resource for process optimization, quality control, and predictive modeling in the manufacturing industry.",.csv
Manufacturing Defects -  Industry Dataset,1,manufacturing-defects-industry-dataset,defects.csv,other,"Defect sampling is used in industrial settings to determine the types and amounts of defects in manufactured items. Items at various stages of production are removed from the process and inspected for defects. Sustained testing allows operations managers to discover whether some part of the manufacturing process is failing to meet performance criteria and product standards. To minimize manufacturing defects, early detection and problem resolution are critical.

In the current sampling plan, one component from the production line is randomly selected every 15 minutes. Each component is inspected and tested for major and minor defects. Major defects, which affect component performance, must be addressed immediately. Fortunately, major defects are rare and are generally contained and corrected early in the process. Minor defects, such as nicks and scratches, are those that affect the appearance of a component but not its functionality.

The data set contains ten days of data on minor defects. Each day, one item is tested every fifteen minutes during an eight-hour shift. The variables in the data set are:
- **Day** - Day of the test: 1 – 10
- **Sample** - Time of the day that sample was taken in military time (e.g., 13:00 is 1pm)
- **Defects** - Number of minor defects detected on the sampled item",.csv
Marathon time Predictions,1,marathon-time-predictions,MarathonData.csv,CC0-1.0,"# Context 

Every Marathoner has a time goal in mind, and this is the result of all the training done in months of exercises. Long runs, Strides, Kilometers and phisical exercise, all add improvement to the result. Marathon time prediction is an art, generally guided by expert physiologists that prescribe the weekly exercises and the milestones to the marathon.  
Unfortunately, Runners have a lot of distractions while preparing the marathon, work, family, illnes, and therefore each one of us arrives to the marathon with his own story. 
The ""simple"" approach is to look at data after the competition, the Leaderboard.  

##But what if we could link the Marathon result to the training history of the Athlete? Could we find that ""non orthodox"" training plans give good results?  

#The Athlete Training History
As a start, I'll take just two data from the **Athlete History**, easy to extract. Two meaningful data, the average km run during the 4 weeks before the marathon, and the average speed that the athlete has run these km.  

**Meaningful**, because in the last month of the training I have the recap of all the previous months that brought me to the marathon.  

**Easy to extract**, because I can go to Strava and I have a ""side-by-side"" comparison, myself and the reference athlete. I said easy, well, that's not so easy, since I have to search every athlete and write down those numbers, the exact day the marathon happened, otherwise I will put in the average the rest days after the marathon.

I've set my future work in **extracting more data** and **build better algorithms**. Thank you for helping me to understand or suggest.

# Content
id:  
simple counter

Marathon:  
the Marathon name where the data were extracted. I use the data coming out from Strava ""Side by side comparison"" and the data coming from the final marathon result

Name:  
The athlete's name, still some problems with UTF-8, I'll fix that soon

Category:  
the sex and age group of a runner
- MAM Male Athletes under 40 years
- WAM Women under 40 Years
- M40 Male Athletes between 40 and 45 years

km4week  
This is the total number of kilometers run in the last 4 weeks before the marathon, marathon included. If, for example, the km4week is 100, the athlete has run 400 km in the four weeks before the marathon 

sp4week  
This is the average speed of the athlete in the last 4 training weeks. The average counts all the kilometers done, included the slow kilometers done before and after the training. A typic running session can be of 2km of slow running, then 12-14km of fast running, and finally other 2km of slow running. The average of the speed is this number, and with time this is one of the numbers that has to be refined

cross training:  
If the runner is also a cyclist, or a triathlete, does it counts? Use this parameter to see if the athlete is also a cross trainer in other disciplines

Wall21:
In decimal. The tricky field. To acknowledge a good performance, as a marathoner, I have to run the first half marathon with the same split of the second half. If, for example, I run the first half marathon in 1h30m, I must finish the marathon in 3h (for doing a good job). If I finish in 3h20m, I started too fast and I hit ""the wall"". My training history is, therefore, less valid, since I was not estimating my result

Marathon time:  
In decimal. This is the final result. Based on my training history, I must predict my expected Marathon time

Category:  
This is an ancillary field. It gives some direction, so feel free to use or discard it. It groups in:  
- A results under 3h  
- B results between 3h and 3h20m  
- C results between 3h20m and 3h40m  
- D results between 3h40 and 4h

# Acknowledgements

Thank you to the main Athletes data sources, **GARMIN** and **STRAVA**

# The Goal of this Competition:
Based on my training history, I must predict my expected Marathon time. Which other relevant data could help me to be more precise? Heart rate, cadence, speed training, what else? And how could I get those data?",.csv
March Madness | Historical Data | 2012-2023,1,march-madness-historical-data-2012-2023,march-madnesss-historical-data.csv,Apache 2.0,"This comprehensive CSV dataset compiles historical features of NCAA basketball teams participating in March Madness tournaments from 2012 to 2023. The dataset includes a rich array of performance metrics aimed at analyzing team dynamics and competitiveness. Key features encompass win-loss percentage, advanced metrics like Simple Rating System (SRS), Strength of Schedule (SOS), field goal percentage (FG%), three-point percentage (3P%), free throw percentage (FT%), home and away win rates, conference win rates, and point differential percentage.

Additionally, advanced statistical insights are provided, such as adjusted efficiency margin (AdjEM), adjusted offensive efficiency (AdjO), adjusted defensive efficiency (AdjD), adjusted tempo (AdjT), luck factor, adjusted strength of schedule (SOS AdjEM), average adjusted offensive efficiency of opposing teams (OppO), average adjusted defensive efficiency of opposing teams (OppD), and non-conference adjusted strength of schedule (NCSOS AdjEM). This dataset serves as a valuable resource for researchers, analysts, and enthusiasts seeking to delve into the intricate performance dynamics of collegiate basketball teams during the March Madness era.",.csv
Market Basket Analysis,1,analytics-case-studyecommerce,Analytics case study (market basket analysis ecommerce).csv,other,"The task is to perform a **market basket analysis** based on the e-commerce data - an online electronics store.
Specifically, you have to find out
- what items are `frequently bought together`
- what items are `usually bought on their own`
- any  opportunity for `up-selling`/`cross-selling`
- anything other `insights` that might `help the business` (especially the types of findings included typically as part of `market basket analysis`)

Collected : agnes@analyticshacker.com",.csv
Market Basket Analysis Data,1,datasets-for-appiori,basket_analysis.csv,CC0-1.0,"Market Basket Analysis 
Apriori algorithm is given by R. Agrawal and R. Srikant in 1994 for finding frequent itemsets in a dataset for boolean association rule. Name of the algorithm is Apriori because it uses prior knowledge of frequent itemset properties. We apply an iterative approach or level-wise search where k-frequent itemsets are used to find k+1 itemsets.",.csv
Market Segmentation in Insurance Unsupervised,1,market-segmentation-in-insurance-unsupervised,Customer Data.csv,DbCL-1.0,"# WHAT IS MARKET SEGMENTATION?
In marketing, market segmentation is the process of dividing a broad consumer or business market, normally consisting of existing and potential customers, into subgroups of consumers based on some type of shared characteristics.

# Objective :
This case requires developing a customer segmentation to give recommendations like saving plans, loans, wealth management, etc. on target customer groups.

# Dataset
The sample Dataset summarizes the usage behavior of about 9000 active credit cardholders during the last 6 months. The file is at a customer level with 18 behavioral variables.
Variables of Dataset
Balance
Balance Frequency
Purchases
One-off Purchases
Installment Purchases
Cash Advance
Purchases Frequency
One-off Purchases Frequency
Purchases Installments Frequency
Cash Advance Frequency
Cash Advance TRX
Purchases TRX
Credit Limit
Payments
Minimum Payments
PRC Full payment
Tenure
Cluster

The sample Dataset summarizes the usage behavior of about 9000 active credit cardholders during the last 6 months. The file is at a customer level with 18 behavioral variables.",.csv
Marketing Analytics,1,marketing-data,ifood_df.csv,CC0-1.0,"## Context

This data is publicly available on GitHub [here](https://github.com/nailson/ifood-data-business-analyst-test). It can be utilized for EDA, Statistical Analysis, and Visualizations. 

## Content

The data set `ifood_df.csv` consists of 2206 customers of XYZ company with data on:
- Customer profiles
- Product preferences
- Campaign successes/failures
- Channel performance

## Acknowledgement

I do not own this dataset. I am simply making it accessible on this platform via the public GitHub [link](https://github.com/nailson/ifood-data-business-analyst-test).",.csv
Marketing Campaign,1,arketing-campaign,marketing_campaign.csv,other,"### Context

A response model can provide a significant boost to the efficiency of a marketing campaign by increasing responses or reducing expenses. The objective is to predict who will respond to an offer for a product or service


### Content

AcceptedCmp1 - 1 if customer accepted the offer in the 1st campaign, 0 otherwise 
AcceptedCmp2 - 1 if customer accepted the offer in the 2nd campaign, 0 otherwise 
AcceptedCmp3 - 1 if customer accepted the offer in the 3rd campaign, 0 otherwise 
AcceptedCmp4 - 1 if customer accepted the offer in the 4th campaign, 0 otherwise 
AcceptedCmp5 - 1 if customer accepted the offer in the 5th campaign, 0 otherwise 
Response (target) - 1 if customer accepted the offer in the last campaign, 0 otherwise 
Complain - 1 if customer complained in the last 2 years
DtCustomer - date of customer’s enrolment with the company
Education - customer’s level of education
Marital - customer’s marital status
Kidhome - number of small children in customer’s household
 Teenhome - number of teenagers in customer’s household
 Income - customer’s yearly household income
MntFishProducts - amount spent on fish products in the last 2 years
MntMeatProducts - amount spent on meat products in the last 2 years
MntFruits - amount spent on fruits products in the last 2 years
MntSweetProducts - amount spent on sweet products in the last 2 years
MntWines - amount spent on wine products in the last 2 years
MntGoldProds - amount spent on gold products in the last 2 years
NumDealsPurchases - number of purchases made with discount
NumCatalogPurchases - number of purchases made using catalogue
NumStorePurchases - number of purchases made directly in stores
NumWebPurchases - number of purchases made through company’s web site
NumWebVisitsMonth - number of visits to company’s web site in the last month
Recency - number of days since the last purchase 


### Acknowledgements

O. Parr-Rud. Business Analytics Using SAS Enterprise Guide and SAS Enterprise Miner. SAS Institute, 2014.


### Inspiration

The main objective is to train a predictive model which allows the company to maximize the profit of the next marketing campaign.",.csv
Marketing Campaign Positive Response Prediction,1,marketing-campaign-positive-response-prediction,campaign_responses.csv,CC-BY-SA-4.0,"Column Descriptions:

- customer_id (int): A unique identifier for each customer.
- age (int): The age of the customer.
- gender (string): The gender of the customer, either 'Male' or 'Female'.
- annual_income (int): The annual income of the customer in dollars.
- credit_score (int): The credit score of the customer, ranging from 300 to 850.
- employed (string): Whether the customer is currently employed or not, either 'Yes' or 'No'.
- marital_status (string): The marital status of the customer, either 'Married' or 'Single'.
- no_of_children (int): The number of children the customer has.
- responded (string): The target variable, indicating whether the customer responded positively ('Yes') or negatively ('No') to the marketing campaign.

This dataset contains various demographic and financial features that could be used to build a classification model for predicting customer response to a marketing campaign. The responded column serves as the target variable for the classification task.",.csv
Marketing Campaigns Data Set,1,marketing-campaigns-data-set,marketing_data.csv,Apache 2.0,"Data Description:
The variables birth-year, education, income, and so on are related to the first 'P' or 'People' in the tabular data provided to the user. The amount spent on wine, fruits, gold, etc., is related to ‘Product’. The information pertinent to sales channels, like websites, stores, etc., is related to ‘Place’, and the fields which talk about promotions and results of different campaigns are related to ‘Promotion’.",.csv
Marketing Promotion Campaign Uplift Modelling,1,customer-retention,data.csv,CC0-1.0,"### Context
Marketing Promotion Campaign
with a total of 6,400 customers data.

### Content
- This dataset show customer's brief information, 
- historical use of discount or BOGO(Buy One Get One) promotion, 
- offer has been made, and the conversion result(buy or not). 
- The conversion average value = $25

### Acknowledgements
This dataset is a fictional dataset for practicing purpose


### Inspiration
- Predict customer's conversion rate
- Uplift Modelling to maximizing marketing campaign and reducing campaign cost",.csv
Marketing_Campaign_Customer_Personality,1,marketing-campaign-customer-personality,marketing_campaign_Customer_Personality.csv,GNU Lesser General Public License 3.0,"<div><h3>Context</h3>
<p><strong>Problem Statement</strong></p>
<p>Customer Personality Analysis serves as an in-depth examination of a company's ideal customers, aiding in a comprehensive understanding of their needs, behaviors, and concerns. This analysis enables businesses to tailor their products and services to align more closely with the preferences of various customer segments.</p>

<p>By delving into the intricacies of customer personalities, businesses can refine their marketing strategies and product offerings to resonate more effectively with specific customer groups. Rather than employing a one-size-fits-all approach, companies can leverage customer personality insights to customize their products and marketing efforts to cater to the distinct preferences of different customer segments.</p>

<p>For example, rather than allocating resources to market a new product indiscriminately to all customers in the company's database, a targeted approach can be adopted. Through customer personality analysis, a company can identify the customer segments most likely to be interested in the new product and focus its marketing efforts exclusively on those segments. This targeted strategy enhances the efficiency and effectiveness of marketing campaigns, resulting in improved customer engagement and higher conversion rates.</p>

<p>Overall, customer personality analysis empowers businesses to better understand their customer base, refine their marketing strategies, and optimize their product offerings to meet the diverse needs of different customer segments effectively.</p>
<h3>Content</h3>
<p><strong>Attributes</strong></p>
<p><strong>People</strong></p>
<ul>
<li>ID: Customer's unique identifier</li>
<li>Year_Birth: Customer's birth year</li>
<li>Education: Customer's education level</li>
<li>Marital_Status: Customer's marital status</li>
<li>Income: Customer's yearly household income</li>
<li>Kidhome: Number of children in customer's household</li>
<li>Teenhome: Number of teenagers in customer's household</li>
<li>Dt_Customer: Date of customer's enrollment with the company</li>
<li>Recency: Number of days since customer's last purchase</li>
<li>Complain: 1 if the customer complained in the last 2 years, 0 otherwise</li>
</ul>
<p><strong>Products</strong></p>
<ul>
<li>MntWines: Amount spent on wine in last 2 years</li>
<li>MntFruits: Amount spent on fruits in last 2 years</li>
<li>MntMeatProducts: Amount spent on meat in last 2 years</li>
<li>MntFishProducts: Amount spent on fish in last 2 years</li>
<li>MntSweetProducts: Amount spent on sweets in last 2 years</li>
<li>MntGoldProds: Amount spent on gold in last 2 years</li>
</ul>
<p><strong>Promotion</strong></p>
<ul>
<li>NumDealsPurchases: Number of purchases made with a discount</li>
<li>AcceptedCmp1: 1 if customer accepted the offer in the 1st campaign, 0 otherwise</li>
<li>AcceptedCmp2: 1 if customer accepted the offer in the 2nd campaign, 0 otherwise</li>
<li>AcceptedCmp3: 1 if customer accepted the offer in the 3rd campaign, 0 otherwise</li>
<li>AcceptedCmp4: 1 if customer accepted the offer in the 4th campaign, 0 otherwise</li>
<li>AcceptedCmp5: 1 if customer accepted the offer in the 5th campaign, 0 otherwise</li>
<li>Response: 1 if customer accepted the offer in the last campaign, 0 otherwise</li>
</ul>
<p><strong>Place</strong></p>
<ul>
<li>NumWebPurchases: Number of purchases made through the company’s website</li>
<li>NumCatalogPurchases: Number of purchases made using a catalogue</li>
<li>NumStorePurchases: Number of purchases made directly in stores</li>
<li>NumWebVisitsMonth: Number of visits to company’s website in the last month</li>
</ul>
<h3>Target</h3>
<p>Need to perform clustering to summarize customer segments.</p>
<h3>Acknowledgement</h3>
<p>The dataset for this project is provided by Dr. Omar Romero-Hernandez. </p>
<h3>Solution</h3>
<p>You can take help from following link to know more about the approach to solve this problem.<br>
<a target=""_blank"" href=""https://thecleverprogrammer.com/2021/02/08/customer-personality-analysis-with-python/"">Visit this URL  </a></p>
<h3>Inspiration</h3>
<p>happy learning….</p>
<p><strong>Hope you like this dataset please don't forget to like this dataset</strong></p></div>",.csv
Marriage and Divorce Dataset,1,marriage-and-divorce-dataset,Marriage_Divorce_DB.csv,CC0-1.0,"This data contains 31 columns (100x31). The first 30 columns are features (inputs), namely Age Gap, Education, Economic Similarity, Social Similarities, Cultural Similarities, Social Gap, Common Interests, Religion Compatibility, No of Children from Previous Marriage, Desire to Marry, Independency, Relationship with the Spouse Family, Trading in, Engagement Time, Love, Commitment, Mental Health, The Sense of Having Children, Previous Trading, Previous Marriage, The Proportion of Common Genes, Addiction, Loyalty, Height Ratio, Good Income, Self Confidence, Relation with Non-spouse Before Marriage, Spouse Confirmed by Family, Divorce in the Family of Grade 1 and Start Socializing with the Opposite Sex Age. The 31th column is Divorce Probability (Target).",.csv
Married at First Sight,1,married-at-first-sight,mafs.csv,CC-BY-SA-4.0,"### Context

The Lifetime reality television show and social experiment, _Married at First Sight_, features men and women who sign up to marry a complete stranger they've never met before. Experts pair couples based on tests and interviews. After marriage, couples have only a few short weeks together to decide if they want to stay married or get a divorce. There have been 10 full seasons so far which provides interesting data to look at what factors may or may not play a role in their decisions at the end of eight weeks as well as longer-term outcomes since the show aired.

### Content

The data was gathered from [Wikipedia](https://en.wikipedia.org/wiki/Married_at_First_Sight_(American_TV_series)). It contains information about the couples, their decisions, and additional metadata.",.csv
Marvel Comic Books Dataset,1,marvel-comic-books,Marvel_Comics.csv,CC0-1.0,"### Context

The dataset contains info on all the comic books ever released in the Marvel Universe.

### Content
Following are the columns:
Comic name: Name of the comic series.
Active years: Years between which the comic series was active.
Issue title: Tv shows have episodes, comic books have issues. For eg, Spiderman comic series has xyz number of issues.
Publish date: Date of publish for the comic issue.
Issue_description: Description of the issue.
Penciler: Penciper of the comic issue.
Writer: Original writer.
Cover artist: Person responsible for cover art of the comic.
Imprint: An imprint of a publisher is a trade name under which it publishes a work
Format: Comic format.
Rating: Age Rating.
Price: Price of the comic.

### Data Source
[A-Z Marvel Comic Series](https://www.marvel.com/comics/series)",.csv
Marvel vs DC,1,marvel-vs-dc,db.csv,other,"### Context

The war between Marvel and DC is old, but what does the numbers say? Check here with data from about the movies from 2000 to 2019

### Content

39 movies from dc and marvel and infos from imdb about them, like rate, budget etc

### Acknowledgements

Data all from imdb

",.csv
Maryland Power Outage : A Geographic Dataset 🌍⚡,1,maryland-power-outage-a-geographic-dataset,Power_Outages_-_Lat_Lon.csv,U.S. Government Works,"This comprehensive dataset offers a detailed chronological record of power outages across Maryland, pinpointing each incident with precise geographic coordinates. Compiled to aid in the analysis of outage patterns and infrastructure resilience, the dataset includes unique identifiers (uid), area codes (area), number of outages (outages), precise timestamps (dt_stamp), and the latitude (Lat) and longitude (Lon) for each event.

**Key Features of the Dataset:**

UID: A unique identifier for each outage incident, ensuring easy reference. 🆔
Area Code: The specific area code where the outage occurred, linking outages to a localized region. 🗺️
Outage Count: The number of outages recorded in each incident, providing insight into the severity and scale. 📊
Timestamp: Exact date and time of each outage, recorded in local time. 🕒
Latitude & Longitude: Accurate geographic coordinates for spatial analysis. 🌐",.csv
Maternal Health Risk Data,1,maternal-health-risk-data,Maternal Health Risk Data Set.csv,other,"### Context

 Data has been collected from different hospitals, community clinics, maternal health cares through the IoT based risk monitoring system.

- Age: Age in years when a woman is pregnant.
- SystolicBP: Upper value of Blood Pressure in mmHg, another significant attribute during pregnancy.
- DiastolicBP: Lower value of Blood Pressure in mmHg, another significant attribute during pregnancy.
- BS: Blood glucose levels is in terms of a molar concentration, mmol/L.
- HeartRate: A normal resting heart rate in beats per minute.
- Risk Level: Predicted Risk Intensity Level during pregnancy considering the previous attribute.

### Acknowledgements

**Relevant Papers:**

1. Ahmed M., Kashem M.A., Rahman M., Khatun S. (2020) Review and Analysis of Risk Factor of Maternal Health in Remote Area Using the Internet of Things (IoT). In: Kasruddin Nasir A. et al. (eds) InECCE2019. Lecture Notes in Electrical Engineering, vol 632. Springer, Singapore. [Web Link]
2. IoT based Risk Level Prediction Model for Maternal Health Care in the Context of Bangladesh, STI-2020, [under publication in IEEE]

### Inspiration

Which health conditions are the strongest indications for health risks during pregnancy?",.csv
Math Students,1,math-students,student-mat.csv,CC0-1.0,"
### Content
This is a dataset from the UCI datasets repository. This dataset contains the final scores of students at the end of a math programs with several features that might or might not impact the future outcome of these students.

### Citation:
Please include this citation if you plan to use this database: 

P. Cortez and A. Silva. Using Data Mining to Predict Secondary School Student Performance. In A. Brito and J. Teixeira Eds., Proceedings of 5th FUture BUsiness TEChnology Conference (FUBUTEC 2008) pp. 5-12, Porto, Portugal, April, 2008, EUROSIS, ISBN 978-9077381-39-7. 
[Web Link]


### Attribute Information:
 Attributes for both student-mat.csv (Math course) and student-por.csv (Portuguese language course) datasets: <br>
1 school - student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira) <br>
2 sex - student's sex (binary: 'F' - female or 'M' - male) <br>
3 age - student's age (numeric: from 15 to 22) <br>
4 address - student's home address type (binary: 'U' - urban or 'R' - rural) <br>
5 famsize - family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3) <br>
6 Pstatus - parent's cohabitation status (binary: 'T' - living together or 'A' - apart) <br>
7 Medu - mother's education (numeric: 0 - none, 1 - primary education (4th grade), 2 â€“ 5th to 9th grade, 3 â€“ secondary education or 4 â€“ higher education) <br>
8 Fedu - father's education (numeric: 0 - none, 1 - primary education (4th grade), 2 â€“ 5th to 9th grade, 3 â€“ secondary education or 4 â€“ higher education) <br>
9 Mjob - mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other') <br>
10 Fjob - father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other') <br>
11 reason - reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other') <br>
12 guardian - student's guardian (nominal: 'mother', 'father' or 'other') <br>
13 traveltime - home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour) <br>
14 studytime - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours) <br>
15 failures - number of past class failures (numeric: n if 1<=n<3, else 4) <br>
16 schoolsup - extra educational support (binary: yes or no) <br>
17 famsup - family educational support (binary: yes or no) <br>
18 paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no) <br>
19 activities - extra-curricular activities (binary: yes or no) <br>
20 nursery - attended nursery school (binary: yes or no) <br>
21 higher - wants to take higher education (binary: yes or no) <br>
22 internet - Internet access at home (binary: yes or no) <br>
23 romantic - with a romantic relationship (binary: yes or no) <br>
24 famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent) <br>
25 freetime - free time after school (numeric: from 1 - very low to 5 - very high) <br>
26 goout - going out with friends (numeric: from 1 - very low to 5 - very high) <br>
27 Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)<br> 
28 Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high) <br>
29 health - current health status (numeric: from 1 - very bad to 5 - very good) <br>
30 absences - number of school absences (numeric: from 0 to 93) <br>

# these grades are related with the course subject, Math: <br>
31 G1 - first period grade (numeric: from 0 to 20) <br>
31 G2 - second period grade (numeric: from 0 to 20) <br>
32 G3 - final grade (numeric: from 0 to 20, output target)<br>",.csv
Maven Roasters: Coffee Shop Sales & Revenue Data,1,trends-product-coffee-shop-sales-revenue-dataset,coffee-shop-sales-revenue.csv,CC0-1.0,"This dataset is ideal for exploring the evolving sales trends over time, identifying peak customer traffic days, and delving into the performance metrics of various products. The dataset comprises transactional records from Maven Roasters, a fictional NYC-based coffee shop operating across three distinct locations. It encompasses comprehensive details such as transaction dates, timestamps, geographical specifics, and product-level information. Researchers can analyze the frequency of product sales, pinpoint top revenue drivers, and investigate factors contributing to fluctuations in sales volume.

<br>

| Field | Type | Description |
| --- | --- | --- |
|transaction_id | Numeric | Unique identifier for each transaction.|
|transaction_date | Date | Date when the transaction occurred <br> (YYYY-MM-DD format).|
|transaction_time | Time | Time of the transaction <br> (HH:MM:SS format).|
|transaction_qty | Numeric | Quantity of products <br> purchased in a transaction.|
|store_id | Numeric | Unique identifier for each store location.|
|store_location | Text | Name or description of the store's <br> physical location.|
|product_id | Numeric | Unique identifier for each product sold.|
|unit_price | Numeric | Price of a single unit of the product <br> in the transaction.|
|product_category | Text | General category to which the product belongs <br> (e.g., Coffee, Tea, Drinking Chocolate).|
|product_type | Text | Specific type or variant of the product <br> (e.g., Gourmet brewed coffee, Brewed Chai tea, Hot chocolate).|
|product_detail | Text | Additional details about the product <br> (e.g., specific flavor, size, or blend)|

<br>

Reference :

Maven Analytics. (n.d.). Maven Analytics | Data analytics online training for Excel, Power BI, SQL, Tableau, Python and more. [online] Available at: https://mavenanalytics.io [Accessed 6 Dec. 2023].",.csv
Mawqif Dataset,1,mawqif-dataset,Mawqif_AllTargets_Train.csv,other,"The vast growth of social media platforms, online news outlets, and digital communication has increased user-generated content exponentially in recent years. This unprecedented surge in online discourse has sparked an urgent need to develop automated tools and techniques to effectively analyze the opinions and attitudes expressed within these expansive streams of text. Stance detection, a critical task within the field of Natural Language Processing (NLP), aims to identify the position or perspective of a writer towards a specific topic or entity by analyzing their written text and/or social media activity, such as preferences and connections. The applications of stance detection are diverse and encompass domains such as politics, marketing, and social media analysis.

## **Classes**
The possible stance labels are:

**FAVOR** means that we can infer from the post that the author supports the target (e.g., explicitly supporting the target or something aligned with the target, or if the post contains information such as news, a quote, a story, which reveals that the author is in favor of the target).

**AGAINST** means that we can infer from the tweet that the author is against the target (e.g., explicitly opposing the target or something aligned with the target, or if the post contains information such as news, a quote, a story, which reveals that the author is against the target).

**NONE** means that the tweet provides no hint as to the author's stance toward the target (e.g., there is no evidence in the tweet to judge the author's stance, such as inquiries, or news that does not express any positive or negative position).

# **Dataset**
Mawqif comprises 4,121 entries distributed across ""COVID-19 vaccine"" (1,373 entries), ""digital transformation"" (1,348 entries), and ""women empowerment"" (1,400 entries). 

It is structured as a multi-label dataset with labels including  stance (Favor, Against, None), sentiment (Positive, Negative, Neutral), and sarcasm (Sarcastic and Non-sarcastic).",.csv
McDonald's India : Menu Nutrition Dataset,1,mcdonalds-india-menu-nutrition-facts,India_Menu.csv,other,"# Context
McDonald’s in India was started in 1996 in Bandra, Mumbai with one single restaurant. It took almost twelve years to grow one restaurant to 50. Today, McDonald's, that arrived in India without its signature Big Mac (substituted in India by the Maharaja Mac) has about 480 stores all over India providing happy meals to folks and families of India.

# Content
This dataset provides a nutrition analysis of every menu item on the Indian McDonald's menu, including breakfast, burgeres, fries, salads, soda, coffee and tea, milkshakes, and desserts.

# Acknowledgements
The menu items and nutrition facts were scraped from the McDonald's website
",.csv
McDonald's Store Reviews,1,mcdonalds-store-reviews,McDonald_s_Reviews.csv,other,"# Description: 

&gt;This dataset contains over 33,000 anonymized reviews of McDonald's stores in the United States, scraped from Google reviews. It provides valuable insights into customer experiences and opinions about various McDonald's locations across the country. The dataset includes information such as store names, categories, addresses, geographic coordinates, review ratings, review texts, and timestamps.

# Key Features:

&gt;- **reviewer_id**: *Unique identifier for each reviewer (anonymized)*
- **store_name**: *Name of the McDonald's store*
- **category**: *Category or type of the store*
- **store_address**: *Address of the store*
- **latitude**: *Latitude coordinate of the store's location*
- **longitude**: *Longitude coordinate of the store's location*
- **rating_count**: *Number of ratings/reviews for the store*
- **review_time**: *Timestamp of the review*
- **review**: *Textual content of the review*
- **rating**: *Rating provided by the reviewer*


# Potential Use Cases:


&gt;- **Sentiment analysis:** Analyze the sentiment of reviews to understand overall customer satisfaction and identify areas for improvement.
- **Location-based analysis:** Explore geographical patterns in reviews and ratings to identify high-performing or underperforming regions.
- **Category analysis:** Investigate how different categories of McDonald's stores (e.g., drive-thru, McCafé) are perceived by customers.
- **Time-based analysis:** Examine temporal trends in reviews to identify any shifts in customer opinions or preferences over time.


Data Source: *The dataset was obtained by scraping Google reviews of McDonald's stores in the United States. The data does not contain any personally identifiable information (PII) to ensure privacy and comply with ethical guidelines.*<br>
If this was helpful, a vote is appreciated ❤️",.csv
McDonald's dataset,1,mcdonaldsdataset,mcd.csv,Community Data License Agreement - Permissive - Version 1.0,"McDonald's dataset contains information about ech product in the McDonald's menu.
It gives information about the proteins, calories, energy, sugar levels, etc. in each and every product in the McDonald's menu.
Dowload the dataset and give it a try!",.csv
McDonald's financial statements (2002-2022),1,mcdonalds-financial-statements-2002-2022,McDonalds_financial_statements.csv,other,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16192307%2F7350eca7614f40bc01574d563fb54642%2Fmcdonalds-rusyayi-nasil-kazandi-ve-nasil-kaybetti-RW7u.jpg?generation=1708629143069211&alt=media)

  McDonald’s Corporation is an American operator and franchisor of fast food restaurants represented worldwide and the biggest fast food company in the world. Founded in 1940 by Richard and Maurice MacDonald, the company has grown significantly and played a key role in shaping the fast food industry. The brand prides itself on providing consistent, fast and affordable food. According to our data, McDonald's is the 51st most valuable company in the world by market capitalization. The company posted revenue of $23.18 billion in 2022, compared to revenue of $23.22 billion in 2021.


  Let's take a look at McDonald's financial data together and see if the biggest fast food player in the world is doing so well.
   

**The data contains the following columns:**

**Year:** Year for which the reports were provided.

**Market cap:** Market capitalization of McDonald. The market capitalization, commonly called market cap, is the total market value of a publicly traded company's outstanding shares and is commonly used to measure how much a company is worth.

**Revenue:** Revenue for McDonald. The revenue is the total amount of income that a company generates by the sale of goods or services. Unlike with the earnings no expenses are subtracted.

**Earnings:** Earnings for McDonald. The profit shown in this column represents the company's income before taxes.

**P/E ratio:** P/E ratio for McDonald. The P/E (Price-to-Earnings) ratio, or price-to-earnings ratio, is one of the key indicators of stock financial analysis. It is used to evaluate the relative high or low value of a company's shares in the market.

**P/S ratio:** P/S ratio for McDonald. P/S (Price-to-Sales) ratio, or price to sales ratio, is another key indicator in stock financial analysis. It is also used to evaluate whether a company's shares are expensive or cheap in the market, but unlike P/E, which uses earnings, P/S uses a company's earnings.

**P/B ratio:** McDonald - P/B ratio. P/B (Price-to-Book) ratio, is another important indicator of a stock's financial analysis. It is used to evaluate the value of a company's shares relative to their book value, that is, the relationship between the market price of the shares and the book value (expressed as book value) of the shares. In other words, it is a way to measure what the stock market thinks a company is worth, compared to what the company says its assets are worth on paper.

**Operating Margin:** Operating Margin for McDonald. This is a financial indicator that allows you to evaluate the effectiveness of a company’s activities in the production process or provision of services. This metric measures the percentage of profit a company makes from sales after deducting all operating costs such as raw materials, labor, facility rent, taxes, and other variable and fixed costs.

**EPS:** EPS for McDonald. EPS (Earnings Per Share) is a metric that measures the net earnings per share of a company's common shareholder. It is widely used by investors and analysts to evaluate the performance of a company's stock.

**Shares Outstanding:** Number of shares outstanding for McDonald.

**Cash on Hand:** McDonald - Cash on Hand. A company’s cash on hand also refered as cash/cash equivalents (CCE) and Short-term investments, is the amount of accessible money a business has.

**Dividend Yield:** Dividend yield history for McDonald.

**Dividend (stock split adjusted):** Dividend history for McDonald.  

**Net assets:** McDonald - Net assets. A company’s net assets is the sum of its assets minus the sum of its liabilities.

**Total assets:** McDonald - Total assets. A company’s total assets is the sum of all current and non-current assets, such as inventories, cash and cash equivalents, properties and equipment.

**Total debt:** McDonald - Total debt. A company’s total debt is the sum of all current and non-current debts.

**Total liabilities:** McDonald - Total liabilities. A company’s total liabilities is the sum of all current and non-current debts and obligations.

**($B) - billion dollar symbol**

",.csv
Mean temperature for countries by year 1901-2022,1,mean-temperature-for-countries-by-year-2014-2022,combined_temperature.csv,MIT,This dataset was scraped from the World Bank Climate Knowledge https://climateknowledgeportal.worldbank.org/ for all available countries from 1901 to 2022. Dataset also includes 5 year smooth temperature values. ,.csv
Measles Immunization Rates in US Schools,1,measles-immunization-rated-in-us-schools,measles_nonduplicated.csv,CC-BY-SA-4.0,"**The dataset includes the overall and MMR-specific vaccination rates for 46,410 schools in 32 states**

#### The table contains the following columns: 
````
|variable |class     |description |
|:--------|:---------|:-----------|
|index    |double    | Index ID |
|state    |character | School's state |
|year     |character | School academic year|
|name     |character | School name|
|type     |character | Whether a school is public, private, charter |
|city     |character | City |
|county   |character | County |
|district |character  | School district |
|enroll   |double    | Enrollment |
|mmr      |double    | School's Measles, Mumps, and Rubella (MMR) vaccination rate |
|overall  |double    | School's overall vaccination rate|
|xrel     |double  | Percentage of students exempted from vaccination for religious reasons |
|xmed     |double    | Percentage of students exempted from vaccination for medical reasons |
|xper     |double    | Percentage of students exempted from vaccination for personal reasons |
|lat      |double    | Latitude  |
|lng      |double    | Longitude  |
````

### Acknowledgements:
This data originally comes from [#tidytuesday](https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-02-25/readme.md) and is originally from [The Wallstreet Journal](https://github.com/WSJ/measles-data). They recently published an [article](https://www.wsj.com/graphics/school-measles-rate-map/) around 46,412 schools across 32 US States.

""This repository contains immunization rate data for schools across the U.S., as compiled by The Wall Street Journal. The dataset includes the overall and MMR-specific vaccination rates for 46,412 schools in 32 states. As used in ""What's the Measles Vaccination Rate at Your Child's School?"".

Vaccination rates are for the 2017-18 school year for Colorado, Connecticut, Minnesota, Montana, New Jersey, New York, North Dakota, Pennsylvania, South Dakota, Utah and Washington. Rates for other states are 2018-19.""  
````
(The #tidytuesday page mentions 46412 records, but the file loads 1 less, and there 1 duplication:  
283	New York	2017-18	Jackson Main	Public	Hempstead	Nassau	NA	NA	100	-1	NA	NA	NA  
284	New York	2017-18	Jackson Main	Public	Hempstead	Nassau	NA	NA	100	-1	NA	NA	NA  
Hence, total of 46410 records if you remove the duplication.)  
  ````

## Data cleaning:
The initial cleaning code from [#tidytuesday](https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-02-25/readme.md) had to be modified because 
1. It was resulting in an error, possibly because the page where [the list of URLs for individual states](https://github.com/WSJ/measles-data/tree/master/individual-states) was coming from has changed since the code was published.

2. When we were adding the latitude and longitude data from the states to the original vaccination file, it was being done only with school name and if one state had multiple schools with the same name, that was leading to a many to many matching, resulting in a cartesian matching and duplication.

### Code:
#### Following code adds latitude and longitude to the original dataset and removes any duplication giving 46410 records  
#### Modifications are mentioned in comments
````{r}
url_wsj &lt;- ""https://raw.githubusercontent.com/WSJ/measles-data/master/all-measles-rates.csv""

wsj &lt;- read_csv(url_wsj)

list_of_urls &lt;- ""https://github.com/WSJ/measles-data/tree/master/individual-states""

raw_states &lt;- list_of_urls %&gt;% 
  read_html() %&gt;% 
  html_table() %&gt;% 
  .[[1]] %&gt;% 
  select(1) %&gt;%  #changed select(Name) to select(1) becase there were three columns with headers 'Name'
  mutate(Name = str_remove(Name, ""\\.csv"")) %&gt;% 
  filter(str_length(Name) &gt; 3, str_length(Name) &lt; 20) %&gt;% 
  pull(Name)

raw_states=raw_states[2:32] # had to add this line of code because the first element on the list was ""parent directory..""  and the last, 33rd element was ""View all files""

all_states &lt;- glue::glue(""https://raw.githubusercontent.com/WSJ/measles-data/master/individual-states/{raw_states}.csv"") %&gt;% 
  map(read_csv)

#As it turns out not every state had all of state, city, county, district information. Hence in the original code was limiting the identifier column to just state.
#Only having state and school name was leading to cross matching in states where multiple schools with same name were present
# clean_states &lt;- all_states %&gt;% 
#   map(~select(., state, name, lat, lng)) %&gt;%   
#   map(~mutate_at(., vars(lat, lng), as.numeric)) %&gt;% 
#   bind_rows() %&gt;% 
#   filter(!is.na(lat))

#Hence added as many parameters that could have been added out of ""state"", ""name"", ""district"", ""county"", ""city"" for each state
clean_states &lt;- all_states %&gt;% 
  map(~select(., tidyselect::any_of(c(""state"", ""name"", ""district"", ""county"", ""city"", ""lat"",""lng"")))) %&gt;% 
  map(~mutate_at(., vars(lat, lng), as.numeric)) %&gt;% 
  bind_rows() %&gt;% 
  filter(!is.na(lat))

wsj1 &lt;- wsj %&gt;% 
  left_join(clean_states, by = c(""name"", ""state"",""district"", ""county"", ""city""))

#creating a new identifier to remove duplications
wsj1=mutate(wsj1,new_id=paste0(state,year,name,type,city,county,district,enroll,mmr,overall,xrel,xmed,xper)) 
wsj1=wsj1[!duplicated(wsj1$new_id),]
  
write_csv(select(wsj1,-""new_id""),""measles_nonduplicated.csv"")

````",.csv
Meat and Dairy Production,1,meat-and-dairy-production,global-meat-production newv2.csv,CC0-1.0,"this graph was created in OurDataWorld,sheets and R : 

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Ffb7b70e11c59739bd12a60144ee6ef0e%2Fgraph1.png?generation=1712521684791045&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F5b18df8db0fe0179716681818bae5725%2Fgraph2.png?generation=1712521690894818&alt=media)

Feeding the world sustainably presents a formidable challenge, particularly as meat consumption continues to rise worldwide. While meat serves as a vital source of nutrition for many, its production exacts a heavy toll on the environment. Over the past five decades, global meat production has surged, now exceeding 350 million tonnes annually. However, this growth comes at a significant cost.

The environmental impacts of meat production are vast and multifaceted. Notably, it contributes substantially to greenhouse gas emissions, strains agricultural land resources, and consumes vast quantities of freshwater. As we grapple with these challenges, it becomes increasingly urgent to develop sustainable practices for producing and consuming meat, dairy, and other protein sources.

In parallel with the meat industry, seafood production also plays a critical role in global nutrition. Fish and seafood provide essential protein and nutrients to populations worldwide. However, the environmental impacts of fishing and aquaculture must be carefully managed to ensure the long-term health of marine ecosystems.

Moreover, dietary habits vary widely across the globe, influencing both health outcomes and environmental sustainability. While some regions enjoy diverse and balanced diets, others suffer from limited access to nutritious foods. Micronutrient deficiencies are a prevalent concern, particularly among populations with poor dietary diversity.

Land use is another crucial aspect of the food production system. Currently, agriculture consumes half of the world's habitable land, with livestock farming accounting for the majority of this area. As demand for meat and dairy continues to rise, the pressure on agricultural land will only intensify, highlighting the need for sustainable land management practices.

In addressing these challenges, a multifaceted approach is essential. This involves promoting dietary diversity, reducing food waste, implementing sustainable farming practices, and investing in innovative solutions such as alternative protein sources. By prioritizing sustainability and resilience in our food systems, we can work towards a future where everyone has access to nutritious and environmentally-friendly food choices.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F0c25331ef5b24d78e763b2b8808915df%2Fgraph3.png?generation=1712521707178769&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F38111522de0c3263d61d08bd80c57cdb%2Fgraph4.png?generation=1712521714429045&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F471df7d30824093af0ba47ce59dadfe5%2Fgraph5.png?generation=1712521722450792&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F46722fadc8f3e11c7a8319a0862d4dd7%2Fgraph6.png?generation=1712521729241883&alt=media)

",.csv
Medical Appointment No Shows,1,noshowappointments,KaggleV2-May-2016.csv,CC-BY-NC-SA-4.0,"# Context 

A person makes a doctor appointment, receives all the instructions and no-show. Who to blame? 
If this help you studying or working, please don´t forget to upvote :).  Reference to Joni Hoppen and  [Aquarela Analytics](http://bit.ly/2Ulwskh)

Greetings! 

# Content

110.527 medical appointments its 14 associated variables (characteristics). The most important one if the patient show-up or no-show to the appointment.  Variable names are self-explanatory, if you have doubts, just let me know! 

scholarship variable means this concept = https://en.wikipedia.org/wiki/Bolsa_Fam%C3%ADlia

14 variables 

#Data Dictionary 

### 01 - PatientId 
- Identification of a patient

### 02 - AppointmentID
 - Identification of each appointment

### 03 - Gender 
- Male or Female . Female is the greater proportion, woman takes way more care of they health in comparison to man.

### 04 - DataMarcacaoConsulta
- The day of the actuall appointment, when they have to visit the doctor.

### 05 - DataAgendamento
- The day someone called or registered the appointment, this is before appointment of course.

### 06 - Age
-  How old is the patient.

### 07 - Neighbourhood
- Where the appointment takes place. 

### 08 - Scholarship
- True of False . Observation, this is a broad topic, consider reading this article https://en.wikipedia.org/wiki/Bolsa_Fam%C3%ADlia 

### 09 - Hipertension 
- True or False

### 10 - Diabetes
- True or False

### Alcoholism
- True or False

### Handcap
- True or False

### SMS_received
- 1 or more messages sent to the patient.

### No-show
- True or False. 

# Inspiration

What if that possible to predict someone to no-show an appointment?",.csv
Medical Insurance Cost Prediction,1,medical-insurance-cost-prediction,medical_insurance.csv,MIT,"# Dataset Overview:
The medical insurance dataset encompasses various factors influencing medical expenses, such as age, sex, BMI, smoking status, number of children, and region. This dataset serves as a foundation for training machine learning models capable of forecasting medical expenses for new policyholders.

Its purpose is to shed light on the pivotal elements contributing to increased insurance costs, aiding the company in making more informed decisions concerning pricing and risk assessment.

The dataset comprises 2.7K rows and 7 columns, including:

1. Age
2. Sex
3. BMI (Body Mass Index)
4. Children
5. Smoker
6. Region
7. Charges

Problem Statement:

1. What are the primary factors influencing medical expenses?
2. How accurate are machine learning models in predicting medical expenses?
3. In what ways can machine learning models enhance the efficiency and profitability of health insurance companies?

If you find the dataset intriguing, please consider upvoting. Thank you.",.csv
Medical Insurance Payout,1,medical-insurance-payout,expenses.csv,other,"ACME Insurance Inc. offers affordable health insurance to thousands of customer all over the United States. You're tasked with creating an automated system to estimate the annual medical expenditure for new customers, using information such as their age, sex, BMI, children, smoking habits and region of residence.

Estimates from your system will be used to determine the annual insurance premium (amount paid every month) offered to the customer.",.csv
Medical Insurance Premium Prediction,1,medical-insurance-premium-prediction,Medicalpremium.csv,CC0-1.0,"### Context

A Medical Insurance Company Has Released Data For Almost 1000 Customers. Create A Model That Predicts The Yearly Medical Cover Cost. The Data Is Voluntarily Given By Customers.


### Content

The Dataset Contains Health Related Parameters Of The Customers. Use Them To Build A Model And Also Perform EDA On The Same. 
The Premium Price Is In INR(₹) Currency And Showcases Prices For A Whole Year.

### Inspiration

Help Solve A Crucial Finance Problem That Would Potentially Impact Many People And Would Help Them Make Better Decisions.
Don't Forget To Submit Your EDAs And Models In The Task Section. These Will Be Keenly Reviewed
Hope You Enjoy Working On The Data.
note- This is a dummy dataset used for teaching and training purposes. It is free to use,
Image Credits-Unsplash",.csv
Medical Insurance Price Prediction,1,medical-insurance-price-prediction,Medical_insurance.csv,CC0-1.0,"**Overview of the dataset:**
The medical insurance dataset contains information about a number of factors that can affect medical expenses, including age, sex, BMI, smoking status, number of children, and region. This dataset can be used to train a machine learning model that can predict medical expenses for new customers.

To provide insights into the key factors that contribute to higher insurance costs and help the company make more informed decisions regarding pricing and risk assessment.

The dataset contains **2.7K rows and 7 columns**
Columns include
1. Age
2. Sex
3. BMI (Body Mass Index)
4. Children
5. Smoker
6. Region
7. Charges

**Problem Statement:**

1. What are the most important factors that affect medical expenses?
2. How well can machine learning models predict medical expenses?
3. How can machine learning models be used to improve the efficiency and profitability of health insurance companies?

Kindly, upvote if you find the dataset interesting. Thank you.

",.csv
Medical_cost_dataset,1,medical-cost-dataset,medical_cost.csv,Apache 2.0,"
#Description:
Explore the intricacies of medical costs and healthcare expenses with our meticulously curated Medical Cost Dataset. This dataset offers valuable insights into the factors influencing medical charges, enabling researchers, analysts, and healthcare professionals to gain a deeper understanding of the dynamics within the healthcare industry.

**Columns:**
1. **ID:** A unique identifier assigned to each individual record, facilitating efficient data management and analysis.
2. **Age:** The age of the patient, providing a crucial demographic factor that often correlates with medical expenses.
3. **Sex:** The gender of the patient, offering insights into potential cost variations based on biological differences.
4. **BMI:** The Body Mass Index (BMI) of the patient, indicating the relative weight status and its potential impact on healthcare costs.
5. **Children:** The number of children or dependents covered under the medical insurance, influencing family-related medical expenses.
6. **Smoker:** A binary indicator of whether the patient is a smoker or not, as smoking habits can significantly impact healthcare costs.
7. **Region:** The geographic region of the patient, helping to understand regional disparities in healthcare expenditure.
8. **Charges:** The medical charges incurred by the patient, serving as the target variable for analysis and predictions.

Whether you're aiming to uncover patterns in medical billing, predict future healthcare costs, or explore the relationships between different variables and charges, our Medical Cost Dataset provides a robust foundation for your research. Researchers can utilize this dataset to develop data-driven models that enhance the efficiency of healthcare resource allocation, insurers can refine pricing strategies, and policymakers can make informed decisions to improve the overall healthcare system.

Unlock the potential of healthcare data with our comprehensive Medical Cost Dataset. Gain insights, make informed decisions, and contribute to the advancement of healthcare economics and policy. Start your analysis today and pave the way for a healthier future.",.csv
Medicare & Medicaid,1,medicare-and-medicaid,CMS.csv,other,"**Dataset updated**
Aug 11, 2023

**Dataset provided by**
[Centers for Disease Control and Prevention](https://www.cdc.gov/)

**Authors**
Centers for Disease Control and Prevention, National Center for Chronic Disease Prevention and Health Promotion, Division of Heart Disease and Stroke Prevention (DHDSP), National Cardiovascular Disease Surveillance System.

**Data Description**

2003 forward. CMS compiles claims data for Medicare and Medicaid patients across a variety of categories and years. This includes Inpatient and Outpatient claims, Master Beneficiary Summary Files, and many other files. Indicators from this data source have been computed by personnel in CDC's Division for Heart Disease and Stroke Prevention (DHDSP). This is one of the datasets provided by the National Cardiovascular Disease Surveillance System. The system is designed to integrate multiple indicators from many data sources to provide a comprehensive picture of the public health burden of CVDs and associated risk factors in the United States. The data are organized by location (national and state) and indicator. The data can be plotted as trends and stratified by sex and race/ethnicity.

**Topics**
Heart Disease & Stroke Prevention
",.csv
Medium Articles,1,medium-articles,articles.csv,CC0-1.0,"### Context

Medium is one of the most famous tools for spreading knowledge about almost any field. It is widely used to published articles on ML, AI, and data science. This dataset is the collection of about 350 articles in such fields. 

### Content

The dataset contains articles, their title, number of claps it has received, their links and their reading time.

### Acknowledgements


This dataset was scraped from [Medium](https://medium.com/).  I created a Python script to scrap all the required articles using just their tags from Medium. Check out the script [here](https://github.com/Hsankesara/medium-scrapper)

### Inspiration

How to write a good article? How to inform the reader in an interesting way? What sort of title attracts more crowd? How long an article should be?",.csv
Melbourne Housing Snapshot,1,melbourne-housing-snapshot,melb_data.csv,CC-BY-NC-SA-4.0,"### Context

Melbourne real estate is BOOMING.  Can you find the insight or predict the next big trend to become a real estate mogul... or even harder, to snap up a reasonably priced 2-bedroom unit?

### Content

This is a snapshot of a [dataset created by Tony Pino][1]. 

It was scraped from publicly available results posted every week from Domain.com.au. He cleaned it well, and now it's up to you to make data analysis magic. The dataset includes Address, Type of Real estate, Suburb, Method of Selling, Rooms, Price, Real Estate Agent, Date of Sale and distance from C.B.D.

### Notes on Specific Variables

Rooms: Number of rooms

Price: Price in dollars

Method: S - property sold; SP - property sold prior; PI - property passed in; PN - sold prior not disclosed; SN - sold not disclosed; NB - no bid; VB - vendor bid; W - withdrawn prior to auction; SA - sold after auction; SS - sold after auction price not disclosed. N/A - price or highest bid not available.

Type: br - bedroom(s); h - house,cottage,villa, semi,terrace; u - unit, duplex; t - townhouse; dev site - development site; o res - other residential.

SellerG: Real Estate Agent

Date: Date sold

Distance: Distance from CBD

Regionname: General Region (West, North West, North, North east ...etc)

Propertycount: Number of properties that exist in the suburb.

Bedroom2 : Scraped # of Bedrooms (from different source)

Bathroom: Number of Bathrooms

Car: Number of carspots

Landsize: Land Size

BuildingArea: Building Size

CouncilArea: Governing council for the area

### Acknowledgements

This is intended as a static (unchanging) snapshot of https://www.kaggle.com/anthonypino/melbourne-housing-market. It was created in September 2017. Additionally, homes with no Price have been removed.


  [1]: https://www.kaggle.com/anthonypino/melbourne-housing-market",.csv
Memory Test on Drugged Islanders Data,1,memory-test-on-drugged-islanders-data,Islander_data.csv,other,"### Context

An experiment on the effects of anti-anxiety medicine on memory recall when being primed with happy or sad memories. The participants were done on novel Islanders whom mimic real-life humans in response to external factors.

Drugs of interest (known-as) [Dosage 1, 2, 3]:

A - Alprazolam (Xanax, Long-term) [1mg/3mg/5mg]

T - Triazolam (Halcion, Short-term) [0.25mg/0.5mg/0.75mg]

S- Sugar Tablet (Placebo) [1 tab/2tabs/3tabs]

*Dosages follow a 1:1 ratio to ensure validity
*Happy or Sad memories were primed 10 minutes prior to testing
*Participants tested every day for 1 week to mimic addiction

Building the Case:
Obstructive effects of Benzodiazepines (Anti-Anxiety Medicine):
- Long term adverse effects on Long Term Potentiation of synapses, metacognition and memory recall ability
http://www.jstor.org/stable/43854146

Happy Memories: 
- research shown positive memories to have a deeper and greater volume of striatum representation under an fMRI
https://www.sciencedirect.com/science/article/pii/S0896627314008484

Sad Memories:
- research shown  sad memories invokes better memory recall for evolutionary purpose whereas, happy memories are more susceptible to false memories
http://www.jstor.org/stable/40064315

**Participants** - all genders above 25+ years old to ensure a fully developed pre-frontal cortex, a region responsible for higher level cognition and memory recall.

### Content

File contains information on participants drug treatment information along with their test scores.


### Acknowledgements

Experiment was executed under the supervision of Mr. Almohalwas at UCLA.
All aspects of the experiment such as experimental design, data collection and preprocessing was done from myself.


### Inspiration

How does anti-anxiety medicine affect you differently by age?
Is there a level of plateauing in effectiveness of anti-anxiety medicine - if so, at what point?
Effect of anti-anxiety medicine on memory recall?
Effectiveness of placebos in a test environment?",.csv
Mental Disorder Classification,1,mental-disorder-classification,Dataset-Mental-Disorders.csv,CC0-1.0,"A Collection of 120 Psychology Patients with 17 Essential Symptoms to Diagnose Mania Bipolar Disorder, Depressive Bipolar Disorder, Major Depressive Disorder, and Normal Individuals. The dataset contains the 17 essential symptoms psychiatrists use to diagnose the described disorders. The behavioral symptoms are considered the levels of patients Sadness, Exhaustness, Euphoric, Sleep disorder, Mood swings, Suicidal thoughts, Anorexia, Anxiety, Try-explaining, Nervous breakdown, Ignore & Move-on, Admitting mistakes, Overthinking, Aggressive response, Optimism, Sexual activity, and Concentration in a Comma Separated Value (CSV) format. The Normal category refer to the individuals using therapy time for specialized counseling, personal development, and life skill enrichments. While such individuals may also have minor mental problems, they differ from those suffering from Major Depressive Disorder and Bipolar Disorder.",.csv
Mental Health Care in the Last 4 Weeks,1,mental-health-care-in-the-last-4-weeks,Mental Health Care in the Last 4 Weeks.csv,CC0-1.0,"Metadata Updated: April 15, 2023

The U.S. Census Bureau, in collaboration with five federal agencies, launched the Household Pulse Survey to produce data on the social and economic impacts of Covid-19 on American households. The Household Pulse Survey was designed to gauge the impact of the pandemic on employment status, consumer spending, food security, housing, education disruptions, and dimensions of physical and mental wellness.

The survey was designed to meet the goal of accurate and timely weekly estimates. It was conducted by an internet questionnaire, with invitations to participate sent by email and text message. The sample frame is the Census Bureau Master Address File Data. Housing units linked to one or more email addresses or cell phone numbers were randomly selected to participate, and one respondent from each housing unit was selected to respond for him or herself. Estimates are weighted to adjust for nonresponse and to match Census Bureau estimates of the population by age, gender, race and ethnicity, and educational attainment. All estimates shown meet the NCHS Data Presentation Standards for Proportions.",.csv
Mental Health Data (Anxiety),1,predicting-anxiety-in-mental-health-data,healthanxiety_dataset.csv,MIT,"This dataset appears to contain a variety of features related to text analysis, sentiment analysis, and psychological indicators, likely derived from posts or text data. Some features include readability indices such as Automated Readability Index (ARI), Coleman Liau Index, and Flesch-Kincaid Grade Level, as well as sentiment analysis scores like sentiment compound, negative, neutral, and positive scores. Additionally, there are features related to psychological aspects such as economic stress, isolation, substance use, and domestic stress. The dataset seems to cover a wide range of linguistic, psychological, and behavioral attributes, potentially suitable for analyzing mental health-related topics in online communities or text data.

**Benefits of using this dataset:**

- Insight into Mental Health: The dataset provides valuable insights into mental health by analyzing linguistic patterns, sentiment, and psychological indicators in text data. Researchers and data scientists can gain a better understanding of how mental health issues manifest in online communication.
- Predictive Modeling: With a wide range of features, including sentiment analysis scores and psychological indicators, the dataset offers opportunities for developing predictive models to identify or predict mental health outcomes based on textual data. This can be useful for early intervention and support.
- Community Engagement: Mental health is a topic of increasing importance, and this dataset can foster community engagement on platforms like Kaggle. Data enthusiasts, researchers, and mental health professionals can collaborate to analyze the data and develop solutions to address mental health challenges.
- Data-driven Insights: By analyzing the dataset, users can uncover correlations and patterns between linguistic features, sentiment, and mental health indicators. These insights can inform interventions, policies, and support systems aimed at promoting mental well-being.
- Educational Resource: The dataset can serve as a valuable educational resource for teaching and learning about mental health analytics, sentiment analysis, and text mining techniques. It provides a real-world dataset for students and practitioners to apply data science skills in a meaningful context.",.csv
Mental Health Dataset,1,mental-health-dataset,Mental Health Dataset.csv,CC0-1.0,"
Mental health includes our emotional, psychological, and social well-being. It affects how we think, feel, and act. It also helps determine how we handle stress, relate to others, and make healthy choices. 1. Mental health is important at every stage of life, from childhood and adolescence through adulthood.",.csv
Mental Health Dataset (Bipolar),1,mental-health-dataset-bipolar,bipolar_dataset.csv,MIT,"This dataset provides a comprehensive collection of textual features extracted from Reddit posts in a subreddit focused on bipolar disorder. Each entry includes various readability indices, sentiment analysis scores, linguistic features, and TF-IDF values for common terms related to mental health and emotional experiences. With this dataset, researchers and practitioners can explore language patterns, sentiment dynamics, and linguistic markers associated with bipolar disorder discussions on Reddit. This resource can support studies on mental health discourse, sentiment analysis, and natural language processing tasks.

This dataset could be beneficial for several purposes related to bipolar disorder research, mental health analysis, and natural language processing (NLP) tasks. Here are some potential benefits:

- Understanding Bipolar Disorder: Researchers and mental health professionals can use the dataset to gain insights into the language patterns and characteristics of individuals with bipolar disorder. By analyzing the content of posts made by individuals with bipolar disorder, researchers can better understand their experiences, challenges, and thought processes.
- Predictive Modeling: Machine learning models can be trained on this dataset to predict various aspects related to bipolar disorder, such as sentiment, symptom severity, or the likelihood of certain behaviors (e.g., substance use, suicidal ideation). These models can help identify individuals at risk and provide timely interventions or support.
- Text Classification: Natural language processing techniques can be applied to classify posts based on their content, sentiment, or topic. For example, posts could be classified into different categories such as manic episodes, depressive episodes, treatment experiences, or coping strategies. This classification can assist in organizing and analyzing large volumes of text data efficiently.",.csv
Mental Health FAQ for Chatbot,1,mental-health-faq-for-chatbot,Mental_Health_FAQ.csv,other,"### Content

Mental health includes our emotional, psychological, and social well-being. Mental health is integral to living a healthy, balanced life. It affects how we think, feel, and act. It also helps determine how we handle stress, relate to others, and make choices. Emotional and mental health is important because it’s a vital part of your life and impacts your thoughts, behaviors and emotions. Being healthy emotionally can promote productivity and effectiveness in activities like work, school or care-giving. It plays an important part in the health of your relationships, and allows you to adapt to changes in your life and cope with adversity. Mental health problems are common but help is available. People with mental health problems can get better and many recover completely. 

This dataset consists of FAQs about Mental Health.


### Acknowledgements

https://www.thekimfoundation.org/faqs/

https://www.mhanational.org/frequently-asked-questions

https://www.wellnessinmind.org/frequently-asked-questions/

https://www.heretohelp.bc.ca/questions-and-answers",.csv
Mental Health in Tech Survey,1,mental-health-in-tech-survey,survey.csv,CC-BY-SA-4.0,"## Dataset Information

This dataset is from a 2014 survey that measures attitudes towards mental health and frequency of mental health disorders in the tech workplace. You are also encouraged to analyze data from the [ongoing 2016 survey found here][1].

## Content

This dataset contains the following data:

* **Timestamp**

* **Age**

* **Gender**

* **Country**

* **state**: If you live in the United States, which state or territory do you live in?

* **self_employed**: Are you self-employed?

* **family_history**: Do you have a family history of mental illness?

* **treatment**: Have you sought treatment for a mental health condition?

* **work_interfere**: If you have a mental health condition, do you feel that it interferes with your work?

* **no_employees**: How many employees does your company or organization have?

* **remote_work**: Do you work remotely (outside of an office) at least 50% of the time?

* **tech_company**: Is your employer primarily a tech company/organization?

* **benefits**: Does your employer provide mental health benefits?

* **care_options**: Do you know the options for mental health care your employer provides?

* **wellness_program**: Has your employer ever discussed mental health as part of an employee wellness program?

* **seek_help**: Does your employer provide resources to learn more about mental health issues and how to seek help?

* **anonymity**: Is your anonymity protected if you choose to take advantage of mental health or substance abuse treatment resources?

* **leave**: How easy is it for you to take medical leave for a mental health condition?

* **mental_health_consequence**: Do you think that discussing a mental health issue with your employer would have negative consequences?

* **phys_health_consequence**: Do you think that discussing a physical health issue with your employer would have negative consequences?

* **coworkers**: Would you be willing to discuss a mental health issue with your coworkers?

* **supervisor**: Would you be willing to discuss a mental health issue with your direct supervisor(s)?

* **mental_health_interview**: Would you bring up a mental health issue with a potential employer in an interview?

* **phys_health_interview**: Would you bring up a physical health issue with a potential employer in an interview?

* **mental_vs_physical**: Do you feel that your employer takes mental health as seriously as physical health?

* **obs_consequence**: Have you heard of or observed negative consequences for coworkers with mental health conditions in your workplace?

* **comments**: Any additional notes or comments

## Inspiration

Some questions worth exploring:

1. How does the frequency of mental health illness and attitudes towards mental health vary by geographic location?
2. What are the strongest predictors of mental health illness or certain attitudes towards mental health in the workplace?

## Acknowledgements

The original dataset is from Open Sourcing Mental Illness and can be downloaded [here](https://osmihelp.org/research/).


  [1]: https://www.kaggle.com/osmi/mental-health-in-tech-2016",.csv
Merger and Acquisitions by Tech Companies,1,company-acquisitions-7-top-companies,acquisitions_update_2021.csv,CC0-1.0,"### Tech Companies - Merger and Acquisitions Dataset - Software Companies 

This dataset contains the list of acquisitions made by the following companies:   

&gt; Microsoft, Google, IBM, Hp, Apple, Amazon, Facebook, Twitter, eBay, Adobe, Citrix, Redhat, Blackberry, Disney
 
The attributes include the date, year, month of the acquisition, name of the company acquired, value or the cost of acquisition,  business use-case of the acquisition, and the country from which the acquisition was made. The source of the dataset is Wikipedia, TechCrunch, and CrunchBase. 

### Interesting Tasks and Analysis Ideas

- Which company makes the acquisitions quickly 
- What is the trend of business use-cases among the acquired companies throughout the years  
- What can be forecasted for upcoming years in terms of acquisitions
- Predict who is likely to make next acquisitions and when",.csv
Meta Platforms Stock Price Data,1,meta-platforms-stock-price-data,META.csv,CC0-1.0,"# Meta Platforms Stock Prices (Oct 28, 2021 - May 7, 2024)

This dataset contains daily stock price data for Meta Platforms (formerly Facebook) from October 28, 2021, to May 7, 2024. The data was collected from [Yahoo Finance](https://finance.yahoo.com/quote/META/)

### Columns:
- Date: Date (DD/MM/YYYY)
- Open: The opening price of the stock on that day
- High: The highest price of the stock on that day
- Low: The lowest price of the stock on that day
- Close: The closing price of the stock on that day
- Adj Close: Adjusted closing price of the stock on that day (adjusted for stock splits)
- Volume: Number of shares traded on that day",.csv
Metabolic Syndrome,1,metabolic-syndrome,Metabolic Syndrome.csv,CC0-1.0,"This dataset contains information on individuals with metabolic syndrome, a complex medical condition associated with a cluster of risk factors for cardiovascular diseases and type 2 diabetes. The data includes demographic, clinical, and laboratory measurements, as well as the presence or absence of metabolic syndrome.

**Column Descriptors:**

- seqn: Sequential identification number.
- Age: Age of the individual.
- Sex: Gender of the individual (e.g., Male, Female).
- Marital: Marital status of the individual.
- Income: Income level or income-related information.
- Race: Ethnic or racial background of the individual.
- WaistCirc: Waist circumference measurement.
- BMI: Body Mass Index, a measure of body composition.
- Albuminuria: Measurement related to albumin in urine.
- UrAlbCr: Urinary albumin-to-creatinine ratio.
- UricAcid: Uric acid levels in the blood.
- BloodGlucose: Blood glucose levels, an indicator of diabetes risk.
- HDL: High-Density Lipoprotein cholesterol levels (the ""good"" cholesterol).
- Triglycerides: Triglyceride levels in the blood.
- MetabolicSyndrome: Binary variable indicating the presence (1) or absence (0) of metabolic syndrome.",.csv
Metal-Organic Frame Materials Prediction,1,metal-organic-frame-materials-prediction,electronic_configuration.csv,CC-BY-NC-SA-4.0,"## Background knowledge

**Metal-Organic Frameworks** (MOF) are a class of crystalline materials connected by coordination bonds between metal ions (or metal clusters) and organic ligands. MOF materials have porous structure, highly tunable and huge specific surface area, which makes them have wide application potential in fields such as adsorption, gas storage, separation, catalysis and so on. Prediction synthesis refers to the prediction and design of synthetic routes and conditions of new MOF materials through computer simulation and machine learning methods.

Structural information of MOF materials (input): MOF is determined by metal, organic ligand, connection mode (topology) and can be given as input data representing structural information by CIF (Crystallographic Information File) file through algorithm (we will provide). This dataset will provide two kinds of data, Fingerprint and RAC, respectively, according to which the players need to make corresponding task predictions.

Synthesis conditions of MOF materials (output): According to the data mining of the corresponding articles on the synthesis of MOF materials, four representative synthetic conditions of materials are obtained: temperature (T), time (t), organic solvent used, and additives.

## Data format specification

### Fingerprint-based features

The data files are presented in the `finger_train.csv` and `finger_test.csv` files and contain 560 training data and 140 test data, respectively.

The fields of sample characteristics are described as follows:

| Field | Description |
| --- | --- |
| `1s` – `5f` | Int, the electronic configuration of the metal at the node |
| `metal` | String, type of metal |
| `linker1smi` | String, structural formula for linker1 |
| `oxidation_state` | Int, nodal metal oxidation states |
| `temperature` | Float, material synthesis temperature |
| `time` | Float, material synthesis time |

linker1smi is a structural expression and a string characteristic. Optionally, the molecular fingerprint of linker can be calculated using the chem.rdkfingerprint function in the chem module of the rdkit library, converting it into a digital vector feature.

Based on Fingerprint characteristics, the following two regression tasks are set:

- temperature Prediction task: Predicts the `temperature` field
- time Prediction task: Predicts the value of the `time` field.

### RAC features

The data files are given in the `RAC_train.csv` and `RAC_test.csv` folders and contain 537 training data and 134 test data, respectively.

The RAC feature data combines the pore geometry of the MOF with the chemical composition (such as metal nodes, ligands, and functional groups) to obtain the feature vector.

The fields of sample characteristics are described as follows:

| Field | Description |
| --- | --- |
| `ASA [m^2/cm^3]` – `CH4HPSTP` | Float and Int, RAC eigenvector of sample MOF |
| `temperature` | Float, material synthesis temperature |
| `time` | Float, material synthesis time |
| `solvent1` – `solvent3` | Int, organic solvent used in material synthesis |
| `additive` | Int, additives used in the synthesis of materials |
| `param1` – `param5` | Float, organic solvent-related properties (normalized) |
| `additive_category` | Int, additive category |

Among them, the five related properties of the solvent are: octanol/water partition coefficient, hydrogen bond donor number, hydrogen bond acceptor number, local charge maximum absolute value, boiling point.

Based on RAC features, the following three regression tasks and one classification task are set:

(1) Regression tasks:

- temperature Prediction task: Predicts the `temperature` field.
- time Prediction task: Predicts the value of the `time` field
- solvent prediction task: Predict the values of `param1`, `param2`, `param3`, `param4`, and `param5`.

(2) Classification tasks:

- additive prediction task: predicts the `additive_category` field values.",.csv
Metallica concerts data,1,metallica-concerts-data,Metallica_gigs.csv,CC-BY-NC-SA-4.0,"Dataset has records for all 2221 concerts (as of April 24, 2024) available on https://www.metallica.com/tour/past/

There are 99 cancelled concerts included into Dataset (as of April 24, 2024). 

There are 129 concerts with missing setlists included into Dataset (as of April 24, 2024).",.csv
Metallica songs (w. lyrics),1,metallica-songs-w-lyrics,Metallica_songs.csv,CC-BY-NC-SA-4.0,"Dataset has records for all 219 songs (as of April 27, 2024) available on https://www.metallica.com/songs/

All the songs (except live albums) published at any media have information in&nbsp;&nbsp;""Duration"", ""Album"", ""Album_type"", ""No_on_album"",&nbsp;""Release_date""&nbsp;columns.

""Album"" and ""Release_date"" are for the first appearance of a song. In the case of songs from studio albums, it's always studio album even if singles were released earlier.",.csv
Meteorite Landings,1,meteorite-landings,meteorite-landings.csv,CC0-1.0,"[The Meteoritical Society](http://www.meteoriticalsociety.org/) collects data on meteorites that have fallen to Earth from outer space. This dataset includes the location, mass, composition, and fall year for over 45,000 meteorites that have struck our planet.

**Notes on missing or incorrect data points**: 

- a few entries here contain date information that was incorrectly parsed into the NASA database. As a spot check: any date that is before 860 CE or after 2016 are incorrect; these should actually be BCE years. There may be other errors and we are looking for a way to identify them.
- a few entries have latitude and longitude of 0N/0E (off the western coast of Africa, where it would be quite difficult to recover meteorites). Many of these were actually discovered in Antarctica, but exact coordinates were not given. 0N/0E locations should probably be treated as NA.

[The starter kernel]() for this dataset has a quick way to filter out these observations using dplyr in R, provided here for convenience:

meteorites.geo <- meteorites.all %>%  
  filter(year>=860 & year<=2016) %>%  # filter out weird years  
  filter(reclong<=180 & reclong>=-180 & (reclat!=0 | reclong!=0))  # filter out weird locations  


## The Data

Note that a few column names start with ""rec"" (e.g., recclass, reclat, reclon). These are the *recommended* values of these variables, according to The Meteoritical Society. In some cases, there were historical reclassification of a meteorite, or small changes in the data on where it was recovered; this dataset gives the currently recommended values.


The dataset contains the following variables:  

- **name**: the name of the meteorite (typically a location, often modified with a number, year, composition, etc)
- **id**: a unique identifier for the meteorite 
- **nametype**: one of:  
-- *valid*: a typical meteorite  
-- *relict*: a meteorite that has been highly degraded by weather on Earth  
- **recclass**: the class of the meteorite; one of a large number of classes based on physical, chemical, and other characteristics (see the Wikipedia article on [meteorite classification](https://en.wikipedia.org/wiki/Meteorite_classification) for a primer)
- **mass**: the mass of the meteorite, in grams
- **fall**: whether the meteorite was seen falling, or was discovered after its impact; one of:  
-- *Fell*: the meteorite's fall was observed  
-- *Found*: the meteorite's fall was not observed  
- **year**: the year the meteorite fell, or the year it was found (depending on the value of **fell**)
- **reclat**: the latitude of the meteorite's landing
- **reclong**: the longitude of the meteorite's landing
- **GeoLocation**: a parentheses-enclose, comma-separated tuple that combines **reclat** and **reclong**

## What can we do with this data?

Here are a couple of thoughts on questions to ask and ways to look at this data:

- how does the geographical distribution of observed falls differ from that of found meteorites?
-- this would be great overlaid on a cartogram or alongside a high-resolution population density map
- are there any geographical differences or differences over time in the class of meteorites that have fallen to Earth?

## Acknowledgements

This dataset was downloaded from [NASA's Data Portal](https://data.nasa.gov/Space-Science/Meteorite-Landings/gh4g-9sfh), and is based on The Meteoritical Society's [Meteoritical Bulletin Database](http://www.lpi.usra.edu/meteor/index.php) (this latter database provides additional information such as meteorite images, links to primary sources, etc.).",.csv
Meteorological Data of Khulna City,1,khulna-weather-data,data.csv,DbCL-1.0,"## **Overview:**
The provided data is in CSV format containing weather observations for Khulna, Bangladesh from 2010 Jan 1 to 2024. It includes various parameters such as humidity,windspeed,winddirection,tempC,tempminC,tempmaxC,	precipitation.

##**Description of Data:**

**Humidity:** The relative humidity measured in percentage.
**Wind Speed:** The speed of wind measured in kilometers per hour at 10 meters above ground.
**Wind Direction:** The direction from which the wind is blowing measured in degrees.
Temperature (Celsius):
**TempC:** The average temperature measured in Celsius.
**TempMinC:** The minimum temperature measured in Celsius.
**TempMaxC:** The maximum temperature measured in Celsius.
**Precipitation:** The amount of rainfall measured in millimeters.
**Date:** The date of observation in ""YYYY-MM-DD"" format.

**These two data will be added in future:**
*HDD12: Heat Degree Days (HDD) calculated as the sum of degrees Celsius below 12°C.*
*HDD15: Heat Degree Days (HDD) calculated as the sum of degrees Celsius below 15°C.*
",.csv
Metro Stations Dataset,1,metro-stations-dataset,metro.csv,CC-BY-NC-SA-4.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F20482184%2Fcbd22bef76de29a64714c285f02686f4%2FWhatsApp%20Image%202024-04-30%20at%207.48.22%20AM.jpeg?generation=1714512877140341&alt=media)
Description: this dataset appears to offer a comprehensive overview of various entities, including their names, addresses, operating hours, and geographic coordinates, which could be valuable for spatial analysis, location-based services, or other applications requiring such information.




",.csv
Mexican Crime Statistics:Comprehensive (2015-2023),1,official-crime-stats-mexico-2015-2023,mexico_crime.csv,ODbL-1.0,"Translated and Tidy dataset of official crime stats for the Country of Mexico. 


# Data Card for Mexican Crime Statistics Dataset

# Title: Mexican Crime Statistics: Comprehensive Incident Dataset
## Subtitle: An Extensive Compilation of Criminal Incidents in Mexico, Sourced from Official Government Data
Source: Official Mexican Government Website

Description: This dataset is a compilation of criminal incidents reported across Mexico. It includes detailed records of various criminal activities, offering insights into crime patterns and trends in different regions. The dataset is ideal for analysis in criminology, public policy, and data science.

- Dataset Description:

year: The year when the crime was reported. This is a numeric field representing the calendar year (e.g., 2015).

entity_code: A numeric code representing a specific entity (state or region) within Mexico. Each number corresponds to a unique entity.

entity: The name of the Mexican state or region where the crime occurred. This is a textual field (e.g., Aguascalientes).

affected_legal_good: A categorical field describing the broad category of the legal good (i.e., personal or societal interest) affected by the crime. Examples include 'Personal freedom' and 'Sexual freedom and security'.

type_of_crime: A categorical field indicating the general type of crime. This field is more specific than 'affected_legal_good' but less specific than 'subtype_of_crime'. Examples include 'Abduction', 'Sexual abuse', and 'Robbery'.

subtype_of_crime: A further categorization of the type of crime. This field provides more specific details within the general type of crime. Examples include 'Sexual Harassment', 'Simple Rape', and 'Home Burglary'.

modality: The specific nature or method of the crime. This field details how the crime was committed or any specific characteristic that differentiates it within its subtype. Examples include 'With violence', 'Without violence', 'Sexual Bullying'.

month: The month when the crime was reported. This is a textual field representing the month (e.g., January).

count: The number of reported incidents for the specific crime type, subtype, and modality in the given entity and month. This is a numeric field


- Dataset Composition:

Type of Data: Structured data, CSV format
Number of Records:  Shape (332416, 9)
Date Range: 2015-2023 ( up to October) Nov - Dec not release yet

- Use Cases:

Intended Use: Research in criminology, public policy analysis, crime trend analysis
Example Analyses: Crime rate trends over time, regional crime analysis, type of crime frequency analysis

- Data Collection Method:

Collection Process: Data aggregated from official crime reports and records maintained by the Mexican government
Data Authenticity: Sourced from [Gobierno de Mexico ](https://www.gob.mx/sesnsp/acciones-y-programas/datos-abiertos-de-incidencia-delictiva)

- Data Quality:

Accuracy: Official - part of the Mexican Government's push for openness
Completeness: Comprehensive coverage of reported incidents within the specified period
Limitations: Possible underreporting or inconsistencies in crime reporting across regions. Nov 2023- Dec 2023 not release yet

- Maintenance Plan:

Update Frequency: Quarterly (or as new data becomes available)",.csv
Miami Housing Dataset,1,miami-housing-dataset,miami-housing.csv,CC0-1.0,"### Content
The dataset contains information on 13,932 single-family homes sold in Miami .

### Content

The dataset contains the following columns:

- PARCELNO: unique identifier for each property. About 1% appear multiple times.
- SALE_PRC: sale price ($)
- LND_SQFOOT: land area (square feet)
- TOT_LVG_AREA: floor area (square feet)
- SPEC_FEAT_VAL: value of special features (e.g., swimming pools) ($)
- RAIL_DIST: distance to the nearest rail line (an indicator of noise) (feet)
- OCEAN_DIST: distance to the ocean (feet)
- WATER_DIST: distance to the nearest body of water (feet)
- CNTR_DIST: distance to the Miami central business district (feet)
- SUBCNTR_DI: distance to the nearest subcenter (feet)
- HWY_DIST: distance to the nearest highway (an indicator of noise) (feet)
- age: age of the structure
- avno60plus: dummy variable for airplane noise exceeding an acceptable level
- structure_quality: quality of the structure
- month_sold: sale month in 2016 (1 = jan)
- LATITUDE
- LONGITUDE
",.csv
Mice Protein Expression,1,mice-protein-expression,Data_Cortex_Nuclear.csv,CC0-1.0,"### Context

Expression levels of 77 proteins measured in the cerebral cortex of 8 classes of control and Down syndrome mice exposed to context fear conditioning, a task used to assess associative learning.

### Content

The data set consists of the expression levels of 77 proteins/protein modifications that produced detectable signals in the nuclear fraction of cortex. There are 38 control mice and 34 trisomic mice (Down syndrome), for a total of 72 mice. In the experiments, 15 measurements were registered of each protein per sample/mouse. Therefore, for control mice, there are 38x15, or 570 measurements, and for trisomic mice, there are 34x15, or 510 measurements. The dataset contains a total of 1080 measurements per protein. Each measurement can be considered as an independent sample/mouse. 

The eight classes of mice are described based on features such as genotype, behavior and treatment. According to genotype, mice can be control or trisomic. According to behavior, some mice have been stimulated to learn (context-shock) and others have not (shock-context) and in order to assess the effect of the drug memantine in recovering the ability to learn in trisomic mice, some mice have been injected with the drug and others have not. 

Classes: 

1. **c-CS-s**: control mice, stimulated to learn, injected with saline (9 mice) 

2. **c-CS-m**: control mice, stimulated to learn, injected with memantine (10 mice) 

3. **c-SC-s**: control mice, not stimulated to learn, injected with saline (9 mice) 

4. **c-SC-m**: control mice, not stimulated to learn, injected with memantine (10 mice) 

5. **t-CS-s**: trisomy mice, stimulated to learn, injected with saline (7 mice) 

6. **t-CS-m**: trisomy mice, stimulated to learn, injected with memantine (9 mice) 

7. **t-SC-s**: trisomy mice, not stimulated to learn, injected with saline (9 mice) 

8. **t-SC-m**: trisomy mice, not stimulated to learn, injected with memantine (9 mice)

### Attribute Information

[1] **Mouse ID** 

[2:78] **Values of expression levels of 77 proteins**; the names of proteins are followed by N indicating that they were measured in the nuclear fraction. *For example: DYRK1A_n*

[79] **Genotype**: control (c) or trisomy (t) 

[80] **Treatment type**: memantine (m) or saline (s) 

[81] **Behavior**: context-shock (CS) or shock-context (SC) 

[82] **Class**: c-CS-s, c-CS-m, c-SC-s, c-SC-m, t-CS-s, t-CS-m, t-SC-s, t-SC-m

### Acknowledgements

Clara Higuera Department of Software Engineering and Artificial Intelligence, Faculty of Informatics and the Department of Biochemistry and Molecular Biology, Faculty of Chemistry, University Complutense, Madrid, Spain. 
Email: clarahiguera at ucm.es 

Katheleen J. Gardiner, creator and owner of the protein expression data, is currently with the Linda Crnic Institute for Down Syndrome, Department of Pediatrics, Department of Biochemistry and Molecular Genetics, Human Medical Genetics and Genomics, and Neuroscience Programs, University of Colorado, School of Medicine, Aurora, Colorado, USA. 
Email: katheleen.gardiner at ucdenver.edu 

Krzysztof J. Cios is currently with the Department of Computer Science, Virginia Commonwealth University, Richmond, Virginia, USA, and IITiS Polish Academy of Sciences, Poland. 
Email: kcios at vcu.edu 

**Source**: [UC Irvine Machine Learning Repository][2]


  [2]: https://archive.ics.uci.edu/ml/datasets/Mice+Protein+Expression

### Inspiration

The aim is to identify subsets of proteins that are discriminant between the classes. ",.csv
Microsoft Corporation (MSFT) 10 years !!!🔥,1,microsoft-corporation-msft-10-years,MSFT.csv,Apache 2.0,"**Data from April 2014 to April 2024**.


-  **Date**: This column represents the calender date when the data about the stock is recorded.

-  **Open**: This column represents the first recorded price of the stock for a trading session.

-  **High**: The high price represents the highest traded price of the stock during a given trading session. It reflects the peak value that the stock reached during the day.

-  **Low**: The low price is the lowest traded price of the stock during a specific trading session. It indicates the minimum value that the stock reached during the day.

-  **Close**: The closing price is the last traded price of the stock at the end of a trading session. It reflects the final value at which the stock was traded before the market closes.

- **Adj Close**(Adjusted Close): The adjusted closing price accounts for corporate actions, such as dividends, stock splits, and new stock offerings, that may affect the stock's price but are not directly related to its performance. The adjusted close is often used to assess the stock's performance over time.

- **Volume**: Volume represents the total number of shares traded during a specific time period. It gives an indication of the level of market activity and liquidity for that stock. High volume often suggests increased investor interest, while low volume may indicate less active trading.

This dataset is crucial for analysis, trend identification, and understanding the historical performance of a stock.

All the best!",.csv
Microsoft Stock Data,1,microsoft-stock-data,MSFT.csv,other,"## **What is Microsoft?**
Microsoft Corporation is an American multinational technology company which produces computer software, consumer electronics, personal computers, and related services. Its best known software products are the Microsoft Windows line of operating systems, the Microsoft Office suite, and the Internet Explorer and Edge web browsers. Its flagship hardware products are the Xbox video game consoles and the Microsoft Surface lineup of touchscreen personal computers. Microsoft ranked No. 21 in the 2020 Fortune 500 rankings of the largest United States corporations by total revenue; it was the world's largest software maker by revenue as of 2016. It is considered one of the Big Five companies in the U.S. information technology industry, along with Google, Apple, Amazon, and Facebook.

## **Data Description**
This dataset provides the history of daily prices of Microsoft Stock (MSFT). All the column descriptions are provided. Currency is USD.",.csv
Microsoft Stock- Time Series Analysis,1,microsoft-stock-time-series-analysis,Microsoft_Stock.csv,CC0-1.0,"### Context

This file contains the stock information of Microsoft from 04/01/2015 to 04/01/2021


### Content

This data was acquired in google sheets using the command 'GOOGLEFINANCE'



### Inspiration

With this data you can do basic EDA and use predictive analysis. ",.csv
Migraine Dataset,1,migraine-dataset,migraine_data.csv,DbCL-1.0,"The migraine dataset described encompasses a comprehensive array of columns, each offering valuable insights into the multifaceted nature of migraine headaches. Beginning with demographic information such as 'Age,' the dataset delves into the specifics of each migraine episode, including its 'Duration' and 'Frequency.' It meticulously documents the characteristics of the pain, from its 'Location' to its 'Intensity,' painting a vivid picture of the subjective experience. The dataset also takes into account the various symptoms that often accompany migraines, such as 'Nausea' and 'Vomiting,' providing a holistic view of the patient's condition. Additionally, it considers sensory and neurological aspects like 'Phonophobia,' 'Photophobia,' and 'Visual' disturbances, shedding light on the diverse manifestations of this condition. Overall, this dataset holds immense potential for in-depth research, diagnosis, and treatment strategies, offering a rich resource for uncovering patterns and correlations within the complex world of migraines.",.csv
Migration Data,1,migration-data,modified_file1.csv,CC0-1.0,"Migration data serves various purposes, including urban planning, resource allocation, public health, economic analysis, and policymaking. It aids in understanding population trends, labor market dynamics, refugee resettlement, demographic shifts, and social integration. Additionally, it informs international relations, humanitarian aid efforts, climate change adaptation strategies, and academic research in fields such as sociology, economics, geography, and public policy.",.csv
Military Spending of Countries (1960-2019),1,military-expenditure-of-countries-19602019,Military Expenditure.csv,world-bank,"### Acknowledgements

STOCKHOLM INTERNATIONAL PEACE RESEARCH INSTITUTE (SIPRI) 

The World Bank Database

###More Relevant Data
https://data.worldbank.org/indicator/MS.MIL.XPND.CD
",.csv
Mines vs Rocks,1,mines-vs-rocks,sonar.all-data.csv,other,"# Connectionist Bench (Sonar, Mines vs. Rocks) Data Set


### Content

http://archive.ics.uci.edu/ml/datasets/connectionist+bench+(sonar,+mines+vs.+rocks)",.csv
Minister's Funds | 17th Lok Sabha Seats | India,1,ministers-funds-17th-lok-sabha-seats-india,Lok_Sabha_17th_MP_Funds.csv,Apache 2.0,"Sources: This dataset comes from the source: https://data.opencity.in/dataset/lok-sabha-mp-local-area-development-funds-details, sourced from various government resources like the Lok Sabha website and the Ministry of Finance’s public records.

Context: It’s about the funds allocated to all MPs in India’s 17th Lok Sabha, used for constituency development.

Inspiration: The topic is inspired by the need to understand how public funds are utilized for constituency development and to promote transparency in public spending.

Election Season: With the ongoing election season in India, the MP’s funding and its utilization become critical factors influencing voting decisions. It serves as a measure of the MP’s performance and their commitment to their constituency’s development. However, other factors like the MP’s engagement with their constituency and legislative performance should also be considered for a comprehensive evaluation.",.csv
Missing Migrants Dataset,1,missingmigrants,MissingMigrantsProject.csv,other,"### About the Missing Migrants Data

This data is sourced from the International Organization for Migration.  The data is part of a specific project called the Missing Migrants Project which tracks deaths of migrants, including refugees , who have gone missing along mixed migration routes worldwide. The research behind this project began with the October 2013 tragedies, when at least 368 individuals died in two shipwrecks near the Italian island of Lampedusa. Since then, Missing Migrants Project has developed into an important hub and advocacy source of information that media, researchers, and the general public access for the latest information.

### Where is the data from?

Missing Migrants Project data are compiled from a variety of sources. Sources vary depending on the region and broadly include data from national authorities, such as Coast Guards and Medical Examiners; media reports; NGOs; and interviews with survivors of shipwrecks. In the Mediterranean region, data are relayed from relevant national authorities to IOM field missions, who then share it with the Missing Migrants Project team. Data are also obtained by IOM and other organizations that receive survivors at landing points in Italy and Greece. In other cases, media reports are used. IOM and UNHCR also regularly coordinate on such data to ensure consistency. Data on the U.S./Mexico border are compiled based on data from U.S. county medical examiners and sheriff’s offices, as well as media reports for deaths occurring on the Mexico side of the border. Estimates within Mexico and Central America are based primarily on media and year-end government reports. Data on the Bay of Bengal are drawn from reports by UNHCR and NGOs. In the Horn of Africa, data are obtained from media and NGOs. Data for other regions is drawn from a combination of sources, including media and grassroots organizations. In all regions, Missing Migrants Projectdata represents minimum estimates and are potentially lower than in actuality.

Updated data and visuals can be found here: https://missingmigrants.iom.int/ 

### Who is included in Missing Migrants Project data?

IOM defines a migrant as any person who is moving or has moved across an international border or within a State away from his/her habitual place of residence, regardless of 

        (1) the person’s legal status; 
        (2) whether the movement is voluntary or involuntary; 
        (3) what the causes for the movement are; or 
        (4) what the length of the stay is.[1]

Missing Migrants Project counts migrants who have died or gone missing at the external borders of states, or in the process of migration towards an international destination. The count excludes deaths that occur in immigration detention facilities, during deportation, or after forced return to a migrant’s homeland, as well as deaths more loosely connected with migrants’ irregular status, such as those resulting from labour exploitation. Migrants who die or go missing after they are established in a new home are also not included in the data, so deaths in refugee camps or housing are excluded.  This approach is chosen because deaths that occur at physical borders and while en route represent a more clearly definable category, and inform what migration routes are most dangerous. Data and knowledge of the risks and vulnerabilities faced by migrants in destination countries, including death, should not be neglected, rather tracked as a distinct category.

### How complete is the data on dead and missing migrants?

Data on fatalities during the migration process are challenging to collect for a number of reasons, most stemming from the irregular nature of migratory journeys on which deaths tend to occur.  For one, deaths often occur in remote areas on routes chosen with the explicit aim of evading detection. Countless bodies are never found, and rarely do these deaths come to the attention of authorities or the media. Furthermore, when deaths occur at sea, frequently not all bodies are recovered - sometimes with hundreds missing from one shipwreck - and the precise number of missing is often unknown.  In 2015, over 50 per cent of deaths recorded by the Missing Migrants Project refer to migrants who are presumed dead and whose bodies have not been found, mainly at sea.      

Data are also challenging to collect as reporting on deaths is poor, and the data that does exist are highly scattered. Few official sources are collecting data systematically. Many counts of death rely on media as a source. Coverage can be spotty and incomplete. In addition, the involvement of criminal actors in incidents means there may be fear among survivors to report deaths and some deaths may be actively covered-up. The irregular immigration status of many migrants, and at times their families as well, also impedes reporting of missing persons or deaths.

The varying quality and comprehensiveness of data by region in attempting to estimate deaths globally may exaggerate the share of deaths that occur in some regions, while under-representing the share occurring in others. 

### What can be understood through this data?

The available data can give an indication of changing conditions and trends related to migration routes and the people travelling on them, which can be relevant for policy making and protection plans.  Data can be useful to determine the relative risks of irregular migration routes. For example, Missing Migrants Project data show that despite the increase in migrant flows through the eastern Mediterranean in 2015, the central Mediterranean remained the more deadly route.  In 2015, nearly two people died out of every 100 travellers (1.85%) crossing the Central route, as opposed to one out of every 1,000 that crossed from Turkey to Greece (0.095%).  From the data, we can also get a sense of whether groups like women and children face additional vulnerabilities on migration routes.

However, it is important to note that because of the challenges in data collection for the missing and dead, basic demographic information on the deceased is rarely known. Often migrants in mixed migration flows do not carry appropriate identification. When bodies are found it may not be possible to identify them or to determine basic demographic information. In the data compiled by Missing Migrants Project, sex of the deceased is unknown in over 80% of cases. Region of origin has been determined for the majority of the deceased. Even this information is at times extrapolated based on available information – for instance if all survivors of a shipwreck are of one origin it was assumed those missing also came from the same region. 

The Missing Migrants Project dataset includes coordinates for where incidents of death took place, which indicates where the risks to migrants may be highest.  However, it should be noted that all coordinates are estimates.

### Why collect data on missing and dead migrants?

By counting lives lost during migration, even if the result is only an informed estimate, we at least acknowledge the fact of these deaths. What before was vague and ill-defined is now a quantified tragedy that must be addressed.  Politically, the availability of official data is important. The lack of political commitment at national and international levels to record and account for migrant deaths reflects and contributes to a lack of concern more broadly for the safety and well-being of migrants, including asylum-seekers. Further, it drives public apathy, ignorance, and the dehumanization of these groups.

Data are crucial to better understand the profiles of those who are most at risk and to tailor policies to better assist migrants and prevent loss of life. Ultimately, improved data should contribute to efforts to better understand the causes, both direct and indirect, of fatalities and their potential links to broader migration control policies and practices.

Counting and recording the dead can also be an initial step to encourage improved systems of identification of those who die. Identifying the dead is a moral imperative that respects and acknowledges those who have died. This process can also provide a some sense of closure for families who may otherwise be left without ever knowing the fate of missing loved ones.                 

### Identification and tracing of the dead and missing

As mentioned above, the challenge remains to count the numbers of dead and also identify those counted. Globally, the majority of those who die during migration remain unidentified. Even in cases in which a body is found identification rates are low. Families may search for years or a lifetime to find conclusive news of their loved one. In the meantime, they may face psychological, practical, financial, and legal problems.       

Ultimately Missing Migrants Project would like to see that every unidentified body, for which it is possible to recover, is adequately “managed”, analysed and tracked to ensure proper documentation, traceability and dignity.  Common forensic protocols and standards should be agreed upon, and used within and between States.  Furthermore, data relating to the dead and missing should be held in searchable and open databases at local, national and international levels to facilitate identification. 

For more in-depth analysis and discussion of the numbers of missing and dead migrants around the world, and the challenges involved in identification and tracing, read our two reports on the issue,  Fatal Journeys: Tracking Lives Lost during Migration (2014) and Fatal Journeys Volume 2, Identification and Tracing of Dead and Missing Migrants        


### Content

The data set records incidents of missing persons and deaths of migrants 

#### columns in the data: 

 1. **ID** - unique key documenting incident 
 2. **Cause of Death** - reason for death
 3. **Region of Origin** 
 4. **Nationality** 
 5. **Missing Persons** - counts 
 6. **Dead** - counts of deaths 
 7.  **Incident Region** - region where incident was recorded 
 8. **Date** - the date when the incident was recorded.  Note the data set includes records from 2014 to June 2017
 9. **Latitude** - spatial coordinates 
 10. **Longitude** - spatial coordinates

 
### Acknowledgements

This data set was created by the International Organization for Migration.  

https://www.iom.int/about-iom

Established in 1951, IOM is the leading inter-governmental organization in the field of migration and works closely with governmental, intergovernmental and non-governmental partners.

With 166 member states, a further 8 states holding observer status and offices in over 100 countries, IOM is dedicated to promoting humane and orderly migration for the benefit of all. It does so by providing services and advice to governments and migrants.

IOM works to help ensure the orderly and humane management of migration, to promote international cooperation on migration issues, to assist in the search for practical solutions to migration problems and to provide humanitarian assistance to migrants in need, including refugees and internally displaced people.

The IOM Constitution recognizes the link between migration and economic, social and cultural development, as well as to the right of freedom of movement.

IOM works in the four broad areas of migration management:

* Migration and development

* Facilitating migration

* Regulating migration

* Forced migration.

IOM activities that cut across these areas include the promotion of international migration law, policy debate and guidance, protection of migrants' rights, migration health and the gender dimension of migration.

#[Start a new kernel][1]


  [1]: https://www.kaggle.com/jmataya/missingmigrants/kernels?modal=true",.csv
Mobile App Permissions for Cyber-security Analysis,1,mobile-app-permissions-for-cyber-security-analysis,Extracted_permssion_updated.csv,MIT,"# Mobile App Permission Analysis and Classification

The dataset consists of a comprehensive list of mobile applications along with their respective categories, download counts, and permission usage. It comprises 321 permission columns representing various permissions requested by each app, such as access to device features, data, or services. The dataset provides a rich source of information for exploring the permission landscape of mobile applications across different categories and download levels.

**Objectives:**

1. **Data Exploration and Visualization:**
   - Perform exploratory data analysis to understand the distribution of app categories, download counts, and permission usage.
   - Visualize the relationships between app categories, download counts, and popular permissions through charts, graphs, and heatmaps.

2. **Feature Engineering:**
   - Select relevant features from the permission columns for model training.
   - Explore techniques such as dimensionality reduction or feature importance analysis to optimize the feature set.

3. **Model Development:**
   - Employ machine learning algorithms (e.g., logistic regression, decision trees, random forests) or deep learning architectures (e.g., neural networks, CNNs, RNNs) to build a classification model.
   - Train the model to predict app categories based on permission usage patterns.

4. **Model Evaluation:**
   - Evaluate the performance of the classification model using appropriate metrics such as accuracy, precision, recall, and F1-score.
   - Utilize techniques like cross-validation to assess model generalization and robustness.

5. **Interpretation and Insights:**
   - Interpret the model results to understand the importance of different permissions in predicting app categories.
   - Provide insights into the privacy implications of certain permissions across app categories and their impact on user trust.


",.csv
Mobile Games A/B Testing - Cookie Cats,1,mobile-games-ab-testing-cookie-cats,cookie_cats.csv,other,"### Context

This dataset includes A/B test results of Cookie Cats to examine what happens when the first gate in the game was moved from level 30 to level 40. When a player installed the game, he or she was randomly assigned to either gate_30 or gate_40. 

### Content

The data we have is from 90,189 players that installed the game while the AB-test was running. The variables are:

**userid:** A unique number that identifies each player.
**version:** Whether the player was put in the control group (gate_30 - a gate at level 30) or the group with the moved gate (gate_40 - a gate at level 40).
**sum_gamerounds:** the number of game rounds played by the player during the first 14 days after install.
**retention_1:** Did the player come back and play <strong>1 day</strong> after installing?
**retention_7:** Did the player come back and play <strong>7 days</strong> after installing?

When a player installed the game, he or she was randomly assigned to either. 

### Acknowledgements

This dataset is taken from  [DataCamp](https://www.datacamp.com/projects/184) 
Cookie Cat is a hugely popular mobile puzzle game developed by [Tactile Entertainment](https://tactilegames.com/cookie-cats/)

Thanks to them for this dataset! 😻 ",.csv
Mobile OS Market Share,1,mobile-os-market-share,mobile_os_market_share.csv,Apache 2.0,"This dataset offers a historical perspective on the evolution of the mobile operating system market over time. By tracking the market share of each OS, it provides insights into consumer preferences, technological advancements, and the competitive landscape within the mobile industry.

For data scientists and analysts, this is valuable for conducting trend analysis, forecasting future market dynamics, and understanding the factors driving changes in OS popularity. It can be used to:

- Analyze trends in mobile OS adoption and decline over time.
- Forecast future shifts in the mobile OS market.
- Assess the impact of new OS releases, features, or other market entrants on existing OS market shares.
- Compare the growth rates of different operating systems.

Several analyses can be conducted, including:

- Identify which operating systems have gained or lost market share over time and the rate of these changes.
- Determine periods during which certain operating systems dominated the market and analyze the causes behind such dominance.
- Compare the year-over-year growth rates of different operating systems to identify which ones are gaining momentum.
- Use historical data to forecast future trends in the mobile OS market.",.csv
Mobile Phone Price,1,mobile-phone-price,Mobile phone price.csv,Attribution 4.0 International (CC BY 4.0),"This dataset contains information on the prices of several mobile phones from different brands. It includes details such as the storage capacity, RAM, screen size, camera specifications, battery capacity, and price of each device.

Columns

•	**Brand:** the manufacturer of the phone

•	**Model:** the name of the phone model

•	**Storage (GB):** the amount of storage space (in gigabytes) available on the phone

•	**RAM (GB):** the amount of RAM (in gigabytes) available on the phone

•	**Screen Size (inches):** the size of the phone's display screen in inches

•	**Camera (MP):** the megapixel count of the phone's rear camera(s)

•	**Battery Capacity (mAh):** the capacity of the phone's battery in milliampere hours

•	**Price ($):** the retail price of the phone in US dollars

Each row represents a different mobile phone model. The data can be used to analyze pricing trends and compare the features and prices of different mobile phones.

** The purpose of creating this dataset is solely for educational use, and any commercial use is strictly prohibited
and this dataset was large language models generated and not collected from actual data sources.
",.csv
Mobile Phones Data,1,ukrainian-market-mobile-phones-data,phones_data.csv,other,"The dataset set contains data about the mobile phones which were released in past 4 years and which can be bought in Ukraine. Dataset contains the model name, brand name and operating system of the phone and it's popularity. It also has it's financial characteristics like lowest/highest/best price and sellers amount. And some of the characteristics like screen/battery size,  memory amount and release date. This data can be useful for improving your machine learning, analysis and vizualization, missing data filling skills. I'm waiting for your notebooks! :) Good luck!",.csv
Mobile Price Prediction,1,mobile-price-prediction,Cellphone.csv,CC0-1.0,"Mobile price depends on various factors such as resolution, brand, size, weight, imaging quality, RAM, battery and cpu power. In this dataset, we want to estimate the price of mobile phones using the above features.",.csv
Mobile Price Prediction | Very Beginner Friendly,1,mobile-price-prediction-very-beginner-friendly,Mobile Price Prediction.csv,Apache 2.0,"Mobile Price Prediction Dataset Description:

This dataset is designed for predicting the price of mobile phones based on various features. It consists of the following columns:

Screen Size (inches): The diagonal size of the mobile phone screen measured in inches.

RAM (GB): The amount of random-access memory (RAM) in gigabytes (GB) available on the mobile phone.

Storage (GB): The storage capacity of the mobile phone in gigabytes (GB).

Battery Capacity (mAh): The capacity of the battery in milliampere-hour (mAh) of the mobile phone.

Camera Quality (MP): The quality of the camera in megapixels (MP) of the mobile phone.

Price ($): The price of the mobile phone in dollars ($).

This dataset includes a total of more than 200 training examples, where each example represents a mobile phone with its associated features and price. The data is synthetic and designed to demonstrate the relationship between mobile phone specifications and their prices.

Researchers and machine learning practitioners can use this dataset to train predictive models, such as regression models, to predict the price of mobile phones based on their features. It can also be used for educational purposes in learning about regression analysis and machine learning algorithms.",.csv
Mobile Prices 2023,1,mobile-prices-2023,mobile_prices_2023.csv,CC0-1.0,"**About Dataset:**
1. Phone Name is the name of the phone that is extracted.
2. Rating is what it gets out of 5 stars.
3. Number of Ratings is the Total number of people those rates this product.
4. Ram size
5. Rom is the Storage that the product has.
6. Front and Rare Camera in the Mega Pixels.
7. Battery size and processor of different types.
8. Lastly the price of the phone in Indian Rupees.

All this data is gathered from the Flipkart Indian Online shopping website.

***In this project I used BeautifulSoup and Request Library for web scraping and FlipCart was the website where I got all the data.***

**Libraries/Dependencies:**
1. Beautiful Soup
2. Request
3. csv
4. numpy
5. pandas
6. re
7. datetime

**How to extract data:**

1. Open the flipcart.com website.
2. Search for specific company names like Apple or Samsung.
3. Apply filter if needed.
4. Get the link to the current page
5. Open AWS Jupyter Notebook or Anaconda Jupyter
6. Request permission to extract the data
If you got 200 in response then you can extract otherwise check the code for what kind of error you are facing.
7. Right Click on the specific part you want to extract and click inspect
8. Get the class of id from div and try my code for extraction
9. Once get all the information for one object now start the loop for all the page
10. Use a loop for all the data
11. Use a loop to go to the next page
12. After all the data is received convert it into a .csv file
13. Now use this data for further analysis and make predictions.",.csv
Mobiles - That you use everyday,1,mobiles-that-you-use-everyday,mobiles_data.csv,Apache 2.0,"I have just collected data from a website , it contains most of the details , costumer reviews , and many more . about 960 rows and 165 columns . 
This dataset focuses and can solve / help you to see market trends , user behaviour and much more , about feedback of that phone , performance and people experiences . 
The dataset can be used in ML problems , basically to predict a price of a phone . 
What make this dataset different ?
**Massive amount of data , costumer feedback , and each and every technical detail - from keypad phones to smartphones .**",.csv
Mobiles phones under 50K,1,mobiles-phones-under-50k,flipkart_mobiles_under_50000.csv,CC0-1.0,"Discover an array of top-tier mobile phones priced under 50k with our comprehensive dataset. This dataset provides detailed information on a variety of smartphones, including their names, prices, and descriptions. Whether you're a tech enthusiast, a savvy shopper, or a data analyst, this dataset offers valuable insights into the latest mobile phone offerings in the market. Explore the diverse range of features and specifications available, and make informed decisions on your next smartphone purchase or analysis project",.csv
Money and Influence: Germany's lobbyists unveiled,1,lobby-groups-in-germany-2024,Lobbyregister2024_full.csv,CC0-1.0,"Dataset has been parsed from the [German Parliament Lobby Register](https://www.lobbyregister.bundestag.de/startseite) (originally only available in PDF). 

## Context

The newly implemented lobby register seeks to increase transparency regarding lobbyists’ influence on the government’s decision-making process in Berlin. Individuals and, in particular, legal entities involved in lobbying activities, will be faced with extensive registration and disclosure obligations. The implementation of the Lobbying Register will therefore impose new compliance challenges on impacted companies.

Under the new act, Lobbyists must immediately register in the Lobby Register if the representation of interest (i) is carried out on a regular basis, (ii) is intended to be permanent, (iii) is carried out commercially for third parties or (iv) more than 50 separate contacts have been established within the past three months. According to the express intention of the legislator, these requirements can already be met when the company engages in lobbying activity for the first time. 

## Column name reference

    'Name': 'Name'
    'Registernummer': 'RegNr'
    'Ersteintrag': 'ErstEintrag'
    'Letzte Änderung': 'LetzteÄnd'
    'Tätigkeitskategorie': 'Tätigkeit'
    'Interessen- und Vorhabenbereiche': 'Interessen'
    'Jährliche finanzielle Aufwendungen im Bereich der Interessenvertretung': 'FinanzAufw'
    'Betrag': 'Betrag'
    'Geschäftsjahr': 'Geschäftsjahr'
    'Vollzeitäquivalent der im Bereich der Interessenvertretung beschäftigten Personen': 'VollzeitEquiv'
    'Konkrete Regelungsvorhaben': 'Regelungen'
    'Stellungnahmen/Gutachten': 'Stellungnahmen'
    'Begründung der Verweigerung der Angaben': 'GrundVerweig'
    'Anzahl der Beschäftigten im Bereich der Interessenvertretung': 'Beschäftigte'
    'Auftraggeberinnen und Auftraggeber': 'Auftraggeber'


[Further reading](https://www.linklaters.com/en-us/insights/blogs/businesscrimelinks/2024/february/german-lobbying-register-act)

**Future work:** Webscrap website to obtain additional meta data not present in the full PDF

**Note:** The dataset is in German

",.csv
Moneyball,1,moneyball-mlb-stats-19622012,baseball.csv,CC0-1.0,"### Context

In the early 2000s, Billy Beane and Paul DePodesta worked for the Oakland Athletics. While there, they literally changed the game of baseball. They didn't do it using a bat or glove, and they certainly didn't do it by throwing money at the issue; in fact, money was the issue. They didn't have enough of it, but they were still expected to keep up with teams that had much deeper pockets. This is where Statistics came riding down the hillside on a white horse to save the day. This data set contains some of the information that was available to Beane and DePodesta in the early 2000s, and it can be used to better understand their methods.


### Content

This data set contains a set of variables that Beane and DePodesta focused heavily on. They determined that stats like on-base percentage (OBP) and slugging percentage (SLG) were very important when it came to scoring runs, however they were largely undervalued by most scouts at the time. This translated to a gold mine for Beane and DePodesta. Since these players weren't being looked at by other teams, they could recruit these players on a small budget. The variables are as follows:

- Team
- League
- Year
- Runs Scored (RS)
- Runs Allowed (RA)
- Wins (W)
- On-Base Percentage (OBP)
- Slugging Percentage (SLG)
- Batting Average (BA)
- Playoffs (binary)
- RankSeason
- RankPlayoffs
- Games Played (G)
- Opponent On-Base Percentage (OOBP)
- Opponent Slugging Percentage (OSLG)

### Acknowledgements

This data set is referenced in The Analytics Edge course on EdX during the lecture regarding the story of Moneyball.
The data itself is gathered from baseball-reference.com.
Sports-reference.com is one of the most comprehensive sports statistics resource available, and I highly recommend checking it out.


### Inspiration

It is such an important skill in today's world to be able to see the ""truth"" in a data set. That is what DePodesta was able to do with this data, and it unsettled the entire system of baseball recruitment. Beane and DePodesta defined their season goal as making it to playoffs. With that in mind, consider these questions:

- How does a team make the playoffs?
- How does a team win more games?
- How does a team score more runs?

They are all simple questions with simple answers, but now it is time to use the data to find the ""truth"" hidden in the numbers.",.csv
Monkey-Pox PATIENTS Dataset.,1,monkeypox-patients-dataset,DATA.csv,CC0-1.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F3350264%2Fd8e67354ac359542555de37891fedf75%2F3E6REX4SHBAJFINHHNZSSD7YAA.jpg?generation=1664643658765570&alt=media)
# Context
An ongoing outbreak of monkeypox, a viral disease, was confirmed in May 2022. The initial cluster of cases was found in the United Kingdom, where the first case was detected in London on 6 May 2022 in a patient with a recent travel history from Nigeria.

# Content
This is a **SYNTHETIC** dataset generated based on a study published by [thebmj](https://www.bmj.com/): Clinical features and novel presentations of human monkeypox in a central London centre during the 2022 outbreak: descriptive case series.

Dataset consists of a CSV which have a record of 25,000 Patients with their corresponding features and a target variable indicating if the patient has monkeypox or not.
```
Features: Patient_ID, Systemic Illness, Rectal Pain, Sore Throat, Penile Oedema, Oral Lesions, Solitary Lesion, Swollen Tonsils, HIV Infection, and Sexually Transmitted Infection
Target Variable: MonkeyPox
```
The dataset currently contains boolean and categorical features and in future, we might add more data and features to help you identify the patients of Monkey-Pox.

# Acknowledgements
```
https://www.bmj.com/content/378/bmj-2022-072410
https://www.bmj.com/company/newsroom/study-finds-important-differences-in-monkeypox-symptoms-between-current-and-previous-outbreaks/
```",.csv
Monthly food price inflation estimates by country,1,monthly-food-price-inflation-estimates-by-country,WLD_RTFP_country_2024-03-26.csv,DbCL-1.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F8706340%2F4cb2a12d17b4a770c483e6803fb43097%2Findia-inflation-likely-rebounded-in-november-on-higher-food-prices-reuters-poll.jpg?generation=1711815784112228&alt=media)
Food price inflation is an important metric to inform economic policy but traditional sources of consumer prices are often produced with delay during crises and only at an aggregate level. This may poorly reflect the actual price trends in rural or poverty-stricken areas, where large populations reside in fragile situations.
This data set includes food price estimates and is intended to help gain insight in price developments beyond what can be formally measured by traditional methods. The estimates are generated using a machine-learning approach that imputes ongoing subnational price surveys, often with accuracy similar to direct measurement of prices. The data set provides new opportunities to investigate local price dynamics in areas where populations are sensitive to localized price shocks and where traditional data are not available.


Geographical Coverage:
Armenia, Bangladesh, Guinea, Indonesia, Kenya, Libya, Malawi, Mauritania, Philippines, Senegal, Sri Lanka, Afghanistan, Burkina Faso, Burundi, Cameroon, Central African Republic, Chad, , Gambia, The, Haiti, Lao People's Democratic Republic, Liberia, Mali, Mozambique, Myanmar, Niger, Somalia, South Sudan, Sudan, , Congo, Republic of, Iraq, Nigeria, Syrian Arab Republic, Lebanon, Guinea-Bissau

Temporal Coverage: 2008  2024
Original data: https://microdata.worldbank.org/index.php/catalog/4509/study-description",.csv
Montreal bike lanes,1,montreal-bike-lanes,comptagesvelo2015.csv,DbCL-1.0,The dataset contains information about the number of bicycles that used certain bicycle lanes in Montreal in the year 2015.,.csv
Moore's Law?,1,moores-law,supercomputerpowerflops new.csv,CC0-1.0,"this graph was created in Loocker and OurDataWorld: 

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F8833be286bac86584e91d6c2697b44e3%2Fgraph3.jpg?generation=1713208055062217&alt=media)

Moore’s Law has held true for more than half a century
In 1965, Gordon Moore predicted that this growth would continue for another 10 years, at least. Was he right?

In the chart, we’ve visualized the growth in transistor density – the number of transistors on integrated circuits – from 1970 onwards.

It looks strikingly similar to Moore’s simple plot from 1965. Note again that the transistor count is on a logarithmic axis, so the linear relationship over time means that the growth rate has been constant.

This means that the growth of the transistor count has, in fact, been exponential. You can also see this on our interactive chart, which shows the average transistor count over time and where you can switch between a linear and a log axis.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F16b596de0567182110ad0fd38d2f2581%2Fgraph2.png?generation=1713208071057914&alt=media)

Transistor counts have doubled approximately every two years, just as Moore predicted.

This has held true for more than 50 years now.

Since its inception in 1965, Moore's Law has stood as a guiding principle for the relentless pace of technological advancement. Coined by Gordon E. Moore, one of the visionaries behind Intel, this observation has become a cornerstone of the digital age, shaping our expectations and driving innovation forward.

At its core, Moore's Law is not a decree etched in stone but rather a testament to the remarkable trajectory of technological progress. It highlights a fascinating trend: the doubling of transistors on computer chips approximately every two years. Moore himself sketched this phenomenon on a logarithmic scale, revealing a straight line that symbolized the constancy of exponential growth.

In his original proclamation, Moore dared to predict the future, envisioning a landscape where this exponential surge would persist unabated. ""There is no reason to believe it will not remain constant for at least 10 years,"" he hypothesized, demonstrating both his insight and audacity.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F5d526c896d257a02b3885edf5c55611a%2Fgraph1.png?generation=1713208087276523&alt=media)

Over the decades, Moore's Law has become more than just an observation; it's a mantra for the tech industry, a rallying cry for progress. It has fueled a perpetual race towards smaller, faster, and more powerful computing devices. From the bulky mainframes of yesteryears to the sleek smartphones of today, every leap forward stands as a testament to this enduring principle.

Yet, Moore's Law is not without its skeptics. Some have questioned its sustainability in the face of physical limitations and economic constraints. As transistors approach atomic scales and production costs escalate, the once-unstoppable march of Moore's Law seems to falter.

But even in the face of skepticism, the spirit of Moore's Law persists. It reminds us of the boundless potential of human ingenuity and the unyielding march of progress. Whether it continues to hold true in its original form or evolves into a new paradigm, Moore's Law remains a symbol of our collective ambition to push the boundaries of what is possible in the realm of technology.",.csv
Most Educated Country in the World,1,most-educated-country-in-the-world,Education by Country.csv,CC0-1.0,"**`Description:`**

This dataset presents the tertiary education rates of the top ten most educated countries in the world. These countries have been ranked based on their tertiary education rates, showcasing their commitment to fostering educated populations and their global prominence in various fields. The dataset highlights the percentage of the population with completed tertiary education for each of these leading nations. With South Korea leading the pack at 69.29%, followed by Canada, Japan, Luxembourg, Ireland, Russia, Lithuania, the United Kingdom, the Netherlands, and Norway, this dataset provides valuable insights into global education trends and the impact of education on socioeconomic development.

**`Columns:`**

Country: Name of the country
Tertiary_Education_Rate: Percentage of the population with completed tertiary education
Potential Applications:

- Comparative analysis of tertiary education rates among the top educated countries
- Understanding the correlation between education levels and socioeconomic indicators
- Identifying factors contributing to high educational attainment in leading nations
- Benchmarking educational policies and initiatives against top-performing countries",.csv
Most Subscribed 1000 Youtube Channels,1,most-subscribed-1000-youtube-channels,topSubscribed.csv,CC0-1.0,"**What is the most subscribed YouTube Channel?**

Indian music network **T-Series** had the most YouTube subscribers in the world as of November 2022, with 229 million users following the channel. YouTube Movies ranked second with roughly 158 million subscribers.

**How many hours of video are uploaded to YouTube every minute?**

**YouTube** was launched in 2005 as a platform for sharing user-generated videos such as vlogs, tutorials, or original series. The site grew rapidly and reportedly had 100 million video views per day and more than 65 thousand daily uploads only a year later. As of February 2020, more than 500 hours of video were uploaded to YouTube every minute, up from a mere 24 hours of content uploads per minute in 2010.

**Highest earning YouTubers**

In November 2022, **MrBeast** surpassed long-standing most subscribed YouTuber **PewDiePie**, having reached approximately 112 million subscribers. Due to the high number of subscribers and even higher number of views, these out-of-the-box stars not only have millions of fans, but also considerable earnings from their YouTube activities. In 2021, MrBeast was estimated to have earned around 54 million U.S. dollars, topping the ranking of the highest-earning YouTube creators.

**YouTube Partner Program**

In the third quarter of 2022, **YouTube’s** ad revenue amounted to over seven billion U.S. dollars. Through its Partner Program, YouTube also rewards uploaders of popular videos with a share of the advertising revenues the content generates. This, paired with the fact that many users of the video sharing platform tend to have favorite channels that they revisit regularly, has given rise to another phenomenon: YouTube celebrities. Although some of these well-known figures were discovered on the website but then carved a successful career outside of YouTube, for many others the site is their primary platform for delivering content and staying in contact with fans, all while signing lucrative deals or promotional partnerships",.csv
Most Subscribed YouTube Channel,1,most-subscribed-youtube-channel,Most Subscribed YouTube Channels_exported.csv,CC0-1.0,"This dataset explores YouTube channel information. It includes:

Channel Names
Brand Focus (Gaming, Music, etc.)
Subscriber Base (Millions)
Primary Languages
Content Categories (Broad & Specific)
Country of Origin
This data allows you to:

Analyze trends by language, category, and region.
Identify popular content areas in various locations.
Benchmark channel performance.
Understand viewer demographics for different content types.
By leveraging this dataset, you can gain valuable insights into YouTube's content landscape, audience makeup, and evolving trends.",.csv
Most Subscribed YouTube Channels ,1,top-youtube-channels-data,most_subscribed_youtube_channels.csv,ODC Public Domain Dedication and Licence (PDDL),"YouTube is an American online video sharing and social media platform headquartered in San Bruno, California. It was launched on February 14, 2005, by Steve Chen, Chad Hurley, and Jawed Karim. Owned by Google, it is the second most visited website, right after Google itself. YouTube has more than one billion monthly users who collectively watch more than one billion hours of videos each day. As of May 2019, videos were being uploaded at a rate of more than 500 hours of content per minute. 

YouTube has had an unprecedented social impact, influencing popular culture, internet trends, and creating multimillionaire celebrities. Despite all its growth and success, YouTube has been widely criticized. Criticism of YouTube includes the website being used to facilitate the spread of misinformation, copyright issues, routine violations of its users' privacy, enabling censorship, and endangering child safety and wellbeing.",.csv
Most Watched Movies and TV Shows,1,most-watched-movies-and-tv-shows,flixpatrol.csv,CC0-1.0,"Explore a comprehensive TV Show Watchtime Dataset for 2024, showcasing top shows based on premiere year, genre, and total watchtime in millions. Genres span Action, Drama, Thriller, Fantasy, and Crime. Gain insights into viewer engagement in the dynamic landscape of television entertainment.",.csv
Most watched Netflix original shows (TV Time),1,most-watched-netflix-original-shows-tv-time,imdb.csv,CC0-1.0,"This file consists of data from Imdb stating the most watched Netflix original shows globally. This contains columns which tells us the timing of the each episode or in total, rating, genre and number of votes given to each of them.",.csv
Motorcycle Dataset,1,motorcycle-dataset,BIKE DETAILS.csv,DbCL-1.0,"This dataset contains information about used motorcycles
This data can be used for a lot of purposes such as price prediction to exemplify the use of linear regression in Machine Learning.
*The columns in the given dataset are as follows:*
1. name
2. selling price
3. year
4. seller type
5. owner
6. km driven
7. ex showroom price


####  **For** **used** **car** **datasets** **please** **go** **to**  *https://www.kaggle.com/nehalbirla/vehicle-dataset-from-cardekho* ",.csv
Movie Rating DataSet,1,movie-rating-dataset,tmdb_5000_movies.csv,CC0-1.0,"This Data About **Movie Voting** and their best rating.
This Data have **20** Columns and **4804** Rows. And In this dataset how was the **popularity** of a movie and their characters and how was the release date of the movie revenue , status , title , movie language , average vote ,id and more..

**Column Names:**

1.**Budget**

2.**Genres**

3.**Homepage**

4.**Id**

5.**Keywords**

6.**Original_language**

7.**Original_title**

8.**Overview**

9.**Popularity**

10.**Production_companies**

11.**Production_countries**

12.**Release_date**

13.**Revenue**

14.**Runtime**

15.**Spoken_languages**

16.**Status**

17.**Tagline**

18.**Title**	

19.**Vote_average**

20.**Vote_count**
",.csv
Movie Time!,1,movie-time,movie_metadata.csv,MIT,"This movie dataset comprises detailed information on 5,043 films, capturing a wide array of characteristics that include both artistic and commercial elements of cinema. Each entry in the dataset provides comprehensive data points such as:

- **Color**: Indicates whether the movie is in color or black and white.
- **Director Information**: Name of the director, number of reviews for the director's films, and the director’s Facebook likes.
- **Actor Information**: Names of the top three actors, their Facebook likes, and other relevant social metrics.
- **Performance Metrics**: Box office gross, number of user reviews, and the number of votes on IMDb.
- **Content Descriptions**: Genres, plot keywords, number of faces on the poster, and links to IMDb pages.
- **Production Details**: Movie title, year of release, language, country of origin, content rating (e.g., PG-13), and production budget.
- **Social Media Metrics**: Facebook likes for the movie.
- **Cinematographic Aspects**: Aspect ratio and IMDb score.

The dataset includes URL links to IMDb for each film, allowing for easy access to additional detailed descriptions and user interactions. This dataset is especially useful for analysis in film studies, marketing, and predictive analytics concerning movie success and viewer preferences. It serves as a comprehensive resource for exploring trends in film genres, directorial success, and the impact of social media on film popularity.",.csv
"Movies Dataset (Netflix, Prime Video, Disney+)",1,movies-dataset-netflix-prime-video-disney,MoviesOnStreamingPlatforms.csv,CC0-1.0,"Movies on Streaming Platforms Dataset

This dataset contains detailed information about movies that are available on various streaming platforms, which has been thoroughly gathered via web scraping techniques.

Content Details

- The data includes unique identifiers for each movie, the title of the film, the release year, and age rating, alongside the Rotten Tomatoes score.
- It specifies whether a movie is available on major streaming platforms such as Netflix, Hulu, Prime Video, and Disney+.
- With 9515 unique values for movie titles, the dataset covers a wide range of cinematic works, from classics to recent releases.
- The dataset spans over a century of movie releases, from as early as 1914 to 2021.

Use Cases and Inspiration

- The dataset can be used to quickly identify on which streaming platforms a specific movie title is available, aiding viewers in their content selection.
- Researchers and marketers can analyze the dataset to find trends in the types of movies offered by different platforms, their release years, and the critical reception reflected by Rotten Tomatoes scores.
- One could explore the relationship between the target age group of movies and the streaming services they are found on, providing insights into platform content strategies.
- The dataset can serve as a foundation for recommendation systems, market competition analysis between streaming services, and studies on the impact of age ratings on a movie's streaming presence.

Column Descriptions

- ID: A unique identifier for each movie within the dataset.
- Title: The full title of the movie as it appears on the streaming platforms.
- Year: The release year of the movie, indicating when the movie was first made available to the public.
- Age: The recommended age group for the movie's audience, such as '7+', '13+', '16+', or '18+'.
- Rotten Tomatoes: The movie's score on Rotten Tomatoes, which reflects critics' reviews and can be used as a measure of the movie's reception.
- Netflix: A binary indicator (0 or 1) of whether the movie is available on Netflix, with 1 indicating availability.
- Hulu: A binary indicator (0 or 1) of whether the movie is available on Hulu.
- Prime Video: A binary indicator (0 or 1) of whether the movie is available on Amazon Prime Video.
- Disney+: A binary indicator (0 or 1) of whether the movie is available on Disney+.
- Type: A categorical indicator distinguishing the content as either a 'Movie' or a 'TV Show'.

Additional Dataset Attributes

- Each row in the dataset represents a single movie, with its corresponding attributes spread across the aforementioned columns.
- The dataset is comprehensive and potentially updated regularly, ensuring a current snapshot of movies across major streaming platforms.
- There are columns for additional streaming platforms, which can be included in the analysis as needed.
- Some entries may have missing values, especially in age ratings, which could be due to various factors such as the movie being unrated or newly released.",.csv
Movies Dataset TMDB,1,movies-dataset-tmdb,movies.csv,CC0-1.0,"The dataset was meticulously curated using the TMDb API, which offers a wealth of movie-related information. Leveraging this API, I extracted pertinent attributes such as movie titles, overview, release dates, popularity, vote count, and vote average, compiling them into a structured CSV format. This initiative was driven by the aspiration to investigate trends in the movie industry, comprehend audience preferences, and potentially develop predictive models for tasks like movie recommendation and box office performance prediction. By providing a meticulously sourced dataset from a reputable platform like TMDb, I aim to facilitate comprehensive analysis and foster further exploration in the domain of movie analytics and entertainment industry studies.",.csv
"Movies on Netflix, Prime Video, Hulu and Disney+",1,movies-on-netflix-prime-video-hulu-and-disney,MoviesOnStreamingPlatforms.csv,CC0-1.0,"### Content
The dataset contains data that was scraped, which comprised a comprehensive list of movies available on various streaming platforms

### Inspiration

- Which streaming platform(s) can I find this movie on?  
- Target age group movies vs the streaming application they can be found on",.csv
Movies on OTT platforms,1,movies-on-ott-platforms,MoviesOnStreamingPlatforms_updated.csv,CC0-1.0,"# **Content**
The dataset is an amalgamation of:
-data that was scraped, which comprised a comprehensive list of movies available on various streaming platforms
-IMDb dataset

# **Inspiration**
Which streaming platform(s) can I find this movie on?
Average IMDb ratings of a movie produced in a country?
Target age group movies vs the streaming application they can be found on
The year during which a movie was produced and the streaming platform they can be found on
Analysis of the popularity of a movie vs directors
Data visualization of the above can be found",.csv
Multiple Linear Regression Dataset,1,multiple-linear-regression-dataset,multiple_linear_regression_dataset.csv,CC0-1.0,This is a very simple multiple linear regression dataset for beginners. This dataset has only three columns and twenty rows. There are only two independent variables and one dependent variable. The independent variables are 'age' and 'experience'. The dependent variable is 'income'. ,.csv
Multiple Sclerosis Disease,1,conversion-predictors-of-cis-to-multiple-sclerosis,conversion_predictors_of_clinically_isolated_syndrome_to_multiple_sclerosis.csv,other,"Prospective cohort study was conducted in Mexican mestizo patients newly diagnosed with CIS who presented at the National Institute of Neurology and Neurosurgery (NINN) in Mexico City, Mexico, between 2006 and 2010. 

**Multiple sclerosis (MS)**: 
""Is the most common demyelinating disease, in which the insulating covers of nerve cells in the brain and spinal cord are damaged. This damage disrupts the ability of parts of the nervous system to transmit signals, resulting in a range of signs and symptoms, including physical, mental, and sometimes psychiatric problems. Specific symptoms can include double vision, visual loss, muscle weakness, and trouble with sensation or coordination.  MS takes several forms, with new symptoms either occurring in isolated attacks (relapsing forms) or building up over time (progressive forms). In the relapsing forms of MS, between attacks, symptoms may disappear completely, although some permanent neurological problems often remain, especially as the disease advances.

While the cause is unclear, the underlying mechanism is thought to be either destruction by the immune system or failure of the myelin-producing cells. Proposed causes for this include genetics and environmental factors, such as viral infections. MS is usually diagnosed based on the presenting signs and symptoms and the results of supporting medical tests. 
No cure for multiple sclerosis is known. Treatments attempt to improve function after an attack and prevent new attacks.[9] Physical therap and occupational therapy can help with people's ability to function. Many people pursue alternative treatments, despite a lack of evidence of benefit.[18] The long-term outcome is difficult to predict; better outcomes are more often seen in women, those who develop the disease early in life, those with a relapsing course, and those who initially experienced few attacks.

Multiple sclerosis is the most common immune-mediated disorder affecting the central nervous system.[20] Nearly one million people have MS in the United States in 2022, and in 2020, about 2.8 million people were affected globally, with rates varying widely in different regions and among different populations. The disease usually begins between the ages of 20 and 50 and is twice as common in women as in men. MS was first described in 1868 by French neurologist Jean-Martin Charcot. The name ""multiple sclerosis"" is short for multiple cerebro-spinal sclerosis, which refers to the numerous glial scars (or sclerae – essentially plaques or lesions) that develop on the white matter of the brain and spinal cord."" [Ref1.](https://en.wikipedia.org/wiki/Multiple_sclerosis)

""Multiple sclerosis (MS) begins with an acute clinical attack (clinically isolated syndrome) in approximately 85% of patients. The conversion rate from clinically isolated syndrome to multiple sclerosis has been documented at 30% to 82% in previous studies. When an individual presents for evaluation after a single episode of inflammation of the CNS, several decisions regarding follow-up in subsequent years need to be made, including that of whether or not to start a therapy. There is, therefore, an emerging need to identify the predictive factors that anticipate conversion from CIS to MS."" [Ref2.](https://pubmed.ncbi.nlm.nih.gov/32570179/)

**Note**: This data was collected in a study conducted in Mexican mestizo patients newly diagnosed with CIS who presented at the National Institute of Neurology and Neurosurgery (NINN) in Mexico City, Mexico, between 2006 and 2010. 

**Citation**: 
Pineda, Benjamin; Flores Rivera, Jose De Jesus (2023), “Conversion predictors of Clinically Isolated Syndrome to Multiple Sclerosis in Mexican patients: a prospective study.”, Mendeley Data, V1, doi: 10.17632/8wk5hjx7x2.1

**License**: 
CC BY 4.0

**Dataset column descriptions**

1. ID: Patient identifier (int)
2. Age: Age of the patient (in years)
3. Schooling: time the patient spent in school (in years) 
4. Gender: 1=male, 2=female
5. Breastfeeding: 1=yes, 2=no, 3=unknown
6. Varicella: 1=positive, 2=negative, 3=unknown
7. Initial_Symptoms: 1=visual, 2=sensory, 3=motor, 4=other, 5= visual and sensory, 6=visual and motor, 7=visual and others, 8=sensory and motor, 9=sensory and other, 10=motor and other, 11=Visual, sensory and motor, 12=visual, sensory and other, 13=Visual, motor and other, 14=Sensory, motor and other, 15=visual,sensory,motor and other
8. Mono _or_Polysymptomatic: 1=monosymptomatic, 2=polysymptomatic, 3=unknown
9. Oligoclonal_Bands: 0=negative, 1=positive, 2=unknown
10. LLSSEP: 0=negative, 1=positive
11. ULSSEP:0=negative, 1=positive
12. VEP:0=negative, 1=positive
13. BAEP: 0=negative, 1=positive
14. Periventricular_MRI:0=negative, 1=positive
15. Cortical_MRI: 0=negative, 1=positive
16. Infratentorial_MRI:0=negative, 1=positive
19. Spinal_Cord_MRI: 0=negative, 1=positive
18. initial_EDSS:?
19. final_EDSS:?
20. Group: 1=CDMS, 2=non-CDMS


### Definition of some of the technical/medical terms [ref. from wikipedia if not stated explicitly].

- **Varicella** : Another name for Chickenpox, or chicken pox, is a highly contagious disease caused by the initial infection with varicella zoster virus (VZV), a member of the herpesvirus family. 

- **BAEP**: In human neuroanatomy, brainstem auditory evoked potentials (BAEPs), also called brainstem auditory evoked responses (BAERs), are very small auditory evoked potentials in response to an auditory stimulus, which are recorded by electrodes placed on the scalp. 

- **VEP**: Visual evoked potential (VEP) is an evoked potential elicited by presenting light flash or pattern stimulus which can be used to confirm damage to visual pathway including retina, optic nerve, optic chiasm, optic radiations, and occipital cortex. 

- **Oligoclonal bands**: Oligoclonal bands (OCBs) are bands of immunoglobulins that are seen when a patient's blood serum, or cerebrospinal fluid (CSF) is analyzed. They are used in the diagnosis of various neurological and blood diseases. Oligoclonal bands are present in the CSF of more than 95% of patients with clinically definite multiple sclerosis. 

- **SSEP** : Somatosensory evoked potentials (SSEP) are recorded from the central nervous system following stimulation of peripheral nerves. ULSSEP (upper limb SSEP), LLSSEP (lower limb SSEP)

- **EDSS**: The Expanded Disability Status Scale (EDSS) is a method of quantifying disability in multiple sclerosis and monitoring changes in the level of disability over time. It is widely used in clinical trials and in the assessment of people with MS. [2](https://mstrust.org.uk/a-z/expanded-disability-status-scale-edss)

-**Oligoclonal_Bands**: ""Oligoclonal bands (OCBs) are bands of immunoglobulins that are seen when a patient's blood serum, or cerebrospinal fluid (CSF) is analyzed. They are used in the diagnosis of various neurological and blood diseases. Oligoclonal bands are present in the CSF of more than 95% of patients with clinically definite multiple sclerosis."" [Ref.3](https://en.wikipedia.org/wiki/Oligoclonal_band)


**Ideas for notebooks:**
- What symptoms/factors are better predictors of MS?
- Classify the two `groups` based of the other independent features.
",.csv
Multivariate Gait Dataset,1,multivariate-gait-dataset,gait.csv,Attribution 4.0 International (CC BY 4.0),"# Multivariate Gait Data

Bilateral (left, right) joint angle (ankle, knee, hip) times series data collected from 10 healthy subjects under 3 walking conditions (unbraced, knee braced, ankle braced). For each condition, each subject’s data consists of 10 consecutive gait cycles.

- Dataset Characteristics : Sequential, Multivariate, Time-Series

- Subject Area: Health and Medicine

- Associated Tasks: Classification, Regression, Clustering

- Feature: Type: Real, Categorical, Integer

- Instances: 181800

-  Features: 7

# Dataset Information

**For what purpose was the dataset created?**
Biomechanical analysis of human locomotion

**Who funded the creation of the dataset?**
National Science Foundation (#0540834) and Mary Jane Neer Disability Research Fund at the University of Illinois

**Has Missing Values?**
No

# Additional Information

This dataset is a six dimensional array of joint angle data: 10 subjects x 3 conditions x 10 replications x 2 legs x 3 joints x 101 time points. The data were recored from ten subjects under three different conditions: normal (unbraced) walking on a treadmill, walking on a treadmill with a knee-brace on the right knee, and walking on a treadmill with an ankle brace on the right ankle. For each subject in each condition, ten consecutive gait cycles (replications) are included, where each gait cycle starts and ends at heel-strike. For each gait cycle, the data were normalized to consist of 101 time points representing 0%,…,100% of the gait cycle. Six joint angles are included, which comprise all combinations of leg (left and right) and joint (ankle, knee, hip). The data were collected at the Human Dynamics and Controls Laboratory at the University of Illinois at Urbana-Champaign. Details of the experimental setup can be found in Shorter et al. (2008). Details on the data preprocessing can be found in Helwig et al. (2011). The data were published as supplementary materials by Helwig et al. (2016). 

# Attribute Information

1. subject: 1 = subject 1, …, 10 = subject 10 (integer)
2. condition: 1 = unbraced, 2 = knee brace, 3 = ankle brace (integer)
3. replication: 1 = replication 1, …, 10 = replication 10 (integer)
4. leg: 1 = left, 2 = right (integer)
5. joint: 1 = ankle, 2 = knee, 3 = hip (integer)
6. time: 0 = 0% gait cycle, …, 100 = 100% gait cycle (integer)
7. angle: joint angle in degrees (real valued)

# Introductory Paper
**Link:** [https://pubmed.ncbi.nlm.nih.gov/27553848/](url) 
**Title:** Smoothing spline analysis of variance models: A new tool for the analysis of cyclic biomechanical data
**Authors:** Nathaniel E. Helwig, K. A. Shorter, Ping Ma, E. Hsiao-Wecksler. 2016 
**Journal:** Journal of Biomechanics

# Cite
`Helwig,Nathaniel and Hsiao-Wecksler,Elizabeth. (2022). Multivariate Gait Data. UCI Machine Learning Repository. https://doi.org/10.24432/C5861T.`

`@misc{misc_multivariate_gait_data_760,
  author       = {Helwig,Nathaniel and Hsiao-Wecksler,Elizabeth},
  title        = {{Multivariate Gait Data}},
  year         = {2022},
  howpublished = {UCI Machine Learning Repository},
  note         = {{DOI}: https://doi.org/10.24432/C5861T}
}`

# Acknowledgement

Any use of these data should cite the following three papers and include a statement along the lines of “The data were collected by Shorter et al. (2008), preprocessed by Helwig et al. (2011), and published by Helwig et al. (2016).”

# Introductory Paper Abstract

Cyclic biomechanical data are commonplace in orthopedic, rehabilitation, and sports research, where the goal is to understand and compare biomechanical differences between experimental conditions and/or subject populations. A common approach to analyzing cyclic biomechanical data involves averaging the biomechanical signals across cycle replications, and then comparing mean differences at specific points of the cycle. This pointwise analysis approach ignores the functional nature of the data, which can hinder one׳s ability to find subtle differences between experimental conditions and/or subject populations. To overcome this limitation, we propose using mixed-effects smoothing spline analysis of variance (SSANOVA) to analyze differences in cyclic biomechanical data. The SSANOVA framework makes it possible to decompose the estimated function into the portion that is common across groups (i.e., the average cycle, AC) and the portion that differs across groups (i.e., the contrast cycle, CC). By partitioning the signal in such a manner, we can obtain estimates of the CC differences (CCDs), which are the functions directly describing group differences in the cyclic biomechanical data. Using both simulated and experimental data, we illustrate the benefits of using SSANOVA models to analyze differences in noisy biomechanical (gait) signals collected from multiple locations (joints) of subjects participating in different experimental conditions. Using Bayesian confidence intervals, the SSANOVA results can be used in clinical and research settings to reliably quantify biomechanical differences between experimental conditions and/or subject populations.
",.csv
Museum Universe Data File,1,museum-universe-data-file,museum-universe-data-file-fy-2015-q3-et8i-mnha.csv,CC0-1.0,"DESCRIPTION
The Museum Universe Data File is an evolving list of museums and related organizations in the United States.
SUMMARY
The Museum Universe Data File is an evolving list of museums and related organizations in the United States. It includes basic information on aquariums, arboretums, botanical gardens, art museums, children’s museums, general museums, historic houses and sites, history museums, nature centers, natural history and anthropology museums, planetariums, science and technology centers, specialized museums, and zoos.

References and Resources
Museum Universe Data File FY 2015 Q3 - Most Current as of 2018-11-20
Canonical Source
Interactive Dataset
Data Table
Documentation (PDF)
GeoJSON
CSV Data File (ZIP)
API
JSON",.csv
"Museums, Aquariums, and Zoos",1,museum-directory,museums.csv,CC0-1.0,"# Content

The museum dataset is an evolving list of museums and related organizations in the United States. The data file includes basic information about each organization (name, address, phone, website, and revenue) plus the museum type or discipline. The discipline type is based on the National Taxonomy of Exempt Entities, which the National Center for Charitable Statistics and IRS use to classify nonprofit organizations.

Non-museum organizations may be included. For example, a non-museum organization may be included in the data file because it has a museum-like name on its IRS record for tax-exempt organizations. Museum foundations may also be included.

Museums may be missing. For example, local municipal museums may be undercounted because original data sources used to create the compilation did not include them.

Museums may be listed multiple times. For example, one museum may be listed as both itself and its parent organization because it was listed differently in each original data sources. Duplicate records are especially common for museums located within universities.

Information about museums may be outdated.  The original scan and compilation of data sources occurred in 2014.  Scans are no longer being done to update the data sources or add new data sources to the compilation.  Information about museums may have changed since it was originally included in the file.


# Acknowledgements

The museum data was compiled from IMLS administrative records for discretionary grant recipients, IRS records for tax-exempt organizations, and private foundation grant recipients.


# Inspiration

Which city or state has the most museums per capita? How many zoos or aquariums exist in the United States? What museum or related organization had the highest revenue last year? How does the composition of museum types differ across the country?",.csv
Mushroom Classification,1,mushroom-classification,mushrooms.csv,CC0-1.0,"### Context

Although this dataset was originally contributed to the UCI Machine Learning repository nearly 30 years ago, mushroom hunting (otherwise known as ""shrooming"") is enjoying new peaks in popularity. Learn which features spell certain death and which are most palatable in this dataset of mushroom characteristics. And how certain can your model be?

### Content 

This dataset includes descriptions of hypothetical samples corresponding to 23 species of gilled mushrooms in the Agaricus and Lepiota Family Mushroom drawn from The Audubon Society Field Guide to North American Mushrooms (1981). Each species is identified as definitely edible, definitely poisonous, or of unknown edibility and not recommended. This latter class was combined with the poisonous one. The Guide clearly states that there is no simple rule for determining the edibility of a mushroom; no rule like ""leaflets three, let it be'' for Poisonous Oak and Ivy.

- **Time period**: Donated to UCI ML 27 April 1987

### Inspiration

- What types of machine learning models perform best on this dataset?

- Which features are most indicative of a poisonous mushroom?

### Acknowledgements

This dataset was originally donated to the UCI Machine Learning repository. You can learn more about past research using the data [here][1]. 

#[Start a new kernel][2]


  [1]: https://archive.ics.uci.edu/ml/datasets/Mushroom
  [2]: https://www.kaggle.com/uciml/mushroom-classification/kernels?modal=true",.csv
Mushroom Dataset (Binary Classification),1,mushroom-dataset,mushroom_cleaned.csv,other,"This dataset is a cleaned version of the original [Mushroom Dataset for Binary Classification](https://archive.ics.uci.edu/dataset/848/secondary+mushroom+dataset) Available at UCI Library. This dataset was cleaned using various techniques such as Modal imputation, one-hot encoding, z-score normalization, and feature selection. It contains 9 columns:

1. Cap Diameter
2. Cap Shape
3. Gill Attachment
4. Gill Color
5. Stem Height
6. Stem Width
7. Stem Color
8. Season
9. Target Class - Is it edible or not?

The Target Class contains two values - 0 or 1 - where 0 refers to edible and 1 refers to poisonous.",.csv
Music Composition,1,music-composition,Ramin Compositions.csv,other,"This dataset provides a diverse collection of original music compositions, encompassing various genres, durations, and ensemble arrangements. With metadata including year of creation, duration, title, and ensemble type, researchers and enthusiasts can analyze trends, explore musical diversity, and develop algorithms for music-related tasks.
The score and additional details are available at www.akhavijou.com

This is  a compact music composition dataset, showcasing typical attributes.",.csv
MusicCaps,1,musiccaps,musiccaps-public.csv,CC-BY-SA-4.0,"The MusicCaps dataset contains **5,521 music examples, each of which is labeled with an English *aspect list* and a *free text caption* written by musicians**.

- An aspect list is for example *""pop, tinny wide hi hats, mellow piano melody, high pitched female vocal melody, sustained pulsating synth lead""*.
- The caption consists of multiple sentences about the music, e.g.,  *""A low sounding male voice is rapping over a fast paced drums playing a reggaeton beat along with a bass. Something like a guitar is playing the melody along. This recording is of poor audio-quality. In the background a laughter can be noticed. This song may be playing in a bar.""*

The text is solely focused on describing *how* the music sounds, not the metadata like the artist name.

The labeled examples are 10s music clips from the [**AudioSet**](https://research.google.com/audioset/) dataset (2,858 from the eval and 2,663 from the train split).

Please cite the corresponding paper, when using this dataset: http://arxiv.org/abs/2301.11325 (DOI: `10.48550/arXiv.2301.11325`)",.csv
Mutual Funds India - Detailed ,1,mutual-funds-india-detailed,comprehensive_mutual_funds_data.csv,CC0-1.0,"This dataset was created by web scraping data from various mutual funds in India. 

The dataset is useful for anyone interested in analyzing the performance of mutual funds in India. Analysts can use this dataset to study trends, compare different funds, and gain insights into the Indian mutual fund industry.

Data fields:

Scheme Name: Name of the mutual fund scheme
Min sip: Min sip amount required to start.
Min lumpsum: Min lumpsum amount required to start.
Expense ratio: calculated as a percentage of the Scheme's average Net Asset Value (NAV).
Fund size: the total amount of money that a mutual fund manager must oversee and invest.
Fund age: years since inception of scheme
Fund manager: A fund manager is responsible for implementing a fund's investment strategy and managing its trading activities.
Sortino : Sortino ratio measures the risk-adjusted return of an investment asset, portfolio, or strategy
Alpha: Alpha is the excess returns relative to market benchmark for a given amount of risk taken by the scheme
Standard deviation: A standard deviation is a number that can be used to show how much the returns of a mutual fund scheme are likely to deviate from its average annual returns.
Beta: Beta in a mutual fund is often used to convey the fund's volatility (gains or losses) in relation to its respective benchmark index
Sharpe: Sharpe Ratio of a mutual fund reveals its potential risk-adjusted returns
Risk level: 
1-	Low risk
2-	Low to moderate
3-	Moderate
4-	Moderately High
5-	High
6-	Very High
AMC name: Mutual fund house managing the assets.
Rating: 0-5 rating assigned to scheme
Category: The category to which the mutual fund belongs (e.g. equity, debt, hybrid)
Sub-category : It includes category like Small cap, Large cap, ELSS, etc.
Return_1yr (%): The return percentage of the mutual fund scheme over 1 year.
Return_3yr (%): The return percentage of the mutual fund scheme over 3 year.
Return_5yr (%): The return percentage of the mutual fund scheme over 5year.

Number of instances: The dataset contains data on hundreds of mutual funds available in India.
Data source: The dataset was created by web scraping data from online websites

Disclaimer: The dataset is for educational and research purposes only. The data may not be 100% accurate and users should verify the data before making any investment decisions.
",.csv
My Uber Drives,1,uberdrives,My Uber Drives - 2016.csv,DbCL-1.0,"# Context 

My Uber Drives (2016)

Here are the details of my Uber Drives of 2016. I am sharing this dataset for data science community to learn from the behavior of an ordinary Uber customer.

# Content

Geography:  USA, Sri Lanka and Pakistan

Time period: January - December 2016 

Unit of analysis: Drives

Total Drives: 1,155

Total Miles: 12,204

Dataset: The dataset contains Start Date, End Date, Start Location, End Location, Miles Driven and Purpose of drive (Business, Personal, Meals, Errands, Meetings, Customer Support etc.)


# Acknowledgements & References

Users are allowed to use, download, copy, distribute and cite the dataset for their pet projects and training. Please cite it  as follows: “Zeeshan-ul-hassan Usmani, My Uber Drives Dataset, Kaggle Dataset Repository, March 23, 2017.”

# Past Research

Uber TLC FOIL Response - The dataset contains over 4.5 million Uber pickups in New York City from April to September 2014, and 14.3 million more Uber pickups from January to June 2015
https://github.com/fivethirtyeight/uber-tlc-foil-response

1.1 Billion Taxi Pickups from New York - 
http://toddwschneider.com/posts/analyzing-1-1-billion-nyc-taxi-and-uber-trips-with-a-vengeance/

What you can do with this data - a good example by Yao-Jen Kuo - https://yaojenkuo.github.io/uber.html


# Inspiration

Some ideas worth exploring:

•	What is the average length of the trip?


•	Average number of rides per week or per month?


•	Total tax savings based on traveled business miles?


•	Percentage of business miles vs personal vs. Meals


•	How much money can be saved by a typical customer using Uber, Careem, or Lyft versus regular cab service?",.csv
"NASA Astronauts, 1959-Present",1,astronaut-yearbook,astronauts.csv,CC0-1.0,"# Context 

The term ""astronaut"" derives from the Greek words meaning ""space sailor"" and refers to all who have been launched as crew members aboard NASA spacecraft bound for orbit and beyond.


# Content

The National Aeronautics and Space Administration (NASA) selected the first group of astronauts in 1959. From 500 candidates with the required jet aircraft flight experience and engineering training in addition to a height below 5 feet 11 inches, seven military men became the nation's first astronauts. The second and third groups chosen included civilians with extensive flying experience. By 1964, requirements had changed, and emphasis was placed on academic qualifications; in 1965, six scientist astronauts were selected from a group of 400 applicants who had a doctorate or equivalent experience in the natural sciences, medicine, or engineering. The group named in 1978 was the first of space shuttle flight crews and fourteen groups have been selected since then with a mix of pilots and mission specialists.

There are currently 50 active astronauts and 35 management astronauts in the program; 196 astronauts have retired or resigned and 49 are deceased (as of April 2013).


# Acknowledgements

This dataset was published by the National Aeronautics and Space Administration as the ""Astronaut Fact Book"" (April 2013 edition). Active astronauts' mission names and flight statistics were updated from the NASA website.


# Inspiration

Which American astronaut has spent the most time in space? What university has produced the most astronauts? What subject did the most astronauts major in at college? Have most astronauts served in the military? Which branch? What rank did they achieve?",.csv
NASA | Neo Earth Close Approaches 🚀,1,nasa-neo-earth-close-approaches,NEO Earth Close Approaches.csv,other,"Near-Earth Objects (NEOs) are a category of asteroids whose orbits come close to intersecting Earth’s orbit. These objects are tracked carefully by astronomers due to their potential impact risk with our planet. As they orbit the Sun, NEOs occasionally approach close to Earth.

NASA’s Center for Near-Earth Object Studies (CNEOS) calculates the motion of all NEOs forwards to 2200 A.D. and backwards to 1900 A.D., determining the times and distances of Earth close approaches.

**Object:**

Object primary designation

**Data Description (Variables)**: 

**Close-Approach (CA) Date**

Date and time (TDB) of closest Earth approach. ""Nominal Date"" is given to appropriate precision. The 3-sigma uncertainty in the time is given in the +/- column in days_hours:minutes format (for example, ""2_15:23"" is 2 days, 15 hours, 23 minutes; ""&lt; 00:01"" is less than 1 minute).

**View CA**

Open the close-approach viewer and render the high-precision trajectory during the close approach.

**CA Distance Nominal (au)**

The most likely (Nominal) close-approach distance (Earth center to NEO center), in astronomical units.

**CA Distance Minimum (au)**

The minimum possible close-approach distance (Earth center to NEO center), in astronomical units. The minimum possible distance is based on the 3-sigma Earth target-plane error ellipse.

**V relative (km/s)**

Object velocity relative to Earth at close-approach.

**V infinity (km/s)**

Object velocity relative to a massless Earth at close-approach.

**H (mag)**

Asteroid absolute magnitude (in general, smaller H implies larger asteroid diameter). Undefined for comets.

**Diameter**

Diameter value when known or a range (min - max) estimated using the asteroid's absolute magnitude (H) and limiting albedos of 0.25 and 0.05.

**Rarity**

A measure of how infrequent the Earth close approach is for asteroids of the same size and larger: 0 means an average frequency of 100 per year, i.e., roughly every few days or less, 1 corresponds to roughly once a month, 2 to roughly once a year, 3 to roughly once a decade, etc. 'n/a' means that a frequency estimate is not available.

**Source of Dataset:**

Nasa Website

**[Click Here](https://cneos.jpl.nasa.gov/ca/)** to study more.
",.csv
NASDAQ Historical Prices (2014-2024),1,nasdaq-historical-prices-2014-2024,NASDAQ Historical Prices.csv,CC0-1.0,"**Experience a decade of NASDAQ market dynamics with this comprehensive historical price dataset from 2014 to 2024.**

The NASDAQ Composite is a benchmark index representing the performance of more than 2,500 stocks listed on the NASDAQ stock exchange, encompassing various sectors including technology, healthcare, and finance. This dataset, sourced meticulously from Yahoo Finance, offers daily insights into the index's opening, highest, lowest, and closing prices, along with adjusted close prices and daily volume.",.csv
NBA 2k20 player dataset,1,nba2k20-player-dataset,nba2k-full.csv,CC0-1.0,"### Context

NBA 2k analysis.


### Content

Detailed attributes for players registered in the NBA2k.


### Acknowledgements

Data scraped from https://hoopshype.com/nba2k/. Additional data about countries and drafts scraped from Wikipedia.


### Inspiration

Inspired from this dataset: https://www.kaggle.com/karangadiya/fifa19",.csv
NBA Players stats(2023 season),1,nba-players-stats2023-season,2023_nba_player_stats.csv,Community Data License Agreement - Sharing - Version 1.0,"**Predicting basketball points for each player is of utmost importance in the world of basketball analytics. It serves as a crucial performance metric that allows coaches, analysts, and fans to assess a player's scoring ability and overall offensive contribution to the team. Understanding players' scoring potential aids in strategic decision-making during games, player selection, and talent scouting.**🏀


|Description|Column|
|:------:|:--------:|
|The name of the basketball player|<code>PName</code>|
|The player's position in the game, including 'N/A'|<code>POS</code>|
|The abbreviation of the team the player is currently playing for this season|<code>Team</code>|
|The age of the player|<code>Age</code>|
|The total number of games the player has played in this season|<code>GP</code>|
|The total number of games won by the player|<code>W</code>|
|The total number of games lost by the player|<code>L</code>|
|The total minutes the player has played in this season|<code>Min</code>|
|<b>The total points made by the player [target]</b>|<code>PTS</code>|
|The total number of field goals made by the player|<code>FGM</code>|
|The total number of field goals attempted by the player|<code>FGA</code>|
|The percentage of successful field goals made by the player|<code>FG%</code>|
|The total number of 3-point field goals made by the player|<code>3PM</code>|
|The total number of 3-point field goals attempted by the player|<code>3PA</code>|
|The percentage of successful 3-point field goals made by the player|<code>3P%</code>|
|The total number of free throws made by the player|<code>FTM</code>|
|The total number of free throws attempted by the player|<code>FTA</code>|
|The percentage of successful free throws made by the player|<code>FT%</code>|
|The total number of offensive rebounds made by the player|<code>OREB</code>|
|The total number of defensive rebounds made by the player|<code>DREB</code>|
|The total number of rebounds (offensive + defensive) made by the player|<code>REB</code>|
|The total number of assists made by the player|<code>AST</code>|
|The total number of turnovers made by the player|<code>TOV</code>|
|The total number of steals made by the player|<code>STL</code>|
|The total number of blocks made by the player|<code>BLK</code>|
|The total number of personal fouls made by the player|<code>PF</code>|
|The total number of NBA fantasy points made by the player|<code>FP</code>|
|The total number of double-doubles made by the player|<code>DD2</code>|
|The total number of triple-doubles made by the player|<code>TD3</code>|
|The total difference between the player's team scoring and the opponents' scoring while the player is in the game|<code>+/-</code>|


You can also check out my notebook for more information about the dataset.",.csv
NBA player of the week,1,nba-player-of-the-week,NBA_player_of_the_week.csv,CC0-1.0,"### Context

The idea of making this data set is to explore regular season domination.  
is seniority / last contract year etc. has an affect on the long run,
or any insignificance conclusion can be made.

any analysis & add data are welcomed

### Content

NBA_player_of_the_week.csv

Contains all granular available player of the week award data 

### Acknowledgements

Scraping source code: [GitHub Repository][3]
Data scraped from [basketball real gm][1]

Photo by [Ricardo Resende on Unsplash][2]


  [1]: https://basketball.realgm.com/
  [2]: https://unsplash.com/photos/HVOwuodWbu0
  [3]:https://github.com/jacobbaruch/NBA_scrapping_analysis",.csv
NCAA Men 538 team ratings,1,ncaa-men-538-team-ratings,538ratingsMen.csv,CC0-1.0,"FiveThirtyEight (https://fivethirtyeight.com/) is a great tool to track NCAA March Madness. Since 2016 it has shared its own team rankings. This dataset contains all team rankings available for men NCAA tournament.

Data taken from:
https://projects.fivethirtyeight.com/march-madness-api/2016/fivethirtyeight_ncaa_forecasts.csv
https://projects.fivethirtyeight.com/march-madness-api/2017/fivethirtyeight_ncaa_forecasts.csv
https://projects.fivethirtyeight.com/march-madness-api/2018/fivethirtyeight_ncaa_forecasts.csv
https://projects.fivethirtyeight.com/march-madness-api/2019/fivethirtyeight_ncaa_forecasts.csv
https://projects.fivethirtyeight.com/march-madness-api/2021/fivethirtyeight_ncaa_forecasts.csv
https://projects.fivethirtyeight.com/march-madness-api/2022/fivethirtyeight_ncaa_forecasts.csv
https://projects.fivethirtyeight.com/march-madness-api/2023/fivethirtyeight_ncaa_forecasts.csv",.csv
NCAA Women 538 team ratings,1,ncaa-women-538-team-ratings,538ratingsWomen.csv,CC0-1.0,"FiveThirtyEight (https://fivethirtyeight.com/) is a great tool to track NCAA March Madness. Since 2016 it has shared its own team rankings. This dataset contains all team rankings available for women NCAA tournament.

Data taken from:
https://projects.fivethirtyeight.com/march-madness-api/2016/fivethirtyeight_ncaa_forecasts.csv
https://projects.fivethirtyeight.com/march-madness-api/2017/fivethirtyeight_ncaa_forecasts.csv
https://projects.fivethirtyeight.com/march-madness-api/2018/fivethirtyeight_ncaa_forecasts.csv
https://projects.fivethirtyeight.com/march-madness-api/2019/fivethirtyeight_ncaa_forecasts.csv
https://projects.fivethirtyeight.com/march-madness-api/2021/fivethirtyeight_ncaa_forecasts.csv
https://projects.fivethirtyeight.com/march-madness-api/2022/fivethirtyeight_ncaa_forecasts.csv
https://projects.fivethirtyeight.com/march-madness-api/2023/fivethirtyeight_ncaa_forecasts.csv",.csv
NCHS - Leading Causes of Death: United States,1,nchs-leading-causes-of-death-united-states,NCHS_-_Leading_Causes_of_Death__United_States.csv,U.S. Government Works,"This dataset presents the age-adjusted death rates for the 10 leading causes of death in the United States beginning in 1999.

Data are based on information from all resident death certificates filed in the 50 states and the District of Columbia using demographic and medical characteristics. Age-adjusted death rates (per 100,000 population) are based on the 2000 U.S. standard population. Populations used for computing death rates after 2010 are postcensal estimates based on the 2010 census, estimated as of July 1, 2010. Rates for census years are based on populations enumerated in the corresponding censuses. Rates for non-census years before 2010 are revised using updated intercensal population estimates and may differ from rates previously published.

Causes of death classified by the International Classification of Diseases, Tenth Revision (ICD–10) are ranked according to the number of deaths assigned to rankable causes. Cause of death statistics are based on the underlying cause of death.",.csv
NER Data,1,ner-data,ner.csv,DbCL-1.0,"### Context
Mainly created to run the notebook for NER using Pretrained Language Models- https://www.kaggle.com/rajnathpatel/ner-using-pretrained-language-models


### Content

The data has 3 columns, 1. Text, 2. Labels, 3. class- True if there is no annotation False otherwise 


### Acknowledgements

This is a processed version of- https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus",.csv
NFL Offensive Stats 2019 - 2022,1,nfl-offensive-stats-2019-2022,nfl_offensive_stats.csv,CC0-1.0,"This dataset includes NFL offensive statistics for all players from 2019-2022. Passing yards, rushing yards, receiving yards, etc. 

This dataset was inspired by my love of football and the NFL.

",.csv
NFL Passing Statistics (2001-2023),1,nfl-passing-statistics-2001-2023,passing_cleaned.csv,CC0-1.0,"NFL passing statistics since 2001. Contains record of every player who attempted a pass within the time period. Tracked metrics include passing yards, passing touchdowns, pass attempts, completions, interceptions, and touchdown/interception/completion percentages. More advanced metrics like yards per attempt, adjusted net yards per attempt, and other similar metrics are also included. I used this dataset, accompanied with the NFL Rushing Statistics dataset to predict the NFL MVP winner in 2024.",.csv
NFL Rushing Statistics (2001-2023),1,nfl-rushing-statistics-2001-2023,rushing_cleaned.csv,CC0-1.0,"NFL rushing statistics since 2001. Contains record of every player who attempted a rush within the time period. Tracked metrics include rushing yards, rushing touchdowns, rush attempts, and fumbles. More advanced metrics like yards per attempt, adjusted net yards per attempt, and other similar metrics are also included. I used this dataset, accompanied with the NFL Passing Statistics dataset to predict the NFL MVP winner in 2024.",.csv
NFL Team Data 2003-2023,1,nfl-team-data-2003-2023,team_stats_2003_2023.csv,CC0-1.0,"**Context**

I was interested in analyzing how NFL offenses have evolved over the modern era. I used [www.pro-football-reference.com](url) to find the data that I was interested in analyzing. I used Python BeautifulSoup4 and a selenium Webdriver to pull the html data from the website and load it into a DataFrame for analysis.

**Content**

There is currently data on 672 Teams across 21 seasons. The stats included are regarding team record, passing, rushing, penalties, turnovers, and more. 
The file `team_stats_2003_2023.csv` contains 35 variables outlined below. ",.csv
NFL Team Stats 2002 - Feb. 2024 (ESPN),1,nfl-team-stats-20022019-espn,nfl_team_stats_2002-2023.csv,CC0-1.0,"**Dataset is updated through the 2023-24 season.**

All data is scraped from ESPN's *Team Stats* page for each game. Seasons include all regular season games plus all playoff games.

Any errors or quirks in ESPN's data will be present in this dataset. For example, redzone conversions are missing prior to the 2006-07 season.",.csv
NHANES Dataset,1,original-dataset,combined_data.csv,CC0-1.0,"Liver steatosis scores (CAP Score) were investigated using data from the National Center for Health Statistics examination survey (NHANES) for 2017-2018 and 2017-March 2020. The datasets include demographics, dietary, examination, laboratory, and questionnaire databases. Each dataset consists of a set of SAS files converted to CSV files using the SAS Viewer software. The selected variables for this analysis are systolic and diastolic blood pressure, total cholesterol, insulin, triglycerides, elasticity score, and CAP scores. Before data cleaning, the total number of records was 8,056 with ten columns. However, after data cleaning, the remaining records used in the analysis were 6,394, with only six columns. ",.csv
NHIS Vision and Eye Health Surveillance Dataset,1,nhis-vision-and-eye-health-surveillance-dataset,NHIS_Vision_and_Eye_Health_Surveillance_20240501.csv,CC0-1.0,"# Dataset Information : 
&gt;This dataset is a de-identified summary table of vision and eye health data indicators from NHIS, stratified by all available combinations of age group, race/ethnicity, gender, and risk factor. NHIS is an annual household survey conducted by the National Center for Health Statistics at CDC that monitors trends in illness, disabilities, and progress towards national health objectives. Approximate sample size is 35,000 households and 87,500 persons annually. NHIS data for VEHSS includes questions related to Visual Function. Data were suppressed for cell sizes less than 30 persons, or where the relative standard error more than 30% of the mean. Data will be updated as it becomes available. Detailed information on VEHSS NHIS analyses can be found on the VEHSS NHIS webpage (link). Additional information about NHIS can be found on the NHIS website (http://www.cdc.gov/nchs/nhis/about_nhis.htm). The VEHSS NHIS dataset was last updated in November 2019.

# Columns :
|Column Name|Description|	Type|
|--|--|--|
YearStart|Starting year for year range|Number|
YearEnd|Ending year for year range. Same as starting year if single year used in evaluation.|Number|
LocationAbbr|Location abbreviation|Plain Text|
LocationDesc|Location full name|Plain Text|
DataSource|Abbreviation of Data Source|Plain Text|
Topic|Topic description|Plain Text|
Category|Category description|Plain Text|
Question|Question description (e.g., Percentage of adults with diabetic retinopathy)|Plain Text|
Response|Optional column to hold the response value that was evaluated.|Plain Text|
Age|Stratification value for age group (e.g., All ages, 0-17 years, 18-39 years, 40-64 years, 65-84 years, or 85 years and older)|Plain Text|
Gender|Stratification value for gender (e.g., Total, Male, or Female)|Plain Text|
RaceEthnicity|Stratification value for race (e.g., All races, Asian, Black, non-hispanic, Hispanic, any race, North American Native, White, non-hispanic, or Other)|Plain Text|
RiskFactor|Stratification value for major risk factor (e.g., All Participants, Diabetes, Hypertension, Smoking)|Plain Text|
RiskFactorResponse|Column holding the response for the risk factor that was evaluated (e.g., All Participants, Borderline, Current Smoker, Former Smoker, Never Smoker, Yes, or No)|Plain Text|
Data_Value_Unit|The unit, such as ""%"" for percent|Plain Text|
Data_Value_Type|The data value type, such as age-adjusted prevalence or crude prevalence|Plain Text|
Data_Value|A numeric data value greater than or equal to 0, or no value when footnote symbol and text are present|Number|
Data_Value_Footnote_Symbol|Footnote symbol|Plain Text|
Data_Value_Footnote|Footnote text|Plain Text|
Low_Confidence_Limit|95% confidence interval lower bound|Number|
High_Confidence_Limit|95% confidence interval higher bound|Number|
Numerator|The prediction of the number of people who may have this condition in the state/country (n)|Number|
Sample_Size|Sample size used to calculate the data value|Number|
LocationID|Lookup identifier value for the location|Plain Text|
TopicID|Lookup identifier for the Topic|Plain Text|
CategoryID|Lookup identifier for the Category|Plain Text|
QuestionID|Lookup identifier for the Question|Plain Text|
ResponseID|Lookup identifier for the Response|Plain Text|
DataValueTypeID|Lookup identifier for the data value type|Plain Text|
AgeID|Lookup identifier for the Age stratification|Plain Text|
GenderID|Lookup identifier for the Gender stratification|Plain Text|
RaceEthnicityID|Lookup identifier for the Race/Ethnicity stratification|Plain Text|
RiskFactorID|Lookup identifier for the Major Risk Factor|Plain Text|
RiskFactorResponseID|Lookup identifier for the Major Risk Factor Response|Plain Text|
GeoLocation|No Geolocation is provided for national data|Location|
Geographic Level||Plain Text|


",.csv
NHL Draft Hockey Player Data (1963 - 2022),1,nhl-draft-hockey-player-data-1963-2022,nhldraft.csv,CC0-1.0,"The dataset contains every player drafted in the NHL Draft from (1963 - 2022).

The data was collected from&nbsp;Sports Reference&nbsp;then cleaned for data analysis.

Tabular data includes:
- `year`: Year of draft
- `overall_pick`: Overall pick player was drafted
- `team`: Team player drafted to
- `player`: Player drafted
- `nationality`: Nationality of player drafted
- `position`: Player position
- `age`: Player age
- `to_year`: Year draft pick played to
- `amateur_team`: Amateur team drafted from
- `games_played`: Total games played by player (non-goalie)
- `goals`: Total goals
- `assists`: Total assists
- `points`: Total points
- `plus_minus`: Plus minus of player
- `penalties_minutes`: Penalties in minutes
- `goalie_games_played`: Goalie games played
- `goalie_wins`
- `goalie_losses`
- `goalie_ties_overtime`: Ties plus overtime/shootout losses
- `save_percentage`
- `goals_against_average`
- `point_shares`",.csv
NIFTY-50 Stocks Dataset,1,nifty50-stocks-dataset,National_Stock_Exchange_of_India_Ltd.csv,other,"### Context

The NIFTY 50 is a benchmark Indian stock market index that represents the weighted average of 50 of the largest Indian companies listed on the National Stock Exchange. It is one of the two main stock indices used in India, the other being the BSE SENSEX.

Nifty 50 is owned and managed by NSE Indices (previously known as India Index Services & Products Limited), which is a wholly-owned subsidiary of the NSE Strategic Investment Corporation Limited. NSE Indices had a marketing and licensing agreement with Standard & Poor's for co-branding equity indices until 2013. The Nifty 50 index was launched on 22 April 1996 and is one of the many stock indices of Nifty.

The NIFTY 50 index has shaped up to be the largest single financial product in India, with an ecosystem consisting of exchange-traded funds (onshore and offshore), exchange-traded options at NSE, and futures and options abroad at the SGX. NIFTY 50 is the world's most actively traded contract. WFE, IOM, and FIA surveys endorse NSE's leadership position.

The NIFTY 50 index covers 13 sectors (as of 30 April 2021) of the Indian economy and offers investment managers exposure to the Indian market in one portfolio. Between 2008 & 2012, the NIFTY 50 index's share of NSE's market capitalization fell from 65% to 29% due to the rise of sectoral indices like NIFTY Bank, NIFTY IT, NIFTY Pharma, NIFTY SERV SECTOR, NIFTY Next 50, etc. The NIFTY 50 Index gives a weightage of 39.47% to financial services, 15.31% to Energy, 13.01% to IT, 12.38% to consumer goods, 6.11% to Automobiles, and 0% to the agricultural sector.

The NIFTY 50 index is a free-float market capitalization weighted index. The index was initially calculated on a full market capitalization methodology. On 26 June 2009, the computation was changed to a free-float methodology. The base period for the NIFTY 50 index is 3 November 1995, which marked the completion of one year of operations of the National Stock Exchange Equity Market Segment. The base value of the index has been set at 1000 and a base capital of ₹ 2.06 trillion.

### Content

In this Dataset, we have records of all the NIFTY-50 stocks along with various parameters.

### Important Note

* % change is calculated with respect to adjusted price on ex-date for Dividend, Bonus, Rights & Face Value Split.
* 52 weeks high & 52-week low prices are adjusted for Bonus, Split & Rights Corporate actions.
* 365 days % Change and 30 days % Change values are adjusted With respect to corporate actions.

### Structure of the Dataset

![](https://i.imgur.com/ZmP0ZQy.png)

### Acknowledgements

This Dataset is created from: https://www1.nseindia.com/. If you want to learn more, you can visit the website of the National Stock Exchange of India Limited (NSE)


Cover Photo: https://wallpaperaccess.com/stock-market",.csv
NIFTY50 HISTORICAL INDEX DATA(2015-2024),1,nifty50-historical-index-data2015-2024,nifty_cleaned.csv,Apache 2.0,"This dataset provides a comprehensive view of the daily trading activity and performance of the NIFTY50 index over the specified period. It enables various analyses, including trend analysis, volatility assessment, trading volume analysis, and correlation studies with other economic indicators or asset classes. Additionally, it can be used for backtesting trading strategies, risk management, and investment decision-making.

## **Features:**

- **Date:** The date of the trading session.
- **Open:** The opening price of the NIFTY50 index at the beginning of the trading session.
- **High:** The highest price reached by the NIFTY50 index during the trading session.
- **Low:** The lowest price reached by the NIFTY50 index during the trading session.
- **Close:** The closing price of the NIFTY50 index at the end of the trading session.
- **Shares Traded:** The total number of shares of all companies in the NIFTY50 index that were traded during the trading session.
- **Turnover (₹ Cr):** The total value of shares traded during the trading session, measured in Indian Rupees (₹) in Crores (Cr).",.csv
NLP Mental Health Conversations,1,nlp-mental-health-conversations,train.csv,CC0-1.0,"_____
# NLP Mental Health Conversations
### Stimulating AI-Driven Mental Health Guidance
By Huggingface Hub [[source]](https://huggingface.co/datasets/Amod/mental_health_counseling_conversations)
_____

### About this dataset
> This dataset contains conversations between users and experienced psychologists related to mental health topics. Carefully collected and anonymized, the data can be used to further the development of Natural Language Processing (NLP) models which focus on providing mental health advice and guidance. It consists of a variety of questions which will help train NLP models to provide users with appropriate advice in response to their queries. Whether you're an AI developer interested in building the next wave of mental health applications or a therapist looking for insights into how technology is helping people connect; this dataset provides invaluable support for advancing our understanding of human relationships through Artificial Intelligence

### More Datasets
> For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
> - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
> This guide will provide you with the necessary knowledge to effectively use this dataset for Natural Language Processing (NLP)-based applications. 
> 
> - Download and install the dataset: To begin using the dataset, download it from Kaggle onto your system. Once downloaded, unzip and extract the .csv file into a directory of your choice. 
>    
> - Familiarize yourself with the columns: Before working with the data, it’s important to familiarize yourself with all of its components. This dataset contains two columns - Context and Response - which are intentionally structured to produce conversations between users and psychologists related to mental health topics for NLP models dedicated to providing mental health advice and guidance. 
> 
> - Analyze data entries: If possible or desired, take time now to analyze what is included in each entry; this may help you better untangle any challenges that come up during subsequent processes yet won't be required for most steps going forward if you prefer not too jump ahead of yourself at this juncture of your work process just yet! Examine questions asked by users as well as answers provided by experts in order glean an overall picture of what types of conversations are taking place within this pool of data that can help guide further work on NLP models for AI-driven mental health guidance purposes later on down the road!  
> 
> - Cleanse any information not applicable to NLP decisioning relevant application goals: It's important that only meaningful items related towards achieving AI-driven results remain within a clean copy of this Dataset going forward; consider removing all extra many verbatim entries or other pieces uneeded while also otherwise making sure all included content adheres closely enough one particular decisions purpose expected from an end goal perspective before proceeding onwards now until an ultimate end result has been successfully achieved eventually afterwards later on next afterward soon afterwards too following conveniently satisfyingly after accordingly shortly near therefore meaningfully likewise conclusively thoroughly properly productively purposely then eventually effectively finally indeed desirably plus concludingly enjoyably popularly splendidly attractively satisfactorally propitiously outstandingly fluently promisingly opportunely in conclusion efficiently hopefully progressively breathtaking deliciousness ideally genius mayhem invented unique impossibility everlastingly intense qualitative cohesiveness behaviorally affectionately fixed voraciously like alive supportively choicest decisively luckily chaotically co-creatively introducing ageless intricacy voicing auspicious promise enterprisingly preferred mathematically godly happening humorous respective achieve ultra favorability fundamentals essentials speciality grandiose selectively perfectly

### Research Ideas
> - Creating sentence-matching algorithms for natural language processing to accurately match given questions with appropriate advice and guidance.
> - Analyzing the psychological conversations to gain insights into topics such as stress, anxiety, and depression. 
> - Developing personalized natural language processing models tailored to provide users with appropriate advice based on their queries and based on their individual state of mental health

### Acknowledgements
> If you use this dataset in your research, please credit the original authors.
> [Data Source](https://huggingface.co/datasets/Amod/mental_health_counseling_conversations)
> 
>


### License
> 
> 
> **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
> No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: train.csv**
| Column name   | Description                                                    |
|:--------------|:---------------------------------------------------------------|
| **Context**   | The conversation between the user and the psychologist. (Text) |
| **Response**  | The response from the psychologist to the user. (Text)         |

### Acknowledgements
> If you use this dataset in your research, please credit the original authors.
> If you use this dataset in your research, please credit [Huggingface Hub](https://huggingface.co/datasets/Amod/mental_health_counseling_conversations).

",.csv
NLP with Disaster Tweets,1,nlp-with-disaster-tweets,s.csv,MIT,"Explore the chaos of disaster tweets through the lens of Natural Language Processing, as we unravel patterns and sentiments to enhance understanding and response strategies in times of crisis.",.csv
NVIDIA Corp Share price 2000-2024,1,nvidia-corp-share-price-2000-2024,NVDA.csv,CC0-1.0,"**Nvidia Corporation is a multinational technology company** headquartered in Santa Clara, California, United States. It was incorporated in Delaware,**United States in 1993**. Nvidia Corporation went public on January 22, 1999, and its shares began trading on NASDAQ Stock Market under the ticker symbol of NVDA. NVDA shares are also included as a component on several stock market indices, namely S&P 500, S&P 100 and NASDAQ-100. On November 6, 2020, NVDA stocks reached an all-time **highest stock closing price of $582.48**. 

In 2002, **Fortune magazine recognised Nvidia Corporation** as the fastest-growing company in the US. NVDA entered in another acquisition in 2003 and bought-off MediaQ Inc. in a transaction of $70 million. Stanford Graduate School of Business Alumni Association named Nvidia Corporation as the Entrepreneurial Company of the Year in 2003. **Nvidia GPUs powered all Academy Award Nominees** in the category of Best Visual Effects 2010, which included Star Trek and Avatar. 

In 2010, it also **powered the world's fastest supercomputer at the time - China's Tianhe- 1A**. The company made an acquisition in 2020 and purchased Mellanox Technologies, Ltd., a leading producer of networking products at the time, for a purchase price of $7 billion. As of 2021, **the company has over 50 offices worldwide,** including countries like Sweden, Denmark, Israel, Czech Republic, Poland, Russia, United Arab Emirates, Germany, France, Ukraine, Finland, Switzerland, and the United Kingdom, among others. 

**NVDA ranked 292nd on the list of Fortune 500 companies.** It ranked 489th on Forbes' list of Global 2000 2020 companies. Forbes also included Nvidia Corporation in its 2020 rankings of World's Best Employers, America's Best Employers By State, and Best Employers for Diversity.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F7974466%2F808b080cc72c5431ad8bd2f2dc361cbe%2Fnvceo%20(1).jpg?generation=1714039131033569&alt=media)",.csv
NVIDIA Corporation (NVDA) Stock | 2020 to 2024,1,nvidia-corporation-nvda-stock-2020-to-2024,nvda_stock_data.csv,Apache 2.0,"# Analyzing NVIDIA Corporation (NVDA) Stock Performance: 2020 to 2024

## Overview
This analysis focuses on NVIDIA Corporation (NVDA) stock performance from January 1, 2020, to May 5, 2024. By analyzing historical stock data, we aim to provide insights into NVIDIA's financial trends, market volatility, and factors influencing its stock price over this period.

## Column Names
- **Date:** The date of the stock data.
- **Open:** The opening price of NVIDIA stock on the given date.
- **High:** The highest price of NVIDIA stock during the trading day.
- **Low:** The lowest price of NVIDIA stock during the trading day.
- **Close:** The closing price of NVIDIA stock on the given date.
- **Adj Close:** The adjusted closing price of NVIDIA stock, accounting for any corporate actions such as dividends or stock splits.
- **Volume:** The trading volume of NVIDIA stock on the given date.


",.csv
NVIDIA Historical Market Data 2023-2024 for ML,1,nvidia-historical-market-data-2023-2024-for-ml,NVIDIA Historical Market Data 01-04-2023 - 05-13-2024 - NVDA.csv,Apache 2.0,"This dataset organized stock market data from 01-04-2023 to 05-13-2024 from Yahoo Finance. 
The dataset is intended to perform machine learning tasks include but not limited to:
1. Simple Linear Regression
2. Multiple Linear Regression
3. MANOVA Test
4. PCA 
5. Factor Analysis
6.ARIMA

The key idea is to utilize historical stock market dataset to predict Next Day adjusted close price by using various variables. The predictive power and importance of each variable will be evaluated using PCA and VIF score.

The project aims to figure out the feasibility to predict stock market adjusted closing price for the trendy AI stock NVIDIA and filter out the most important indicator of stock price prediction.

Features included in this dataset:

- Predictive Variable: Next Day Adjusted Close price 
- Independent Variables and its Types

1. Date ( Time Series, Numerical)
2.Open ( Numerical)
3. LogRange ( Stock Daily High - Low, risk indicator)
***Risk Indicator
4. Log_Volume (Log Value of Daily Traded Volume)
***Momentum Indicator
5. Return_Percentage (   [Today AdjClose - Prior Day AdjClose)/Prior Day AdjClose]*100% ) 
***This is a profit Indicator
6. 3_Day_Avg_AdjClose(Market Price Level Assassin indicatory, Delay=3)
*** Historical Market Price Level Assessment
7. PriorDay_AdjClose ( prior day adjusted closed price)",.csv
NY 2010 - 2016 School Safety Report,1,ny-2010-2016-school-safety-report,2010-2016-school-safety-report.csv,CC0-1.0,"### Content  

Since 1998, the New York City Police Department (NYPD) has been tasked with the collection and maintenance of crime data for incidents that occur in New York City public schools. The NYPD has provided this data to the New York City Department of Education (DOE). The DOE has compiled this data by schools and locations for the information of our parents and students, our teachers and staff, and the general public. 
In some instances, several Department of Education learning communities co-exist within a single building. In other instances, a single school has locations in several different buildings. In either of these instances, the data presented here is aggregated by building location rather than by school, since safety is always a building-wide issue. We use “consolidated locations” throughout the presentation of the data to indicate the numbers of incidents in buildings that include more than one learning community.  

### Context  

This is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  

* Update Frequency: This dataset is updated annually.

### Acknowledgements

This dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  

[Cover photo](https://unsplash.com/photos/cXUOQWdRV4I) by [Ryan Jacobson](https://unsplash.com/@rcjphoto) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv
NY School Demographics and Accountability Snapshot,1,ny-school-demographics-and-accountability-snapshot,2006-2012-school-demographics-and-accountability-snapshot.csv,CC0-1.0,"### Content  

Annual school accounts of NYC public school student populations served by grade, special programs, ethnicity, gender and Title I funded programs.   

### Context  

This is a dataset hosted by the City of New York. The city has an open data platform found [here](https://opendata.cityofnewyork.us/) and they update their information according the amount of data that is brought in. Explore New York City using Kaggle and all of the data sources available through the City of New York [organization page](https://www.kaggle.com/new-york-city)!  

* Update Frequency: This dataset is updated annually.

### Acknowledgements

This dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  

[Cover photo](https://unsplash.com/photos/_sSYhR2yHq4) by [Eric Parks](https://unsplash.com/@parksed24) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv
NYC Car Crashes - Contributing Factors,1,nyc-car-crashes-contributing-factors,NYC crashes - contributing factors.csv,CC0-1.0,"Picture shoutout to Matt C. [over at unsplash](https://unsplash.com/photos/policeman-leaning-on-sports-cars-window-ZI-vWZBbwj8?utm_content=creditShareLink&utm_medium=referral&utm_source=unsplash) .

This data was taken from the data published at [data.gov](https://catalog.data.gov/dataset/motor-vehicle-collisions-crashes).

This data set contains all of the reported contributing factors for car accidents from the years 2015 to early 2024.",.csv
NYC Consumer Product Metal Content Analysis,1,nyc-consumer-product-metal-content-analysis,nyc_products_metal_content.csv,Apache 2.0,"# NYC Consumer Product Metal Content Analysis: Health Department Tests

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F1937611%2F18a0c0dba41cb7ca73dbb78bcd95a9e4%2FDesigner.jpeg?generation=1709697574652184&alt=media)

The dataset is to assess the presence and concentration of various metals in consumer products tested by the NYC Health Department. This analysis aims to achieve the following goals:

**1. Identify Health Risks:** Determine the extent to which consumer products contain harmful metals such as lead, cadmium, nickel, chromium, and mercury, which can pose health risks to consumers upon exposure.

**2. Ensure Consumer Safety:** Assess compliance with safety regulations and standards to ensure that consumer products meet acceptable levels of metal content, thereby safeguarding public health and consumer safety.

**3.Evaluate Regulatory Effectiveness:** Evaluate the effectiveness of regulatory measures and enforcement actions in controlling the presence of harmful metals in consumer products, identifying areas for improvement in regulatory frameworks.

**4.Inform Policy Decisions: **Provide evidence-based insights to policymakers and regulatory authorities to guide the formulation of policies and regulations aimed at mitigating metal-related health risks and enhancing consumer protection measures.

**5.Protect Vulnerable Populations:** Identify products with elevated metal concentrations that may disproportionately impact vulnerable populations, such as children, pregnant women, and communities residing in low-income areas, and develop targeted interventions to protect their health and well-being.

By achieving these objectives, stakeholders can enhance consumer safety, improve regulatory oversight, and mitigate health risks associated with metal exposure from consumer products in New York City.

In this dataset, each row represents a consumer product tested by the NYC Health Department for its metal content. Here's a brief overview of the columns:

- ROW_ID: Unique identifier for each record.
- PRODUCT_TYPE: Type of the product (e.g., Toy, Paint, Jewelry, Cosmetics, Food).
- PRODUCT_NAME: Name or description of the product.
- METAL: Type of metal found in the product (e.g., Lead, Cadmium, Nickel, Chromium, Mercury).
- CONCENTRATION: Concentration of the metal found in the product, measured in parts per million (ppm).
- UNITS: Units of measurement for concentration (e.g., ppm).
- MANUFACTURER: Manufacturer or producer of the product.
- MADE_IN_COUNTRY: Country where the product was manufactured.
- COLLECTION_DATE: Date when the sample was collected for testing.


This dataset can be analyzed to identify products with high metal concentrations, evaluate regulatory compliance, and ensure consumer safety standards are met.",.csv
NYC Property Sales,1,nyc-property-sales,nyc-rolling-sales.csv,CC0-1.0,"### Context

This dataset is a record of every building or building unit (apartment, etc.) sold in the New York City property market over a 12-month period.

### Content

This dataset contains the location, address, type, sale price, and sale date of building units sold. A reference on the trickier fields:

* `BOROUGH`: A digit code for the borough the property is located in; in order these are Manhattan (1), Bronx (2), Brooklyn (3), Queens (4), and Staten Island (5).
* `BLOCK`; `LOT`: The combination of borough, block, and lot forms a unique key for property in New York City. Commonly called a `BBL`.
* `BUILDING CLASS AT PRESENT` and `BUILDING CLASS AT TIME OF SALE`: The type of building at various points in time. See the glossary linked to below.

For further reference on individual fields see the [Glossary of Terms](http://www1.nyc.gov/assets/finance/downloads/pdf/07pdf/glossary_rsf071607.pdf). For the building classification codes see the [Building Classifications Glossary](http://www1.nyc.gov/assets/finance/jump/hlpbldgcode.html).

Note that because this is a financial transaction dataset, there are some points that need to be kept in mind:

* Many sales occur with a nonsensically small dollar amount: $0 most commonly. These sales are actually transfers of deeds between parties: for example, parents transferring ownership to their home to a child after moving out for retirement.
* This dataset uses the financial definition of a building/building unit, for tax purposes. In case a single entity owns the building in question, a sale covers the value of the entire building. In case a building is owned piecemeal by its residents (a condominium), a sale refers to a single apartment (or group of apartments) owned by some individual.

### Acknowledgements

This dataset is a concatenated and slightly cleaned-up version of the New York City Department of Finance's [Rolling Sales dataset](http://www1.nyc.gov/site/finance/taxes/property-rolling-sales-data.page).

### Inspiration

What can you discover about New York City real estate by looking at a year's worth of raw transaction records? Can you spot trends in the market, or build a model that predicts sale value in the future?",.csv
NYC Restaurants Data - Food Ordering and Delivery,1,food-ordering-and-delivery-app-dataset,food_order.csv,CC0-1.0,"**CONTEXT**

The number of restaurants in New York is increasing day by day. Lots of students and busy professionals rely on those restaurants due to their hectic lifestyles. Online food delivery service is a great option for them. It provides them with good food from their favorite restaurants. A food aggregator company FoodHub offers access to multiple restaurants through a single smartphone app.

The app allows the restaurants to receive a direct online order from a customer. The app assigns a delivery person from the company to pick up the order after it is confirmed by the restaurant. The delivery person then uses the map to reach the restaurant and waits for the food package. Once the food package is handed over to the delivery person, he/she confirms the pick-up in the app and travels to the customer's location to deliver the food. The delivery person confirms the drop-off in the app after delivering the food package to the customer. The customer can rate the order in the app. The food aggregator earns money by collecting a fixed margin of the delivery order from the restaurants.

**OBJECTIVE**

The food aggregator company has stored the data of the different orders made by the registered customers in their online portal. They want to analyze the data to get a fair idea about the demand of different restaurants which will help them in enhancing their customer experience. Suppose you are hired as a Data Scientist in this company and the Data Science team has shared some of the key questions that need to be answered. Perform the data analysis to find answers to these questions that will help the company to improve the business.",.csv
NYC Total Car Crashes and Injuries/deaths,1,nyc-total-car-crashes-and-injuriesdeaths,NYC crashes - breakdown of crashes.csv,CC0-1.0,"Picture shoutout to Michael Jin [over at unsplash](https://unsplash.com/photos/black-ford-car-ipHlSSaC3vk?utm_content=creditShareLink&utm_medium=referral&utm_source=unsplash).

Raw data can be found at [data.gov](https://catalog.data.gov/dataset/motor-vehicle-collisions-crashes).

This data set contains the total amount of car crashes in NYC between the years 2015 to 2024. It also contains a breakdown of who was injured and sadly killed from a car crash.",.csv
Naive bayes classification data,1,naive-bayes-classification-data,Naive-Bayes-Classification-Data.csv,CC0-1.0,"glucose and blood pressure data to classify whether the patient has diabetes or not.
the dataset has 3 columns and 995 entries.
- glucose
- blood pressure
- diabetes",.csv
Name Entity Recognition (NER) Dataset,1,name-entity-recognition-ner-dataset,NER dataset.csv,other,"### Context
This is a very clean dataset and is for anyone who wants to try his/her hand on the NER ( Named Entity recognition ) task of NLP.

### Content

The dataset with 1M x 4 dimensions contains columns = ['# Sentence', 'Word', 'POS', 'Tag'] and is grouped by #Sentence.

### Columns
Word:
This column contains English dictionary words form the sentence it is taken from.

POS:
Parts of speech tag

Tag:
Standard named entity recognition tags as follows
[
ORGANIZATION - Georgia-Pacific Corp., WHO
PERSON - Eddy Bonte, President Obama
LOCATION - Murray River, Mount Everest
DATE - June, 2008-06-29
TIME - two fifty a m, 1:30 p.m.
MONEY - 175 million Canadian Dollars, GBP 10.40
PERCENT - twenty pct, 18.75 %
FACILITY - Washington Monument, Stonehenge
GPE - South East Asia, Midlothian
]

I am also adding basic kernel for reference

If you like it, please give it a thumbs up 🤗",.csv
Name_Entity_Recognition_data,1,name-entity-recognition-data,ner.csv,CC0-1.0,"This dataset contain around 47000 sentences of English Language along with Part of Speech Tags of each sentence and for every word in each sentence. This Dataset can be used for Name Entity Recognition task of Machine Learning by any method. But I attached a notebook for this dataset in which NER is achieved by Sequential models like:- RNN, LSTM and GRUs.",.csv
Named Entity Recognition (NER)  Corpus,1,named-entity-recognition-ner-corpus,ner.csv,DbCL-1.0,"### Task

**Named Entity Recognition(NER)** is a task of categorizing the entities in a text into categories like names of persons, locations, organizations, etc. 


### Dataset

Each row in the CSV file  is a complete sentence, list of POS tags for each word in the sentence, and list of NER tags for each word in the sentence

You can use Pandas Dataframe to read and manipulate this dataset. 


**Since each row in the CSV file contain lists, if we read the file with pandas.read_csv() and try to get tag lists by indexing the list will be a string.**
```
&gt;&gt;&gt; data['tag'][0] 
""['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']""
&gt;&gt;&gt; type(data['tag'][0])
string
```
You can use the following to convert it back to list type: 
```
&gt;&gt;&gt; from ast import literal_eval
&gt;&gt;&gt; literal_eval(data['tag'][0] )
['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']
&gt;&gt;&gt; type(literal_eval(data['tag'][0] ))
list
 ```


### Acknowledgements

This dataset is taken  from *Annotated Corpus for Named Entity Recognition* by *Abhinav Walia* dataset and then processed. 

*Annotated Corpus for Named Entity Recognition* is annotated Corpus for Named Entity Recognition using GMB(Groningen Meaning Bank) corpus for entity classification with enhanced and popular features by Natural Language Processing applied to the data set.

 
**Essential info about entities:**

- geo = Geographical Entity
- org = Organization
- per = Person
- gpe = Geopolitical Entity
- tim = Time indicator
- art = Artifact
- eve = Event
- nat = Natural Phenomenon",.csv
Nashville Housing Data,1,nashville-housing-data,Nashville_housing_data_2013_2016.csv,CC0-1.0,"# Context 

This is home value data for the hot Nashville market.

#Content

There are 56,000+ rows altogether.  However, I'm missing home detail data for about half. So if anyone wants to track that down then go for it! I'll be looking in the mean time. Enjoy.

Will add the Python file that retrieved this data once I clean it up.

#**Shameless plug**: 
##visit [this link][1] for my latest project, a SQL magic function for IPython Notebook.


  [1]: https://github.com/tmthyjames/SQLCell",.csv
National Family Health Survey (NFHS) - 2019-21,1,national-family-health-survey-nfhs-2019-21,datafile.csv,ODC Public Domain Dedication and Licence (PDDL),"The National Family Health Survey 2019-2021, the fifth in the NFHS series, provides information on population, health, and nutrition for India and each state and union territory. Like NFHS-4, NFHS-5 also provides district-level estimates for many important indicators. The contents of NFHS-5 are similar to NFHS-4 to allow comparisons over time. However, NFHS-5 includes some new topics, such as preschool education, disability, access to a toilet facility, death registration, bathing practices during menstruation, and methods and reasons for abortion. The scope of clinical, anthropometric, and biochemical testing has also been expanded to include the measurement of waist and hip circumferences and the age range for the measurement of blood pressure and blood glucose has been expanded. However, HIV testing has been dropped. The NFHS-5 sample has been designed to provide national, state, and union territory, and district-level estimates of various indicators covered in the survey. However, estimates of indicators of sexual behavior, husband's background and woman's work, HIV and AIDS knowledge, attitudes and behavior, and domestic violence are available only at the state and union territory and national level",.csv
Native Plant Species of New Jersey,1,native-plant-species-of-new-jersey,New_Jersey_native_plants.csv,Apache 2.0,"## Native Plant Species of New Jersey

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F1937611%2Fd76d81c8fbd0a87b5ea5fb43a8f5c195%2F_dd92faa4-e9ca-441b-a4b7-2c07d68a2772.jpeg?generation=1715763841805211&alt=media)

This dataset provides information about native plant species found in New Jersey. It includes details such as family, scientific name, common name, duration, habit, light requirements, soil moisture preferences, height, color, bloom period, and additional notes.

- **Family**: The taxonomic family of the plant species.
- **Scientific Name**: The scientific name of the plant species.
- **Common Name**: The common name of the plant species.
- **Duration**: The duration of the plant (e.g., perennial, annual).
- **Habit**: The growth habit of the plant (e.g., tree, shrub, herb).
- **Light**: The light requirements for optimal growth (e.g., full sun, part shade).
- **Soil Moisture**: The preferred soil moisture level for the plant.
- **Height**: The typical height range of the plant.
- **Color**: The color of the plant's flowers or foliage.
- **Bloom Period**: The period during which the plant typically blooms.
- **Notes**: Additional notes or descriptions about the plant species.",.csv
Natural Gas Usage (2014-Now),1,natural-gas-usage,data.csv,U.S. Government Works,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F8734253%2F006f3d6d0824da80687f8abf944f4fe0%2Fus%20natural%20gas%20flag.png?generation=1711916828635588&alt=media)
Natural gas is a versatile and widely used fossil fuel that plays a crucial role in the United States' energy landscape. It is a primary energy source for heating, cooking, and electricity generation in residential, commercial, and industrial settings. This dataset contains **monthly natural gas consumption** data for the United States from *January 2014* to *January 2024*, broken down by state, sector (residential, commercial, industrial, vehicle fuel, and electric power), and specific consumption process. The data comes from the U.S. Energy Information Administration (EIA).

Each row represents the natural gas consumption value for a specific state, sector, and process. The ""value"" column provides the consumption amount in millions of cubic feet (MMcf). Some values are missing, likely due to data not being available.

The key columns are:
- duoarea: State abbreviation
- area-name: State name
- product: Energy product (all rows have ""EPG0"" for Natural Gas)
- sector: Consumption sector (e.g. ""VRS"" for residential, ""VCS"" for commercial)
- process: Specific consumption process within the sector
- value: Monthly consumption in millions of cubic feet (MMcf)

This granular dataset allows for detailed analysis of natural gas consumption patterns across states and sectors. It could be used to compare consumption between states, identify the largest consuming sectors in each state, track seasonal consumption trends, and more. The data may be of interest to energy analysts, utility companies, policymakers, and others researching natural gas usage.",.csv
NetFlix,1,netflix,netflix.csv,other,"**Description:**

This dataset provides data on the movies and TV shows available on Netflix, a popular streaming service. You can use this dataset to discover the movies and TV shows available on Netflix, as well as their title, type, director, cast, country, date added, release year, rating, duration, genre and description.

Everything in this dataset is easy to follow, because this topic and this website is one of the most importance one in the world.

So, enjoy coding on this Dataset and share your talents.
Good luck",.csv
Netflix - All Movie Ratings by IMDb,1,netflix-all-movie-ratings-by-imdb,imdb_data.csv,CC0-1.0,"The ""Netflix - All Movie Ratings by IMDb"" dataset is sourced directly from IMDb, a popular online database for movies and TV shows. It compiles IMDb ratings for movies available on Netflix, providing insights into viewer perception and preferences. The dataset aims to facilitate analysis and exploration of Netflix's movie catalog, offering valuable information for researchers and enthusiasts interested in understanding audience reception and trends within the streaming platform.",.csv
Netflix - Exploratory Data Analysis ,1,exploratory-data-analysis-on-netflix-data,netflix_titles_2021.csv,CC0-1.0,"Data Description:

This Netflix Dataset has information about the TV shows and Movies available on Netflix from the year 2008 to 2021.
Netflix is an application that keeps growing exponentially whole around the world and it is the most famous streaming platform.",.csv
"Netflix Data: Cleaning, Analysis and Visualization",1,netflix-data-cleaning-analysis-and-visualization,netflix1.csv,CC0-1.0,"Netflix is a popular streaming service that offers a vast catalog of movies, TV shows, and original contents. This dataset is a cleaned version of the original version which can be found [here](https://www.kaggle.com/datasets/shivamb/netflix-shows). The data consist of contents added to Netflix from 2008 to 2021. The oldest content is as old as 1925 and the newest as 2021. This dataset will be cleaned with PostgreSQL and visualized with Tableau. The purpose of this dataset is to test my data cleaning and visualization skills. The cleaned data can be found below and the Tableau dashboard can be found [here](https://public.tableau.com/app/profile/abdulrasaq.ariyo/viz/NetflixTVShowsMovies_16615029026580/NetflixDashboard) .   

## Data Cleaning
We are going to:
1. Treat the Nulls 
2. Treat the duplicates
3.  Populate missing rows
4. Drop unneeded columns
5. Split columns
Extra steps and more explanation on the process will be explained through the code comments

```
--View dataset

SELECT * 
FROM netflix;

```

```
--The show_id column is the unique id for the dataset, therefore we are going to check for duplicates
                                                                   
SELECT show_id, COUNT(*)                                                                                                                                                                            
FROM netflix 
GROUP BY show_id                                                                                                                                                                                            
ORDER BY show_id DESC;

--No duplicates
```

```
--Check null values across columns

SELECT COUNT(*) FILTER (WHERE show_id IS NULL) AS showid_nulls,
       COUNT(*) FILTER (WHERE type IS NULL) AS type_nulls,
       COUNT(*) FILTER (WHERE title IS NULL) AS title_nulls,
       COUNT(*) FILTER (WHERE director IS NULL) AS director_nulls,
	   COUNT(*) FILTER (WHERE movie_cast IS NULL) AS movie_cast_nulls,
	   COUNT(*) FILTER (WHERE country IS NULL) AS country_nulls,
       COUNT(*) FILTER (WHERE date_added IS NULL) AS date_addes_nulls,
       COUNT(*) FILTER (WHERE release_year IS NULL) AS release_year_nulls,
       COUNT(*) FILTER (WHERE rating IS NULL) AS rating_nulls,
	   COUNT(*) FILTER (WHERE duration IS NULL) AS duration_nulls,
       COUNT(*) FILTER (WHERE listed_in IS NULL) AS listed_in_nulls,
	   COUNT(*) FILTER (WHERE description IS NULL) AS description_nulls
FROM netflix;
```
```
We can see that there are NULLS. 
director_nulls = 2634
movie_cast_nulls = 825
country_nulls = 831
date_added_nulls = 10
rating_nulls = 4
duration_nulls = 3  
```

The director column nulls is about 30% of the whole column, therefore I will not delete them. I will rather find another column to populate it. To populate the director column, we want to find out if there is relationship between movie_cast column and director column


``` 
-- Below, we find out if some directors are likely to work with particular cast

WITH cte AS
(
SELECT title, CONCAT(director, '---', movie_cast) AS director_cast 
FROM netflix
)

SELECT director_cast, COUNT(*) AS count
FROM cte
GROUP BY director_cast
HAVING COUNT(*) &gt; 1
ORDER BY COUNT(*) DESC;

With this, we can now populate NULL rows in directors 
using their record with movie_cast 
```
```
UPDATE netflix 
SET director = 'Alastair Fothergill'
WHERE movie_cast = 'David Attenborough'
AND director IS NULL ;

--Repeat this step to populate the rest of the director nulls
--Populate the rest of the NULL in director as ""Not Given""

UPDATE netflix 
SET director = 'Not Given'
WHERE director IS NULL;

--When I was doing this, I found a less complex and faster way to populate a column which I will use next
```

Just like the director column, I will not delete the nulls in country. Since the country column is related to director and movie, we are going to populate the country column with the director column

```
--Populate the country using the director column

SELECT COALESCE(nt.country,nt2.country) 
FROM netflix  AS nt
JOIN netflix AS nt2 
ON nt.director = nt2.director 
AND nt.show_id &lt;&gt; nt2.show_id
WHERE nt.country IS NULL;
UPDATE netflix
SET country = nt2.country
FROM netflix AS nt2
WHERE netflix.director = nt2.director and netflix.show_id &lt;&gt; nt2.show_id 
AND netflix.country IS NULL;


--To confirm if there are still directors linked to country that refuse to update

SELECT director, country, date_added
FROM netflix
WHERE country IS NULL;

--Populate the rest of the NULL in director as ""Not Given""

UPDATE netflix 
SET country = 'Not Given'
WHERE country IS NULL;
```

The date_added rows nulls is just 10 out of over 8000 rows, deleting them cannot affect our analysis or visualization

```
--Show date_added nulls

SELECT show_id, date_added
FROM netflix_clean
WHERE date_added IS NULL;

--DELETE nulls

DELETE FROM netflix
WHERE show_id 
IN ('6797', 's6067', 's6175', 's6807', 's6902', 's7255', 's7197', 's7407', 's7848', 's8183');

```

rating nulls is 4. Delete them
```
--Show rating NULLS

SELECT show_id, rating
FROM netflix_clean
WHERE date_added IS NULL;

--Delete the nulls, and show deleted fields
DELETE FROM netflix 
WHERE show_id 
IN (SELECT show_id FROM netflix WHERE rating IS NULL)
RETURNING *;
```

--duration nulls is 4. Delete them
```

DELETE FROM netflix 
WHERE show_id 
IN (SELECT show_id FROM netflix WHERE duration IS NULL);
```
Now run the query to show the number of nulls in each column to confirm if there are still nulls. After this, run the query to confirm the row number in each column is the same

```
--Check to confirm the number of rows are the same(NO NULL)

SELECT count(*) filter (where show_id IS NOT NULL) AS showid_nulls,
       count(*) filter (where type IS NOT NULL) AS type_nulls,
       count(*) filter (where title IS NOT NULL) AS title_nulls,
       count(*) filter (where director IS NOT NULL) AS director_nulls,
	   count(*) filter (where country IS NOT NULL) AS country_nulls,
       count(*) filter (where date_added IS NOT NULL) AS date_addes_nulls,
       count(*) filter (where release_year IS NOT NULL) AS release_year_nulls,
       count(*) filter (where rating IS NOT NULL) AS rating_nulls,
	   count(*) filter (where duration IS NOT NULL) AS duration_nulls,
       count(*) filter (where listed_in IS NOT NULL) AS listed_in_nulls
FROM netflix;

 --Total number of rows are the same in all columns
```
We can drop the description and movie_cast column because they are not needed for our analysis or visualization task. 
```
--DROP unneeded columns

ALTER TABLE netflix
DROP COLUMN movie_cast, 
DROP COLUMN description;
```
Some of the rows in country column has multiple countries, for my visualization, I only need one country per row to make my map visualization clean and easy. Therefore, I am going to split the country column and retain the first country by the left which I believe is the original country of the movie
```
SELECT *,
	   SPLIT_PART(country,',',1) AS countryy, 
           SPLIT_PART(country,',',2),
	   SPLIT_PART(country,',',4),
	   SPLIT_PART(country,',',5),
	   SPLIT_PART(country,',',6),
	   SPLIT_PART(country,',',7),
	   SPLIT_PART(country,',',8),
	   SPLIT_PART(country,',',9),
	   SPLIT_PART(country,',',10) 
	   
FROM netflix;
	   
-- NOW lets update the table

ALTER TABLE netflix 
ADD country1 varchar(500);
UPDATE netflix 
SET country1 = SPLIT_PART(country, ',', 1);

--This will create a column named country1 and Update it with the first split country.
```

Delete the country column that has multiple country entries
```
--Delete column
ALTER TABLE netflix 
DROP COLUMN country;
```
Rename the country1 column to country
```
ALTER TABLE netflix 
RENAME COLUMN country1 TO country;
```

## Data Visualization
After cleaning, the dataset is set for some analysis and visualization with Tableau. 

**Note: In the visualization captions, Contents means Movies and TV shows, and Content may either mean Movie or TV Show**. 

**Sheet 1. Content type in percentage**

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10322697%2F1c95dee22870057541bc3c1cce7b1a36%2FType%20percent.png?generation=1661603826265148&alt=media)

This first sheet shows the two categories of content in the dataset which are Movie and Tv show. 
- As we can see the majority of the content is Movie which takes 69.9%. 
- There are more details in the tooltip which shows the exact count of Movie and Tv show


**Sheet 2. Movie & TV Show by Country**

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10322697%2F511f5a3f07f2fa9d8faea77d1dd21180%2FNumber%20of%20shows%20by%20map.png?generation=1661604888232420&alt=media)

This shows the the total amount of Movies and Tv shows per country within the given period of time(2008 - 2021). This can be noted by the size of the coloured circle in the map. 
- We can see that the United State of America has the largest size, followed by India and the United Kingdom. 
- In the Tableau hosted dashboard/sheet, there is a filter for the years between 2008 and 2021 to calculate yearly record.

 To give an alternate and a clearer view. Movie & TV shows by country bar chart is below
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10322697%2F64e9f79965e62a4bb63b04acc835a07c%2FNumber%20of%20shows%20by%20bar.png?generation=1661609485785468&alt=media)


**Sheet 3. Number of Contents Added through the Years**

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10322697%2Fe02290507d0be382870f6651e3682cd1%2FNumber%20of%20Contents%20added%20by%20year.png?generation=1661605691430129&alt=media)

This time series chart shows the total number of contents added to Netflix all through the given years (2008 - 2021)
- It shows that most movies and tv shows on Netflix were added in 2019
- In the Tableau sheet, there is a filter to know how much Movies and Tv shows were added in each month of the year 


**Sheet 4. Top Directors**

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10322697%2F0fa58900b62df123b690da63b6111a3a%2FDirector.png?generation=1661606812783874&alt=media)

This chart shows the top 10 directors with most contents on Netflix. This char shows the count of Movie and Tv shows in their catalouge. 
- We can see that most of these directors contents are movies. 
- We can also note that the duo of Raul Campos and Jan Suter are fond of working together and have directed 18 movies on Netflix. 


**Sheet 5. Top Genres** 

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10322697%2Fbc458d5885c3d7bcd3e690962c5cc2c3%2FTop%20Genres.png?generation=1661607262740686&alt=media)

This chart shows the genres with the highest numbers on Netflix. 
- We can see that Drama & International movies followed by Documentary have the highest number of contents on Netflix within the period.


**Sheet 6. Top Ratings**

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10322697%2F181df392cb0006559cd9fb19a29cadef%2FRating.png?generation=1661607535247137&alt=media)
 
Rating is a system to rate motion picture's suitability for certain audiences based on its content. This chart shows the top ratings on Netflix
-We can note that most contents on Netflix are rated TV-MA. TV-MA in the United States by the TV Parental Guidelines signifies content for mature audiences. 


**Sheet 7. Oldest Contents on Netflix by Content Release year**

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10322697%2F263493038e8dacd330c9e54aed2c467b%2FOldest%20shows%20on%20netflix.png?generation=1661607864455871&alt=media)

This table shows the 10 oldest movies and tv shows on Netflix
- The oldest is as old as 1925

**Sheet 8. Content Types over the Years**
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10322697%2F520da629aceef21a7af890198897c58e%2FContent%20Type%20over%20the%20years.png?generation=1661608071825961&alt=media)

This line chart compares the Movie and Tv shows contents added to Netflix all through the years.
- We can see that more movies have always been added. 
- In 2013, the number of contents added to Netflix for both were almost the same with Movies having 6 contents that year and Tv shows having 5.
- It shows that in the first 5 years, only movies were added to Netflix. 


**Sheet 9. Release Years with Highest Contents**

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10322697%2F063881abc476d466ad983f96b7f23284%2FRelease_years%20with%20highest%20movie.png?generation=1661608527082875&alt=media)

This chart shows the Movies and Tv shows production year which has with highest contents on Netflix. We focus on the top 10 release year/production year. 
-We can see that from 2012 to 2018, Netflix added most recent contents, they made sure most recent contents per release year are higher than the older release year contents.  Then in 2019, it started dropping, this may be due to the Covid-19, but further analysis may be needed to determine this. 

 And with this, I have come to the end of this exercise. As I said this is just an exercise to test my skills as I look forward to be better. Thanks for following through. Cheers!

",.csv
Netflix Dataset,1,netflix-dataset,netflix_titles.csv,Apache 2.0,"Dive into the vast and diverse world of Netflix entertainment with this extensive dataset. From blockbuster movies to binge-worthy TV shows, this collection offers insights into the rich content library available on the popular streaming platform. Gain access to detailed information about each title, including genre, release year, cast, director, and synopsis. Whether you're a data enthusiast, a movie buff, or a TV aficionado, this dataset provides valuable resources for analysis, recommendation systems, and exploring trends in the ever-evolving landscape of digital entertainment. Uncover hidden gems, track audience preferences, and embark on a journey through the dynamic realm of Netflix originals and licensed content.",.csv
Netflix Dataset for Analysis,1,netflix-dataset-for-analysis,netflix.csv,CC0-1.0,"Here's a brief description of each column:

1. **Title:** The title of the movie or TV show.
2. **Genre:** The category or type of content, indicating its theme or style.
3. **Premiere:** The date when the movie or TV show was first released or premiered.
4. **Runtime:** The duration of the movie or TV show in minutes.
5. **IMDb Score:** The rating of the movie or TV show on the IMDb (Internet Movie Database) platform, representing its overall quality as rated by users.
6. **Language:** The language in which the movie or TV show is primarily spoken or produced.
7. **Year:** The year when the movie or TV show was released or premiered.",.csv
Netflix IMDB Scores,1,netflix-imdb-scores,Netflix TV Shows and Movies.csv,other,"_____
# Netflix IMDB Scores
### IMDB Scores for Netflix TV Shows and Movies
By Back 2 Viz Basics [[source]](https://data.world/back2vizbasics)
_____

### About this dataset
> The Netflix TV Shows and Movies dataset provides comprehensive information about various titles available on the popular streaming platform. The dataset includes details such as the title's name, its type (whether it is a TV show or a movie), a brief description of the content, the year it was released, age certification rating, runtime (for TV shows: length of episodes; for movies: duration), IMDb score, and IMDb votes.
> 
> By analyzing this dataset, we can gain insights into the distribution of IMDb scores and ratings for both TV shows and movies available on Netflix. This information can help us understand the popularity and reception of titles based on user ratings.
> 
> The dataset has been carefully curated to ensure accuracy and relevance. It excludes any null values in IMDb scores to maintain data integrity. Each entry also contains an ID that corresponds to JustWatch (a platform for legal streaming) as well as the respective title ID on IMDb.
> 
> To visualize the distribution of IMDb scores effectively, we will be using histograms. Histograms categorize data into bins or intervals based on a chosen metric (in this case: IMDb score). The length of each bar within a bin represents the number of titles falling within that particular range of scores. With correct binning techniques, we can observe patterns and trends in how different shows and movies are rated by viewers.
> 
> When creating your visualization using Tableau or any other tool you prefer, feel free to experiment with color schemes to enhance your chart's visual impact without overshadowing its analytical purpose. However, remember not to sacrifice clarity and simplicity in pursuit of creativity.
> 
> We encourage you to take your time in crafting an insightful visualization over the next week. Once completed, share it on Tableau Public or through social media platforms like Twitter or LinkedIn using #B2VB hashtag while tagging ReadySetData and ItsElisaDavis for recognition. Don't forget to fill out our submission form on [Back 2 Viz Basics website](https://www.thetableaustudentguide.com/vizbasics) to officially participate in the challenge.
> 
> Best of luck, and we look forward to seeing your visualization!

### How to use the dataset
> 
> 
> - **title**: The name of the TV show or movie.
>    
>    This column contains the titles of various TV shows and movies available on Netflix. You can use this information to identify specific titles within the dataset.
> 
> - **type**: Indicates whether the entry is a TV show or a movie.
> 
>    The type column categorizes each entry as either a TV show or a movie. You can filter your analysis based on these categories to focus on either TV shows or movies specifically.
> 
> - **description**: A brief description of the TV show or movie.
> 
>    The description column provides a summary of each TV show or movie's plot or storyline. This information can help you get an overview of what each title is about before diving into further analysis.
> 
> - **release_year**: The year in which the TV show or movie was released.
> 
>    This column indicates the release year for each title in numeric format. You can utilize this data point to examine trends over time by grouping and aggregating titles based on their release years.
> 
> - **age_certification**: The age certification rating for the TV show or movie.
>    
>    The age_certification column specifies age ratings assigned to each title, indicating whether they are suitable for general audiences (e.g., all ages) or restricted due to mature content (e.g., rated R). Analyzing this attribute allows you to understand what type of content Netflix offers at different age levels.
> 
> 6 .**runtime**: The length of episodes for TV shows OR duration for movies.
> 
>    The runtime column provides the length of episodes for TV shows or the duration of movies in numeric format. This information can help you identify shorter or longer titles based on their runtime and compare them within your analysis.
> 
> - **imdb_score**: The score of the TV show or movie on IMDB.
> 
>    This column displays the IMDB score assigned to each title, representing its overall quality and popularity on IMDB. Utilize this metric to evaluate and rank different titles based on their ratings, potentially uncovering interesting patterns or insights.
> 
> - **imdb_votes**: The number of votes received by the TV show or

### Research Ideas
> - Analyzing the distribution of IMDB scores and ratings for TV shows and movies on Netflix can help identify trends and patterns in audience preferences. This information can be valuable for content creators and producers in deciding what types of shows or movies to invest in.
> - By examining the age certification ratings, it is possible to analyze the target audience for different TV shows and movies on Netflix. This information can be useful for advertisers who want to reach specific demographic groups or for parents who want to make informed decisions about what their children watch.
> - Comparing IMDB scores and votes across different release years can provide insights into how the quality of content on Netflix has evolved over time. This analysis may reveal any shifts in audience preferences or changes in industry standards that have influenced viewers' perceptions and opinions

### Acknowledgements
> If you use this dataset in your research, please credit the original authors.
> [Data Source](https://data.world/back2vizbasics)
> 
>


### License
> 
> 
> See the dataset description for more information.

### Columns

**File: Netflix TV Shows and Movies.csv**
| Column name           | Description                                                          |
|:----------------------|:---------------------------------------------------------------------|
| **title**             | The name of a TV show or movie. (Text)                               |
| **type**              | Indicates whether an entry is a TV show or a movie. (Text)           |
| **description**       | A brief summary or description of a TV show or movie. (Text)         |
| **release_year**      | The year in which a TV show or movie was released. (Numeric)         |
| **age_certification** | The age certification rating for a TV show or movie. (Text)          |
| **runtime**           | The length of an episode for TV shows or duration of a movie. (Text) |
| **imdb_score**        | The score given by users on IMDB for a particular title. (Numeric)   |
| **imdb_votes**        | The number of votes received by each title on IMDB. (Numeric)        |

### Acknowledgements
> If you use this dataset in your research, please credit the original authors.
> If you use this dataset in your research, please credit [Back 2 Viz Basics](https://data.world/back2vizbasics).

",.csv
Netflix Movie and TV Shows (June 2021),1,netflix-tv-shows-and-movie-list,netflix_list.csv,CC0-1.0,"### Context

Dataset contains the list and metadata of all TV Shows and Movies available on Netflix currently about 7000 taken from the IMDB website.
Upvote if you liked it.


### Content

netflix_list.csv

- imdb_id           : Unique show identifier.
- title                  : Title of the show.
- popular_rank   : Ranking as given by IMDB when filtered by popularity.
- certificate        : Contains the age certifications received by the show. Many null values.
- startYear          : When the show was first broadcasted.
- endYear           : Year of show ending
- episodes         : Number of episodes in the show. 1 for movies.
- type                 : Movie or Series
- orign_country  : Country of origin of the show
- language          : Language of the show.
- plot                   : Synopsis of the show.
- summary          : Summary of the story of the show.
- rating               : Average rating given to the show.
- numVotes        : Number of votes received by the show.
- genres             : Genre the show belongs to.
- isAdult             : 1  If adult content present. 0 if not.
- cast                 : Main cast of the show in list format.
- image_url        : Link to poster image.

### Acknowledgements

This is collected from IMDB website
Data collected by web scrapping through the shows ranking pages with filtered to show Netflix related content(16000+ entries) and noting down the imdb_id, followed by single page search for each collected ID and unique title name.

",.csv
Netflix Movies & Shows Dataset,1,netflix-movies-and-shows-dataset,netflix_data.csv,Apache 2.0,"This dataset pertains to Netflix, a highly popular media and video streaming service. As of mid-2021, Netflix boasts more than 8,000 movies and TV shows in its library and has amassed a global subscriber base exceeding 200 million. The dataset in tabular form includes information on all the movies and TV shows accessible on Netflix, encompassing details like cast, directors, ratings, release year, duration, and more.",.csv
Netflix Movies and TV Shows,1,netflix-movies-and-tv-shows,netflix_titles.csv,CC0-1.0,"**Context**

**Netflix Movies and TV Shows**
Netflix is a streaming service that offers a wide variety of award-winning TV shows, movies, anime, documentaries and more – on thousands of internet-connected devices.

You can watch as much as you want, whenever you want, without a single ad – all for one low monthly price. There's always something new to discover, and new TV shows and movies are added every week!

Enjoy your favourite Movies and TV Shows",.csv
Netflix Movies and TV Shows 2021 ,1,netflix-movies-and-tv-shows-2021,netflixData.csv,CC0-1.0,"### Context

This is my first dataset on Kaggle. I had great fun creating this dataset and learned a ton. If found useful, please upvote.

![Netflix logo](https://i.pinimg.com/originals/61/d1/42/61d14291ee3bd48dc9c6a68e4a3a442d.gif)
### Content

This dataset contains all the listed movies and TV shows on Netflix as of 2021. The dataset was collected from [Flixable](https://flixable.com/), a third-party Netflix search engine. 


### Acknowledgements
Firstly, I would like to thank [Shivamb](https://www.kaggle.com/shivamb) as a similar dataset for Netflix content was available. There were two shortcomings with the previously available database. Firstly, it was of the year 2019. Secondly, (which is the more important part), IMDb rating for the movies and TV shows was missing. This is a very important feature, especially when it comes to building recommendation algorithms.



### Inspiration
This dataset can be used to perform the following:
- EDA (exploratory data analysis)
- Data visualization
- Building a Recommendation Algorithm
and many more...
",.csv
Netflix OTT Revenue and Subscribers (CSV File),1,netflix-ott-revenue-and-subscribers-csv-file,netflix_revenue_updated.csv,CC0-1.0,"Netflix OTT Revenue and Number of Paid Subscribers dataset contains the revenue of Netflix  in dollars and number of paid subscribers region wise. 

**Note** : Netflix's financial year is from Jan 1st to 31st Dec.

**Data Dictionary (column description)**

Date : Month-Year of Quarter .

Global Revenue: Revenue collected Worldwide (Streaming Revenue + United States Domestic DVD Revenue).
UCAN : United States and Canada
EMEA : Europe, Middle East and Africa
APAC : Asia-Pacific
LATM : Latin America

ARPU is average revenue per member and it is calculated as streaming revenue divided by number of month in period, i.e. , for quarter is 3 months (here).
All revenue is in US Dollars.  

For older versions :
From 2019 till today, Netflix released data region wise, before that It released as Domestic market
(UACN) and International Market.
Before 2019, global users are higher in number because it in lost his subscribers drastically. [Read Here](https://www.cnbc.com/2019/07/18/why-netflix-says-it-had-a-rare-subscriber-loss-in-q2-2019.html)
[Read Here](https://www.forbes.com/sites/stephenmcbride1/2019/11/11/in-24-hours-netflix-could-lose-25-of-its-subscribers/?sh=20e217341b39)

**Note #1.  In 2019, difference in global and all region sum revenue is 297217000 USD . In 2020 is 239381000 USD. In 2021 is 182348000 USD. In 2022 is 145698000 USD. In Q1, 2023 is 31502000 USD. Excludes DVD revenues of $182 million, $146 million and $32 million for the years ended December 31, 2021, 2022, and the three months ended March 31, 2023, respectively. Q1, 2023 Financial Statement Excludes DVD revenues of $0.2 billion, $0.2 billion and $0.1 billion for the years ended December 31, 2020, 2021 and 2022, respectively. Total US revenues for the years ended December 31, 2020, 2021 and 2022 were $10.8 billion, $12.1 billion and $13.0 billion, respectively. Q4, 2022 Financial Statement**",.csv
Netflix Original Films & IMDB Scores ,1,netflix-original-films-imdb-scores,NetflixOriginals.csv,CC0-1.0,"### Context

This dataset consists of all Netflix original films released as of June 1st, 2021. Additionally, it also includes all Netflix documentaries and specials. The data was webscraped off of [this](https://en.wikipedia.org/wiki/Lists_of_Netflix_original_films) Wikipedia page, which was then integrated with a dataset consisting of all of their corresponding IMDB scores. IMDB scores are voted on by community members, and the majority of the films have 1,000+ reviews. 

### Content

Included in the dataset is: 

- Title of the film
- Genre of the film
- Original premiere date
- Runtime in minutes 
- IMDB scores (as of 06/01/21)
- Languages currently available (as of 06/01/21) 

### Acknowledgements

Thank you to Nakul Lakhotia, whose article I used as a reference to scrape the Wikipedia tables. [Here](https://medium.com/analytics-vidhya/web-scraping-a-wikipedia-table-into-a-dataframe-c52617e1f451) is the article I used. 

### Inspiration

I originally planned on using this data solely to make a public dashboard in Tableau, but I thought I would upload it to Kaggle in case anyone was interested in using this data. Integrating IMDB scores with this dataset was a pain, so I hope someone is able to make interesting correlations between the scores and other facets of the data. ",.csv
Netflix Reviews [DAILY UPDATED],1,netflix-reviews-playstore-daily-updated,netflix_reviews.csv,Apache 2.0,"This dataset contains information about the reviews given by netflix users on Google Play Store. Apart from the reviews, it also contains information about the ratings and the date of review as well as the likes on each of the review.",.csv
Netflix Stock Price Data set 2002-2022,1,netflix-stock-price-data-set-20022022,NFLX.csv,ODbL-1.0,"### Context
This is a Data set for Stock Price of Netflix .
This Data set start from 2002 to 2022 . 
It was collected from [Yahoo Finance](https://finance.yahoo.com/quote/NFLX/).
### Source
[Yahoo Finance](https://finance.yahoo.com/quote/NFLX/)",.csv
Netflix Stock Price Prediction,1,netflix-stock-price-prediction,NFLX.csv,CC0-1.0,"The Dataset contains data for 5 years ie. from 5th Feb 2018 to 5th Feb 2022

The art of forecasting stock prices has been a difficult task for many of the researchers and analysts. In fact, investors are highly interested in the research area of stock price prediction. For a good and successful investment, many investors are keen on knowing the future situation of the stock market. Good and effective prediction systems for the stock market help traders, investors, and analyst by providing supportive information like the future direction of the stock market.",.csv
Netflix Stock Price With Indicators,1,netflix-stock-price-with-indicators,nflx_2014_2023.csv,CC0-1.0,"This dataset offers an in-depth analysis of Netflix's stock performance over the last decade, incorporating numerous technical indicators to examine its price fluctuations. It includes the recording date and several vital statistics: the opening, highest, lowest, and closing prices for each trading day, along with the trading volume. It also contains momentum indicators like the 7-day and 14-day Relative Strength Index (RSI) to determine if the stock is overbought or oversold. The Commodity Channel Index (CCI) for 7 and 14 days is also included, helping identify short- and medium-term market trends by comparing the current price to the historical average. The dataset integrates the 50-day and 100-day Simple Moving Average (SMA) and Exponential Moving Average (EMA), which shed light on the stock's trend direction. Additional important indicators are the Moving Average Convergence Divergence (MACD), Bollinger Bands for assessing price volatility, the True Range, and the 7-day and 14-day Average True Range (ATR), which provide a gauge of market volatility. This dataset is designed to forecast the closing price for the following day, making it a crucial tool for predicting future movements of Netflix's stock.

Please find descriptions for the columns.

- **Open**: The price at which a stock first trades upon the opening of an exchange on a trading day.

- **High**: The highest price at which a stock traded during the trading day.

- **Low**: The lowest price at which a stock traded during the trading day.

- **Close**: The final price at which a stock trades during a trading day.

- **Volume**: The total number of shares of a stock traded during a trading day.

- **[RSI_7 / RSI_14](https://www.investopedia.com/terms/r/rsi.asp)**: The Relative Strength Index (RSI) is a momentum oscillator that measures the speed and change of price movements. RSI_7 and RSI_14 indicate the RSI calculated over 7 days and 14 days, respectively. https://www.investopedia.com/terms/r/rsi.asp


- **CCI_7 / CCI_14**: The Commodity Channel Index (CCI) is a versatile indicator that can be used to identify a new trend or warn of extreme conditions. CCI_7 and CCI_14 are calculated over 7 days and 14 days, respectively. https://www.investopedia.com/terms/c/commoditychannelindex.asp

- **SMA_50 / SMA_100**: The Simple Moving Average (SMA) is calculated by averaging the price of a stock over a specific number of days. SMA_50 and SMA_100 are the averages over 50 days and 100 days, respectively. https://www.investopedia.com/terms/s/sma.asp

- **EMA_50 / EMA_100**: The Exponential Moving Average (EMA) gives more weight to more recent prices and thus reacts more quickly to price changes than the SMA. EMA_50 and EMA_100 are calculated over 50 days and 100 days, respectively. https://www.investopedia.com/terms/e/ema.asp

- **MACD**: The Moving Average Convergence Divergence (MACD) is a trend-following momentum indicator that shows the relationship between two moving averages of a stock’s price. https://www.investopedia.com/terms/m/macd.asp

- **Bollinger Bands (Bollinger)**: A set of lines plotted two standard deviations (positively and negatively) away from a simple moving average (SMA) of a stock's price. https://www.investopedia.com/terms/b/bollingerbands.asp

- **True Range**: The greatest of the following: current high minus the current low, the absolute value of the current high minus the previous close, or the absolute value of the current low minus the previous close.

- **ATR_7 / ATR_14**: The Average True Range (ATR) is a measure of volatility that shows how much a stock moves, on average, over a given period. ATR_7 and ATR_14 are calculated over 7 days and 14 days, respectively. https://www.investopedia.com/terms/a/atr.asp

- **Next Day Close**: Future price. Closing price of a stock for the following trading day. Can be used as target variable for regression predictions.",.csv
Netflix Stock Trends & Insights Compilation 📊,1,netflix-stock-trends-and-insights-compilation,nflx_stock_data2.csv,Apache 2.0,"## A Detailed Examination of Netflix's Stock Data from 2023 to the Previous Trading Day

### Overview
This analysis focuses on Netflix Inc. (NFLX) stock performance over the period spanning from January 1, 2023, to the previous trading day. By analyzing daily stock data, we aim to provide insights into Netflix's financial trends, volatility, and factors influencing its stock price over the past year.

### Column Names
1. **Date:** The date of the stock data.
2. **Open:** The opening price of Netflix stock on the given date.
3. **High:** The highest price of Netflix stock during the trading day.
4. **Low:** The lowest price of Netflix stock during the trading day.
5. **Close:** The closing price of Netflix stock on the given date.
6. **Adj Close:** The adjusted closing price of Netflix stock, accounting for any corporate actions such as dividends or stock splits.
7. **Volume:** The trading volume of Netflix stock on the given date.
",.csv
Netflix TV Shows 2021,1,netflix-tv-shows-2021,netflix_shows.csv,MIT,"Netflix is an American subscription video on-demand over-the-top streaming service. The service primarily distributes original and acquired films and television shows from various genres, and it is available internationally in multiple languages",.csv
Netflix popular movies dataset,1,netflix-popular-movies-dataset,n_movies.csv,CC0-1.0,"## Context
This data is all about Movies That are available on [Netflix Website ](https://www.netflix.com/) **movies title, cast of the movie,desc of movies, duration, rating on IMDB, voted by people, year, genre, certificate**
## source
This dataset comes from the [IMDB website](https://www.imdb.com/) data is collected by using web scraping
## For movies recommenders system
 You can use this data for any project according to you",.csv
New Year Resolutions Dataset,1,new-year-resolutions-dataset,NewYear_Resolutions.csv,CC0-1.0,"This dataset contains information about New Year resolutions posted by users on Twitter. The data includes the tweet ID, username, gender, the resolution category, the tweet text, number of retweets, date and time of tweet creation, and the US state of the user. Column description as follow:-

**tweet_id:** Unique identifier for each tweet

**name:** Name or username of the Twitter user

**gender:** Gender of the Twitter user

**Resolution_Category:** Category under which the resolution falls

**text:** The actual text content of the tweet

**retweet_count:** Number of times the tweet has been retweeted

**tweet_created:** Date and time when the tweet was created

**tweet_state:** State/location information of the user",.csv
New York City - East River Bicycle Crossings,1,nyc-east-river-bicycle-crossings,nyc-east-river-bicycle-counts.csv,CC0-1.0,"### Context

The New York City Department of Transportation collects daily data about the number of bicycles going over bridges in New York City. This data is used to measure bike utilization as a part of transportation planning. This dataset is a daily record of the number of bicycles crossing into or out of Manhattan via one of the East River bridges (that is, excluding Bronx thruways and the non-bikeable Hudson River tunnels) for a stretch of 9 months.

### Content

A count of the number of bicycles on each of the bridges in question is provided on a day-by-day basis, along with information on maximum and minimum temperature and precipitation.

### Acknowledgements

This data is published in an Excel format by the City of New York ([here](https://data.cityofnewyork.us/Transportation/Bicycle-Counts-for-East-River-Bridges/gua4-p9wg)). It has been processed into a CSV file for use on Kaggle.

### Inspiration

* In this dataset, how many bicycles cross into and out of Manhattan per day?
* How strongly do weather conditions affect bike volumes?
* What is the top bridge in terms of bike load?",.csv
New York City Airbnb Open Data,1,new-york-city-airbnb-open-data,AB_NYC_2019.csv,CC0-1.0,"###Context

Since 2008, guests and hosts have used Airbnb to expand on traveling possibilities and present more unique, personalized way of experiencing the world. This dataset describes the listing activity and metrics in NYC, NY for 2019.

###Content

This data file includes all needed information to find out more about hosts, geographical availability, necessary metrics to make predictions and draw conclusions.

###Acknowledgements

This public dataset is part of Airbnb, and the original source can be found on this [website](http://insideairbnb.com).

###Inspiration

- What can we learn about different hosts and areas?
- What can we learn from predictions? (ex: locations, prices, reviews, etc)
- Which hosts are the busiest and why?
- Is there any noticeable difference of traffic among different areas and what could be the reason for it?",.csv
New York City Taxi Trip - Hourly Weather Data,1,new-york-city-taxi-trip-hourly-weather-data,Weather.csv,CC0-1.0,"### Hourly weather data for the New York City Taxi Trip Duration Challange

Here is some detailed weather data for the New York City Taxi Trip Duration Challange. I noticed that many contenders use daily weather data and thought that the ML could be improved with hourly data for NYC (default KNYC station) since pickup_datetime is given. python code on github can return same data for any city

### Content
Wundergrounds API provides hourly weather data in JSON format, but I assume most people just want the complete data set in csv. i stands for imperial, m for metric so the difference stands in the relative unit for the returned value (ex. Fahrenheit vs. Celsius).

Note that values will = -9999 or -999 for Null or Non applicable (NA) variables. (replaced with NaN in Version 2)
[Wundergrounds full Phrase Glossary][1]

- datetime: Date and time of day (EST)
- tempm: Temperature in Celcius
- tempi: Temperature in Fahrenheit
- dewptm: Dewpoint in Celcius
- dewpti: Dewpoint in Fahrenheit
- hum: Humidity %
- wspdm: Wind speed in kph
- wspdi: Wind speed in mph 
- wgustm: Wind gust in kph
- wgusti: Wind gust in mph
- wdird: Wind direction in degrees
- wdire: Wind direction description
- vism: Vivibility in Km
- visi: Visibility in miles
- pressurem: Pressure in mBar
- pressurei: Pressure in inHg
- windchillm: Wind chill in Celcius
- windchilli: Wind chill in Fahrenheit
- heatindexm: Heat index Celcius
- heatindexi: Heat index Fahrenheit
- precipm: Precipitation in mm
- precipi: Precipitation in inches
- conds: Conditions: [See full list of conditions][2]
- icon 
- fog: Boolean
- rain: Boolean
- snow: Boolean
- hail: Boolean
- thunder: Boolean
- tornado: Boolean

Thanks to Wunderground


  [1]: https://www.wunderground.com/weather/api/d/docs?d=resources/phrase-glossary&_ga=2.149985459.425490249.1500920794-834212210.1500800604&MR=1
  [2]: https://www.wunderground.com/weather/api/d/docs?d=resources/phrase-glossary&_ga=2.149985459.425490249.1500920794-834212210.1500800604&MR=1
  [3]: https://github.com/meinertsen/Hourly-Weatherdata",.csv
New York City Weather: A 154-Year Retrospective,1,new-york-city-weather-18692022,NYC_Central_Park_weather_1869-2022.csv,CC0-1.0,"## History
The National Weather Service has been formally recognizing weather observations taken in Central Park since January 1, 1869. Initially, the location of the measurements within the park varied. But since 1920, they have all been taken at the automated station at Belvedere Castle. That is over 100 years of observations taken in the exact same place, a rarity for weather stations. While the station is said to be automated, a human with a ruler still measures snowfall in Central Park.
## Content
This dataset contains six  columns:
- DATE = the date of the observation in the format YYYY-MM-DD
- PRCP = the amount of precipitation for the day, in inches
- SNOW = the amout of snowfall for the day, in inches
- SNWD = the measured snow depth on that day, in inches (missing before 1912)
- TMIN = the minimum temperature for the day, in degrees Fahrenheit
- TMAX = the maximum temperature for the day, in degrees Fahrenheit
## Acknowledgements
This dataset is derived from a dataset created by NOAA's [Global Historical Climatology Network daily (GHCNd)](https://www.ncei.noaa.gov/products/land-based-station/global-historical-climatology-network-daily) program.
 
Photo from [Pixabay](https://www.pexels.com/@pixabay/).
## Getting Started
There is a wealth of information in this dataset. To get familiar with it, you might try the following:
- Find the  maximum and minimum temperature, maximum rainfall, and maximum snowfall  over the entire record
- Do the same thing for each month
- Find the  maximum TMIN   and minimum TMAX over the record
- Average the data for each day of the year to create a seasonal cycle for the maximum and minimum temperatures
- Compute an anomaly set of maximum and minimum temperatures by subtracting  the seasonal cycles
- Compute the trends of the maximum and minimum temperature anomaly series you just made",.csv
New York Housing Market,1,new-york-housing-market,NY-House-Dataset.csv,other,"# Description:

&gt; This dataset contains prices of New York houses, providing valuable insights into the real estate market in the region. It includes information such as broker titles, house types, prices, number of bedrooms and bathrooms, property square footage, addresses, state, administrative and local areas, street names, and geographical coordinates.

# Key Features:

&gt; - **BROKERTITLE**: *Title of the broker*
- **TYPE**: *Type of the house*
- **PRICE**: *Price of the house*
- **BEDS**: *Number of bedrooms*
- **BATH**: *Number of bathrooms*
- **PROPERTYSQFT**: *Square footage of the property*
- **ADDRESS**: *Full address of the house*
- **STATE**: *State of the house*
- **MAIN_ADDRESS**: *Main address information*
- **ADMINISTRATIVE_AREA_LEVEL_2**: *Administrative area level 2 information*
- **LOCALITY**: *Locality information*
- **SUBLOCALITY**: *Sublocality information*
- **STREET_NAME**: *Street name*
- **LONG_NAME**: *Long name*
- **FORMATTED_ADDRESS**: *Formatted address*
- **LATITUDE**: *Latitude coordinate of the house*
- **LONGITUDE**: *Longitude coordinate of the house*

# Potential Use Cases:

&gt; - **Price analysis:** Analyze the distribution of house prices to understand market trends and identify potential investment opportunities.
- **Property size analysis:** Explore the relationship between property square footage and prices to assess the value of different-sized houses.
- **Location-based analysis:** Investigate geographical patterns to identify areas with higher or lower property prices.
- **Bedroom and bathroom trends:** Analyze the impact of the number of bedrooms and bathrooms on house prices.
- **Broker performance analysis:** Evaluate the influence of different brokers on the pricing of houses.



If you find this dataset useful, your support through an upvote would be greatly appreciated ❤️🙂
Thank you",.csv
New York State Math Test Results (2006-2012),1,new-york-state-math-test-results-2006-2012,NY_Math_Test_Results_2006-2012.csv,Apache 2.0,"# New York State Math Test Results

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F1937611%2Fd08067a1c078259d0026dde197817660%2F_7ceb67e5-e417-4a42-8b01-9b7cb8d78871.jpeg?generation=1715699004202376&alt=media)

This dataset presents detailed information on math examination results administered in New York State from 2006 to 2012. It includes the following categories:

- **Report Category**: The high-level grouping for each report.
- **Geographic Subdivision**: The individual schools or geographic subregion for each of the main categories.
- **Grade**: The school grade for which the test was administered.
- **Year**: The year the test was administered.
- **Student Category**: Reflects the set of students who were tested.
- **Number Tested**: Total number of students tested.
- **Mean Scale Score**: Average score of total students tested.
- **Num Level 1**: Number of students who scored in Level 1 range.
- **Pct Level 1**: Percentage of students who scored in Level 1 range.
- **Num Level 2**: Number of students who scored in Level 2 range.
- **Pct Level 2**: Percentage of students who scored in Level 2 range.
- **Num Level 3**: Number of students who scored in Level 3 range.
- **Pct Level 3**: Percentage of students who scored in Level 3 range.
- **Num Level 4**: Number of students who scored in Level 4 range.
- **Pct Level 4**: Percentage of students who scored in Level 4 range.
- **Num Level 3 and 4**: Number of students who scored in Level 3 and 4 range combined.
- **Pct Level 3 and 4**: Percentage of students who scored in Level 3 and 4 range.
",.csv
New York Surgeon Database 2024: 2000 Entries,1,new-york-surgeon-database-2024-2000-entries,surgeons_in_ny.csv,ODC Attribution License (ODC-By),"

#### Dataset Overview
This dataset, titled ""New York Surgeon Database 2024,"" encompasses detailed profiles of 2,000 surgeons operating in New York City. It was carefully compiled to serve as a resource for understanding healthcare provider distribution, specialties, and accessibility in one of the world's most dynamic urban environments. The dataset is intended for researchers, data scientists, and healthcare professionals interested in analyzing medical practice trends and specialties within New York.

#### Data Science Applications
This dataset is a valuable asset for various data science projects including:
- **Geospatial Analysis**: Mapping the locations of surgeons to study the accessibility and distribution across different neighborhoods.
- **Specialization Analysis**: Understanding prevalent medical specialties and identifying potential gaps in healthcare services.
- **Temporal Business Hours Analysis**: Investigating the operational hours of medical practices to gauge healthcare availability.
- **Sentiment Analysis**: Using review snippets to analyze patient satisfaction and service quality.

**Note**: This data is provided for educational and learning purposes only. Users are advised to respect privacy and use the data ethically without infringing on individual rights or data protection regulations.

#### Column Descriptors
- **address**: The physical address of the surgeon's practice.
- **categories/0, categories/1, categories/2**: Medical specialties and services offered.
- **extraPhones**: Additional contact numbers including fax and toll-free.
- **generalInfo**: Detailed description of the practice's services.
- **infoSnippet**: Short summary information about the practice.
- **name**: Name of the practice or individual surgeon.
- **openHours**: Hours during which the practice is open.
- **phone**: Primary phone number.
- **rating**: Customer rating of the practice.
- **reviewSnippet**: Extract of customer reviews.
- **website**: Official website URL of the practice.

#### Ethically Mined Data
The data for this dataset was ethically mined and aggregated from publicly available sources, namely the Yellow Pages. Strict adherence to ethical scraping guidelines ensures the data's integrity and respects individual privacy.

#### Acknowledgments
We thank Yellow Pages for providing the data and Photo by <a href=""https://unsplash.com/@gpiron?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Piron Guillaume</a> on <a href=""https://unsplash.com/photos/doctors-treating-patient-vNFHg0J0wRs?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
   used in visualizations and presentations related to this dataset. Their contributions have been invaluable in enhancing the comprehensiveness and visual appeal of this resource.

",.csv
New York Times India News Analysis,1,new-york-times-india-news-analysis,new_york_times_india.csv,other,"**New York Times India News Analysis** : It covers the India section of New York Times. This data have headlines and descriptions of it from November,2023 to April,2024. All data collected through web scrapping using python.

Data license depend on NYT sharing rules.",.csv
New Zealand Migration,1,migration-nz,migration_nz.csv,other,"### Context 

**This dataset shows the migration to and from New Zealand by country and citizenship from 1979 to 2016. **


### Content
The columns in this dataset are:

 - Measure: The signal type given in this row, one of: ""Arrivals"", ""Departures"", ""Net""
 - Country: Country from where people arrived into to New Zealand (for Measure = ""Arrivals"") or to where they left (for Measure = ""Departures""). Contains special values ""Not Stated"" and ""All countries"" (grand total)
 - Citizenship: Citizenship of the migrants, one of: ""New Zealand Citizen"", ""Australian Citizen"", ""Total All Citizenships""
 - Year: Year of the measurement
 - Value: Number of migrants

Permanent and long-term arrivals include overseas migrants who arrive in New Zealand intending to stay for a period of 12 months or more (or permanently), plus New Zealand residents returning after an absence of 12 months or more.
Permanent and long-term departures include New Zealand residents departing for an intended period of 12 months or more (or permanently), plus overseas visitors departing New Zealand after a stay of 12 months or more.
For arrival series, the country of residence is the country where a person arriving in New Zealand last lived for 12 months or more (country of last permanent residence).
For departure series, the country of residence is the country where a person departing New Zealand intends to live for the next 12 months or more (country of next permanent residence).


### Acknowledgements
Curated data by [figure.nz][1], original data from [Stats NZ][2]. Dataset licensed under [Creative Commons 4.0 - CC BY 4.0][3].


### Inspiration
A good challenge would be to explain New Zealand migration flows as a function of the economic performance of New Zealand or other countries (combine with other datasets). The data could be possibly linked up with other data sources to predict general migration to/from countries based on external factors.


  [1]: https://figure.nz
  [2]: http://www.stats.govt.nz/infoshare/
  [3]: https://creativecommons.org/licenses/by/4.0/",.csv
News Articles,1,news-articles,Articles.csv,CC0-1.0,"# Content

This Dataset is scraped from https://www.thenews.com.pk website. It has news articles from 2015 till date related to business and sports. It Contains the Heading of the particular Article, Its content and its date. The content also contains the place from where the statement or Article was published.

# Importance

This dataset can be used to detect main patterns between writing pattern of different types of articles. One more thing that can be extracted from it is that we could also detect the main locations from where the different types of articles originate.

# Improvements

Some Data Cleaning could still be done specially in the content area of the dataset. One more thing that could be done is that we could extract the locations from the content and make a separated table for it.


# Acknowledgements

I'd like to thanks developer of Selenium Library. That helped a lot in retrieving the data.",.csv
News Detection (Fake or Real) Dataset,1,news-detection-fake-or-real-dataset,fake_and_real_news.csv,MIT,"The Fake News Detection Dataset is created to assist researchers, data scientists, and machine learning enthusiasts in tackling the challenge of distinguishing between genuine and false information in today's digital landscape inundated with social media and online channels. With thousands of news items labeled as either ""Fake"" or ""Real,"" this dataset provides a robust foundation for training and testing machine learning models aimed at automatically detecting deceptive content.

Each entry in the dataset contains the full text of a news article alongside its corresponding label, facilitating the development of supervised learning projects. The inclusion of various types of content within the news articles, ranging from factual reporting to potentially misleading information or falsehoods, offers a comprehensive resource for algorithmic training.

The dataset's structure, with a clear binary classification of news articles as either ""Fake"" or ""Real,"" enables the exploration of diverse machine learning approaches, from traditional methods to cutting-edge deep learning techniques.

By offering an accessible and practical dataset, the Fake News Detection Dataset aims to stimulate innovation in the ongoing battle against online misinformation. It serves as a catalyst for research and development within the realms of text analysis, natural language processing, and machine learning communities. Whether it's refining feature engineering, experimenting with state-of-the-art transformer models, or creating educational tools to enhance understanding of fake news, this dataset serves as an invaluable starting point for a wide range of impactful projects.",.csv
Newyork Room Rental Ads,1,newyork-room-rentalads,room-rental-ads.csv,CC0-1.0,"### Context
This data set consist of house and commercial space ads from various sources.These ads are classified as vague or not according to the description posted by the people.


### Content
This file consist of two columns - description given by the people and Vague or not. Vague ads are labelled  as  0.


### Acknowledgements
This is done during the internship at Tact Labs. Thanks to Aishwarya who helped me in collecting the dataset.
 ",.csv
NextEra Energy Inc. Stocks,1,nextera-energy-inc-stocks,NEE.csv,CC0-1.0,"This dataset covers the stock prices of NewEra Energy Inc. a distributor of renewable energy such as electricity. The columns are as follows:

```Date``` - The date

```Open``` - The opening value

```High``` - The highest value

```Low``` - The lowest value

```Close``` - The closing value

```Adj Close``` - The adjusted closing value

```Volume``` - The trading volume of the stocks

I hope you will like this dataset. God bless you.",.csv
Nifty 50 (NSEI) Index Price Data (2015-2023),1,nifty-50-nsei-index-price-data-2015-2023,NSEI 2015-2023.csv,CC0-1.0,"This dataset provides a comprehensive collection of historical price data for the Nifty 50 Index (NSEI), spanning from the year 2015 to 2023. The Nifty 50 Index is the premier benchmark stock market index in India, representing the performance of the country's top 50 blue-chip companies listed on the National Stock Exchange of India (NSE). The dataset comprises daily records of key price indicators, including opening, closing, highest, and lowest prices, along with corresponding trading volumes.",.csv
Nifty50_Index_data,1,nifty50-index-data,Nifty50.csv,Apache 2.0,"The Nifty 50 Index data provides a comprehensive overview of the performance of the top 50 actively traded stocks listed on the National Stock Exchange of India (NSE). This dataset encompasses a wide range of industries, including finance, technology, healthcare, and consumer goods, offering insights into the overall health and direction of the Indian stock market.

Included in the data are key metrics such as daily opening and closing prices, high and low prices, trading volume, and percentage changes. These metrics allow analysts and investors to track trends, identify patterns, and make informed decisions regarding investment strategies.

Additionally, the dataset may incorporate historical data, enabling users to conduct thorough analyses over specific time periods and assess the long-term performance of individual stocks or the index as a whole. Whether used for research, financial modeling, or investment decision-making, the Nifty 50 Index data serves as a valuable resource for understanding and navigating the dynamic landscape of the Indian stock market.",.csv
Nigerian Foods,1,nigerian-foods,Nigerian Foods.csv,Apache 2.0,"This dataset provides a sample of 100+ Nigerian food items. It includes information on the food's name, main ingredients, a brief description, food health (generally healthy, moderately healthy, or not healthy), food class (traditional, snack, breakfast, etc.), region of origin, spice level (mild, medium, or spicy), and price range (affordable, moderate, expensive, or very expensive).

This data can be used to explore the variety of Nigerian cuisine, understand the health profile of different dishes, and learn about regional specialties. 

The Data can be used for:
- Food Recommendation: Recommend dishes based on user preferences (e.g., spice level, region, dietary restrictions).
- Price Prediction: Predict the price range of a dish based on ingredients.
- Nutritional Analysis: Estimate the nutritional content of a dish based on ingredients.",.csv
Nike Shoes Sales,1,nike-shoes-sales,nike_shoes_sales.csv,Attribution 4.0 International (CC BY 4.0),"Nike is one of the largest and most recognizable athletic shoe brands in the world, known for their high-quality products and innovative designs. To gain insight into how Nike's shoes are received by consumers, a dataset has been compiled that contains information on Nike shoe sales, including customer reviews and ratings.

The dataset includes information on Nike shoes sold across a variety of platforms, including Nike's own website, Amazon, and other retailers. It contains data on the shoe model, colorway, size, price, and the number of reviews and ratings. Additionally, the dataset contains text data on customer reviews, allowing for a detailed analysis of consumer opinions and feedback.

By analyzing this dataset, researchers and analysts can gain insight into which Nike shoes are most popular among consumers, as well as the features and characteristics that customers value most in a shoe. This information could be used to inform future product design and marketing strategies for Nike and other shoe brands.

Furthermore, consumers and shoe enthusiasts can benefit from this dataset to make more informed decisions about purchasing Nike shoes based on the experiences of other customers. The dataset may also be used by retailers to optimize their inventory and marketing strategies based on popular models, sizes, and colorways. Overall, this dataset has the potential to provide valuable insights for both the industry and consumers, shedding light on the factors that contribute to the success of Nike's shoes.",.csv
Nobel Prize Dataset,1,nobel-prize,complete.csv,other,"### Context

&gt; * The Nobel Prize is a set of annual international awards bestowed in several categories by Swedish and Norwegian institutions in recognition of academic, cultural, or scientific advances. 
&gt;* The will of the Swedish chemist, engineer and industrialist Alfred Nobel established the five Nobel prizes in 1895. 
&gt; * The prizes in Chemistry, Literature, Peace, Physics, and Physiology or Medicine were first awarded in 1901.
&gt; * The prizes are widely regarded as the most prestigious awards available in their respective fields

### Content

&gt; There are two JSON files
&gt; 1. **json_award.json** - Contains data Nobel prize data in the format Year&Category - Winner(s)
&gt; 2. **json_laureates.json** - Contains data Nobel prize laureates data in the format Winner - Year(s)&Category
   
&gt; * The CSV files are available both in raw and clean form
&gt; * The Nobel Prize laureate can be a person or an organization
&gt; * **csv_clean_laureates_persons.csv** - contains people who won Nobel prize with their birth and death information
&gt; * **csv_clean_laureates_organization.csv** - contains organizations that won Nobel prize with it's founded date and place information

### Acknowledgements / Data Source

&gt; https://www.nobelprize.org/about/developer-zone-external-resources-and-examples/

### Collection methodology

&gt; https://github.com/imdevskp/nobel-data-scraping-munging-cleaning",.csv
North America Central FNCS Grand Finals Statistics,1,north-america-central-fncs-grand-finals-placements,NAC FNCS.csv,CC0-1.0,"**Content**
The dataset contains the Grand Finals statistics for the NA Central region. Day1 consists of the first 6 games, and Day2 contains the last 6.

Date: Day 1. Each Grand Finals is a two day event. The Date column lists the first day of competition. The second day of competition is just one day later.

Season: The Chapter and Season of the Grand Finals. CH - Chapter; S - Season

Place: Final Placement at the end of the two day Grand Finals

Player1, Player2: The names of the two players in each duo competing together.

Points: Total number of points at the end of the two day Grand Finals.

Wins: Total number of wins at the end of the two day Grand Finals.

Avg. Points: Average number of points scored per duo over the 12 games.

Avg. Place: Average placement by the duo over the 12 games.

Total Eliminations: Total number of eliminations at the end of the two day Grand Finals.

Avg. Elims: Average eliminations by the duo over the 12 games.

K/D: Eliminations (Kills) / Death Rate

Game1-12 Place: Placement by the duo for each of the 12 games.

Game1-12 Elims: Eliminations by the duo for each of the 12 games.

**Missing Data**
Missing data in the csv is handled through ""-1"" in the Game Place/Elim columns.
These can occur if a duo doesn't load into the match, or a game crash prior to the match.

**Acknowledgements**
I collected the data by hand from Fortnite Tracker website (https://fortnitetracker.com/).
The public Fortnite Tracker API was disabled.",.csv
North American Hurricanes from 2000,1,north-american-hurricanes-from-2000,Hurricane Data.csv,CC0-1.0,"This dataset contains information on hurricanes that affect the continent of North America. The columns are as follows:

```Year``` - The year

```Name``` - The name of the hurricane

```Category``` - The category of the hurricane. They are:
- ```TS``` - Tropical Storm
- ```1``` - Category 1
- ```2``` - Category 2
- ```3``` - Category 3
- ```4``` - Category 4
- ```5``` - Category 5

```Rain Inch.``` - The amount of rain that fell in inches

```Highest Wind Speed``` - The highest wind speed achieved by the hurricane

```Damage(USD)``` - The cost of damage in US dollars

```Fatalities``` - The amount of deaths

```Areas Affected``` - The area affected by the hurricane

I hope you will like this dataset. God bless you.",.csv
Nuclear Share of Electricity Generation,1,nuclear-share-of-electricity-generation,Nuclear_Electricity_Statistics_2022.csv,other,"### Dataset Overview
This dataset provides a detailed snapshot of nuclear electricity generation across various countries for the year 2022. It is ideal for those interested in energy statistics and the role of nuclear power in global electricity markets. The data includes total net electrical capacity in megawatts (MW), number of operated reactors, nuclear electricity supplied in gigawatt-hours (GW.h), and the nuclear share of total electricity generation in percentages.

### Data Science Application
This dataset is well-suited for beginners in data science looking to practice basic data manipulation and visualization techniques. With 31 datasets available, users can employ libraries like Matplotlib and Pandas in Python to create meaningful visualizations. This collection allows for exploratory data analysis, helping learners to understand trends in nuclear energy usage and its impact on electricity generation across different nations.

### Column Descriptors
- **Country**: The name of the country.
- **Total Net Electrical Capacity [MW]**: The total net electrical capacity of nuclear reactors in megawatts.
- **Number of Operated Reactors**: The total number of operational nuclear reactors.
- **Nuclear Electricity Supplied [GW.h]**: The total nuclear electricity supplied in gigawatt-hours for the year.
- **Nuclear Share [%]**: The percentage of total electricity generation that comes from nuclear power.

### Ethically Mined Data
This dataset has been compiled using information from the International Atomic Energy Agency (IAEA), ensuring ethical data collection practices.

### Acknowledgements
Special thanks to the International Atomic Energy Agency (IAEA) for providing the data. Additionally, gratitude is extended to Dall-E 3 for the creation of compelling imagery used in representing this dataset.",.csv
Nursery,1,nursery,nursery.csv,other,"## **Past Usage:**

   The hierarchical decision model, from which this dataset is
   derived, was first presented in 

   M. Olave, V. Rajkovic, M. Bohanec: An application for admission in
   public school systems. In (I. Th. M. Snellen and W. B. H. J. van de
   Donk and J.-P. Baquiast, editors) Expert Systems in Public
   Administration, pages 145-160. Elsevier Science Publishers (North
   Holland)}, 1989.

   Within machine-learning, this dataset was used for the evaluation
   of HINT (Hierarchy INduction Tool), which was proved to be able to
   completely reconstruct the original hierarchical model. This,
   together with a comparison with C4.5, is presented in

   B. Zupan, M. Bohanec, I. Bratko, J. Demsar: Machine learning by
   function decomposition. ICML-97, Nashville, TN. 1997 (to appear)

## **Relevant Information Paragraph:**

   Nursery Database was derived from a hierarchical decision model
   originally developed to rank applications for nursery schools. It
   was used during several years in 1980's when there was excessive
   enrollment to these schools in Ljubljana, Slovenia, and the
   rejected applications frequently needed an objective
   explanation. The final decision depended on three subproblems:
   occupation of parents and child's nursery, family structure and
   financial standing, and social and health picture of the family.
   The model was developed within expert system shell for decision
   making DEX (M. Bohanec, V. Rajkovic: Expert system for decision
   making. Sistemica 1(1), pp. 145-157, 1990.).

## **Attribute Values:**
| Features | Values|
| --- | --- |
| parents | usual, pretentious, great_pret |
| has_nurs | proper, less_proper, improper, critical, very_crit |
| form | complete, completed, incomplete, foster |
| children | 1, 2, 3, more |
| housing | convenient, less_conv, critical |
| finance | convenient, inconv |
| social | non-prob, slightly_prob, problematic |
| health | recommended, priority, not_recom |",.csv
NutriKit: Your Ultimate Food Database,1,diet-dataset-calorie,Calorie_value.csv,CC-BY-NC-SA-4.0,"This dataset presents a comprehensive nutrition database featuring a wide array of food items categorized into fruits, grains, beverages, vegetables, meats, nuts & seeds, salads, soups, dairy products, sandwiches, and breads. Each entry includes essential nutritional information such as average serving size, calorie content, and category classification. With over [insert number] food items meticulously documented, this dataset serves as a valuable resource for nutritionists, dietitians, researchers, and individuals interested in understanding the nutritional composition of various foods.
Delve into the world of nutrition with this extensive dataset comprising a diverse range of food items. From familiar fruits like apples and bananas to exotic grains like teff and quinoa, each entry provides insights into average serving sizes and calorie counts. Whether you're analyzing the calorie content of your favorite fruits, exploring the nutritional benefits of different grains, or comparing the calorie density of various beverages, this dataset offers a comprehensive overview of the nutritional landscape across different food categories.
Unlock a wealth of practical applications and research opportunities with this detailed nutrition dataset. Explore correlations between serving sizes and calorie content, examine dietary trends across different food categories, or develop predictive models for calorie estimation. Nutritionists can leverage this dataset to formulate personalized diet plans, while food manufacturers can use it to develop healthier product offerings. Researchers can also use this dataset to investigate dietary patterns and their impact on health outcomes, paving the way for evidence-based nutritional interventions and policies.",.csv
"Nutrition, Physical Activity, and Obesity",1,nutrition-physical-activity-and-obesity,Nutrition__Physical_Activity__and_Obesity.csv,CC0-1.0,"This dataset includes data on adult's diet, physical activity, and weight status from Behavioral Risk Factor Surveillance System. This data is used for DNPAO's Data, Trends, and Maps database, which provides national and state specific data on obesity, nutrition, physical activity, and breastfeeding.

Tabular data includes:

- `YearStart`
- `YearEnd`
- `LocationAbbr`
- `LocationDesc`
- `Datasource`
- `Class`
- `Topic`
- `Question`
- `Data_Value_Unit`
- `Data_Value_Type`
- `Data_Value`
- `Data_Value_Alt`
- `Data_Value_Footnote_Symbol`
- `Data_Value_Footnote`
- `Low_Confidence_Limit`
- `High_Confidence_Limit`
- `Sample_Size`
- `Total`
- `Age(years)`
- `Education`
- `Gender`
- `Income`
- `Race/Ethnicity`
- `GeoLocation`
- `ClassID`
- `TopicID`
- `QuestionID`
- `DataValueTypeID`
- `LocationID`
- `StratificationCategory1`
- `Stratification1`
- `StratificationCategoryID1`
- `StratificationID1`",.csv
Nutritional Facts for most common foods,1,nutrition-details-for-most-common-foods,nutrients_csvfile.csv,CC0-1.0,"### Context

Everybody nowadays is mindful of what they eat. 🥑Counting calories and reducing fat intake is the number one advice given by all dieticians and nutritionists. Therefore, we need to know what foods are rich in what nutrients, don't we?

### Content

The dataset contains a csv file with more than 300 foods each with the amount of Calories, Fats, Proteins, Saturated Fats, Carbohydrates, Fibers labelled for each food. Also, the foods are also categorised into various groups like Desserts, Vegetables, Fruits etc.
Note: ""t"" indicates that only a trace amount is available(miniscule) 


### Acknowledgements

References: 
* [Food Nutrient List from Wikipedia](https://en.wikipedia.org/wiki/Table_of_food_nutrients)

",.csv
Nutritional values for common foods and products,1,nutritional-values-for-common-foods-and-products,nutrition.csv,CC0-1.0,"### Context

I found this data occasionally and I just could not pass by. So I hope that this dasatet will help anyone who interested in food nutrition values.


### Content

This dataset contains nutrition values for about 8.8k types of food. The features names is very self-explanatory, so I'll not make a description for them.",.csv
OCD Patient Dataset: Demographics & Clinical Data,1,ocd-patient-dataset-demographics-and-clinical-data,ocd_patient_dataset.csv,other,"The ""OCD Patient Dataset: Demographics & Clinical Data"" is a comprehensive collection of information pertaining to 1500 individuals diagnosed with Obsessive-Compulsive Disorder (OCD). This dataset encompasses a wide range of parameters, providing a detailed insight into the demographic and clinical profiles of these individuals.

Included in this dataset are key demographic details such as age, gender, ethnicity, marital status, and education level, offering a comprehensive overview of the sample population. Additionally, clinical information like the date of OCD diagnosis, duration of symptoms, and any previous psychiatric diagnoses are recorded, providing context to the patients' journeys.

The dataset also delves into the specific nature of OCD symptoms, categorizing them into obsession and compulsion types. Severity of these symptoms is assessed using the Yale-Brown Obsessive-Compulsive Scale (Y-BOCS) scores for both obsessions and compulsions. Furthermore, it documents any co-occurring mental health conditions, including depression and anxiety diagnoses.

Notably, the dataset outlines the medications prescribed to patients, offering valuable insights into the treatment approaches employed. It also records whether there is a family history of OCD, shedding light on potential genetic or environmental factors.

Overall, this dataset serves as a valuable resource for researchers, clinicians, and mental health professionals seeking to gain a deeper understanding of OCD and its manifestations within a diverse patient population.",.csv
OSMI Mental Health in Tech Survey 2017,1,osmi-mental-health-in-tech-survey-2017,OSMI Mental Health in Tech Survey 2017.csv,CC-BY-SA-4.0,"OSMI Mental Health in Tech Survey 2017

The 2017 survey aims to measure attitudes towards mental health in the tech workplace, and examine the frequency of mental health disorders among tech workers.
How Will This Data Be Used?

We are interested in gauging how mental health is viewed within the tech/IT workplace, and the prevalence of certain mental health disorders within the tech industry. The Open Sourcing Mental Illness team of volunteers will use this data to drive our work in raising awareness and improving conditions for those with mental health disorders in the IT workplace.",.csv
Obesity,1,obesity,csv-1.csv,other,"This dataset includes data on adult's diet, physical activity, and weight status from Behavioral Risk Factor Surveillance System. This data is used for DNPAO's Data, Trends, and Maps database, which provides national and state specific data on obesity, nutrition, physical activity, and breastfeeding.

Dataset:
You can find these interesting variables in the dataset:
1- Year start and year end
2- Location
3- Datasource
4- Class
And many more...

This dataset belongs to 
U.S. Department of Health & Human Services",.csv
Obesity Classification Dataset,1,obesity-classification-dataset,Obesity Classification.csv,Attribution 4.0 International (CC BY 4.0),"This dataset contains information about the obesity classification of individuals. The data was collected from a variety of sources, including medical records, surveys, and self-reported data. The dataset includes the following columns:

ID: A unique identifier for each individual
Age: The age of the individual
Gender: The gender of the individual
Height: The height of the individual in centimeters
Weight: The weight of the individual in kilograms
BMI: The body mass index of the individual, calculated as weight divided by height squared
Label: The obesity classification of the individual, which can be one of the following:
Normal Weight
Overweight
Obese
Underweight",.csv
Obesity Risk Dataset,1,obesity-risk-dataset,obesity_level.csv,MIT,"Overview:
This Kaggle dataset provides comprehensive information on individuals, encompassing key attributes such as gender, age, height, weight, family history with overweight, dietary habits, physical activity, transportation mode, and the corresponding obesity level. The dataset is meticulously curated for research and analysis in the domain of health and lifestyle studies.

Tags:

Gender
Age
Height
Weight
Family_history_with_overweight
FAVC (Frequent consumption of high-caloric food)
FCVC (Frequency of consumption of vegetables)
NCP (Number of main meals)
CAEC (Consumption of food between meals)
SMOKE
CH2O (Daily water consumption)
SCC (Caloric beverages consumption)
FAF (Physical activity frequency)
TUE (Time spent using technological devices)
CALC (Consumption of alcohol)
MTRANS (Mode of transportation)
0be1dad (Target variable representing obesity level)",.csv
Obesity Risk Prediction Cleaned,1,obesity-risk-prediction-cleaned,estimation_of_obesity_levels_based_on_eating_habits_and_physical_condition.csv,other,"This dataset was taken from [UCI library](https://archive.ics.uci.edu/dataset/544/estimation+of+obesity+levels+based+on+eating+habits+and+physical+condition). It has been cleaned using techniques- z-score normalization, one-hot encoding, outlier removal, min-max scaling, and feature selection.",.csv
Obesity or CVD risk (Classify/Regressor/Cluster),1,obesity-or-cvd-risk-classifyregressorcluster,ObesityDataSet.csv,CC-BY-SA-4.0,"The data consist of the estimation of obesity levels in people from the countries of Mexico, Peru and Colombia, with ages between 14 and 61 and diverse eating habits and physical condition , data was collected using a web platform with a survey where anonymous users answered each question, then the information was processed obtaining 17 attributes and 2111 records. 
                   The attributes related with eating habits are: Frequent consumption of high caloric food (FAVC), Frequency of consumption of vegetables (FCVC), Number of main meals (NCP), Consumption of food between meals (CAEC), Consumption of water daily (CH20), and Consumption of alcohol (CALC). The attributes related with the physical condition are: Calories consumption monitoring (SCC), Physical activity frequency (FAF), Time using technology devices (TUE), Transportation used (MTRANS)
 variables obtained :
 Gender, Age, Height and Weight. 


 NObesity values are:    

•Underweight Less than 18.5
•Normal 18.5 to 24.9
•Overweight 25.0 to 29.9
•Obesity I 30.0 to 34.9
•Obesity II 35.0 to 39.9
•Obesity III Higher than 40

The data contains numerical data and continous data, so it can be used for analysis based on algorithms of classification, prediction, segmentation and association. Data is available in CSV format.",.csv
Obesity prediction,1,obesity-prediction,obesity_data.csv,Apache 2.0,"The Obesity Prediction Dataset provides a comprehensive collection of attributes related to individuals' demographics, lifestyle habits, and health indicators, aimed at facilitating the prediction of obesity prevalence. This dataset offers a valuable resource for researchers, data scientists, and healthcare professionals interested in exploring the complex interplay of factors contributing to obesity and developing effective intervention strategies.",.csv
ObesityRisk,1,obesityrisk,s.csv,MIT,"This dataset, labeled NObeyesdad, offers a comprehensive exploration into the prediction of obesity risk across multiple classes. With over thousands of entries, each tagged with corresponding weight categories such as Normal Weight, Overweight, Obesity Type I, II, and III, the dataset serves as a valuable resource for developing predictive models aimed at understanding and mitigating obesity-related risks. ",.csv
Observations during the eclipse in Mexico,1,observations-during-the-eclipse-in-mexico,Eclipse_04082024.csv,Apache 2.0,"This dataset contains environmental sensor data collected during the 2024 solar eclipse event in Mexico City and Querétaro. The data was transmitted by two ESP32 microcontrollers, one located in Mexico City (CDMX) and the other in Querétaro. The sensors measure various environmental variables such as air quality, altitude, heat index, humidity, light intensity, pressure, temperature, and pH levels.

It's important to note that there were some communication issues during data collection, and the ESP32 in Querétaro does not have the same sensors as the one in Mexico City. As a result, there may be discrepancies in the data between the two locations.

This dataset is intended for exploratory analysis and research purposes, providing insights into environmental conditions during the eclipse event. Researchers and data enthusiasts can utilize this dataset to study the impact of solar eclipses on local environmental parameters and to explore potential correlations between environmental variables.

**Disclaimer:**

- The data may contain inconsistencies or missing values due to communication issues during data transmission.
- The ESP32 in Querétaro does not have the same sensors as the one in Mexico City, leading to potential differences in the recorded environmental variables between the two locations.
- For the ""Temperature of Tank"" variable, it represents water tank conditions in Querétaro, whereas in CDMX, it reflects ambient conditions.

**Dataset Contents:**

Air Quality (Air_Quality_1, Air_Quality_2)
Altitude
City
Country
Heat Index
Humidity
Light Intensity (Light)
Location
Pressure
Temperature
Temperature of Tank
Device
pH Levels
Time stamp (time)",.csv
Octopath Traveler II Equipment,1,octopath-traveler-ii-equipment,octopath_equipment.csv,CC0-1.0,"This dataset catalogs the diverse array of equipment available in Octopath Traveler II, a captivating RPG adventure. Each entry provides detailed specifications for various gear, aiding adventurers in optimizing their party's capabilities.

- Name: The unique name of the equipment.
- Maximum_HP: The maximum amount of HP (Hit Points) the equipment provides.
- Maximum_SP: The maximum amount of SP (Skill Points) the equipment provides.
- Physical_Attack: The equipment's contribution to physical attack power.
- Elemental_Attack: The equipment's contribution to elemental (magical) attack power.
- Physical_Defense: The degree of protection the equipment offers against physical attacks.
- Elemental_Defense: The degree of protection the equipment offers against elemental attacks.
- Accuracy: The equipment's effect on the wielder's accuracy in combat.
- Speed: The equipment's influence on the wielder's speed, affecting turn order in battles.
- Critical: The chance of landing a critical hit when using the equipment.
- Evasion: The equipment's impact on the wielder's ability to dodge incoming attacks.
- Effect: Any special effects or abilities conferred by the equipment.
- Buy_Price_Leaves: The price, in leaves (the in-game currency), required to purchase the equipment.
- Sell_Price_Leaves: The price, in leaves, at which the equipment can be sold.
- Source(s): The locations or methods through which the equipment can be obtained, including quests, merchants, or enemy drops.
- Equipment_Type: Categorization of the equipment type (e.g., weapon, armor, accessory).

This comprehensive dataset empowers players to make informed decisions about their party's loadout, ensuring they are adequately equipped to face the myriad challenges that await them in the world of Octopath Traveler II.",.csv
Octopath Traveler II Items,1,octopath-traveler-ii-items,octopath_items.csv,CC0-1.0,"This dataset provides a comprehensive list of items found within the realm of Octopath Traveler II, the highly acclaimed RPG sequel. Each entry includes details crucial for adventurers seeking to navigate their journey effectively.

- Name: The name of the item, as it appears in the game.
- Description: A brief description outlining the item's characteristics, potential uses, and any notable traits.
- Buy_Price_Leaves: The purchase price of the item in leaves, the game's currency, when acquiring it from a merchant or vendor.
- Sell_Price_Leaves: The amount of leaves a character receives when selling the item.
- Item_Type: Categorization of the item based on its function or nature, aiding in inventory management and strategic decision-making.

This dataset aims to empower players with the information necessary to make informed choices regarding their inventory, trading, and item usage throughout their epic adventures in the world of Octopath Traveler II.",.csv
Office Supply Sales,1,office-supply-sales,OfficeSupplies.csv,CC0-1.0,"### Context

Dummy data to demo matplotlib


### Content

43 CSV rows of sales (qty and price) of 5 products in 3 regions by 11 reps


### Acknowledgements

https://www.wintellect.com
https://www.superdatascience.com/


### Inspiration

Thanks!",.csv
"Oil Pipeline Accidents, 2010-Present",1,pipeline-accidents,database.csv,CC0-1.0,"# Content

This database includes a record for each oil pipeline leak or spill reported to the Pipeline and Hazardous Materials Safety Administration since 2010. These records include the incident date and time, operator and pipeline, cause of incident, type of hazardous liquid and quantity lost, injuries and fatalities, and associated costs.


# Acknowledgements

The oil pipeline accident reports were collected and published by the DOT's Pipeline and Hazardous Materials Safety Administration.",.csv
Oil Production Dataset,1,oil-production,oil_production_statistics.csv,other,"### Context
This dataset offers comprehensive insights into oil production across 36 countries from 2021 to 2023. With columns detailing country names, types of production, product specifications, flow information, and corresponding production values, it serves as a valuable resource for analysts, researchers, and policymakers in the energy sector. Understanding global oil production trends is critical for making informed decisions regarding energy policies, investments, and sustainability efforts.

### Content
Encompassing a wide array of data points, including country-specific production types, products, and production values over a thirteen-year period, this dataset facilitates detailed analyses of oil production dynamics. Researchers can delve into variations across countries, identify trends in production types and products, and explore the impact of geopolitical factors on oil production. By leveraging this dataset, stakeholders can gain actionable insights to optimize energy strategies, mitigate risks, and drive sustainable development in the oil sector.

### Dataset Structure:
The dataset (`oil_production_statistics.csv`) comprises data from 2021 to 2023 and consists of the following columns:

| Column Name   | Description                                |
| ------------- | ------------------------------------------ |
| `country_name`| Name of the country                        |
| `type`        | Type of statistics         |
| `product`     | Specification of oil production (e.g., crude, refined)           |
| `flow`        | Oil product movement and distribution (e.g., exports, imports)  |
| `year`        | Year of the production data                |
| `value`       | Production value                           |

### Acknowledgment
The primary dataset was sourced from [IEA (2024)](https://www.iea.org/data-and-statistics/data-product/monthly-oil-statistics) Monthly Oil Statistics, IEA, Paris, and I extend my sincere gratitude to the team for providing the core data used in this dataset.

© Image credit: [Freepik](https://www.freepik.com/premium-photo/oil-pump-rig-fuel-industry_18184848.htm)",.csv
Oil Spills,1,oil-spills,operationattimeofincident1970-2022.csv,CC0-1.0,"this was created in R,locker studio  and OurDataWorld: 

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F1186bf8ac2ec71e011a1f32b9cddd616%2Fgraph1.png?generation=1711827671921471&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F8c3da9f92a888c5377a37da35f9005f8%2Fgraph4.png?generation=1711827678203730&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fc1a7d4178e9eb1b22d6cf3ae45784bef%2Fgraph2.jpg?generation=1711827684461798&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F938f2204577ba7cb4a06e5e02c810f90%2Fgraph3.png?generation=1711827690124923&alt=media)


Oil spills are disasters that can have severe social, economic, and environmental impacts.

They are the release of crude oil or refined petroleum products from tankers, rigs, wells, and offshore platforms.

These spills are most common in marine environments but can also occur on land. They can have disastrous consequences for local ecosystems, and be expensive due to the loss of oil and the costs involved in their clean-up.

The number of oil spills and the quantity of oil that is spilled from tankers has fallen substantially in recent decades.1

On this page, you can find all our data, visualizations, and writing relating to oil spills. Specifically, this refers to oil spills from tankers – container ships transporting oil – where consistent, high-quality global data is available.

But not all oil spills come from tankers. They can also come from other sites, such as offshore oil rigs and damaged pipelines. The world’s largest (and most well-known) event was Deepwater Horizon in the Gulf of Mexico in 2010. This disaster was caused by an explosion in a drilling rig. The US Government estimates that 4.9 million barrels of oil were released (equivalent to around 700,000 tonnes).

Tracking non-tanker oil spills is essential, but we are unaware of any global, updated databases that include this. Filling this gap would be critical to global environmental data and monitoring.",.csv
Oil and Gas ,1,oil-and-gas,Oil and Gas 1932-2014.csv,other,"### Context

The Global dataset of oil and natural gas production, prices, exports, and net exports. 


### Content

Oil production and prices data are for 1932-2014 (2014 data are incomplete); gas production and prices are for 1955-2014; export and net export data are for 1986-2013. Country codes have been modified from earlier versions to conform to Correlates of War (COW) and Quality of Government (QOG) standards

### Acknowledgements

Ross, Michael; Mahdavi, Paasha, 2015, ""Oil and Gas Data, 1932-2014"", doi:10.7910/DVN/ZTPW0Y, Harvard Dataverse

### Inspiration

How has the price varied from 1900s to 2000s?
",.csv
"Oil, Gas & Other Fuels Futures Data",1,fuels-futures-data,all_fuels_data.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"This dataset provides comprehensive and up-to-date information on futures related to oil, gas, and other fuels. Futures are financial contracts obligating the buyer to purchase and the seller to sell a specified amount of a particular fuel at a predetermined price and future date.

**Use Cases**:
1. **Trend Analysis:** Scrutinize patterns and price fluctuations to anticipate future market directions in the energy sector.
2. **Academic Research:** Delve into the historical behavior of oil and gas prices and understand the influence of global events on these commodities.
3. **Trading Strategies:** Develop and test trading tactics based on the dynamics of oil, gas, and other fuel futures.
4. **Risk Management:** Utilize the dataset for hedging and risk management for corporations involved in the extraction, refining, or trading of fuels.

**Dataset Image Source**:
Photo by Pixabay: https://www.pexels.com/photo/industrial-machine-during-golden-hour-162568/

**Column Descriptions**:
1. **Date:** The date when the data was documented. Format: YYYY-MM-DD.
2. **Open:** Market's opening price for the day.
3. **High:** Peak price during the trading window.
4. **Low:** Lowest traded price during the day.
5. **Close:** Price at which the market closed.
6. **Volume:** Number of contracts exchanged during the trading period.
7. **Ticker:** The unique market quotation symbol for the future.
8. **Commodity:** Specifies the type of fuel the future contract pertains to (e.g., crude oil, natural gas).",.csv
Old car price prediction,1,old-car-price-prediction,car_price.csv,other,"The steps listed below must be included in your notebooks:

1. Understand the problem statement.
2. Import required libraries and Data.
3. Check the Data
4. Pre-processing and data cleansing should be done.
5. Utilize the provided dataset to conduct exploratory data analysis.
           Each and every graph you create should be explained.
6. Feature Selection
7. Data splitting
7. Create an ML model, then test it using various metrics.

Data source - https://www.cardekho.com/used-car-details
Cover image source - https://cdni.autocarindia.com/Utils/ImageResizer.ashx?n=https://cdni.autocarindia.com/Galleries/20200206032922_Tata-Harrier-BS6-5.jpg&w=872&h=578&q=75&c=1",.csv
Olympic Medal Data (Summer+Winter),1,olympic-medal-data-summer-winter,Olympic_Medal_Data.csv,Apache 2.0,"- Comprehensive dataset covering all-time Olympic medal standings.
- Encompasses both the Summer and Winter Olympics.
- Provides insights into countries' performances and medal distributions.",.csv
Omicron Rising,1,omicron-rising,omicron.csv,CC0-1.0,"### Context

These tweets are collected using Twitter API and a Python script. A query for this high-frequency hashtag (#Omicro) is run on a daily basis for a certain time period, to collect a larger number of tweets samples.

<img src=""https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F769452%2F35db2dd68238bfd958efdabebc9fef8f%2Fcovid-19-4961257_1280-e1586986896105.jpg?generation=1595760042647275&alt=media"">

The collection script is a variation of such script: https://github.com/gabrielpreda/covid-19-tweets

### Content

The tweets have #Omicron hashtag. Collection started on 30/11/2021, with an initial 3.1k batch and will continue on a daily basis.

### Inspiration

You can use this data to dive into the subjects that use this hashtag, look to the geographical distribution, evaluate sentiments, looks to trends.",.csv
Onion Time Series Dataset,1,onion-time-series-dataset,OnionTimeSeries - Sheet1.csv,Apache 2.0,"The dataset aims to provide insights into onion market dynamics, including trends in arrivals, pricing variations, and modal price trends over time. Analysts and researchers can utilize this dataset to analyze market behavior, assess pricing patterns, and identify factors influencing onion pricing fluctuations.  

##**Features:**

- **Commodity:** Type of commodity, with a focus on onions.
- **Date:** Date of observation for the onion market data.
- **Arrivals in Qtls.:** Quantity of onions arriving in the market, measured in quintals (Qtls.).
- **Min:**Minimum price observed for onions on the given date.
- **Max:** Maximum price observed for onions on the given date.
- **Modal:** Modal price of onions, representing the most frequently occurring price range.",.csv
Online Food Dataset,1,online-food-dataset,onlinefoods.csv,MIT,"# **Online Food Order Dataset**

**Description**:
The dataset contains information collected from an online food ordering platform over a period of time. It encompasses various attributes related to Occupation, Family Size, Feedback etc..

**Attributes**:

Demographic Information:

Age: Age of the customer.
Gender: Gender of the customer.
Marital Status: Marital status of the customer.
Occupation: Occupation of the customer.
Monthly Income: Monthly income of the customer.
Educational Qualifications: Educational qualifications of the customer.
Family Size: Number of individuals in the customer's family.
Location Information:

Latitude: Latitude of the customer's location.
Longitude: Longitude of the customer's location.
Pin Code: Pin code of the customer's location.
Order Details:

Output: Current status of the order (e.g., pending, confirmed, delivered).
Feedback: Feedback provided by the customer after receiving the order.

**Purpose**:
This dataset can be utilized to explore the relationship between demographic/location factors and online food ordering behavior, analyze customer feedback to improve service quality, and potentially predict customer preferences or behavior based on demographic and location attributes.",.csv
Online Food Delivery Preferences-Bangalore region,1,online-food-delivery-preferencesbangalore-region,onlinedeliverydata.csv,CC0-1.0,"### Context of dataset

There has been a rise in the demand of online delivery in the metropolitan cities such as Bangalore in India. The question about why this increase in the demand has always been a lingering question. So a survey is conducted and the data is presented.


### Content

The dataset has nearly 55 variables based on the following titles
1. Demographics of consumers
2. Overall/general purchase decision 
3. Time of delivery influencing the purchase decision 
4. Rating of Restaurant influencing the purchase decision 


### This dataset can be useful for
1. Classification modelling (Whether this consumer will buy again or not)
2. Text analysis (Reviews of consumers)
3. Geo-spatial Analysis (location-latitude and longitude of consumers)


### Inspiration

This dataset was collected as a part of my masters thesis",.csv
Online Gaming Anxiety Data ,1,online-gaming-anxiety-data,GamingStudy_data.csv,Attribution 4.0 International (CC BY 4.0),"This dataset consists of data collected as a part of a survey among gamers worldwide. The questionnaire asked questions that psychologists generally ask people who are prone to anxiety, social phobia, and less to no life satisfaction. The questionnaire consists of several set of questions as asked as a part of psychological study. The original data was collated by Marian Sauter and Dejan Draschkow. ",.csv
Online Gaming Transaction History,1,online-gaming-transaction-history,Online_Gaming_Transaction_History.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"A player's transaction history from an online gaming platform.

Columns include Date/Time, Category, Transaction Type, Description, Wallet, Amount (CAD), and End Balance.

Categories are Banking, Bonus, Gaming, and Lottery.

Transaction Types are Stake, Win, Deposit, Activated, Expired, Purchase, Prize, and Payment.

The Description Column features game titles such as ""777 Strike,"" or ""Triple Gold Bars.""

There are two types of Wallet, Cash, and Casino. The Casino Wallet represents conditional promotion amounts, and the Cash wallet represents the user's funds.

The Amount (CAD) and End Balance Columns contained strings that represented signed floating point values and the Regular Expression, ""^[+-]?\d+(\.\d+)$"", was used to pattern match every value in this column and replace it with the appropriately signed floating point value.

The End Balance Column represents the change in Wallet from the previous transaction given the value of the Amount (CAD) Column.",.csv
Online Retail Customer Churn Dataset,1,online-retail-customer-churn-dataset,online_retail_customer_churn.csv,CC0-1.0,"## Overview:
&gt;This dataset provides a comprehensive overview of customer interactions with an online retail store, aiming to predict customer churn based on various behavioral and demographic features. It includes data on customer demographics, spending behavior, satisfaction levels, and engagement with marketing campaigns. The dataset is designed for analysis and development of predictive models to identify customers at risk of churn, enabling targeted customer retention strategies.

## Description of Columns:

&gt; - **Customer_ID**: A unique identifier for each customer.
- **Age**: The customer's age.
- **Gender**: The customer's gender (Male, Female, Other).
- **Annual_Income**: The annual income of the customer in thousands of dollars.
- **Total_Spend**: The total amount spent by the customer in the last year.
- **Years_as_Customer**: The number of years the individual has been a customer of the store.
- **Num_of_Purchases**: The number of purchases the customer made in the last year.
- **Average_Transaction_Amount**: The average amount spent per transaction.
- **Num_of_Returns**: The number of items the customer returned in the last year.
- **Num_of_Support_Contacts**: The number of times the customer contacted support in the last year.
- **Satisfaction_Score**: A score from 1 to 5 indicating the customer's satisfaction with the store.
- **Last_Purchase_Days_Ago**: The number of days since the customer's last purchase.
- **Email_Opt_In**: Whether the customer has opted in to receive marketing emails.
- **Promotion_Response**: The customer's response to the last promotional campaign (Responded, Ignored, Unsubscribed).
- **Target_Churn**: Indicates whether the customer churned (True or False).
",.csv
Online Shoppers Intention UCI Machine Learning,1,online-shoppers-intention,online_shoppers_intention.csv,other,"**Data Set Information:**

The dataset consists of feature vectors belonging to 12,330 sessions.
The dataset was formed so that each session
would belong to a different user in a 1-year period to avoid
any tendency to a specific campaign, special day, user
profile, or period.

**Dataset Origin:**

[https://archive.ics.uci.edu/ml/datasets/Online+Shoppers+Purchasing+Intention+Dataset](https://archive.ics.uci.edu/ml/datasets/Online+Shoppers+Purchasing+Intention+Dataset)

**Source:**

1. C. Okan Sakar
Department of Computer Engineering, Faculty of
Engineering and Natural Sciences, Bahcesehir University,
34349 Besiktas, Istanbul, Turkey

2. Yomi Kastro
Inveon Information Technologies Consultancy and Trade,
34335 Istanbul, Turkey

**Relevant Papers:**

Sakar, C.O., Polat, S.O., Katircioglu, M. et al. Neural Comput & Applic (2018). [[Web Link]](https://doi.org/10.1007/s00521-018-3523-0)

**Citation Request:**

If you use this dataset, please cite:
Sakar, C.O., Polat, S.O., Katircioglu, M. et al. Neural Comput & Applic (2018). [[Web Link]](https://doi.org/10.1007/s00521-018-3523-0)

**Cover Photo:**

Photo by [Bruno Kelzer on Unsplash](https://unsplash.com/photos/LvySG1hvuzI)

Dataset downloaded from UCI Machine Learning Repository.

Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [[http://archive.ics.uci.edu/ml](http://archive.ics.uci.edu/ml)]. Irvine, CA: University of California, School of Information and Computer Science.",.csv
Online-eCommerce,1,online-ecommerce,Online-eCommerce.csv,CC0-1.0,"Online eCommerce refers to the buying and selling of goods or services over the internet. It enables consumers to browse, select, and purchase products from the comfort of their homes or anywhere with internet access. Retailers leverage eCommerce platforms to showcase their products, facilitate transactions, and manage inventory efficiently. Customers benefit from a wide variety of choices, competitive prices, and convenient payment and delivery options. eCommerce has revolutionized retail by providing a seamless and accessible shopping experience, fostering global trade, and empowering businesses of all sizes to reach a broader audience.",.csv
Open Exoplanet Catalogue,1,open-exoplanet-catalogue,oec.csv,other,"Our first glimpse at planets outside of the solar system we call home came in 1992 when several terrestrial-mass planets were detected orbiting the pulsar PSR B1257+12. In this dataset, you can become a space explorer too by analyzing the characteristics of all discovered exoplanets (plus some familiar faces like Mars, Saturn, and even Earth). Data fields include **planet** and **host star attributes**, **discovery methods**, and (of course) **date of discovery**.

Data was originally collected and continues to be updated by [Hanno Rein][1] at the [Open Exoplanet Catalogue Github repository][2]. If you discover any new exoplanets, please submit a pull request there.

## Constants

- **Jupiter mass**: 1.8991766e+27 kg

- **Solar mass**: 1.9891e+30 kg

- **Jupiter radius**: 69911000 m

- **Solar radius**: 6.96e+08 m

## License

The database is licensed under an MIT license. If you use it for a scientific publication, please include a reference to the [Open Exoplanet Catalogue on GitHub][3] or to [this arXiv paper][4].

  [1]: https://github.com/hannorein ""Hanno Rein""
  [2]: https://github.com/OpenExoplanetCatalogue/open_exoplanet_catalogue
  [3]: https://github.com/OpenExoplanetCatalogue/open_exoplanet_catalogue
  [4]: http://arxiv.org/abs/1211.7121",.csv
Open Missing People Cases Inside National Parks,1,open-missing-person-cases-inside-national-parks,victims_coords.csv,MIT,Each year people go missing inside national parks all across the United States. This dataset contains information of 264 active missing person cases that were reported inside national parks including the coordinates of the national park in order to facilitate geographical analysis. ,.csv
OpenFlights Airports Database 2017,1,openflights-airports-database-2017,airports.csv,DbCL-1.0,"### Context

As of January 2017, the OpenFlights Airports Database contains over 10,000 airports, train stations and ferry terminals spanning the globe


### Content

Each entry contains the following information:
Airport ID, Name, City, Country, IATA, ICAO, Latitude, Longitude, Altitude, Timezone, DST, Database Timezone, Type, Source

The OpenFlights Airport, Airline, Plane and Route Databases are made available under the Open Database License. Any rights in individual contents of the database are licensed under the Database Contents License.

This data is not suitable for navigation

### Acknowledgements

Data taken from - [OpenFlights](https://openflights.org/data.html)
Airport base data was generated by from DAFIF (October 2006 cycle) and OurAirports, plus timezone information from EarthTools. All DST information added manually. Significant revisions and additions made by the users of OpenFlights.
",.csv
Optimism Transaction Dataset (Raw),1,optimism-transaction-dataset-raw,optimism.csv,other,"Explore Optimism Transaction Dataset: Dive into the world of Optimism blockchain with this dataset, containing transaction details. Analyze transaction patterns, track the flow of funds, and uncover insights into one of the leading cryptocurrencies.
[Source](https://optimistic.etherscan.io/)",.csv
Orange Quality Analysis Dataset| 🍊,1,orange-quality,Orange Quality Data.csv,Apache 2.0,"<img src=""https://i.pinimg.com/originals/46/c7/d4/46c7d41b776e74c02d0cc0ca3386ceca.jpg"">

## Content:
The tabular dataset contains numerical attributes describing the quality of oranges, including their size, weight, sweetness (Brix), acidity (pH), softness, harvest time, and ripeness, as well as categorical attributes such as color, variety, presence of blemishes, and overall quality.

## Columns:
- Size: Size of orange in cm
- Weight: Weight of orange in g
- Brix: Sweetness level in Brix
- pH: Acidity level (pH)
- Softness: Softness rating (1-5)
- HarvestTime: Days since harvest
- Ripeness: Ripeness rating (1-5)
- Color: Fruit color
- Variety: Orange variety
- Blemishes: Presence of blemishes (Yes/No)
- Quality: Overall quality rating (1-5)

## Potential use case:
- Quality Prediction
- Classification

**If you've found this dataset helpful, I'd be over the moon with a little upvote love! 💗 Thanks a bunch!**",.csv
Oranges vs. Grapefruit,1,oranges-vs-grapefruit,citrus.csv,CC0-1.0,"### Oranges vs. Grapefruit

The task of separating oranges and grapefruit is fairly obvious to a human, but even with manual observation there is still a bit of error. This dataset takes the color, weight, and diameter of an ""average"" orange and grapefruit and generates a larger dataset containing a wide variety of values and are ""oranges"" and ""grapefruit"".

### Content

The dataset is mostly fictional. I'd love to collect real data, but for now measuring starting fruit and creating artificial samples from there seems adequate.

### Inspiration

Binary classification situations are numerous, but tricky for teaching situations. I needed something to create a nice binary classification dataset and still be interesting.",.csv
Organized Diabetes Dataset,1,useful-diabetes-dataset,diabetes.csv,Apache 2.0,"This dataset provides a comprehensive look into the various factors and parameters associated with diabetes, a chronic health condition that affects millions of people worldwide. The data has been meticulously collected and organized to facilitate in-depth analysis and exploration of the complex interplay between these factors and the onset of diabetes. The dataset includes information on demographic factors, lifestyle habits, medical history, and laboratory results, among other variables. Each row represents an individual patient, and each column represents a different variable related to diabetes. Please note that all patient data included in this dataset has been anonymized to protect patient privacy. We encourage all users to respect this privacy and use the data responsibly.",.csv
Osteoporosis Risk Prediction,1,lifestyle-factors-influencing-osteoporosis,osteoporosis.csv,Apache 2.0,"The dataset offers comprehensive information on health factors influencing osteoporosis development, including demographic details, lifestyle choices, medical history, and bone health indicators. It aims to facilitate research in osteoporosis prediction, enabling machine learning models to identify individuals at risk. Analyzing factors like age, gender, hormonal changes, and lifestyle habits can help improve osteoporosis management and prevention strategies.

**Potential Analysis:**

**Predictive Modeling:** Develop machine learning models to predict the probability of osteoporosis based on the provided features. This analysis is crucial for identifying individuals at risk of osteoporosis, enabling early intervention and prevention strategies.

**Feature Importance Analysis:** Determine the importance of each feature in predicting osteoporosis risk. Understanding which factors have the most significant impact on osteoporosis risk can provide insights into the underlying mechanisms and guide targeted interventions.

**Correlation Analysis:** Examine correlations between different features and osteoporosis risk. Identifying strong correlations can help identify potential risk factors or associations that may warrant further investigation or intervention.

**Subgroup Analysis:** Analyze how osteoporosis risk varies across different subgroups based on demographics, lifestyle factors, or medical history. Understanding how risk factors interact within different population groups can inform personalized approaches to osteoporosis prevention and management.

**Model Interpretation:** Interpret the trained models to understand how different features contribute to osteoporosis risk prediction. This analysis can provide insights into the underlying relationships between variables and help healthcare professionals make informed decisions regarding patient care and management strategies.",.csv
PC Games Sales,1,most-selling-pc-games,Games.csv,CC-BY-SA-3.0,"### Context

Gaming industry is an interesting field to explore, it would be fun knowing who is the most popular publishers and developers and which games are the most popular.

### Content

Name: Name of the game

Sales: Sales of the game in Millions

Series: Series of the game

Release: Release date of the game

Genre: Genre of the game

Developer: Developer of the game

Publisher: Publisher of the game

### Questions to be answered

Which genre is the most popular ?
Which publisher published most of the games ?
Which developer developed most of the games ?
Which series is the most popular ?",.csv
PHDs Produced by Pakistani Universities,1,phds-produced-by-pakistani-universities,PHDs Produced by Pakistani Universities (2010-2014).csv,CC0-1.0,"**Context:**

This comprehensive dataset provides information on the number of PhDs produced by Pakistani universities between 2010 to 2014. It includes data on the number of PhDs, the awarding institution, and the year of conferment. This dataset aims to offer insights into trends in higher education and research output in Pakistan, which may be useful for academic researchers, policymakers, and educational planners.

**Variables:** 

The dataset has Institute, year (2010, 2011, 2012, 2013, 2014) and sector variables.

**Data Source:**

Data compiled from public records provided by the Higher Education Commission of Pakistan. Data source can be verified by visiting this [url](https://www.hec.gov.pk/Urdu/universities/Pages/AJK/PhD-Produced-by-Pakistani-Universities.aspx).

**Inspiration**

This data helps to analyze:

- Which sector produced more PHDs?
- Which Institution produced the more PHDs?
- In which year most PHD degrees were awarded?
- What was the trend of PHD candidates?

Please feel free to perform any analysis or visualization on this dataset.",.csv
PHQ-9 Depression Assessment,1,phq-9-depression-assessment,Dataset_14-day_AA_depression_symptoms_mood_and_PHQ-9.csv,CC0-1.0,"_____
# PHQ-9 Depression Assessment
### 14-Days of Ambulatory Mood Dynamics in a General Population
By  [[source]](https://zenodo.org/record/3384860#.Y8OrbdJBwUE)
_____

### About this dataset
> This dataset contains 14 days of ambulatory assessment (AA) data related to depression symptoms and mood ratings, as well as findings from a retrospective Patient Health Questionnaire (PHQ-9) designed for depression screening purposes. Furthermore, it contains demographic information about the participants such as their age and gender. 
> 
> This dataset is composed of various fields including: phq1, phq2, phq3, phq4, phq5, phq6, phq7,ph q8 ,ph q9 ,age ,sex ,q10 ,e11 ,12 w13 w14 e16 e46 e47 happiness.score time period name start time Ph Q day  The data gathered through this survey allows us to gain insight into the daily fluctuations in self-reported symptoms experienced by these individuals at different stages of their lives. In addition to providing important clues about possible causes or triggers associated with depressive episodes, this type of survey can also help identify interventions that may prove successful in reducing symptom severity and frequency. Our hope is that we can use this extensive collection of data to inform treatment decisions and ultimately improve outcomes for those affected by depression

### More Datasets
> For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
> - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
> This dataset contains information about the Patient Health Questionnaire (PHQ-9) depression screening assessment, which is used to assess the severity of depressive symptoms over the past two weeks. This dataset can be used to gain insights into depression in a general population sample. 
> 
> The data is broken down into several categories: PHQ Score (1-9), Age and Gender of participant, Questions 10-47 (Numeric Scores), Happiness score, Time/Period Name/Start Time, and PHQ Day. 
> 
> In order to use this dataset effectively and accurately analyze your results it is important to understand how each column impacts your results. The PHQ Score column contains information on the severity of depressive symptoms in a scale from 1-9. The Age and Gender columns contain demographic information related to participants while Questions 10-47 represent a range of mental health subject including anhedonia, fatigue, sleep disturbance and changes in appetite or weight that are rated on a numeric scale from 0-4. The Happiness score reflects individual’s subjective ratings at time of assessment with higher scores reflecting greater positivity toward life as reported by participant during study period. Finally the Time/Period Name/Start Time columns provide date and time information related to study period while the PHQ Day represents total number of days elapsed since onset of clinical trial at beginning of assessment period. 
> 
> By understanding how each category contributes as well as any relationships that may exist between variables researchers can use this data set effectively when analyzing their results for more detailed insights into depression in general population samples across different lengths of time or months scoring methodologies employed reflected by total PHQ scores attained over course on particular month interval included within scope defined for particular study group being considered for analysis by researcher during evaluation protocol being employed developed data research development team assigned project develop analysis offers potential obtainable from working current model designed herein designed incorporated iteration included questionnaires offer basis obtainable utilizing utilized platform outlined herethrough model presented currently established outcome metrics thereby providing tool required necessary review evaluate found current project implementation structure framework wherein needed result may provided evaluated research rationale procedures ultimately yielding findings potentially productive goals desired analytical outcomes original objective initial efforts made implement intended protocol design methodological measures prescribed evaluator's evaluation criteria reported therewith provide result assist uncovering needed research answers discoverable platform established herein presented purpose obviate further attempts previously reviewed limitations encountered earlier trials thus executing member's logbook objectives upgraded format allow corporate setting without interruption driven process overhaul project initiation iterative systemic component procedure triage session estimation techniques management applicable foundational principles

### Research Ideas
> - Developing an AI-driven screening tool that can rapidly identify and monitor symptoms of depression. This AI-based tool could integrate the PHQ-9 responses and other AA data to collect detailed insights on mood changes over time, providing more accurate and customized detections of depression. 
> - Investigating potential correlations between age, gender, PHQ scores and daily happiness scores in order to better understand which individuals are most at risk for developing depression. Additionally, using this data to gain a better understanding of how daily moods may be linked to longer term mental health is highly valuable insight for medical professionals that could lead to improved treatment plans or interventions. 
> - Using the start time and period name variables as inputs for creating a predictive model that seeks out patterns in the occurrence of depressive symptoms over specific phases or times; helping medical professionals identify when patients may need additional guidance or resources during certain periods in their lives

### Acknowledgements
> If you use this dataset in your research, please credit the original authors.
> [Data Source](https://zenodo.org/record/3384860#.Y8OrbdJBwUE)
> 
>


### License
> 
> 
> **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
> No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: Dataset_14-day_AA_depression_symptoms_mood_and_PHQ-9.csv**
| Column name         | Description                                                               |
|:--------------------|:--------------------------------------------------------------------------|
| **phq1**            | Patient Health Questionnaire-9 score for the first day. (Numeric)         |
| **phq2**            | Patient Health Questionnaire-9 score for the second day. (Numeric)        |
| **phq3**            | Patient Health Questionnaire-9 score for the third day. (Numeric)         |
| **phq4**            | Patient Health Questionnaire-9 score for the fourth day. (Numeric)        |
| **phq5**            | Patient Health Questionnaire-9 score for the fifth day. (Numeric)         |
| **phq6**            | Patient Health Questionnaire-9 score for the sixth day. (Numeric)         |
| **phq7**            | Patient Health Questionnaire-9 score for the seventh day. (Numeric)       |
| **phq8**            | Patient Health Questionnaire-9 score for the eighth day. (Numeric)        |
| **phq9**            | Patient Health Questionnaire-9 score for the ninth day. (Numeric)         |
| **age**             | Age of the participant. (Numeric)                                         |
| **sex**             | Gender of the participant. (Categorical)                                  |
| **q10**             | Patient Health Questionnaire-9 score for the tenth day. (Numeric)         |
| **q11**             | Patient Health Questionnaire-9 score for the eleventh day. (Numeric)      |
| **q12**             | Patient Health Questionnaire-9 score for the twelfth day. (Numeric)       |
| **q13**             | Patient Health Questionnaire-9 score for the thirteenth day. (Numeric)    |
| **q14**             | Patient Health Questionnaire-9 score for the fourteenth day. (Numeric)    |
| **q16**             | Patient Health Questionnaire-9 score for the sixteenth day. (Numeric)     |
| **q46**             | Patient Health Questionnaire-9 score for the forty-sixth day. (Numeric)   |
| **q47**             | Patient Health Questionnaire-9 score for the forty-seventh day. (Numeric) |
| **happiness.score** | Happiness score of the participant. (Numeric)                             |
| **time**            | Time of day the assessment was taken. (Categorical)                       |
| **period.name**     | Name of the period the assessment was taken in. (Categorical)             |
| **start.time**      | Start time of the period the assessment was taken in. (Numeric)           |
| **phq.day**         | Day of the period the assessment was taken in. (Numeric)                  |

### Acknowledgements
> If you use this dataset in your research, please credit the original authors.
> If you use this dataset in your research, please credit [](https://zenodo.org/record/3384860#.Y8OrbdJBwUE).

",.csv
PII Detection : Gemini Created Dataset,1,pii-detection-gemini-created-dataset,pii_gemini.csv,Apache 2.0,"This dataset was generated using Gemini API. It is made for The Learning Agency Lab - PII Data Detection.

Notebook used: https://www.kaggle.com/code/newtonbaba12345/pii-detection-data-generation-using-gemini/notebook

Please Note that the thumbnail was generated by AI.",.csv
PII Detection Dataset (GPT),1,pii-detection-dataset-gpt,ai_data.csv,Attribution 4.0 International (CC BY 4.0),"External Data for [The Learning Agency Lab - PII Data Detection](https://www.kaggle.com/competitions/pii-detection-removal-from-educational-data/overview)

Created using GPT, for more info, please refer to [Notebook](https://www.kaggle.com/code/pjmathematician/pii-external-data-creation-loading) and [Discussion](https://www.kaggle.com/competitions/pii-detection-removal-from-educational-data/discussion/470921)",.csv
PISA Performance Scores by Country,1,pisa-performance-scores-by-country,OECD PISA data.csv,other,"_____
# PISA Performance Scores by Country
### PISA Performance Scores by Country and Year
By Dennis Kao [[source]](https://data.world/professorkao)
_____

### About this dataset
&gt; The OECD PISA dataset provides performance scores for 15-year-old students in reading, mathematics, and science across OECD countries. The dataset covers the years 2000 to 2018. 
&gt; 
&gt; These performance scores are measured using the Programme for International Student Assessment (PISA), which evaluates students' abilities to apply their knowledge and skills in reading, mathematics, and science to real-life challenges. 
&gt; 
&gt; Reading performance is assessed based on the capacity to comprehend, use, and reflect on written texts for achieving goals, developing knowledge and potential, and participating in society. 
&gt; 
&gt; Mathematical performance measures a student's mathematical literacy by evaluating their ability to formulate, employ, and interpret mathematics in various contexts. This includes describing, predicting, and explaining phenomena while recognizing the role that mathematics plays in the world.
&gt; 
&gt; Scientific performance examines a student's scientific literacy in terms of utilizing scientific knowledge to identify questions/problems/topics of interest relevant with respect to acquiring new findings/evidence/information/knowledge/content/formulation/input/output/extra-data/base/media/stats/questions/dimensions/distributions/effects/conclusions/issues/observations/trends/patterns/distribution/symptoms/hypotheses/preferences/facts/opinions/theories/beliefs/problems/causes/reasons/tests/methods/classifications/experiments/analysis/measurement/context/situations/experience/reactions/respondents/influences/emotions/perceptions/criteria/outcomes/effects/effects/significance/importance/applications/variables/models/procedures/mechanisms/concepts/spaces/types/designs/goals/models/schematics/specifications/tools/interventions/initiatives/factors/metrics/advice/sources/research/reference/background/theoretical/historical/cultural/scientific/ethical/methodological limits/rules/norms/steps/examples/practices/workflows/judgments/inferences/discoveries/disputed-effects/negative-effects/right/strength Theses skills enable them i.e., recognize claims or manipulate materials as evidence-based conclusions to address scientific phenomena and draw evidence-based conclusions about science-related issues. 
&gt; 
&gt; The dataset includes information on the performance scores categorized by location (country alpha‑3 codes), indicator (reading, mathematical, or scientific performance), subject (boys/girls/total), and time of measurement (year). The mean score for each combination of these variables is provided in the Value column.
&gt; 
&gt; For more detailed information on how the dataset was collected and analyzed, please refer to the original source

### How to use the dataset
&gt; 
&gt; 
&gt; ## Understanding the Columns
&gt; Before diving into the analysis, it is important to understand the meaning of each column in the dataset:
&gt; 
&gt; - **LOCATION:** This column represents country alpha-3 codes. OAVG indicates an average across all OECD countries.
&gt; 
&gt; - **INDICATOR:** The performance indicator being measured can be one of three options: Reading performance (PISAREAD), Mathematical performance (PISAMATH), or Scientific performance (PISASCIENCE).
&gt; 
&gt; - **SUBJECT:** This column categorizes subjects as BOY (boys), GIRL (girls), or TOT (total). It indicates which group's scores are being considered.
&gt; 
&gt; - **TIME:** The year in which the performance scores were measured can range from 2000 to 2018.
&gt; 
&gt; - **Value:** The mean score of the performance indicator for a specific subject and year is provided in this column as a floating-point number.
&gt; 
&gt; 
&gt; ## Getting Started with Analysis
&gt; Here are some ideas on how you can start exploring and analyzing this dataset:
&gt; 
&gt; - **Comparing countries**: You can use this dataset to compare educational performances between different countries over time for various subjects like reading, mathematics, and science.
&gt; 
&gt; 
&gt; - **Subject-based analysis**: You can focus on studying how gender affects students' performances by filtering data based on subject ('BOY', 'GIRL') along with years or individual countries.
&gt; 
&gt; 
&gt; - **Time-based trends**: Analyze trends over time by examining changes in mean scores for various indicators across years.
&gt; 
&gt; 
&gt; - ** OECD vs Non-OECD Countries**: Determine if there are significant differences in performance scores between OECD countries and non-OECD countries. You can filter the data by the LOCATION column to obtain separate datasets for each group and compare their mean scores.
&gt; 
&gt; 
&gt; ## Data Visualization
&gt; To enhance your understanding of the dataset, visualizations can be powerful tools. Here are some visualization ideas:
&gt; 
&gt; - **Line Charts**: Plot line charts to visualize how mean scores change over time for a specific location, subject, or indicator.
&gt; 
&gt; - **Bar Charts**: Use bar charts to compare mean scores across different locations or subject groups within a specific year.
&gt; 
&gt; - **Heat Maps**: Representing location-wise performances

### Research Ideas
&gt; - Comparing performance between genders: This dataset allows for analysis of the performance scores for boys, girls, and the total across reading, mathematics, and science. By comparing these scores over time and across countries, it is possible to identify any gender disparities in educational outcomes.
&gt; - Assessing changes in performance over time: With data ranging from 2000 to 2018, this dataset provides an opportunity to analyze the changes in performance scores over time. By identifying trends and patterns, researchers can gain insights into how educational systems have evolved and what factors may have contributed to improvements or declines in student performance.
&gt; - Benchmarking against OECD average: The dataset includes an average score across all OECD countries (OAVG). By comparing individual country's performance against this average score, it is possible to evaluate how well a country's educational system performs compared to other OECD members. This benchmarking can help identify areas where improvements are needed or where a country excels in education

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://data.world/professorkao)
&gt; 
&gt;


### License
&gt; 
&gt; 
&gt; See the dataset description for more information.

### Columns

**File: OECD PISA data.csv**
| Column name   | Description                                                                                                                                                                        |
|:--------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **LOCATION**  | Country alpha-3 codes or OAVG (average across all OECD countries). (Categorical)                                                                                                   |
| **INDICATOR** | The performance indicator being measured, which can be PISAREAD (Reading performance), PISAMATH (Mathematical performance), or PISASCIENCE (Scientific performance). (Categorical) |
| **SUBJECT**   | The subject of the performance scores, which can be BOY (Boys' performance), GIRL (Girls' performance), or TOT (Total performance combining boys and girls). (Categorical)         |
| **TIME**      | The year in which the performance scores were measured, ranging from 2000 to 2018. (Numeric)                                                                                       |
| **Value**     | The mean score of the specified subject and indicator for a given year. (Numeric)                                                                                                  |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [Dennis Kao](https://data.world/professorkao).

",.csv
PK Undergrad Students : GPA vs Intermediate Marks,1,pk-undergrad-students-gpa-vs-intermediate-marks,grades.csv,MIT,"# Content
A single CSV file containing data of undergraduate students enrolled in a public-sector university in Pakistan.

# Attributes
###### ID
Randomly generated id for each observation
###### Gender
Student gender *(Male/Female)*
###### Program Duration
The duration of most undergraduate programs is 4 years. However, for some disciplines like law and pharmacy, it is 5 years. *(4/5)*
###### Year of Student
Student's current year of undergraduate study *(1-5)*
###### HSC Percentage
Percentage marks obtained in High School Certificate (11-12 years of education also known as intermediate) *(0-100)*
###### CGPA
Student's Cumulative GPA up till current year of study *(0-4)*

# Data Limitations
The data was collected in May-June 2023 during applications for [PM Laptop Scheme Phase III](https://laptop.pmyp.gov.pk/eligibility_criteria.php) 
The originally obtained dataset was completely anonymized and potentially identifying information such as enrolled degree program was removed to ensure student privacy. Observations for students enrolled in graduate or doctorate programs were also removed from originally obtained dataset.
The data is not collectively exhaustive because students with higher grades were more likely to apply than those with lower grades. A minimum eligibility criteria was also set for program, however students not meeting the criteria also applied for the scheme, hence their data was also recorded.",.csv
PLASTIC-BASED TEXTILES IN CLOTHING INDUSTRY,1,plastic-based-textiles-in-clothing-industry,Plastic based Textiles in clothing industry.csv,DbCL-1.0,"This dataset serves as a comprehensive exploration into the environmental footprint of plastic-based textiles within the clothing industry, with a specific focus on the practices of Zara, a leading fashion retailer. Plastic-based textiles, such as polyester, nylon, and synthetic blends, have gained significant popularity in the apparel sector due to their affordability, durability, and versatility. However, their production and usage often come at a significant cost to the environment.

Key Features:

Company and Product Type: The dataset encompasses data from various production years and product types, providing a detailed overview of Zara's utilization of plastic-based textiles.
Environmental Metrics: It includes crucial environmental metrics such as greenhouse gas emissions, pollutants emitted, water and energy consumption, and waste generation associated with the production of plastic-based textiles.
Sales Revenue: Additionally, the dataset features information on sales revenue, offering insights into the economic aspect of Zara's operations in relation to plastic-based textiles.
Significance:
Understanding the environmental impact of plastic-based textiles is paramount in mitigating the detrimental effects of the clothing industry on the planet. By analyzing this dataset, researchers, policymakers, and industry stakeholders can gain valuable insights into the extent of greenhouse gas emissions, pollutants, and resource consumption associated with plastic-based textile production. Moreover, it facilitates informed decision-making towards more sustainable practices within the fashion industry.

Potential Applications:

Research and Analysis: Researchers can leverage this dataset to conduct in-depth analyses on the environmental implications of plastic-based textiles, contributing to the body of knowledge surrounding sustainable fashion.
Policy Formulation: Policymakers can utilize the insights derived from this dataset to inform the development of regulations and initiatives aimed at reducing the environmental impact of the clothing industry.
Corporate Sustainability: Fashion companies, including Zara, can utilize this dataset to assess their environmental performance and implement strategies to minimize their carbon footprint and adopt more sustainable practices.
Future Updates:
To ensure the dataset remains relevant and reflective of current trends, it will be periodically updated with new data as it becomes available. These updates will enable ongoing monitoring of Zara's environmental practices and their impact on the clothing industry.

Disclaimer:
While every effort has been made to ensure the accuracy and reliability of the data presented in this dataset, users are encouraged to exercise discretion and verify information as needed. The dataset is provided for informational and research purposes only, and no guarantees are made regarding its suitability for any specific application or analysis.",.csv
"POTUS : Age , State , Health and Wealth",1,us-presidents-age-state-health-and-wealth,US-Presidents.csv,CC0-1.0,"The data contains the educational degree, university , age , weight , married life , no of children , IQ, Wealth and the percentage of the US budget that they spent on defense. The major wars that have happened during their tenure as POTUS.


The Office of the President of the United States (POTUS) was established by the US Constitution in 1789, with George Washington being elected as the first US president. At the time of his presidency, the role of POTUS was largely ceremonial and focused on the administration of the federal government. However, over time, the position grew in power and influence as the US became a global superpower and the demands of the post changed. With the expansion of the executive branch of the government and the development of modern communication and transportation technologies, the role of POTUS became even more significant. The US president now plays a central role in shaping policy, implementing agendas, and representing the country on the world stage. Throughout history, the POTUS has also been involved in many historical events and crises, such as the Civil War, the Great Depression, World War II, the civil rights movement, and the War on Terror. Each president has brought their unique set of values, leadership style, and vision for the country, shaping the office and the nation in their own way.

The POTUS is the most powerful political figure in the United States, responsible for shaping domestic and foreign policy, appointing federal judges and other officials, and representing the country both at home and abroad. The US president is elected to a four-year term and can serve a maximum of two terms under the 22nd Amendment to the US Constitution. The role and responsibilities of the POTUS have evolved over time, reflecting the changing needs and expectations of the American people and the world at large.
",.csv
Pakistan House Prices - 2023,1,house-prices-2023,house_prices.csv,Apache 2.0,"This is a dataset of house prices in 2023. It has been sourced from [**here**](https://www.gigasheet.com/sample-data/house-prices-2023-dataset). 

There are a lot of possibilities for this dataset and some of them have been listed below:

**General Overview:**
   - What is the average price of properties in the dataset?
   - What is the distribution of property types (e.g., flats, houses, penthouses)?
   - How many properties are listed for sale, and in which cities?

**Location Analysis:**
   - Which locations have the highest and lowest average property prices?
   - What are the most popular locations based on the number of listings?

**Property Characteristics:**
   - What is the average number of bedrooms and bathrooms for listed properties?
   - How does property size vary across different types and locations?

**Price Analysis:**
   - Are there outliers or high-value properties in the dataset?
   - How does property price correlate with the number of bedrooms and bathrooms?

**City Comparison:**
   - How do property prices differ between cities?
   - Are there specific property types more common in certain cities?

**Purpose of Listings:**
   - What is the distribution of properties based on their purpose (e.g., for sale)?
   - How does the average price vary between different purposes?

**Specific Property Types:**
   - What is the average price and size of flats in the dataset?
   - Are there trends or patterns specific to flats, houses, or other property types?

**Popular Locations and Property Types:**
   - Identify popular locations based on the number of listings.
   - Are certain property types more prevalent in popular locations?

**Feature Importance:**
    - Which features (e.g., location, number of bedrooms) contribute the most to predicting property prices?
    - Can we identify the top features that influence the model's predictions?

**Property Type Classification:**
    - Can we use machine learning to classify properties into different types (e.g., flat, house, penthouse) based on their features?
    - What is the accuracy of classification models in identifying property types?

**Location-based Clustering:**
    - Are there natural clusters of properties based on their location, and can we identify them using machine learning clustering algorithms?
    - How well do clustering algorithms group similar properties together?

**Outlier Detection with ML:**
    - Can machine learning algorithms automatically detect outliers or high-value properties in the dataset?
    - How effective are anomaly detection methods in identifying unusual property listings?

**Optimal Property Selection:**
    - Can machine learning help identify the optimal combination of features for a property that maximizes its sale price or rental income?
    - How well can models recommend suitable properties based on user preferences?

**Customer Segmentation:**
    - Are there distinct segments of customers with specific preferences for property features?
    - Can machine learning algorithms identify and characterize these customer segments?

**Property Investment Risk Assessment:**
    - How can machine learning assist in assessing the risk associated with investing in certain types of properties or locations?
    - Can we build a model to predict potential property value fluctuations?

**Predictive Modeling:**
   - Can we build a machine learning model to predict property prices based on features such as location, number of bedrooms, and size?
   - What is the performance (accuracy, RMSE, etc.) of different regression models for predicting property prices?

***Happy Processing!!!***",.csv
Pakistan ToshaKhana Files,1,pakistan-toshakhana-files,Refined_TK_data ver 2.csv,CC0-1.0,"The Toshakhana case in Pakistan involves allegations of former government officials receiving luxury vehicles and other gifts from foreign leaders and dignitaries. The case centers around a toshakhana, or treasure trove, where such gifts are kept. The Supreme Court of Pakistan ordered an investigation into the case in 2018 and directed the National Accountability Bureau (NAB) to probe the matter.

The investigation found that former presidents, prime ministers, and other officials had accepted gifts worth millions of dollars, but had not declared them to the government or paid the required taxes on them. The case has stirred controversy in Pakistan, with some arguing that the officials violated ethical and legal norms by accepting the gifts, while others defend the practice as a diplomatic courtesy.

The case is ongoing, with several high-profile figures, including former presidents and prime ministers, being summoned by the NAB for questioning. The outcome of the case will have important implications for Pakistan's political and legal systems, as it raises questions about the transparency and accountability of its leaders.

Here are few questions we can ask from this dataset:

1. What is the total value of all gifts received by former government officials from foreign leaders and dignitaries?
2. Which specific individuals received gifts from the Toshakhana, and what were those gifts?
3. Did any government officials declare the gifts they received to the Pakistani government or pay taxes on them?
4. Were there any patterns or trends in the types of gifts received by different officials or from different countries?
5.  Did any gifts received by government officials influence their decisions or actions while in office?
6. How did the Toshakhana function in terms of record-keeping and accountability for the gifts it received and distributed?
7. What legal or ethical violations, if any, occurred as a result of officials receiving gifts from foreign leaders through the Toshakhana?
8. Were there any efforts made to conceal the receipt of gifts by government officials, and if so, how were those efforts carried out?",.csv
Palmer Penguins Dataset-Alternative Iris Dataset,1,palmer-penguins-datasetalternative-iris-dataset,penguins.csv,CC0-1.0,"Palmer Penguins Dataset
The goal of palmerpenguins is to provide a great dataset for data exploration & visualization, as an alternative to iris.

About the data
Data were collected and made available by Dr. Kristen Gorman and the Palmer Station, Antarctica LTER, a member of the Long Term Ecological Research Network.",.csv
Pandas Practice Dataset,1,pandas-practice-dataset,data.csv,CC0-1.0,"**What is Pandas?**

Pandas is a Python library used for working with data sets.

It has functions for analyzing, cleaning, exploring, and manipulating data.

The name ""Pandas"" has a reference to both ""Panel Data"", and ""Python Data Analysis"" and was created by Wes McKinney in 2008.

**Why Use Pandas?**

Pandas allows us to analyze big data and make conclusions based on statistical theories.

Pandas can clean messy data sets, and make them readable and relevant.

Relevant data is very important in data science.

**What Can Pandas Do?**

Pandas gives you answers about the data. Like:

Is there a correlation between two or more columns?

What is average value?

Max value?

Min value?",.csv
Pandas practices,1,police,police.csv,U.S. Government Works,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F3718520%2Fccd96a32c92d21640b67c1aa74a685c6%2Findir%20(1).jpg?generation=1581067964496524&alt=media)
### Context

vehicles stopped and search by the police

### Content

Age, reason....

### Acknowledgements

thx for stanford
### Inspiration
do practice",.csv
Panel Dataset / Cost Data of U.S. Airlines,1,paneldata,PanelData.csv,CC-BY-NC-SA-4.0,"### Dataset Details:

Data Set contains Cost Data for U.S. Airlines, 90 Observations  On 6 Firms For 15 Years, 1970-1984

### Predictors:
I = Airline,
T = Year,
Q = Output, in revenue passenger miles, index number,
PF = Fuel price,
LF = Load factor, the average capacity utilization of the fleet.

###  Response:
C = Total cost, in $1000,

### Acknowledgements and Credit

These data are a subset of a larger data set provided to the author by Professor Moshe Kim.
They were originally constructed by Christensen Associates of Madison, Wisconsin.

### Inspiration
Perform various econometric analyses to check which model suits best for the given dataset. To start with can check this [notebook](https://www.kaggle.com/sandhyakrishnan02/econometric-analysis-of-panel-data-using-r) which is programmed in R.
",.csv
Paraphrased English ,1,paraphrased-tapaco,tapaco_paraphrases_dataset.csv,other,"Het Pandya  English version csv

https://github.com/hetpandya/paraphrase-datasets-pretrained-models

TaPaCo: A Corpus of Sentential Paraphrases for 73 Languages

Scherrer, Yves

Citation: @dataset{scherrer_yves_2020_3707949,
  author       = {Scherrer, Yves},
  title        = {{TaPaCo: A Corpus of Sentential Paraphrases for 73 Languages}},
  month        = mar,
  year         = 2020,
  publisher    = {Zenodo},
  version      = {1.0},
  doi          = {10.5281/zenodo.3707949},
  url          = {https://doi.org/10.5281/zenodo.3707949}
}",.csv
Paris 2024 Cultural Olympiad,1,paris-2024-cultural-olympiad,paris_2024_cultural_olympiad.csv,CC0-1.0,"# Cultural Olympiad

The Cultural Olympiad aims to create a dialogue between art and sport, through artistic proposals inviting the public to participate in the various cultural activities.

![](https://img.olympics.com/images/image/private/f_auto/primary/yol0kmpb0bhasuydacqf)

Pierre de Coubertin, known as the father of the modern Olympic Games, believed that the combination of ‘muscle and mind’ (sport and art) was *one of the core values* of the Games. Although sculpture, architecture, literature, music, and painting were considered Olympic disciplines from 1912 to 1949, the arts gradually disappeared from the competitions. Nevertheless, these artistic disciplines are well represented during the games in the Cultural Olympiad – and a key part of the charter of the Games – organized alongside this major world sporting event.  (from parisjetaime.com )

Data is downloaded from data.paris2024.org, and slightly cleaned

Translation of titles and discipline names to English is done using DeepL API

",.csv
Paris 2024 Olympic Venues,1,paris-2024-olympic-venues,paris_2024_olympic_venues.csv,CC0-1.0,"Paris 2024 Olympic Venues

Dataset has been scrapped from Wikipedia using `rvest `package.   Latitude and Longitude queried using Google Maps (ggmap package)
It will be expanded further as new data becomes available
",.csv
Parkinson Disease Detection,1,parkinson-disease-detection,Parkinsson disease.csv,other,"### Context

Parkinson’s Disease (PD) is a degenerative neurological disorder marked by decreased dopamine levels in the brain. It manifests itself through a deterioration of movement, including the presence of tremors and stiffness. There is commonly a marked effect on speech, including dysarthria (difficulty articulating sounds), hypophonia (lowered volume), and monotone (reduced pitch range). Additionally, cognitive impairments and changes in mood can occur, and risk of
dementia is increased. 

Traditional diagnosis of Parkinson’s Disease involves a clinician taking a neurological history of the patient and observing motor skills in various situations. Since there is no definitive laboratory test to diagnose PD, diagnosis is often difficult, particularly in the early stages when motor effects are not yet severe. Monitoring progression of the disease over time requires repeated clinic visits by the patient. An effective screening process, particularly one that doesn’t require a clinic visit, would be beneficial. Since PD patients exhibit characteristic vocal features, voice recordings are a useful and non-invasive tool for diagnosis. If machine learning algorithms could be applied to a voice recording dataset to accurately diagnosis PD, this would be an effective screening step prior to an appointment with a clinician. 

### Data

The data & attributes information for this project is available at https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/

### Attribute Information:

Matrix column entries (attributes):
name - ASCII subject name and recording number
MDVP:Fo(Hz) - Average vocal fundamental frequency
MDVP:Fhi(Hz) - Maximum vocal fundamental frequency
MDVP:Flo(Hz) - Minimum vocal fundamental frequency
MDVP:Jitter(%),MDVP:Jitter(Abs),MDVP:RAP,MDVP:PPQ,Jitter:DDP - Several 
measures of variation in fundamental frequency
MDVP:Shimmer,MDVP:Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,MDVP:APQ,Shimmer:DDA - Several measures of variation in amplitude
NHR,HNR - Two measures of ratio of noise to tonal components in the voice
status - Health status of the subject (one) - Parkinson's, (zero) - healthy
RPDE,D2 - Two nonlinear dynamical complexity measures
DFA - Signal fractal scaling exponent
spread1,spread2,PPE - Three nonlinear measures of fundamental frequency variation 

### Citation Request:

If you use this dataset, please cite the following paper: 
'Exploiting Nonlinear Recurrence and Fractal Scaling Properties for Voice Disorder Detection', 
Little MA, McSharry PE, Roberts SJ, Costello DAE, Moroz IM. 
BioMedical Engineering OnLine 2007, 6:23 (26 June 2007)",.csv
Parkinson's Disease Dataset,1,parkinsonsdataset,parkinsons.csv,GNU Free Documentation License 1.3,"### Context

Try finding the reasons for Parkinsons disease and predict who might have it next!
",.csv
Patient Treatment Classification,1,patient-treatment-classification,data-ori.csv,Attribution 4.0 International (CC BY 4.0),"### Context

The dataset is Electronic Health Record Predicting collected from a private Hospital in Indonesia. It contains the patients laboratory test results used to determine next patient treatment whether in care or out care patient. The task embedded to the dataset is classification prediction. 

### Content

Attribute Information:
Given is the attribute name, attribute type, the measurement unit and a brief description. The number of rings is the value to predict: either as a continuous value or as a classification problem. Name / Data Type / Value Sample/ Description----------------------------- 
HAEMATOCRIT /Continuous /35.1 / Patient laboratory test result of haematocrit
HAEMOGLOBINS/Continuous/11.8 / Patient laboratory test result of haemoglobins
ERYTHROCYTE/Continuous/4.65 /  Patient laboratory test result of erythrocyte
LEUCOCYTE/Continuous /6.3 / Patient laboratory test result of leucocyte
THROMBOCYTE/Continuous/310/ Patient laboratory test result of thrombocyte
MCH/Continuous /25.4/ Patient laboratory test result of MCH
MCHC/Continuous/33.6/ Patient laboratory test result of MCHC
MCV/Continuous /75.5/ Patient laboratory test result of MCV
AGE/Continuous/12/ Patient age
SEX/Nominal – Binary/F/ Patient gender
SOURCE/Nominal/ {in,out}/The class target in.= in care patient, out = out care patient

### Acknowledgements

Sadikin, Mujiono (2020), “EHR Dataset for Patient Treatment Classification”, Mendeley Data, V1, doi: 10.17632/7kv3rctx7m.1

### Inspiration

Classify the patients based on their treatment. patients in care or patients out care.
",.csv
Paypal Holdings| Stock Ticker💰📊,1,paypal-holdings-stock-ticker,PYPL.csv,Apache 2.0,"# **Description:**

This dataset contains historical stock price data for PayPal Holdings, Inc. (PYPL) from [Jan/01/2020] to [May/01/2024]. The dataset includes daily opening, high, low, and closing prices, as well as adjusted closing prices and volume.

## **About Columns:**

- Date:
- Open:
- High:
- Low:
- Close:
- Adj Close:
- Volume:

### **Used by:**

- Predicting stock prices
- Building stock forecasting models
- Analyzing stock market trends
- Backtesting investment strategies
- Comparing machine learning models for stock prediction

  * This dataset is perfect for data scientists, analytics, and students looking to practice their skills in:
*
- Time series analysis
- Stock market analysis
- Predictive modeling
- Machine learning

**Get started:** Download the dataset and start exploring!",.csv
Pegasus Spyware,1,pegasus-spyware,Final_Tweets.csv,MIT,"A collection of Twitter data related to Pegasus Spyware, with additional sentiment analysis metrics. Here’s a brief description:

Tweets on Pegasus Spyware: This dataset likely contains the text of tweets that mention Pegasus Spyware. Pegasus is a type of spyware developed by the Israeli cyberarms firm NSO Group that can be covertly installed on mobile phones (and other devices) running most versions of iOS and Android.
Sentiment Score: This is a metric that quantifies the sentiment of the tweet text, typically on a scale from negative to positive. This score is usually derived from sentiment analysis algorithms that evaluate the words used in the tweet and classify them as expressing positive, negative, or neutral sentiment.
Polarity: This is another metric from sentiment analysis. Polarity classifies the sentiment expressed in the tweet as positive, negative, or neutral. It’s often used in conjunction with the sentiment score to provide a more nuanced understanding of the sentiment expressed in the tweet.
Timestamp: This is likely the date and time when the tweet was posted. This can be useful for tracking how sentiment about Pegasus Spyware has changed over time or in response to specific events.
This dataset would be valuable for social media analysis, public opinion research, and studying the public’s perception and awareness of cybersecurity issues like spyware. ",.csv
Penguin Sizes Dataset,1,penguin-size-dataset,penguins_size.csv,MIT,This is meant to be a fun dataset for you to learn on and use it as something to play around with. This dataset includes data about different species of penguins from different islands with their dimensions and genders. What kind of insights can you get out of this? ,.csv
People and their Cultural Practices,1,cultural-practices-of-french-people-survey,EGsurveyArtsCulture.csv,other,"This dataset was born from a wish to understand if they exist factors that influence the types of people's cultural practices and outings. Therefore, I conceived a survey asking people about their lifestyle, in addition to multiple questions about the frequency of their artistic and cultural practices. About 150 people answered the survey and here are their responses.",.csv
Personal Exercise and Health Data,1,personal-exercise-and-health-data,exercise_data.csv,DbCL-1.0,"It sounds like you have a substantial amount of personal exercise and health data accumulated over 150 days. This data can provide valuable insights into your fitness journey and overall well-being. Here are some suggestions on how you can analyze and make the most of this information:

**Exercise Types:**

Identify the types of exercises you've been engaging in. Categorize them into cardiovascular, strength training, flexibility, and other categories.
Note the frequency and duration of each type of exercise.

**Intensity Levels:**
Assess the intensity of your workouts. This can be measured in terms of heart rate, perceived exertion, or weight lifted.
Determine if there are patterns in intensity levels over time.

**Progress and Setbacks:**
Look for trends in your progress. Are you consistently improving, or have you encountered any setbacks?
Identify factors that contribute to your success or challenges.

**Rest and Recovery:**
Analyze your rest days and recovery strategies. Ensure that you're allowing your body enough time to recover between intense workouts.
Look for patterns in your energy levels and performance related to rest.

**Nutrition and Hydration:**
Correlate your exercise data with your nutrition and hydration habits. Consider whether certain eating patterns impact your workouts positively or negatively.

**Sleep Patterns:**
Examine your sleep data if available. Adequate sleep is crucial for recovery and overall health.
Identify any correlations between your sleep patterns and exercise performance.

**Mood and Stress Levels:**
Reflect on your mood and stress levels on different days. Exercise can have a significant impact on mental well-being.
Consider whether there are connections between your exercise routine and your emotional state.

**Injury Analysis:**
If you've experienced any injuries during this period, analyze the circumstances surrounding them. This can help in understanding potential risk factors.

**Goal Alignment:**
Evaluate whether your exercise routine aligns with your initial goals. Are you progressing toward your desired outcomes?

**Adjustment of Exercise Routine:**
Based on the analysis, consider adjustments to your exercise routine. This might involve modifying the types of exercises, intensity, or frequency.

Remember, the goal of analyzing this data is to make informed decisions about your fitness routine, identify areas of improvement, and celebrate your successes. If you have specific questions about the data or need guidance on certain aspects, feel free to provide more details for personalized advice.",.csv
Personal Loan Modeling ,1,personal-loan-modeling,Bank_Personal_Loan_Modelling.csv,CC0-1.0,"### Context

This case is about a bank (Thera Bank) whose management wants to explore ways of converting its liability customers to personal loan customers (while retaining them as depositors). A campaign that the bank ran last year for liability customers showed a healthy conversion rate of over 9% success. This has encouraged the retail marketing department to devise campaigns with better target marketing to increase the success ratio with minimal budget.


### Content

The file Bank.xls contains data on 5000 customers. The data include customer demographic information (age, income, etc.), the customer's relationship with the bank (mortgage, securities account, etc.), and the customer response to the last personal loan campaign (Personal Loan). Among these 5000 customers, only 480 (= 9.6%) accepted the personal loan that was offered to them in the earlier campaign.

There are no empty or (NaN) values in the dataset. The dataset has a mix of numerical and categorical attributes, but all categorical data are represented with numbers. Moreover, Some of the predictor variables are heavily skewed (long - tailed), making the data pre-processing an interesting yet not too challenging aspect of the data.",.csv
Personal expense data,1,personal-expense-data,myExpenses1.csv,CC0-1.0,This is my personal expense data collected in march of 2023. useful for exploratory data analysis and visualization. this dataset is about what i am eating on which time and the main focus on money how much i am spending on which thing.,.csv
Personality classification Data: 16 Personalities,1,60k-responses-of-16-personalities-test-mbt,16P.csv,other,"### This may be a very interesting dataset to work with 😎

<br>
### Please Note: This is a synthetic dataset and must not be taken seriously for academic research or other purposes, the purpose of the dataset is to have fun and learn classification on a challenging dataset and the data may not be accurate to what real world personalities turn out.

### Context

This is a really cool Multi-class Classification Problem


### Content

It contains the questions from the 16 Personality Tests and their answers in the Scale that they use but is numerically encoded:

Fully Agree: 3
Partially Agree: 2
Slightly Agree: 1
neutral -&gt; 0
Slightly disagree: -1
Partially disagree: -2
Fully disagree: -3

### Method

The methodology has been a gruesome one. There has been a lot of effort and thought that has gone into making this data. Although the data is synthetic, once you start working on the dataset you will realize that this is a valid classification data.

### Some additional Info:
This is a synthetically generated data, I generated a make classification data, converted the random numbers to integers(Likert scale), and based on traits of each personality, I scaled up/down the values of some features (questions that determine Intuitive/ Judging / Thinking), etc, and then tested a few classification models to see if this data really holds true. This is the 11th version and I'm constantly working on fine-tuning the dataset, one feature at a time trying to scale down/ scale values of certain features based on the personality (target column) they correspond to. So building a dataset of this magnitude and making it a valid dataset will actually take me a lot of effort but I am still in the Process of perfecting it. I actually every week better the dataset and run some AutoML Pycaret scripts and tune some hyperparameters to see if the quality has improved 😅. So this is like a research topic in itself and will eventually turn out to be a source in itself for people who want to work on this problem.

### A Request
It has taken me a lot of time to make this dataset and I hope this dataset received a Gold Medal. Please appreciate my work if you like my efforts.",.csv
Persuade 2.0,1,persuade-2-0,persuade_2.0_human_scores_demo_id_github.csv,CC-BY-NC-SA-4.0,"Persuade 2.0 available from https://github.com/scrosseye/persuade_corpus_2.0. 
<br>It contains essays from students covering topics among:
- Online course/classes.
- Student summer projects.
- Cell phone use in school.
- School policy for sports participation.
- Asking advice/opinion for decision making.
- Cell phone use while driving.
- Student extracurricular activities.
- Student community services.
- Driverless cars safety cost and legal issues.
- Emotions/facial expressions recognition.
- Solar planets exploration (Venus, Mars).
- Voting/Election.
- Limiting car usage for cleaner air.
- Experience as seagoing cowboy.

<br>Provided as CSV format.",.csv
Perth House Prices,1,perth-house-prices,all_perth_310121.csv,CC-BY-NC-SA-4.0,"### Acknowledgements

This data was scraped from [http://house.speakingsame.com/](http://house.speakingsame.com/) and includes data from 322 Perth suburbs, resulting in an average of about 100 rows per suburb.


### Content

I believe the columns chosen to represent this dataset are the most crucial in predicting house prices. Some preliminary analysis I conducted showed a significant correlation between each of these columns and the response variable (i.e. price). 

### Data obtained from other than scrape source
Longitude and Latitude data was obtained from [data.gov.au](https://data.gov.au/data/dataset/geocoded-national-address-file-g-naf).
School ranking data was obtained from [bettereducation](https://bettereducation.com.au/Default.aspx).

The nearest schools to each address selected in this dataset are schools which are defined to be 'ATAR-applicable'. In the Australian secondary school education system, ATAR is a scoring system used to assess a student's culminative academic results and is used for entry into Australian universities. As such, schools which do not have an ATAR program such as primary schools, vocational schools, special needs schools etc. are not considered in determining the nearest school.

 Do also note that under the ""NEAREST\_SCH_RANK"" column, there are some missing rows as some schools are unranked according to [this criteria](https://bettereducation.com.au/Results/WA/wace.aspx) by bettereducation.

",.csv
Pesticides are substances,1,pesticides-are-substances,pesticide-use-tonnes new.csv,CC0-1.0,"this graph was created in  OurDataWorld:

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fc9f34c4e80f051dc0ccdd6f64923a759%2Fpesticide-breakdown-by-type.png?generation=1714687076252916&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fbd088d77e913fdf764e12ef0af692475%2Finsecticide-use.png?generation=1714687082782050&alt=media)

Pesticides are substances that are used to control and protect crops against pests.

This includes herbicides, insecticides, fungicides, and other substances used to control other types of pests.

Pesticides, in various forms, have been used for millennia in agriculture. It was common for ancient agricultural societies to use naturally occurring elements such as sulfur, arsenic, or mercury to poison crop pests.

Today, pesticides are often produced synthetically and designed to target specific organisms.

They can be important for the protection of crops, farmers’ produce, and increases in crop yields.

But pesticides can also have negative impacts on local biodiversity, and when they’re used without appropriate safety protocols, can be toxic to the farmers or workers applying them.

On this page, you can find all our data and visualizations relating to pesticides.",.csv
Petrol Price Data By District,1,petrol-price-data-by-district,petrol_data.csv,CC0-1.0,"### Context

The Petrol Price data is the data which comprises of time series data on all districts in India.


### Content

The table comprises of 3 columns, 
| Column      | Description |
| ----------- | ----------- |
| City      | City Name (String)       |
| Date   | Date on when the data is collected (Datetime)        |
| Price   |  Price of petrol (float) |



### Acknowledgements

This data is been scraped from mypetrolprice.com. Please find the scraping code at https://github.com/syedjafer/scraping_fuel_price.


### Inspiration

As there is a recent rise in the petrol price, i wanted to find the reason of why there is a rise. Also, since the petrol price is  been directly related to the agricultural price (PFD from https://www.kaggle.com/syedjaferk/agriculture-commodity-data-2019 ). So we can find the relation between Agriculture and Petrol data. ",.csv
Pfizer Vaccine Tweets,1,pfizer-vaccine-tweets,vaccination_tweets.csv,CC0-1.0,"### Context

We collect recent tweets about Pfizer & BioNTech vaccine.

The data is collected using **tweepy** Python package to access Twitter API.

### Inspiration

Study the subjects of recent tweets about the vaccine made in collaboration by Pfizer and BioNTech, perform various NLP tasks on this data source.",.csv
Pharmacies,1,pharmacies,Pharmacies.csv,other,"**Data Description:**

This dataset represents pharmacies in the United States and Territories. A pharmacy is a facility whose primary function is to store, prepare and legally dispense prescription drugs under the professional supervision of a licensed pharmacist. It meets any licensing or certification standards set forth by the jurisdiction where it is located. This geospatial dataset includes pharmacies in the United States, as well as the territories of American Samoa, Guam, Puerto Rico, the Commonwealth of the Northern Mariana Islands, and the Virgin Islands.

The tabular data was gathered from the National Plan and Provider Enumeration System (NPPES) dataset. Pharmacies that were verified to service only animal populations were excluded from the dataset. The currentness of this dataset is indicated by the [CONTDATE] field. Based on this field the oldest record dates from 03/30/2010 and the newest record dates from 10/25/2010.

**Dataset provided by**

data.world, Inc.

",.csv
Phishing Dataset for Machine Learning,1,phishing-dataset-for-machine-learning,Phishing_Legitimate_full.csv,Attribution 4.0 International (CC BY 4.0),"### Context

Anti-phishing refers to efforts to block phishing attacks. Phishing is a kind of cybercrime where attackers pose as known or trusted entities and contact individuals through email, text or telephone and ask them to share sensitive information. Typically, in a phishing email attack, and the message will suggest that there is a problem with an invoice, that there has been suspicious activity on an account, or that the user must login to verify an account or password. Users may also be prompted to enter credit card information or bank account details as well as other sensitive data. Once this information is collected, attackers may use it to access accounts, steal data and identities, and download malware onto the user’s computer.

### Content

This dataset contains 48 features extracted from 5000 phishing webpages and 5000 legitimate webpages, which were downloaded from January to May 2015 and from May to June 2017. An improved feature extraction technique is employed by leveraging the browser automation framework (i.e., Selenium WebDriver), which is more precise and robust compared to the parsing approach based on regular expressions. 

Anti-phishing researchers and experts may find this dataset useful for phishing features analysis, conducting rapid proof of concept experiments or benchmarking phishing classification models.

### Acknowledgements

Tan, Choon Lin (2018), “Phishing Dataset for Machine Learning: Feature Evaluation”, Mendeley Data, V1, doi: 10.17632/h3cgnj8hft.1
[Source of the Dataset.](https://data.mendeley.com/datasets/h3cgnj8hft/1)",.csv
Phone Classification Dataset,1,phone-classification-dataset,train.csv,Apache 2.0,"
Dataset Overview: A collection of features characterizing mobile phones, including battery power, camera specifications, network support, memory, screen dimensions, and other attributes. The 'price_range' column categorizes phones into price ranges, making this dataset suitable for mobile phone classification and price prediction tasks.",.csv
Phone Prices,1,phone-prices,cleaned_all_phones.csv,Attribution 4.0 International (CC BY 4.0),"This dataset contains phone features including price of popular brands. Every phone in this dataset continues to be manufactured. Does not include discontinued phones.

- phone_name: name of the phone
- brand: brand of the phone
- os: operating system of the phone
- inches size of the phone screen as inches
- resolution: resolution of the phone screen
- battery: battery capacity of the phone
- battery_type: battery type of the phone
- ram(GB): ram of the phone as GB
- announcement_date: the date of the announcement of the phone
- weight(g): weight of the phone as gram
- storage(GB): storage capacity of the phone as GB
- video_720p: does phone camera has 720p feature
- video_1080p: does phone camera has 1080p feature
- video_4K: does phone camera has 4K feature
- video_8K: does phone camera has 8K feature
- video_30fps: does phone camera has 30fps feature
- video_60fps: does phone camera has 60fps feature
- video_120fps: does phone camera has 120fps feature
- video_240fps: does phone camera has 240fps feature
- video_480fps: does phone camera has 480fps feature
- video_960fps: does phone camera has 960fps feature
- price(USD): price of the phone as USD

NOTE : The purpose of this dataset is training and practice. It can never be used for commercial purposes.",.csv
Pima Indians Diabetes Database,1,pima-indians-diabetes-database,diabetes.csv,CC0-1.0,"## Context

This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.

## Content

The datasets consists of several medical predictor variables and one target variable, `Outcome`. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.

## Acknowledgements

Smith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). [Using the ADAP learning algorithm to forecast the onset of diabetes mellitus][1]. *In Proceedings of the Symposium on Computer Applications and Medical Care* (pp. 261--265). IEEE Computer Society Press.

## Inspiration

Can you build a machine learning model to accurately predict whether or not the patients in the dataset have diabetes or not?

  [1]: http://rexa.info/paper/04587c10a7c92baa01948f71f2513d5928fe8e81",.csv
Pinterest Stock Performance 📈 | 2022 to 2024,1,pinterest-stock-performance-2022-to-present,pins_stock_data.csv,Apache 2.0,"## Overview
This analysis focuses on Pinterest, Inc. (PINS) stock performance from January 1, 2022, to the present date. By analyzing historical stock data, we aim to provide insights into Pinterest's financial trends, market volatility, and factors influencing its stock price over this period.

## Column Names
- **Date:** The date of the stock data.
- **Open:** The opening price of Pinterest stock on the given date.
- **High:** The highest price of Pinterest stock during the trading day.
- **Low:** The lowest price of Pinterest stock during the trading day.
- **Close:** The closing price of Pinterest stock on the given date.
- **Adj Close:** The adjusted closing price of Pinterest stock, accounting for any corporate actions such as dividends or stock splits.
- **Volume:** The trading volume of Pinterest stock on the given date.",.csv
Pistachio types detection,1,pistachio-types-detection,pistachio.csv,Community Data License Agreement - Sharing - Version 1.0,"Did you know there are numerous varieties of pistachios? Considering that each species has unique properties, recognizing and isolating pistachios is a highly practical technique. Some pistachios, for example, are better suited for baking, and others, which are more crunchy, are generally consumed as snacks.
Pistachio types detection, numbers are extracted by image processing methods.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F11592511%2F9107ea75bea18b095900b48e230bc4ec%2F2.jpg?generation=1688826287210809&alt=media)

You can visit my notebook to get more information about dataset

",.csv
Pizza Hut Ratings and Reviews,1,pizza-hut-ratings-and-reviews,pizza_hut_reviews.csv,ODC Attribution License (ODC-By),"### Dataset Overview:
The ""Pizza Hut Reviews and Ratings: Insights from One of Sri Lanka's Pioneer Branches"" dataset comprises a detailed compilation of customer feedback for the Pizza Hut outlet at Union Place, Colombo. This branch stands out as one of the inaugural Pizza Hut locations in Sri Lanka. The dataset is structured to encapsulate a wide array of customer experiences through ratings and textual reviews.

### Data Science Applications:
- Sentiment Analysis: Extracting and analyzing customer sentiments from textual reviews.
- Trend Identification: Identifying patterns and trends in customer feedback over time.
- Customer Satisfaction Metrics: Quantifying satisfaction levels based on ratings and review content.

### Column Descriptors:
- **title**: Specifies the Pizza Hut location reviewed, here being Union Place, Colombo.
- **stars**: Customer-provided rating on a scale from 1 (lowest) to 5 (highest).
- **text**: Customer's written review, offering deeper insights into their experience.

### Ethically Mined Data:
The dataset adheres to strict data privacy standards, including GDPR, ensuring the removal of personal identifiers to maintain reviewer anonymity and privacy.

### Acknowledgments:
Gratitude is extended to the platforms enabling this data collection and to Pizza Hut for the use of their logo as the thumbnail image for this dataset. This is purely for illustrative purposes and does not imply any affiliation or endorsement.",.csv
Pizza Price Data,1,pizza-price-prediction-real-data,pizza_data.csv,CC0-1.0,"## Context

I created 4 pizza prices list data from various companies, such as Pizza Hut, Domino's Pizza, etc. And my purpose for making this data is only for learning purposes, and I don't use it for my personal interests, here's the description for every company:

## **Desc**

### **Domino’s Pizza Menu Prices**

If Domino’s doesn’t ring a bell, then you must have been living in Mongolia, as this is one of the only places this chain doesn’t have a restaurant. With over 10,000 stores in 73 countries, Domino’s have conquered the global pizza market. Not to mention being the second-largest pizza chain in the USA.

From their humble beginnings as a traditional pizzeria, they have continuously expanded their menu and at current locations, you can find a huge variety of items. Worldwide you’ll find first and foremost a vast range of pizzas; but also chicken wings, pasta, garlic bread, cheesy bread, potato wedges, a range of soft drinks and a divine selection of delicious desserts. All baked in-house and to your personal preferences.

### **Pizza Hut Menu Prices**

Pizza Hut is a company founded in Wichita Kansas. The franchise was started by two brothers in the 1950’s and grew from there. There are several options for customers to choose. The. There are salads, pizzas, pasta, and various other food items. The food’s taste is generally great and has good quality.

The company employs over 160,000 people worldwide. Pizza Hut is a wholly-owned subsidiary owned by Yum! Brands. Currently t the restaurant is headquartered in Plano Texas. The franchise’s slogan is Flavor of Now. This slogan shows of the brand want to improve itself int into the future. The franchise has found consistent success and growth throughout the years.

### **Godfather’s Pizza Menu Prices**

This fast-casual Italian chain has been a long time favourite across America, at one point ranking the third-largest pizza chain in the country. While they no longer hold the title of one of the largest, they remain one of the best. Their slogan is simple and straight to the point “We serve good pizza”.

Godfather’s Pizza has always been committed to providing a better tasting, all-around superior product and this is exactly what they provide. They make their signature dish the way it’s supposed to be made, with four different types of delicious crust, 100% real cheese and incredible toppings.

### **IMO’s Pizza Menu Prices**

This chain has been around for many years, filling the homes of their customers with consistently improving delights.  Their thin crust is something their particularly famous for, cooked to perfection and cut into delightful bitesize squares, their slogan “the square beyond compare” definitely holds up to its high expectations.

Imo’s Pizza is also famous for the incredible St. Louis style pizza that is made with amazing Provel cheese. The company are dedicated to ensuring their customers are fully satisfied with every aspect of the business. So, whether you stop in and collect or get it delivered straight to your home, try one of their legendary dishes today.

## **Content**

### **Independent Variables**

* `Company`: The company that made the pizza.
* `Pizza Name`: The name of the pizza.
* `Type`: The type of pizza.
* `Size`: The size of the pizza.

### **Dependant Variable**

* `Price`: The price of the pizza.

## **Task**

* Q1: What is the most expensive pizza in each company?
* Q2: Which company has more pizzas on the menu?
* Q3: What is the average ($\mu$) price of pizza in each company?
* Q4: Suppose the Pizza Hut company owns $P = \{X | X \ unique \ price \ value\}$ and Domnino's Pizza owns $D = \{X | X \ unique \ price \ value\}$ what is $P \cap D$?
* Q5: For example, the average success probability (success makes customers happy) in the service of each existing company is $87\%$
    1. What is the probability for any company to succeed in making customers happy?
    2. What is the probability for each company to fail to make customers happy?
    3. What is the probability of at least one of the four companies succeeding in making customers happy?
* Q6: In a city, the city has $4$ pizza selling companies, namely **Domino's Pizza**, **Pizza Hut**, **Godfather's Pizza**, and **IMO's Pizza**, Employees want to buy pizza to accompany their lunch break, unfortunately these employees can only choose to buy from $3$ companies only, How many choices can the five employees choose?

## **Disclaimer**

All attempts are made to provide up to date pricing information. However, prices and menu offerings can vary by location and time of the day. Hence please consider prices to be estimated prices.  RealMenuPrices.com is an independent site and is not associated with or are affiliate of any restaurants food chains or entity listed on the site.

## **Data Source**

https://realmenuprices.com/dominos-pizza-menu-prices/",.csv
Pizza Sales Dataset,1,pizza-sales-dataset,pizza_sales.csv,Apache 2.0,"This dataset contain detailed information about pizza orders, including specifics about the pizza variants, quantities, pricing, dates, times, and categorization details.

**pizza_id**: A unique identifier assigned to each distinct pizza variant available for ordering.
**order_id:** A unique identifier for each order made, which links to multiple pizzas.
**pizza_name_id:** An identifier linking to a specific name of the pizza.
**quantity:** The number of units of a specific pizza variant ordered within an order.
**order_date:** The date when the order was placed.
**order_time:** The time when the order was placed.
**unit_price:** The cost of a single unit of the specific pizza variant.
**total_price:** The aggregated cost of all units of a specific pizza variant in an order.
**pizza_size:** Represents the size of the pizza (e.g., small, medium, large).
**pizza_category:** Indicates the category of the pizza, such as vegetarian, non-vegetarian, etc.
**pizza_ingredients:** Provides a list or description of the ingredients used in the pizza.
**pizza_name:** Specifies the name of the specific pizza variant ordered.
",.csv
Placement Classification,1,placement-classification,placement.csv,Apache 2.0,"The Placement Classification Dataset is a comprehensive collection of data designed to facilitate the prediction of career trajectories and job placements for students or job seekers. This dataset encompasses various attributes related to individuals' academic backgrounds, skills, experiences, and eventual employment outcomes.

Key attributes within the dataset typically include:

1. **Educational Background**: Information about the academic qualifications of individuals, such as their degree programs, majors, grades, and academic institutions attended.

2. **Skills and Certifications**: Details about the specific skills, certifications, and training programs completed by individuals, which may be relevant to their desired career paths or job roles.

3. **Internships and Work Experience**: Records of internships, co-op programs, part-time jobs, and full-time employment experiences, including company names, roles, responsibilities, and durations.

4. **Personal Attributes**: Additional characteristics of individuals, such as their age, gender, nationality, and languages spoken, which may influence their career opportunities and job placements.

5. **Placement Status**: The ultimate outcome of individuals' job search efforts, indicating whether they were successfully placed in employment positions or are still seeking employment.

6. **Salary Information**: Details about individuals' compensation packages, including base salaries, bonuses, benefits, and other forms of remuneration offered by employers.

7. **Industry and Job Role**: Classification of individuals' employment positions by industry sectors, job functions, seniority levels, and specific job titles.

8. **Geographical Location**: Information about the geographical locations of individuals' job placements, including city, state, or country, which may affect factors such as cost of living and career advancement opportunities.

Researchers, career counselors, human resource professionals, and educational institutions leverage the Placement Classification Dataset for various purposes, including:

- Predictive Modeling: Developing machine learning algorithms and statistical models to predict individuals' likelihood of job placement and their expected career trajectories based on their educational backgrounds, skills, and experiences.

- Career Counseling: Providing personalized guidance and recommendations to students or job seekers regarding their career options, skill development opportunities, and strategies for securing desired employment positions.

- Talent Acquisition: Assisting employers in identifying and recruiting suitable candidates for job vacancies by matching candidates' profiles with job requirements and organizational needs.

- Educational Program Evaluation: Evaluating the effectiveness of educational programs, curricula, and career development initiatives in preparing students for successful job placements and career advancement.

Overall, the Placement Classification Dataset serves as a valuable resource for understanding the dynamics of the labor market, facilitating informed decision-making in career planning and talent management, and supporting efforts to bridge the gap between education and employment.",.csv
Placement of  Students,1,placement-of-students,placement.csv,MIT,"Hi there 👋🏻,  
The inspiration for uploading the Dataset on the placement of students is to fine-tune, implement and test more and more theoretical concepts of Machine Learning and Deep Learning.",.csv
PlantUML Dataset,1,plantuml-dataset,plantuml-dataset.csv,GNU Lesser General Public License 3.0,"A compilation of PlantUML implementations tailored for various use cases. This dataset is the learning resource used to train [2UML](https://robertovicario.github.io).

The dataset contains information on various systems and processes, each represented by a title, description, keywords, code, and diagram type. Here's a breakdown of the features:

1. `title`: Describes the name or main functionality of the system or process.
2. `description`: Provides a brief overview or explanation of the system or process.
3. `keywords`: Contains relevant terms or phrases associated with the system or process, aiding in search and categorization.
4. `code`: Likely represents code snippets or diagrams illustrating the functioning or flow of the system or process. The code appears to be in a format compatible with PlantUML, a tool for creating UML diagrams using a simple textual description language.
5. `diagram`: Indicates the type of diagram corresponding to the system or process, such as sequence diagrams for depicting interactions between components or entities.",.csv
Play Badminton,1,play-badminton,badminton_dataset.csv,other,"This synthetic dataset contains information on the playability of badminton under different weather conditions. It includes features such as outlook (Sunny, Overcast, Rain), temperature (Hot, Mild, Cool), humidity (High, Normal), and wind (Weak, Strong). The target variable indicates whether badminton can be played ('Yes') or not ('No') based on these weather conditions. This dataset can be used for training machine learning models to predict the suitability of playing badminton given specific weather conditions.",.csv
PlaygroundS3E21Shakeup,1,playgrounds3e21shakeup,ShakeupAnalysis.csv,Community Data License Agreement - Permissive - Version 1.0,"This is a small curated excel file created from the private and public LBs in playground season 3 episode 21. 
I analyze the shakeup in detail dividing the final standings into regions based on my understanding of the overall participant behavior. 
I think this will help me fine tune my preparation going ahead as I realize that winners in the private LB resorted to very simple approaches and submitted less but meaningfully. Also, I learn not to fall prey to behavioral biases while making a submission selection choice here as I often fall prey to endowment bias and make a sub-optimal choice. 
Best regards! Happy learning!

Image source - https://www.shutterstock.com/search/falling-off-cliff",.csv
Poems from poetryfoundation.org,1,modern-renaissance-poetry,all.csv,CC0-1.0,"### Context
Study for poem classification. Trying to classified poems with targets age and type. 
I use two Xgboost predictors to predict target and type separately.     


### Content

Please refer to the website https://www.poetryfoundation.org/
For now I only crawl the data of 

 - renaissance love
 - modern love 
 - renaissance nature
 - modern nature
 - renaissance  mythology & folklore
 - modern  mythology & folklore


Some have copyrights. I only use for studying :)
### Acknowledgements

https://www.poetryfoundation.org/ has the copyright 

### Inspiration

classification is fun!!",.csv
Pokemon Dataset,1,pokemon-dataset,Pokemon.csv,MIT,"This data set includes 898 Pokemon, 1072 including alternate forms, including their number, name, first and second type, the stat total and basic stats: HP, Attack, Defense, Special Attack, Special Defense, and Speed, generation, and legendary status. It has been of great use when teaching statistics to kids. With certain types you can also give a geeky introduction to machine learning.

These are the raw attributes that are used for calculating how much damage an attack will do in the games. This dataset is about the pokemon games (NOT pokemon cards or Pokemon Go).

Number: The ID for each pokemon

Name: The name of each pokemon

Type 1: Each pokemon has a type, this determines weakness/resistance to attacks

Type 2: Some pokemon are dual type and have 2

Total: Sum of all stats that come after this, a general guide to how strong a pokemon is

HP: Hit points, or health, defines how much damage a pokemon can withstand before fainting

Attack: The base modifier for normal attacks (eg. Scratch, Punch)

Defense: The base damage resistance against normal attacks

SP Atk: Special attack, the base modifier for special attacks (e.g. fire blast, bubble beam)

SP Def: Special defense, the base damage resistance against special attacks

Speed: Determines which pokemon attacks first each round

Generation: The generation of games where the pokemon was first introduced

Legendary: Some pokemon are much rarer than others, and are dubbed ""legendary""

Inspiration: The type of a pokemon cannot be inferred only by its Attack and Defense. It would be worthy to find which two variables can define the type of a pokemon, if any. Two variables can be plotted in a 2D space, and used as an example for machine learning. This could mean the creation of a visual example any geeky Machine Learning class would love.",.csv
Pokemon Gen VII Pokedex with Moves,1,pokemon-gen-vii-pokedex,pokedex.csv,CC0-1.0,"### Context

This dataset includes much of the general data and stats seen on other similar datasets, with the main highlight being the inclusion of the level-up moveset of every Pokemon.
I may include other moves also learnable such as TM/HMs and egg moves in the future.
The dataset includes information only on the base forms/formes of each pokemon, so no information on Megas, Alolan variants, or things like Deoxys Attack/Defense/Speed formes.
I'm unlikely to ever include that sort of info.


### Content

- ID: (National) Pokedex number.
- Name: Pokemon's English name.
- Type 1: Pokemon's main typing.
- Type 2: Pokemon's secondary typing.
- Abilities: List of all abilities that Pokemon species can have. Includes hidden/special ones.
- Category: The ""species"" of that Pokemon as given in the Sun/Moon Pokedex.
- Height (ft)
- Height (m)
- Weight (lbs)
- Weight (kg)
- [Capture Rate:](https://bulbapedia.bulbagarden.net/wiki/Catch_rate) Quantifies how easy to catch the Pokemon is.
- Egg Steps: Number of in-game steps require for an egg of this Pokemon to hatch.
- Exp Group: All Pokemon fall into one of six ""Exp Groups"" that determine how much experience points are required for it to level up.
- Total: The sum of the base stats.
- HP: Hit Points, or Health Points.
- Attack
- Defense
- Sp. Attack: Special Attack
- Sp. Defense: Special Defense
- Speed
- Moves: A list (python dict) of all the moves that Pokemon can learn:
    - Type: The move's typing.
    - Level: The level at which the Pokemon learns this move.
    - Power
    - Accuracy: Base accuracy as a percentage.
    - PP: Power points, or how many times the move can be used per battle.
    - Effect: If the move has a secondary effect, the percentage of it being activated.
    - Description: Some flavour text from the game.


### Acknowledgements

Thanks to [serebii.net](https://serebii.net) who keep an exhaustive database on all things Pokemon.

Photo by Jay on Unsplash",.csv
Pokemon Image Dataset,1,pokemon-images-and-types,pokemon.csv,Attribution 4.0 International (CC BY 4.0),"### Context

Images of all Pokemon from generation 1 to generation 7, along with their types (primary and secondary) as a csv. 


### Inspiration
New evolution forms from two different Pokemon. (Create new Pokemon) 

Predict Pokemon primary and secondary types from the images. Identify what types the evolution form will have based on the pre-evolved forms. Eg. from Pichu and Pikachu predict for Raichu. 



### Future work/Ideas: 
Merge with other information such as moves, generation, strong/weak against etc, and use the images to classify.

### Acknowledgements

data scrapped from https://pokemondb.net/pokedex/national

cover image from https://www.hjackets.com/blog/pikachu-costume-for-kids-and-adult/
",.csv
Pokemon Stats (1025 Pokemons),1,pokemon-stats-1025-pokemons,pokemon_data.csv,CC0-1.0,"This dataset contains information about Pokémon registered within the National Dex. It includes details such as Pokémon Name, Type, Stats (Attack, Defense, Special Defense, Special Attack, Speed, HP), Ability, Egg Group, Grouping, Generation, and more.

The data was collected by scraping the following websites:
- https://pokemondb.net/
- https://bulbapedia.bulbagarden.net

I tried to make the dataset as clean as possible, but there may be some errors since I am still a beginner experimenting with web scraping. I hope this data can be helpful to others who are also experimenting with data analytics or are just Pokémon fans.

Header and Thumbnail image from: https://pngfre.com/pokeball-png/pokeball-1/",.csv
Pokemon TCG All Cards 1999 - 2023,1,pokemon-tcg-all-cards-1999-2023,pokemon-tcg-data-master 1999-2023.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"Aggregate CSV that compiles comprehensive information on Pokémon Trading Card Game (TCG) sets and cards from 1999 to 2023, sourced from the Pokémon TCG API. This dataset provides a comprehensive view of Pokémon TCG cards, including detailed attributes, abilities, attacks, and other relevant information. It serves as a valuable resource for analysis, research, and exploration of the Pokémon TCG universe spanning multiple series and generations.

**Data Representation:**
The dataset includes columns containing Python syntax, such as lists, dictionaries, and lists of dictionaries. These structures enhance the flexibility and richness of representing various attributes associated with Pokémon Trading Card Game (TCG) sets and cards.

**Academic Research Notice:**
This dataset is intended exclusively for academic research purposes. Users are reminded that the dataset is not to be transformed or redistributed for commercial purposes. Academic researchers can leverage this dataset to explore and analyze the evolution of Pokémon TCG sets and cards over the years.",.csv
PokemonGO,1,pokemongo,pokemonGO.csv,CC0-1.0,"This is a database of the first 151 pokemon; the ones you can find in the **PokemonGO** game. The stats include Pokemon Number, Name, First and Second Type, Max CP, Max HP and a url from the bulbagarden.net gallery.

- **Pokemon No**: Number or ID of the pokemon.
- **Name**: The original name of the pokemon.
- **First Type**: What type of pokemon it is.
- **Second Type**: Some pokemon can have two types, if they don't, this cell is empty.
- **Max CP**: This is the maximum amount of damage a pokemon can infringe.
- **Max HP**: The maximum amount of damage a pokemon can receive.
- **URL**: This is a link to the pokemon's image on bulbagarden.

This database presents a great way of helping new generations of pokemon players learn about data science and pokemon at the same time. This data was scrapped from http://handbooks.bulbagarden.net/pokemongo/pokemon-index",.csv
Pokémon Combat Power Prediction!,1,pokmon-combat-power-prediction,pokemon.csv,CC-BY-SA-4.0,"**Problem Statement:**

Predict the combat power of Pokémon based on various attributes, while handling null values and outliers for data cleaning practices.

**Dataset Description:**

Name: Name of the Pokémon.
Type 1: Primary type of the Pokémon (e.g., Grass, Fire, Water, etc.).
Type 2: Secondary type of the Pokémon, if any.
Total: Total combat power of the Pokémon.
HP: Hit Points, indicating the Pokémon's health.
Attack: Attack power of the Pokémon.
Defense: Defensive power of the Pokémon.
Sp. Atk: Special Attack power of the Pokémon.
Sp. Def: Special Defense power of the Pokémon.
Speed: Speed attribute of the Pokémon.
Generation: Generation of the Pokémon.
Legendary: Whether the Pokémon is legendary or not.

This dataset will contain null values and outliers intentionally introduced to mimic real-world data cleaning scenarios.",.csv
Political Social Media Posts,1,political-social-media-posts,political_social_media.csv,CC0-1.0,"This dataset, from [Crowdflower's Data For Everyone Library](https://www.crowdflower.com/data-for-everyone/), provides text of 5000 messages from politicians' social media accounts, along with human judgments about the purpose, partisanship, and audience of the messages.

## How was it collected?
Contributors looked at thousands of social media messages from US Senators and other American politicians to classify their content. Messages were broken down into audience (national or the tweeter’s constituency), bias (neutral/bipartisan, or biased/partisan), and finally tagged as the actual substance of the message itself (options ranged from informational, announcement of a media appearance, an attack on another candidate, etc.)

## Acknowledgments

Data was provided by the [Data For Everyone Library](https://www.crowdflower.com/data-for-everyone/) on [Crowdflower](https://www.crowdflower.com).

Our Data for Everyone library is a collection of our favorite open data jobs that have come through our platform. They're available free of charge for the community, forever.

## Inspiration

Here are a couple of questions you can explore with this dataset:

- what words predict partisan v. neutral messages?
- what words predict support messages v. attack messages?
- do politicians use Twitter and Facebook for different purposes? (e.g., Twitter for attack messages, Facebook for policy messages)?

## The Data

The dataset contains one file, with the following fields:

- **_unit_id**: a unique id for the message
- **_golden**: always FALSE; (presumably whether the message was in Crowdflower's gold standard)
- **_unit_state**: always ""finalized""
- **_trusted_judgments**: the number of trusted human judgments that were entered for this message; an integer between 1 and 3
- **_last_judgment_at**: when the final judgment was collected
- **audience**: one of *national* or *constituency*
- **audience:confidence**: a measure of confidence in the audience judgment; a float between 0.5 and 1
- **bias**: one of *neutral* or *partisan*
- **bias:confidence**: a measure of confidence in the bias judgment; a float between 0.5 and 1
- **message**: the aim of the message. one of:
-- *attack*: the message attacks another politician  
-- *constituency*: the message discusses the politician's constituency  
-- *information*: an informational message about news in government or the wider U.S.  
-- *media*: a message about interaction with the media  
-- *mobilization*: a message intended to mobilize supporters  
-- *other*: a catch-all category for messages that don't fit into the other  
-- *personal*: a personal message, usually expressing sympathy, support or condolences, or other personal opinions  
-- *policy*: a message about political policy  
-- *support*: a message of political support  
- **message:confidence**: a measure of confidence in the message judgment; a float between 0.5 and 1
- **orig__golden**: always empty; presumably whether some portion of the message was in the gold standard
- **audience_gold**: always empty; presumably whether the audience response was in the gold standard
- **bias_gold**: always empty; presumably whether the bias response was in the gold standard
- **bioid**: a unique id for the politician
- **embed**: HTML code to embed this message
- **id**: unique id for the message WITHIN whichever social media site it was pulled from
- **label**: a string of the form ""From: *firstname lastname* (*position* from *state*)""
- **message_gold**: always blank; presumably whether the message response was in the gold standard
- **source**: where the message was posted; one of ""facebook"" or ""twitter""
- **text**: the text of the message",.csv
Polycystic ovary syndrome (PCOS),1,polycystic-ovary-syndrome-pcos,PCOS_infertility.csv,CC-BY-NC-SA-4.0,"**If you reach this DATASET, please UPVOTE this dataset to show your appreciation**


Polycystic ovary syndrome is a disorder involving infrequent, irregular or prolonged menstrual periods, and often excess male hormone (androgen) levels. The ovaries develop numerous small collections of fluid — called follicles — and may fail to regularly release eggs
dataset contains all physical and clinical parameters to determine PCOS and infertility related issues .
data is collect from 10 different hospital across Kerala,India.
   all the best and don't forget to upvote the dataset👍 
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F2533028%2Fbd7cb716170c664ce3485c9e0643dea1%2FUntitled.png?generation=1573970628670762&alt=media)
 I encourage you to use this Dataset to start your own projects. If you do, please cite the Dataset:
  author = {Prasoon Kottarathil},
  title = {Polycystic ovary syndrome (PCOS)},
  year = {2020},
  publisher = {kaggle},
  journal = {Kaggle Dataset},
  how published = {\url{https://www.kaggle.com/prasoonkottarathil/polycystic-ovary-syndrome-pcos}}
",.csv
Polygon Transaction Dataset (Raw),1,polygon-transaction-dataset-raw,polygon.csv,other,"Explore Polygon Transaction Dataset: Dive into the world of Polygon blockchain with this dataset, containing transaction details. Analyze transaction patterns, track the flow of funds, and uncover insights into one of the leading cryptocurrencies.
[Source](https://polygonscan.com/)",.csv
Popular Books Dataset,1,goodreads-popular-books-dataset,books.csv,Apache 2.0,"This file contains information about popular books. Each row represents a book and includes details such as the book ID, Goodreads book ID, best book ID, work ID, number of books in the series, ISBN and ISBN13 numbers, authors, original publication year, original title, title, language code, average rating, number of ratings, number of work ratings, number of text reviews, rating counts for different rating levels (1-5 stars), and URLs for the book's image and small image.

This dataset can be useful for various purposes, such as analyzing reading trends, popular authors, and book ratings across different genres or languages. It can also be used to build recommendation systems or explore correlations between book characteristics and their popularity or ratings.",.csv
Popular Health Supplements Flipkart,1,popular-health-supplements-flipkart,Health_Suppliments_Flipkart_02_04_2022.csv,CC0-1.0,"Pricing and Review data of popular health supplements available in https://www.flipkart.com/

Data scraped on the basis of 5 distinct categories of health supplements.
categories are:
1. Vitamin Supplement
1. Protein Supplement
1. Digestive Probiotic
1. Energy Drinks
1. Milk Drink Mixes

Example: Vitamin Supplement - https://www.flipkart.com/health-care/health-supplements/vitamin-supplement/pr?sid=hlc%2Cetg%2Cqtw&otracker=categorytree&page=  

Major Attributes are:

1. title: title of the product 
2. quantity:  quantity of product 
3. brand: name of the manufacturer 
4. url: product url 
5. product_id: product id or sku in flipkart.com
6. listing_id: listing id of product
7. highlights: highlight section available in the product page 
8. availability: availability of  product 
9. selling_price: selling price or discounted price of the product
10. original_price: actual price of the model or the pre-discounted price
11. currency: currency of selling and original price
12. avg_rating: average rating of the product
13. ratings_count: total number of ratings
14. reviews_count: total number of reviews
15.  attributes 
      one stars count, 
      two stars count, 
      three stars count, 
      four stars count and five stars count 
      represent the histogram breakup of Ratings & Reviews section in the product page. 
16. category: category health supplement.

Note: histogram break up data gives a clear insight on the review data of a product.

",.csv
Popular Movies of IMDb,1,tmdb-top-10000-popular-movies-dataset,TMDb_updated.CSV,CC0-1.0,"[![forthebadge](https://forthebadge.com/images/badges/made-with-python.svg)](https://forthebadge.com) 

**Introduction**

TMDB.org is a crowd-sourced movie information database used by many film-related consoles, sites and apps, such as XBMC, MythTV and Plex. Dozens of media managers, mobile apps and social sites make use of its API.
TMDb lists some 80,000 films at time of writing, which is considerably fewer than IMDb. While not as complete as IMDb, it holds extensive information for most popular/Hollywood films.
This is dataset of the 10,000 most popular movies across the world has been fetched through the read API.
TMDB's free API provides for developers and their team to programmatically fetch and use TMDb's data.
Their API is  to use as long as you attribute TMDb as the source of the data and/or images. Also, they update their API from time to time.

This data set is fetched using exception handling process so the data set contains some null values as there are missing fields in the tmdb database. Thought it's good for a young analyst to deal with messing value.  
Hey  analyst are you all excited?

",.csv
Popular Video Games 1980 - 2023 🎮,1,popular-video-games-1980-2023,games.csv,DbCL-1.0,"This dataset contains a list of video games dating from 1980 to 2023, it also provides things such as release dates, user review rating, and critic review rating.

Not only can you find the popular games mentioned here but also the obscure indie ones which we have forgotten in time!

Backloggd is a video game collection website mixed with social elements to focus on bringing your gaming profile to life. Create a free account to get started on logging the games you've played, and then rating and reviewing as you go! Go into detail with logging platforms, time played, and even a daily journal to keep track your daily gaming progress with playthroughs. It's all tailored to how much you want to log, so that your profile fits you. Then outside of that you can create lists of games, friend other users, follow their activities, and so much more!

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F7428813%2F826d926de85723f7ac541cd0b1b96ff8%2Fbackloggd.png?generation=1679588946343916&alt=media)

#  Inspiration
The purpose of this dataset is to gain insights into the trends of game genre popularity.

I am particularly interested in the following questions:

Which game genres are the most popular?
What are the trends in popularity for each game genre?
Can we identify any relationship between plot, genre, and popularity?
Can we use generative NLP to generate catchy game titles or plots?
Which games are users inclined to play right now and which ones do they keep hanging in their game shelves?",.csv
Population Growth in India 1950-2024,1,population-growth-in-india-1950-2024,macrotrends.csv,CC0-1.0,This dataset contains the variation in the population of India over the past 74 years. This dataset will be of great help in driving insights related to the population growth in India. ,.csv
Population Ranking👩‍👩‍👦‍👦⚡,1,population-ranking,POP.csv,Apache 2.0,"# **Description**

The Population Ranking dataset contains information about the population of countries around the world, ranked in order of highest to lowest population. The dataset may include additional information such as:

- Country name
- Population size (estimated or actual)
- Source of data
- Column 2 (Show the Ranking)

## This dataset can be used for various purposes such as:

- Analyzing population trends and growth patterns
- Comparing population sizes across countries
- Identifying the most population countries
- Visualizing population data on a map or chart
- Informing policy decisions related to population and demographics
",.csv
Population by Country - 2020,1,population-by-country-2020,population_by_country_2020.csv,other,"### Context

I always wanted to access a data set that was related to the world’s population (Country wise). But I could not find a properly documented data set. Rather, I just created one manually.


### Content

Now I knew I wanted to create a dataset but I did not know how to do so. So, I started to search for the content (Population of countries) on the internet. Obviously, [Wikipedia](https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population) was my first search. But I don't know why the results were not acceptable. And also there were only I think 190 or more countries. So then I surfed the internet for quite some time until then I stumbled upon a great website. I think you probably have heard about this. The name of the website is [Worldometer](https://www.worldometers.info/world-population/population-by-country/). This is exactly the website I was looking for. This website had more details than Wikipedia. Also, this website had more rows I mean more countries with their population.

Once I got the data, now my next hard task was to download it. Of course, I could not get the raw form of data. I did not mail them regarding the data. Now I learned a new skill which is very important for a data scientist. I read somewhere that to obtain the data from websites you need to use this technique. Any guesses, keep reading you will come to know in the next paragraph.


![alt text](https://fiverr-res.cloudinary.com/images/t_main1,q_auto,f_auto/gigs/119580480/original/68088c5f588ec32a6b3a3a67ec0d1b5a8a70648d/do-web-scraping-and-data-mining-with-python.png)

You are right its, [Web Scraping](https://en.wikipedia.org/wiki/Web_scraping). Now I learned this so that I could convert the data into a CSV format. Now I will give you the scraper code that I wrote and also I somehow found a way to directly convert the pandas data frame to a CSV(Comma-separated fo format) and store it on my computer. Now just go through my code and you will know what I'm talking about.


**Below is the code that I used to scrape the code from the website**


![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F3200273%2Fe814c2739b99d221de328c72a0b2571e%2FCapture.PNG?generation=1581314967227445&alt=media)


### Acknowledgements

Now I couldn't have got the data without [Worldometer](https://www.worldometers.info/world-population/population-by-country/). So special thanks to the website. It is because of them I was able to get the data.

### Inspiration

As far as I know, I don't have any questions to ask. You guys can let me know by finding your ways to use the data and let me know via kernel if you find something interesting",.csv
Portuguese Apartment Listings Dataset,1,portugal-real-estate-house-pricing,portugal_apartments.csv,Apache 2.0,"The dataset provides information about apartments available for sale in Portugal, gathered from Imovirtual. Each entry in the dataset represents an apartment and includes the following attributes:

Index: A unique identifier for each entry in the dataset.
Name: The apartment type, indicating the number of bedrooms.
Price: The selling price of the apartment.
Area: The area of the apartment in square meters.
Location: The district where the apartment is situated.

The provided data sample encompasses a variety of apartment types, prices, areas, and locations in different districts of Portugal, covering both new and used apartments. These data are valuable for real estate market analysis and price predictions.",.csv
Possum Regression,1,openintro-possum,possum.csv,CC0-1.0,"### Context

Can you use your regression skills to predict the age of a possum, its head length, whether it is male or female?  This classic practice regression dataset comes originally from the [DAAG R package](https://cran.r-project.org/web/packages/DAAG/index.html) (datasets used in examples and exercises in the book Maindonald, J.H. and Braun, W.J. (2003, 2007, 2010) ""Data Analysis and Graphics Using R"").  This dataset is also used in the [OpenIntro Statistics](https://www.openintro.org/book/os/) book chapter 8 *Introduction to linear regression*.

### Content

From the DAAG R package:  ""*The possum data frame consists of nine morphometric measurements on each of 104 mountain brushtail possums, trapped at seven sites from Southern Victoria to central Queensland*.""


### Acknowledgements

Data originally found in the [DAAG R package](https://cran.r-project.org/web/packages/DAAG/index.html) and used in the book Maindonald, J.H. and Braun, W.J. (2003, 2007, 2010) ""Data Analysis and Graphics Using R"").  

A subset of the data was also put together for the [OpenIntro Statistics](https://www.openintro.org/book/os/) book chapter 8 *Introduction to linear regression*.

***Original Source of dataset:***
*Lindenmayer, D. B., Viggers, K. L., Cunningham, R. B., and Donnelly, C. F. 1995. Morphological
variation among columns of the mountain brushtail possum, Trichosurus caninus Ogilby (Phalangeridae: Marsupiala). Australian Journal of Zoology 43: 449-458.*

### Inspiration

Get your feet wet with regression techniques here on Kaggle by using this dataset.  Perfect for beginners since the OpenIntro Statistics book does a good explanation in Chapter 8.

*  Can we use total length to predict a possum's head length?
*  Which possum body dimensions are most correlated with age and sex?
*  Can we classify a possum's sex by its body dimensions and location?
*  Can we predict a possum's trapping location from its body dimensions?",.csv
PostPartum Depression,1,postpartum-depression,post natal data.csv,CC0-1.0,"In our research, we gathered a dataset of 1503 records from a medical hospital using a
questionnaire administered through a Google form. This dataset has not yet been published.
Our dataset includes 15 attributes, where I select 10 attributes, 9 of which were used for
analysis and 1 of which was the target attribute. The target attribute, ""Feeling Anxious,""
was chosen as a predictor of postpartum depression.",.csv
Power Consumption of Tetouan City,1,power-consumption,Tetuan City power consumption.csv,CC0-1.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F12038776%2F8656e914a85ebc06bb6823f743e8e28e%2Fjpg.jpeg?generation=1713847292872398&alt=media)

# About Dataset
This dataset is related to power consumption of three different distribution networks of Tetouan city which is located in north Morocco.
## Column info

| Variable Name           | Role   | Type            | Description                                                  | Units        | Missing Values |
|----------------------|-------|--------------|------------------------------------------|------------------|-----------|
| DateTime                   | Feature|   Date          | Each ten minutes                                        | -                       | no             |
| Temperature              | Feature| Continuous | Weather Temperature of Tetouan city       | -                       | no             |
| Humidity                    | Feature| Continuous | Weather Humidity of Tetouan city              | -                       | no             |
| Wind Speed               | Feature| Continuous | Wind speed of Tetouan city                        | -                       | no             |
| general diffuse flows | Feature| Continuous | General diffuse flows                               | -                       | no             |
| diffuse flows              | Feature| Continuous | Diffuse flows                                     | -                       | no             |
| Zone 1 Power Consumption| Target | Continuous | Power consumption of zone 1 of Tetouan city       | -                    | no            |  
| Zone 2 Power Consumption| Target | Continuous | Power consumption of zone 2 of Tetouan city       | -                       | no             |
| Zone 3 Power Consumption| Target | Continuous | Power consumption of zone 3 of Tetouan city       | -                       | no             |
",.csv
PowerCo Churn Data,1,powerco-churn-data,client_data.csv,MIT,"Now that you have a dataset of cleaned and engineered features, it is time to build a predictive model to see how well these features are able to predict a customer churning. The energy market has had a lot of change in recent years and there are more options than ever for customers to choose from. PowerCo are concerned about their customers leaving for better offers from other energy providers. When a customer leaves to use another service provider, this is called churn. This is becoming a big issue for PowerCo and they have engaged BCG to help diagnose the reason why their customers are churning.

● id = client company identifier

● activity_new = category of the company’s activity

● channel_sales = code of the sales channel

● cons_12m = electricity consumption of the past 12 months

● cons_gas_12m = gas consumption of the past 12 months

● cons_last_month = electricity consumption of the last month

● date_activ = date of activation of the contract

● date_end = registered date of the end of the contract

● date_modif_prod = date of the last modification of the product

● date_renewal = date of the next contract renewal

● forecast_cons_12m = forecasted electricity consumption for next 12 months

● forecast_cons_year = forecasted electricity consumption for the next calendar year

● forecast_discount_energy = forecasted value of current discount

● forecast_meter_rent_12m = forecasted bill of meter rental for the next 2 months

● forecast_price_energy_off_peak = forecasted energy price for 1st period (off peak)

● forecast_price_energy_peak = forecasted energy price for 2nd period (peak)

● forecast_price_pow_off_peak = forecasted power price for 1st period (off peak)

● has_gas = indicated if client is also a gas client

● imp_cons = current paid consumption

● margin_gross_pow_ele = gross margin on power subscription

● margin_net_pow_ele = net margin on power subscription

● nb_prod_act = number of active products and services

● net_margin = total net margin

● num_years_antig = antiquity of the client (in number of years)

● origin_up = code of the electricity campaign the customer first subscribed to

● pow_max = subscribed power

● churn = has the client churned over the next 3 months",.csv
Predict Chargeback Frauds,1,predict-chargeback-frauds-payment,df.csv,other,"### Context

The dataset contains one month of credit card transactions in a pretty raw situation. It also yells if the transaction was detected as a chargeback - a kind of fraud, or not.
The business running beyond the data set is an e-commerce and the focus was around reaching South Americans.

### Content

Each observation is a transaction and you got when it happened, the card holder main number and the amount. Make a magic and sort it out how can you understand the behaviour of frauds.


### Inspiration

Can you predict a chargeback fraud?",.csv
Predict Diabetes,1,predict-diabities,diabetes.csv,CC0-1.0,"This dataset is originally from the National Institute of Diabetes and Digestive and Kidney
Diseases. The objective of the dataset is to diagnostically predict whether a patient has diabetes,
based on certain diagnostic measurements included in the dataset. Several constraints were placed
on the selection of these instances from a larger database. In particular, all patients here are females
at least 21 years old of Pima Indian heritage.2
From the data set in the (.csv) File We can find several variables, some of them are independent
(several medical predictor variables) and only one target dependent variable (Outcome).

# Data Dictionary
| Columns | Description |
| --- | --- |
| Pregnancies | To express the Number of pregnancies |
| Glucose | To express the Glucose level in blood |
| BloodPressure | To express the Blood pressure measurement |
| SkinThickness | To express the thickness of the skin |
| Insulin | To express the Insulin level in blood |
| BMI | To express the Body mass index |
| DiabetesPedigreeFunction | To express the Diabetes percentage |
| Age | To express the age |
| Outcome | To express the final result 1 is Yes and 0 is No |",.csv
Predict FIFA 2018 Man of the Match,1,fifa-2018-match-statistics,FIFA 2018 Statistics.csv,other,"### Context

I thought of consolidating and sharing this public data to see how the data science world uses it discover interesting patterns. The data has been collected from 2018 FIFA World Cup Russia Official App.

### Content
The data will be updated after each match daily.

Note: On the column '1st Goal', any goal that was scored in the extra time will be denoted as 45 or 90 based on 1st or 2nd half of the game (ex. if 1st goal was scored in 45+2 mins then it will be mentioned as 45 instead of 47, likewise for the 2nd half)

### Acknowledgements

Thanks to the FIFA 2018 World Cup App.


### Inspiration
I thought of consolidating and sharing this public data to see how the data science world uses it discover interesting patterns. Can we predict the Man of the match award using this statistics before the official announcement that will be made right after the match?",.csv
"Predict students dropout, academic success👨‍🎓📖",1,predict-students-dropout-and-academic-success,dataset.csv,CC0-1.0,"# About Dataset
This dataset created from a higher education institution (acquired from several disjoint databases) related to students enrolled in different undergraduate degrees, such as agronomy, design, education, nursing, journalism, management, social service, and technologies. The dataset includes information known at the time of student enrollment (academic path, demographics, and social-economic factors) and the students' academic performance at the end of the first and second semesters. The data is used to build classification models to predict students' dropout and academic success. The problem is formulated as a three-category classification task, in which there is a strong imbalance towards one of the classes. 

# Dataset Attributes 
Column name	              Description
Marital status	             The marital status of the student. (Categorical)
Application mode	     The method of application used by the student. (Categorical)
Application order	    The order in which the student applied. (Numerical)
Course	                  The course taken by the student. (Categorical)
Daytime/evening attendance	Whether the student attends classes during the day or in the evening. (Categorical)
Previous qualification	The qualification obtained by the student before enrolling in higher education. (Categorical)
Nacionality	           The nationality of the student. (Categorical)
Mother's qualification	The qualification of the student's mother. (Categorical)
Father's qualification	The qualification of the student's father. (Categorical)
Mother's occupation	The occupation of the student's mother. (Categorical)
Father's occupation	The occupation of the student's father. (Categorical)
Displaced	Whether the student is a displaced person. (Categorical)
Educational special needs	Whether the student has any special educational needs. (Categorical)
Debtor	Whether the student is a debtor. (Categorical)
Tuition fees up to date	Whether the student's tuition fees are up to date. (Categorical)
Gender	The gender of the student. (Categorical)
Scholarship holder	Whether the student is a scholarship holder. (Categorical)
Age at enrollment	The age of the student at the time of enrollment. (Numerical)
International	Whether the student is an international student. (Categorical)
Curricular units 1st sem (credited)	The number of curricular units credited by the student in the first semester. (Numerical)
Curricular units 1st sem (enrolled)	The number of curricular units enrolled by the student in the first semester. (Numerical)
Curricular units 1st sem (evaluations)	The number of curricular units evaluated by the student in the first semester. (Numerical)
Curricular units 1st sem (approved)	The number of curricular units approved by the student in the first semester. (Numerical)",.csv
Predict students' dropout and academic success,1,higher-education-predictors-of-student-retention,dataset.csv,CC0-1.0,"_____
# Predict students' dropout and academic success
### Investigating the Impact of Social and Economic Factors
By  [[source]](https://zenodo.org/record/5777340#.Y7FJotJBwUE)
_____

### About this dataset
&gt; This dataset provides a comprehensive view of students enrolled in various undergraduate degrees offered at a higher education institution. It includes demographic data, social-economic factors and academic performance information that can be used to analyze the possible predictors of student dropout and academic success. This dataset contains multiple disjoint databases consisting of relevant information available at the time of enrollment, such as application mode, marital status, course chosen and more. Additionally, this data can be used to estimate overall student performance at the end of each semester by assessing curricular units credited/enrolled/evaluated/approved as well as their respective grades. Finally, we have unemployment rate, inflation rate and GDP from the region which can help us further understand how economic factors play into student dropout rates or academic success outcomes. This powerful analysis tool will provide valuable insight into what motivates students to stay in school or abandon their studies for a wide range of disciplines such as agronomy, design, education nursing journalism management social service or technologies

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; This dataset can be used to understand and predict student dropouts and academic outcomes. The data includes a variety of demographic, social-economic and academic performance factors related to the students enrolled in higher education institutions. The dataset provides valuable insights into the factors that affect student success and could be used to guide interventions and policies related to student retention.
&gt; 
&gt; Using this dataset, researchers can investigate two key questions: 
&gt; - which specific predictive factors are linked with student dropout or completion? 
&gt; - how do different features interact with each other? 
&gt; For example, researchers could explore if there any demographic characteristics (e.g., gender, age at enrollment etc.) or immersion conditions (e.g., unemployment rate in region) are associated with higher student success rates, as well as understand what implications poverty has for educational outcomes.  By answering these questions, research insight is generated which can provide critical information for administrators on formulating strategies that promote successful degree completion among students from diverse backgrounds in their institutions.             
&gt;                     
&gt; In order to use this dataset effectively it is important that scientists familiarize themselves with all variables provided in the dataset including categorical (qualitative) variables such as gender or application mode; numerical variables such as number of curricular units at the beginning of semesters or age at enrollment; ordinal data measurement type variables such as marital status; studied trends over time such as inflation rate or GDP; frequency measurements variables like percentage of scholarship holders; etc.. Additionally scientists should make sure they aware off all potential bias included in the data prior running analysis–for example understanding if one population is underrepresented compared another -as this phenomenon could lead unexpected results if not taken into consideration while conducting research undertaken using this data set.. Finally it would be important for practitioners realize that this current Kaggle Dataset contains only one semester-worth information on each admission intake whereas additional studies conducted for a longer time period might be able provide more accurate results related selected topic area due further deterioration retention achievement coefficients obtained from those gradually accurate experiments unfolding different year-long admissions seasons

### Research Ideas
&gt; - Prediction of Student Retention: This dataset can be used to develop predictive models that can identify student risk factors for dropout and take early interventions to improve student retention rate. 
&gt; - Improved Academic Performance: By using this data, higher education institutions could better understand their students' academic progress and identify areas of improvement from both an individual and institutional perspective. This will enable them to develop targeted courses, activities, or initiatives that enhance academic performance more effectively and efficiently. 
&gt; - Accessibility Assistance: Using the demographic information included in the dataset, institutions could develop specific initiatives designed to help certain groups more easily access higher education services or resources that may not typically be available in their area or for their social-economic class, helping close existing gaps in accessibility across different student populations

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://zenodo.org/record/5777340#.Y7FJotJBwUE)
&gt; 
&gt;


### License
&gt; 
&gt; 
&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: dataset.csv**
| Column name                                | Description                                                                                   |
|:-------------------------------------------|:----------------------------------------------------------------------------------------------|
| **Marital status**                         | The marital status of the student. (Categorical)                                              |
| **Application mode**                       | The method of application used by the student. (Categorical)                                  |
| **Application order**                      | The order in which the student applied. (Numerical)                                           |
| **Course**                                 | The course taken by the student. (Categorical)                                                |
| **Daytime/evening attendance**             | Whether the student attends classes during the day or in the evening. (Categorical)           |
| **Previous qualification**                 | The qualification obtained by the student before enrolling in higher education. (Categorical) |
| **Nacionality**                            | The nationality of the student. (Categorical)                                                 |
| **Mother's qualification**                 | The qualification of the student's mother. (Categorical)                                      |
| **Father's qualification**                 | The qualification of the student's father. (Categorical)                                      |
| **Mother's occupation**                    | The occupation of the student's mother. (Categorical)                                         |
| **Father's occupation**                    | The occupation of the student's father. (Categorical)                                         |
| **Displaced**                              | Whether the student is a displaced person. (Categorical)                                      |
| **Educational special needs**              | Whether the student has any special educational needs. (Categorical)                          |
| **Debtor**                                 | Whether the student is a debtor. (Categorical)                                                |
| **Tuition fees up to date**                | Whether the student's tuition fees are up to date. (Categorical)                              |
| **Gender**                                 | The gender of the student. (Categorical)                                                      |
| **Scholarship holder**                     | Whether the student is a scholarship holder. (Categorical)                                    |
| **Age at enrollment**                      | The age of the student at the time of enrollment. (Numerical)                                 |
| **International**                          | Whether the student is an international student. (Categorical)                                |
| **Curricular units 1st sem (credited)**    | The number of curricular units credited by the student in the first semester. (Numerical)     |
| **Curricular units 1st sem (enrolled)**    | The number of curricular units enrolled by the student in the first semester. (Numerical)     |
| **Curricular units 1st sem (evaluations)** | The number of curricular units evaluated by the student in the first semester. (Numerical)    |
| **Curricular units 1st sem (approved)**    | The number of curricular units approved by the student in the first semester. (Numerical)     |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [](https://zenodo.org/record/5777340#.Y7FJotJBwUE).

",.csv
Predict survival of patients with heart failure,1,predict-survival-of-patients-with-heart-failure,heart_failure_clinical_records_dataset.csv,Attribution 4.0 International (CC BY 4.0),"**Quick Start 🚀:** If you're not up for reading all of this, head straight to **the file section**. There, you'll find detailed explanations of the files and all the variables you need.


This dataset contains the medical records of 299 patients who had heart failure, collected during their follow-up period, where each patient profile has 13 clinical features.

**Dataset Characteristics:** Multivariate

**Subject Area:** Health and Medicine

**Associated Tasks:** Classification, Regression, Clustering

**Feature Type:** Integer, Real

**Instances:** 299

**Features:** 12

# Dataset Information

A detailed description of the dataset can be found in the Dataset section of the following paper: 

**Title:**
Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone

**Authors:**

Davide Chicco
Giuseppe Jurman
**Source:**
BMC Medical Informatics and Decision Making 20, 16 (2020)

**DOI:**
`https://doi.org/10.1186/s12911-020-1023-5`


#Dataset Details

| Feature                   | Explanation                                            | Measurement     | Range               |
|---------------------------|--------------------------------------------------------|-----------------|---------------------|
| Age                       | Age of the patient                                     | Years           | [40,..., 95]        |
| Anaemia                   | Decrease of red blood cells or hemoglobin             | Boolean         | 0, 1                |
| High blood pressure       | If a patient has hypertension                         | Boolean         | 0, 1                |
| Creatinine phosphokinase  | Level of the CPK enzyme in the blood                  | mcg/L           | [23,..., 7861]      |
| (CPK)                     |                                                        |                 |                     |
| Diabetes                  | If the patient has diabetes                           | Boolean         | 0, 1                |
| Ejection fraction         | Percentage of blood leaving the heart at each         | Percentage      | [14,..., 80]        |
|                           | contraction                                            |                 |                     |
| Sex                       | Woman or man                                           | Binary          | 0, 1                |
| Platelets                 | Platelets in the blood                                 | kiloplatelets/mL| [25.01,..., 850.00] |
| Serum creatinine          | Level of creatinine in the blood                       | mg/dL           | [0.50,..., 9.40]    |
| Serum sodium              | Level of sodium in the blood                           | mEq/L           | [114,..., 148]      |
| Smoking                   | If the patient smokes                                  | Boolean         | 0, 1                |
| Time                      | Follow-up period                                      | Days            | [4,...,285]         |
| (target) death event     | If the patient died during the follow-up period       | Boolean         | 0, 1                |



#Statistical quantitative description of the category features

number of patients. %: percentage of patients. Full sample: 299 individuals. Dead patients: 96 individuals. Survived patients: 203 individuals.



| Category feature          | Full sample | Dead patients | Survived patients |
|---------------------------|-------------|---------------|-------------------|
| Anaemia (0: false)       |             |               |                   |
|                           | #           | %             | #                 | %                 | #                | %
|                           | 170         | 56.86         | 50                | 52.08             | 120              | 59.11
| Anaemia (1: true)        |             |               |                   |
|                           | #           | %             | #                 | %                 | #                | %
|                           | 129         | 43.14         | 46                | 47.92             | 3                | 40.89
| High blood pressure (0: false) |         |               |                   |
|                           | #           | %             | #                 | %                 | #                | %
|                           | 194         | 64.88         | 57                | 59.38             | 137              | 67.49
| High blood pressure (1: true) |          |               |                   |
|                           | #           | %             | #                 | %                 | #                | %
|                           | 105         | 35.12         | 39                | 40.62             | 66               | 32.51
| Diabetes (0: false)      |             |               |                   |
|                           | #           | %             | #                 | %                 | #                | %
|                           | 174         | 58.19         | 56                | 58.33             | 118              | 58.13
| Diabetes (1: true)       |             |               |                   |
|                           | #           | %             | #                 | %                 | #                | %
|                           | 125         | 41.81         | 40                | 41.67             | 85               | 41.87
| Sex (0: woman)           |             |               |                   |
|                           | #           | %             | #                 | %                 | #                | %
|                           | 105         | 35.12         | 34                | 35.42             | 71               | 34.98
| Sex (1: man)             |             |               |                   |
|                           | #           | %             | #                 | %                 | #                | %
|                           | 194         | 64.88         | 62                | 64.58             | 132              | 65.02
| Smoking (0: false)       |             |               |                   |
|                           | #           | %             | #                 | %                 | #                | %
|                           | 203         | 67.89         | 66                | 68.75             | 137              | 67.49
| Smoking (1: true)        |             |               |                   |
|                           | #           | %             | #                 | %                 | #                | %
|                           | 96          | 32.11         | 30                | 31.25             | 66               | 32.51


#Statistical quantitative description of the category features

Full sample: 299 individuals. Dead patients: 96 individuals. Survived patients: 203 individuals. σ: standard deviation

Here's the organized table:

| Numeric feature           | Full sample | Dead patients          | Survived patients      |
|---------------------------|-------------|------------------------|------------------------|
|                           | Median      | Mean       | σ          | Median | Mean     | σ           | Median | Mean    | σ           |
| Age                       | 60.00       | 60.83      | 11.89      | 65.00       | 65.22      | 13.21       | 60.00       | 58.76      | 10.64       |
| Creatinine phosphokinase  | 250.00      | 581.80     | 970.29     | 259.00      | 670.20     | 1316.58     | 245.00      | 540.10     | 753.80      |
| Ejection fraction         | 38.00       | 38.08      | 11.83      | 30.00       | 33.47      | 12.53       | 38.00       | 40.27      | 10.86       |
| Platelets                 | 262.00      | 263.36     | 97.80      | 258.50      | 256.38     | 98.53       | 263.00      | 266.66     | 97.53       |
| Serum creatinine          | 1.10        | 1.39       | 1.03       | 1.30        | 1.84       | 1.47        | 1.00        | 1.19       | 0.65        |
| Serum sodium              | 137.00      | 136.60     | 4.41       | 135.50      | 135.40     | 5.00        | 137.00      | 137.20     | 3.98        |
| Time                      | 115.00      | 130.30     | 77.61      | 44.50       | 70.89      | 62.38       | 172.00      | 158.30     | 67.74       |



#Deep dive into the dataset

**Dataset Overview:**

- Medical records of 299 heart failure patients collected at Faisalabad Institute of Cardiology and Allied Hospital in Faisalabad, Punjab, Pakistan, during April–December 2015.
- Patients had left ventricular systolic dysfunction and were classified as NYHA classes III or IV.
- Consisted of 105 women and 194 men, aged between 40 and 95 years old.

**Features:**

- 13 features including clinical, body, and lifestyle information.
- Binary features: anaemia, high blood pressure, diabetes, sex, and smoking.
- Anaemia defined as haematocrit levels lower than 36%.
- Definition of high blood pressure not provided in the dataset.
- Creatinine phosphokinase (CPK) indicates the level of CPK enzyme in blood, possibly indicating heart failure or injury with high levels.
- Ejection fraction measures the percentage of blood pumped out by the left ventricle with each contraction.
- Serum creatinine indicates kidney function; high levels may suggest renal dysfunction.
- Serum sodium test checks sodium levels in the blood, abnormal levels may indicate heart failure.
- Death event feature used as target in binary classification study, indicating if the patient died or survived during the follow-up period (130 days on average).

**Dataset Characteristics:**

- Dataset represented as a table with 299 rows (patients) and 13 columns (features).
- Imbalance in the dataset with 203 survived patients and 96 dead patients.
- Survival rate: 67.89% negatives (survived), 32.11% positives (died).
- Further details and changes to feature names available in the original dataset curator's publication.


**Note 📝:** If you find this dataset useful, please consider giving it an **upvote!** Your support is appreciated.
",.csv
Predicting Credit Card Customer Segmentation,1,predicting-credit-card-customer-attrition-with-m,BankChurners.csv,CC0-1.0,"_____
# Predicting Credit Card Customer Segmentation
### Exploring Key Customer Characteristics
By  [[source]](https://zenodo.org/record/4322342#.Y8OsBdJBwUE)
_____

### About this dataset
&gt; This dataset contains a wealth of customer information collected from within a consumer credit card portfolio, with the aim of helping analysts predict customer attrition. It includes comprehensive demographic details such as age, gender, marital status and income category, as well as insight into each customer’s relationship with the credit card provider such as the card type, number of months on book and inactive periods. Additionally it holds key data about customers’ spending behavior drawing closer to their churn decision such as total revolving balance, credit limit, average open to buy rate and analyzable metrics like total amount of change from quarter 4 to quarter 1, average utilization ratio and Naive Bayes classifier attrition flag (Card category is combined with contacts count in 12months period alongside dependent count plus education level & months inactive). Faced with this set of useful predicted data points across multiple variables capture up-to-date information that can determine long term account stability or an impending departure therefore offering us an equipped understanding when seeking to manage a portfolio or serve individual customers

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; This dataset can be used to analyze the key factors that influence customer attrition. Analysts can use this dataset to understand customer demographics, spending patterns, and relationship with the credit card provider to better predict customer attrition. 
&gt; 

### Research Ideas
&gt; - Using the customer demographics, such as gender, marital status, education level and income category to determine which customer demographic is more likely to churn. 
&gt; - Analyzing the customer’s spending behavior leading up to churning and using this data to better predict the likelihood of a customer of churning in the future. 
&gt; - Creating a classifier that can predict potential customers who are more susceptible to attrition based on their credit score, credit limit, utilization ratio and other spending behavior metrics over time; this could be used as an early warning system for predicting potential attrition before it happens

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://zenodo.org/record/4322342#.Y8OsBdJBwUE)
&gt; 
&gt;


### License
&gt; 
&gt; 
&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: BankChurners.csv**
| Column name                                                                                                                            | Description                                                                                           |
|:---------------------------------------------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------------------------|
| **CLIENTNUM**                                                                                                                          | Unique identifier for each customer. (Integer)                                                        |
| **Attrition_Flag**                                                                                                                     | Flag indicating whether or not the customer has churned out. (Boolean)                                |
| **Customer_Age**                                                                                                                       | Age of customer. (Integer)                                                                            |
| **Gender**                                                                                                                             | Gender of customer. (String)                                                                          |
| **Dependent_count**                                                                                                                    | Number of dependents that customer has. (Integer)                                                     |
| **Education_Level**                                                                                                                    | Education level of customer. (String)                                                                 |
| **Marital_Status**                                                                                                                     | Marital status of customer. (String)                                                                  |
| **Income_Category**                                                                                                                    | Income category of customer. (String)                                                                 |
| **Card_Category**                                                                                                                      | Type of card held by customer. (String)                                                               |
| **Months_on_book**                                                                                                                     | How long customer has been on the books. (Integer)                                                    |
| **Total_Relationship_Count**                                                                                                           | Total number of relationships customer has with the credit card provider. (Integer)                   |
| **Months_Inactive_12_mon**                                                                                                             | Number of months customer has been inactive in the last twelve months. (Integer)                      |
| **Contacts_Count_12_mon**                                                                                                              | Number of contacts customer has had in the last twelve months. (Integer)                              |
| **Credit_Limit**                                                                                                                       | Credit limit of customer. (Integer)                                                                   |
| **Total_Revolving_Bal**                                                                                                                | Total revolving balance of customer. (Integer)                                                        |
| **Avg_Open_To_Buy**                                                                                                                    | Average open to buy ratio of customer. (Integer)                                                      |
| **Total_Amt_Chng_Q4_Q1**                                                                                                               | Total amount changed from quarter 4 to quarter 1. (Integer)                                           |
| **Total_Trans_Amt**                                                                                                                    | Total transaction amount. (Integer)                                                                   |
| **Total_Trans_Ct**                                                                                                                     | Total transaction count. (Integer)                                                                    |
| **Total_Ct_Chng_Q4_Q1**                                                                                                                | Total count changed from quarter 4 to quarter 1. (Integer)                                            |
| **Avg_Utilization_Ratio**                                                                                                              | Average utilization ratio of customer. (Integer)                                                      |
| **Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1** | Naive Bayes classifier for predicting whether or not someone will churn based on characteristics such |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [](https://zenodo.org/record/4322342#.Y8OsBdJBwUE).

",.csv
Predicting Critical Heat Flux,1,predicting-heat-flux,Data_CHF_Zhao_2020_ATE.csv,Attribution 4.0 International (CC BY 4.0),"### Context

This dataset was prepared for the journal article entitled ""On the prediction of critical heat flux using a physics-informed machine learning-aided framework"" (doi: 10.1016/j.applthermaleng.2019.114540). The dataset contains processed and compiled records of experimental critical heat flux and boundary conditions used for the work presented in the article. 

### Acknowledgements

Zhao, Xingang (2020), “Data for: On the prediction of critical heat flux using a physics-informed machine learning-aided framework”, Mendeley Data, V1, doi: 10.17632/5p5h37tyv7.1",.csv
Predicting Divorce,1,predicting-divorce,divorce.csv,other,"### Context

Answers to certain questions can provide key information regarding if a couple is likely to get divorced in the future.


### Content

**Attribute Information:**

Questions are ranked on a scale of 0-4 with 0 being the lowest and 4 being the highest. The last category states if the couple has divorced. 

1. If one of us apologizes when our discussion deteriorates, the discussion ends.
2. I know we can ignore our differences, even if things get hard sometimes.
3. When we need it, we can take our discussions with my spouse from the beginning and correct it.
4. When I discuss with my spouse, to contact him will eventually work.
5. The time I spent with my wife is special for us.
6. We don't have time at home as partners.
7. We are like two strangers who share the same environment at home rather than family.
8. I enjoy our holidays with my wife.
9. I enjoy traveling with my wife.
10. Most of our goals are common to my spouse.
11. I think that one day in the future, when I look back, I see that my spouse and I have been in harmony with each other.
12. My spouse and I have similar values in terms of personal freedom.
13. My spouse and I have similar sense of entertainment.
14. Most of our goals for people (children, friends, etc.) are the same.
15. Our dreams with my spouse are similar and harmonious.
16. We're compatible with my spouse about what love should be.
17. We share the same views about being happy in our life with my spouse
18. My spouse and I have similar ideas about how marriage should be
19. My spouse and I have similar ideas about how roles should be in marriage
20. My spouse and I have similar values in trust.
21. I know exactly what my wife likes.
22. I know how my spouse wants to be taken care of when she/he sick.
23. I know my spouse's favorite food.
24. I can tell you what kind of stress my spouse is facing in her/his life.
25. I have knowledge of my spouse's inner world.
26. I know my spouse's basic anxieties.
27. I know what my spouse's current sources of stress are.
28. I know my spouse's hopes and wishes.
29. I know my spouse very well.
30. I know my spouse's friends and their social relationships.
31. I feel aggressive when I argue with my spouse.
32. When discussing with my spouse, I usually use expressions such as ‘you always’ or ‘you never’ .
33. I can use negative statements about my spouse's personality during our discussions.
34. I can use offensive expressions during our discussions.
35. I can insult my spouse during our discussions.
36. I can be humiliating when we discussions.
37. My discussion with my spouse is not calm.
38. I hate my spouse's way of open a subject.
39. Our discussions often occur suddenly.
40. We're just starting a discussion before I know what's going on.
41. When I talk to my spouse about something, my calm suddenly breaks.
42. When I argue with my spouse, ı only go out and I don't say a word.
43. I mostly stay silent to calm the environment a little bit.
44. Sometimes I think it's good for me to leave home for a while.
45. I'd rather stay silent than discuss with my spouse.
46. Even if I'm right in the discussion, I stay silent to hurt my spouse.
47. When I discuss with my spouse, I stay silent because I am afraid of not being able to control my anger.
48. I feel right in our discussions.
49. I have nothing to do with what I've been accused of.
50. I'm not actually the one who's guilty about what I'm accused of.
51. I'm not the one who's wrong about problems at home.
52. I wouldn't hesitate to tell my spouse about her/his inadequacy.
53. When I discuss, I remind my spouse of her/his inadequacy.
54. I'm not afraid to tell my spouse about her/his incompetence.
**

### Acknowledgements

**Relevant Papers:**

Yöntem, M , Adem, K , İlhan, T , Kılıçarslan, S. (2019). DIVORCE PREDICTION USING CORRELATION BASED FEATURE SELECTION AND ARTIFICIAL NEURAL NETWORKS. Nevşehir Hacı Bektaş Veli University SBE Dergisi, 9 (1), 259-273. Retrieved from [Web Link]

**Citation Request:**

Yöntem, M , Adem, K , İlhan, T , Kılıçarslan, S. (2019). DIVORCE PREDICTION USING CORRELATION BASED FEATURE SELECTION AND ARTIFICIAL NEURAL NETWORKS. Nevşehir Hacı Bektaş Veli University SBE Dergisi, 9 (1), 259-273. Retrieved from [Web Link]


### Inspiration

What are the key indicators for divorce?
Which questions/factors are most significant when predicting divorce?",.csv
Predicting Heart Failure,1,heart-failure-clinical-records,heart_failure_clinical_records_dataset.csv,Attribution 4.0 International (CC BY 4.0),"Cardiovascular diseases (CVDs) are the number 1 cause of death globally, taking an estimated 17.9 million lives each year, which accounts for 31% of all deaths worlwide.
Heart failure is a common event caused by CVDs and this dataset contains 12 features that can be used to predict mortality by heart failure.

Most cardiovascular diseases can be prevented by addressing behavioural risk factors such as tobacco use, unhealthy diet and obesity, physical inactivity and harmful use of alcohol using population-wide strategies.

People with cardiovascular disease or who are at high cardiovascular risk (due to the presence of one or more risk factors such as hypertension, diabetes, hyperlipidaemia or already established disease) need early detection and management wherein a machine learning model can be of great help.

## Attribute Information:
Thirteen (13) clinical features:
- age: age of the patient (years)
- anaemia: decrease of red blood cells or hemoglobin (boolean)
- high blood pressure: if the patient has hypertension (boolean)
- creatinine phosphokinase (CPK): level of the CPK enzyme in the blood (mcg/L)
- diabetes: if the patient has diabetes (boolean)
- ejection fraction: percentage of blood leaving the heart at each contraction (percentage)
- platelets: platelets in the blood (kiloplatelets/mL)
- sex: woman or man (binary)
- serum creatinine: level of serum creatinine in the blood (mg/dL)
- serum sodium: level of serum sodium in the blood (mEq/L)
- smoking: if the patient smokes or not (boolean)
- time: follow-up period (days)
- [target] death event: if the patient deceased during the follow-up period (boolean)

&gt; More
- Find More Exciting🙀 Datasets [Here](https://www.kaggle.com/whenamancodes/datasets)
- An Upvote👍 A Dayᕙ(`▿´)ᕗ , Keeps Aman Hurray Hurray..... ٩(˘◡˘)۶Haha
",.csv
Predicting antibiotic resistance in gonorrhoea,1,gono-unitigs,metadata.csv,CC0-1.0,"### Context

In this project, you will learn how to fit a model for predicting resistance in bacteria, and see how different forms of cross-validation impact the interpretation of your performance results.

We will be focussing on a species called Neisseria gonorrhoeae, bacteria which cause gonorrhoea. Gonorrhoea is the second most common sexually transmitted infection (STI) in Europe, after chlamydia. Rates of gonorrhoea infection are on the rise, with a 26% increase reported from 2017-2018 in the UK.

Many people who are infected (especially women) experience no symptoms, helping its spread. However  if the infection is left untreated, it can lead to infertility in women, and can occasionally spread to other parts of the body such as your joints, heart valves, brain or spinal cord.

Resistance of these bacteria to antibiotics is rising over time, making infections hard to treat. Below, you can see rates of resistance to different antibiotics. Image is from this paper: https://www.mdpi.com/2079-6382/7/3/60.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F359577%2F15abf2baad53ec5d984d43e5fd48000a%2FResistance.png?generation=1568108650228712&alt=media)

In the past, patients were treated with an antibiotic called ciprofloxacin. Doctors had to stop using this antibiotic because resistance to the drug became too common, causing treatments if infections to fail. Until very recently, the recommended treatment was two drugs - ceftriaxone and azithromycin. Azithromycin was removed from recommendations because of concern over rising resistance to the antibiotic. Currently, in the UK, patients are only treated with ceftriaxone. In February 2018, the first ever reported case of resistance to treatment with ceftriaxone and azithromycin, as well as resistance to the last-resort treatment spectinomycin, was reported.

We will look at machine learning algorithms for predicting resistance to both ciprofloxacin and azithromycin.

### Content

For this project, we will be working with ""unitigs"", which are segments of DNA shared by a subset of the strains in our collection. This dataset contains unitigs that are statistically associated with resistance to three different antibiotics. 

There are three unitig files ('[code]_gwas_filtered_unitigs'), corresponding to trimmed versions of the full unitig files. Each contains the unitigs that have the lowest P-values in a genome-wide association study for resistance to a given antibiotic (azm = azithromycin, cfx = cefixime, cip = ciprofloxacin). Each column corresponds to a unitig, or sequence found in samples in the dataset. 1 means the unitig is present in a given sample, 0 means it is absent.

The metadata file contains the phenotype data we will be trying to predict. For this work, focus on predicting azm_sr, cfx_sr and cip_sr with the corresponding unitig data. sr refers to sensitive and resistant isolates, with 1 corresponding to resistance and 0 corresponding to sensitivity to the antibiotic. 


### Acknowledgements

The strains for this project have been gathered from the following sources:

Chisholm et al. (2016). An outbreak of high-level azithromycin resistant Neisseria gonorrhoeae in England. Sexually Transmitted Infections.
Demczuk et al. (2015). Whole-Genome Phylogenomic Heterogeneity of Neisseria gonorrhoeae Isolates with Decreased Cephalosporin Susceptibility Collected in Canada between 1989 and 2013. Journal of Clinical Microbiology.
Demczuk et al. (2016). Genomic Epidemiology and Molecular Resistance Mechanisms of Azithromycin-Resistant Neisseria gonorrhoeae in Canada from 1997 to 2014. Journal of Clinical Microbiology.
Eyre et al. (2017). WGS to predict antibiotic MICs for Neisseria gonorrhoeae. The Journal of Antimicrobial Chemotherapy.
Fifer et al. (2018). Sustained transmission of high-level azithromycin-resistant Neisseria gonorrhoeae in England: an observational study. The Lancet Infectious Diseases.
Grad et al. (2014). Genomic epidemiology of Neisseria gonorrhoeae with reduced susceptibility to cefixime in the USA: a retrospective observational study. The Lancet Infectious Diseases.
Grad et al. (2016). Genomic Epidemiology of Gonococcal Resistance to Extended-Spectrum Cephalosporins, Macrolides, and Fluoroquinolones in the United States, 2000-2013. The Journal of Infectious Diseases.
Harris et al. (2018). Public health surveillance of multidrug-resistant clones of Neisseria gonorrhoeae in Europe: a genomic survey. The Lancet Infectious Diseases.
Jacobsson et al. (2016). WGS analysis and molecular resistance mechanisms of azithromycin-resistant (MIC &gt;2 mg/L) Neisseria gonorrhoeae isolates in Europe from 2009 to 2014. The Journal of Antimicrobial Chemotherapy.
Lee et al. (2018). Genomic epidemiology and antimicrobial resistance of Neisseria gonorrhoeae in New Zealand. The Journal of Antimicrobial Chemotherapy.
Sánchez-Busó et al. (2018). Antimicrobial exposure in sexual networks drives divergent evolution in modern gonococci. bioRxiv.
Unemo et al. (2016). The novel 2016 WHO Neisseria gonorrhoeae reference strains for global quality assurance of laboratory investigations: phenotypic, genetic and reference genome characterization. The Journal of Antimicrobial Chemotherapy.


### Inspiration

Antimicrobial resistance is becoming a serious concern— currently antimicrobial resistant infections kill over 700,000 people per year. By 2050 its estimated 10 million people will die from of antimicrobial resistant infections.

A lot of infections are treated “empirically”, meaning that if the doctor has an idea of what bacteria you’re infected with, they will prescribe a standard antibiotic to treat it. This means that if you have an infection that’s resistant to the standard antibiotic, while you’re taking your course of antibiotics, the bacteria are still living and replicating inside you. This can lead to a rise in the prevalence of antibiotic resistant bacteria over time.

There’s growing interest in testing for antibiotic resistance before a patient begins treatment. But, there are some practical limitations that get in the way of doing this routinely. A major problem is that when people go to their doctor or to the hospital for treatment, they expect to be given antibiotics to treat their infection straight away. Laboratory testing for resistance can take between 24 hours for infections like MRSA, to months for tuberculosis.

Whole genome sequencing is becoming cheaper over time, making it a more practical approach for detecting antibiotic resistance. Sequencing can, in theory, give you results in a matter of hours, rather than days. The mechanisms that drive resistance in these bacteria are coded in their DNA, meaning that a single test could tell us about resistance to a panel of antibiotics, and also give us other useful information, like whether the strain you’re infected with is on the rise, or is related to one that’s circulating in the hospital or community at the time. We know that the information we need to find is in the DNA of these bacteria, but we don’t always know how to find it. That’s where machine learning could help.",.csv
Predicting the Hourly Electricity Consumption,1,predicting-the-hourly-electricity-consumption,Hourly Electricity Consumption.csv,CC-BY-SA-4.0,"This dataset can then be used to develop and validate time series forecasting models.
The dataset contains 2 columns:
- Timestamp
- Hourly Electricity Consumption",.csv
Prediction of music genre ,1,prediction-of-music-genre,music_genre.csv,CC0-1.0,"The full list of genres included in the CSV are 'Electronic', 'Anime', 'Jazz', 'Alternative', 'Country', 'Rap', 'Blues', 'Rock', 'Classical', 'Hip-Hop'. ",.csv
Predictive Maintenance Dataset,1,predictive-maintenance-dataset,predictive_maintenance_dataset.csv,MIT,"A company has a fleet of devices transmitting daily sensor readings. They would like to create a predictive maintenance solution to proactively identify when maintenance should be performed. This approach promises cost savings over routine or time based preventive maintenance, because tasks are performed only when warranted.

The task is to build a predictive model using machine learning to predict the probability of a device failure. When building this model, be sure to minimize false positives and false negatives. The column you are trying to Predict is called failure with binary value 0 for non-failure and 1 for failure.",.csv
Predictive Maintenance Dataset (AI4I 2020),1,predictive-maintenance-dataset-ai4i-2020,ai4i2020.csv,CC-BY-NC-SA-4.0,"Please note that **this is the original dataset** with **additional information and proper attribution**. There is at least one other version of this dataset on Kaggle that was uploaded without permission. Please be fair and attribute the original author.
This synthetic dataset is modeled after an existing milling machine and consists of 10 000 data points from a stored as rows with 14 features in columns

1.	UID: unique identifier ranging from 1 to 10000
2.	product ID: consisting of a letter L, M, or H for low (50% of all products), medium (30%) and high (20%) as product quality variants and a variant-specific serial number
3.	type: just the product type L, M or H from column 2
4.	air temperature [K]: generated using a random walk process later normalized to a standard deviation of 2 K around 300 K
5.	process temperature [K]: generated using a random walk process normalized to a standard deviation of 1 K, added to the air temperature plus 10 K.
6.	rotational speed [rpm]: calculated from a power of 2860 W, overlaid with a normally distributed noise
7.	torque [Nm]: torque values are normally distributed around 40 Nm with a SD = 10 Nm and no negative values.
8.	tool wear [min]: The quality variants H/M/L add 5/3/2 minutes of tool wear to the used tool in the process. 
9.	a 'machine failure' label that indicates, whether the machine has failed in this particular datapoint for any of the following failure modes are true.

The machine failure consists of five independent failure modes
10.	tool wear failure (TWF): the tool will be replaced of fail at a randomly selected tool wear time between 200 - 240 mins (120 times in our dataset). At this point in time, the tool is replaced 69 times, and fails 51 times (randomly assigned).
11.	heat dissipation failure (HDF): heat dissipation causes a process failure, if the difference between air- and process temperature is below 8.6 K and the tools rotational speed is below 1380 rpm. This is the case for 115 data points.
12.	power failure (PWF): the product of torque and rotational speed (in rad/s) equals the power required for the process. If this power is below 3500 W or above 9000 W, the process fails, which is the case 95 times in our dataset.
13.	overstrain failure (OSF): if the product of tool wear and torque exceeds 11,000 minNm for the L product variant (12,000 M, 13,000 H), the process fails due to overstrain. This is true for 98 datapoints.
14.	random failures (RNF): each process has a chance of 0,1 % to fail regardless of its process parameters. This is the case for only 5 datapoints, less than could be expected for 10,000 datapoints in our dataset.
If at least one of the above failure modes is true, the process fails and the 'machine failure' label is set to 1. It is therefore not transparent to the machine learning method, which of the failure modes has caused the process to fail.

This dataset is part of the following publication, please cite when using this dataset:
S. Matzka, ""Explainable Artificial Intelligence for Predictive Maintenance Applications,"" 2020 Third International Conference on Artificial Intelligence for Industries (AI4I), 2020, pp. 69-74, doi: 10.1109/AI4I49448.2020.00023.

The image of the milling process is the work of Daniel Smyth @ Pexels: https://www.pexels.com/de-de/foto/industrie-herstellung-maschine-werkzeug-10406128/",.csv
Premier League Matches 1993-2023,1,premier-league-matches-19922022,premier-league-matches.csv,CC0-1.0,"## Context
This dataset covers every match played in the English Premier League history from the start in 1992, to the final week of the 2021-2022 season.

## About the Premier League
The Premier League was founded on 20 February 1992 following the decision of clubs in the Football League First Division to break away from the Football League, founded in 1888, and take advantage of a lucrative television rights sale to Sky.

In total, 50 clubs have competed since the inception of the Premier League in 1992: forty-eight English and two Welsh clubs. Seven teams overall have won the title: Manchester United (13), Manchester City (6), Chelsea (5), Arsenal (3), Blackburn Rovers (1), Leicester City (1) and Liverpool (1).

## Analysis ideas 💡 
* Does the home stadium ground give any advantage? And if the answer is yes, what’s the quantity for this advantage?
* What is the best way to collect points, defensive or attacking play?
* Who is the best club manager in PL history?",.csv
Premier League Player Stats Data,1,premier-league-player-stats-data,Premier League Player Stats.csv,CC-BY-NC-SA-4.0,"### Context
Data set for people who love Football and Data Science.
Scraping code at GitHub repo: https://github.com/themlphdstudent/kaggle/blob/master/datasets/Premier%20League%20Player%20Stats/Premier%20League%20Player%20Stats.ipynb

### Content
- Rank : Rank of the player
- Player : Player name
- Team : Player team name
- GP : Games played
- GS : Games started
- MIN : Minutes played
- G : Goals
- ASST : Assists
- SHOTS : Total shots
- SOG : Shots on goal

### Data Source
The data is scraped from the website https://www.msn.com/en-us/sports/soccer/premier-league/player-stats by extracting the player stats in premier league. 

### Acknowledgements

The data has been crawled from the https://www.msn.com/en-us/sports/soccer/premier-league/player-stats website.
Cover photo credit : Photo by [Fachry Zella Devandra](https://unsplash.com/@zelladun?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com).",.csv
Premier League Standings 22 Seasons (2000-2022),1,premier-league-standings-11-seasons-20102021,EPL Standings 2000-2022.csv,CC0-1.0,"### Context

The Premier League, often referred to as the English Premier League or the EPL (legal name: The Football Association Premier League Limited), is the top level of the English football league system. Contested by 20 clubs, it operates on a system of promotion and relegation with the English Football League (EFL). Seasons run from August to May with each team playing 38 matches (playing all 19 other teams both home and away).[1] Most games are played on Saturday and Sunday afternoons. This data included the premier league standings of the last decade.

### Content

| Column |Description  |
| --- | --- |
| Season | Football season year |
| Pos | Final position of the team for that season |
| Team | Name of the team |
| Pld | Number of games played |
| W | Win |
| D | Draw |
| L | Loss |
| GF | Goals Scored |
| GA | Goals Conceded |
| GD | Goal Difference |
| Pts | Total Points scored by the team in that season |
| Qualification or relegation | Whether the team has qualified for the european continental cup or has been relegated to a lower tier league |

### Acknowledgements

I would like to acknowledge the work of all my fellow contributors to give me as gist of what kind of data can be uploaded on this platform

### Inspiration

Which teams have the best attacking or defensive record in the last decade ?
How many points does it usually take to qualify for Europe ?
Who are the underdogs of the last decade ?",.csv
Preço do aluguel de imóveis no Distrito Federal,1,preo-do-aluguel-de-imveis-no-distrito-federal,imoveis-df.csv,CC0-1.0,"Lista de imóveis a serem alugados que foram publicados no site DF imóveis no ano de 2024 para o Distrito Federal. Para cada imóvel há informações do valor cobrado no aluguel, a área do imóvel, a quantidade de quartos e a região administrativa em que está localizado. ",.csv
Price Prediction -Multiple Linear Regression,1,price-prediction-multiple-linear-regression,scrap price.csv,CC0-1.0,"The car company wants to enter a new market and needs an estimation of exactly which variables affect the car prices.
The goal is:
- Which variables are significant in predicting the price of a car
- How well do those variables describe the price of a car",.csv
Price of electricity and the renewable energy,1,price-of-electricity-and-the-renewable-energy,final_dataset.csv,CC-BY-NC-SA-4.0,"The dataset contains the evolution of electricity prices in Spain for the period 2020-11-01 to 2022-10-31. The average energy prices (in MWh) as a function of the market, the produced energy (in MW), as well as the renewable energy produced (in MW) by type (wind, solar, hydroelectric, etc.) are provided with a granularity of hours for the period of time mentioned above.

The data has been obtained from the webpage: https://www.esios.ree.es/es/.

Disclaimer: Express consent was provided by Red Eléctrica de España (source and proprietary of the data) to gather the data using web scraping under the framework of a practicum from the Master in Data Science from the Universitat Oberta de Catalunya (UOC). Under no circumstance do they support the reuse of the data. We express our intention to use the data for the purpose of the activity and decline any commercial interest in the use of the data extracted.",.csv
Private FM Radio Station in India as of 2021,1,private-fm-radio-station-in-india-as-of-2021,Private_FM_Stations.csv,other,"This dataset provides information on Private FM Radio Stations in India as of 2021. It includes details such as city, state, station category based on minimum net worth requirements, permission holder name, channel ID, frequency, and license validity dates. This data can be useful for analyzing the distribution of FM radio stations across different city tiers, understanding ownership structures, or studying trends in licensing. Licensed under the Government Open Data License -  India.

Here's a breakdown of the category system based on minimum net worth (as of 2021):

**D category**: Cities and those with a population up to 1 lakh (100,000): Rs. 50 Lakhs (5 million rupees)
**C category**: Cities: Rs. 1 Crore (10 million rupees)
**B category**: Cities: Rs. 2 Crore (20 million rupees)
**A category**: Cities: Rs. 3 Crore (30 million rupees)
**A+ category**: Cities: Rs. 3 Crore (30 million rupees)
All categories (All regions): Rs. 10 Crore (100 million rupees)",.csv
Procurement Notices,1,procurement-notices,procurement-notices.csv,CC0-1.0,"### Content  

This dataset includes procurement tender notices for World Bank financed projects. Learn more about the World Bank Group's operations in procurement at http://go.worldbank.org/9KQZWXNOI0.  

### Context  

This is a dataset hosted by the World Bank. The organization has an open data platform found [here](finances.worldbank.org) and they update their information according the amount of data that is brought in. Explore World Bank's Financial Data using Kaggle and all of the data sources available through the World Bank [organization page](https://www.kaggle.com/theworldbank)!  

* Update Frequency: This dataset is updated daily.

### Acknowledgements

This dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  

This dataset is distributed under Creative Commons Attribution 3.0 IGO",.csv
Product Advertising Data,1,product-advertising-data,Advertising_Data.csv,other,"Explore the dynamics of advertising impact on product sales with this synthesized dataset. Created using Python programming language, the dataset comprises **seven columns** representing advertising costs on various platforms — **TV, Billboards, Google Ads, Social Media, Influencer Marketing, and Affiliate Marketing**. The last column, **'Product_Sold'** quantifies the corresponding number of **units sold.** This dataset is designed for analysis and experimentation, allowing you to delve into the relationships between different advertising channels and the resulting product sales. Gain insights into marketing strategies and optimize your approach using this comprehensive, yet user-friendly dataset.",.csv
Product Classification and Clustering,1,product-classification-and-clustering,pricerunner_aggregate.csv,CC0-1.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F12038776%2F80f5b355cecadcd6755894dbf770d2d4%2F0_hbeIx8g0MO81snB_.jpg?generation=1713974740038283&alt=media)
# Dataset
This dataset was collected from PriceRunner, a popular product comparison platform. It includes 35311 product offers from 10 categories, provided by 306 different merchants. This dataset offers an ideal ground for evaluating classification, clustering, and entity matching algorithms. Although it contains product-related data, it can still be applied to any problem involving text/short-text mining.

# Column Information
| Variable Name | Role          | Type        | Description                           | Units | Missing Values |
|---------------|---------------|-------------|---------------------------------------|-------|----------------|
| Product ID    | Feature       | Integer     | Unique identifier for each product    |       | No             |
| Product Title | Feature       | Categorical | Title/name of the product             |       | No             |
| Merchant ID   | Feature       | Integer     | Unique identifier for each merchant   |       | No             |
| Cluster ID    | Feature       | Integer     | Identifier for product clusters       |       | No             |
| Cluster Label | Feature       | Categorical | Label for product clusters            |       | No             |
| Category ID   | Feature       | Integer     | Unique identifier for each category   |       | No             |
| Category Label| Feature       | Categorical | Label for product category            |       | No             |
",.csv
Product Reviews,1,product-reviews,reviews.csv,other,"The Product Reviews dataset has been synthetically generated.
This meticulously curated balanced review dataset is designed to enhance your natural language processing prowess. It comprises 2 columns.

-&gt; **Review**: 
This column contains the textual description of the reviews, offering a diverse range of vocabulary and language patterns.

-&gt; **Sentiment**: 
Each review is classified into one of the three distinct categories: Positive, Negative, or Neutral.


You can use this dataset to fine-tune existing pre-trained Large Language Models, create your own NLP models, and perform tasks of sentiment analysis using techniques such as Logistic Regression, Naive Bayes, Recursive Neural Network (RNN), and various other methods to hone your NLP skills.

**Useful Tip**: For better use, you can map the sentiment column to numeric values. You can also create N-gram models and tables for the same to analyze the dataset better.",.csv
Product Sales Data,1,product-sales-data,statsfinal.csv,CC0-1.0,"
**Greetings , fellow analyst !**

REC corp LTD. is small-scaled business venture established in India. They have been selling **FOUR PRODUCTS for OVER TEN YEARS** . 
The products are P1, P2, P3 and P4.   

They have collected data from their retail centers and organized it into a small csv file , which has been  given to you. 
**The excel file contains about 8 numerical parameters : ** 
 
Q1- Total unit sales of product 1  
Q2- Total unit sales of product 2  
Q3- Total unit sales of product 3  
Q4- Total unit sales of product 4  

S1- Total revenue from product 1  
S2- Total revenue from product 2  
S3- Total revenue from product 3  
S4- Total revenue from product 4  

**Example :**   
On 13-06-2010 , product 1 had been brought by 5422 people and INR 17187.74 had been generated in revenue from product 1.      

**Now , REC corp needs you to solve the following questions : **  

1) Is there any trend in the sales of all four products during certain months?   
2) Out of all four products , which product has seen the highest sales in all the given years?   
3) The company has all it's retail centers closed on the 31st of December every year. Mr: Hariharan , the CEO , would love to get an estimate on no: of units of each product that could be sold on 31st of Dec , every year , if all their retail centers were kept open.   
4) The CEO is considering an idea to drop the production of any one of the products. He wants you to analyze this data and suggest whether his idea would result in a massive setback for the company.  
5) The CEO would also like to predict the sales and revenues for the  year 2024. He wants you to give a yearly estimate with the best possible accuracy.   

Can you help REC corp with your analytical and data science skills ?  

NOTE: This is a hypothetical dataset generated using python for educational purposes. It bears no resemblance to any real firm. Any similarity is a matter of coincidence.  ",.csv
Product Sales and Returns Dataset,1,product-sales-and-returns-dataset,order_dataset.csv,Apache 2.0,"About the columns:

1. Item Name: This column likely represents the name or description of the product.
2. Category: This indicates the type or category of the product.
3. Version: It specifies a particular version or variant of the product.
4. Item Code: This is a unique code or identifier for the product variant.
5. Item ID: This column represents a unique identifier for the specific item.
6.  Buyer ID: It identifies the customer who made the purchase.
7. Transaction ID: This is a unique identifier for the order or transaction.
8. Date: This column represents the date when the transaction occurred.
9. Final Quantity: This indicates the final quantity of the product sold.
10. Total Revenue: It represents the total sales revenue generated from this transaction.
11. Price Reductions: This indicates any discounts or price reductions applied to the total sales.
12. Refunds: This represents the amount refunded for returned items.
13. Final Revenue: This represents the net sales revenue after deductions such as discounts and refunds.
14. Sales Tax: This represents any applicable taxes on the transaction.
15. Overall Revenue: This column represents the total revenue, including taxes.
16. Refunded Item Count: It indicates the quantity of items returned in this transaction.
17. Purchased Item Count: This column represents the total quantity of items ordered in this transaction.",.csv
Productivity and Hourly Compensation (1948-2021),1,productivity-and-hourly-compensation-1948-2021,productivity_n_hourly_compensation.csv,CC0-1.0,"This dataset provides insight into the productivity and hourly compensation trends in the United States from 1948 to 2021. 

It includes data on both overall compensation and compensation specifically for production and nonsupervisory workers. 

The data is sourced from the Economic Policy Institute's State of Working America Data Library.

#### What is productivity?
![](https://www.youtube.com/watch?v=y_kX5KKCJoU)

## Interesting Task Ideas:

1. Analyze the correlation between productivity growth and compensation trends.
2. Investigate the gender pay gap by comparing median compensation between men and women.
3. Study the impact of economic recessions on productivity and compensation patterns.
4. Compare hourly wages between production and nonsupervisory workers against the overall average.
5. Visualize the long-term trends and fluctuations in productivity and compensation.
6. Determine whether increases in productivity have resulted in proportional increases in compensation.
7. Analyze how compensation growth has varied across different decades.

---

If you find this dataset helpful, please consider upvoting it! 😊💖

---

### Checkout my other datasets

[USA Hispanic-White Wage Gap Dataset ](https://www.kaggle.com/datasets/asaniczka/usa-hispanic-white-wage-gap-dataset-1973-2022)

[Gender Wage Gap in the USA](https://www.kaggle.com/datasets/asaniczka/gender-wage-gap-in-the-usa-1973-2022)

[130K Kindle Books](https://www.kaggle.com/datasets/asaniczka/amazon-kindle-books-dataset-2023-130k-books)

[900K TMDb Movies](https://www.kaggle.com/datasets/asaniczka/tmdb-movies-dataset-2023-930k-movies)

[Black-White Wage Gap in the USA Dataset](https://www.kaggle.com/datasets/asaniczka/black-white-wage-gap-in-the-usa-dataset)

---

Photo by [Matt Ragland](https://unsplash.com/@mattragland?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash) on [Unsplash](https://unsplash.com/photos/8OVDzMGB_kw?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)",.csv
Programming Languages Trend Over Time,1,programming-languages-trend-over-time,programming language trend over time.csv,Apache 2.0,"This dataset titled ""Programming Languages Search over Time"" provides weekly search interest scores for three prominent programming languages - Python, Java, and C++ - over a period spanning from April 21, 2019, to April 23, 2024. The search interest scores represent the relative popularity of each programming language as determined by search engine queries.

This dataset can be used to analyze and visualize trends and patterns in the popularity of these programming languages over time, providing valuable insights into their usage and adoption in the software development community.",.csv
Project Management Dataset,1,project-management-dataset,Project_Management_Data.csv,CC0-1.0,"This dataset contains information about projects, and is very important for people who want to do task on project management. This dataset includes department or office name, Project name, project title, project component, project details, date and time. It has 6 columns and 1870 unique values.",.csv
Property Listings in Kuala Lumpur,1,property-listings-in-kuala-lumpur,data_kaggle.csv,CC0-1.0,"# Property Listings in Kuala Lumpur
This is the tabular result of scraping a property listing website for properties for sale in Kuala Lumpur, Malaysia. Only the overview page was scraped so individual property details are scarce.",.csv
Property Sale Data,1,property-sale-data,Hprice.csv,Apache 2.0,"Here's an explanation of each column:

1. **MSSubClass**: The building class. This column represents the type of dwelling involved in the sale.

2. **MSZoning**: The general zoning classification of the sale. This column indicates the general zoning classification of the property.

3. **LotArea**: Lot size in square feet. This column represents the area of the land associated with the property.

4. **LotConfig**: Lot configuration. This column describes the shape of the property and how it is situated.

5. **BldgType**: Type of dwelling. This column indicates the type of building involved in the sale, such as single-family detached, duplex, etc.

6. **OverallCond**: Overall condition rating. This column represents the overall condition of the property, rated on a scale from 1 to 10.

7. **YearBuilt**: Original construction date. This column indicates the year when the property was originally built.

8. **YearRemodAdd**: Remodel date. This column represents the year when the property was remodeled or renovated.

9. **Exterior1st**: Exterior covering on the house. This column describes the primary exterior covering material of the property.

10. **BsmtFinSF2**: Type 2 finished square feet. This column represents the area of the basement that is finished with a secondary type of finishing material.

11. **TotalBsmtSF**: Total square feet of basement area. This column indicates the total area of the basement in square feet.

12. **SalePrice**: Sale price of the property. This column represents the sale price of the property in dollars.

These columns provide various attributes and characteristics of the properties in the dataset, which can be used to predict the sale price of houses.",.csv
Prostate Cancer,1,prostate-cancer,Prostate_Cancer.csv,other,"This is the dataset of 100 patients to implement the machine learning algorithm and thereby interpreting results 

The data set consists of 100 observations and 10 variables (out of which 8 numeric variables and one categorical variable and is ID) which are as follows:

0. Id
1.Radius
2.Texture
3.Perimeter
4.Area
5.Smoothness
6.Compactness
7.diagnosis_result
8.Symmetry
9.Fractal dimension


",.csv
Proyecto 3: Segmentación de Clientes en ecommerce,1,proyecto-3-segmentacin-de-clientes-en-ecommerce,ventas-por-factura.csv,CC0-1.0,"### Introducción

En este proyecto realizarás un análisis descriptivo que permitirá mostrar a la CEO de una empresa de comercio online, qué tan bien o mal están yendo las ventas en la compañía, medir el *engagement* de los clientes a partir de un **análisis de cohortes**, y realizar una **segmentación de clientes aplicando la metodología RFM**, con el objetivo de que el negocio pueda enfocar sus esfuerzos y tomar estrategias distintas por cada segmento. Adicionalmente, aprenderás la importancia de la limpieza y el tratamiento de datos previo a la realización de cualquier análisis.

### La situación

Eres una Analista de Datos de una consultora de transformación digital que busca “apoyar a nuestros clientes a mejorar sus negocios a través de los datos” según se puede observar en su página web. El servicio más contratado de la empresa es el de Business Intelligence, en donde se busca integrar, visualizar y analizar grandes volúmenes de datos históricos para apoyar la toma de decisiones estratégicas en ventas.

Tu jefe te invita a una reunión con un cliente nuevo: UK Merch. Esta es una empresa joven, de tan solo 10 meses de antigüedad, que se dedica a la venta de ropa al por mayor, es decir, vende en cantidades relativamente grandes (generalmente de 20 artículos o más) y ofrece un precio más competitivo que el retail convencional. Sus clientes son emprendimientos más pequeños que se abastecen comprando a UK Merch.

En la reunión conoces a Federico, el Gerente de Administración y Finanzas de la compañía, y a Alejandra, la CEO. “Abrimos hace más o menos un año en el Reino Unido”, comienza contando Federico. “A los pocos meses, como vimos que las ventas iban bien y que nuestros precios eran competitivos, decidimos expandir nuestra operación a otros países de Europa”.

“Si bien comenzaron a llegar nuevos clientes, no estamos seguros si fue una decisión correcta.”, complementa Alejandra. “Esto ha complejizado nuestro día a día. No estamos seguros de dónde provienen nuestros mejores clientes, no hemos sido muy rigurosos en la recolección de datos, y no sabemos cómo enfocar el trabajo de nuestro equipo”. ""Creo que lo más grave, es que no tenemos foco. Estamos apuntando para todos lados sin saber si ese esfuerzo esta trayendo resultados"", complementa Federico.

Ambos callan y se mantienen atentos mientras tu jefe dispara preguntas para hacerse una idea de estado financiero del negocio.

“¿Cuánto es lo que venden en promedio al mes?, ¿cuántas ventas tienen en cada mes?, ¿cuál es el mes que más venden?, ¿quiénes son sus clientes más importantes?, ¿cuál es el monto promedio que gastan sus clientes?, ¿qué porcentaje de sus clientes han vuelto a comprarles?, ¿cómo se desglosa esta información según los países en donde venden?”

Mientras tomas nota de estas preguntas y términos nuevos, ves como Federico y Alejandra se miran confundidos.

“No sabemos cómo responder ninguna de esas preguntas”, responde Alejandra avergonzada.

“Si no conocen sus ventas, ni el perfil de sus clientes, ni que tan leales son, ¿cómo es que enfocan sus esfuerzos de mercadeo?, ¿a quién apuntan sus esfuerzos publicitarios?, ¿cuál es su estrategia de venta?” sigue tu jefe.

“Nuestro mensaje y estrategia es la misma para todos nuestros clientes” responde la CEO, sabiendo que no es la mejor respuesta.

“Hay mucho por hacer” dice tu jefe mirándote.

Al salir de la reunión acompañas a tu jefe por el pasillo mientras él te entrega instrucciones: “Este es un tipo de cliente común. Tiene un buen modelo de negocio entre manos pero no están seguros si la estrategia que están utilizando es la correcta. Además, claramente no están tomando decisiones basados en datos. Alejandra me compartió un **set de datos de las ventas del año pasado por factura**. Al parecer **no están completos** los datos pero es lo único que tenemos para trabajar.”

Casi tropiezas con un compañero mientras sigues caminando y tomando notas.

“Lo primero será revisar la calidad de los datos. Intuyo que no han sido muy rigurosos en la recolección de datos, por lo que primero debes **revisar datos faltantes, datos duplicados donde no corresponda (por ejemplo, que hayan ingresado dos veces la misma boleta) y valores que no tengan sentido, como números negativos en los precios o cantidades de los artículos**.” 

Llegan a su oficina. Se sienta y sigue: “Luego tenemos que hacernos una idea general de la salud del negocio. Para eso debes construir un** reporte que incluya tablas y gráficos que resuman las métricas claves de negocio,** como las que les pregunté en la reunión, pero también me gustaría que pongas de tu propia cosecha. Investiga y agrega las métricas y gráficos que tu creas conveniente para resumir los datos.”

“Lo que todavía no tengo muy claro es cómo medir la retención de los clientes…” piensa en voz alta mientras toma un sorbo de su café. A esto, tú respondes que hace poco aprendiste a hacer análisis por cohortes. Anteriormente lo aplicaste para [medir la retención en una startup Saas](https://www.kaggle.com/datacertlaboratoria/proyecto-2-startup-tecnolgica) pero hace unos días leíste [un artículo](https://www.barilliance.com/es/analisis-de-cohortes/) que explicaba que podías hacer algo similar si tomabas la fecha de la primera compra de un cliente como la fecha de inicio del cohort. “¡Me gusta la idea! **Podemos hacer ese análisis por separado para clientes de UK y extranjeros para ver si la expansión que hicieron de forma apresurada tuvo sentido**” concluye tu jefe.

“Creo que el aporte más significativo que podemos hacer a esa empresa en esta consultoría es ayudarlas a segmentar a sus clientes para poder tomar decisiones estratégicas entendiendo el público objetivo. ¿Has escuchado sobre la ley de pareto?"". Al ver tu cara de confusión procede a explicar: ""Pareto postula que el 80% de las ganancias provienen del 20% del esfuerzo. No es necesario hacer todo el esfuerzo para que un negocio ande bien, basta que uno sea inteligente y enfoque sus recursos estratégicamente para obtener grandes resultados. En el caso de UK Merch, intuyo que están mal gastando sus recursos. Podrían enfocar su comunicación de forma mucho más eficiente, dirigida a un público acotado de buenos clientes. Para esto necesito que hagas **una segmentación basada en Recencia, Frecuencia y Monto (RFM)  y de esta forma podremos recomendar a UK Merch estrategias concretas para atender a sus clientes.**”

Con este contexto, muchas preguntas, pero también muchas ganas de aprender, comienzas tu trabajo.

### Entregable

Para considerar completado este proyecto deberás entregar, por medio de la [plataforma de aprendizaje](http://app.laboratoria.la), lo siguiente:

1. Una hoja de cálculo que tenga, como mínimo, lo siguiente:
    - Fuente de datos pre-procesada (datos limpios)
    - Una pestaña de reporte con tablas y gráficos de las métricas principales del negocio
    - Una pestaña con un análisis por cohorte general y también uno para clientes UK y clientes no-UK
    - Una segmentación usando la metodología RFM
    - Todos los datos, tablas y visualizaciones adicionales que te sumen en tu análisis
2. Un video de máximo 5 minutos simulando una reunión con tu jefe, en donde le expliques tus conclusiones y recomendaciones. Para esto puedes apoyarte en tu spreadsheet o armar una presentación en Google Slides. Para grabarte te recomendamos la plataforma Loom. En particular, tu video debe entregar un diagnóstico de las ventas del negocio y recomendaciones concretas en base a tu análisis.

&gt;💡En este proyecto también te guiaremos en la construcción de tu informe, de esta manera estarás preparada para resolver exitosamente los siguientes proyectos. Te recomendamos primero completar la sección 1 del curso [“Estadística para no estadísticos”](https://skills.yourlearning.ibm.com/activity/UDEMY-4171216?planId=PLAN-F2DC3A8C2759§ionId=SECTION-A) en la plataforma de SkillsBuild para después continuar con la [guía de resolución](https://www.kaggle.com/datacertlaboratoria/gu-a-de-resoluci-n-proyecto-3).

### Objetivos de aprendizaje

Al resolver este proyecto serás capaz de:
- **Pre-procesar datos en hojas de cálculo**: identificas datos duplicados, en blanco o fuera de su dominio (por ejemplo, valores negativos cuando no corresponde) con el fin de preparar tus datos para su posterior análisis.
- **Organizar datos en hojas de cálculo**: conoces los distintos tipos de datos que acepta una celda y eres capaz de dar formato a monedas, fechas, números para mostrar de mejor forma la información. Adicionalmente ocupas filtros para organizar los datos y puedes ordenar columnas de mayor a menor (o viceversa) según su tipo de dato.
- **Manipular datos en hojas de cálculo**: utilizas tablas dinámicas para calcular, resumir y analizar datos con el fin de ver comparaciones, patrones y tendencias en ellos. Además, logras conectar dos o más fuentes de datos utilizando la función BUSCAV (VLOOKUP).
- **Visualizar datos en hojas de cálculo**: confeccionas gráficas de línea y barra para visualizar información con el fin de resumir hallazgos, encontrar patrones o comparar distintas series de datos.
- **Realizar un análisis por cohorte**: organizas la información para formar cohortes de clientes según su fecha de ingreso al producto/servicio. Realizas cálculos y formateas la información para encontrar mapas de calor. Identificas puntos de fuga.
- **Segmentar clientes utilizando el modelo RFM**: comprendes la regla de pareto, y la utilizas para identificar clientes claves de negocio con el fin de enfocar los esfuerzos ahí y obtener el mayor retorno (80/20). 

### Recursos recomendados

Además del [curso de Skillsbuild de Google Spreadsheet](https://skills.yourlearning.ibm.com/activity/UDEMY-2795000?planId=PLAN-F2DC3A8C2759§ionId=SECTION-A) que ya deberías haber hecho, te recomendamos:

- La [sección 1 del curso de estadística para no estadísticos](https://ibmcsr.udemy.com/course/estadistica-para-no-estadisticos/learn/lecture/27411570#search) que está en [el learning path de Skillsbuild](https://skills.yourlearning.ibm.com/activity/PLAN-F2DC3A8C2759).
- Este [artículo](https://www.zendesk.com.mx/blog/segmentacion-de-clientes/) para que aprendas sobre segmentación.
- Este [podcast](https://www.youtube.com/watch?v=CM0L1rftBfA) que profundiza en la metodología de segmentación RFM.
- Este [video](https://www.youtube.com/watch?v=n3xpKz0SYlQ) que explica el concepto de pareto y como aplicarlo a los negocios.
- Este [video](https://www.youtube.com/watch?v=HjE4C4p7U2w) de youtube que muestra como hacer reportes ordenados y con diseños modernos.
- Este [artículo](https://medium.com/@miramontesayelen/claves-del-dise%C3%B1o-ux-para-visualizaci%C3%B3n-de-datos-8faeca47a709) que habla sobre buenas prácticas al momento de crear reportes con datos.",.csv
Proyectos Análisis Datos en R y Python,1,proyectos-anlisis-datos-en-r-y-python,dataset_banco.csv,DbCL-1.0,"En este Database se irán colgando aquellos proyectos que realice en Análisis de Datos, tanto en Python como en R, así como tutoriales de interés para tener como referencia.",.csv
Psychosocial Dimensions of Student Life,1,psychosocial-dimensions-of-student-life,CSE_student_performances.csv,MIT,"This dataset comprises survey results from 100 computer science students, aiming to identify correlations between their depression levels, class performance, and ADHD patterns through data analysis.

Here's a brief description of each column:

**Age:**

Represents the age of the individuals in the dataset, providing insight into the age distribution of the study.


**Gender:**

Indicates the gender of each individual, allowing for the exploration of gender-related patterns and trends within the dataset.


**Academic Performance:**

Reflects the academic achievements of individuals.


**Taking Note In Class:**

Describes about individuals take notes during class, providing insights into study habits and engagement during lectures.

**Depression Status:**

Indicates the presence or absence of depressive symptoms, contributing valuable information about the mental health of individuals in the dataset.


**Face Challenges To Complete Academic Task:**

Explores whether individuals encounter challenges in completing academic tasks.


**Like Presentation:**

Reflects individuals' preferences for presentations, offering insights into their learning style and engagement with visual or oral communication. This aim also measure is they extrovert or introvert.


**Sleep Per Day Hours:**

Represents the average hours of sleep individuals get per day, providing information on sleep patterns and potential correlations with academic performance.


**Number Of Friend:**

Quantifies the social aspect by indicating the number of friends each individual has, contributing to the understanding of social dynamics within the dataset.

**Like New Things:**

Explores individuals' receptiveness to new experiences or concepts, offering insights into their adaptability and openness to innovation.


This dataset is designed to facilitate a comprehensive analysis of the interplay between demographic factors, academic performance, mental health, study habits, and social dynamics among individuals in the specified context.

",.csv
Psycological Effects of COVID,1,psycological-effects-of-covid,psyco.csv,other,"The dataset was collected with the help of Google Forms. The data contains answers to various questions provided by people. Most of the questions in the form were provided as multiple choice to avoid any case sensitive issues. 
A version of this dataset was used to publish a research paper. 
This is a processed dataset with the same structural aspects of the raw data. Please note that the raw data cannot be shared as it is PII. 

## Columns
The columns present are as follows:
Please note that all the custom columns can be ignored.

- **age** Age group of the person
- **gender**	Gender of the person
- **occupation** Occupation/sector where the person works
- **line_of_work**	The line of work performed by the person
- **time_bp**	The time spent on work before pandemic
- **time_dp**	The time spent on work during pandemic
- **travel_time** The travel time spent 
- **easeof_online**	Rating of work going online
- **home_env** Liking of home environment
- **prod_inc**	Rating Productivity Increase
- **sleep_bal** The rating of sleep cycle
- **new_skill**	Whether any new skill was learnt
- **fam_connect** Rating how well the person connected with his family
- **relaxed**	Rating of how relaxed the person is feeling
- **self_time**	Rating how much self time was procured
- **like_hw** Liking of working from Home
- **dislike_hw** Disliking Working from Home
- **prefer** Preference of the person to work from home/office
- **certaindays_hw** Liking whether certain days of working from home is needed
- **X** Custom Column 
- **time_bp.1**	Custom Column 
- **travel_new** Custom Column 
- **net_diff**	Custom Column 

Please not that if some column looks like binary. This was an encoding issue and it is in binary range. So higher the value is higher value in real. ",.csv
Public Company ESG Ratings Dataset,1,public-company-esg-ratings-dataset,data.csv,CC-BY-NC-SA-4.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F8734253%2F84d76e9b100f0eaee4b913d74c0aab45%2FScreenshot%202024-03-10%20at%203.46.10PM.png?generation=1710099996246003&alt=media)
*Caption: Visualization of Microsoft (MSFT) ESG Data*

## Dataset Overview
This dataset contains **ESG (Environmental, Social, and Governance)** scores and ratings for a large number of publicly traded companies across various industries. The data is provided at a company level, with each row representing one company.

The key fields include:
- Basic company information: ticker symbol, company name, currency, exchange, industry, logo URL, website URL
- Environmental scores and rating: environment_score, environment_grade, environment_level
- Social scores and rating: social_score, social_grade, social_level
- Governance scores and rating: governance_score, governance_grade, governance_level
- Overall ESG scores and rating: total_score, total_grade, total_level
- Last processing date of the ESG data
- CIK identifier

The environmental, social, governance and total scores are numeric values, while the corresponding grades are letter ratings (like AAA, BB etc.) and levels are categorical (like High, Medium, Low).

This dataset can be analyzed to understand the distribution of ESG scores and ratings across different companies, sectors and industries. It could be combined with financial datasets to explore relationships between ESG performance and key metrics like profitability, valuation, and stock returns. The data can provide valuable insights for investors, asset managers, financial analysts, corporate strategists, policymakers and sustainability researchers.

By sharing this data publicly, the provider likely aims to bring greater transparency to corporate ESG practices, enable better integration of ESG considerations into investment decisions, and create incentives for companies to improve their ESG performance over time. Wide availability of robust ESG data is critical to driving progress on major societal goals like combating climate change and enhancing social equity.

See ESG Compare (http://esgcompare.org) for an interactive demo!",.csv
Pulsar Classification For Class Prediction,1,pulsar-classification-for-class-prediction,Pulsar.csv,DbCL-1.0,"## Pulsar Classification For Class Prediction
17898 entries

Data can be useful for prediction models of classification.

COLUMNS:
Based on Integrated Profile of Observation

- Mean_Integrated: Mean of Observations

- SD: Standard deviation of Observations

- EK: Excess kurtosis of Observations

- Skewness: In probability theory and statistics, skewness is a measure of the asymmetry of the probability distribution of a real-valued random variable about its mean. Skewness of Observations.

- Mean _ DMSNR _ Curve: Mean of DM SNR CURVE of Observations

- SD _ DMSNR _ Curve: Standard deviation of DM SNR CURVE of Observations

- EK _ DMSNR _ Curve: Excess kurtosis of DM SNR CURVE of Observations

- Skewness _ DMSNR _ Curve: Skewness of DM SNR CURVE of Observations

- Class: Class 0 - 1


WHAT IS DM SNR CURVE:

Radio waves emitted from pulsars reach earth after traveling long distances in space which is filled with free electrons. The important point is that pulsars emit a wide range of frequencies, and the amount by which the electrons slow down the wave depends on the frequency. Waves with higher frequency are sowed down less as compared to waves with higher frequency. It means dispersion.

TARGET:

Class
0 -- It is not
1 -- It is",.csv
Pulsar Classification For Class Prediction Cleaned,1,pulsar-classification-for-class-prediction-cleaned,Pulsar_cleaned.csv,other,"This dataset is a cleaned version of [Pulsar Classification For Class Prediction Dataset](https://www.kaggle.com/datasets/brsdincer/pulsar-classification-for-class-prediction). Different techniques like outlier removal, z-score normalization, and feature selection have been used for creating this dataset.
It contains 8 columns:
1. Mean_Integrated: Mean of Observations
2. EK: Excess kurtosis of Observations
3. Skewness: It's a measure of the asymmetry of the probability distribution of a real-valued random variable about its mean. It refers to the skewness of Observations
4. Mean _ DMSNR _ Curve: Mean of DM SNR CURVE of Observation
5. SD _ DMSNR _ Curve: Standard deviation of DM SNR CURVE of Observations
6. EK _ DMSNR _ Curve: Excess kurtosis of DM SNR CURVE of Observations
7. Skewness _ DMSNR _ Curve: Skewness of DM SNR CURVE of Observations
8. Class: Binary (either 0 or 1)


Explanation:
Radio waves emitted from pulsars reach Earth after traveling long distances in space that is filled with free electrons. The important point is that pulsars emit a wide range of frequencies and the amount which which the electrons slow down the wave depends on the frequency. Waves with higher frequency are sowed down less as compared with waves with higher frequency. It means dispersion.",.csv
"Python - Past, Present, Future",1,python-past-present-future,Python_Future.csv,CC0-1.0,"This dataset shows python statistics over years namely, from 1991 to 2024. It shows the year, the version in use during that year, and the approximate amount of users in that year. There is also another dataset that shows the future amount of users python might have. Here are the column descriptions:

```Year``` - The Year 

```Version``` - The version in use or development during that year

```Version Rel_Date``` - The date on which that version came out

```Added Features``` - Shows the features add to that version

```Num Users``` - The approximate amount of users in that year.

The ```Python_Future``` data set might not be very accurate because of very approximate amounts of users in the training set. I hope you will like this dataset. God bless you.",.csv
Python Code Instruction ,1,python-code-instruction-dataset,train.csv,CC0-1.0,"_____
# Python Code Instruction 
### Training Data with Instruction, Input, Output, and Prompt Columns
By Tarun Bisht (From Huggingface) [[source]](https://huggingface.co/datasets/iamtarun/python_code_instructions_18k_alpaca)
_____

### About this dataset
&gt; The python_code_instructions_18k_alpaca dataset is a comprehensive training dataset specifically curated for researchers and developers involved in the analysis and comprehension of Python code instructions. It contains a vast collection of Python code snippets along with their corresponding instruction, input, output, and prompt information. By utilizing this dataset, users can gain valuable insights into various Python programming concepts and techniques.
&gt; 
&gt; The dataset is organized into columns to facilitate easy access to the required information. The instruction column holds the specific task or instruction that the Python code snippet is designed to perform. This allows users to understand the purpose or requirement of each code snippet at a glance.
&gt; 
&gt; The input column contains all necessary input data or parameters that are required for executing the Python code snippet accurately. These inputs provide context and enable users to comprehend how different variables or values impact the overall functioning of each code snippet.
&gt; 
&gt; Likewise, the output column presents expected results or outcomes that should be produced when executing each Python code snippet with its specified input values. This allows for validation and verification purposes, ensuring that each code snippet performs as intended.
&gt; 
&gt; In addition to instruction, input, and output details, this dataset also includes prompts. The prompt column provides additional context or information intended to assist users in better understanding the purpose or requirements of each particular Python code snippet.
&gt; 
&gt; By leveraging this comprehensive python_code_instructions_18k_alpaca training dataset, researchers and developers can delve into numerous real-world examples of Python programming challenges - helping them enhance their coding skills while gaining invaluable knowledge about effective implementation techniques across various domains


### Research Ideas
&gt; - Code Instruction Analysis: This dataset can be used to analyze different types of Python code instructions and identify patterns or common practices. Researchers or developers can use this dataset to gain insights into effective ways of writing code instructions.
&gt; - Code Output Prediction: With the given input and instruction, this dataset can be used to train models for predicting the expected output of a Python code snippet. This can be useful in automating the testing process or verifying the correctness of the code.
&gt; - Prompt Generation: Developers often struggle with providing clear and concise prompts for their code snippets. This dataset can serve as a resource for generating prompts by analyzing existing examples and extracting key information or requirements from them

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://huggingface.co/datasets/iamtarun/python_code_instructions_18k_alpaca)
&gt; 
&gt;


### License
&gt; 
&gt; 
&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: train.csv**
| Column name     | Description                                                                                                       |
|:----------------|:------------------------------------------------------------------------------------------------------------------|
| **instruction** | Specific tasks or instructions assigned to each Python code snippet. (Text)                                       |
| **input**       | The input data or parameters required for executing the code instruction. (Text)                                  |
| **output**      | The expected result or output that should be produced when executing the code instruction. (Text)                 |
| **prompt**      | Additional information or context to help understand the purpose or requirements of each code instruction. (Text) |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [Tarun Bisht (From Huggingface)](https://huggingface.co/datasets/iamtarun/python_code_instructions_18k_alpaca).

",.csv
Python project on Weather Dataset,1,python-project-on-weather-dataset,Weather Data.csv,DbCL-1.0,"Python Project for Data Analytics(Beginners)
(A part of Big Data Analysis)
The Weather Dataset

Description:
The Weather Dataset is a time-series dataset with per-hour information about the weather condition at a particular location. It records Temperature, dew Point temperature, Relative humidity, Wind speed, Visibility, Pressure and conditions.
This Dataset available as a csv file. We are going to analyze this dataset using Pandas dataPython Project for Data Analytics (Beginners)

Workflow:
* Import library
* Analyzing the data
* Solve few questions on Data Analytics",.csv
Qatar Airways Reviews,1,qatar-airways-reviews,qatar_airways_reviews.csv,other,"The ""Qatar Airways Review Dataset"" comprises a compilation of feedback, evaluations, and ratings pertaining to Qatar Airways, a prominent airline headquartered in Doha, Qatar. This dataset encompasses diverse forms of information, including:

1. **Customer Reviews**: Textual assessments submitted by passengers following their experiences with Qatar Airways. These reviews encompass various facets such as flight experiences, customer service quality, in-flight amenities, seating comfort, and overall satisfaction levels.

2. **Ratings**: Numerical evaluations or scores assigned by passengers across different dimensions of their flight encounters, encompassing overall satisfaction levels, food quality, cleanliness standards, punctuality, and other pertinent criteria.

3. **Demographic Information**: Data pertaining to reviewers, including demographic attributes such as age, gender, nationality, frequent flyer status, and travel preferences.

4. **Flight Details**: Specifics regarding the flights or routes undertaken by reviewers, encompassing departure and arrival destinations, flight durations, aircraft types, and travel classes (economy, business, first class, etc.).

5. **Sentiment Analysis**: Analysis of the expressed sentiment within reviews, categorized into positive, negative, or neutral sentiments.

The Qatar Airways Review Dataset serves various purposes, including:

- Facilitating analysis of customer feedback to identify areas necessitating enhancement and to optimize the overall passenger experience.
- Conducting sentiment analysis to gauge public sentiment and perceptions towards Qatar Airways.
- Comparing Qatar Airways' performance against that of other airlines within the industry.
- Training machine learning models for tasks such as sentiment classification, opinion mining, or summarization of customer reviews.

This dataset is valuable for researchers, data analysts, airline industry professionals, and machine learning enthusiasts seeking to conduct analyses, derive insights, and develop predictive models relating to customer satisfaction and airline performance.",.csv
Question-Answer Dataset,1,questionanswer-dataset,text_data_toc.csv,CC-BY-SA-3.0,"### Context: 

Being able to automatically answer questions accurately remains a difficult problem in natural language processing. This dataset has everything you need to try your own hand at this task. Can you correctly generate the answer to questions given the Wikipedia article text the question was originally generated from?

### Content: 

There are three question files, one for each year of students: S08, S09, and S10, as well as 690,000 words worth of cleaned text from Wikipedia that was used to generate the questions.

The ""question_answer_pairs.txt"" files contain both the questions and answers. The columns in this file are as follows:                  

* **ArticleTitle** is the name of the Wikipedia article from which questions and answers initially came.
* **Question** is the question.
* **Answer** is the answer.
* **DifficultyFromQuestioner** is the prescribed difficulty rating for the question as given to the question-writer. 
* **DifficultyFromAnswerer** is a difficulty rating assigned by the individual who evaluated and answered the question, which may differ from the difficulty in field 4.
* **ArticleFile** is the name of the file with the relevant article

Questions that were judged to be poor were discarded from this data set.

There are frequently multiple lines with the same question, which appear if those questions were answered by multiple individuals. 

### Acknowledgements: 

These data were collected by Noah Smith, Michael Heilman, Rebecca Hwa, Shay Cohen, Kevin Gimpel, and many students at Carnegie Mellon University and the University of Pittsburgh between 2008 and 2010. It is released here under CC BY_SA 3.0. Please cite this paper if you write any papers involving the use of the data above:

Smith, N. A., Heilman, M., & Hwa, R. (2008, September). Question generation as a competitive undergraduate course project. In Proceedings of the NSF Workshop on the Question Generation Shared Task and Evaluation Challenge.

### You may also like:

* [Question-Answer Jokes: Jokes of the question-answer form from Reddit's r/jokes](https://www.kaggle.com/jiriroz/qa-jokes)
* [Stanford Question Answering Dataset: New Reading Comprehension Dataset on 100,000+ Question-Answer Pairs](https://www.kaggle.com/stanfordu/stanford-question-answering-dataset)
* [Question Pairs Dataset: Can you identify duplicate questions?](https://www.kaggle.com/quora/question-pairs-dataset)",.csv
Question-Answer Jokes,1,qa-jokes,jokes.csv,other,"This dataset contains 38,269 jokes of the question-answer form, obtained from the [r/Jokes](https://www.reddit.com/r/Jokes/) subreddit. The dataset contains a csv file, where a row contains a question  (""Why did the chicken cross the road""), the corresponding answer (""To get to the other side"") and a unique ID.

The data comes from the end of 2016 all the way to 2008. The entries with a higher ID correspond to the ones submitted earlier.

An example of what one might do with the data is build a sequence-to-sequence model where the input is a question and the output is an answer. Then, given a question, the model should generate a funny answer. This is what I did as the final project for my fall 2016 machine learning class. The project page can be viewed [here](https://github.com/jiriroz/JokeGeneratorSeq2Seq/).

Disclaimer: The dataset contains jokes that some may find inappropriate.

# License

Released under reddit's [API terms](https://www.reddit.com/wiki/api-terms)",.csv
Quikr Cars Cleaned Dataset,1,quikr-cars-cleaned-dataset,Quikr Cars Cleaned Dataset.csv,Apache 2.0,"This dataset contains information about second-hand cars listed on Quikr, a popular online classified platform. The data was scrapped from quikr.com; however, it required significant cleaning due to heavy noise and inconsistencies. This dataset comprises details of approximately 815 cars available for sale.

 The dataset encompasses various features that are crucial for analyzing the second-hand car market, including:

1. **Name:** The make and model of the car.
2. **Company:** The manufacturer of the car.
3. **Year:** The manufacturing year of the car.
4. **Price:** The listed price of the car in Indian Rupees (INR).
5. **Kilometers Driven:** The total distance covered by the car in kilometers.
6. **Fuel Type:** The type of fuel used by the car (e.g., petrol, diesel).

This dataset is meticulously cleaned and organized to ensure reliability and usability for data analysis tasks. Missing values have been addressed, and outliers have been treated appropriately to enhance the dataset's quality. Moreover, the dataset includes categorized price ranges and detailed insights into the distribution of cars based on their manufacturing years and kilometers driven.",.csv
Quotes Dataset,1,quotes-dataset,Quotes Dataset.csv,Apache 2.0,"All the Quotes along with the Authors name have mix topics in count almost 725.
So this dataset can be used for next word prediction using LSTM and Tensorflow lib.
In this NLP task we can make the task of text generation to text classification.",.csv
RMIT Semester 1 2024 textbooks,1,rmit-semester-1-2024-textbooks,RMIT Semester 1 2024 textbooks - Sheet1.csv,Apache 2.0,"RMIT Semester 1 2024 textbooks data

* No commercial use, only for researching",.csv
ROCK_OR_MINE CLASSIFICATION,1,rock-or-mine-classification,ROCK_OR_MINE.csv,CC0-1.0,"There is war is going on between two countries submarine of the country is going under the water to another country and enemy country planted some mines in the oceans mine are nothing but explosive that explodes when some object comes in contact with it and there can be rocks in the ocean so submarine needs to predict whether it is crossing mine or rock our job is to make a system that can predict whether the object beneath the submarine is a mine or a rock so how this is done is submarine uses sonar signal that sends sound and receives switchbacks so this signal in the processed to detect whether the object is a mine or it's just a rock in the ocean to predict the rock and mine we use some types of algorithms like decision tree, KNN, Logistic Regression, Random Forest and SVM",.csv
RSNA Breast Cancer - helper data,1,rsna-breast-cancer-helper-data,train_path.csv,other,"### Data info

This is a small dataset constructed on the Kaggle competiton: https://www.kaggle.com/competitions/rsna-breast-cancer-detection

It contains the prepped `train` dataset, as well as some other helper files for the published notebook on the competition. :)

Use it as you may like ^^",.csv
RT-IoT2022(Real Time Internet Of Things),1,rt-iot2022real-time-internet-of-things,RT_IOT2022.csv,Attribution 4.0 International (CC BY 4.0),"- The RT-IoT2022, a proprietary dataset encompasses both normal and adversarial network behaviors, providing a general representation of real-world scenarios.
- Incorporating data from IoT devices such as ThingSpeak-LED, Wipro-Bulb, and MQTT-Temp, as well as simulated attack scenarios involving Brute-Force SSH attacks, DDoS attacks using Hping and Slowloris, and Nmap patterns, RT-IoT2022 offers a detailed perspective on the complex nature of network traffic. The bidirectional attributes of network traffic are meticulously captured using the Zeek network monitoring tool and the Flowmeter plugin.
- Infrastructure consists of two parts, namely IoT victim devices and IoT attacker devices, both connected through a router. We collect the network traffic through a router using Wireshark, which is an open-source monitoring tool for network traffic that helps extract traces and convert them into a PCAP file.
- The attacking infrastructure includes 50 machines, and the victim organization has 5 departments and includes 420 machines and 30 servers. The dataset includes the captures network traffic and system logs of each machine, along with 80 features extracted from the captured traffic.

- It includes 9 different attack scenarios: DOS_SYN_Hping,, ARP_poisioning, NMAP_UDP_SCAN, 
NMAP_XMAS_TREE_SCAN, NMAP_OS_DETECTION, NMAP_TCP_scan, DDOS_Slowloris, Metasploit_Brute_Force_SSH, NMAP_FIN_SCAN and 3 normal pattern MQTT, Thing_speak and Wipro_bulb_Dataset.

- Dataset is downloaded from site: https://archive.ics.uci.edu/dataset/942/rt-iot2022
- Paper with details of the dataset: https://cybersecurity.springeropen.com/articles/10.1186/s42400-023-00178-5#Tab4",.csv
Rain in Australia,1,weather-dataset-rattle-package,weatherAUS.csv,other,"### Context
Predict **next-day rain** by training classification models on the target variable **RainTomorrow**. 



### Content
This dataset contains about 10 years of daily weather observations from many locations across Australia.

**RainTomorrow is the target variable to predict. It means -- did it rain the next day, Yes or No?
This column is Yes if the rain for that day was 1mm or more.**

### Source & Acknowledgements 
Observations were drawn from numerous weather stations. The daily observations are available from http://www.bom.gov.au/climate/data. 
An example of latest weather observations in Canberra: http://www.bom.gov.au/climate/dwo/IDCJDW2801.latest.shtml

Definitions adapted from http://www.bom.gov.au/climate/dwo/IDCJDW0000.shtml
Data source: http://www.bom.gov.au/climate/dwo/ and http://www.bom.gov.au/climate/data.

Copyright Commonwealth of Australia 2010, Bureau of Meteorology.
",.csv
Rainfall of Iranian cities,1,average-monthly-precipitation-of-iranian-cities,Rainfall_Iran_19012022.csv,CC-BY-SA-4.0,"Datasets provide monthly precipitation data for 31 Iranian cities from 1901 to 2022. The data was obtained from the CRU-HRG dataset (https://crudata.uea.ac.uk/cru/data/hrg/) using specialized GIS workflows. The dataset consists of 1464 rows, with each row representing a month over 120 years, spanning from 1901 to 2022. Each column contains the average monthly rainfall for each city, measured in millimeters (mm).

This dataset serves as a valuable resource for researchers and decision-makers interested in understanding precipitation patterns in Iran. It can be used to analyze long-term precipitation trends, assess the impacts of climate change, and aid in natural resource management.

<p>
  <strong>Please note:</strong><br>
  <em>
    This dataset contains satellite-derived climate data from the website https://crudata.uea.ac.uk. Satellite data are measured using sensors that may be subject to error. Therefore, it is possible that these data may differ from ground-based observations, which are typically used to generate real-world data. This difference is generally greater in remote areas and regions with high cloud. 
  </em>
</p>",.csv
Raisin binary classification,1,raisin-binary-classification,Raisin_Dataset.csv,other,"Abstract: Images of the Kecimen and Besni raisin varieties were obtained with CVS. A total of 900 raisins were used, including 450 from both varieties, and 7 morphological features were extracted.

Data Set Information: Images of Kecimen and Besni raisin varieties grown in Turkey were obtained with CVS. A total of 900 raisin grains were used, including 450 pieces from both varieties. These images were subjected to various stages of pre-processing and 7 morphological features were extracted. These features have been classified using three different artificial intelligence techniques.
",.csv
Rampant Ravages,1,rampant-ravages,numberofdeathsbyriskfactor NEW.csv,CC0-1.0,"this graph was created in Power Bi and code R :

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F1f98feeb428e1494b8cd8725a8a146ba%2Fgraph1.jpg?generation=1711482131833793&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F260fa84ae4681b4bab133320bde254b6%2Fgraph3.png?generation=1711482144354809&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F884688063d2df72d41303b7873b6f2b5%2Fgraph2.jpg?generation=1711482156479618&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Ff4939941262478fddc62fff6151206c2%2Fgraph3.png?generation=1711482174542439&alt=media)


Lead poisoning, though often relegated to the shadows of public awareness, exacts a staggering toll, contributing approximately 1% to the colossal burden of global disease. Yet, amidst its ominous prevalence, this perilous issue remains shrouded in relative obscurity.

Individually, the ramifications are profound. The insidious infiltration of lead into the environment imperils the delicate trajectory of childhood development, impeding neural maturation and precipitating a cascade of cognitive impairments. With each exposure, the potential for irreversible harm looms large – manifesting as diminished IQ, compromised cognitive function, and a disconcerting surge in antisocial behavior.

However, amidst the pervasive gloom, glimmers of hope emerge. Across the globe, concerted efforts are underway, heralding progress in the relentless crusade against lead pollution. Through collaborative initiatives and unwavering resolve, nations are forging a path towards redemption, striving to mitigate the pervasive scourge of lead toxicity.

Within these pages lie a compendium of insights, data-driven revelations, and illuminating visualizations, offering a panoramic view of the labyrinthine complexities of lead pollution. Acknowledgments are due to Lucia Coulter and Clare Donaldson of the Lead Exposure Elimination Project, whose invaluable contributions have fortified this endeavor. Gratitude is also extended to Max Roser for his astute feedback and invaluable counsel, guiding this work towards its fruition.

As we navigate the treacherous terrain of lead pollution, let us seize this collective imperative with unwavering determination, for in the crucible of concerted action lies the promise of a future unburdened by the shadow of lead's silent terror.",.csv
Random_Exp_Data,1,random-exp-data,Random_Exp_Data.csv,Community Data License Agreement - Sharing - Version 1.0,"Data set for my random experiment. You can see the experiment notebook in the code section. The dataset was generated using sklearn library.

**Note :** The image for the dataset is generated by AI.",.csv
Ranking sports by skill requirement,1,ranking-sports-by-skill-requirement,toughestsport.csv,CC0-1.0,"Ever wondered which sports are the toughest and which are a walk in the park? This dataset has the answers, straight from a panel of experts at [ESPN](https://www.espn.com/watch/?country=us&redirected=true) that includes sports scientists from the United States Olympic Committee, muscle and movement science academicians, a star two-sport athlete, and seasoned sports journalists.

Upon meticulously analyzing 60 sports across 10 categories of athletic skills, such as endurance, strength, power, speed, agility, flexibility, nerve, durability, hand-eye coordination, and analytic aptitude, each expert rated the demands each sport places on these skills on a scale of 1 to 10. By averaging their ratings, we've calculated a degree-of-difficulty number for each sport, ranging from 1 to 60, providing a comprehensive view of the relative difficulty of each sport.

For instance, the experts ranked boxing as the most demanding sport and fishing as the least demanding. Want to know where your favorite sport ranks? Explore this dataset to find out!
",.csv
Rap Lyrics Dataset,1,rap-lyrics-for-nlp,lyrics_raw.csv,CC0-1.0,"This dataset was compiled by me for a personal project. It contains lyrics from 11 different artists including: Drake, J. Cole, Kendrick Lamar, Eminem, Nas, Skepta, Rapsody, Nicki Minaj, Dave, 2Pac, and Future.

#### All data was compiled using Spotify's API and Genius' API.

## **FEATURES**
- ``track_name``: the name of each track
- ``artist``: the name of each artist
- ``raw_lyrics``: raw text of lyrics scraped from Genius website
- ``artist_verses``: text extracted from raw_lyrics — verses performed by each artist only

#### NOTE: Some entires in ``raw_lyrics`` may contain a different formatting structure to others, so text consistency will vary.
<br>
<br>
#### What can this dataset be used for?
- Text analysis
- Text pre-processing
- Text EDA
- Text classification",.csv
Rating of IT Companies Islamabad(Dated:05/05/24),1,rating-of-it-companies-islamabaddated050524,Rating of IT Companies In Islamabad.csv,Apache 2.0,"Title: Rating of IT Companies in Islamabad (Google Stats - Dated: 05/05/2024)

Description:

Discover the latest insights into the ratings of IT companies in Islamabad as of May 5th, 2024, sourced directly from Google Stats. This comprehensive overview provides a snapshot of the performance and reputation of various IT firms operating in the capital city of Pakistan's technology sector.

Key highlights from the data include:

1. **Rating Distribution**: Gain insights into the distribution of ratings among IT companies in Islamabad. From top-performing companies with stellar ratings to those striving to enhance their reputation, the spectrum of ratings offers a comprehensive view of the industry landscape.

2. **Top-Rated Companies**: Identify the leading IT companies in Islamabad based on their ratings. Discover which firms have earned the highest acclaim from customers and stakeholders, indicating superior service quality and customer satisfaction.

Stay informed and empowered with the latest ratings of IT companies in Islamabad, providing valuable insights into the evolving landscape of the technology industry in the capital city.",.csv
Raw Caesarian Section Dataset for Classification,1,caesarian-section-dataset-for-classification,Ceasarian Section Dataset for Classification.csv,MIT,"Ceasarian Section Dataset for Classification.
A caesarean section is a surgical procedure in which a baby is born through a cut made in the mother's abdominal wall and uterus. A baby will need to be born by caesarean section if there are serious problems that prevent the baby being born by a normal vaginal birth.",.csv
Real Breast Cancer Data,1,breastcancerdataset,BRCA.csv,CC0-1.0,"### Content

The period is over short time frame but it useful for hypothesis testing and statistical analysis. There are &gt;400 rows so is a great beginners dataset. 

### Background

This dataset consists of a group of breast cancer patients, who had surgery to remove their tumour. The dataset consists of the following variables:

**Patient_ID:** unique identifier id of a patient

**Age:** age at diagnosis (Years)

**Gender:** Male/Female

**Protein1, Protein2, Protein3, Protein4:** expression levels (undefined units)

**Tumour_Stage:** I, II, III

**Histology:** Infiltrating Ductal Carcinoma, Infiltrating Lobular Carcinoma, Mucinous Carcinoma

**ER status:** Positive/Negative

**PR status:** Positive/Negative

**HER2 status:** Positive/Negative

**Surgery_type:** Lumpectomy, Simple Mastectomy, Modified Radical Mastectomy, Other

**Date_of_Surgery:** Date on which surgery was performed (in DD-MON-YY)

**Date_of_Last_Visit:** Date of last visit (in DD-MON-YY) [can be null, in case the patient didn’t visited again after the surgery]

**Patient_Status:** Alive/Dead [can be null, in case the patient didn’t visited again after the surgery and there is no information available whether the patient is alive or dead].
",.csv
Real Estate Data Chicago 2024,1,real-estate-data-chicago-2024,real_estate_data_chicago.csv,ODC Attribution License (ODC-By),"
### Dataset Overview
This dataset comprises detailed real estate listings scraped from Realtor.com, providing a snapshot of various property types across Chicago. It includes 2,000 entries with information on property characteristics such as type, size, age, price, and features. This dataset was ethically collected using an API provided by Apify, ensuring all data scraping adhered to legal and ethical standards.

### Data Science Applications
This dataset is ideal for a variety of data science applications, including but not limited to:
- **Predictive Modeling**: Forecast property prices based on various features like location, size, and age.
- **Market Analysis**: Understand trends in real estate, including the types of properties being sold, pricing trends, and the influence of property features on market value.
- **Natural Language Processing**: Analyze the textual descriptions provided for each listing to extract additional features or perform sentiment analysis.
- **Anomaly Detection**: Identify unusual listings or potential outliers in the data, which could indicate errors in data collection or unique investment opportunities.

### Column Descriptors
1. **type**: The type of property (e.g., single-family home, condo).
2. **text**: A textual description of the property.
3. **year_built**: The year in which the property was constructed.
4. **beds**: The number of bedrooms.
5. **baths**: Total number of bathrooms (including full and half).
6. **baths_full**: Number of full bathrooms.
7. **baths_half**: Number of half bathrooms.
8. **garage**: Garage capacity (number of cars).
9. **lot_sqft**: Size of the lot in square feet.
10. **sqft**: Living area size in square feet.
11. **stories**: Number of stories/floors in the property.
12. **lastSoldPrice**: The price at which the property was last sold.
13. **soldOn**: The date on which the property was last sold.
14. **listPrice**: The listing price of the property at the time of data collection.
15. **status**: The current status of the listing (e.g., for sale, sold).

### Ethically Mined Data
This dataset was responsibly and ethically mined, adhering to all legal standards of data collection. The use of Apify's API ensures that the data collection process respects privacy and the platform's terms of service.

### Acknowledgements
We thank Realtor.com for maintaining a comprehensive and accessible database, and Apify for providing the tools necessary for ethical data scraping. Their contributions have been invaluable in the creation of this dataset.
Credits to Dall E3 for thumbnail image.

### Usage Policy
This dataset is provided for non-commercial and educational purposes only. Users are encouraged to use this data to enhance learning, contribute to academic or personal projects, and develop skills in data science and real estate market analysis.

",.csv
Real Estate Data UAE,1,real-estate-data-uae,uae_properties.csv,ODC Attribution License (ODC-By),"**Title:** Real Estate Data UAE  
**Subtitle:** UAE Studio Listings 2024

**Description:**


**Dataset Overview:**
This dataset offers a comprehensive snapshot of studio apartment listings available for sale across the United Arab Emirates as of 2024. It encompasses a variety of properties, presenting a unique opportunity for market analysis, trend identification, and investment evaluation within the UAE real estate sector.
The collection meticulously compiles data from various listings, presenting attributes such as unique identifiers, property titles, display addresses, the number of bathrooms, bedrooms, listing addition dates, regulatory details, property types, and pricing. This dataset is particularly tailored for those interested in the dynamics of the UAE's studio apartment market.

**Data Science Applications:**
Despite its compact size, this dataset is ripe for various data science explorations. Analysts can leverage it for predictive modeling of property prices, trend analysis over time, geographical market segmentation, and feature importance studies to understand price determinants. It's a valuable resource for academic research, market analysis, and portfolio management, providing insights into the burgeoning real estate market of the UAE.

**Column Descriptors:**
- `id`: Unique property listing identifier.
- `title`: Descriptive title of the property listing.
- `displayAddress`: Location information including community and city.
- `bathrooms`: Count of bathrooms in the property.
- `bedrooms`: Count of bedrooms in the property, noting the studio nature.
- `addedOn`: Timestamp marking the listing's addition to the dataset.
- `type`: Denotes the transaction nature, focused here on sales.
- `rera`: Real Estate Regulatory Agency number for regulatory compliance.
- `propertyType`: Categorized as 'apartment' for all entries.
- `price`: Listed price of the property.

**Ethically Mined Data:**
This dataset is curated with a strong commitment to ethical data practices. Sensitive information, such as agent contacts, has been diligently excluded to respect privacy and confidentiality. The compilation process adhered to fair use principles, ensuring data integrity and compliance with legal standards.

**Acknowledgements:**
Special appreciation is extended to Property Finder and other platforms that serve as primary sources for real estate listings. Their dedication to maintaining up-to-date and accessible property information has been instrumental in the creation of this dataset.

This dataset is intended for educational and informational purposes, aiming to contribute to the broader understanding of the UAE real estate landscape. It encourages responsible use and further exploration within the data science community.",.csv
Real Estate Dataset California,1,real-estate-dataset-california,ca_real_estate.csv,ODC Attribution License (ODC-By),"

#### Dataset Overview
This dataset provides a comprehensive look at real estate listings across various cities in California, collected from Zillow  ethically. The data represents a snapshot of the market, showcasing properties for sale, including condos and houses. It serves as a valuable resource for understanding market trends, regional demand, and pricing distributions across the Golden State.

#### Data Science Applications
The California Real Estate Listings Dataset is ideal for various data science projects and analyses, particularly in the realms of market analysis, trend forecasting, and regional economic studies. The data can serve as a foundation for predictive modeling, clustering for market segmentation, and comparative studies between different locales. **Note: This data is intended for educational purposes only.**

#### Column Descriptors
- **addressCity**: The city where the property is located.
- **addressState**: The state for the property, which is CA for all entries.
- **price**: The listed price of the property.
- **statusType**: Indicates the listing status, consistently ""FOR_SALE"" across the dataset.
- **statusText**: Describes the type of property listed, such as ""Condo for sale"" or ""House for sale"".

#### Ethically Mined Data
This dataset was ethically mined, ensuring that sensitive information, including exact addresses and broker names, was omitted to respect privacy. This consideration helps maintain ethical standards while providing valuable insights.

#### Acknowledgements
We extend our gratitude to Zillow which is the source of the data and which made this dataset possible. We also thank Florian Schmidinger for the image of a California property, which can be viewed [here](https://unsplash.com/photos/white-and-brown-concrete-building-b_79nOqf95I), enhancing our dataset's presentation.
",.csv
Real Estate Property Transactions Dataset,1,real-estate-property-transactions-dataset,V3.csv,CC0-1.0,"**Description**:

- This dataset contains information about real estate property transactions.
- Each row represents a single property transaction.
- The dataset includes various attributes such as transaction dates, property locations, estimated and sale prices, property characteristics (e.g., type, residential status, number of rooms and bathrooms, carpet area), and property tax rates.
- The dataset provides insights into the real estate market, including trends in property prices, property types, and tax rates across different localities and years.
- It can be used for various analytical purposes such as market analysis, predictive modeling, and decision-making in the real estate industry.
- Researchers, analysts, and stakeholders in the real estate sector can utilize this dataset to understand market dynamics, assess property values, and make informed investment decisions.

**Features**:

**Date**: The date when the property transaction occurred.
**Year**: The year of the property transaction.
**Locality**: The locality or area where the property is located.
**Estimated Value**: The estimated value of the property.
**Sale Price**: The actual sale price of the property.
**Property**: The type of property (e.g., Single Family).
**Residential**: Indicates whether the property is residential or not.
**Num_rooms**: The number of rooms in the property.
**Num_bathrooms**: The number of bathrooms in the property.
**Carpet Area**: The carpet area of the property.
**Property Tax Rate**: The property tax rate applicable to the property.
**Face**: The facing direction of the property (e.g., North, South, East).",.csv
Real Estate Sales 2001-2021 ,1,real-estate-sales-2001-2021-gl,Real_Estate_Sales_2001-2021_GL.csv,CC0-1.0,"```
The Office of Policy and Management maintains a listing of all real estate sales with a sales price of $2,000 or greater that occur between October 1 and September 30 of each year. For each sale record, the file includes: town, property address, date of sale, property type (residential, apartment, commercial, industrial or vacant land), sales price, and property assessment.
```",.csv
Real Madrid Currently Schedule In 2023/2024 Season,1,real-madrid-currently-schedule,Real_Madrid_Schedule_Final.csv,Apache 2.0,"# Information about all matches of Real Madrid this season (2023/2024) is included.

**Thanks to this data, you can create any bar chart, line chart or pie chart you want and analyze everything from Real Madrid's winning rate to how many spectators came to which matches.**

**Match dates are placed in different columns as month, day, year and time.**

**Information about whether the matches are league or European matches is included in the data set.**

**The formations of the match and information on which player was on the field as the captain of Real Madrid in that match are also available in the data set.**

## Hala Madrid !🤍💙",.csv
Real World Smartphone's Dataset,1,real-world-smartphones-dataset,smartphones.csv,CC0-1.0,"This dataset provides a comprehensive collection of information about all the latest smartphones available in the market as of the current time. 

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F13571604%2Fb608498b1cf7f70b9a22952566197db6%2FScreenshot%202023-08-02%20003740.png?generation=1690961033930490&alt=media)

The dataset was created by web scraping reputable online sources to gather accurate and up-to-date information about various smartphone models, their specifications, features, and pricing.",.csv
Real-estate Kolkata,1,real-estate-kolkata,real_estate_properties.csv,CC0-1.0,"Introducing an extensive dataset focused on the real estate market in Kolkata, this collection provides valuable information about property prices, area sizes, and other essential details. Meticulously curated and compiled, this dataset offers a comprehensive view of the Kolkata real estate landscape.",.csv
Recipe Popularity Prediction,1,recipe-popularity-prediction,recipe_popularity_prediction.csv,Apache 2.0,"### Context
The Recipe Popularity Prediction Dataset aims to facilitate the analysis and prediction of the popularity of recipes based on various factors. These factors include the number of ingredients, cooking time, and difficulty level of recipes. The dataset provides an opportunity to explore the relationship between these features and the popularity of recipes as measured by the number of views they receive on a cooking website.

### Content
The dataset contains information on a sample of recipes, including the number of ingredients required, the cooking time in minutes, the difficulty level categorized as 'Easy', 'Medium', or 'Hard', and the popularity of each recipe measured by the number of views it receives on a cooking website.

### Dataset Structure:
This dataset (`recipe_popularity_dataset.csv`) consists of the following columns:

| Column Name         | Description                                            |
| ------------------- | ------------------------------------------------------ |
| `num_ingredients`    | The number of ingredients used in the recipe.         |
| `cooking_time_minutes`| The cooking time in minutes required to prepare the recipe. |
| `difficulty_level`   | The difficulty level of the recipe categorized as 'Easy', 'Medium', or 'Hard'. |
| `popularity_views`   | The popularity of the recipe measured by the number of views it receives on a cooking website. |

### Acknowledgment
© Image credit: [Freepik](https://img.freepik.com/free-photo/top-view-tasty-cooked-potatoes-delicious-dish-with-greens-seasonings-dark-surface-dinner-cooking-meal-potato-dish_140725-102123.jpg)",.csv
Recorded Crime Data at the Police Force Area Level,1,recorded-crime-data-at-police-force-area-level,rec-crime-pfa.csv,other,"### Context

Recorded crime for the Police Force Areas of England and Wales.
The data are rolling 12-month totals, with points at the end of each financial year between year ending March 2003 to March 2007 and at the end of each quarter from June 2007.


### Content

The data are a single `.csv` file with comma-separated data.
It has the following attributes:

- **12 months ending**: the end of the financial year.
- **PFA**: the Police Force Area.
- **Region**: the region that the criminal offence took place.
- **Offence**: the name of the criminal offence.
- **Rolling year total number of offences**: the number of occurrences of a given offence in the last year.


### Acknowledgements

This data is from the [Office for National Statistics](https://www.ons.gov.uk/) and was downloaded [from here](https://www.ons.gov.uk/peoplepopulationandcommunity/crimeandjustice/datasets/recordedcrimedataatpoliceforcearealevel) on 21 June 2019.

The dataset's release date was 25 April 2019.

The dataset is licensed under the [Open Government Licence v3.0](http://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/).
",.csv
Red Wine Dataset,1,red-wine-dataset,wineQualityReds.csv,DbCL-1.0,"Citation Request:
  This dataset is public available for research. The details are described in [Cortez et al., 2009]. 
  Please include this citation if you plan to use this database:

  P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. 
  Modeling wine preferences by data mining from physicochemical properties.
  In Decision Support Systems, Elsevier, 47(4):547-553. ISSN: 0167-9236.

  Available at: [@Elsevier] http://dx.doi.org/10.1016/j.dss.2009.05.016
                [Pre-press (pdf)] http://www3.dsi.uminho.pt/pcortez/winequality09.pdf
                [bib] http://www3.dsi.uminho.pt/pcortez/dss09.bib

1. Title: Wine Quality 

2. Sources
   Created by: Paulo Cortez (Univ. Minho), Antonio Cerdeira, Fernando Almeida, Telmo Matos and Jose Reis (CVRVV) @ 2009
   
3. Past Usage:

  P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. 
  Modeling wine preferences by data mining from physicochemical properties.
  In Decision Support Systems, Elsevier, 47(4):547-553. ISSN: 0167-9236.

  In the above reference, two datasets were created, using red and white wine samples.
  The inputs include objective tests (e.g. PH values) and the output is based on sensory data
  (median of at least 3 evaluations made by wine experts). Each expert graded the wine quality 
  between 0 (very bad) and 10 (very excellent). Several data mining methods were applied to model
  these datasets under a regression approach. The support vector machine model achieved the
  best results. Several metrics were computed: MAD, confusion matrix for a fixed error tolerance (T),
  etc. Also, we plot the relative importances of the input variables (as measured by a sensitivity
  analysis procedure).
 
4. Relevant Information:

   The two datasets are related to red and white variants of the Portuguese ""Vinho Verde"" wine.
   For more details, consult: http://www.vinhoverde.pt/en/ or the reference [Cortez et al., 2009].
   Due to privacy and logistic issues, only physicochemical (inputs) and sensory (the output) variables 
   are available (e.g. there is no data about grape types, wine brand, wine selling price, etc.).

   These datasets can be viewed as classification or regression tasks.
   The classes are ordered and not balanced (e.g. there are munch more normal wines than
   excellent or poor ones). Outlier detection algorithms could be used to detect the few excellent
   or poor wines. Also, we are not sure if all input variables are relevant. So
   it could be interesting to test feature selection methods. 

5. Number of Instances: red wine - 1599; white wine - 4898. 

6. Number of Attributes: 11 + output attribute
  
   Note: several of the attributes may be correlated, thus it makes sense to apply some sort of
   feature selection.

7. Attribute information:

   For more information, read [Cortez et al., 2009].

   Input variables (based on physicochemical tests):
   1 - fixed acidity (tartaric acid - g / dm^3)
   2 - volatile acidity (acetic acid - g / dm^3)
   3 - citric acid (g / dm^3)
   4 - residual sugar (g / dm^3)
   5 - chlorides (sodium chloride - g / dm^3
   6 - free sulfur dioxide (mg / dm^3)
   7 - total sulfur dioxide (mg / dm^3)
   8 - density (g / cm^3)
   9 - pH
   10 - sulphates (potassium sulphate - g / dm3)
   11 - alcohol (% by volume)
   Output variable (based on sensory data): 
   12 - quality (score between 0 and 10)

8. Missing Attribute Values: None

9. Description of attributes:

   1 - fixed acidity: most acids involved with wine or fixed or nonvolatile (do not evaporate readily)

   2 - volatile acidity: the amount of acetic acid in wine, which at too high of levels can lead to an unpleasant, vinegar taste

   3 - citric acid: found in small quantities, citric acid can add 'freshness' and flavor to wines

   4 - residual sugar: the amount of sugar remaining after fermentation stops, it's rare to find wines with less than 1 gram/liter and wines with greater than 45 grams/liter are considered sweet

   5 - chlorides: the amount of salt in the wine

   6 - free sulfur dioxide: the free form of SO2 exists in equilibrium between molecular SO2 (as a dissolved gas) and bisulfite ion; it prevents microbial growth and the oxidation of wine

   7 - total sulfur dioxide: amount of free and bound forms of S02; in low concentrations, SO2 is mostly undetectable in wine, but at free SO2 concentrations over 50 ppm, SO2 becomes evident in the nose and taste of wine

   8 - density: the density of water is close to that of water depending on the percent alcohol and sugar content

   9 - pH: describes how acidic or basic a wine is on a scale from 0 (very acidic) to 14 (very basic); most wines are between 3-4 on the pH scale

   10 - sulphates: a wine additive which can contribute to sulfur dioxide gas (S02) levels, wich acts as an antimicrobial and antioxidant

   11 - alcohol: the percent alcohol content of the wine

   Output variable (based on sensory data): 
   12 - quality (score between 0 and 10)",.csv
Reddit Stock Data (All Time),1,reddit-stock-data-all-time,RDDT.csv,CC0-1.0,"Reddit is an American social news aggregation, content rating, and forum social network. Registered users submit content to the site such as links, text posts, images, and videos, which are then voted up or down by other members. 

Reddit website: https://www.reddit.com/

Dataset Dates: 22 March 2024 - 13th May 2024",.csv
Reddit Vaccine Myths,1,reddit-vaccine-myths,reddit_vm.csv,CC0-1.0,"### Context

**VaccineMyths** (**r/VaccineMyths**), is a subreddit where people discuss about various Vaccine Myths.

The data might contain a small percent of harsh language, the posts were not filtered.


### Colection

Reddit posts from subreddit **VaccineMyths** , downloaded from https://www.reddit.com/r/VaccineMyths/ using [praw](https://praw.readthedocs.io/en/latest/) (The Python Reddit API Wrapper).

Script used for collection can be found here: [Reddit extract content](https://github.com/gabrielpreda/reddit_extract_content)

### Content

Data contains both posts and comments.
Both posts and comments contains the following fields:

* title - relevant for posts
* score - relevant for posts - based on impact, number of comments
* id - unique id for posts/comments
* url - relevant for posts - url of post thread
* commns_num - relevant for post - number of comments to this post
* created - date of creation 
* body - relevant for posts/comments - text of the post or comment
* timestamp - timestamp 


### Inspiration   

You can use the data to:
* Perform sentiment analysis;  
* Identify discussion topics;   

",.csv
Regression with a Mohs Hardness Dataset,1,regression-with-a-mohs-hardness-dataset,s.csv,MIT,"Unlock the secrets of mineral hardness with the Mohs Hardness Dataset. This dataset delves into the diverse world of minerals, providing detailed information on their hardness levels. Through regression analysis, this resource empowers researchers and geologists to make accurate predictions about the hardness of various minerals, unraveling crucial insights for fields ranging from material science to industrial applications. Dive into the dataset to discover the predictive power that unfolds when regression meets the fascinating realm of Mohs hardness.",.csv
Reliance Stock Price,1,reliance-stock-price,reliance_stock.csv,Apache 2.0,"This dataset contains Open, Close, High, Low, Previous Day close, vwap and volume of shares data for reliance stock. It can be used to predict future prices of reliance stock.",.csv
Renewable Energy (1960-2023),1,renewable-energy-1960-2023,renewable_energy.csv,other,"Renewable energy is defined as the contribution of renewables to total primary energy supply (TPES). Renewables include the primary energy equivalent of hydro (excluding pumped storage), geothermal, solar, wind, tide and wave sources. Energy derived from solid biofuels, biogasoline, biodiesels, other liquid biofuels, biogases and the renewable fraction of municipal waste are also included. Biofuels are defined as fuels derived directly or indirectly from biomass (material obtained from living or recently living organisms). This includes wood, vegetal waste (including wood waste and crops used for energy production), ethanol, animal materials/wastes and sulphite lyes. Municipal waste comprises wastes produced by the residential, commercial and public service sectors that are collected by local authorities for disposal in a central location for the production of heat and/or power. This indicator is measured in thousand toe (tonne of oil equivalent) as well as in percentage of total primary energy supply.",.csv
Renewable Power Generation and weather Conditions,1,renewable-power-generation-and-weather-conditions,Renewable.csv,CC0-1.0,"# Renewable Power Generation and weather Conditions

Imagine having access to a treasure trove of information that reveals how weather directly impacts renewable energy generation. This dataset, meticulously compiled with hourly measurements, is your key to unlocking those secrets.

## Delving into the Details:

1.Solar Power's Prime Driver: The dataset features ""Global Horizontal Irradiance (GHI)"" readings, which tell you the exact amount of solar radiation hitting a flat surface every hour. This is crucial, as sunlight is the lifeblood of solar energy production.

2.Beyond Sunshine: But weather has more to offer than just sunshine. The dataset also includes data on temperature, humidity, and precipitation – all playing a role in energy production and consumption.

3.Time Makes a Difference: By incorporating ""dayLength"" and ""sunlightTime"" measurements, you can see how the amount of daylight and sunshine availability directly affects energy generation patterns.

Insights for Everyone:

Whether you're a researcher, analyst, or simply curious about renewable energy, this dataset empowers you to:

Predict Renewable Energy Output: By analyzing the relationship between weather and past energy generation, you can develop models to predict future output, aiding in grid management and energy planning.

Understand Energy Demand: Weather can also influence energy consumption. Studying how temperature and other factors affect demand can help optimize energy infrastructure and distribution.

## A Stepping Stone to a Greener Future:

This dataset is an invaluable tool for anyone working towards a more sustainable energy future. By understanding the intricate link between weather and renewable energy, we can unlock the full potential of clean energy sources and build a more resilient power grid.

This rewrite uses a more engaging tone, highlights specific data points with factual figures (""hourly measurements"", ""Global Horizontal Irradiance (GHI)""), and explains the potential applications of the data in a way that's relevant to a broader audience.



![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F8127972%2Fe3331867b7cec1abcafe3a43d57e6e6d%2Feclipse-grid-illo-superJumbo.gif?generation=1715074561444369&alt=media)",.csv
"Rental Pricing Dataset, Malaysia",1,rent-pricing-kuala-lumpur-malaysi,mudah-apartment-kl-selangor.csv,Attribution 4.0 International (CC BY 4.0),"**Context**

This dataset contains information on rent pricing surrounding Kuala Lumpur and Selangor region, Malaysia. The information was scraped from mudah.my

**Content**

There are 13 features with one unique ids (`ads_id`) and one target feature (`monthly_rent`)

-   `ads_id`: the listing ids (unique)
-   `prop_name`: name of the building/ property
-   `completion_year`: completion/ established year of the property
-   `monthly_rent`: monthly rent in ringgit malaysia (RM)
-   `location`: property location in Kuala Lumpur region
-   `property_type`:property type such as apartment, condominium, flat, duplex, studio, etc
-   `rooms`: number of rooms in the unit
-   `parking`: number of parking space for the unit
-   `bathroom`: number of bathrooms in the unit
-   `size`: total area of the unit in square feet
-   `furnished`: furnishing status of the unit (fully, partial, non-furnished)
-   `facilities`: main facilities available
-   `additional_facilities`: additional facilities (proximity to attraction area, mall, school, shopping, railways, etc)


**Acknowledgements**
The data was scraped from mudah.my

**Inspiration**
I have been living in Kuala Lumpur, Malaysia since 2017, and in the past there was no easy way to understand whether certain unit pricing is making sense or not. With this dataset, I wanted to be able to answer the following questions:

- What are the biggest factor affecting the unit/rent pricing?
- Which location in Kuala Lumpur/ Selangor region that has the highest rent price?
etc?",.csv
Rental in Lisbon [2023],1,rental-in-lisbon-2023,rental_lisbon.csv,ODC Public Domain Dedication and Licence (PDDL),"This dataset contains information about rental prices in Lisbon, referring to the year 2023. It has the following columns:

* address: The address of the property.
* price_€: The rental price in euros.
* typology: The typology of the property, indicates the number of rooms or divisions.
* area: The area of the property in square meters.
* latitude: The geographic latitude of the property.
* longitude: The geographic longitude of the property.
* neighborhood: The neighborhood where the property is located.
* room: The number of rooms in the property.

This dataset has a total of 1466 entries, providing a representative sample of rental prices and property characteristics in Lisbon during the year 2023. This data can be useful for real estate market analysis, studies of price trends and to assist in taking decisions related to the rental sector in the city.",.csv
Restaurant Dataset,1,restaurant-dataset,Dataset .csv,MIT,"**Dataset Description: Restaurant Cuisine Classification**

**Introduction:**
This dataset is designed for developing a machine learning model to classify restaurants based on their cuisines. It includes various attributes related to restaurants such as location, average cost, ratings, and services offered. The primary objective is to predict the cuisine type of a restaurant using these attributes.

**Attributes:**
1. **Restaurant ID:** Unique identifier for each restaurant.
2. **Restaurant Name:** Name of the restaurant.
3. **Country Code:** Country code where the restaurant is located.
4. **City:** City where the restaurant is situated.
5. **Address:** Address of the restaurant.
6. **Locality:** General locality of the restaurant.
7. **Locality Verbose:** Detailed locality description.
8. **Longitude:** Longitude coordinate of the restaurant's location.
9. **Latitude:** Latitude coordinate of the restaurant's location.
10. **Cuisines:** Type of cuisines offered by the restaurant (target variable).
11. **Average Cost for Two:** Average cost for two people dining at the restaurant.
12. **Currency:** Currency used for pricing.
13. **Has Table Booking:** Binary variable indicating if the restaurant accepts table bookings.
14. **Has Online Delivery:** Binary variable indicating if the restaurant offers online delivery.
15. **Is Delivering Now:** Binary variable indicating if the restaurant is currently delivering.
16. **Switch to Order Menu:** Binary variable indicating if the restaurant has an online menu ordering option.
17. **Price Range:** Range indicating the price level of the restaurant's menu items.
18. **Aggregate Rating:** Average rating of the restaurant based on customer reviews.
19. **Rating Color:** Color code representing the rating level.
20. **Rating Text:** Textual representation of the rating level.
21. **Votes:** Total number of votes received by the restaurant.

**Acknowledgements:**
This dataset was collected from various sources and curated for research purposes. Gratitude is extended to all contributors who made this dataset available for analysis and experimentation.

**Usage Policy:**
The dataset is intended for research and educational purposes only. Commercial use or redistribution of the dataset requires explicit permission from the data owners.

**Disclaimer:**
While efforts were made to ensure the accuracy and reliability of the dataset, the creators do not guarantee its correctness or suitability for any particular purpose. Users are advised to validate the data before making any decisions based on it.",.csv
Restaurant Inspection Results,1,restaurant-inspection-results,DOHMH_New_York_City_Restaurant_Inspection_Results_20240429.csv,Apache 2.0,"The dataset contains every sustained or not yet adjudicated violation citation from every full or special program inspection conducted up to three years prior to the most recent inspection for restaurants and college cafeterias in an active status on the RECORD DATE (date of the data pull). When an inspection results in more than one violation, values for associated fields are repeated for each additional violation record.

Establishments are uniquely identified by their CAMIS (record ID) number. Keep in mind that thousands of restaurants start business and go out of business every year; only restaurants in an active status are included in the dataset.

Records are also included for each restaurant that has applied for a permit but has not yet been inspected and for inspections resulting in no violations. Establishments with inspection date of 1/1/1900 are new establishments that have not yet received an inspection. Restaurants that received no violations are represented by a single row and coded as having no violations using the ACTION field.

This dataset provides comprehensive information on food service restaurants, including their geographic coordinates and inspection histories, which can be crucial for studies on public health and safety. Analysts can use this data to identify patterns in health code violations, assess the efficacy of food safety regulations, and predict future restaurants that might be at risk of failing inspections.

I believe there are several types of analysis that can be performed with the restaurant inspection dataset, each leveraging different aspects of the data to provide valuable insights:

- **Descriptive Analysis**: Provides a foundational understanding of the data, such as the average inspection score, common violations, and general trends in inspection results across different areas or types of cuisine.
- **Geospatial Analysis**: Helps in targeted interventions and policy making, enabling health departments to focus resources on areas with persistently low scores or frequent critical violations.
- **Temporal Analysis**: Analyzing inspection results over different time frames to determine if there are seasonal trends in violations, or if policy changes have led to improvements in hygiene standards.",.csv
Restaurant Order Data,1,restaurant-order-data,zomato.csv,other,"The dataset is of the restaurants and the most searched cuisines in those by zomato.
The dataset contains the restaurant average cost, address etc.
The dataset does not contain any null value.
",.csv
Restaurant Sales report,1,fast-food-sales-report,Balaji Fast Food Sales.csv,Apache 2.0,"**In the end, you should only measure and look at the numbers that drive action, meaning that the data tells you what you should do next.🥰**

**Please do upvote if you love the work.♥️🥰**
***For more related datasets:***
https://www.kaggle.com/datasets/rajatsurana979/fifafcmobile24 
https://www.kaggle.com/datasets/rajatsurana979/most-streamed-spotify-songs-2023 
https://www.kaggle.com/datasets/rajatsurana979/comprehensive-credit-card-transactions-dataset
https://www.kaggle.com/datasets/rajatsurana979/hotel-reservation-data-repository
https://www.kaggle.com/datasets/rajatsurana979/percent-change-in-consumer-spending
https://www.kaggle.com/datasets/rajatsurana979/fast-food-sales-report


**Description**:
This dataset captures sales transactions from a local restaurant near my home. It includes details such as the order ID, date of the transaction, item names (representing various food and beverage items), item types (categorized as Fast-food or Beverages), item prices, quantities ordered, transaction amounts, transaction types (cash, online, or others), the gender of the staff member who received the order, and the time of the sale (Morning, Evening, Afternoon, Night, Midnight). The dataset offers a valuable snapshot of the restaurant's daily operations and customer behavior.

**Columns**:
1. **order_id**: a unique identifier for each order.
2. **date**: date of the transaction.
3. **item_name**: name of the food.
4. **item_type**: category of item (Fastfood or Beverages).
5. **item_price**: price of the item for 1 quantity.
6. **Quantity**: how much quantity the customer orders.
7. **transaction_amount**: the total amount paid by customers.
8. **transaction_type**: payment method (cash, online, others).
9. **received_by**: gender of the person handling the transaction.
10. **time_of_sale**: different times of the day (Morning, Evening, Afternoon, Night, Midnight).

**Potential Uses**:
- Analyzing sales trends over time.
- Understanding customer preferences for different items.
- Evaluating the impact of payment methods on revenue.
- Investigating the performance of staff members based on gender.
- Exploring the popularity of items at different times of the day.


#Makeyourhandsdirtyonit
",.csv
Restaurant's cuisine ratings data (for EDA),1,cuisine-rating,Cuisine_rating.csv,CC-BY-NC-SA-4.0,"### Context

There's a story behind every dataset and here's your opportunity to share yours.


### Content

What's inside is more than just rows and columns. Make it easy for others to get started by describing how you acquired the data and what time period it represents, too.


### Acknowledgements

Thanks to @AnirudhKalabande for sharing the data with me, who in turn sharing in the community. 


### Inspiration

Some questions can be answered as: 
Q: Visualizing the food rating as per their origin in both the genders category 
Q: Comparison of services & preference rating etc. etc. 
Q: Visualizing on basis of other criteria such as marital status or profession the rating they give. ",.csv
Restaurants Revenue Prediction,1,restaurants-revenue-prediction,Restaurant_revenue (1).csv,Apache 2.0,"The Restaurant Revenue Prediction Dataset is a comprehensive collection of simulated data designed for predicting monthly revenue for a set of fictitious restaurants. This dataset was created for educational and illustrative purposes, allowing data enthusiasts to explore and experiment with machine learning algorithms for regression tasks.",.csv
Retail Insights: A Comprehensive Sales Dataset,1,retail-insights-a-comprehensive-sales-dataset,data.csv,Community Data License Agreement - Sharing - Version 1.0,"The provided dataset is a synthetic dataset which represents sales information for a company, containing 5000 entries with 24 columns. The data encompasses various aspects of sales transactions, including order details, customer information, product details, pricing, and shipping information. Below is a detailed breakdown of each column:

**Column Descriptions:**
1.	Order No: Unique identifier for each order.
2.	Order Date: Date when the order was placed.
3.	Customer Name: Name of the customer placing the order.
4.	Address: Customer's address (one entry appears to be missing).
5.	City: City where the customer is located.
6.	State: State where the customer is located.
7.	Customer Type: Type of customer (e.g., retail, wholesale).
8.	Account Manager: Name of the account manager handling the order.
9.	Order Priority: Priority level of the order.
10.	Product Name: Name of the product being sold.
11.	Product Category: Category to which the product belongs.
12.	Product Container: Container type for the product.
13.	Ship Mode: Mode of shipping for the order.
14.	Ship Date: Date when the order was shipped.
15.	Cost Price: Cost price of the product.
16.	Retail Price: Retail price at which the product is sold.
17.	Profit Margin: Margin between retail and cost prices.
18.	Order Quantity: Quantity of products ordered.
19.	Sub Total: Subtotal cost of the order.
20.	Discount %: Percentage of discount applied to the order.
21.	Discount $: Dollar amount of the discount.
22.	Order Total: Total cost of the order after applying discounts.
23.	Shipping Cost: Cost associated with shipping the order.
24.	Total: Overall total cost, including product cost, discounts, and shipping.

**Dataset Characteristics:**
The dataset is diverse, containing both categorical and numerical data. It includes temporal information with ""Order Date"" and ""Ship Date"" in datetime format. Some columns like ""Cost Price,"" ""Retail Price,"" and others related to monetary values are currently stored as objects, which may need conversion for accurate numerical analysis. The dataset provides a comprehensive snapshot of the sales process, making it suitable for various analytical and exploratory tasks.",.csv
Retail Orders,1,retail-orders,orders.csv,CC0-1.0,This dataset contains 2022 and 2023 global mart sales dataset,.csv
Retail Price Optimization,1,retail-price-optimization,retail_price.csv,CC0-1.0,"### Context

Price optimization is using historical data to identify the most appropriate price of a product or a service that maximizes the company’s profitability. There are numerous factors like demography, operating costs, survey data, etc that play a role in efficient pricing, it also depends on the nature of businesses and the product that is served. The business regularly adds/upgrades features to bring more value to the product and this obviously has a cost associated with it in terms of effort, time, and most importantly companies reputation.

As a result, it is important to understand the correct pricing, a little too high, you lose your customers and slight underpricing will result in loss of revenue. Price optimization helps businesses strike the right balance of efficient pricing, achieving profit objectives, and also serve their customers.

### Content

The data contains the demand and corresponding average unit price at a product - month_year level


### Tasks

- Exploratory data analysis
- Data visualization
- Demand forecasting
- Price optimization

",.csv
Retail Sales Dataset,1,retail-sales-dataset,retail_sales_dataset.csv,CC0-1.0,"Welcome to the Retail Sales and Customer Demographics Dataset! This synthetic dataset has been meticulously crafted to simulate a dynamic retail environment, providing an ideal playground for those eager to sharpen their data analysis skills through exploratory data analysis (EDA). With a focus on retail sales and customer characteristics, this dataset invites you to unravel intricate patterns, draw insights, and gain a deeper understanding of customer behavior.

****Dataset Overview:**

This dataset is a snapshot of a fictional retail landscape, capturing essential attributes that drive retail operations and customer interactions. It includes key details such as Transaction ID, Date, Customer ID, Gender, Age, Product Category, Quantity, Price per Unit, and Total Amount. These attributes enable a multifaceted exploration of sales trends, demographic influences, and purchasing behaviors.

**Why Explore This Dataset?**

- **Realistic Representation:** Though synthetic, the dataset mirrors real-world retail scenarios, allowing you to practice analysis within a familiar context.
- **Diverse Insights:** From demographic insights to product preferences, the dataset offers a broad spectrum of factors to investigate.
- **Hypothesis Generation:** As you perform EDA, you'll have the chance to formulate hypotheses that can guide further analysis and experimentation.
- **Applied Learning:** Uncover actionable insights that retailers could use to enhance their strategies and customer experiences.

**Questions to Explore:**

- How does customer age and gender influence their purchasing behavior?
- Are there discernible patterns in sales across different time periods?
- Which product categories hold the highest appeal among customers?
- What are the relationships between age, spending, and product preferences?
- How do customers adapt their shopping habits during seasonal trends?
- Are there distinct purchasing behaviors based on the number of items bought per transaction?
- What insights can be gleaned from the distribution of product prices within each category?

**Your EDA Journey:**

Prepare to immerse yourself in a world of data-driven exploration. Through data visualization, statistical analysis, and correlation examination, you'll uncover the nuances that define retail operations and customer dynamics. EDA isn't just about numbers—it's about storytelling with data and extracting meaningful insights that can influence strategic decisions.

Embrace the Retail Sales and Customer Demographics Dataset as your canvas for discovery. As you traverse the landscape of this synthetic retail environment, you'll refine your analytical skills, pose intriguing questions, and contribute to the ever-evolving narrative of the retail industry. Happy exploring!",.csv
Retail Sales Forecasting,1,retail-sales-forecasting,mock_kaggle.csv,CC-BY-NC-SA-4.0,"### Context

This dataset contains lot of historical sales data. It was extracted from a Brazilian top retailer and has many SKUs and many stores. The data was transformed to protect the identity of the retailer.

### Content

[TBD]

### Acknowledgements

This data would not be available without the full collaboration from our customers who understand that sharing their core and strategical information has more advantages than possible hazards. They also support our continuos development of innovative ML systems across their value chain.


### Inspiration

Every retail business in the world faces a fundamental question: how much inventory should I carry? In one hand to mush inventory means working capital costs, operational costs and a complex operation. On the other hand lack of inventory leads to lost sales, unhappy customers and a damaged brand.

Current inventory management models have many solutions to place the correct order, but they are all based in a single unknown factor: the demand for the next periods.

This is why short-term forecasting is so important in retail and consumer goods industry.

We encourage you to seek for the best demand forecasting model for the next 2-3 weeks. This valuable insight can help many supply chain practitioners to correctly manage their inventory levels.",.csv
Retail Store Sales Transactions (Scanner Data),1,retail-store-sales-transactions,scanner_data.csv,other,"Detailed data on sales of consumer goods obtained by ‘scanning’ the bar codes for individual products at electronic points of sale in a retail store. The data provide detailed information about quantities, characteristics and values of goods sold as well as their prices.

The anonymized dataset includes 64.682 transactions of 5.242 SKU's sold to 22.625 customers during one year.

### Dataset Description

1. Date of Sales Transaction
2. Customer ID
3. Transaction ID
4. SKU Category ID
5. SKU ID
6. Quantity Sold
7. Sales Amount (Unit price times quantity. For unit price, please divide Sales Amount by Quantity.) 

### Inspiration

You can use the data for the identification of customer purchase patterns, association rule mining or RFM & CLV analysis. You can also study how changes to prices affects quantity sold.",.csv
Retail Transaction Dataset,1,retail-transaction-dataset,Retail_Transaction_Dataset.csv,Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0),"Unlocking insights into consumer behavior and retail dynamics, this comprehensive dataset captures the essence of transactions within a retail environment. Featuring ten essential columns, including CustomerID, ProductID, Quantity, Price, TransactionDate, PaymentMethod, StoreLocation, ProductCategory, DiscountApplied(%), and TotalAmount, this dataset encapsulates crucial information for retail analytics. Each entry provides a glimpse into the intricate interactions between customers, products, and sales channels, facilitating the exploration of purchasing patterns, popular products, pricing strategies, and regional preferences.

&gt;# Please Upvote my Dataset, Let's Support each other.

By delving into the wealth of information contained within this dataset, analysts can uncover valuable insights to drive strategic decision-making. The TransactionDate column offers a temporal dimension, allowing for the identification of seasonal trends, peak purchasing periods, and the impact of marketing campaigns over time. PaymentMethod data sheds light on evolving consumer payment preferences and the effectiveness of different payment strategies. Moreover, the DiscountApplied(%) column provides insights into consumer responsiveness to promotions and discounts, enabling retailers to optimize their pricing strategies for maximum impact. With such rich and diverse data at their disposal, businesses can refine their marketing efforts, enhance customer experiences, and ultimately, thrive in today's competitive retail landscape.

### Columns:
1. `CustomerID:` Unique identifier for each customer.
2. `ProductID:` Unique identifier for each product.
3. `Quantity:` The number of units purchased for a particular product.
4. `Price:` The unit price of the product.
5. `TransactionDate:` Date and time when the transaction occurred.
6. `PaymentMethod:` The method used by the customer to make the payment.
7. `StoreLocation:` The location where the transaction took place.
8. `ProductCategory:` Category to which the product belongs.
9. `DiscountApplied(%):` Percentage of the discount applied to the product.
10. `TotalAmount:` Total amount paid for the transaction.

",.csv
Retail Transactions Dataset,1,retail-transactions-dataset,Retail_Transactions_Dataset.csv,CC0-1.0,"This dataset was created to simulate a market basket dataset, providing insights into customer purchasing behavior and store operations. The dataset facilitates market basket analysis, customer segmentation, and other retail analytics tasks. Here's more information about the context and inspiration behind this dataset:

# ``` Context:```
Retail businesses, from supermarkets to convenience stores, are constantly seeking ways to better understand their customers and improve their operations. Market basket analysis, a technique used in retail analytics, explores customer purchase patterns to uncover associations between products, identify trends, and optimize pricing and promotions. Customer segmentation allows businesses to tailor their offerings to specific groups, enhancing the customer experience.

# ``` Inspiration:```
The inspiration for this dataset comes from the need for accessible and customizable market basket datasets. While real-world retail data is sensitive and often restricted, synthetic datasets offer a safe and versatile alternative. Researchers, data scientists, and analysts can use this dataset to develop and test algorithms, models, and analytical tools.

# ``` Dataset Information: ```
The columns provide information about the transactions, customers, products, and purchasing behavior, making the dataset suitable for various analyses, including market basket analysis and customer segmentation. Here's a brief explanation of each column in the  Dataset:

- **Transaction_ID:** A unique identifier for each transaction, represented as a 10-digit number. This column is used to uniquely identify each purchase.
- **Date:** The date and time when the transaction occurred. It records the timestamp of each purchase.
- **Customer_Name:** The name of the customer who made the purchase. It provides information about the customer's identity.
- **Product:** A list of products purchased in the transaction. It includes the names of the products bought.
- **Total_Items:** The total number of items purchased in the transaction. It represents the quantity of products bought.
- **Total_Cost:** The total cost of the purchase, in currency. It represents the financial value of the transaction.
- **Payment_Method:** The method used for payment in the transaction, such as credit card, debit card, cash, or mobile payment.
- **City:** The city where the purchase took place. It indicates the location of the transaction.
- **Store_Type:** The type of store where the purchase was made, such as a supermarket, convenience store, department store, etc.
- **Discount_Applied:** A binary indicator (True/False) representing whether a discount was applied to the transaction.
- **Customer_Category:** A category representing the customer's background or age group.
- **Season:** The season in which the purchase occurred, such as spring, summer, fall, or winter.
- **Promotion:** The type of promotion applied to the transaction, such as ""None,"" ""BOGO (Buy One Get One),"" or ""Discount on Selected Items.""

# ``` Use Cases:```

- **Market Basket Analysis:** Discover associations between products and uncover buying patterns.
- **Customer Segmentation:** Group customers based on purchasing behavior.
- **Pricing Optimization:** Optimize pricing strategies and identify opportunities for discounts and promotions.
- **Retail Analytics:** Analyze store performance and customer trends.

&gt;###Note: This dataset is entirely synthetic and was generated using the Python Faker library, which means it doesn't contain real customer data. It's designed for educational and research purposes.",.csv
Revisiting  a Concrete Strength regression,1,yeh-concret-data,Concrete_Data_Yeh.csv,other,"#Context

**Abstract**:
-------------

Concrete is the most important material in civil engineering.    
The concrete compressive strength is a highly nonlinear function of age and ingredients.

#Content


**Concrete Compressive Strength Data Set**
------------------------------------------

**Data Set Information:**
-------------------------

Number of instances 1030 
Number of Attributes	9 
Attribute breakdown	8 quantitative input variables, and 1 quantitative output variable 
Missing Attribute Values	None 


**Attribute Information:**   
--------------------------

Given are the variable name, variable type, the measurement unit and a brief description. The concrete compressive strength is the regression problem. The order of this listing corresponds to the order of numerals along the rows of the database. 

Name -- Data Type -- Measurement -- Description 

Cement (component 1) -- quantitative -- kg in a m3 mixture -- Input Variable    
Blast Furnace Slag (component 2) -- quantitative -- kg in a m3 mixture -- Input Variable    
Fly Ash (component 3) -- quantitative -- kg in a m3 mixture -- Input Variable    
Water (component 4) -- quantitative -- kg in a m3 mixture -- Input Variable    
Superplasticizer (component 5) -- quantitative -- kg in a m3 mixture -- Input Variable    
Coarse Aggregate (component 6) -- quantitative -- kg in a m3 mixture -- Input Variable    
Fine Aggregate (component 7)	-- quantitative -- kg in a m3 mixture -- Input Variable    
Age -- quantitative -- Day (1~365) -- Input Variable    
Concrete compressive strength -- quantitative -- MPa -- Output Variable    

#Acknowledgements

**Source:**
-----------

Original Owner and Donor    
Prof. I-Cheng Yeh    
Department of Information Management    
Chung-Hua University,    
Hsin Chu, Taiwan 30067, R.O.C.    
e-mail:icyeh '@' chu.edu.tw    
TEL:886-3-5186511    

Date Donated: August 3, 2007    

From:  https://archive.ics.uci.edu/ml/datasets/Concrete+Compressive+Strength

**Relevant Papers:**   
--------------------

**Main**    
1)	I-Cheng Yeh, ""Modeling of strength of high performance concrete using artificial neural networks,"" Cement and Concrete Research, Vol. 28, No. 12, pp. 1797-1808 (1998). 

**Others**    

2)	I-Cheng Yeh, ""Modeling Concrete Strength with Augment-Neuron Networks,"" J. of Materials in Civil Engineering, ASCE, Vol. 10, No. 4, pp. 263-268 (1998).    

3)	I-Cheng Yeh, ""Design of High Performance Concrete Mixture Using Neural Networks,"" J. of Computing in Civil Engineering, ASCE, Vol. 13, No. 1, pp. 36-42 (1999).    

4)	I-Cheng Yeh, ""Prediction of Strength of Fly Ash and Slag Concrete By The Use of Artificial Neural Networks,"" Journal of the Chinese Institute of Civil and Hydraulic Engineering, Vol. 15, No. 4, pp. 659-663 (2003).    

5)	I-Cheng Yeh, ""A mix Proportioning Methodology for Fly Ash and Slag Concrete Using Artificial Neural Networks,"" Chung Hua Journal of Science and Engineering, Vol. 1, No. 1, pp. 77-84 (2003).    

6)	Yeh, I-Cheng, ""Analysis of strength of concrete using design of experiments and neural networks,"" Journal of Materials in Civil Engineering, ASCE, Vol.18, No.4, pp.597-604 (2006).    


**Citation Request:**   
---------------------

NOTE: Reuse of this database is unlimited with retention of copyright notice for Prof. I-Cheng Yeh and the following published paper:    

I-Cheng Yeh, ""Modeling of strength of high performance concrete using artificial neural networks,"" Cement and Concrete Research, Vol. 28, No. 12, pp. 1797-1808 (1998). 

#Inspiration
Can you predict the strength of concrete?",.csv
Rich Dad Poor Dad Reviews / Rating,1,rich-dad-poor-dad-reviews-rating,rich_dad_poor_dad.csv,MIT,"This dataset comprises reviews of the popular personal finance book ""Rich Dad Poor Dad"" authored by Robert T. Kiyosaki. ""Rich Dad Poor Dad"" is a timeless classic that challenges conventional wisdom about money and investing, presenting insights and lessons from the author's personal experiences with his two fathers - one rich, one poor.

The dataset includes reviews posted by certified buyers on Amazon, offering a comprehensive perspective on readers' experiences and perceptions of the book. Each review provides valuable insights into the impact of ""Rich Dad Poor Dad"" on individuals' financial mindsets, investment strategies, and overall approach to wealth accumulation.

By analyzing this dataset, researchers and data enthusiasts can uncover patterns, sentiments, and trends in readers' feedback, exploring how the book resonates with diverse audiences across different demographics, geographical locations, and socioeconomic backgrounds. Additionally, this dataset can serve as a valuable resource for sentiment analysis, natural language processing (NLP), and machine learning projects aimed at understanding consumer preferences and behaviors in the personal finance domain.

Whether you're a data scientist, researcher, or enthusiast interested in personal finance, this dataset offers a rich source of information for exploration and analysis. Dive into the world of ""Rich Dad Poor Dad"" reviews to gain deeper insights into the impact of financial education and mindset on individuals' lives and aspirations",.csv
Rick&Morty Scripts,1,rickmorty-scripts,RickAndMortyScripts.csv,other,"### Context

Data was already scraped by [Gabriel Hernandes](https://www.kaggle.com/andradaolteanu/sentiment-analysis-rick-and-morty-scripts?scriptVersionId=28440168) (bless his soul) right here. 

All I did afterwards is I took some of the txt files (the ones that had more clearer splits and classification) and I cleaned it and brought it into the tabular form you see in the csv file.


### Content

**Rick and Morty Scripts**:

* index: just the index of the row 
* season no: The season number of the dialogue
* episode no: The episode number of the dialogue
* episode name: The name of the episode
* name: the character name
* line: the dialogue of the character


### Acknowledgements

Thanks again to Gabriel Hernandes, I couldn't get this data without him.


### Inspiration

A lot of text mining, sentiment analysis or other text processing ideas can be done from this data.
 
You can find my vision for it here: [Sentiment Analysis: Rick and Morty Scripts](https://www.kaggle.com/andradaolteanu/sentiment-analysis-rick-and-morty-scripts?scriptVersionId=28440168)",.csv
Risk Factor prediction of Chronic Kidney Disease,1,risk-factor-prediction-of-chronic-kidney-disease,ckd-dataset-v2.csv,Attribution 4.0 International (CC BY 4.0),"Chronic kidney disease (CKD) is an increasing medical issue that declines the productivity of renal capacities and subsequently damages the kidneys.

**Was there any data preprocessing performed?**

This dataset is not pre-processed, if you want to apply a Machine learning Algorithm at first you have to need to pre-process the data

**Additional Information**

This dataset is real Bangladeshi patient data. The dataset is collected from Enam Medical College, Savar, Dhaka, Bangladesh.

**Variable Information**

1. bp(Diastolic)
2. bp limit
3. sg
4. al
5. class
6. rbc
7. su
8. pc
9. pcc
10. ba
11.bgr
12. bu
13. sod
14. sc
15. pot
16. hemo
17. pcv
18. rbcc
19. wbcc
20. htn
21. dm
22. cad
23. appet
24. pe
25. ane
26. grf
27. stage
28. affected
29. age",.csv
Risk Factors for Cardiovascular Heart Disease,1,exploring-risk-factors-for-cardiovascular-diseas,heart_data.csv,other,"_____
# Exploring Risk Factors for Cardiovascular Disease in Adults
### Examining Age, Gender, Height, Weight and Health Metrics
By Kuzak Dempsy [[source]](https://data.world/kudem)
_____

### About this dataset
> This dataset contains detailed information on the risk factors for cardiovascular disease. It includes information on age, gender, height, weight, blood pressure values, cholesterol levels, glucose levels, smoking habits and alcohol consumption of over 70 thousand individuals. Additionally it outlines if the person is active or not and if he or she has any cardiovascular diseases. This dataset provides a great resource for researchers to apply modern machine learning techniques to explore the potential relations between risk factors and cardiovascular disease that can ultimately lead to improved understanding of this serious health issue and design better preventive measures

### More Datasets
> For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
> - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
> This dataset can be used to explore the risk factors of cardiovascular disease in adults. The aim is to understand how certain demographic factors, health behaviors and biological markers affect the development of heart disease. 
>  
> To start, look through the columns of data and familiarize yourself with each one. Understand what each field means and how it relates to heart health:
> - **Age**: Age of participant (integer)
> - **Gender**: Gender of participant (male/female).
> - **Height**: Height measured in centimeters (integer) 
> - **Weight**: Weight measured in kilograms (integer) 
> - **Ap_hi**: Systolic blood pressure reading taken from patient (integer) 
> - **Ap_lo** : Diastolic blood pressure reading taken from patient (integer) 
> - **Cholesterol** : Total cholesterol level read as mg/dl on a scale 0 - 5+ units( integer). Each unit denoting increase/decrease by 20 mg/dL respectively.  
> ‐ Gluc : Glucose level read as mmol/l on a scale 0 - 16+ units( integer). Each unit denoting increase Decreaseby 1 mmol/L respectively.               ‐ Smoke  : Whether person smokes or not(binary; 0= No , 1=Yes).              ‐ Alco ​­ : Whether person drinks alcohol or not(binary; 0 =No ,1 =Yes ).                     • Active : whether person physically active or not( Binary ;0 =No,1 = Yes ).    . Cardio ­­ : whether person suffers from cardiovascular diseases or not(Binary ;0 – no , 1 ­‑yes ).Identify any trends between the different values for each attribute and the developmetn for cardiovascular disease among individuals represented by this dataset . Age, gender, weight, lifestyle practices like smoking & drinking alcohol are all key influences when analyzing this problem set. You can always modify pieces of your analysis until you're able to find patterns that will enable you make conclusions based on your understanding & exploration. You can further enrich your understanding using couple mopdeling technique like Regressions & Classification models over this dataset alongwith latest Deep Learning approach! Have Fun!

### Research Ideas
> - Analyzing the effect of lifestyle and environmental factors on the risk of cardiovascular disease.
> - Predicting the risks of different age groups based on their demographic characteristics such as gender, height, weight and smoking status.
> - Detecting patterns between levels of physical activity, blood pressure and cholesterol levels with likelihood of developing cardiovascular disease among individuals

### Acknowledgements
> If you use this dataset in your research, please credit the original authors.
> [Data Source](https://data.world/kudem)
> 
>


### License
> 
> 
> See the dataset description for more information.

### Columns

**File: heart_data.csv**
| Column name     | Description                                              |
|:----------------|:---------------------------------------------------------|
| **age**         | Age of the individual. (Integer)                         |
| **gender**      | Gender of the individual. (String)                       |
| **height**      | Height of the individual in centimeters. (Integer)       |
| **weight**      | Weight of the individual in kilograms. (Integer)         |
| **ap_hi**       | Systolic blood pressure reading. (Integer)               |
| **ap_lo**       | Diastolic blood pressure reading. (Integer)              |
| **cholesterol** | Cholesterol level of the individual. (Integer)           |
| **gluc**        | Glucose level of the individual. (Integer)               |
| **smoke**       | Smoking status of the individual. (Boolean)              |
| **alco**        | Alcohol consumption status of the individual. (Boolean)  |
| **active**      | Physical activity level of the individual. (Boolean)     |
| **cardio**      | Presence or absence of cardiovascular disease. (Boolean) |

### Acknowledgements
> If you use this dataset in your research, please credit the original authors.
> If you use this dataset in your research, please credit [Kuzak Dempsy](https://data.world/kudem).

",.csv
Road Accident Data 2020 India,1,road-accident-data-2020-india,df.csv,other,"## The data contains road accident information for 50 cities of India in the year 2020. 

source : https://data.gov.in/catalog/road-accidents-india-2020

Columns :
1. **Million plus cities** : Contains the name of the cities
2. **Cause Category**: 5 primary category for classification of accidents ( Traffic Control, Junction, Road Features, Impacting Vehicle/Object, Weather Conditions)
3. **Cause Subcategory**: Further classifying the exact cause for the accident
4. **Outcome of Incident**: Indicating , injuries , deaths and accidents
5. **Count**: Count in Millions for each incident.

",.csv
Road Accident Severity in India,1,road-accident-severity-in-india,Road.csv,DbCL-1.0,"The data set has been prepared from manual records of road traffic accidents for the years 2017–22. All the sensitive information has been excluded during data encoding, and finally, it has 32 features and 12316 instances of the accident. Then it is preprocessed for the identification of major causes of the accident by analyzing it using different machine learning classification algorithms. Road.csv is the preprocessed dataset.",.csv
Road Accident Trends in Bangladesh: 1980-2024,1,road-accident-statistics-in-bangladesh,road_accident_statistics.csv,Apache 2.0,"# Road Accident Statistics in Bangladesh: 1980-2024

Exploring road accident statistics complements the analysis of city population data, offering vital insights into public safety and infrastructure challenges in Bangladesh. This dataset provides a comprehensive overview of road accidents spanning from 1980 to 2024, encompassing various metrics such as accident numbers, fatalities, and injuries. By examining these statistics alongside population data, stakeholders can gain a holistic understanding of demographic trends, urban development, and transportation infrastructure needs, facilitating informed decision-making for sustainable urban planning and safety initiatives.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F1937611%2Ffbb0dfb7c9b95e8340b93b99b977ff6d%2F_754f8c74-86cd-43d1-bd94-0c1aff7eec21.jpeg?generation=1711678847363477&alt=media)

## Dataset Overview:

The dataset comprises comprehensive road accident statistics spanning from 1980 to 2024 in Bangladesh. It includes metrics such as the number of accidents, fatalities, serious injuries, minor injuries, moderate injuries, and severe injuries for each year. This dataset provides valuable insights into road safety trends and public health concerns, facilitating informed policymaking and infrastructure improvements.

Source: The dataset was compiled from reliable sources tracking road accident statistics in Bangladesh.

Content: It comprises comprehensive road accident data, including metrics such as the number of accidents, fatalities, serious injuries, minor injuries, moderate injuries, and severe injuries.

Format: Structured in a tabular format suitable for analysis, facilitating easy comprehension and interpretation of the data.

Representation: Encompasses road accident statistics across Bangladesh, providing insights into the prevalence and severity of accidents in various regions.

Temporal Coverage: Spans from 1980 to 2024, allowing for a longitudinal analysis of road safety trends and patterns over several decades.

Insights into Public Safety: Provides valuable insights into public safety concerns and infrastructure challenges, enabling informed decision-making and targeted interventions to enhance road safety measures.

Included Metrics: The dataset likely includes fields such as:

- Year: The year for which the accident data is recorded.
- Number of Accidents: Total number of accidents reported in the specified year.
- Death: Number of fatalities resulting from road accidents.
- Number of Serious Injuries: Count of serious injuries sustained in accidents.
- Number of Minor Injuries: Count of minor injuries sustained in accidents.
- Number of Moderate Injuries: Count of moderate injuries sustained in accidents.
- Number of Severe Injuries: Count of severe injuries sustained in accidents.

This dataset offers a comprehensive overview of road accident statistics in Bangladesh, facilitating in-depth analyses of road safety trends, public health implications, and infrastructure improvements over time.


",.csv
Road Accidents Data,1,road-accidents-data,dft-road-casualty-statistics-casualty-provisional-mid-year-unvalidated-2023.csv,Community Data License Agreement - Sharing - Version 1.0,"""Road Accidents Dataset"":

Description: This comprehensive dataset provides detailed information on road accidents reported over multiple years. The dataset encompasses various attributes related to accident status, vehicle and casualty references, demographics, and severity of casualties. It includes essential factors such as pedestrian details, casualty types, road maintenance worker involvement, and the Index of Multiple Deprivation (IMD) decile for casualties' home areas.

Columns:

1.Status: The status of the accident (e.g., reported, under investigation).

2.Accident_Index: A unique identifier for each reported accident.

3.Accident_Year: The year in which the accident occurred.

4.Accident_Reference: A reference number associated with the accident.

5.Vehicle_Reference: A reference number for the involved vehicle in the accident.

6.Casualty_Reference: A reference number for the casualty involved in the accident.

7.Casualty_Class: Indicates the class of the casualty (e.g., driver, passenger, pedestrian).

8.Sex_of_Casualty: The gender of the casualty (male or female).

9.Age_of_Casualty: The age of the casualty.

10.Age_Band_of_Casualty: Age group to which the casualty belongs (e.g., 0-5, 6-10, 11-15).

11.Casualty_Severity: The severity of the casualty's injuries (e.g., fatal, serious, slight).

12.Pedestrian_Location: The location of the pedestrian at the time of the accident.

13.Pedestrian_Movement: The movement of the pedestrian during the accident.

14.Car_Passenger: Indicates whether the casualty was a car passenger at the time of the accident (yes or no).

15.Bus_or_Coach_Passenger: Indicates whether the casualty was a bus or coach passenger (yes or no).

16.Pedestrian_Road_Maintenance_Worker: Indicates whether the casualty was a road maintenance worker (yes or no).

17.Casualty_Type: The type of casualty (e.g., driver/rider, passenger, pedestrian).

18.Casualty_Home_Area_Type: The type of area in which the casualty resides (e.g., urban, rural).

19.Casualty_IMD_Decile: The IMD decile of the area where the casualty resides (a measure of deprivation).

20.LSOA_of_Casualty: The Lower Layer Super Output Area (LSOA) associated with the casualty's location.

This dataset provides valuable insights for analyzing road accidents, identifying trends, and implementing safety measures to reduce casualties and enhance road safety. Researchers, policymakers, and analysts can leverage this dataset for evidence-based decision-making and improving overall road transportation systems.",.csv
Road Accidents Data -2022,1,road-accidents-data-2022,dft-road-casualty-statistics-casualty-provisional-mid-year-unvalidated-2022 (1).csv,Community Data License Agreement - Sharing - Version 1.0,"""Road Accidents Dataset"":

Description:
This comprehensive dataset provides detailed information on road accidents reported over multiple years. The dataset encompasses various attributes related to accident status, vehicle and casualty references, demographics, and severity of casualties. It includes essential factors such as pedestrian details, casualty types, road maintenance worker involvement, and the Index of Multiple Deprivation (IMD) decile for casualties' home areas.

Columns:
1. **Status**: The status of the accident (e.g., reported, under investigation).
2. **Accident_Index**: A unique identifier for each reported accident.
3. **Accident_Year**: The year in which the accident occurred.
4. **Accident_Reference**: A reference number associated with the accident.
5. **Vehicle_Reference**: A reference number for the involved vehicle in the accident.
6. **Casualty_Reference**: A reference number for the casualty involved in the accident.
7. **Casualty_Class**: Indicates the class of the casualty (e.g., driver, passenger, pedestrian).
8. **Sex_of_Casualty**: The gender of the casualty (male or female).
9. **Age_of_Casualty**: The age of the casualty.
10. **Age_Band_of_Casualty**: Age group to which the casualty belongs (e.g., 0-5, 6-10, 11-15).
11. **Casualty_Severity**: The severity of the casualty's injuries (e.g., fatal, serious, slight).
12. **Pedestrian_Location**: The location of the pedestrian at the time of the accident.
13. **Pedestrian_Movement**: The movement of the pedestrian during the accident.
14. **Car_Passenger**: Indicates whether the casualty was a car passenger at the time of the accident (yes or no).
15. **Bus_or_Coach_Passenger**: Indicates whether the casualty was a bus or coach passenger (yes or no).
16. **Pedestrian_Road_Maintenance_Worker**: Indicates whether the casualty was a road maintenance worker (yes or no).
17. **Casualty_Type**: The type of casualty (e.g., driver/rider, passenger, pedestrian).
18. **Casualty_Home_Area_Type**: The type of area in which the casualty resides (e.g., urban, rural).
19. **Casualty_IMD_Decile**: The IMD decile of the area where the casualty resides (a measure of deprivation).
20. **LSOA_of_Casualty**: The Lower Layer Super Output Area (LSOA) associated with the casualty's location.

This dataset provides valuable insights for analyzing road accidents, identifying trends, and implementing safety measures to reduce casualties and enhance road safety. Researchers, policymakers, and analysts can leverage this dataset for evidence-based decision-making and improving overall road transportation systems.",.csv
Roadway Markings Jobs,1,roadway-markings-jobs,Roadway_Markings_Jobs.csv,other,"This dataset contains records of work completed and in-progress work from June 2018 to present for the purpose of tracking the installation and maintenance of roadway markings across the City of Austin. The Jobs dataset is separated into four categories: Long Line, Short Line, Specialty Markings, and Raised Pavement Markings.

Long Line: Work group responsible for installing and maintaining lane lines, double yellow centerlines, bike lane lines, and turn bay.

Short Line: Work group responsible for installing and maintaining crosswalks, school zone lines, and stop lines.

Specialty Markings: Work group responsible for installing and maintaining arrows, words, bike symbols, pedestrian symbols, railroad crossings, yield triangles, parking stalls/Ls/Ts, green pads, and speed hump markings.

Raised Pavement Markings: Work group responsible for installing and maintaining delineators, raised pavement markings (RPMs), and concrete domes.

This work is managed by the Signs & Markings Division of the City of Austin Transportation Department.

You may also be interested in these related datasets, which can be joined together using the work order ID columns:

- Road Markings Work Orders: https://data.austintexas.gov/Transportation-and-Mobility/Roadway-Markings-Work-Orders/nyhn-669r
- Signs and Markings Time Logs: https://data.austintexas.gov/dataset/Work-Order-Signs-Markings-Time-Logs/qvth-gwdv
- Signs and Markings Reimbursements: https://data.austintexas.gov/dataset/Signs-and-Markings-Reimbursement-Tracking/pma8-yy5k

Division website: http://www.austintexas.gov/department/signs-markings",.csv
Roast Coffee Shop - 2023 Financials,1,roast-coffee-shop-2023-financials,Coffee_Shop_Financial_Data_2023.csv,Apache 2.0,"This CSV file contains daily financial data for a mock coffee shop for the year 2023. The data includes both forecasted and actual amounts for different revenue and expense categories. Revenue categories include ""Coffee Sales"" and ""Food Sales."" Expense categories cover ""Ingredients Cost,"" ""Labor,"" ""Rent,"" ""Utilities,"" and ""Marketing."" 

This dataset was created to enable financial analysis, questions we might ask include: 

How do the actual sales and expenses compare with the forecasted figures? Are there any significant variances, and what might be the reasons for these discrepancies?

Are there specific months or seasons when sales peak or decline? What might be driving these trends?
How do expenses trend throughout the year? Are there any notable fluctuations that need to be addressed?

Which months had the highest and lowest profitability? What contributed to these outcomes?
How do the gross and net profit margins vary over the year?

Which expense category has the largest variance from the forecast? What measures can be taken to control these costs more effectively?

Are there any noticeable trends in the cost of ingredients and labor relative to sales?

Between coffee and food sales, which category is performing better in terms of meeting or exceeding forecasts?

What could be the potential financial impact if the rent increases by 10% next year?",.csv
Rohit Sharma International Centuries,1,rohit-sharma-international-centuries,Rohit_Sharma_Centuries.csv,MIT,"**Rohit Sharma** is an accomplished **Indian cricketer** known for his prolific batting in all formats of the game. He is particularly celebrated for his ability to score centuries (100 or more runs in a single innings) consistently across Test matches, One-Day Internationals (ODIs), and Twenty20 Internationals (T20Is). This dataset captures details of his century-scoring innings, providing insights into his performance and match circumstances.

This **dataset** contains information about Rohit Sharma's centuries in international cricket. Each row represents a specific century scored by Rohit Sharma, detailing various aspects of the match and his performance. Dataset contains the following columns :

- **S.No.** : Serial number or index of the century in chronological order.
- **Date** : Date on which Rohit Sharma scored the century.
- **Score** : Runs scored by Rohit Sharma in that innings.
- **Strike Rate** : Strike rate at which Rohit Sharma scored (calculated as runs per 100 balls).
- **Type of Match** : Indicates the format of the match (Test, ODI, T20).
- **Position** : Batting position of Rohit Sharma in that innings.
- **Innings** : Innings number (1st or 2nd) played by Rohit Sharma.
- **Dismissed** : Indicates whether Rohit Sharma was dismissed (Yes) or remained not out (No).
- **Man of the Match** : Whether Rohit Sharma was awarded Man of the Match for his performance in that match (Yes or No).
- **Captain** : Indicates if Rohit Sharma was the captain of the team during that match (Yes or No).
- **Against** : Name of the opposition team against whom Rohit Sharma scored the century.
- **Venue** : Name of the cricket ground where the match was played.
- **H/A/N** : Indicates if the match was played at Home (India), Away (outside India), or Neutral venue.
- **Result** : Outcome of the match for Rohit Sharma's team (Won or Lost).

This dataset provides valuable insights into Rohit Sharma's century-scoring performances and can be used for statistical analysis and cricket enthusiasts interested in his career milestones.",.csv
Roller Coaster Database,1,rollercoaster-database,coaster_db.csv,CC0-1.0,"### The Rollercoaster Database

This data contains information about over 1000 rollercoasters. Information was scraped from wikipedia.

Code can be found here: https://github.com/RobMulla/twitch-stream-projects/tree/main/001-rollercoaster-dataset",.csv
Roman interior and modern interior&nbsp;design IMG,1,roman-interior-and-modern-interior-design-img,img_of_homes.csv,CC0-1.0,"This dataset offers a comprehensive collection of interior design ideas, showcasing both Roman and modern design styles. It consists of two primary components: a CSV file and an image folder.
Image Folder:
The image folder contains a vast collection of images illustrating Roman and modern interior design concepts. Each image is referenced in the CSV file by its corresponding path.",.csv
Room Occupancy Detection,1,room-occupancy-detection,room_occupancy_detection_data.csv,Attribution 4.0 International (CC BY 4.0),"Dataset of room-level indoor environmental quality measurements and occupancy ground truth for five residential apartments in Denmark. ***The occupancy ground truth variable is a binary 0 (no occupancy in the room) or 1 (occupancy in the room).***

**Methodology:**

*(the following information provided by the authors of the experiment)*

This dataset contains room-level measurements of indoor environmental quality (IEQ) variables together with occupancy ground truth for five residential apartments in Denmark over 7 days (2023-01-30/2023-02-06), with a temporal resolution of 15 minutes. The occupancy ground truth has been determined based on activity logbooks filled in by apartments’ occupants. The measured IEQ variables are:
* Indoor CO2 concentration
* Indoor operative temperature
* Indoor relative humidity

Additional features were generated from those three variables: variable transforms representing the short-term dynamics of the indoor environment for each of the three IEQ variables:
* Difference between current variable value and average over the last hour
* Difference between current variable value and previous recording (15 minutes prior)
* Average of the variable over the last hour

Moreover, metadata parameters include the apartment number (1-5), room number (1-16), room type number, one-hot-encoded room type, floor area of the room, hour of the day, day number of the week, day number of the year, day label (unique identifier of a day for the different rooms) and date and time stamp.

**Detailed information about each column follows:**

* **datetime**: Date and time stamp in the format DD-MM-YY HH:MM (Day-Month-Year Hour:Minute).
* **indoor_co2_concentration**: Indoor CO2 concentration inside the corresponding room (in ppm: parts per million).
* **indoor_operative_temperature**: Indoor operative temperature inside the corresponding room (in Celsius degrees).
* **indoor_relative_humidity**: Indoor relative humidity inside the corresponding room (in percent).
* **current_value_minus_average_last_hour_co2**: Difference between the current indoor CO2 concentration inside the corresponding room and the average indoor CO2 concentration over the last hour (in ppm: parts per million).
* **current_value_minus_average_last_hour_operative_temperature**: Difference between the current indoor operative temperature inside the corresponding room and the average indoor operative temperature over the last hour (in Celsius degrees).
* **current_value_minus_average_last_hour_relative_humidity**: Difference between the current indoor relative humidity inside the corresponding room and the average indoor relative humidity over the last hour (in percent).
* **average_co2_last_hour**: Average indoor CO2 concentration inside the corresponding room over the last hour (in ppm: parts per million).
* **average_operative_temperature_last_hour**: Average indoor operative temperature inside the corresponding room over the last hour (in Celsius degrees).
* **average_relative_humidity_last_hour**: Average indoor relative humidity inside the corresponding room over the last hour (in percent).
* **current_value_minus_last_15_min_co2**: Difference between the current indoor CO2 concentration inside the corresponding room and the indoor CO2 concentration 15 minutes before (in ppm: parts per million).
* **current_value_minus_last_15_min_operative_temperature**: Difference between the current indoor operative temperature inside the corresponding room and the indoor operative temperature 15 minutes before (in Celsius degrees).
* **current_value_minus_last_15_min_relative_humidity**: Difference between the current indoor relative humidity inside the corresponding room and the indoor relative humidity 15 minutes before (in percent).
* **room_number**: Room number label (from 1 to 16).
* **kitchen**: One-hot-encoded room type for kitchen rooms.
* **livingroom**: One-hot-encoded room type for living rooms.
* **bedroom**: One-hot-encoded room type for bedrooms.
* **office**: One-hot-encoded room type for office rooms.
* **kitchen_livingroom**: One-hot-encoded room type for kitchen/living rooms.
* **hour_of_the_day**: Hour of the day (from 0 to 23).
* **day_number_of_the_week**: Day number label of the week (from 1 to 7).
* **day_of_year**: Day number label of year (from 30 to 37).
* **day_label**: Day number label as a unique identifier of a day for the different rooms (from 0 to 112).
* **occupancy_ground_truth**: Ground truth value of occupancy in the corresponding room. Binary variable taking the value of 0 when there is no occupancy (no people) in the room or 1 when there is occupancy (at least one person) in the room.
* **floor_area**: Surface floor area of the corresponding room (in square meters).
* **apartment_number**: Apartment number label (from 1 to 5).
* **room_type**: Type of the corresponding room (kitchen, living room, bedroom, office or kitchen_livingroom).

**Acknowledgements:**

A detailed description of the study case building can be found in a dedicated technical report: *Kamilla Heimar Andersen, Anna Marszal-Pomianowska, Henrik N. Knudsen, Hicham Johra, Simon Pommerencke Melgaard, Marc Zein Dahl, Patrick Andersen Hundevad, Per Kvols Heiselberg (2023). Room-based Indoor Environment Measurements and Occupancy Ground Truth Datasets from Five Residential Apartments in a Nordic Climate.* DCE Technical Reports No. 318. Aalborg University, Department of the Built Environment.

If you use this dataset in your research, please credit the original authors.
https://doi.org/10.54337/aau550646548",.csv
Run or Walk,1,run-or-walk,dataset.csv,CC-BY-NC-SA-4.0,"### Context

This dataset complements https://github.com/vmalyi/run-or-walk project which aims to detect whether the person is running or walking based on deep neural network and sensor data collected from iOS device.

This dataset has been accumulated with help of ""Data Collection"" iOS app specially developed for this purpose: https://github.com/vmalyi/run-or-walk/tree/master/ios_app_data_collection. 

Please note that this app is not available in the AppStore yet.

### Content

Currently, the dataset contains a single file which represents 88588 sensor data samples collected from accelerometer and gyroscope from iPhone 5c in 10 seconds interval and ~5.4/second frequency. This data is represented by following columns (each column contains sensor data for one of the sensor's axes): 

 - acceleration_x
 - acceleration_y
 - acceleration_z
 - gyro_x
 - gyro_y
 - gyro_z

There is an activity type represented by ""activity"" column which acts as label and reflects following activities:
 
 - ""0"": walking
 - ""1"": running

Apart of that, the dataset contains ""wrist"" column which represents the wrist where the device was placed to collect a sample on:

 - ""0"": left wrist
 - ""1"": right wrist

Additionally, the dataset contains ""date"", ""time"" and ""username"" columns which provide information about the exact date, time and user which collected these measurements.",.csv
Rural Credit Dataset Cleaned,1,rural-credit-dataset-cleaned,RuralCreditDataCleaned.csv,other,"This is the cleaned version of [Credit/Loan Dataset - Rural India](https://www.kaggle.com/datasets/heydido/creditloan-dataset-rural-india). The dataset has been cleaned by filling the missing values , outlier removal and feature selection.
",.csv
Russian Rap 2017-2022 Dataset,1,russian-rap-2017-2022-dataset,Five_years_of_Russian_Rap_Dataset.csv,MIT,"## tldr:
**Size**: Dataset includes 12,743 unique songs and 282 unique artists (14397 observations), 28 columns<br>
**What's inside**: success variables + audio originality characteristics + collaborations variables + meta-info from Spotify about songs, albums, artist + audio preview download links from Spotify API<br>
**I would be very grateful for upvote/comment/reaction/notebooks on this dataset**

## Background

This dataset was collected in purpose of music research for my bachelor thesis. The data was collected through web-scraping, parsing of Spotify API, and magical audio extraction functions in librosa. (If you are interested in more details - read the [full thesis text](https://spb.hse.ru/en/ba/soc/students/diplomas/835759635))

### Research Questions
1. To what extent does an artist's previous success in producing chart-topping songs impact the success of their future releases in the modern Russian rap market?
2. How does collaboration with other artists impact the success of a released song in the modern Russian rap market?
3. How does the sound characteristics of a rap song influence its popularity in the modern Russian rap market?

### Sampling
The sample consists of full or partial discographies of artists with at least one song that was presented in the Russian music charts of such music streaming services as Spotify, Yandex.Music and Apple Music within the time period of 01.01.2017 to 06.03.2022. Final dataset includes 282 unique artists (therefore content of 282 discographies overall) and 12743 unique songs, of which 2043 songs are hits and 10700 are non-hits.

## Variables

- **track_id** - id of the song in Spotify (non-unique due to collaborations)
- **artist_name** - name of the performer of the song
- **Song_Success** - whether the song was in russian music streaming charts   
- **album_release_date** - realease date of the song (YYYY-MM-DD)
- **hit_n** - Number of Previous Hits for the performer according to release date fo the song (so, if the artist did not have hits, then this cell will be equal to zero, even if this song became a hit)
- **7 Audio Originality Features** - the lower it is, the less original is the song (=more similar to the last year's hits). 
- **is_feat** - is this song a collaboration?
- **n_feat** - how many collaborators perform the song (except the performer specified in artist_name column)
- **status_guest** - (if guest artists) how many hits do guest artists have
- **higher_guest** - is there a guest artist with more hits than the performer specified in artist_name column
- **album_name** - title of the release (album/single) the track is on
- **album_type** - type of the release - album or single
- **track_number** - index number of the track in the album
- **explicit** - does the track contain offensive language
- **key_name** - name of the song's key 
- **mode_name** - name of the song's mode
- **key_mode** - combination of the song's key and mode
- **artists_all** - full list of the performers of the track
- **remake** - is the track remake (i.e. remix)
- **artist_id** - id of the artist in Spotify
- **album_id** - id of the album in Spotify
- **download_link** - link for download 30-seconds preview of the track in MP3 (provided by Spotify API)


***Audio Originality Features in details:***  
Median distance by 'any audio characteristic below' between particular song and all hits released in last year. For example, Drums_Energy variable answers such question ""How different is drums energy in this song compared to hits released in the last year?"" (description of every audio feature further)

1. **Drums_Energy** - the higher it is, the more intense and energetic the beat *(Rock or EDM Instrumentals have higher values, while classic trap, RnB, instrumentals without drums have lower values)*

2. **Drums_Complexity** - The higher it is, the more dynamic and varied the beat. *(For example, Hyperpop or songs with frequently changing drum patterns have higher values, while Pop music or instrumentals without drums (music with a stable drum pattern) have lower values.)*

3. **Variety_of_musical_instruments** - Simple music with one or two instruments, for example acoustic guitar ballads, has higher values, while songs with instrumental overload, complex multi-layered instrumental (in terms of the number of instruments, not in terms of the notes played) have lower values.

4. **Mixing_Quality** - Songs where many instruments  change each other (very timbre dynamic, instruments do not become a single layer, as in the case of a low “variety of musical instruments”) have higher values, music with same sounds/instruments all along the whole song typically has lower values. 

5. **Harmonic_Richness** - Songs with higher Harmonic Richness would have more rich sound in terms of notes mixing (for example, complex Electronic, Jazz beats), while songs with lower harmonic richness would sound less interesting, but more catchy and simpler due to lack of tonal textures (for example, Minimal Trap, Pop).

6. **Mixing Character** - The lower it is, the more bass in music. The higher it is the more high-frequency instruments (synths, high-pitched vocals, distorted sounds) or noise is in music.

7. **Emotional Intensity** - The lower it is, the more hard-hitting, gritty or aggressive the track is. The higher it is, the more laid-back, relaxing or groovy the track is.

## Research
Read my thesis and observe the code!   
Code files: [Github Folder](https://github.com/tim-toothed/Portfolio_Projects/tree/88cd981d01cba2bcef1ce20ec2c72afca0bf9cd3/Thesis)   
Thesis Full Text: [HSE Website](https://spb.hse.ru/en/ba/soc/students/diplomas/835759635)",.csv
RwandaCO2Emissions,1,rwandaco2emissions,s.csv,MIT,"Dive into the heart of environmental data with the ""RwandaCO2Emissions"" dataset, meticulously recording carbon dioxide (CO2) emissions in Rwanda. Each entry, identified by the unique combination of latitude, longitude, year, and week (ID_LAT_LON_YEAR_WEEK), corresponds to the measured CO2 emission for that specific location and time. ",.csv
Ryan's Laptop Inventory and Specifications,1,ryans-laptop-inventory-and-specifications,ryans_laptop_inventory.csv,Apache 2.0,"# Ryan's Laptop Inventory and Specifications
## A Comprehensive Collection of Laptop Models and Specifications from Ryan's Store

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F1937611%2Fcbfa70788f7fa6933f1953800e1ea918%2Fcase1_1.jpg?generation=1715700898540756&alt=media)

This dataset contains detailed information on laptops available at Ryan's store. It includes the following attributes:

- **Link**: URL link to the laptop product page.
- **Brand**: The brand of the laptop.
- **Model**: The model name of the laptop.
- **Laptop Series**: The series or product line to which the laptop belongs.
- **Part No**: Part number or product identifier of the laptop.
- **Processor Brand**: The brand of the processor.
- **Processor Type**: The type of processor (e.g., Intel Core i5, AMD Ryzen 7).
- **Processor Model**: The specific model of the processor.
- **Processor Core**: The number of processor cores.
- **RAM**: The amount of RAM (Random Access Memory) in the laptop.
- **RAM Type**: The type of RAM used in the laptop.
- **HDD RPM**: The rotational speed of the hard disk drive (if applicable).
- **Installed SSD Type**: The type of SSD (Solid State Drive) installed in the laptop.
- **Graphics Chipset**: The chipset of the graphics card.
- **Graphics Memory Accessibility**: Accessibility of the graphics memory (e.g., dedicated, integrated).
- **Graphics Memory**: The amount of graphics memory.
- **Display Size (Inch)**: The size of the laptop display in inches.
- **Display Type**: The type of display technology (e.g., LED, LCD).
- **Display Resolution**: The resolution of the display.
- **Touch Screen**: Indicates whether the laptop has a touchscreen feature.
- **Optical Drive**: Presence of an optical drive (e.g., DVD-ROM).
- **HDMI Port**: Presence of an HDMI port.
- **LAN**: Presence of LAN (Local Area Network) port.
- **Finger Print Sensor**: Presence of a fingerprint sensor for biometric authentication.
- **Operating System**: The operating system pre-installed on the laptop.
- **Color**: The color of the laptop.
- **Weight (Kg)**: The weight of the laptop in kilograms.
- **Power Adapter**: Specifications of the laptop's power adapter.
- **Warranty**: Warranty information for the laptop.
- **Country Of Origin**: The country where the laptop was manufactured.

This dataset provides valuable insights for consumers, retailers, and analysts interested in laptop specifications and market trends.",.csv
S&P 500 ESG Risk Ratings,1,s-and-p-500-esg-risk-ratings,SP 500 ESG Risk Ratings.csv,CC0-1.0,"This dataset exclusively showcases companies from the S&P 500 index. Researchers, investors, analysts, and policy-makers can utilize this dataset to gain insights into the ESG performance and risk profiles of these major corporations. Whether exploring trends, conducting ESG assessments, or making informed investment decisions, this dataset serves as a valuable resource for comprehending the sustainability and governance practices of S&P 500 companies.",.csv
S&P 500 Historical Data,1,sp-500-historical-data,SPX.csv,DbCL-1.0,"### Context

Historical data of S&P 500 Index 


### Content

This dataset includes the historical data of S&P 500 index from 1927 to 2020 with columns of date, opening price, highest price, lowest price, closing price, adjusted closing price, and the number of shares traded each day. 


### Acknowledgements

https://finance.yahoo.com/


### Inspiration

Inspired from this dataset: https://www.kaggle.com/borismarjanovic/price-volume-data-for-all-us-stocks-etfs",.csv
S4E03 - leaderboard scores,1,s4e03-leaderboard-scores,S4P03_leaderboard_scores.csv,MIT,"Leaderboard scores for the **Steel Plate Defect Prediction** competition which is part of Playground Series - Season 4, Episode 3. Data was web-scrapped on 2024-04-01.",.csv
SEER Breast Cancer Data,1,seer-breast-cancer-data,SEER Breast Cancer Dataset .csv,Attribution 4.0 International (CC BY 4.0),"This dataset of breast cancer patients was obtained from the 2017 November update of the SEER Program of the NCI, which provides information on population-based cancer statistics. The dataset involved female patients with invasive breast cancer who were diagnosed between 2000 and 2017. The dataset includes information on the patient's age, race, ethnicity, stage of cancer, tumor size, grade, and treatment.

The data is available for sharing under the Creative Commons Attribution 4.0 International License. To share the data, please cite the dataset as follows:

Citation:
JING TENG, January 18, 2019, ""SEER Breast Cancer Data"", IEEE Dataport, doi: https://dx.doi.org/10.21227/a9qy-ph35.",.csv
SEWA Energy Demand Forecasting,1,sewa-energy-demand-forecasting,SEWA_energy.csv,CC-BY-SA-4.0,"## SEWA Weather and Power Consumption Dataset for 2021

This dataset, curated by Mohammed Saeed in 2023, presents electricity demand forecasting data for the Sharjah Electricity and Water Authority (SEWA) for the years 2020 and 2021. The dataset is hosted on Mendeley Data and is version 2.

The dataset contains a comprehensive collection of features relevant to electricity demand forecasting, including historical load data, meteorological factors, economic indicators, and other relevant parameters. Researchers, analysts, and practitioners interested in energy demand forecasting, predictive modeling, and policy analysis can leverage this dataset for various research purposes.

Please note that while the data has been adapted and cleaned for the year 2021, it retains its integrity and usefulness for analyzing electricity demand patterns in the SEWA region. This dataset only contains the data for the year 2021.

This dataset provides comprehensive weather and power consumption data for the entire year, from 1 Jan 2021 to 31 Dec 2021. It includes daily records of maximum and minimum temperature (in Celsius), maximum and minimum humidity levels (as a percentage), actual temperature (in Celsius), humidity (as a percentage), SEWA minimum load (in megawatts), SEWA peak load (in megawatts), and SEWA energy consumption per hour (in megawatt-hours).

The weather data covers various meteorological parameters such as temperature and humidity, while the power consumption data pertains to SEWA (Sharjah Electricity and Water Authority) load and energy consumption. This dataset can be valuable for researchers, analysts, and stakeholders interested in studying the relationship between weather patterns and electricity consumption, as well as for developing predictive models for energy demand forecasting.

Columns:

- Date: Date of the record
- Day: Day of the week
- MAX Tem: Maximum temperature of the day (in Celsius)
- Min Tem: Minimum temperature of the day (in Celsius)
- Max Hum: Maximum humidity of the day (as a percentage)
- Min Hum: Minimum humidity of the day (as a percentage)
- Temp: Average temperature (in Celsius)
- Hum: Average humidity (as a percentage)
- SEWA MIN LOAD(MW): SEWA minimum load (in megawatts)
- SEWA Peak Load(MW): SEWA peak load (in megawatts)
- SEWA Energy/hr.: SEWA energy consumption per hour (in megawatt-hours)

This dataset can be utilized for various analyses, including but not limited to weather trend analysis, energy consumption patterns, load forecasting, and climate impact studies.

Citation:
jawad, Mohammed Saeed (2023), “SEWA Electricity Deman Forecasting -- 2020 and 2021”, Mendeley Data, V2, doi: 10.17632/4rjc87zrd3.2",.csv
SF Restaurant Scores - LIVES Standard,1,sf-restaurant-scores-lives-standard,restaurant-scores-lives-standard.csv,ODbL-1.0,"### Content  

The Health Department has developed an inspection report and scoring system. After conducting an inspection of the facility, the Health Inspector calculates a score based on the violations observed. Violations can fall into:high risk category: records specific violations that directly relate to the transmission of food borne illnesses, the adulteration of food products and the contamination of food-contact surfaces.moderate risk category: records specific violations that are of a moderate risk to the public health and safety.low risk category: records violations that are low risk or have no immediate risk to the public health and safety.The score card that will be issued by the inspector is maintained at the food establishment and is available to the public in this dataset.
San Francisco's LIVES restaurant inspection data leverages the LIVES Flattened Schema (https://goo.gl/c3nNvr), which is based on LIVES version 2.0, cited on Yelp's website (http://www.yelp.com/healthscores).  

### Context  

This is a dataset hosted by the city of San Francisco. The organization has an open data platform found [here](https://data.sfgov.org) and they update their information according the amount of data that is brought in. Explore San Francisco's Data using Kaggle and all of the data sources available through the San Francisco [organization page](https://www.kaggle.com/san-francisco)!  

* Update Frequency: This dataset is updated daily.

### Acknowledgements

This dataset is maintained using Socrata's API and Kaggle's API. [Socrata](https://socrata.com/) has assisted countless organizations with hosting their open data and has been an integral part of the process of bringing more data to the public.  

[Cover photo](https://unsplash.com/photos/EkwOre9Oqhc) by [Autumn Goodman](https://unsplash.com/@auttgood) on [Unsplash](https://unsplash.com/)  
_Unsplash Images are distributed under a unique [Unsplash License](https://unsplash.com/license)._",.csv
SINASC - Rondônia 2019,1,sinasc-sistema-de-informao-sobre-nascidos-vivos,SINASC_RO_2019.csv,CC0-1.0,"# SINASC Dataset Description - Rondônia, Brazil

## Overview:
O conjunto de dados contém informações detalhadas sobre os nascidos vivos registrados no Sistema de Informação sobre Nascidos Vivos (SINASC) do estado de Rondônia, Brasil em 2019. Este conjunto de dados fornece uma visão geral das características demográficas e clínicas dos recém-nascidos e das suas mães.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F6702943%2Fdd19592e3b421b15398021d0067dc4e7%2FCopetina.png?generation=1714849888987306&alt=media)

- **IDADEMAE**: Idade da mãe.
- **ESTCIVMAE**: Estado civil da mãe.
- **ESCMAE**: Escolaridade da mãe.
- **QTDFILVIVO**: Quantidade de filhos vivos.
- **QTDFILMORT**: Quantidade de filhos mortos.
- **GESTACAO**: Tempo de gestação.
- **GRAVIDEZ**: Número de gravidezes.
- **PARTO**: Tipo de parto.
- **CONSULTAS**: Número de consultas durante a gravidez.
- **DTNASC**: Data de nascimento do bebê.
- **HORANASC**: Hora de nascimento do bebê.
- **SEXO**: Sexo do bebê.
- **APGAR1**: Nota de Apgar no primeiro minuto.
- **APGAR5**: Nota de Apgar no quinto minuto.
- **RACACOR**: Raça/cor do bebê.
- **PESO**: Peso do bebê ao nascer.
- **IDANOMAL**: Indicador de anomalia.
- **DTCADASTRO**: Data de cadastro.
- **NATURALMAE**: Naturalidade da mãe.
- **DTNASCMAE**: Data de nascimento da mãe.
- **RACACORMAE**: Raça/cor da mãe.
- **QTDGESTANT**: Quantidade de gestações.
- **QTDPARTNOR**: Quantidade de partos normais.
- **QTDPARTCES**: Quantidade de partos cesáreos.
- **IDADEPAI**: Idade do pai.
- **CONSPRENAT**: Consultas pré-natais.
- **MESPRENAT**: Mês das consultas pré-natais.
- **munResNome**: Nome do município de residência.
- **munResUf**: UF do município de residência.
- **munResLat**: Latitude do município de residência.
- **munResLon**: Longitude do município de residência.
- **munResAlt**: Altitude do município de residência.
- **munResArea**: Área do município de residência.
- **DTNASC_DIA**: Dia de nascimento do bebê.
- **DTNASC_MES**: Mês de nascimento do bebê.
- **DTCADASTRO_DIA**: Dia de cadastro.
- **DTCADASTRO_MES**: Mês de cadastro.
- **DTNASCMAE_DIA**: Dia de nascimento da mãe.
- **DTNASCMAE_MES**: Mês de nascimento da mãe.",.csv
SMILE Twitter Emotion Dataset,1,smile-twitter-emotion-dataset,smile-annotations-final.csv,Attribution 3.0 Unported (CC BY 3.0),"## SMILE Twitter Emotion dataset

This dataset is collected and annotated for the SMILE project http://www.culturesmile.org. This collection of tweets mentioning 13 Twitter handles associated with British museums was gathered between May 2013 and June 2015. It was created for the purpose of classifying emotions, expressed on Twitter towards arts and cultural experiences in museums. 

It contains 3,085 tweets, with 5 emotions namely anger, disgust, happiness, surprise and sadness. Please see our paper ""SMILE: Twitter Emotion Classification using Domain Adaptation"" for more details of the dataset.

License: The annotations are provided under a CC-BY license, while Twitter retains the ownership and rights of the content of the tweets.",.csv
SMS Spam Collection (Text Classification),1,sms-spam-collection-a-more-diverse-dataset,train.csv,CC0-1.0,"# SMS Spam Collection (Text Classification)
### SMS labeled messages that have been collected for mobile phone spam research
_____

### Source
&gt; **Huggingface Hub:** [link](https://huggingface.co/datasets/sms_spam)

### About this dataset
&gt; The SMS Spam Collection v.1 is a set of SMS messages that have been collected and labeled as either spam or not spam. This dataset contains 5574 English, real, and non-encoded messages. The SMS messages are thought-provoking and eye-catching. The dataset is useful for mobile phone spam research

### How to use the dataset

### Research Ideas
&gt; - This dataset could be used to train a machine learning model to classify SMS messages as spam or not spam.
&gt; - This dataset could be used to develop a tool that can automatically identify and block spam messages.
&gt; - This dataset could be used to study the characteristics of spam messages and develop strategies for identifying and avoiding them

### Acknowledgements
&gt; _This dataset is used to train a machine learning model to classify SMS messages as spam or not spam.
&gt; 
&gt; The SMS Spam Collection v.1 is a public set of SMS labeled messages that have been collected for mobile phone spam research. This dataset contains 5574 English, real, and non-encoded messages, tagged as being legitimate (ham) or spam. The dataset has been collected from various sources and is released under the CC BY-SA 4.0 license by Kaggle user Almeida et al._

&gt; 
&gt; 
&gt; ### License
&gt; 
&gt; 
&gt; &gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
&gt; &gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: train.csv**
| Column name   | Description                                                                   |
|:--------------|:------------------------------------------------------------------------------|
| **sms**       | The text of the SMS message. (String)                                         |
| **label**     | The label for the SMS message, indicating whether it is ham or spam. (String) |

",.csv
SMS Spam Dataset,1,spam-text-messages-dataset,spam_texts.csv,Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0),"# Spam Text Messages Dataset

The SMS spam dataset contains a collection of text messages. The dataset includes a diverse range of spam messages, including *promotional offers, fraudulent schemes, phishing attempts, and other forms of unsolicited communication*.

# 💴 For Commercial Usage: To discuss your requirements, learn about the price and buy the dataset, leave a request on **[TrainingData](https://trainingdata.pro/datasets/spambase?utm_source=kaggle&utm_medium=cpc&utm_campaign=spam-text-messages-dataset)** to buy the dataset

Each SMS message is represented as a string of text, and each entry in the dataset also has a link to the corresponding screenshot. The dataset's content represents real-life examples of spam messages that users encounter in their everyday communication.

### The dataset's possible applications:
- spam detection
- fraud detection
- customer support automation
- trend and sentiment analysis
- educational purposes
- network security

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F618942%2Fbb49e9783917bb524ecd11b085375a28%2FMacBook%20Air%20-%201%20(2).png?generation=1689765543776590&alt=media)

# Content

- **images**: includes screenshots of spam messages
- **.csv** file: contains information about the dataset

### File with the extension .csv

includes the following information:

- **image**: link to the screenshot with the spam message,
- **text**: text of the spam message

# Spam messages might be collected in accordance with your requirements.

# 💴 Buy the Dataset: This is just an example of the data. Leave a request on **[https://trainingdata.pro/datasets](https://trainingdata.pro/datasets/spambase?utm_source=kaggle&utm_medium=cpc&utm_campaign=spam-text-messages-dataset)** to discuss your requirements, learn about the price and buy the dataset.

## **[TrainingData](https://trainingdata.pro/datasets/spambase?utm_source=kaggle&utm_medium=cpc&utm_campaign=spam-text-messages-dataset)** provides high-quality data annotation tailored to your needs

*keywords: sms spam collection, labeled messages, mobile phone spam, spam sms dataset, sms spam classification, spam or not-spam, spam sms database, spam detection system, sma spamming data set, spam filtering system, spambase, feature extraction, spam ham email dataset, classifier, machine learning algorithms, cybersecurity, text dataset, sentiment analysis, llm dataset, language modeling, large language models, text classification, text mining dataset, natural language texts, nlp, nlp open-source dataset, text data*",.csv
SMS Spam Detection Dataset,1,sms-spam-detection-dataset,spam_sms.csv,MIT,"Description:
In an era where communication is predominantly digital, SMS spam poses a significant challenge, cluttering inboxes and sometimes even posing security risks. Our ""SMS Spam Detection Dataset"" is tailored to empower machine learning enthusiasts, data scientists, and researchers to tackle this pervasive issue using the power of AI. This dataset is meticulously curated to provide a robust foundation for developing and benchmarking spam detection models.

Dataset Overview:
The dataset comprises two columns: 'Text' and 'Label', containing the SMS content and corresponding labels ('ham' for regular messages and 'spam' for unsolicited messages), respectively. With a diverse collection of messages, this dataset serves as an ideal playground for exploring various text processing and machine learning techniques.

Potential Uses:
Spam Detection Models: Use the dataset to train binary classification models capable of distinguishing between spam and ham messages with high accuracy.
Natural Language Processing (NLP) Techniques: Experiment with different NLP methodologies, including tokenization, stemming, lemmatization, and the application of word embeddings or transformers to understand the nuances of SMS language.
Feature Engineering: Explore how different features, such as message length, punctuation usage, and keyword frequency, can impact model performance.
Model Benchmarking: Compare the effectiveness of various machine learning algorithms, from classical approaches like Naive Bayes and SVM to advanced deep learning models like LSTM and BERT.

Challenges & Opportunities:
While the dataset offers a straightforward binary classification task, the real challenge lies in dealing with the nuances of natural language, including slang, abbreviations, and the evolving nature of spam tactics. Innovators in the field can explore advanced techniques like transfer learning and semi-supervised models to push the boundaries of what's possible in spam detection.",.csv
SONAR MINE DATASET,1,sonar-mine-dataset,sonar data.csv,CC0-1.0,"### Context
Dataset is collection of sonar data.  Which Predict weather we have found rock or mine 
### Content
It contains various data column which consist sonar data. Last column tells us weather it has found rock or mine.
Target Column consist of :
R - &gt;  Rock
M -&gt; Mine


###Thank you !!
Please upvote if you liked my work 👍👍",.csv
Sachin Tendulkar All International Centuries,1,sachin-tendulkar-all-international-centuries,Sachin_Tendulkar_Centuries.csv,MIT,"**Sachin Tendulkar**, often regarded as one of the **greatest cricketers** of all time, is a former **Indian international cricketer**. He is known for his exceptional batting skills and holds numerous records in the sport, including being the first player to score **100 international centuries**.

The dataset captures details of each century scored by **Sachin Tendulkar** in international cricket. It includes the following comprehensive information : 

- **S.No.** : Serial number or index of the century in chronological order.
- **Date** : Date on which Sachin scored the century.
- **Score** : Runs scored by Sachin in that innings.
- **Strike Rate** : Strike rate at which Sachin scored (calculated as runs per 100 balls).
- **Type of Match** : Indicates the format of the match (Test, ODI, T20).
- **Position** : Batting position of Sachin in that innings.
- **Innings** : Innings number (1st or 2nd) played by Sachin.
- **Dismissed** : Indicates whether Sachin was dismissed (Yes) or remained not out (No).
- **Man of the Match** : Whether Sachin was awarded Man of the Match for his performance in that match (Yes or No).
- **Captain** : Indicates if Sachin was the captain of the team during that match (Yes or No).
- **Against** : Name of the opposition team against whom Sachin scored the century.
- **Venue** : Name of the cricket ground where the match was played.
- **H/A/N** : Indicates if the match was played at Home (India), Away (outside India), or Neutral venue.
- **Result** : Outcome of the match for Sachin's team (Won or Lost).

This dataset provides valuable insights into Sachin century-scoring performances and can be used for statistical analysis and cricket enthusiasts interested in his career milestones.",.csv
Salaries in Data Science,1,salaries-in-data-science,ds_salaries.csv,CC0-1.0,"Title: Data Science Salary and Employment Dataset

Description: This dataset contains information about salaries and employment characteristics across various roles and industries. It includes data on work year, experience level, employment type, job title, salary, salary currency, salary converted to USD, employee residence, remote work ratio, company location, and company size.

Columns:

- work_year: The year the salary was paid.
- experience_level: Entry-level / Junior, Mid-level / Intermediate, Senior-level / Expert, Executive-level / Director.
- employment_type: Part-time, Full-time, Contract, Freelance.
- job_title: The role worked in during the year.
- salary: Total gross salary amount paid.
- salary_currency: Currency of the salary paid as an ISO 4217 currency code.
- salary_in_usd: Salary in USD (FX rate divided by average USD rate for the respective year).
- employee_residence: Employee's primary country of residence during the work year as an ISO 3166 country code.
- remote_ratio: Overall amount of work done remotely (0 for no remote work, 50 for partially remote, 100 for fully remote).
- company_location: Country of the employer's main office or contracting branch as an ISO 3166 country code.
- company_size: Average number of people that worked for the company during the year (S for less than 50 employees, M for 50 to 250 employees, L for more than 250 employees).

Acknowledgements: Special thanks to ai-jobs.net Salaries for aggregating this data!",.csv
Salary Data with Age and Experience,1,salary-data-with-age-and-experience,Salary_Data.csv,other,This data shows the change in salary based on years of experience and the age of the person. Use this dataset to create machine learning models for prediction of salaries of people based on their age and years of experience.,.csv
Salary Dataset - Simple linear regression,1,salary-dataset-simple-linear-regression,Salary_dataset.csv,CC0-1.0,"## Dataset Description
Salary Dataset in CSV for Simple linear regression. It has also been used in Machine Learning A to Z course of my series.

## Columns
- #
- YearsExperience
- Salary",.csv
Salary Dataset Of Business Levels,1,salary-dataset-of-business-levels,salary.csv,CC0-1.0,"In This Dataset we have 3 columns and ten rows and its about a Company Where we will see the levels and how much salary is offered by the company for each level.
We can use this dataset for Machine Learning Predictions.",.csv
Salary Prediction Data,1,salary-prediction-data,salary_prediction_data.csv,Apache 2.0,"The ""Salary Prediction Dataset"" is a synthetic dataset generated for the purpose of exploring salary prediction tasks. It contains simulated data reflecting various factors influencing salary levels such as education, experience, location, job title, age, and gender. This dataset can be utilized for predictive modeling tasks to estimate salaries based on these factors.",.csv
Salary Prediction dataset,1,salaly-prediction-for-beginer,Salary Data.csv,Attribution 4.0 International (CC BY 4.0),"This dataset contains information about the salaries of employees at a company. Each row represents a different employee, and the columns include information such as age, gender, education level, job title, years of experience, and salary.

Columns:

**Age:**  This column represents the age of each employee in years. The values in this column are numeric.

**Gender:** This column contains the gender of each employee, which can be either male or female. The values in this column are categorical.

**Education Level:** This column contains the educational level of each employee, which can be high school, bachelor's degree, master's degree, or PhD. The values in this column are categorical.

**Job Title:** This column contains the job title of each employee. The job titles can vary depending on the company and may include positions such as manager, analyst, engineer, or administrator. The values in this column are categorical.

**Years of Experience:** This column represents the number of years of work experience of each employee. The values in this column are numeric.

**Salary:** This column represents the annual salary of each employee in US dollars. The values in this column are numeric and can vary depending on factors such as job title, years of experience, and education level.

** The purpose of creating this dataset is solely for educational use, and any commercial use is strictly prohibited
and this dataset was large language models generated and not collected from actual data sources.",.csv
Sales Data for Economic Data Analysis,1,sales-data-for-economic-data-analysis,salesforcourse-4fe2kehu.csv,DbCL-1.0,"- The dataset contains information about sales transactions, including details such as the customer's age, gender, location, and the products sold. 
- The dataset includes data on both the cost of the product and the revenue generated from its sale, allowing for calculations of profit and profit margins.
- The quantity column provides information on the volume of products sold, which could be used to analyze sales trends over time.
- The dataset includes information on customer age and gender, which could be used to analyze purchasing behavior across different demographic groups.
- The dataset likely includes both numeric and categorical data, which would require different types of analysis and visualization techniques.
Overall, the dataset appears to provide a comprehensive view of sales transactions, with the potential for analysis at multiple levels, including by product, customer, and location.

## Column Descriptors

1. Year: This column represents the year in which the transaction occurred. It could be used to track trends over time or to filter the data based on a specific year or range of years.

2. Month: This column represents the month in which the transaction occurred. It could be used to track trends over time or to filter the data based on a specific month or range of months.

3. Customer Age: This column represents the age of the customer. It could be used to segment customers based on age ranges or to analyze the purchasing behavior of different age groups.

4. Customer Gender: This column represents the gender of the customer. It could be used to segment customers based on gender or to analyze the purchasing behavior of different genders.

5. Country: This column represents the country where the transaction occurred. It could be used to analyze sales by country or to filter the data based on a specific country or range of countries.

6. State: This column represents the state where the transaction occurred. It could be used to analyze sales by the state or to filter the data based on a specific state or range of states.

7. Product Category: This column represents the broad category of the product sold. It could be used to analyze sales by product category or to filter the data based on a specific product category.

8. Sub Category: This column represents the specific subcategory of the product sold. It could be used to analyze sales by subcategory or to filter the data based on a specific subcategory.

9. Quantity: This column represents the quantity of the product sold. It could be used to analyze sales volume or to calculate the total revenue generated from a particular product or product category.

10. Unit Cost: This column represents the cost of producing or acquiring one unit of the product. It could be used to calculate profit margins or to compare the costs of different products or product categories.

11. Unit Price: This column represents the price at which one unit of the product was sold. It could be used to analyze pricing strategies or to compare the prices of different products or product categories.

12. Cost: This column represents the total cost of the products sold, which is calculated as the product of the quantity and the unit cost. It could be used to analyze the cost structure of the business or to calculate the profit margin of each sale.

13. Revenue: This column represents the total revenue generated by the sales, which is calculated as the product of the quantity and the unit price. It could be used to analyze the overall sales performance of the business or to calculate the profit generated by each sale.

",.csv
Sales for Furniture Store,1,sales-for-furniture-store,Super_Store_data.csv,Apache 2.0,"For a retail furniture store, predicting future sales is critical to avoiding inventory issues like overstocking 
or under-stocking. The challenge lies in utilizing time series data from the superstore dataset to forecast 
furniture sales for the next year accurately. This predictive insight ensures an optimal customer 
experience, avoids losses, and maintains store sustainability.",.csv
Sales of a Supermarket,1,sales-of-a-supermarket,supermarket_sales.csv,Apache 2.0,"**Context**

The growth of supermarkets in most populated cities are increasing and market competitions are also high. The dataset is one of the historical sales of supermarket company which has recorded in 3 different branches for 3 months data. Predictive data analytics methods are easy to apply with this dataset.

**Attribute information**

Invoice id: Computer generated sales slip invoice identification number.

Branch: Branch of supercenter (3 branches are available identified by A, B and C).

City: Location of supercenters.

Customer type: Type of customers, recorded by Members for customers using member card and Normal for without member card.

Gender: Gender type of customer.

Product line: General item categorization groups - Electronic accessories, Fashion accessories, Food and beverages, Health and beauty, Home and lifestyle, Sports and travel.

Unit price: Price of each product in $.

Quantity: Number of products purchased by customer.

Tax: 5% tax fee for customer buying.

Total: Total price including tax.

Date: Date of purchase (Record available from January 2019 to March 2019).

Time: Purchase time (10am to 9pm).

Payment: Payment used by customer for purchase (3 methods are available – Cash, Credit card and Ewallet).

COGS: Cost of goods sold.

Gross margin percentage: Gross margin percentage.

Gross income: Gross income.

Rating: Customer stratification rating on their overall shopping experience (On a scale of 1 to 10).


**Purpose**
This dataset can be used for predictive data analytics purpose.",.csv
Salmon catch statistics for Scotland (1952–2022).,1,salmon-catch-statistics-for-scotland-19522022,SalmonandSeaTroutNets1952-2022.csv,other,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16192307%2F3e910feebf3c88d41dacc431ffb5f2dc%2F700933_1200x99999x90.jpg?generation=1709642194665843&alt=media)

**Fishery districts and regions**

For the purposes of these statistics, Marine Scotland (MS) combine data geographically into 109 Districts which are further aggregated into 11 regions. Districts correspond either to a single river catchment together with adjacent coast or to groups of neighbouring river catchments and associated coastline. Where Districts have more than one river draining to the coast, these are split into Assessment Areas for the purpose of the annual assessment of stocks and development of Conservation of Salmon (Scotland) Regulations. Outflow points for Assessment Areas are available in the consultation for the proposed river gradings.

The blank area on the map below corresponds to that part of the Border Esk catchment located in Scotland. Functions relating to the management of salmon and sea trout in respect of this catchment rest with UK Ministers. Similarly, the parts of the Tweed catchment that lie in England are the responsbility of Scottish Ministers for salmon and sea trout management purposes. Interactive maps of the Statistical Regions, Districts and assessment areas are available via the Marine Scotland Information pages for Salmon and Sea Trout Fishing.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16192307%2F1d39fc55dc69e98678260340c80b7913%2FSCT05234088621_g01.png?generation=1709641064886993&alt=media)

Regions (black boundary) and disticts (white boundary)

**The Fisheries**

All Scottish salmon and sea trout fisheries fall into three broad categories:

**Fixed Engine** - fisheries are generally restricted to the coast where they must be set outside estuary limits. Poke nets and haaf nets are restricted to the Solway Region where they may be fished on the coast or within estuaries. Historically, cruives operated within rivers and were classified as fixed engines. No cruives are currently active.

**Net and Coble** - fisheries generally operate in estuaries and the lower reaches of rivers.

**Rod and Line** - fisheries comprise recreational angling activities which generally take place within rivers.

**Catches**

Currently each fishery is required to provide the numbers and total weights of both wild and farmed multi sea-winter (MSW) and one sea-winter (1SW) salmon, as well as sea trout. This includes caught and retained fish and those fish caught and released back into the river. Data is published as reported. No attempt is made to correct for 'grilse error', the mis-classification of fish between 1SW salmon (grilse) and MSW salmon categories.

**Fishing effort**

Fisheries are also required to provide monthly fishing effort data. Fixed engine fisheries report minimum and maximum numbers of traps deployed while net and coble fisheries report the minimum and maximum number of crews that operated. This information is used to derive the median monthly effort data. Netting effort data from the Solway region (haaf and poke nets) is omitted when calculating the national index for fixed engine fishing effort. Rod fisheries have reported rod days effort per month since 2019.

**Continuity of the data collected**

Aggregate monthly data has been collected annually from Scottish salmon and sea trout fisheries since 1952.

The number and weight of wild MSW and 1SW salmon caught and retained by both net and rod fisheries have been collected throughout the time series as has netting effort. Between 1952 and 1964, single values were reported each month for both the numbers of traps and crew deployed and the numbers of individuals employed in netting. Since 1965, however, net fisheries have been required to report the maximum and minimum numbers for each metric.

The number and weight of sea trout caught and retained by both net and rod fisheries have also been collected throughout the time series. Between 1952 and 1993, fisheries were simply required to report sea trout taken as a single category. Between 1994 and 2003, fisheries were required to report sea trout weighing less than 0.5 kg separately from those weighing greater than 0.5kg. During both periods, any reports of finnock catches were disregarded.

Finnock are sea trout which have spent less than a year at sea before making their first return to fresh water. They may also be known as whitling or herling. Since 2004, fisheries have been required to report finnock catches and other sea trout as separate categories. Marine Scotland routinely provide a historical time series of sea trout data aggregated over all categories except those reported as finnock, which are provided separately. Since 1994, the number and weight of farmed salmon taken by net and rod and the number and weight of salmon and sea trout released by the rod fishery has been collected. Collection of the number and weight of released net caught fish began in 2021.

**Columns:**

**District**
Description: Salmon Fishery District identifier
Type: categorical
Levels: 97
Note: Single Salmon Fishery District or geographically-coherent group of Salmon Fishery Districts. No net catch or effort has been reported from Districts Aline, Balgay, Clayburn, Drummachloy, Gour, Grudie, Howmore, Irvine, Kinloch, Kishorn, Resort and Shetland.

**District ID**
Description: Numerical Salmon Fishery District identifier
Type: categorical
Levels: 97
Note: orders Salmon Fishery Disticts alphabetically. No net catch or effort has been reported from District IDs 2 (Aline), 12 (Balgay), 21 (Clayburn), 33 (Drummachloy), 48 (Gour), 50 (Grudie), 55 (Howmore), 60 (Irvine), 63 (Kinloch), 65 (Kishorn), 87 (Resort) and 108 (Shetla****nd).

**Report order**
Description: spatial ordering of Reporting Areas
Type: categorical
Levels: 97
Note: orders Salmon Fishery Districts spatially, counter-clockwise from Tweed. No net catch or effort has been reported from the Districts with Report Order 32 (Kinloch), 34 (Grudie), 50 (Balgay), 52 (Kishorn), 64 (Aline), 66 (Gour), 84 (Drummachloy), 87 (Irvine), 101 (Shetland), 105 (Resort), 107 (Clayburn) and 109 (Howmore).

**Region**
Description: Salmon Fishery Region
Type: categorical
Levels: Clyde Coast, East, Moray Firth, North, North East, North West, Orkney, Outer Hebrides, Solway, West Coast

**Method**
Description: fishing method
Type: categorical
Levels: Fixed Engine: Retained, Fixed Engine: Released, Net and Coble: Retained, Net and Coble: Released
Note: In 2021, released net caught fish were required to be reported for the first time

**Year**
Description: year of season fish were reported caught
Type: discrete
Range: 1952 to 2022
Note: In 2021, released net caught fish were required to be reported for the first time

**Month**
Description: month fish were reported caught
Unit:
Type: discrete
Range: February to November

**Month number**
Description: number of month that fish were reported caught
Type: discrete
Range: 2 to 11

**Wild MSW number**
Description: number of wild multi sea-winter salmon reported caught
Type: continuous
Range: 0 to 18942

**Wild MSW weight (kg)**
Description: weight of wild multi sea-winter salmon reported caught
Unit: kg
Type: continuous
Range: 0 to 102188.0

**Wild 1SW number**
Description: number of wild one sea-winter salmon reported caught
Type: continuous
Range: 0 to 34633

**Wild 1SW weight (kg)**
Description: weight of wild one sea-winter salmon reported caught
Unit: kg
Type: continuous
Range: 0 to 103010.8

**Sea trout number**
Description: number of sea trout reported caught
Type: continuous
Range: 0 to 26126
Note: Categories used to report sea trout data have varied throughout the time series and are detailed in “Collecting the Marine Scotland Salmon and Sea.

**Sea trout weight (kg)**
Description: weight of sea trout reported caught
Unit: kg
Type: continuous
Range: 0 to 46142.6
Note: Categories used to report sea trout data have varied throughout the time series and are detailed in “Collecting the Marine Scotland Salmon and Sea.

**Finnock number**
Description: number of finnock reported caught
Type: continuous
Range: 0 to 5
Note: Finnock (may also be known as whitling or herling) have been reported since 2004 and are not included in the sea trout figures.

**Finnock weight (kg)**
Description: weight of finnock reported caught
Unit: kg
Type: continuous
Range: 0 to 5.7
Note: Finnock (may also be known as whitling or herling) have been reported since 2004 and are not included in the sea trout figures.

**Farmed MSW number**
Description: number of farmed-origin multi sea-winter salmon reported caught
Type: continuous
Range: 0 to 129
Note: Farmed-origin fish have been reported since 1994.

**Farmed MSW weight (kg)**
Description: weight of farmed-origin multi sea-winter salmon reported caught
Unit: kg
Type: continuous
Range: 0 to 621.8
Note: Farmed-origin fish have been reported since 1994.

**Farmed 1SW number**
Description: number of farmed-origin one sea-winter salmon reported caught
Type: continuous
Range: 0 to 209
Note:Farmed-origin fish have been reported since 1994.

**Farmed 1SW weight (kg)**
Description: weight of farmed-origin one sea-winter salmon reported caught
Unit: kg
Type: continuous
Range: 0 to 639.6
Note: Farmed-origin fish have been reported since 1994.

**Netting effort**
Description: summarised as median number of crews/traps
Type: continuous
Range: 0 to 2215.0
Note: To prevent duplication Netting effort is only recorded in Fixed Engine: Retained and Net and Coble: Retained. Fixed engine effort is summarised as median number of traps operated. Net and coble effort is summarised as median number of crews operated.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16192307%2F5f8c5efa8d8854c052704e4373b1a283%2Frabstol_net_flags_19.jpg?generation=1709641610126164&alt=media)",.csv
Sample Sales Data,1,sample-sales-data,sales_data_sample.csv,CC0-1.0,"Sample Sales Data, Order Info, Sales, Customer, Shipping, etc., Used for Segmentation, Customer Analytics, Clustering and More.  Inspired for retail analytics.  This was originally used for Pentaho DI Kettle, But I found the set could be useful for Sales Simulation training. 

Originally Written by María Carina Roldán, Pentaho Community Member, BI consultant (Assert Solutions), Argentina. This work is licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported License.  Modified by Gus Segura June 2014.",.csv
Sample Superstore Dataset,1,sample-supermarket-dataset,SampleSuperstore.csv,CC0-1.0,"### Context

This is a sample superstore dataset, a kind of a simulation where you perform extensive data analysis to deliver insights on how the company can increase its profits while minimizing the losses.

",.csv
Samsung Smartphone Dataset ,1,smartphone-features-dataset,SamsungPhone.csv,Apache 2.0,"This dataset provides comprehensive information about various Samsung smartphones, including their dimensions, system-on-chip (SoC), central processing unit (CPU), graphics processing unit (GPU), RAM, storage capacity, display specifications, battery details, operating system (OS), and camera attributes. Each row represents a different Samsung smartphone model, and the dataset contains valuable data for comparative analysis, research, or exploring the features of these smartphones. With details on multiple key specifications, this dataset is a valuable resource for tech enthusiasts, consumers, and analysts interested in Samsung's mobile offerings.

The dataset offers a structured format for easily comparing and contrasting different Samsung smartphone models, making it a valuable tool for decision-making, market analysis, and understanding the evolving landscape of Samsung's mobile devices.",.csv
San Francisco Building Permits,1,building-permit-applications-data,Building_Permits.csv,DbCL-1.0,"## Background

A building permit is an official approval document issued by a governmental agency that allows you or your contractor to proceed with a construction or remodeling project on one's property. For more details go to https://www.thespruce.com/what-is-a-building-permit-1398344. Each city or county has its own office related to buildings, that can do multiple functions like issuing permits, inspecting buildings to enforce safety measures, modifying rules to accommodate needs of the growing population etc. For the city of San Francisco, permit issuing is taken care by www.sfdbi.org/

Why is this important: In the recent past, several posts and blogs highlighted that main discrepancy in demand and supply in real estate industry is due to delays in issuing building permits. Refer:
https://www.trulia.com/blog/trends/elasticity-2016/  - Introduces concept of elasticity, and nice scatterplot of various cities. A good data story!
https://biv.com/article/2014/11/city-building-permit-delays-costing-developers-tim

## Content

The data was downloaded for the dates ranging from Jan 1st, 2013 to Feb 25th, 2018 using the filter in San Francisco open data portal.  This is the exact link:  https://data.sfgov.org/Housing-and-Buildings/Building-Permits/i98e-djp9/data
There are 43 columns and close to 200k records in the downloaded version (kept here). Description is separately uploaded as dictionary.

## Thanks to

1.  San Francisco Open Data portal for keeping and updating this data every Saturday.
2. A fellow Kaggler and mentor Rajiv Shah for encouraging me to think of business problems
3. A friend, Nandan PC, for suggesting to post it here and another friend Andrew Maguire for encouraging

## Challenges

May be some of the questions that can be answered are:

Can you try predicting permit issue times for various permit types? Which ones matter more?
Can you suggest which is the best week day to visit Department of building inspections, based on this data?
Can you conclude anything on the city's developments based on this data?

Waiting to hear from all enthusiastic Kagglers! Enjoy..",.csv
San Francisco Library Usage,1,sf-library-usage-data,Library_Usage.csv,other,"### Context 

San Francisco's Integrated Library System (ILS) is composed of bibliographic records including inventoried items, patron records, and circulation data. The data is used in the daily operation of the library, including circulation, online public catalog, cataloging, acquisitions, collection development, processing, and serials control. This dataset represents the usage of inventoried items by patrons (~420K records).

### Content

The dataset includes approximately 420,000 records, with each record representing an anonymized library patron. Individual columns include statistics on the type code and age of the patron, the year the patron registered (only since 2003), and how heavily the patron has been utilizing the library system (in terms of number of checkouts) since first registering.

For more information on specific columns refer to the [official data dictionary][1] and the information in the Column Metadata on the `/Data` tab.

### Acknowledgements

The data is provided by [SF Public Library][3] via the [San Francisco Open Data Portal](https://data.sfgov.org/d/qzz6-2jup), under the PDDL 1.0 ODC Public Domain Dedication and Licence ([PDDL][4]).

Photo via Flickr [Kolya Miller][5] [(CC BY-NC-SA 2.0)][6].

### Inspiration

* What attributes are most associated with library activity (# of checkouts, # of renewals)?
* Can you group the data into type of patrons?  What classifiers would you use to predict patron type?

  [1]: https://data.sfgov.org/api/views/qzz6-2jup/files/72c2070f-7b56-4d14-840a-d1a70f5d0f19?download=true&amp;filename=LIB-0003_DataDictionary_library-usage.xlsx
  [2]: https://data.sfgov.org/Geographic-Locations-and-Boundaries/Supervisor-Districts-as-of-April-2012/xz9b-wyfc
  [3]: http://sfpl.org/
  [4]: http://opendatacommons.org/licenses/pddl/1.0/
  [5]: https://www.flickr.com/photos/kolya/71123986/
  [6]: https://creativecommons.org/licenses/by-nc-sa/2.0/",.csv
Sanitation,1,sanitation,number-of-deaths-by-risk-factor new.csv,CC0-1.0,"this graph was created in OurdataWorld:

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F4e431afce1b3c86e59bd916ccc95810f%2Fgraph1.png?generation=1714167500327775&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F47815568fdfcebb1ee2bedaed8c110e1%2Fgraph2.png?generation=1714167506513587&alt=media)

Having access to and being able to use safe sanitation facilities is one of our most basic human needs.

Nevertheless, due to a range of barriers, such as lack of availability, affordability, or cultural norms, around 40% of the world’s population do not use safe sanitation facilities. This is a major health risk. Unsafe sanitation is responsible for hundreds of thousands of deaths each year.

In this article, we give an overview of global and national data on the usage of sanitation facilities and its impact on health outcomes.

Unsafe sanitation is a leading risk factor for death
Unsafe sanitation is responsible for hundreds of thousands of deaths each year
Unsafe sanitation is one of the world's largest health and environmental problems – particularly for the poorest in the world.

These estimates of the annual number of deaths attributed to a wide range of risk factors are shown here.

Unsafe sanitation is a leading risk factor for infectious diseases, including cholera, diarrhea, dysentery, hepatitis A, typhoid, and polio.1 It also exacerbates malnutrition and, in particular, childhood stunting. In the chart, we see that it ranks as significant risk factor for death globally.",.csv
Saree Retailers Database in India,1,saree-retailers-database-in-india-april-2021,301-Saree-Garment-Retailer-Database-Sample.csv,other,"_____
# Saree Retailers Database in India
### Accurate Up-to-Date Data for All Types of Business Purposes

By Amresh [[source]](https://data.world/ecommercedataba)
_____

### About this dataset
&gt; This All India Saree Retailers Database is a comprehensive collection of up-to-date information on 10,000 Saree Retailers located all over India. The database is updated in April 2021 and offers an overall accuracy rate of around 90%. 
&gt; 
&gt; For business owners, marketers, and data analysts and researchers, this dataset is an invaluable resource. It contains contact details of store name, contact person names, phone number and email address along with store location information like city state and pin code to help you target the right audience precisely. 
&gt; 
&gt; The database can be accessed in Microsoft Excel (.xlsx) format which makes it easy to read or manipulate the file according to your needs. Apart from this wide range of payment options like Credit/Debit Card; Online Transfer; NEFT; Cash Deposit; Paytm; PhonePe; Google Pay or PayPal allow quick download access within 2-3 business hours. 
&gt; 
&gt; So if you are looking for reliable business intelligence data related to Indian saree retailers that can help you unlock incredible opportunities for your business then make sure to download our All India Saree Retailers Database at the earliest!

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; This dataset provides a comprehensive list of Saree retailers in India, including store name, contact person, email address, mobile number, phone number, address details like city and state along with pin code. It contains 10 thousand records updated in April 2021 with an overall accuracy rate of around 90%. This data can be used to understand customer behaviour as well as to analyse geographical customer pattern.
&gt; 
&gt; Using this dataset you can: 
&gt; - Target specific states or cities where potential customers are located for your Saree business. 
&gt; - Get in touch with local Saree retailers for possible collaborations and partnerships. 
&gt; - Learn more about industry trends from actual store owners who can offer insights into the latest ongoing trends and identify new opportunities for you to grow your business. 
&gt; 4 .Analyse existing competitors’ market share by studying the cities/states where they operate and their contact information such as Mobile Number & Email Ids .  
&gt; 5 .Identify potential new customers for better sales conversion rates by understanding who is already operating in similar products nearby or have similar target audience as yours that help your company reach out to them quickly & effectively using direct marketing techniques such as emails & SMS etc.,

### Research Ideas
&gt; - Creating targeted email campaigns to increase Saree sales: The dataset can be used to create targeted email campaigns that can reach the 10,000 Saree Retailers in India. This will allow businesses to increase sales by directing their message about promotions and discounts directly to potential customers. 
&gt; - Customizing online product recommendations for each retailer: The dataset can be used to identify the specific products that each individual retailer is interested in selling, so product recommendations on an e-commerce website could be tailored accordingly. This would optimize customer experience giving them more accurate and relevant results when searching for a particular item they are looking for while shopping online. 
&gt; - Using GPS technology to generate location-based marketing campaigns: By creating geo-fenced areas around each store using the pin code database, it would be possible to send out marketing messages based on people's physical location instead of just sending them out in certain neighborhoods or cities without regard for store locations within those areas. This could help reach specific customers with relevant messages about products or promotions that may interested them more effectively than a standard marketing campaign with no location targeting involved

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://data.world/ecommercedataba)
&gt; 
&gt;


### License
&gt; 
&gt; 
&gt; See the dataset description for more information.

### Columns

**File: 301-Saree-Garment-Retailer-Database-Sample.csv**

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [Amresh](https://data.world/ecommercedataba).

",.csv
School Student Daily Attendance,1,school-student-daily-attendance,2018-2019_Daily_Attendance_20240429.csv,Apache 2.0,"Daily listing (counts) of students registered, present, absent and released by School DBN.

Each record includes the date, total enrollment, number of students absent, present, and released on that day. This structured data is pivotal for understanding daily attendance trends, student engagement, and the operational dynamics of the school environment over time.

From a data science perspective, this dataset is a treasure trove for analyzing educational trends, attendance patterns, and their correlations with academic performance and other socio-economic factors. Analyzing these patterns over time or across different schools can help in identifying critical issues such as chronic absenteeism, the effectiveness of attendance policies, and the impact of external factors on student attendance.

Various types of analyses can be performed on this dataset to extract meaningful insights:

- **Time Series Analysis**: This involves examining the data across time to identify trends, seasonal patterns, or anomalies in student attendance.
- **Predictive Modeling**: Using historical attendance data to predict future trends. This could help in forecasting future attendance patterns and planning necessary interventions early.
- **Correlation Analysis**: This type of analysis can be used to explore correlations between attendance rates and other variables, possibly external, like local events, weather conditions, or public health issues.
- **Cluster Analysis**: By clustering different days based on attendance figures, schools can categorize 'types' of days (e.g., high attendance vs. low attendance days) and possibly link these to specific events or conditions.



",.csv
School Student Health and Wellbeing,1,school-student-health-and-wellbeing,school-survey-2018-19-1.csv,other,"_____
# School Student Health and Wellbeing
### Physical Activity, Nutrition, Lifestyle, and Emotional Health Behaviors
By data.world's Admin [[source]](https://data.world/dataworldadmin)
_____

### About this dataset
&gt; The ‘My Health, My School’ (MHMS) annual school survey is an invaluable online primary and secondary school pupil survey tool. It is available for students in Years 5, 6, 7, 9 and 11 – with the survey now being extended to include SILC and post-16 settings too. 
&gt; 
&gt; This survey allows schools to measure student health behaviours in order to improve their well-being as it provides an instant snapshot of data on important areas like Healthy Eating, Physical Activity and Sports, Drugs, Alcohol and Tobacco consumption , Sexual Health amongst others. 
&gt; 
&gt; Where blank sections appear on the data set does not mean that there is no information - instead these questions have been directed towards different year groups.  This dataset will provide a comprehensive picture of how school age students perceive their own health and well-being from across key areas such as society values, mental states including feelings associated with being bullied or worried , physical activity levels measured by minutes per week active or whether they partake in certain activities either through college/school or outside it.  Schools can also measure drug use levels weekly basis as well games clubs offered by them which are both enjoyed during break times or lunchtimes. All this taken together should help a school develop a more holistic view of their student’s individual needs when it comes to providing for their physical health as well as day-to-day triggers which may affect their mental wellbeing within the learning environment.

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; 
&gt; - Explore available columns - The first step when utilizing this dataset is to become familiar with the available columns. Take some time to read through the data points that are included in the table so that you know what information you have access too and can plan accordingly when conducting your analysis. 
&gt; - Clean your data - There might be missing or inaccurate data points in your table which will negatively affect any analysis you do on it. Make sure that all of your data is accurate and complete before beginning any type of exploration or analysis! 
&gt; - Choose summary statistics - If you want to summarize large amounts of data quickly, summary statistics like mean or median are great options! These will allow you get an overall snapshot of how students responded to each question without getting lost trying look through all responses individually .  
&gt; - Use visualization tools - Visualization tools such as graphs and charts can help bring new life into the raw numbers in your table! Seeing trends visually can help with understanding patterns in responses more quickly than if relying solely on text-based analysis methods .  
&gt; - Interpret results relative to British values - Finally, remember why we're here: British Values! Once you've conducted your analysis across different questions/data points within this dataset be sure also compare them against relevant aspects/metrics related to British Values so as not get too lost looking at individual findings without understanding their context within Britain's broader culture 

### Research Ideas
&gt; - The dataset can be used to identify any physical activity, social-emotional and mental health issues, or unhealthy behaviours being exhibited by students across different age groups and school/college settings.
&gt; - The data can be analysed to measure the level of understanding of British values among school pupils and the amount of useful information received about them through lessons in school/college.
&gt; - It can also be used to assess how safe students feel in certain places and evaluate the attendance rate of pupils at educational institutions by exploring questions related to missed lessons without ill-health being a factor

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://data.world/dataworldadmin)
&gt; 
&gt;


### License
&gt; 
&gt; 
&gt; See the dataset description for more information.

### Columns

**File: school-survey-2018-19-1.csv**
| Column name                                                                                              | Description                                                                                                                            |
|:---------------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------------------------------------------------|
| **In a normal week, how often do you have the following (this means not just a snack or a drink)?**      | This column contains data on how often students have certain foods and drinks in a normal week. (Multiple Choice)                      |
| **On a normal day, how many portions of the following do you have?**                                     | This column contains data on how many portions of certain foods students have on a normal day. (Multiple Choice)                       |
| **How much do you agree or disagree with the following statements?**                                     | This column contains data on how much students agree or disagree with certain statements. (Multiple Choice)                            |
| **How many minutes a week are you physically active for?  **                                             | This column contains data on how many minutes a week students are physically active. (Multiple Choice)                                 |
| **In the last four weeks, not through school/college, which of the following activities have you done?** | This column contains data on which activities students have done in the last four weeks outside of school/college. (Multiple Choice)   |
| **Does anything stop you from taking part in physical activities? **                                     | This column contains data on what stops students from taking part in physical activities. (Multiple Choice)                            |
| **In the last 12 months, what sports/activities have you done in PE lessons?**                           | This column contains data on what sports/activities students have done in PE lessons in the last 12 months. (Multiple Choice)          |
| **Has PE encouraged you to do any of the following ….?**                                                 | This column contains data on what PE has encouraged students to do. (Multiple Choice)                                                  |
| **What after school clubs would you like school to offer?**                                              | This column contains data on what after school clubs students would like their school to offer. (Multiple Choice)                      |
| **What sports/activities have you done in PE lessons? **                                                 | This column contains data on what sports/activities students have done in PE lessons. (Multiple Choice)                                |
| **What active/sports clubs at break/lunch time would you like school to offer?**                         | This column contains data on what active/sports clubs students would like their school to offer at break/lunch time. (Multiple Choice) |
| **Which of these describes you? **                                                                       | This column contains data on which of the given descriptions best describes the student. (Multiple Choice)                             |
| **How often have you used each of the following drugs?**                                                 | This column contains data on how often students have used certain drugs. (Multiple                                                     |
| **How good do you think your school/college are at dealing with the following …..?**                     | This column contains data on how students rate their school/college in dealing with certain topics. (Multiple Choice)                  |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [data.world's Admin](https://data.world/dataworldadmin).

",.csv
Science Courses: Subject Combinations Dataset,1,science-courses-subject-combinations-dataset,science_courses_subject_combinations.csv,other,"
Certainly! Here's the description with some emojis added:

This dataset 📊 provides information on various academic fields or courses of study 🎓, particularly in the fields of science 🔬, engineering 🛠️, technology 💻, and related disciplines. Each entry includes the name of the field or course, the required subjects or prerequisites for pursuing it, and the estimated cost associated with studying it.

The dataset covers a wide range of fields including traditional disciplines like Engineering, Medicine, and Computer Science, as well as emerging areas such as Data Science, Artificial Intelligence, and Renewable Energy Engineering. It also includes interdisciplinary fields like Biotechnology, Environmental Science, and Forensic Science.

For each field or course, the required subjects typically include Physics, Chemistry, Mathematics, and sometimes Biology, Computer Science, or other optional subjects. Additionally, the dataset lists the estimated cost associated with pursuing each field of study, providing a rough indication of the financial investment required for education in these areas.

Overall, this dataset serves as a resource for individuals interested in exploring various academic paths and the prerequisites and costs associated with them in the fields of science, engineering, and related disciplines. 🌟",.csv
Scottish Crime/Offences in 22/23,1,scottish-crimeoffences-in-2223,recorded-crime.csv,CC0-1.0,"# About Dataset
This dataset was built from public records produced by the Scottish Government and details all crimes and offences committed during 2022 and 2023.

### Dataset Overview:
The dataset includes 58 different types of crimes along with their locations (split up into areas).

### Some Data Science Applications:

**- Predictive Modeling:** Utilizing historical data to forecast future crime/offence levels.

**- Trend Analysis:** Identifying patterns and trends in crime over time and across different locations to understand the impact of how the location affects the crime.

### Ethically Obtained Data:
The data has been ethically sourced from statistics.gov.scot, a platform dedicated to making publicly available data accessible and usable. You can explore the dataset further at [Recorded Crimes and Offences.](https://statistics.gov.scot/resource?uri=http%3A%2F%2Fstatistics.gov.scot%2Fdata%2Frecorded-crime)",.csv
Seattle weather prediction dataset,1,seattle-weather-prediction-dataset,seattle-weather.csv,Apache 2.0,"Explore the intricate climate patterns of the ""Emerald City"" with the Seattle Weather Dataset. Dive into a comprehensive collection of weather data that unveils the city's renowned reputation for rain and its ever-changing atmospheric conditions. Uncover seasonal trends, precipitation variations, and temperature fluctuations, all encapsulating the unique charm of Seattle's weather. Whether you're a data enthusiast, a climate researcher, or simply curious about the city's meteorological nuances, this dataset provides valuable insights into Seattle's dynamic weather landscape.",.csv
Sebian National Football Team - all games,1,sebian-national-football-team-all-games,serbian_male_national_team_football.csv,CC0-1.0,"Dataset scrapped from https://www.reprezentacija.rs/ 

Dataset is cleaned the following way:
- all country names are changed to their Alpha 3 codes
- old country names (e.g. West Germany is transcoded to DEU)",.csv
Second Hand Car Price Prediction,1,second-hand-car-price-prediction,cars.csv,CC-BY-SA-4.0,"You are provided with a dataset containing information about various cars, including their specifications and selling prices. The task is to develop a machine learning model that can predict the selling price of a car based on its specifications. This predictive model will assist potential buyers and sellers in estimating the fair market value of a car.",.csv
Second hand cars price predicting v2,1,second-hand-cars-price-predicting-v2,advanced_car_dataset.csv,Apache 2.0,"Dataset contains these rows:

Brand: The brand or manufacturer of the car (e.g., Toyota, Honda, Ford, etc.).

Model: The model of the car (e.g., Camry, Civic, Mustang, etc.).

Year: The manufacturing year of the car.

Fuel_Type: The type of fuel used by the car (e.g., Petrol, Diesel, Electric, etc.).

Transmission: The transmission type of the car (e.g., Manual, Automatic).

Owner_Type: The number of previous owners of the car (e.g., First, Second, Third).

Mileage: The fuel efficiency of the car in kilometers per liter.

Mpg: miles per gallon values 

Engine_Size: random engine sizes 

Price: The selling price of the car in INR (Indian Rupees), which is the target variable to predict.",.csv
Selfie Related Injuries,1,selfie-related-injuries,Selfie_Related_Injuries.csv,CC0-1.0,"### Context

This is a dataset containing a list of serious injuries and deaths in which one or more subjects of a selfie were killed or injured before, during, or after taking a photo of themselves, with the accident at least in part attributed to taking the photo.

Ideas - 

- Which Countries tops the selfie accidents ? 
- What age group is the most affected ? ",.csv
Semester Result of Technical Students,1,student-semester-result,data.csv,CC0-1.0,"### Story :

Prediction of next semester cgpa is very difficult. Prediction of next semester cgpa can be done by analyzing  the past performance of a student.



### Data collection :

This data has been collected manually from a website of a Technical University. Roll number has been converted to a random number for the privacy of the students. College code and subject is real and the semester cgpa is also a real world dataset. 


### Solution : 

Prediction of the next semester marks can be determined by using machine learning algorithms. In my point of view advance regression technique can be a good performer for this case. 
",.csv
Sensor Fault Detection Data,1,sensor-fault-detection-data,sensor-fault-detection.csv,CC0-1.0,"### Context

The current industrial trend regarding automatisms and regarding industrial plants leads us towards systems more and more complex mechatronics, working in an uncertain, evolutionary environment. It is so necessary to develop a diagnosis module to detect a fault (Fault Detection) that may affect the operation of these systems and to locate their causes (Fault Isolation). Therefore, a diagnosis module is needed to improve the performance and productivity of systems and limit the consequences of failures that can be catastrophic on human goods and life. 


### Content

Time series of measurements on sensors uniquely identified by a Sensor Id. During the serie of measurement the sensor is disconnected or on failure.

This Dataset is aimed to serve the Fault detection Analytic component.

- SensorID = 1 = PT100 temperature sensor, in an industrial environment, with dust & vibrations

Themes : Plant, Building, Power, IT, Machine
Keywords : Operational, Meters & sensors, Ambient, Electrical, per minute, over months
Modified: March 7, 2018 



### Acknowledgements

The Publisher of this dataset is [Schneider-Electric](https://www.se.com/ww/en/). 



### Inspiration

Diagnosis consists of detecting abnormal functioning from sensor data. These data may be noisy or corrupt due to unpredictable events. That abnormal operation may be a failure of process equipment (a sensor, actuator or a component), control system failure (due to operator error or cyber-attack of
the system), or change of environment for example resources that are lacking (unavailable operators, exhausted stocks, etc.), or change due to non-conformity product etc. After detecting abnormal functioning, the cause can then be located and identified to make decisions (corrective actions or
reconfiguration of the system). The different type of faultsin the process is illustrated 

The application of IoT systems in industries creates a huge amount of data. In addition, these industrial systems have become more and more complex and it is difficult to obtain an analytical model of the system. In this context, the use of ML tools comes out obvious and logic to cope with the challenges of 
diagnosis in these systems. The goal of this dataset  is to apply through several methods, the application of ML techniques on fault detection and diagnosis 
problems. Among the machine learning techniques(may be traditional) , there are Support Vector Machine (SVM), Artificial Neural Network (ANN), Fuzzy 
Neural Network (FNN), Decision Trees (DT), Bayesian Network (BN).

It could be a great idea to apply novel Deep Learning algorithms on this dataset such as: 
- Denoising stacked auto-encode and Long Short-Term Memory Network
- Self-Attentive Convolutional Neural Networks

### Some references:
- https://arxiv.org/pdf/2006.13380.pdf
- https://www.sciencedirect.com/science/article/abs/pii/S0020025520308422
- https://reader.elsevier.com/reader/sd/pii/S0306261920308114?token=1675928516A34730661B0C6A35207B4AB4BECC82512AC9C5A4F09E0D5395594AA636FF55A3BDE3206452AE185E61951B",.csv
Sentiment Analysis,1,sentiment-analysis,sentiment_analysis.csv,MIT,"This project focuses on developing a sentiment analysis system from social media posts. Using natural language processing techniques, the system aims to automatically identify and categorize the sentiment expressed within social media content.",.csv
Sentiment Analysis for Financial News,1,sentiment-analysis-for-financial-news,all-data.csv,CC-BY-NC-SA-4.0,"### Context

This dataset (FinancialPhraseBank) contains the sentiments for financial news headlines from the perspective of a retail investor.

### Content

The dataset contains two columns, ""Sentiment"" and ""News Headline"". The sentiment can be negative, neutral or positive.

### Acknowledgements

Malo, P., Sinha, A., Korhonen, P., Wallenius, J., & Takala, P. (2014). Good debt or bad debt: Detecting semantic orientations in economic texts. Journal of the Association for Information Science and Technology, 65(4), 782-796.",.csv
Sentiment Analysis: Amazon Product Reviews,1,sentiment-analysis-amazon-product-reviews,Amazon-Product-Reviews - Amazon Product Review (1).csv,Apache 2.0,"I am currently enrolled in a data science apprenticeship program. We were given a task of performing a Natural Language Processing (NLP) workload by analyzing an amazon product review dataset. We will be building a sentiment Analysis model that can classify reviews into positive and negative.  

This task can be done by Beginners and Intermediates in the field. ",.csv
Sentiment140 dataset with 1.6 million tweets,1,sentiment140,training.1600000.processed.noemoticon.csv,other,"### Context

This is the sentiment140 dataset. It contains 1,600,000 tweets extracted using the twitter api . The tweets have been annotated (0 = negative, 4 = positive) and they can be used to detect sentiment .

### Content

It contains the following 6 fields:

1. **target**: the polarity of the tweet (*0* = negative, *2* = neutral, *4* = positive)

2. **ids**: The id of the tweet ( *2087*)

3. **date**: the date of the tweet (*Sat May 16 23:58:44 UTC 2009*)

4. **flag**: The query (*lyx*). If there is no query, then this value is NO_QUERY.

5. **user**: the user that tweeted (*robotickilldozr*)

6.  **text**: the text of the tweet (*Lyx is cool*)


### Acknowledgements

The official link regarding the dataset with resources about how it was generated is [here][1]
The official paper detailing the approach is  [here][2]

Citation: Go, A., Bhayani, R. and Huang, L., 2009. Twitter sentiment classification using distant supervision. *CS224N Project Report, Stanford, 1(2009), p.12*.


### Inspiration

To detect severity from tweets. You [may have a look at this][3].

[1]: http://%20http://help.sentiment140.com/for-students/
[2]: http://bhttp://cs.stanford.edu/people/alecmgo/papers/TwitterDistantSupervision09.pdf
[3]: https://www.linkedin.com/pulse/social-machine-learning-h2o-twitter-python-marios-michailidis",.csv
Sentimental Analysis for Tweets,1,sentimental-analysis-for-tweets,sentiment_tweets3.csv,GPL-2.0,"### Context

Finding if a person is depressed from their use of words on social media can definitely help in the cure!

### Can you predict depression?

Sentimental Analysis can be very useful to find out depression and cure it before someone gets into serious trouble.",.csv
Seoul Bike Sharing Demand,1,seoul-bike-sharing-demand,SeoulBikeData.csv,MIT,"```
Currently Rental bikes are introduced in many urban cities for the enhancement of mobility comfort. It is important to make the rental bike available and accessible to the public at the right time as it lessens the waiting time. Eventually, providing the city with a stable supply of rental bikes becomes a major concern. The crucial part is the prediction of bike count required at each hour for the stable supply of rental bikes. 
The dataset contains weather information (Temperature, Humidity, Windspeed, Visibility, Dewpoint, Solar radiation, Snowfall, Rainfall), the number of bikes rented per hour and date information. 

Has Missing Values?

No
```
```
https://archive.ics.uci.edu/dataset/560/seoul+bike+sharing+demand
```

```
Variable Information
Date : year-month-day
Rented Bike count - Count of bikes rented at each hour
Hour - Hour of he day
Temperature-Temperature in Celsius
Humidity - %
Windspeed - m/s
Visibility - 10m
Dew point temperature - Celsius 
Solar radiation - MJ/m2
Rainfall - mm
Snowfall - cm
Seasons - Winter, Spring, Summer, Autumn
Holiday - Holiday/No holiday
Functional Day - NoFunc(Non Functional Hours), Fun(Functional hours)
```",.csv
Seoul Bike Sharing Demand Prediction,1,seoul-bike-sharing-demand-prediction,SeoulBikeData.csv,Attribution 4.0 International (CC BY 4.0),"### Context

Data include weather information (Temperature, Humidity, Windspeed, Visibility, Dewpoint, Solar radiation, Snowfall, Rainfall), the number of bikes rented per hour and date information.


### Acknowledgements

V E, Sathishkumar (2020), “Seoul Bike Sharing Demand Prediction”, Mendeley Data, V2, doi: 10.17632/zbdtzxcxvg.2

### Inspiration

Predict how atmospheric conditions affect the number of bikes rented",.csv
Servo Motor  Mechanism Dataset,1,servo-motor-mechanism-dataset,Servo Mechanism.csv,Apache 2.0,"# Title: Servo Motor Mechanism Dataset

Description:
This dataset provides information about a servo motor mechanism, capturing various parameters and their corresponding classes. Each entry in the dataset represents a specific configuration of the servo motor mechanism along with associated attributes.
  
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F19517213%2F76e6bdc47f6b0459da63e1508bdd2344%2F12d8ac11ee020eefc1f76900aa7a271c.jpg?generation=1712418501189517&alt=media)

## Attributes:

- **Motor:** Represents the type of motor used in the mechanism, categorized as 'A', 'B', 'C', 'D', or 'E'.
- **Screw:** Indicates the type of screw used in the mechanism, classified as 'A', 'B', 'C', 'D', or 'E'.
- **Pgain:** Refers to the proportional gain setting for the servo motor.
- **Vgain:** Represents the velocity gain setting for the servo motor.
- **Class:** Denotes the class label assigned to each configuration, which is a measure related to the performance or behavior of the servo mechanism.
## Dataset Information:
The dataset contains a total of 5 entries, each representing a unique configuration of the servo motor mechanism. This dataset can be used for tasks such as classification or regression to predict the class label or performance metric based on the given attributes.

## Potential Uses:

Servo Mechanism Performance Prediction: Build machine learning models to predict the performance class of a servo mechanism based on its attributes.
Feature Engineering and Selection: Explore the relationships between different attributes (e.g., Motor type, Screw type, Pgain, Vgain) and their impact on servo mechanism performance.
Educational Purposes: Use this dataset for educational activities such as data analysis, visualization, and modeling within the context of servo motor mechanisms.
## Data Source:
This dataset was originally sourced from a study or experiment involving servo motor mechanisms and has been made available for analysis and exploration. The dataset is suitable for use in machine learning projects, educational settings, and research related to servo motor systems and control mechanisms.",.csv
Shakespeare's Plays: Dialogues & Characters,1,shakespeare-plays-dataset,shakespeare_plays.csv,CC0-1.0,"This comprehensive dataset includes every line from all of William Shakespeare’s plays, categorized by play, genre, character, and more. It is an invaluable resource for those interested in literary analysis, natural language processing, and the historical study of one of the most significant figures in English literature. The dataset consists of 108,093 rows and 9 columns, capturing lines from various plays by William Shakespeare. Here’s a breakdown of the dataset structure and its contents:

### Columns
1. **play_name**: The name of the play.
2. **genre**: The genre of the play (Comedy, History, Tragedy).
3. **character**: The character who delivers the line.
4. **act**: Act number in the play.
5. **scene**: Scene number in the act.
6. **sentence**: Line number in the scene.
7. **text**: The text of the dialogue.
8. **sex**: The gender of the character, reflecting Shakespeare's diverse cast.

#### Key Features:
- **Detailed Line Entries:** Over 100,000 lines of dialogue.
- **Rich Character Metadata:** Lines are linked to over 950 unique characters, along with the character's sex, providing a deep dive into the sex dynamics within Shakespeare's works.

#### Potential Uses & Inspired Analysis:
- **Textual Analysis:** Use natural language processing techniques to analyze Shakespeare’s language, themes, and character development.
- **Gender Studies:** Explore the representation of gender across different plays and genres.
- **Educational Tools:** Create educational content and analysis tools to help students and scholars understand Shakespeare’s work in depth.
- **Sentiment Analysis:** Determine the sentiment of dialogues and how it varies across different types of plays and characters.
- **Topic Modeling:** Identify prevalent themes and topics across different plays.
- **Network Analysis:** Analyze interactions between characters to map out social networks within plays.

#### How to Get Started:
1. Explore the distribution of plays by genre and the frequency of characters’ appearances using visualizations included in the dataset.
2. Analyze the most common words and phrases used by different characters or in different genres.
3. Use machine learning to predict the play or the character based on a line of text, with example code snippets provided for quick experimentation.

This dataset offers a plethora of possibilities for anyone interested in delving deep into the linguistic and thematic elements of Shakespeare's works, with ready-to-use data for various levels of analysis.",.csv
Shampoo Sales Dataset,1,shampoo-saled-dataset,shampoo_sales.csv,CC0-1.0,"### Context

This dataset describes the monthly number of sales of shampoo over a 3 year period. The units are a sales count and there are 36 observations.


### Content

Contain the sales of shampoo for 36 months time


### Acknowledgements

 The original dataset is credited to Makridakis, Wheelwright, and Hyndman (1998).",.csv
Shark Tank India Dataset,1,shark-tank-india-dataset,Shark Tank India Dataset.csv,CC0-1.0,"## Context:
Shark Tank India is an Indian Hindi-language business reality television series that airs on Sony Entertainment Television. The show is the Indian franchise of the American show Shark Tank. It shows entrepreneurs making business presentations to a panel of investors or sharks, who decide whether to invest in their company. The first season of Shark Tank India premiered on 20 December 2021, and concluded on 4 February 2022.

## Sharks Intro
1- Ashneer Grover
* Managing Director and Co-founder of BharatPe

2- Aman Gupta
* Co-founder and Chief Marketing Officer of boAt

3- Anupam Mittal
* Founder and CEO of Shaadi.com and People Group

4- Ghazal Alagh	
* Co-founder and Chief Mama of MamaEarth

5- Namita Thapar	
* Executive Director of Emcure Pharmaceuticals

6- Peyush Bansal	
* Co-founder and CEO of Lenskart

7- Vineeta Singh	
* CEO and co-founder of SUGAR Cosmetics



## Data Description
* Episode_number - Number of the episode
* Pitch_number - Number of the Pitch
* Brand_name - Name of the brand Idea
* Idea  - behind the brand building Deal
* Deal - done or not ; 1 - YES, 0 - NO
* Pitcher_ask_amount - Amount asked by the pitchers
* Ask_equity - Equity offered by the pitchers
* Ask_valuation - Valuation asked by pitchers
* Deal_amount - Final Deal Amount
* Deal_equity - Final Deal equity percentage
* Deal_valuation - Final Valuation of Company after Deal
* Ashneer_present - Ashneer was present during the pitching ; 1 - YES, 0 - NO
* Anupam_present - Anupam was present during the pitching ; 1 - YES, 0 - NO
* Aman_present - Aman was present during the pitching ; 1 - YES, 0 - NO
* Namita_present - Namita was present during the pitching ; 1 - YES, 0 - NO
* Vineeta_present - Vineeta was present during the pitching ; 1 - YES, 0 - NO
* Peyush_present - Peyush was present during the pitching ; 1 - YES, 0 - NO
* Ghazal_present - Ghazal was present during the pitching ; 1 - YES, 0 - NO
* Ashneer_deal - Ashneer is a part of Final Deal ; 1 - YES, 0 - NO
* Anupam_deal - Anupam is a part of Final Deal ; 1 - YES, 0 - NO
* Aman_deal - Aman is a part of Final Deal ; 1 - YES, 0 - NO
* Namita_deal - Namita is a part of Final Deal ; 1 - YES, 0 - NO
* Vineeta_deal - Vineeta is a part of Final Deal ; 1 - YES, 0 - NO
* Peyush_deal - Peyush is a part of Final Deal ; 1 - YES, 0 - NO
* Ghazal_deal - Ghazal is a part of Final Deal ; 1 - YES, 0 - NO
* Total_sharks_invested - Number of total sharks invested in the Company
* Amount_per_shark - Amount per shark invested 
* Equity_per_shark - Final Equity gained per Shark



## Acknowledgement:
[Shark Tank India | Wikipedia
](https://en.wikipedia.org/wiki/Shark_Tank_India)
",.csv
Shinzo Abe (Japanese Prime Minister) Twitter NLP,1,shinzo-abe-japanese-prime-minister-twitter-nlp,Shinzo Abe Tweet 20171024 - Tweet.csv,CC-BY-SA-3.0,"### Context
This dataset contains Japanese Prime Minister Tweet.   Japanese culture, diplomatic problem ( North Korea and Tramp etc), time of disaster, economics...
For example,14.April 2014 ""Removing radiation contaminated water in all weather, 365/24 at Fukushima. I am deeply thankful for dedication and commitment of our peers."" Maybe if you analyze his tweets about  Japanese economy this data will be useful for stock price forecasting etc.

### Content

This dataset contains following the data:

 - url
 - Full name show
 - user name dir
 - tweet nav
 - tweet nav_link
 - tweet text size block
 - tweet text size link
 - tweet text size Link_link
 - Profile tweet 1
 - Profile tweet 2
 - Profile tweet 3
 - replay
 - re tweet
 - like

### Inspiration

Inspired by Trump vs Clinton NLP",.csv
Shipping,1,shipping,shipping.csv,CC0-1.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F12038776%2F8dd289d2d5a6d0c0fac04b4dcdaf0e41%2FShipping-Company.webp?generation=1713160536436842&alt=media)

The dataset used for model building contained 10999 observations of 12 variables. The data contains the following information:

* ID: ID Number of Customers.
* Warehouse block: The Company have big Warehouse which is divided in to block such as A,B,C,D,E.
* Mode of shipment:The Company Ships the products in multiple way such as Ship, Flight and Road.
* Customer care calls: The number of calls made from enquiry for enquiry of the shipment.
* Customer rating: The company has rated from every customer. 1 is the lowest (Worst), 5 is the highest (Best).
* Cost of the product: Cost of the Product in US Dollars.
* Prior purchases: The Number of Prior Purchase.
* Product importance: The company has categorized the product in the various parameter such as low, medium, high.
* Gender: Male and Female.
* Discount offered: Discount offered on that specific product.
* Weight in gms: It is the weight in grams.
* Reached on time: It is the target variable, where 1 Indicates that the product has NOT reached on time and 0 indicates it has reached on time.

",.csv
Shoe Prices dataset,1,shoe-prices-dataset,Shoe prices.csv,Attribution 4.0 International (CC BY 4.0),"This dataset contains information about the sales of shoes in a particular region. The data includes information on the brand, model, type of shoe, gender, size, color, material, and price.

Column Details

**Brand:** The brand of the shoe, such as Nike, Adidas, or Reebok.

**Model:** The specific model name or number of the shoe, such as Air Jordan 1, Ultra Boost 21, or Classic Leather.

**Type:** The type of shoe, such as running, casual, or skate. This column describes the intended use or function of the shoe.

**Gender:** The gender the shoe is designed for, such as men, women, or unisex. This column specifies the target demographic for the shoe.

**Size:** The size of the shoe, using US sizing. This column indicates the length of the shoe in inches or centimeters.

**Color:** The color of the shoe's exterior. This column describes the predominant color or color combination of the shoe.

**Material:** The primary material of the shoe, such as leather, mesh, or suede. This column indicates the material that comprises the majority of the shoe's construction.

**Price:** The price of the shoe, in US dollars. This column specifies the cost of purchasing the shoe.

** The purpose of creating this dataset is solely for educational use, and any commercial use is strictly prohibited
and this dataset was large language models generated and not collected from actual data sources.

cover image: https://pin.it/6Eb04Gf",.csv
Shop Customer Data,1,customers-dataset,Customers.csv,DbCL-1.0,"Shop Customer Data is a detailed analysis of a imaginative shop's ideal customers. It helps a business to better understand its customers. The owner of a shop gets information about Customers through membership cards. 

Dataset consists of 2000 records and 8 columns:
- Customer ID 
- Gender
- Age
- Annual Income
- Spending Score - Score assigned by the shop, based on customer behavior and spending nature
- Profession
- Work Experience - in years
- Family Size
",.csv
Shopify Inc. Stock Performance | 2022 to 2024,1,shopify-inc-stock-performance-2022-to-present,shop_stock_data.csv,Apache 2.0,"## Overview
This analysis focuses on Shopify Inc. (SHOP) stock performance from January 1, 2022, to the present date. By analyzing historical stock data, we aim to provide insights into Shopify's financial trends, market volatility, and factors influencing its stock price over this period.

## Column Names
- **Date:** The date of the stock data.
- **Open:** The opening price of Shopify stock on the given date.
- **High:** The highest price of Shopify stock during the trading day.
- **Low:** The lowest price of Shopify stock during the trading day.
- **Close:** The closing price of Shopify stock on the given date.
- **Adj Close:** The adjusted closing price of Shopify stock, accounting for any corporate actions such as dividends or stock splits.
- **Volume:** The trading volume of Shopify stock on the given date.",.csv
Shopping Mall Customer Segmentation Data,1,shopping-mall-customer-segmentation-data,Shopping Mall Customer Segmentation Data .csv,CC0-1.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F17636898%2F184b6d8052250ba87a287246aa21df07%2FScreenshot%202024-04-15%20at%209.37.34%20AM.png?generation=1713155898550914&alt=media)
This dataset is designed for learning **customer segmentation concepts**, such as market basket analysis. It includes basic customer data such as **Customer ID, age, gender, annual income, and spending score,** which is assigned based on customer behavior and purchasing data. The goal is to help a supermarket mall owner understand their customers better, identify target customers who are likely to converge, and provide insights to the marketing team for **strategic planning.**",.csv
Shopping dataset,1,shopping-dataset,Shopping_data.csv,CC0-1.0,"Customer ID: A unique identifier assigned to each customer for tracking and analysis purposes.

Gender: The gender of the customer, which can be categorized as male, female, or non-binary. Understanding the gender distribution of customers can help retailers tailor their marketing strategies and product offerings to different demographic segments.

Income: The income level of the customer, typically categorized into income brackets or ranges. Income data provides insights into the purchasing power of different customer segments and helps retailers determine pricing strategies and product affordability.

Spending Score: A numerical score assigned to each customer based on their spending behavior, often calculated using factors such as purchase frequency, average transaction value, and total expenditure. Spending scores help retailers identify high-value customers who contribute significantly to sales and profitability.

Age: The age of the customer, usually categorized into age groups or ranges. Age data is essential for understanding the demographic composition of the customer base and tailoring marketing messages and product offerings to different age segments. Additionally, age information can inform decisions related to product design, packaging, and store layout to appeal to specific age demographics.",.csv
ShxtsNGigs Podcast Youtube Performance,1,shxtsngigs-podcast-youtube-performance,shxtsngigs_data.csv,MIT,"*As of Wednesday 03 January 2024 09:00 PM Korean Standard Time(KST).*
Welcome to the exploration of the ""ShxtsNGigs"" podcast, a thriving and engaging show that has carved its niche on YouTube. This dataset serves as a reservoir of information, encapsulating the essence of each episode, its impact, and the intricate dynamics of audience engagement.

### Unraveling the ShxtsNGigs Experience

""ShxtsNGigs"" isn't just another podcast; it's a vibrant platform where conversations flourish, stories unfold, and ideas collide. Each episode is a testament to the power of dialogue, be it with guests gracing the show or the captivating narratives woven by the hosts themselves.

### Columns in the Dataset

1. **Episode Number:** The number of the released episode.
2. **ID:** Unique identifier for each podcast episode.
3. **Podcast Episode Title:** Title of the specific podcast episode.
4. **Guest:** Value denoting whether a guest was absent or who was the guest in the episode.
5. **Release Day:** The day of the week when the podcast episode was released.
6. **Release Date:** Date of release for the podcast episode.
7. **Duration in Seconds:** Length of the episode in seconds.
8. **View Count:** Number of views the episode garnered on YouTube.
9. **Like Count:** Count of likes received on the episode.
10. **Comment Count:** Number of comments posted in response to the episode.
11. **Number of Discussed Topics:** Total count of topics discussed within the episode.
12. **Discussed Topics:** List or description of the specific topics covered during the episode.

### Objectives of Exploration

1. **Audience Engagement:** Understand how engagement metrics correlate with the presence of guests, episode duration, and discussed topics.
2. **Guest Impact:** Analyze the influence of guest appearances on viewership, engagement, and the variety of topics discussed.
3. **Topic Relevance:** Evaluate the resonance of topics by examining the correlation between discussed themes and audience engagement metrics.
4. **Temporal Trends:** Uncover patterns in release dates and days to identify potential trends in audience behaviour.

### Why Explore ShxtsNGigs Dataset?

This dataset is more than an amalgamation of numbers; it's a portal into the realms of captivating storytelling, thought-provoking discussions, and the pulse of audience intrigue. By dissecting the metrics behind the ShxtsNGigs podcast, the goal is to unearth insights that transcend statistics insights that illuminate the success factors, engagement drivers, and the magic that keeps the audience enthralled.

Join this journey as I navigate the trove of data from ShxtsNGigs, seeking to extract valuable insights that resonate beyond numbers and charts insights that decode the essence of an enthralling podcasting experience.",.csv
Simple Housing Dataset for Regression!,1,assignment,DS - Assignment Part 1 data set.csv,Attribution 4.0 International (CC BY 4.0),"A straightforward regression dataset of the int type. Improve your Machine Learning - Regression skills through this dataset! 

The dataset contains these columns -

Transaction date
INT

House Age
INT

Distance from nearest Metro station (km)
INT

Number of convenience stores
INT

latitude
INT

longitude
INT

Number of bedrooms
INT

House size (sqft)
INT

House price
INT


Happy Learning!",.csv
Simple Linear Regression - Placement data,1,simple-linear-regression-placement-data,placement.csv,CC0-1.0,"### Context

This package was build to understand Simple Linear Regression. The content in this dataset are easy to understand.


### Content

Contains Two columns:

CGPA : Aggregate Cgpa received 
Package : Total Package (LPA)

### Thank You !!
If like my work please UPVOTE  🙏🙏

##Happy Learning",.csv
Simple Loan Classification Dataset,1,simple-loan-classification-dataset,loan.csv,CC-BY-SA-4.0,"Column Descriptions:

- age (int): The age of the individual.
- gender (string): The gender of the individual, either 'Male' or 'Female'.
- occupation (string): The occupation of the individual.
- education_level (string): The highest level of education attained by the individual, such as 'High School', 'Associate's', 'Bachelor's', 'Master's', or 'Doctoral'.
- marital_status (string): The marital status of the individual, either 'Single' or 'Married'.
- income (int): The annual income of the individual in dollars.
- credit_score (int): The credit score of the individual, ranging from 300 to 850.

loan_status (string): The target variable, indicating whether the loan application was 'Approved' or 'Denied'.
This dataset contains various demographic and financial features that could be used to build a classification model for predicting loan approval or denial. The loan_status column serves as the target variable for the classification task.",.csv
Simple Weather Forecast,1,simple-weather-forecast,weather_forecast.csv,DbCL-1.0,"1. Dataset contains five attributes to describe the forecast:
    * **Outlook**: A forecast or prediction about how the weather will develop over the day.
    * **Temperature**: Measure of hotness or coldness.
    * **Humidity**: Measure of water vapor in the air.
    * **Wind**: Presence or absence of wind.
    * **Play**: Is it ideal to play outdoors.
2. The values of the four attributes are qualitative (also known as categorical). 
3. Dataset was gathered over 14 different days.

First four attributes acts as features and take on the values shown below:
1. Outlook ∈ [Sunny, Overcast, Rainy]
2. Temperature ∈ [Hot, Mild, Cool]
3. Humidity ∈ [High, Normal]
4. Windy ∈ [Weak, Strong]

Attribute **Play** is the class-label and takes the values *yes* or *no*.
1. Play ∈ [Yes, No]",.csv
Simulated Reservoir Levels,1,simulated-reservoir-levels,Simulated Reservoir Levels.csv,CC0-1.0,"The organisation Stream (a collaboration between 16 British water companies) is going to be releasing data about the water levels of reservoirs in the UK. I wanted to generate a dataset that aligned with this to build a notebook that I could use to analyse the data when it is released by simply switching over the data source.

I accomplished this by assuming that there are three main factors that determine the current water level of a reservoir:
- The rain into it's catchment area
- The hours of sunlight/solar radiation on the body of water
- The reservoir's last water level measurement

From this a wrote a python script that: 
1. Generated some ""reservoir"" objects with various attributes like ""surface area"" and ""current water level"".
2. Read in some historic weather data 
3. Calculates an estimate for the monthly effect of rainfall and evaporation on the reservoirs based on the weather data
4. Updates the relevant attributes of each reservoir
5. Records each iteration and saves the output 

The output of this script is this dataset, 

Limitations of the simulation:
- Only had access to monthly historic weather data, I believe this leads to a very ""seesaw"" model that either doesn't have a lot of variation or snowballs
- Only used weather from one station (Aberporth) in order to avoid joining in another dataset of the lat/long of the weather stations.
",.csv
Sing To The World: Top 100 Karaoke Hits USA (2022),1,sing-to-the-world-top-100-karaoke-hits-usa-2022,2022_10_01_sttw_top_100_karaoke_hits_usa.csv,other,"# Sing To The World: Top 100 Most Popular Karaoke Songs of All Time!
---
&gt; We’ve compiled a list of the top 100 below, based on data from over 20 years of sales from [Sing to the World](https://www.singtotheworld.com/).

Source: https://www.singtotheworld.com/100-most-popular-karaoke-songs-of-all-time

## Data
---
- `rank` from 1 to 100.
- `artist` of the song.
- `title` of the song.
- `company` who created the list.
- `source` title of where the data was collected.
- `date_rated` formatted as `YYYY-MM-DD`.

## Usage License
---
`Copyright © 2024 Yousing Limited`. This is not for commercial usage and should only be used for research.",.csv
Singapore Airlines Reviews,1,singapore-airlines-reviews,singapore_airlines_reviews.csv,ODC Attribution License (ODC-By),"

**Overview:**
The ""Singapore Airlines Reviews"" dataset aggregates 10,000 anonymized customer reviews, providing a broad perspective on the passenger experience with Singapore Airlines. This extensive collection is instrumental for data-driven insights into customer satisfaction and service quality.

**Data Science Applications:**
Ideal for sentiment analysis, trend spotting, and predictive analytics, this dataset is a valuable asset for improving customer experience and operational efficiency.

**Column Descriptors:**
- `published_date`: Date and time of review publication.
- `published_platform`: Platform where the review was posted.
- `rating`: Customer satisfaction rating, from 1 (lowest) to 5 (highest).
- `type`: Specifies the content as a review.
- `text`: Detailed customer feedback.
- `title`: Summary of the review.
- `helpful_votes`: Number of users finding the review helpful.

**Ethical Considerations:**
Compiled with a commitment to privacy, all personal identifiers have been removed to ensure ethical standards.

**Acknowledgements:**
Thanks to TripAdvisor for the review platform and Singapore Airlines for the service quality reflected in the dataset. The thumbnail features the Singapore Airlines logo, acknowledging the brand's influence on the data.",.csv
Single Layer Perceptron Dataset(Small),1,single-layer-perceptron-datasetsmall,Single Layer Perceptron Dataset.csv,CC0-1.0,"We have chosen a simple numpy array to implement the single layer perceptron algorithm. We have considered a total of 13 samples with three features and one class label. The class label is defined in binary 0 and 1. The training dataset contains eight data samples, while the validation dataset contains five.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F9905947%2F7dc95405d7b0696adeb1c90f1cf8682b%2Ftraining%20data.jpg?generation=1681929479850322&alt=media)
                  Fig 1.1: Train Data
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F9905947%2Fe83b9677df9780414f25471c72ead9ca%2Ftest%20data.jpg?generation=1681929512768929&alt=media)
                   Fig 1.2: Test Data
Here the first value for every sample is considered 1, as the algorithm says the value of x0 should always be 1. But even without this characteristic, our code will give the correct output.",.csv
Sirtuin6 Small Molecules Dataset,1,sirtuin6-small-molecules-dataset,SIRTUIN6.csv,Attribution 4.0 International (CC BY 4.0),"The dataset includes 100 molecules with 6 most relevant descriptors to determine the candidate inhibitors of a target protein, Sirtuin6. The molecules are grouped based on their low- and high-BFEs.

**Dataset Characteristics:** Tabular

**Subject Area:** Biology

**Associated Tasks:** Classification

**Instances:** 100

**Features:** 6

# Dataset Information

**What do the instances in this dataset represent?**
Small molecules

**Was there any data preprocessing performed?**
The original data consists a complete set of 1875 molecular descriptors generated by PaDEL-Descriptor software and needs feature selection before classification since some of the features are redundant. We reduced the descriptor set by Unsupervised Forward Selection and used the hyperbox classification method in combination with partial least squares regression to determine the most relevant molecular descriptors of the drug molecules for an efficient classification.

# Introductory Paper

**Title:** Milp-hyperbox classification for structure-based drug design in the discovery of small molecule inhibitors of SIRTUIN6

**Link:** [https://www.semanticscholar.org/paper/Milp-hyperbox-classification-for-structure-based-in-Tardu-Rahim/ea7c62fd26da17dd1487613361fb7b012121189c](url)

**By:** Mehmet Tardu, F. Rahim, I. Kavakli, Metin Türkay. 2016

**Published in:** RAIRO Oper. Res.

# Citation
**If you use this dataset, please cite:**
ardu, M., Rahim, F., Kavakli, I. H., & Turkay, M. (2016). Milp-hyperbox classification for structure-based drug design in the discovery of small molecule inhibitors of Sirtuin6. RAIRO-Operations Research, 50(2), 387-400.
https://doi.org/10.1051/ro/2015042

`Tardu,Mehmet and RAHIM,FATIH. (2022). Sirtuin6 Small Molecules. UCI Machine Learning Repository. https://doi.org/10.24432/C56C9Z.`

`@misc{misc_sirtuin6_small_molecules_748,
  author       = {Tardu,Mehmet and RAHIM,FATIH},
  title        = {{Sirtuin6 Small Molecules}},
  year         = {2022},
  howpublished = {UCI Machine Learning Repository},
  note         = {{DOI}: https://doi.org/10.24432/C56C9Z}
}`

",.csv
Skills Migration || LinkedIn Jobs👨🏼‍💻👨🏼‍💻,1,skills-migration-linkedin-jobs,skill_migration_public.csv,Apache 2.0,"# **Description**


The Skills Migration LinkedIn Jobs dataset contains information about job postings related to skills migration, including:

## About Column

- Country-code: Show the country code.
- Country-name: Show the country name.
- wb-income: low income, high income etc.
- wb-region: Show the web region
- skill-group-id: Show the id num
- skill_group_category: This column show the categories for jobs.
- skill_group_name: This column show the skills for jobs.
- net_per_10K_2015:  This column show the income in 2015.
- net_per_10K_2016:  This column show the income in 2016.
- net_per_10K_2017:  This column show the income.

*This dataset can be used to analyze:*

- In-demand skills for migration-related jobs
- Job market trends and growth areas
- Geographic distribution of skills migration jobs
- Industry-specific skills requirements
- Company-specific hiring patterns",.csv
Sleep Health Data,1,sleep-health-data-sampled,Sleep_Data_Sampled.csv,Apache 2.0,"Dataset Overview:
The Sleep Health and Lifestyle Dataset comprises 15000 rows and 13 columns, covering a wide range of variables related to sleep and daily habits. It includes details such as gender, age, occupation, sleep duration, quality of sleep, physical activity level, stress levels, BMI category, blood pressure, heart rate, daily steps, and the presence or absence of sleep disorders.

Key Features of the Dataset:
Comprehensive Sleep Metrics: Explore sleep duration, quality, and factors influencing sleep patterns.
Lifestyle Factors: Analyze physical activity levels, stress levels, and BMI categories.
Cardiovascular Health: Examine blood pressure and heart rate measurements.
Sleep Disorder Analysis: Identify the occurrence of sleep disorders such as Insomnia and Sleep Apnea.

Dataset Columns:
Person ID: An identifier for each individual.
Gender: The gender of the person (Male/Female).
Age: The age of the person in years.
Occupation: The occupation or profession of the person.
Sleep Duration (hours): The number of hours the person sleeps per day.
Quality of Sleep (scale: 1-10): A subjective rating of the quality of sleep, ranging from 1 to 10.
Physical Activity Level (minutes/day): The number of minutes the person engages in physical activity daily.
Stress Level (scale: 1-10): A subjective rating of the stress level experienced by the person, ranging from 1 to 10.
BMI Category: The BMI category of the person (e.g., Underweight, Normal, Overweight).
Blood Pressure (systolic/diastolic): The blood pressure measurement of the person, indicated as systolic pressure over diastolic pressure.
Heart Rate (bpm): The resting heart rate of the person in beats per minute.
Daily Steps: The number of steps the person takes per day.
Sleep Disorder: The presence or absence of a sleep disorder in the person (Healthy, Insomnia, Sleep Apnea).

Details about Sleep Disorder Column:

Healthy: The individual does not exhibit any specific sleep disorder.
Insomnia: The individual experiences difficulty falling asleep or staying asleep, leading to inadequate or poor-quality sleep.
Sleep Apnea: The individual suffers from pauses in breathing during sleep, resulting in disrupted sleep patterns and potential health risks.
",.csv
Sleep Health and Lifestyle Dataset,1,sleep-health-and-lifestyle-dataset,Sleep_health_and_lifestyle_dataset.csv,CC0-1.0,"Note: Don't forget to upvote when you find this useful.

**Dataset Overview:**
The Sleep Health and Lifestyle Dataset comprises 400 rows and 13 columns, covering a wide range of variables related to sleep and daily habits. It includes details such as gender, age, occupation, sleep duration, quality of sleep, physical activity level, stress levels, BMI category, blood pressure, heart rate, daily steps, and the presence or absence of sleep disorders.

**Key Features of the Dataset:**
Comprehensive Sleep Metrics: Explore sleep duration, quality, and factors influencing sleep patterns.
Lifestyle Factors: Analyze physical activity levels, stress levels, and BMI categories.
Cardiovascular Health: Examine blood pressure and heart rate measurements.
Sleep Disorder Analysis: Identify the occurrence of sleep disorders such as Insomnia and Sleep Apnea.

**Dataset Columns:**<br>
Person ID: An identifier for each individual.<br>
Gender: The gender of the person (Male/Female).<br>
Age: The age of the person in years.<br>
Occupation: The occupation or profession of the person.<br>
Sleep Duration (hours): The number of hours the person sleeps per day.<br>
Quality of Sleep (scale: 1-10): A subjective rating of the quality of sleep, ranging from 1 to 10.<br>
Physical Activity Level (minutes/day): The number of minutes the person engages in physical activity daily.<br>
Stress Level (scale: 1-10): A subjective rating of the stress level experienced by the person, ranging from 1 to 10.<br>
BMI Category: The BMI category of the person (e.g., Underweight, Normal, Overweight).<br>
Blood Pressure (systolic/diastolic): The blood pressure measurement of the person, indicated as systolic pressure over diastolic pressure.<br>
Heart Rate (bpm): The resting heart rate of the person in beats per minute.<br>
Daily Steps: The number of steps the person takes per day.<br>
Sleep Disorder: The presence or absence of a sleep disorder in the person (None, Insomnia, Sleep Apnea).<br>

**Details about Sleep Disorder Column:**
- None: The individual does not exhibit any specific sleep disorder.
- Insomnia: The individual experiences difficulty falling asleep or staying asleep, leading to inadequate or poor-quality sleep.
- Sleep Apnea: The individual suffers from pauses in breathing during sleep, resulting in disrupted sleep patterns and potential health risks.


**Acknowledgement:**
- I would like to clarify that the data I am presenting is synthetic and created by me for illustrative purposes. ",.csv
"Sleep, Health, and Lifestyle",1,sleep-health-and-lifestyle,ss.csv,MIT,"This dataset, containing 373 rows and 13 columns, encompasses a broad spectrum of variables associated with sleep and daily routines. It provides information on aspects like gender, age, profession, duration of sleep, sleep quality, level of physical activity, stress levels, BMI classification, blood pressure, heart rate, daily step count, and the existence or non-existence of sleep disorders.

The variables are as follows:

Person ID: A unique identifier for each participant.
Gender: The participant's gender (Male/Female).
Age: The participant's age in years.
Occupation: The job or career of the participant.
Sleep Duration (hours): The daily sleep duration of the participant in hours.
Quality of Sleep (scale: 1-10): A subjective assessment of sleep quality on a scale from 1 to 10.
Physical Activity Level (minutes/day): The daily duration of physical activity for the participant, measured in minutes.
Stress Level (scale: 1-10): A subjective assessment of the participant's stress level on a scale from 1 to 10.
BMI Category: The participant's BMI classification (e.g., Underweight, Normal, Overweight).
Blood Pressure (systolic/diastolic): The participant's blood pressure, represented as systolic pressure over diastolic pressure.
Heart Rate (bpm): The participant's resting heart rate, measured in beats per minute.
Daily Steps: The number of steps the participant takes each day.
Sleep Disorder: The presence or absence of a sleep disorder in the participant (None, Insomnia, Sleep Apnea).",.csv
Sloan Digital Sky Survey DR14,1,sloan-digital-sky-survey,Skyserver_SQL2_27_2018 6_51_39 PM.csv,CC-BY-SA-4.0,"### Context

I was looking for an unused and interesting dataset to improve my data science skills on when my professor mentioned the Sloan Digital Sky Survey which offers public data of space observations. As I found the data to be super insightful I want to share the data.

### Content

The data consists of 10,000 observations of space taken by the SDSS. Every observation is described by 17 feature columns and 1 class column which identifies it to be either a star, galaxy or quasar.

### Feature Description

The table results from a query which joins two tables (actuaclly views): ""PhotoObj"" which contains photometric data and ""SpecObj"" which contains spectral data.

**To ease your start with the data you can read the feature descriptions below:**

#### View ""PhotoObj""
* objid = Object Identifier
* ra = J2000 Right Ascension (r-band)
* dec = J2000 Declination (r-band)

Right ascension (abbreviated RA) is the angular distance measured eastward along the celestial equator from the Sun at the March equinox to the hour circle of the point above the earth in question. When paired with declination (abbreviated dec), these astronomical coordinates specify the direction of a point on the celestial sphere (traditionally called in English the skies or the sky) in the equatorial coordinate system.

Source: https://en.wikipedia.org/wiki/Right_ascension

* u = better of DeV/Exp magnitude fit
* g = better of DeV/Exp magnitude fit
* r = better of DeV/Exp magnitude fit
* i = better of DeV/Exp magnitude fit
* z = better of DeV/Exp magnitude fit

The Thuan-Gunn astronomic magnitude system. u, g, r, i, z represent the response of the 5 bands of the telescope.

Further education: https://www.astro.umd.edu/~ssm/ASTR620/mags.html

* run = Run Number
* rereun = Rerun Number
* camcol = Camera column
* field = Field number

Run, rerun, camcol and field are features which describe a field within an image taken by the SDSS. A field is basically a part of the entire image corresponding to 2048 by 1489 pixels. A field can be identified by:
- **run** number, which identifies the specific scan,
- the camera column, or ""**camcol**,"" a number from 1 to 6, identifying the scanline within the run, and
- the **field** number. The field number typically starts at 11 (after an initial rampup time), and can be as large as 800 for particularly long runs.
- An additional number, **rerun**, specifies how the image was processed. 

#### View ""SpecObj""

* specobjid = Object Identifier
* class = object class (galaxy, star or quasar object)

The class identifies an object to be either a galaxy, star or quasar. This will be the response variable which we will be trying to predict.

* redshift = Final Redshift
* plate = plate number
* mjd = MJD of observation
* fiberid = fiber ID

In physics, **redshift** happens when light or other electromagnetic radiation from an object is increased in wavelength, or shifted to the red end of the spectrum. 

Each spectroscopic exposure employs a large, thin, circular metal **plate** that positions optical fibers via holes drilled at the locations of the images in the telescope focal plane. These fibers then feed into the spectrographs. Each plate has a unique serial number, which is called plate in views such as SpecObj in the CAS.

**Modified Julian Date**, used to indicate the date that a given piece of SDSS data (image or spectrum) was taken.

The SDSS spectrograph uses optical fibers to direct the light at the focal plane from individual objects to the slithead. Each object is assigned a corresponding **fiberID**. 

**Further information on SDSS images and their attributes:** 

http://www.sdss3.org/dr9/imaging/imaging_basics.php

http://www.sdss3.org/dr8/glossary.php

### Acknowledgements

The data released by the SDSS is under public domain. Its taken from the current data release **RD14**.

More information about the license: 

http://www.sdss.org/science/image-gallery/

It was acquired by querying the CasJobs database which contains all data published by the SDSS.

The exact query can be found at:

http://skyserver.sdss.org/CasJobs/ (Free account is required!)

There are also other ways to get data from the SDSS catalogue. They can be found under:

http://www.sdss.org/dr14/

They really have a huge database which offers the possibility of creating all kinds of tables with respect to personal interests.

**Please don't hesitate to contact me regarding any questions or improvement suggestions. :-)**


### Inspiration

The dataset offers plenty of information about space to explore. Also the class column is the perfect target for classification practices!

Note: Since the data was already maintained very well it might not be best dataset to practice data cleaning / filtering...your decision though.",.csv
Slogan Dataset,1,slogan-dataset,sloganlist.csv,DbCL-1.0,"### Context

""Just do it"" (nike), ""Das Auto""(Volkswagen), ""High Performance Delivered"" (Accenture), ""Think Different"" (Apple) are some of the all-time famous slogans (mottos/taglines) of the famous corporations. They have left a mark in the minds of the audience. I was curious to understand the thought process behind the slogans, aside from knowing which company has which slogan. These tagline/mottos are a reflection of the company, the organization culture, the psychology and mindset. More than anything else, it is a symbol.

### Content

I acquired the data by scraping off a bunch of websites. I started with scraping the data from slogan-list.com (using basic Python libraries - beautiful soup and requests)

### Acknowledgements

I owe a lot to the websites through which slogans were captured.
- slogan-list.com
Above all, I owe it to the companies/organizations and their marketing/advertising teams responsible for coming up with such constructive and sticky slogans/taglines.

### Inspiration

I hope this dataset serves useful for all the marketing analysts, businessmen/entrepreneurs, strategy folks.
Some open questions we can find answers to:
1. What are some of the commonly used words in sticky slogans?
2. How many words does a usual slogan have?
3. What's the secret behind the popular slogans?
4. Are there any trends emerging from the slogans?
5. Are certain slogans specific to certain industry? Is there any correlation between the two?",.csv
Smallpox,1,smallpox,swedenlifeexpectancysmallpoxdeaths new.csv,CC0-1.0,"this graph was created in Power Bi and OurDataWorld: 

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F9fcf389834756b07bd0e107336a787e2%2Fgraph1.png?generation=1712176125187485&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F3bbbb35d7b6be384fd5977da5879251d%2Fgraph2.png?generation=1712176131773955&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fd2e1fa3dc92cddd17b516140bee45390%2Fgraph3.jpg?generation=1712176138440610&alt=media)

**Smallpox: A Historical and Medical Journey**

Smallpox, an ancient scourge that haunted humanity for millennia, remains a poignant reminder of the devastating power of infectious diseases. Its impact, both medically and socially, reverberated across cultures and epochs, leaving an indelible mark on human history. In delving into the depths of smallpox, we uncover not only its medical characteristics but also its intricate relationship with societies, shaping beliefs, rituals, and even societal structures.

**Origins and Spread:**

The variola virus, responsible for smallpox, is believed to have plagued humanity for thousands of years. Historical evidence, such as mummified remains from ancient Egypt, suggests its existence as far back as 1100–1500 BCE. The presence of characteristic skin eruptions and pustules on the mummified remains of individuals like Pharaoh Ramses V provides haunting testimony to the ancient origins of smallpox.

The exact origins and transmission routes of smallpox remain subjects of scholarly debate. It is thought to have emerged through zoonotic transmission, likely originating from animal sources before adapting to human hosts. The virus spread through various means, facilitated by human migration, trade routes, and societal interactions. Its relentless march across continents knew no bounds, leaving devastation in its wake.

**Clinical Manifestations:**

The clinical course of smallpox is insidious, marked by distinct stages that unfold with alarming predictability. The initial incubation period, lasting 10–14 days, lulls victims into a false sense of security, often devoid of discernible symptoms. However, this deceptive calm precedes the storm, as fever, headache, and malaise herald the onset of the prodromal phase.

The hallmark of smallpox, the rash, emerges with striking intensity, transforming the body into a landscape of pustular lesions. These lesions progress through stages of maturation, eventually forming crusts before sloughing off, leaving behind a mosaic of depigmented skin and scars. The physical toll exacted by smallpox is not confined to the realm of the body; it leaves an indelible imprint on the psyche, shattering lives and communities in its wake.

**Societal Impact:**

The impact of smallpox transcends the confines of the clinic, permeating every facet of society. In endemic regions, smallpox became an inescapable specter, exacting a heavy toll on populations, particularly children. Societies grappled with the profound implications of smallpox, shaping cultural norms, rituals, and even familial structures.

In 17th-century Britain, the threat of smallpox loomed large, relegating children to a state of liminality until they had weathered the storm of infection. The survival of smallpox conferred not only immunity but also a newfound status within the family, symbolizing resilience in the face of adversity. However, for many, the price of survival was steep, leaving behind a legacy of physical and emotional scars.

**Medical Response and Legacy:**

Throughout history, humanity grappled with the formidable challenge posed by smallpox, often with limited tools at its disposal. The absence of effective treatments rendered smallpox a relentless adversary, claiming countless lives with impunity. It wasn't until the advent of vaccination, pioneered by figures like Edward Jenner, that humanity gained a foothold in the battle against smallpox.

The development of the smallpox vaccine heralded a new era in medicine, offering hope where there was once despair. Through widespread vaccination campaigns, humanity achieved the unthinkable: the eradication of smallpox. In 1980, the World Health Organization declared smallpox eradicated, marking a triumph of science and international cooperation.

**Conclusion:**

Smallpox stands as a testament to the resilience of the human spirit in the face of adversity. Its eradication represents a triumph of science and collective action, underscoring the transformative power of vaccination. However, the legacy of smallpox endures, serving as a stark reminder of the perils posed by infectious diseases. As we navigate the complexities of the modern world, the lessons of smallpox resonate with newfound urgency, reminding us of the importance of vigilance, preparedness, and solidarity in safeguarding public health.",.csv
Smart Cities Index Datasets,1,smart-cities-index-datasets,Smart_City_index_headers.csv,CC0-1.0,"Utilizing different types of IoT (Internet of Things) sensors to collect and manage data - combined with many other technical integrations into our city hubs - defines the future of data & automation being embedded in our urban-living. Think of Smart Cities as a customer experience - for residents of a city.

The Leap Data team utilized globally-recognized indices (formalized for the evaluation of Smart City initiatives), and developed a data model to interpret how Calgary & Edmonton stand in relation to Global Leaders of Smart City activities. The indices utilized to create these insights were developed exclusively from Open Datasets.

Smart City Index Methodology :
[https://www.imd.org/globalassets/wcc/docs/smart_city/smart_city_index_methodology_and_groups.pdf]
**I just shared this dataset, it wasn't me who collected and parameterized the data.",.csv
Smart Home Commands Dataset,1,smart-home-commands-dataset,dataset.csv,CC0-1.0,"# Smart Home Commands Dataset

I wanted to play around with certain commands that could be given to smart home systems and eventually, I would like to build my own. I noticed that it's hard to find a decent dataset with all sorts of commands so I build my own tiny dataset that I could start with just for fun.

## Columns
- Number (index)
- Category (main category)
- Action_needed (action needed or not)
- Question (question or not)
- Subcategory (the subcategory)
- Action (the action that needs to be taken)
- Time (the timeframe it needs to be done)
- Sentence (the sentence itself)

## Acknowledgements
Photo by Bence Boros on Unsplash https://unsplash.com/photos/anapPhJFRhM",.csv
Smart Watch prices,1,smart-watch-prices,Smart watch prices.csv,Attribution 4.0 International (CC BY 4.0),"The Smartwatch Price Dataset contains information about the features and prices of popular smartwatch models from various brands. The dataset includes columns such as Brand, Model, Operating System, Connectivity, Price (USD), Display Type, Display Size (inches), Resolution, Water Resistance (meters), Battery Life (days), Heart Rate Monitor, GPS, and NFC. 

**Columns**

**Brand:** the manufacturer of the smartwatch

**Model:** the specific model of the smartwatch

**Operating System:** the operating system used by the smartwatch (e.g. watchOS, Wear OS, Garmin OS, Fitbit OS, etc.)

**Connectivity:** the types of connectivity supported by the smartwatch (e.g. Bluetooth, Wi-Fi, Cellular)

**Display Type:** the type of display technology used by the smartwatch (e.g. AMOLED, Retina, E-Ink, LCD)

**Display Size (inches):** the size of the smartwatch's display in inches

**Resolution:** the resolution of the smartwatch's display in pixels

**Water Resistance (meters):** the depth to which the smartwatch can be submerged in water without damage

**Battery Life (days):** the estimated battery life of the smartwatch in days

**Heart Rate Monitor:** whether or not the smartwatch has a built-in heart rate monitor

**GPS:** whether or not the smartwatch has built-in GPS for location tracking

**NFC:** whether or not the smartwatch has NFC (Near Field Communication) for contactless payments or other wireless data transfer.

**Price (USD):** the price of the smartwatch in US dollars

The dataset provides a comprehensive overview of the different smartwatches available in the market and can be used for various purposes such as price comparison, feature analysis, and market research. The data is gathered from various sources such as official brand websites, online retailers, and tech blogs. This dataset can be useful for individuals or businesses interested in the smartwatch industry, as well as researchers and data analysts.

* The purpose of creating this dataset is solely for educational use, and any commercial use is strictly prohibited
and this dataset was large language models generated and not collected from actual data sources.

Cover image: https://pin.it/13TyoYn",.csv
Smart home dataset,1,smart-home-dataset,preprocessed_dataset.csv,CC0-1.0,"The dataset is created with almost 49,000 rows, spanning a simulated period of four years (2020-2023). The generated dataset is saved in a CSV file named 'smart_home_dataset.csv'. It is a valuable resource for analyzing smart home behavior, energy consumption patterns, and decision-making scenarios related to offloading computational tasks.

Dataset for Smart Home Appliances:

Unix Timestamp: Represents the Unix timestamp corresponding to each data entry, providing a standardized time format.
Transaction ID: Assigns a unique identifier to each transaction or entry in the dataset, ensuring distinction between different observations.
Appliance Usage (Television, Dryer, Oven, Refrigerator, Microwave): Binary indicators (0 or 1) indicating whether each corresponding smart home appliance is in use (1) or not (0).
Voltage Metrics (Line Voltage, Voltage, Apparent Power): • Line Voltage: The voltage level in the electrical line. • Voltage: The voltage level at the specific location. • Apparent Power: The combination of real and reactive power in the electrical system.
Energy Consumption (kWh): Represents the energy consumed, generated randomly within a specified range.
Bandwidth (kbps): Bandwidth in a smart home system refers to the capacity or speed at which data can be transmitted between devices. It is crucial in facilitating smooth communication, enabling seamless control, monitoring, and automation of various home functions.
Offloading Decision: Randomly selects between 'Local' and 'Remote' to simulate decision-making for offloading computational tasks.",.csv
Smart_Agricultural Production Optimizing Engine,1,smart-agricultural-production-optimizing-engine,Crop_recommendation.csv,ODC Public Domain Dedication and Licence (PDDL),"Need For Efficiency In Agriculture- More Than Ever!
Need For Efficiency In Agriculture- More Than Ever!
In one of our earlier blog post, Agriculture to Agritech: Trends, Challenges, and the Path Forward with Digital Technology and Software Solutions,  we projected that the agriculture industry would feed an estimated global population of 9.7 billion by 2050. In 2020 alone, a 60% increase is required to feed the population. We talked about macroeconomics, changing consumer preferences, emerging technologies and transforming supply chains as the key drivers for digital transformation in agriculture and how the challenges facing the agriculture industry worldwide could be effectively tackled by following the right approach and leveraging technology to meet the growing demand for food.

Until now, factors such as climate change, population growth and food security concerns have propelled the industry into seeking more innovative approaches to improve crop yield. But the current COVID-19 crisis has further exposed the vulnerability of the agricultural landscape and raised questions about meeting the global food demands sustainably, with adverse factors at play. Again, the answer lies in achieving efficiency- producing more with less, now more than ever.

“The industry will be transformed by data science and artificial intelligence. Farmers will have the tools to get the most from every acre.”",.csv
Smartphone Dataset,1,smartphone-dataset,smartphones.csv,Apache 2.0,"# Mobile Phones Dataset Description

This dataset provides comprehensive information about various mobile phones, including their specifications and features. The dataset includes the following columns:

### Brand and Model Information
- `brand_name`: The brand name of the mobile phone manufacturer.
- `model`: The specific model name or designation of the mobile phone.

### General Specifications
- `price`: The price of the mobile phone in the respective currency.
- `avg_rating`: The average rating or score given by users or reviewers for the mobile phone.
- `5G_or_not`: Indicates whether the mobile phone supports 5G connectivity (0 for no, 1 for yes).

### Processor Details
- `processor_brand`: The brand or manufacturer of the processor used in the mobile phone.
- `num_cores`: The number of cores in the processor.
- `processor_speed`: The speed or clock rate of the processor, typically measured in GHz.

### Battery and Charging
- `battery_capacity`: The capacity of the mobile phone's battery, typically measured in mAh.
- `fast_charging_available`: Indicates whether the mobile phone supports fast charging (0 for no, 1 for yes).
- `fast_charging`: The fast charging capability or technology used by the mobile phone (e.g., Quick Charge, Dash Charge, etc.).

### Memory and Storage
- `ram_capacity`: The amount of RAM (Random Access Memory) available in the mobile phone, typically measured in GB.
- `internal_memory`: The internal storage capacity of the mobile phone, typically measured in GB.
- `screen_size`: The size of the mobile phone's display screen, typically measured in inches.
- `refresh_rate`: The refresh rate of the display screen, typically measured in Hz.
- `extended_memory_available`: Indicates whether the mobile phone supports expandable memory via a memory card slot (0 for no, 1 for yes).

### Camera
- `num_rear_cameras`: The number of rear-facing cameras on the mobile phone.
- `primary_camera_rear`: The resolution or megapixel count of the primary rear-facing camera.
- `primary_camera_front`: The resolution or megapixel count of the primary front-facing (selfie) camera.

### Display
- `resolution_height`: The height dimension of the display screen resolution, typically measured in pixels.
- `resolution_width`: The width dimension of the display screen resolution, typically measured in pixels.

### Operating System
- `os`: The operating system installed on the mobile phone (e.g., Android, iOS, etc.).

The dataset provides a comprehensive overview of various mobile phone models, allowing for analysis and comparison of their specifications and features.",.csv
Smartphone Dataset for Anomaly Detection in Crowds,1,smartphone-dataset-for-anomaly-detection-in-crowds,data.csv,Attribution 4.0 International (CC BY 4.0),"This dataset was collected from the Smartphone sensors and can be used to analyse behaviour of a crowd, for example, an anomaly.

**Dataset Characteristics:** Time-Series

**Subject Area:** Computer Science

**Associated Tasks:** Classification

**Instances:** 14221


#Dataset Information

**For what purpose was the dataset created?**

The key purpose of donating this dataset is to provide an opportunity to the research community to use it for further research purposes.

**Who funded the creation of the dataset?**
Muhammad Irfan

**What do the instances in this dataset represent?**
One instance represents a movement patter for a group based activity.

**Are there recommended data splits?**
No.

**Has Missing Values?**
No

#Introductory Paper

**Title:** Anomaly Detection in Crowds using Multi Sensory Information

**Author:**M. Irfan, L. Marcenaro, and L. Tokarchuk, C. Regazzoni. 2018

**Journal:** Published in 5th IEEE International Conference on Advanced Video and Signal-based Surveillance (AVSS), Auckland, New Zealand,

**Link:** [https://ieeexplore.ieee.org/document/8639151](url)

#Abstract of Introductory Paper

This paper presents, a system capable of detecting unusual activities in crowds from real-world data captured from multiple sensors. The detection is achieved by classifying the distinct movements of people in crowds, and those patterns can be different and can be classified as normal and abnormal activities. Statistical features are extracted from the dataset collected by applying sliding time window operations. A model for classifying movements is trained by using Random Forest technique. The system was tested by using two datasets collected from mobile phones during social events gathering. Results show that mobile data can be used to detect anomalies in crowds as an alternative to video sensors with significant performances. Our approach is the first to detect any unusual behavior in crowd with non-visual data, which is simple to train and easy to deploy. We also present our dataset for public research as there is no such dataset available to perform experiments on crowds for detecting unusual behaviours.


#Cite

**Citation:**  `Irfan,Muhammad. (2021). Smartphone Dataset for Anomaly Detection in Crowds. UCI Machine Learning Repository. https://doi.org/10.24432/C5Q90H.`

**BibTeX:**  `@misc{misc_smartphone_dataset_for_anomaly_detection_in_crowds_613,
  author       = {Irfan,Muhammad},
  title        = {{Smartphone Dataset for Anomaly Detection in Crowds}},
  year         = {2021},
  howpublished = {UCI Machine Learning Repository},
  note         = {{DOI}: https://doi.org/10.24432/C5Q90H}
}`


",.csv
Smartphone Models Dataset,1,smartphone-new-data,smartphone_cleaned_v5.csv,other,"Welcome to the Smartphone Models Dataset on Kaggle! This dataset compiles information about a wide range of smartphone models, offering insights into their specifications and features.",.csv
Smartphone Specifications  Dataset under 50000,1,smartphone-specifications-dataset-under-50000,Mobile.csv,other,"The data provided is a catalog of various smartphone models, including their names, prices, specifications, descriptions, and user ratings. Each entry includes details such as RAM, ROM (storage), display size, camera specifications, battery capacity, processor, and warranty information. The descriptions provide key features of each smartphone, helping consumers make informed decisions based on their preferences and needs.",.csv
Smartphone Specifications and Prices in India,1,smartphone-specifications-and-prices-in-india,smartphones - smartphones.csv,CC0-1.0,"# Contex :
The dataset seems to contain information about different mobile phone models along with their specifications such as price, rating, sim type, processor, RAM, battery, display, camera, memory card support, and operating system.

Source: The csv data was scraped from https://www.smartprix.com/mobiles

Inspiration: You can build a recommender system or Price Prediction using the csv data.",.csv
Smartphone-Cleaned,1,smartphone-cleaned,smartphone_cleaned_v2.csv,Apache 2.0,"The dataset contains information about several smartphone models from different brands. Here's a description of the columns:

- `brand_name`: The brand name of the smartphone.
- `model`: The model name or number of the smartphone.
- `price`: The price of the smartphone in the RUPEES.
- `rating`: The rating of the smartphone out of 100.
- `has_5g`: Indicates whether the smartphone supports 5G connectivity (TRUE/FALSE).
- `has_nfc`: Indicates whether the smartphone has NFC (Near Field Communication) capability (TRUE/FALSE).
- `has_ir_blaster`: Indicates whether the smartphone has an IR blaster (TRUE/FALSE).
- `processor_name`: The name of the processor used in the smartphone.
- `processor_brand`: The brand of the processor used in the smartphone.
- `num_cores`: The number of cores in the processor.
- `processor_speed`: The speed of the processor in GHz.
- `battery_capacity`: The battery capacity of the smartphone in mAh (milliampere-hour).
- `fast_charging`: The fast-charging capability of the smartphone in watts.
- `ram_capacity`: The RAM (Random Access Memory) capacity of the smartphone in GB (gigabytes).
- `internal_memory`: The internal storage capacity of the smartphone in GB.
- `refresh_rate`: The refresh rate of the smartphone display in Hz (hertz).
- `resolution`: The resolution of the smartphone display.
- `num_rear_cameras`: The number of rear cameras on the smartphone.
- `num_front_cameras`: The number of front cameras on the smartphone.
- `os`: The operating system used in the smartphone (e.g., Android, iOS).
- `primary_camera_rear`: The resolution of the primary rear camera in megapixels (MP).
- `primary_camera_front`: The resolution of the primary front camera in megapixels (MP).
- `extended_memory`: The capacity of extended memory (e.g., microSD card support) in the smartphone, if applicable.

This dataset provides comprehensive details about various aspects of smartphone models, including specifications related to hardware, connectivity, and camera capabilities, which can be useful for analysis and comparison purposes.",.csv
Smartphones Complete Data,1,smartphones-complete-data,smartphones.csv,Apache 2.0,"It contains data about various smartphone brands and their model names along with the most relevant specification details of a smartphone. It has 26 columns altogether and can be of a great help for data analysis and other tasks

Please upvote if you download and use the dataset. Thanks",.csv
Smartphones Price Dataset,1,smartphones-price-dataset,smartphones.csv,Apache 2.0,"This dataset provides a comprehensive collection of information on various smartphones, enabling a detailed analysis of their specifications and pricing. It encompasses a wide range of smartphones, encompassing diverse brands, models, and configurations, making it a valuable resource for researchers, data analysts, and machine learning enthusiasts interested in the smartphone industry.

The data comes from the spanish website PC componentes. The data was collected using Power Automate.

Fields included:

- **Smartphone Name**: The unique identifier or model name of the smartphone.
- **Brand:** Smartphone brand.
- **Model:** Smartphone brand model.
- **RAM (Random Access Memory):** The amount of memory available for multitasking.
- **Storage:** capacity of the smartphone.
- **Color:** Color of the smarthpone.
- **Free:** Yes/No if the smartphone is attached to a cell company contract.
- **Price:** The cost of the smartphone in the respective currency.
By utilizing this dataset, researchers and analysts can explore patterns, trends, and relationships between smartphone specifications and their pricing. It serves as an excellent resource for tasks such as price prediction, market analysis, and comparison of different smartphone configurations. Whether you are interested in identifying the most cost-effective options or understanding the impact of specific hardware components on smartphone 
prices, this dataset offers abundant possibilities for in-depth exploration.",.csv
Smartphones Sales Dataset,1,smartphone-sale-dataset,Sales.csv,Apache 2.0,"Description for each of the variables:

1. **Brands:** The brands of smartphones included in the dataset.
2. **Colors:** The colors available for the smartphones.
3. **Memory:** The storage capacity of the smartphones, typically measured in gigabytes (GB) or megabytes (MB).
4. **Storage:** The internal storage capacity of the smartphones, often measured in gigabytes (GB) or megabytes (MB).
5. **Rating:** The user ratings or scores assigned to the smartphones, reflecting user satisfaction or performance.
6. **Selling Price:** The price at which the smartphones are sold to consumers.
7. **Original Price:** The original or list price of the smartphones before any discounts or promotions.
8. **Mobile:** Indicates whether the device is a mobile phone.
9. **Discount:** The discount applied to the original price to calculate the selling price.
10. **Discount percentage:** The percentage discount applied to the original price to calculate the selling price.",.csv
Smartwatch Indian Price Prediction Dataset,1,smartwatch-indian-price-prediction-dataset,smartch_watch_cleaned.csv,CC0-1.0,"Smartwatch Indian Price Prediction Dataset

Overview

Welcome to the Smartwatch Indian Price Prediction Dataset! This dataset is a comprehensive collection of features and specifications of various smartwatches available in the market, curated specifically for machine learning and data analysis purposes. Whether you're a data enthusiast, a machine learning practitioner, or a researcher, this dataset provides a rich resource for exploring trends, predicting prices, and uncovering insights in the Indian smartwatch market.

About the Dataset

The dataset includes a wide array of attributes, ranging from technical specifications like RAM and display size to functional features such as GPS, NFC, and health monitoring capabilities. Each entry provides detailed information about a specific smartwatch model, making it suitable for a variety of analytical tasks, including price prediction, market segmentation, and feature correlation analysis.

Potential Use Cases
Price Prediction: Utilize the provided features to build machine learning models for predicting smartwatch prices in the Indian market.
Market Analysis: Analyze trends and patterns in smartwatch features and pricing to identify market opportunities and consumer preferences.
Feature Importance: Determine the significance of different features in influencing smartwatch prices and consumer choices.
Segmentation Analysis: Explore how various segments of smartwatches differ in terms of features, pricing, and consumer ratings.
Recommendation Systems: Develop recommendation systems based on user preferences and feature preferences extracted from the dataset.

File Descriptions
smart_watch_cleaned.csv: CSV file containing the cleaned dataset.

 
## Column Descriptions
- `name`: Name of the smartwatch model.
- `price`: Price of the smartwatch in Indian Rupees.
- `rating`: Rating of the smartwatch.
- `wifi`: Whether the smartwatch has WiFi connectivity (True or False).
- `GPS`: Whether the smartwatch has GPS functionality (True or False).
- `NFC`: Whether the smartwatch has NFC (Near Field Communication) capability (True or False).
- `voice_calling`: Whether the smartwatch supports voice calling (True or False).
- `Bluetooth`: Bluetooth types .
- `Bluetooth_calling`: Whether the smartwatch supports Bluetooth calling (True or False).
- `display_size_inches`: Size of the display in inches.
- `Touch`: Whether the smartwatch display is touch-sensitive (True or False).
- `ram_gb`: RAM capacity of the smartwatch in gigabytes.
- `memory_inbuilt`: Inbuilt memory capacity of the smartwatch in gigabytes.
- `water_resistance`: Whether the smartwatch is water-resistant (True or False).
- `dust_proof`: Whether the smartwatch is dustproof (True or False).
- `scratch_resistance`: Whether the smartwatch has a scratch-resistant screen (True or False).
- `heart_rate_monitor`: Whether the smartwatch has a heart rate monitor (True or False).
- `Blood_Pressure_monitor`: Whether the smartwatch has a blood pressure monitor (True or False).
- `calorie_count`: Whether the smartwatch counts calories burned (True or False).
- `sleep_monitor`: Whether the smartwatch monitors sleep patterns (True or False).
- `step_count`: Whether the smartwatch counts steps (True or False).
- `Pedometer`: Whether the smartwatch has a pedometer (True or False).
- `Blood_oxygen`: Whether the smartwatch measures blood oxygen levels (True or False).
- `Altimeter`: Whether the smartwatch has an altimeter (True or False).
- `alarm_clock`: Whether the smartwatch has an alarm clock feature (True or False).
- `stopwatch`: Whether the smartwatch has a stopwatch feature (True or False).
- `reminder`: Whether the smartwatch has a reminder feature (True or False).
- `timer`: Whether the smartwatch has a timer feature (True or False).
- `battery`: Battery capacity of the smartwatch.

 Usage Guidelines
Feel free to explore, analyze, and utilize this dataset for various machine learning and data analysis purposes. Please attribute the dataset appropriately if used in research or publications. Your feedback and contributions to improving this dataset are highly appreciated!
 

 

 
",.csv
Smite 2 Alpha Weekend 1 Items Dataset,1,smite-2-alpha-weekend-1-items-dataset,smite2_items.csv,CC0-1.0,"This dataset contains detailed information on items featured in the alpha version of Smite 2 during its first weekend. Each row represents a unique item and includes the following columns:

- Name: The name of the item.
- Price: The cost of purchasing the item.
- Tier: The tier or level of the item.
- Strength: Strength attribute of the item.
- Attack_Speed_Percentage: Percentage increase in attack speed provided by the item.
- Max_Mana: Maximum mana attribute of the item.
- Intelligence: Intelligence attribute of the item.
- Max_Health: Maximum health attribute of the item.
- Cooldown_Rate_Percentage: Percentage decrease in cooldown time provided by the item.
- Magical_Protection: Magical protection attribute of the item.
- Critical_Chance_Percentage: Percentage increase in critical hit chance provided by the item.
-Lifesteal_Percentage: Percentage of lifesteal provided by the item.
- Physical_Protection: Physical protection attribute of the item.
- Magical_Penetration_Percentage: Percentage of magical penetration provided by the item.
- Physical_Penetration_Percentage: Percentage of physical penetration provided by the item.
- Mana_Regen: Mana regeneration attribute of the item.
- Movement_Speed_Percentage: Percentage increase in movement speed provided by the item.
- Health_Regen: Health regeneration attribute of the item.
- Passive: Description of the passive ability or effect of the item.
- Active: Description of the active ability or effect of the item, if applicable.",.csv
Smite God Base Statistics Data,1,smite-god-base-statistics-data,smite_gods.csv,CC0-1.0,"This dataset provides the base statistics for every Smite god, including their role, health, mana, speed, attack range, basic attack damage, attack speed, physical and magical protections, as well as their HP5 (Health per 5 seconds) and MP5 (Mana per 5 seconds). These values can be used to understand a god's strengths and weaknesses and guide gameplay strategies.

[Link to notebook](https://www.kaggle.com/code/mattop/scraping-smite-item-hero-data) used to collect the data.",.csv
Smite Item Statistics Data,1,smite-item-statistics-data,smite_items.csv,CC0-1.0,"This dataset provides comprehensive statistics on items available in Smite, a popular multiplayer online battle arena (MOBA) game. Each entry includes detailed information such as item type, tier, cost, total cost, stats provided, and any passive effects associated with the item.

- Item: The name of the item.
- Item Type: Categorization of the item based on its function or purpose in the game, such as physical damage, magical power, defense, utility, or consumables.
- Item Tier: The tier or level of the item, indicating its power and effectiveness relative to other items.
- Cost: The base cost of purchasing the item.
- Total Cost: The total amount of in-game currency required to fully upgrade or purchase the item, including any additional costs for upgrades or enhancements.
- Stats: A breakdown of the numerical attributes and bonuses provided by the item, including factors like health, mana, physical power, magical power, attack speed, penetration, and more.
- Passive Effect: Any unique or passive abilities granted by the item when equipped, which may offer strategic advantages or synergies with specific character builds and playstyles.


This dataset serves as a valuable resource for Smite players, allowing them to analyze item effectiveness, optimize builds, and make informed decisions during gameplay to gain a competitive edge on the battlefield.

[Link to notebook](https://www.kaggle.com/code/mattop/scraping-smite-item-hero-data) used to collect the data.",.csv
Smoke Detection Dataset ,1,smoke-detection-dataset,smoke_detection_iot.csv,other,"# Quick Start Guide

Problem Type : Binary Classification
Target Variable : Fire Alarm

# Context 

A smoke detector is a device that senses smoke, typically as an indicator of fire. Smoke detectors are usually housed in plastic enclosures, typically shaped like a disk about 150 millimetres (6 in) in diameter and 25 millimetres (1 in) thick, but shape and size vary.

--&gt; Types of Smoke Detectors

1. Photoelectric Smoke Detector

A photoelectric smoke detector contains a source of infrared, visible, or ultraviolet light, a lens, and a photoelectric receiver. In some types, the light emitted by the light source passes through the air being tested and reaches the photosensor. The received light intensity will be reduced due to scattering from particles of smoke, air-borne dust, or other substances; the circuitry detects the light intensity and generates an alarm if it is below a specified threshold, potentially due to smoke. Such detectors are also known as optical detectors.

2. Ionization Smoke Detector

An ionization smoke detector uses a radioisotope to ionize air. If any smoke particles enter the open chamber, some of the ions will attach to the particles and not be available to carry the current in that chamber. An electronic circuit detects that a current difference has developed between the open and sealed chambers, and sounds the alarm
 
**The author of this dataset has successfully created a smoke detection device with the help of IOT devices and AI model. (Check Acknowledgement )**

# About the dataset

Collection of training data is performed with the help of IOT devices since the goal is to develop a AI based smoke detector device.
Many different environments and fire sources have to be sampled to ensure a good dataset for training. A short list of different scenarios which are captured:

- Normal indoor
- Normal outdoor
- Indoor wood fire, firefighter training area
- Indoor gas fire, firefighter training area
- Outdoor wood, coal, and gas grill
- Outdoor high humidity
- etc.

The dataset is nearly 60.000 readings long. The sample rate is 1Hz for all sensors. To keep track of the data, a UTC timestamp is added to every sensor reading.

# Acknowledgement / Credits 

The data is collected by Stefan Blattmann in his project [Real-time Smoke Detection with AI-based Sensor Fusion](https://www.hackster.io/stefanblattmann/real-time-smoke-detection-with-ai-based-sensor-fusion-1086e6). 
Author's GitHub : https://github.com/Blatts01",.csv
Smoker's Health Data,1,smokers-health-data,smoking_health_data_final.csv,MIT,"Data filtered from a Hypertension Risk Dataset by Md Raihan Kahn. I was more interested in looking for health effects of smokers versus non-smokers here, but in the end I was the most surprised by the age groups of the heaviest smokers that were polled.",.csv
Smoking Dataset from UK,1,smoking-dataset-from-uk,smoking.csv,CC0-1.0,"``` 
Survey data on smoking habits from the United Kingdom. The data set can be used for analyzing the demographic characteristics of smokers and types of tobacco consumed. A data frame with 1691 observations on the following 12 variables.
```
| Column | Description |
| --- | --- |
| gender | Gender with levels Female and Male. |
| age | Age. |
| marital_status | Marital status with levels Divorced, Married, Separated, Single and Widowed. |
| highest_qualification | Highest education level with levels A Levels, Degree, GCSE/CSE, GCSE/O Level, Higher/Sub Degree, No Qualification, ONC/BTEC and Other/Sub Degree |
| nationality | Nationality with levels British, English, Irish, Scottish, Welsh, Other, Refused and Unknown. |
| ethnicity | Ethnicity with levels Asian, Black, Chinese, Mixed, White and Refused Unknown. |
| gross_income | Gross income with levels Under 2,600, 2,600 to 5,200, 5,200 to 10,400, 10,400 to 15,600, 15,600 to 20,800, 20,800 to 28,600, 28,600 to 36,400, Above 36,400, Refused and Unknown. |
| region | Region with levels London, Midlands And East Anglia, Scotland, South East, South West, The North and Wales |
| smoke | Smoking status with levels No and Yes |
| amt_weekends | Number of cigarettes smoked per day on weekends. |
| amt_weekdays | Number of cigarettes smoked per day on weekdays. |
| type | Type of cigarettes smoked with levels Packets, Hand-Rolled, Both/Mainly Packets and Both/Mainly Hand-Rolled
 |

# Source
National STEM Centre, Large Datasets from stats4schools, https://www.stem.org.uk/resources/elibrary/resource/28452/large-datasets-stats4schools.",.csv
Smoking Status by Race,1,smoking-status-by-race,Behavioral_Risk_Factor_Data__Tobacco_Use__2011_to_present__20240127.csv,Apache 2.0,"2011-2018. Centers for Disease Control and Prevention (CDC). State Tobacco Activities Tracking and Evaluation (STATE) System. BRFSS Survey Data. The BRFSS is a continuous, state-based surveillance system that collects information about modifiable risk factors for chronic diseases and other leading causes of death. The data for the STATE System were extracted from the annual BRFSS surveys from participating states. Tobacco topics included are cigarette and e-cigarette use prevalence by demographics, cigarette and e-cigarette use frequency, and quit attempts. 
For more information, please visit: https://data.cdc.gov/Survey-Data/Smoking-Status-by-Race/",.csv
Smoking related lung cancers,1,smoking-related-lung-cancers,lung_cancer.csv,CC0-1.0,"This is a subset of data available from the US National Lung Screening Trial (NLST). The data contains information about current and former smokers who were observed for 7 years and were tested for lung cancer each year. No non-smokers were involved in the trial.

Data contains:
- pid - anonymous identifier of a person
- age - age of a person at the start of the trial
- gender - Male/Female
- race - the race of a person
- smoker - Former/Current (Former is defined as quit smoking in last 15 years)
- days\_to\_cancer - number of days passed since the trial when the cancer was first observed
- stage\_of\_cancer - the stage of cancer when the cancer was first observed 

Full trial metadata is available at https://wiki.cancerimagingarchive.net/download/attachments/5800702/package-nlst-780.2021-05-28.zip?version=1&modificationDate=1633562878492&api=v2",.csv
Snapchat Reviews [Daily Updated],1,snapchat-reviews-daily-updated,snapchat_reviews.csv,Apache 2.0,"The primary elements of this dataset are the reviews and ratings given by users to the SnapChat App, updated every day. Additional information such as the relevancy of each review and the posting date is also included.",.csv
Snappfood - Persian Sentiment Analysis,1,snappfood-persian-sentiment-analysis,Snappfood - Sentiment Analysis.csv,CC0-1.0,"[Snappfood ](https://snappfood.ir/)(an online food delivery company) user comments containing 70,000 comments with two labels (i.e. polarity classification):

-  Happy
- Sad

| Label | Number |
| --- | --- |
| Negative | 35000 |
| Positive | 35000 |",.csv
Snowfall,1,snowfall,snowfall.csv,other,"Annual snowfall data for Paradise, Mt. Rainier National Park. To include a full winter season, snowfall is recorded from July 1 to June 30. Data from 1943-1946 not available due to road closure during World War II. Records also unavailable from 1948-1954.

Usage
snowfall
Format
A data frame with 100 rows and 3 variables.

year_start
The year snowfall measurement began on July 1.

year_end
The year snowfall measurement ended on June 30.

snowfall
Snowfall measured in inches

Source
National Parks Services",.csv
Social Connections,1,social-connections,self-reported-loneliness-older-adults new.csv,CC0-1.0,"this graph was created in OurDataWorld:

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F4e44719f291a8be66c9409a44d8375f9%2Fgraph1.png?generation=1714771350638083&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Faf366ee31aaa34d98551bdabbf99de83%2Fgraph2.png?generation=1714771357034773&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F17a034edfa04341215c7eb4ebee9cb26%2Fgraph3.png?generation=1714771362551517&alt=media)


Research shows that social connections are important for our well-being. Having support from family and friends is important for our happiness and health and is also instrumental to our ability to share information, learn from others, and seize economic opportunities.

In this article, we explore data on loneliness and social connections across countries and over time and review the available evidence on how and why social connections and loneliness affect our health and emotional welfare, as well as our material well-being.

Despite the fact that there is a clear link between social connections and well-being, more research is needed to understand causal mechanisms, effect sizes, and changes over time.

As we show here, oversimplified narratives that compare loneliness with smoking or that claim we are living in a 'loneliness epidemic' are wrong and unhelpful.

See all interactive charts on loneliness and social connections ↓",.csv
Social Influence on Shopping,1,uncovering-millennials-shopping-habits-and-socia,WhatsgoodlyData-6.csv,CC-BY-SA-4.0,"_____
# Social Influence on Shopping
### Social Survey Data from 300,000 Millennials and Gen Z Members
By Adam Halper [[source]](https://data.world/ahalps)
_____

### About this dataset
&gt; This dataset offers a comprehensive look into the shopping habits of millennials and Gen Z members, including valuable insights about how their choices are influenced by social media. By exploring the responses given to survey questions related to this topic, we can gain an understanding of how these generations' interests, beliefs and desires shape their decisions when it comes to retail experiences. With 150 million survey responses from our 300,000+ millennial and Gen Z participants, we can uncover powerful insights that could help influencers, businesses and marketers more accurately target this demographic. Our data includes important information such as questions asked during the survey, segment types targeted by those questions and corresponding answers gathered with detailed counts/percentages - making this dataset incredibly useful for anyone wanting an in-depth understanding of what drives the purchasing behavior of today's youth

### More Datasets
&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
&gt; - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
&gt; 
&gt; The first step in using this dataset is to take a look at each column: Question, Segment Type, Segment Description, Answer, Count & Percentage. The Question column will provide background on what exactly each survey question was asking - allowing you to get an overall view of what kind of topics were being surveyed in relation to millennials' shopping habits & social media influence. You will then be able to follow up with analysis based on the respective Segment Types & Descriptions given (such as income levels), which leads us into analyzing answers from both Count & Percentage columns combined - providing absolute numbers vs relative ones for further analysis (such as percentages). 
&gt; 
&gt; Afterwards you'll need an advanced data analysis program such as SPSS or R-Studio - depending on your technical ability - though all most basic spreadsheet programs should suffice, excluding Matlab supported ones due its excessive complexity for something simple like this.. After selecting your preferred program inputting our file with all 150 million survey responses may take some time based on your computers processing capabilities but once loaded you'll be ready for endless possibilities! Now it's time get running with pulling out key insights you require utilizing various different tools found within these platforms whether it be linear regression or guided ANOVA testing which ever technique fits best should help lead navigate through uncovering deeper meaning in your ultra specific question! 
&gt; 
&gt; As a final precaution while diving through waters filled surprises also keep note any adjustments needed potentially due overfitting or multicollinearity otherwise could cause major issues skew end results unfit requiring start whole process anew! Good luck delving deep discovering millennial behavior related digital world!

### Research Ideas
&gt; - Identifying which type of segment is most responsive to engaging shopping experiences, such as influencer marketing, social media discounts and campaigns, etc. 
&gt; - Analyzing the answers given to survey questions in order to understand millennial and Gen Z's opinion about social influence on their shopping habits - what do they view positively or negatively? 
&gt; - Using the survey responses to uncover any interesting trends or correlations between different segments - is there a particular demographic that values or uses certain types of social influence on their shopping habits more than others?

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; [Data Source](https://data.world/ahalps)
&gt;  

### License 
&gt; 
&gt; **License: [Attribution-ShareAlike 4.0 International (CC BY-SA 4.0)](https://creativecommons.org/licenses/by-sa/4.0/)**
&gt; - You are free to:
&gt;      - **Share** - copy and redistribute the material in any medium or format for any purpose, even commercially.
&gt;      - **Adapt** - remix, transform, and build upon the material for any purpose, even commercially.
&gt; - You must:
&gt;      - **Give appropriate credit** - Provide a link to the license, and indicate if changes were made.
&gt;      - **ShareAlike** - You must distribute your contributions under the same license as the original.

### Columns

**File: WhatsgoodlyData-6.csv**
| Column name             | Description                                                                                                                                                                                                                         |
|:------------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Question**            | This column contains a list of questions asked in our survey regarding topics such as shopping habits, trust in online retailers, influences from friends and family at purchase time, etc. (Text)                                  |
| **Segment Type**        | This section indicates whether or not an individual was part of a larger segmented group which was surveyed exclusively for that specific question. (Text)                                                                          |
| **Segment Description** | Here you will find a description of the segment population who were surveyed for each question listed in “Question” above. (Text)                                                                                                   |
| **Answer**              | The Answer column includes all the possible answers given by each respondent per question asked on our survey (i.e., Yes/No/Unsure). (Text)                                                                                         |
| **Count**               | The Count column contains number values representing the total amount of respondents uniquely corresponding with each Answer option to its respective Question (i.e., 10 respondents answered No). (Numeric)                        |
| **Percentage**          | This last column provides percentage values that interpret count data found in Count while including all answers among any segments specified across all Questions posed by our survey platform (i.e., 30% responded No). (Numeric) |

### Acknowledgements
&gt; If you use this dataset in your research, please credit the original authors.
&gt; If you use this dataset in your research, please credit [Adam Halper](https://data.world/ahalps).

",.csv
Social Media Consumer Buying Behavior Dataset,1,social-advertisement-dataset,social_ads.csv,Apache 2.0,"# Social Media Buying Dataset

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F19517213%2Fe2f9c167d7297b63c931dbc8b02d34ff%2FScreenshot%202024-04-14%20154826.png?generation=1713089935415579&alt=media)

## **Data Description**
This dataset contains information about individuals and their response to a particular advertisement campaign on social media. The dataset includes the following columns:

- **Age:** Age of the individual in years.
- **EstimatedSalary:** Estimated salary of the individual.
- **Purchased:** Binary variable indicating whether the individual made a purchase (1) or not (0) after seeing the advertisement.

## **Column Descriptions**

i. Age:

**Data Type:**  Integer
**Description:**  Represents the age of the individual in years.

ii. EstimatedSalary:

**Data Type:** Integer
**Description:** Indicates the estimated salary of the individual.

iii. Purchased:

**Data Type:** Integer (0 or 1)
**Description:** Indicates whether the individual made a purchase (1) or not (0) after seeing the advertisement.

## Additional Information
This dataset can be used to analyze the relationship between age, estimated salary, and purchase behavior in response to the advertisement.
The dataset appears to be suitable for binary classification tasks, where the goal might be to predict whether an individual will make a purchase based on age and estimated salary.
Exploratory data analysis (EDA) techniques can be applied to understand patterns and correlations within the dataset before building predictive models.",.csv
Social Media Sentiments Analysis Dataset 📊,1,social-media-sentiments-analysis-dataset,sentimentdataset.csv,CC0-1.0,"The Social Media Sentiments Analysis Dataset captures a vibrant tapestry of emotions, trends, and interactions across various social media platforms. This dataset provides a snapshot of user-generated content, encompassing text, timestamps, hashtags, countries, likes, and retweets. Each entry unveils unique stories—moments of surprise, excitement, admiration, thrill, contentment, and more—shared by individuals worldwide.

**Key Features**



| Feature    | Description                                      |
|------------|--------------------------------------------------|
| Text       | User-generated content showcasing sentiments    |
| Sentiment  | Categorized emotions                             |
| Timestamp  | Date and time information                        |
| User       | Unique identifiers of users contributing        |
| Platform   | Social media platform where the content originated |
| Hashtags   | Identifies trending topics and themes            |
| Likes      | Quantifies user engagement (likes)               |
| Retweets   | Reflects content popularity (retweets)           |
| Country    | Geographical origin of each post                 |
| Year       | Year of the post           |
| Month      | Month of the post            |
| Day        | Day of the post            |
| Hour       | Hour of the post           |



How to Use The Social Media Sentiments Analysis Dataset 📊

The Social Media Sentiments Analysis Dataset is a rich source of information that can be leveraged for various analytical purposes. Below are key ways to make the most of this dataset:

**Sentiment Analysis:**

Explore the emotional landscape by conducting sentiment analysis on the ""Text"" column.
Classify user-generated content into categories such as surprise, excitement, admiration, thrill, contentment, and more.

**Temporal Analysis:**

Investigate trends over time using the ""Timestamp"" column.
Identify patterns, fluctuations, or recurring themes in social media content.

**User Behavior Insights:**

Analyze user engagement through the ""Likes"" and ""Retweets"" columns.
Discover popular content and user preferences.

**Platform-Specific Analysis:**

Examine variations in content across different social media platforms using the ""Platform"" column.
Understand how sentiments vary across platforms.

**Hashtag Trends:**

Identify trending topics and themes by analyzing the ""Hashtags"" column.
Uncover popular or recurring hashtags.

**Geographical Analysis:**

Explore content distribution based on the ""Country"" column.
Understand regional variations in sentiment and topic preferences.

**User Identification:**

Use the ""User"" column to track specific users and their contributions.
Analyze the impact of influential users on sentiment trends.

**Cross-Analysis:**

Combine multiple features for in-depth insights.
For example, analyze sentiment trends over time or across different platforms and countries.
",.csv
Social Media and Mental Health,1,social-media-and-mental-health,smmh.csv,ODbL-1.0,"This dataset was originally collected for a data science and machine learning project that aimed at investigating the potential correlation between the amount of time an individual spends on social media and the impact it has on their mental health.

The project involves conducting a survey to collect data, organizing the data, and using machine learning techniques to create a predictive model that can determine whether a person should seek professional help based on their answers to the survey questions.

This project was completed as part of a Statistics course at a university, and the team is currently in the process of writing a report and completing a paper that summarizes and discusses the findings in relation to other research on the topic.

The following is the Google Colab link to the project, done on Jupyter Notebook -

[https://colab.research.google.com/drive/1p7P6lL1QUw1TtyUD1odNR4M6TVJK7IYN](url)

The following is the GitHub Repository of the project -

[https://github.com/daerkns/social-media-and-mental-health](url)

Libraries used for the Project -

    Pandas
    Numpy
    Matplotlib
    Seaborn
    Sci-kit Learn
",.csv
Social-Media-Users-Dataset,1,social-media-users,SocialMediaUsersDataset.csv,DbCL-1.0,"This dataset contains information about users for a social media friend recommendation project. It includes fields such as UserID, Name, Gender, Date of Birth (DOB), Interests, City, and Country. The dataset aims to capture diverse user profiles and their characteristics in terms of personal information, interests, and geographical locations.",.csv
Software Developers Jobs with salary (India),1,software-developer-job-opening-fresher-2024,fresher_jobs.csv,Apache 2.0,"The Comprehensive Dataset of Fresher Software Job Openings presents an extensive compilation of job opportunities tailored specifically for recent graduates venturing into the realm of software development, engineering, and testing. Covering a diverse array of positions across various industries and geographic locations, this dataset serves as an indispensable resource for individuals embarking on their professional journey or seeking to expand their horizons in the tech industry. Alongside detailed job titles and precise geographical placements, the dataset also offers insights into salary ranges, providing invaluable context for assessing the financial aspects of prospective roles. While some job listings may lack salary information, the dataset nonetheless offers a robust foundation for analyzing trends, identifying opportunities, and making informed career decisions within the software domain.

🚨 check my new dataset related to more fresher Opening job : [Indian Fresher's Job Market](https://www.kaggle.com/datasets/nuhmanpk/indian-fresher-job-market/)


Do checkout my other [Datasets](https://kaggle.com/nuhmanpk/datasets), and follow me on [Github](https://github.com/nuhmanpk)









Photo by <a href=""https://unsplash.com/@jasongoodman_youxventures?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Jason Goodman</a> on <a href=""https://unsplash.com/photos/man-standing-behind-flat-screen-computer-monitor-bzqU01v-G54?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>😇  ",.csv
Software Development Companies in Pakistan 2024,1,software-development-companies-in-pakistan-2024,Top_Software_Development_Comapnies_in_Pakistan.csv,Apache 2.0,"In 2024, Pakistan's software development sector maintains its upward trajectory, with several prominent companies leading the charge in innovation and excellence. Systems Limited, a longstanding pillar of the industry, continues to impress with its diverse service offerings and client-focused approach. Meanwhile, 10Pearls solidifies its reputation as a digital transformation specialist, offering bespoke solutions in software development, UX/UI design, and consultancy across various sectors. NetSol Technologies remains a powerhouse, renowned for its cutting-edge IT solutions tailored specifically for the global finance and leasing domains. Techlogix stands out with its comprehensive suite of enterprise applications, business intelligence, and mobile solutions, catering to businesses of all sizes. Arbisoft continues to carve its niche with expertise in software development, data science, and machine learning, serving a broad clientele both locally and internationally. In the healthcare technology arena, CureMD shines, providing state-of-the-art electronic health record solutions and practice management software. VentureDive excels in mobile app development and digital product design, delivering user-centric solutions across diverse industries. Folio3 maintains its position as a leading provider of software development and eCommerce solutions, empowering businesses to thrive in the digital age. Avanza Solutions, specializing in FinTech solutions, drives innovation in payment systems, digital banking, and enterprise solutions. Additionally, S&P Global Pakistan, leveraging its global resources, offers cutting-edge software solutions in data analytics, financial services technology, and risk management. These companies collectively represent the dynamic and thriving landscape of Pakistan's software development industry in 2024, poised for continued growth and success both domestically and internationally.",.csv
Solar Radiation Prediction,1,SolarEnergy,SolarPrediction.csv,DbCL-1.0,"# Context 

Space Apps Moscow was held on April 29th & 30th. Thank you to the 175 people who joined the International Space Apps Challenge at this location!



# Content

The dataset contains such columns as: ""wind direction"", ""wind speed"", ""humidity"" and temperature. The response parameter that is to be predicted is: ""Solar_radiation"". It contains measurements for the past 4 months and you have to predict the level of solar radiation.
Just imagine that you've got solar energy batteries and you want to know will it  be reasonable to use them in future?


# Acknowledgements

Thanks NASA for the dataset.

# Inspiration

Predict the level of solar radiation.
Here are some intersecting dependences that i have figured out:
1. Humidity & Solar_radiation.
2.Temeperature & Solar_radiation.

The best result of accuracy  I could get using cross-validation was only 55%.",.csv
Solar System major bodies data,1,solar-system-major-bodies-data,sol_data.csv,CC-BY-NC-SA-4.0,"This dataset that was used for a project I was doing in college. The data started out pretty basic and was added to over time. Some of the data was retrieved from papers and some of it was calculated. 

##  Contents
`eName` - string - the name of the object
`isPlanet` - boolean - is the object a planet (this includes the five dwarf planets)
`semimajorAxis` - integer - mean orbital distance in km
`perihelion` - integer - closest distance from the Sun during its orbit
`aphelion` - integer - furthest distance from the Sun during its orbit
`eccentricity` - double - ratio of perihelion to aphelion
`inclination` - double - difference in angle between body's orbit and the ecliptic
`density` - double - average density of the body
`gravity` - double - surface gravity, measures in m/s^2
`escape` - integer - escape velocity at surface level
`meanRadius` - double - average total radius
`equaRadius` - double - average equatorial radius
`polarRadius` - double - average polar radius
`flattening` - double - ratio of equatorial radius to polar radius
`dimension` - string - approximate spatial dimensions of irregular shaped objects
`sideralOrbit` - double - orbital period in Earth days
`sideralRotation` - double - rotational period in hours
`discoveryDate` - date - date of discovery, this is left blank for any objects that were known since antiquity
`mass_kg` - integer - total estimated mass of object in kg
`volume` - integer - approximate volume in km^3
`orbit_type` - class - either primary; orbites the Sun, or secondary; orbits a planet
`orbits` - class - the planet that the body orbits. If it does not orbit a planet then it is NA
`bondAlbedo` - double - Bond albedo, portion of light/energy that get reflected by the surface
`geomAlbedo` - double - Geometric albedo, modified reflective metric for spherical objects which, because of opposition effects, can be greater than 1
`RV_abs` - double - radial velocity of Sun due to object's gravitational pull
`p_transit` - double - probability that a transit will be observable
`transit_visibility` - double - angle from the ecliptic that a transit will be visible
`transit_depth` - double - portion of Sun's energy that is blocked during transit
`massj` - integer - mass compared to Jupiter
`semimajorAxis_AU` - integer - orbital radius in Astronomical Units
`grav_int` - gravitational interaction with the Sun",.csv
Solar☀️ Power💡 Diffusion in Indian🇮🇳 Villages,1,solar-power-diffusion-in-indian-villages,solar_power_adoption_data.csv,Apache 2.0,"This dataset contains simulated data on the adoption and impact of solar energy in Indian villages. It includes information on the population of villages, their geographic coordinates (latitude and longitude), average household income, electricity access status, and the adoption rate of solar energy over ten years. Additionally, the dataset provides information on the corresponding impacts of solar energy adoption, including carbon reduction, improvement in electricity access, and economic benefits.

**Column Descriptors:**
| Column Name | Data Type | Description |
| --- | --- | --- |
| State | object | State in which the village is located |
| Population |	int64 | Total population of the village |
| Latitude | float64 | Geographic latitude of the village (decimal degrees) |
| Longitude | float64 | Geographic longitude of the village (decimal degrees) |
| Income | int64 | Average household income in the village (rupees) |
| Electricity Access | bool | Whether the village has initial access to electricity |
| Year_X_Adoption_Rate (X=1-10) | float64 | Adoption rate of solar power in year X (0 to 1) |
| Year_X_CarbonReduction (X=1-10) | float64 | Estimated reduction in carbon emissions in year X |
| Year_X_ElectricityAccess (X=1-10) | bool | Improved electricity access due to solar power adoption rate in year X. In general if adoption rate is greater than 0.5 in a particular year the value is taken as True|
| Year_X_EconomicBenefit (X=1-10) | float64 | Estimated economic benefit from solar power in year X |",.csv
Sonar data,1,sonar-data,sonar data.csv,Apache 2.0,"Sonar data, short for Sound Navigation and Ranging, is a fascinating technology used primarily in underwater environments. It works by emitting sound waves and analyzing the echoes that bounce back from objects, creating detailed maps or images of the underwater terrain. Sonar is crucial for various applications, including underwater navigation, marine exploration, fishing, and military purposes. It comes in different forms, such as active sonar, which emits pulses of sound, and passive sonar, which listens for sounds generated by objects in the water. Sonar data provides valuable insights into underwater topography, the presence of underwater objects, marine life, and even the seabed composition. However, it also raises concerns about its impact on marine ecosystems, particularly its potential to disrupt marine life through noise pollution. As technology advances, sonar data continues to evolve, offering increasingly detailed and accurate information about the underwater world.",.csv
Song Popularity Dataset,1,song-popularity-dataset,song_data.csv,CC0-1.0,"![](https://raw.githubusercontent.com/Masterx-AI/Project_Song_Popularity_Prediction_/main/songs.jpg)

### Description:

Humans have greatly associated themselves with Songs & Music. It can improve mood, decrease pain and anxiety, and facilitate opportunities for emotional expression. Research suggests that music can benefit our physical and mental health in numerous ways. 

Lately, multiple studies have been carried out to understand songs & it's popularity based on certain factors. Such song samples are broken down & their parameters are recorded to tabulate. Predicting the Song Popularity is the main aim.

The project is simple yet challenging, to predict the song popularity based on energy, acoustics, instumentalness, liveness, dancibility, etc. The dataset is large & it's complexity arises due to the fact that it has strong multicollinearity. Can you overcome these obstacles & build a decent predictive model?

### Acknowledgement: 
The dataset is referred from Kaggle.


### Objective:
- Understand the Dataset & cleanup (if required).
- Build Regression models to predict the song popularity.
- Also evaluate the models & compare their respective scores like R2, RMSE, etc.",.csv
Source based Fake News Classification,1,source-based-news-classification,news_articles.csv,CC0-1.0,"### Context

Social media is a vast pool of content, and among all the content available for users to access, news is an element that is accessed most frequently. These news can be posted by politicians, news channels, newspaper websites, or even common civilians. These posts have to be checked for their authenticity, since spreading misinformation has been a real concern in today’s times, and many firms are taking steps to make the common people aware of the consequences of spread misinformation. The measure of authenticity of the news posted online cannot be definitively measured, since the manual classification of news is tedious and time-consuming, and is also subject to bias.
Published paper: http://www.ijirset.com/upload/2020/june/115_4_Source.PDF


### Content

Data preprocessing has been done on the dataset [Getting Real about Fake News](https://www.kaggle.com/mrisdal/fake-news) and skew has been eliminated.

### Inspiration

In an era where fake WhatsApp forwards and Tweets are capable of influencing naive minds, tools and knowledge have to be put to practical use in not only mitigating the spread of misinformation but also to inform people about the type of news they consume. 
Development of practical applications for users to gain insight from the articles they consume, fact-checking websites, built-in plugins and article parsers can
further be refined, made easier to access, and more importantly, should create more awareness.

### Acknowledgements

[Getting Real about Fake News](https://www.kaggle.com/mrisdal/fake-news) seemed the most promising for preprocessing, feature extraction, and model classification. 
The reason is due to the fact that all the other datasets lacked the sources from where the article/statement text was produced and published from. Citing the sources for article text is crucial to check the trustworthiness of the news and further helps in labelling the data as fake or untrustworthy.

Thanks to the dataset’s comprehensiveness in terms of citing the source information of the text along with author names, date of publication and labels. 

",.csv
SpaceX Launch Data,1,spacex-launch-data,spacex_launch_data.csv,CC-BY-SA-3.0,"### Context

SpaceX designs, manufactures and launches advanced rockets and spacecraft. The company was founded in 2002 to revolutionize space technology, with the ultimate goal of enabling people to live on other planets - [SpaceX][1]

### Content

The dataset contains mission information for rocket launches conducted by SpaceX (Space Exploration Technologies Corp).


### Acknowledgements

Data was obtained via Wikipedia's entry for [Falcon 9 and Falcon Heavy launches][2].


### Inspiration

Do you anticipate an increase in launches with the introduction of the Falcon Heavy? How has launch rate increased over time? Do you predict a shift in payload orbits for upcoming launches? How has the customer diversity changed over the years?


  [1]: http://www.spacex.com/about
  [2]: https://en.wikipedia.org/wiki/List_of_Falcon_9_and_Falcon_Heavy_launches",.csv
Spaceship Titanic dataset,1,spaceship-titanic-dataset,s.csv,MIT,"tep into the expansive universe of the Spaceship Titanic dataset, a captivating repository of information that chronicles the intricacies of a groundbreaking interstellar journey. This dataset offers a comprehensive glimpse into the technological marvels, operational intricacies, and human experiences embedded within the luxurious confines of the Spaceship Titanic.

From the propulsion systems propelling us through the cosmos to the meticulous data on life support and environmental controls ensuring the well-being of passengers, every byte within this dataset tells a story of innovation and engineering excellence. Navigate through the wealth of information on celestial navigation, astronomical observations, and real-time communication protocols that knit together the fabric of space exploration.",.csv
Spam Email Dataset,1,email-spam-dedection,mail_data.csv,DbCL-1.0,"# About Data 
This Data Set Contains Two Columns 
- Message 
- Category
   -ham
   -spam

#### Used this data to practice your NLP task. Basically i Get this Data from a Website and Sharing With you all. So you can do Projects on That and do Practice

",.csv
Spam Email Prediction,1,spam-email-prediction,spambase.csv,CC-BY-SA-4.0,"
The classification task for this dataset is to determine whether a given email is spam or not.
	
Our collection of spam e-mails came from our postmaster and individuals who had filed spam.  Our collection of non-spam e-mails came from filed work and personal e-mails, and hence the word 'george' and the area code '650' are indicators of non-spam.  These are useful when constructing a personalized spam filter.  One would either have to blind such non-spam indicators or get a very wide collection of non-spam to generate a general purpose spam filter.",.csv
Spam Emails,1,spam-emails,spam.csv,Apache 2.0,"**Overview:**
This dataset contains a collection of emails, categorized into two classes: ""Spam"" and ""Non-Spam"" (often referred to as ""Ham""). These emails have been carefully curated and labeled to aid in the development of spam email detection models. Whether you are interested in email filtering, natural language processing, or machine learning, this dataset can serve as a valuable resource for training and evaluation.

**Context:**
Spam emails continue to be a significant issue, with malicious actors attempting to deceive users with unsolicited, fraudulent, or harmful messages. This dataset is designed to facilitate research, development, and testing of algorithms and models aimed at accurately identifying and filtering spam emails, helping protect users from various threats.

**Content:**
The dataset includes the following features:
Message: The content of the email, including the subject line and message body.
Category: Categorizes each email as either ""Spam"" or ""Ham"" (Non-Spam).

**Potential Use Cases:**
- Email Filtering: Develop and evaluate email filtering systems that automatically classify incoming emails as spam or non-spam.
- Natural Language Processing (NLP): Use the email text for text classification, topic modeling, and sentiment analysis.
- Machine Learning: Create machine learning models for spam detection, potentially employing various algorithms and techniques.
- Feature Engineering: Explore email content features that contribute to spam classification accuracy.
- Data Analysis: Investigate patterns and trends in spam email content and characteristics.

**License:**
Please note that this dataset is for research and analysis purposes only and may be subject to copyright and data use restrictions. Ensure compliance with relevant policies when using this data.

",.csv
Spam Emails Dataset,1,spamemailsdataset,Spam.csv,CC0-1.0,"![](https://raw.githubusercontent.com/Masterx-AI/Project_Email_Spam_Detection_/main/ee.png)

### Description:

The ""spam"" concept is diverse: advertisements for products/web sites, make money fast schemes, chain letters, pornography...

Our collection of spam e-mails came from our postmaster and individuals who had filed spam. Our collection of non-spam e-mails came from filed work and personal e-mails, and hence the word 'george' and the area code '650' are indicators of non-spam. These are useful when constructing a personalized spam filter. One would either have to blind such non-spam indicators or get a very wide collection of non-spam to generate a general purpose spam filter.

The dataset, taken from the UCI ML repository, contains about 4600 emails labelled as **spam** or **ham**. 

The dataset can be downloaded here: https://archive.ics.uci.edu/ml/datasets/spambase

### Objective:
- Understand the Dataset & cleanup (if required).
- Build classification models to predict whether or not the email spam.
- Compare the evaluation metrics of vaious classification algorithms.",.csv
Spam Mails Dataset,1,spam-mails-dataset,spam_ham_dataset.csv,CC0-1.0,"This dataset is collected from [here][1]. I just used enron1 folder. It contains two folders of spam and ham. Each folder contains emails. I iterated to each text file of those folders and created a dataframe and written to a csv file. This can be helpful for others.


  [1]: http://www2.aueb.gr/users/ion/data/enron-spam/",.csv
Spam Text Message Classification,1,spam-text-message-classification,SPAM text message 20170820 - Data.csv,CC0-1.0,"### Context

Coming Soon

### Content

Coming Soon

### Acknowledgements
Special thanks to;
http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/

### Inspiration

Coming soon",.csv
Spam email Dataset,1,spam-email-dataset,emails.csv,GNU Lesser General Public License 3.0,"**Dataset Name:** Spam Email Dataset

**Description:**
This dataset contains a collection of email text messages, labeled as either spam or not spam. Each email message is associated with a binary label, where ""1"" indicates that the email is spam, and ""0"" indicates that it is not spam. The dataset is intended for use in training and evaluating spam email classification models.

**Columns:**

**text (Text):** This column contains the text content of the email messages. It includes the body of the emails along with any associated subject lines or headers.

**spam_or_not (Binary):** This column contains binary labels to indicate whether an email is spam or not. ""1"" represents spam, while ""0"" represents not spam.

**Usage:**
This dataset can be used for various Natural Language Processing (NLP) tasks, such as text classification and spam detection. Researchers and data scientists can train and evaluate machine learning models using this dataset to build effective spam email filters.",.csv
Spam email from Enron Dataset,1,spam-email-from-enron-dataset,labeled_emails.csv,GPL-2.0,"# Descripcion del conjunto de datos
El conjunto de datos a utilizar es el correspondiente a la base de datos “Enron Email
Dataset”. Contiene datos de alrededor de 150 usuarios con un total de alrededor de 500,000
mensajes de correo electronico. Originalmente el dataset se hizo publico por la Comision Federal
Regulatoria de Energıa de Estaos Unidos durante la investigacion alrededor del colapso de la
empresa Enron.

## Descargar documento completo

[Ver documento completo](https://drive.google.com/file/d/14te4-1IlYMbS1xrNoxW8f4DEsQugqdAZ/view?usp=sharing)
 ",.csv
Spam or Not Spam Dataset,1,spam-or-not-spam-dataset,spam_or_not_spam.csv,other,"### Context

The collection consists of '0030228_easy_ham.tar.bz2' and '20030228_spam.tar.bz2' taking from https://spamassassin.apache.org/old/publiccorpus/ i.e. _Apache SpamAssassin’s public datasets_.  There are 2500 ham and 500 spam emails in the dataset. You may also notice that all the numbers and URLs were converted to strings as  `NUMBER` and `URL`  respectively.  This is the simplified spam and ham dataset.

### Acknowledgements

My first interaction about the content was on the 'Machine Learning and Deep Learning in python using Scikit-Learn and TensorFlow' book. If you follow the questions at the end of Chapter 3, Aurélien Geron asks you to build a spam classifier using this dataset. Thanks to Aurélien, I was familiar with the data itself and tried several models including Embeddings and Machine Learning Algorithms. 
",.csv
Spanish second hand cars,1,spanish-second-hand-cars,Spaniish_second_hand_cars.csv,CC0-1.0,"This is a dataset of Spanish second-hand cars.
It is composed of 7500 different cars, all of them scrapped from this website as of Wednesday, May 8, 2024, [https://www.ooyyo.com](url)
<br>
| Columns||
| --- | --- |
|*make*|Brand of the car in the row.|
|*car_price*|Price of the car in the row.|
|*price_rating*|Rating given to the car depending on its price compared to its specifications.|
|*model*|Model of the car.|
|*trim*|The specific version or configuration of the car, which may include variations in features, options, and styling details.|
|*mi*|Ammount of kilometers that the car had traversed until it was sold to the second-hand cars dealer.|
|*fuel_type*| The Kind of fuel that the car uses, it may be Electric, Diesel, or Petrol, Hybrid may use Petrol or Diesel.|
|*body_type*|The shape of the car, SUV(big car), Crossover(smaller SUV).|
|*color*|Color of the car's paint.|
|*power*|Horsepower of the car's engine.|
|*transmissions*|Automatic or Manual.|",.csv
Sports Car Prices dataset,1,sports-car-prices-dataset,Sport car price.csv,Attribution 4.0 International (CC BY 4.0),"This dataset contains information about the prices of different sports cars from various manufacturers. The dataset includes the make and model of the car, the year of production, the engine size, the horsepower, the torque, the 0-60 MPH time, and the price in USD. The dataset is useful for analyzing the prices of different sports cars and identifying trends in the market.

Columns

**1.	Car Make:** The make of the sports car, which represents the brand or company that produced the car. Examples of car makes in this dataset include Porsche, Lamborghini, Ferrari, Audi, and McLaren.

**2.	Car Model:** The model of the sports car, which represents the specific version or variant of the car produced by the manufacturer. Examples of car models in this dataset include 911, Huracan, 488 GTB, R8, 720S, M8, AMG GT, Corvette, Mustang Shelby GT500, and GT-R Nismo.

**3.	Year:** The year of production of the sports car, which indicates the model year when the car was first introduced or made available for purchase.

**4.	Engine Size (L):** The size of the sports car's engine in liters, which represents the volume of the engine's cylinders. A larger engine size typically indicates higher power and performance. Engine sizes in this dataset range from 2.0L to 8.0L, with some cars having electric motors instead.

**5.	Horsepower:** The horsepower of the sports car, which represents the power output of the car's engine. Higher horsepower typically indicates faster acceleration and higher top speed. Horsepower values in this dataset range from 300 to 1479.

**6.	Torque (lb-ft):** The torque of the sports car in pound-feet, which represents the rotational force generated by the engine. Higher torque values typically indicate stronger acceleration and better handling. Torque values in this dataset range from 270 to 1180.

**7.	0-60 MPH Time (seconds):** The time it takes for the sports car to accelerate from 0 to 60 miles per hour, which is a common measure of acceleration and performance. Lower 0-60 MPH times typically indicate faster acceleration and better performance. 0-60 MPH times in this dataset range from 1.85 to 5.3 seconds.

**8.	Price (in USD):** The price of the sports car in US dollars, which represents the cost of purchasing the car. Prices in this dataset range from $25,000 to $3,000,000.

** The purpose of creating this dataset is solely for educational use, and any commercial use is strictly prohibited
and this dataset was large language models generated and not collected from actual data sources.

cover image: https://www.pinterest.com/pin/357332551696985459/
",.csv
Sports venues,1,sports-venues,file_report.csv,CC0-1.0,"List of sports areas, halls, playgrounds, swimming pools, swimming pools, opening hours, entrance fees and fees.

Publisher:
Name: Statutární město Opava

Catalogue Record:
Added to data.europa.eu: 22 April 2023


Updated on data.europa.eu: 09 September 2023

Identifiers:
sportoviste

uriRef
http://data.europa.eu/88u/dataset/sportoviste

Access Rights:

public

Accrual Periodicity:

annual",.csv
Sports_ECommerce_Products_Dataset,1,sports-ecommerce-products-dataset,Sports_ECommerce_Products_Data.csv,Apache 2.0,"<div style=""border: 2px solid rgba(0, 0, 0, 1); padding: 20px; font-family: Arial, sans-serif"">

<h2 style=""color: rgba(0, 0, 255, 1)"">Sports E-Commerce Products Data</h2>

<p>This dataset contains information about various sports products scraped from an e-commerce website. The data was collected using web scraping techniques with Python's BeautifulSoup library.</p>

<p>Each row in the dataset represents a unique product and includes the following features:</p>

<ul>
<li><strong>Product Name:</strong> The name of the product.</li>
<li><strong>Old Price:</strong> The original price of the product before any discounts.</li>
<li><strong>Special Price:</strong> The discounted price of the product.</li>
<li><strong>Discount %:</strong> The percentage discount on the original price.</li>
<li><strong>Product:</strong> The category or type of the product.</li>
</ul>

<p>The dataset covers a wide range of sports products across multiple categories like Cricket, Football, Hockey, Volleyball, Basketball, Badminton, Tennis, Table Tennis, Squash, Roller Skates, Boxing, Carrom, Swimming, and Chess.</p>

<p>This dataset can be useful for various exploratory data analysis, price comparison, discount pattern analysis, and other e-commerce related data science projects.</p>

<p><strong>Note:</strong> Please respect the terms of service of the website from which the data was scraped. The data is provided for educational purposes only.</p>

</div>
",.csv
Spotify - All Time Top 2000s Mega Dataset,1,spotify-top-2000s-mega-dataset,Spotify-2000.csv,CC0-1.0,"### Context

This dataset contains audio statistics of the top 2000 tracks on Spotify. The data contains about 15 columns each describing the track and it's qualities. Songs released from 1956 to 2019 are included from some notable and famous artists like *Queen*, *The Beatles*, *Guns N' Roses*, etc.
http://sortyourmusic.playlistmachinery.com/ by @plamere uses Spotify API to extract the audio features from the tracks given the Spotify Playlist URI. This data contains audio features like Danceability, BPM, Liveness, Valence(Positivity) and many more.
Each feature's description has been given in detail below.

### Content

- **Index**: ID
- **Title**: Name of the Track
- **Artist**: Name of the Artist
- **Top Genre**: Genre of the track
- **Year**: Release Year of the track
- **Beats per Minute(BPM)**: The tempo of the song
- **Energy**: The energy of a song - the higher the value, the more energtic. song
- **Danceability**: The higher the value, the easier it is to dance to this song.
- **Loudness**: The higher the value, the louder the song.
- **Valence**: The higher the value, the more positive mood for the song.
- **Length**: The duration of the song.
- **Acoustic**: The higher the value the more acoustic the song is.
- **Speechiness**: The higher the value the more spoken words the song contains
- **Popularity**: The higher the value the more popular the song is.


### Acknowledgements

This data is extracted from the Spotify playlist - Top 2000s on PlaylistMachinery(@plamere) using Selenium with Python. More specifically, it was scraped from http://sortyourmusic.playlistmachinery.com/. Thanks to Paul for providing a free and open source to extract features and do cool stuff with your Spotify playlists!


### Inspiration

This is a very fun dataset to explore and find out unique links which land songs in the Top 2000s. With this dataset, I wanted to be able to answer some questions like:

1. Which genres were more popular coming through 1950s to 2000s?
2. Songs of which genre mostly saw themselves landing in the Top 2000s?
3. Which artists were more likely to make a top song?
4. Songs containing which words are more popular?
5. What is the average tempo of songs compared over the years?
6. Is there a trend of acoustic songs being popular back in 1960s than they are now?
7. Is there a trend in genres preferred back in the day vs now?
... and a lot more.",.csv
Spotify App Reviews,1,spotify-app-reviews-2022,reviews.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"### **Overview**
Spotify is one of the largest music streaming service providers, with over 422 million monthly active users, including 182 million paying subscribers, as of March 2022. Some of them don't hesitate to share their experience using this application along with the given rating to denote how satisfied they are with the Application

### **The way data was collected**
Scraping Spotify reviews on Google Play Store

### **Ideas for using this dataset**
- Sentiment analysis
- What makes the application receive 1-star and 5-star",.csv
Spotify Charts (All Audio Data),1,spotify-charts-all-audio-data,merged_data.csv,ODbL-1.0,"#### Content
This is a complete dataset of all the ""Top 200"" and ""Viral 50"" charts published globally by Spotify. Spotify publishes a new chart every 2-3 days. This is its entire collection since January 1, 2019. This dataset is a continuation of the Kaggle Dataset: [Spotify Charts](https://www.kaggle.com/datasets/dhruvildave/spotify-charts) but contains 29 rows for each row that was populated using the Spotify API. 

#### Note
The value of streams is NULL when the chart column is ""viral50"".

#### Acknowledgment
Base Dataset: [Spotify Charts](https://www.kaggle.com/datasets/dhruvildave/spotify-charts)

Photo by <a href=""https://unsplash.com/@alexbemore?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Alexander Shatov</a> on <a href=""https://unsplash.com/photos/green-and-black-plastic-tool-w-qqwn5O-4I?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv
Spotify Data:Popular Hip-Hop  Artists and Tracks🎶,1,spotify-datapopular-hip-hop-artists-and-tracks,top_hiphop_artists_tracks.csv,ODC Attribution License (ODC-By),"This dataset, titled ""Spotify Data: Popular Hip-hop Artists and Tracks,"" offers a curated glimpse into the pulsating world of hip-hop, featuring tracks and artists that have significantly influenced the genre's landscape. Encompassing a collection of around 500 entries, it meticulously compiles the most celebrated hip-hop tracks and artists as per Spotify's extensive music repository. Each entry in the dataset not only highlights the popularity and musical composition of these tracks but also serves as a testament to the artists' creative prowess and their resonating impact on listeners worldwide.

**Data Science Application:**
This concise yet rich dataset is primed for a range of data science explorations. Analysts can dive into popularity trend analysis to uncover the dynamics of hit hip-hop tracks over recent years. It also opens avenues for network analysis to map collaborative patterns among top artists, offering insights into the genre's evolving collaborative landscape. Furthermore, the dataset can fuel predictive models aimed at forecasting track popularity based on various features, providing valuable insights for artists, producers, and marketers alike.

**Column Descriptors:**
- **Artist**: The name of the artist, offering a direct link to the creative mind behind the track.
- **Track Name**: The title of the track, encapsulating its identity and essence.
- **Popularity**: A numeric score reflecting the track's reception and appeal among Spotify listeners.
- **Duration (ms)**: The track's length in milliseconds, detailing the temporal extent of the musical experience.
- **Track ID**: A unique identifier within Spotify's ecosystem, facilitating direct access to the track for further exploration.

**Ethically Mined Data:**
The compilation of this dataset adheres to ethical data mining practices, utilizing Spotify's public API in full compliance with their guidelines. This approach underscores a commitment to respecting copyright and data usage norms, ensuring that the dataset serves as a credible and responsible academic resource.

Gratitude is extended to Spotify for the invaluable data made accessible through their platform, enabling a deeper understanding of musical trends and artist impact within the hip-hop genre. This dataset is a bridge connecting the realms of data science and music, inviting exploration into the rhythmical patterns and narratives that define hip-hop's sonic footprint.",.csv
Spotify Oldies Dataset🎶,1,spotify-oldies-dataset,oldies_60s_top_artists_tracks.csv,ODC Attribution License (ODC-By),"**Spotify Oldies Dataset: A Treasury of Classics**

### Overview:
The Spotify Oldies Collection is a handpicked selection of 455 timeless tracks that stand as testaments to the enduring legacy of music from bygone eras. Featuring luminaries like The Beatles, Marvin Gaye, and Aretha Franklin, this dataset not only celebrates musical genius but also offers a nostalgic journey through the soundscapes that have shaped our cultural heritage. Each entry in this collection is a piece of history, echoing the rhythms and melodies that have transcended time.

### Data Science Applications:
- **Genre Evolution**: Analyze the dataset to explore the evolution of music genres and styles, gaining insights into how historical and cultural contexts influenced musical trends.
- **Popularity Insights**: Utilize the 'Popularity' column to study the factors contributing to the lasting appeal of these oldies, and understand what makes a song timeless in the eyes of contemporary listeners.
- **Duration Analysis**: Investigate trends in track durations to understand historical preferences in song length and structure, shedding light on how technological and media changes have impacted music production.

### Column Descriptors:
- **Artist**: Indicates the performer or group behind each track, providing a glimpse into the diverse talents that have contributed to the rich tapestry of music history.
- **Track Name**: The title of each song, serving as a key to unlock memories and emotions associated with these enduring melodies.
- **Popularity**: A measure of the track's current popularity on Spotify, reflecting how these ageless tunes continue to resonate with today's audience.
- **Duration (ms)**: The length of each track, presented in milliseconds, offering insight into the pacing and flow that characterize songs from different periods.
- **Track ID**: Spotify's unique identifier for each track, facilitating easy access for further exploration and listening on the platform.

### Ethically Mined Data:
This dataset was responsibly compiled using Spotify's API, in strict adherence to their data usage policies. The collection respects the limits and guidelines set by Spotify, ensuring that the process of data acquisition maintains the highest standards of ethical practice.

### Acknowledgments:
We are grateful to Spotify for creating a platform that not only connects listeners with the music they love but also serves as an invaluable resource for data enthusiasts looking to delve into musical analysis. This dataset stands as a bridge across generations, celebrating the timeless nature of music and its power to unite us across temporal divides.",.csv
Spotify Recommendation,1,spotify-recommendation,data.csv,CC0-1.0,"# Spotify Recommandation

( You can check how I used this dataset on [my github repository](https://github.com/Brice-Vergnou/spotify_recommandation) )

I am basically a HUGE fan of music ( mostly French rap though with some exceptions but I love music ). And someday , while browsing stuff on Internet , I found the [Spotify's API](https://developer.spotify.com/documentation/web-api/) . I knew I had to use it when I found out you could get information like danceability about your favorite songs just with their id's.

![image](https://user-images.githubusercontent.com/86613710/127216769-745ac143-7456-4464-bbe3-adc53872c133.png)

Once I saw that , my machine learning instincts forced me to work on this project.

## 1. Data Collection

### 1.1 Playlist creation
I collected 100 liked songs and 95 disliked songs

For those I like , I made a [playlist](https://open.spotify.com/playlist/2WONKi3eZaR29QaQCRSiAE?si=a2463f1d382f4399) of my favorite 100 songs. It is mainly French Rap , sometimes American rap , rock or electro music.

For those I dislike , I collected songs from various kind of music so the model will have a broader view of what I don't like

There is :
- [25 metal songs ( Cannibal Corps )](https://open.spotify.com/playlist/37i9dQZF1DZ06evO0grpKg?si=3c829a46465d4367)
- [20 "" I don't like "" rap songs ( PNL )](https://open.spotify.com/playlist/37i9dQZF1DX2fxPY4lXxv8?si=c69f40a2a2014a25)
- [25 classical songs](https://open.spotify.com/playlist/1h0CEZCm6IbFTbxThn6Xcs?si=933db0752a684db0)
- [25 Disco songs](https://open.spotify.com/playlist/2rkU3Aop33atDJoF8LCCjh?si=5e1247ee29284f0a)

I didn't include any Pop song because I'm kinda neutral about it

### 1.2 Getting the ID's

1. From the [Spotify's API ""Get a playlist's Items""](https://developer.spotify.com/console/get-playlist-tracks/) , I turned the playlists into json formatted data which cointains the ID and the name of each track ( ids/yes.py and ids/no.py ). NB : on the website , specify ""items(track(id,name))"" in the fields format , to avoid being overwhelmed by useless data.

2. With a script ( ids/ids_to_data.py ) , I turned the json data into a long string with each ID separated with a comma.

### 1.3 Getting the statistics

Now I just had to enter the strings into the [Spotify API ""Get Audio Features from several tracks""](https://developer.spotify.com/console/get-audio-features-several-tracks/) and get my data files ( data/good.json and data/dislike.json )

## 2. Data features

From [Spotify's API documentation](https://developer.spotify.com/documentation/web-api/reference/#object-audiofeaturesobject) :

* **acousticness** : A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic.
* **danceability** : Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable.
* **duration_ms** : The duration of the track in milliseconds.
* **energy** : Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy.
* **instrumentalness** : Predicts whether a track contains no vocals. “Ooh” and “aah” sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly “vocal”. The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0.
* **key** : The key the track is in. Integers map to pitches using standard Pitch Class notation . E.g. 0 = C, 1 = C♯/D♭, 2 = D, and so on.
* **liveness** : Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live.
* **loudness** : The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typical range between -60 and 0 db.
* **mode** : Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.
* **speechiness** : Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks.
* **tempo** : The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration.
* **time_signature** : An estimated overall time signature of a track. The time signature (meter) is a notational convention to specify how many beats are in each bar (or measure).
* **valence** : A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).


And the variable that has to be predicted :

* **liked** : 1 for liked songs , 0 for disliked songs
",.csv
"Spotify Revenue, Expenses and Its Premium Users ",1,spotify-revenue-expenses-and-its-premium-users,Spotify Quarterly.csv,CC0-1.0,"Spotify Revenue, Expenses and Its Premium Users contains the number of premium users, number of Ad-supported users and total monthly active users (MAUs).

MAUs include number of premium users as well as number of Ad-supported users.

**Note : Sum of Premium Users and Ad-supported users can have some difference from MAUs.**
**Note : All money figures are in Euro millions except ARPU which is in Euro and as it is.**
**Note : All users figures are in millions. **
**Note : Kindly Ignore the last row.**

Following definitions:
MAUs : It is defined as the total count of Ad-Supported Users and Premium Subscribers that have consumed content for greater than zero milliseconds in the last thirty days from the period-end indicated.
Premium MAUs : It is defined as users that have completed registration with Spotify and have activated a payment method for Premium Service.
Ad MAUs : It is defined as the total count of Ad-Supported Users that have consumed content for greater than zero milliseconds in the last thirty days from the period-end indicated.
Premium ARPU : It is average revenue per user which is monthly measure defined as Premium subscription revenue recognized in the quarter indicated divided by the average daily Premium Subscribers in such quarter, which is then divided by three months.
Cost of Revenue : It is expenses done by company.

Photo by <a href=""https://unsplash.com/@alexbemore?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText"">Alexander Shatov</a> on <a href=""https://unsplash.com/photos/JlO3-oY5ZlQ?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText"">Unsplash</a>
  ",.csv
Spotify Top 10000 Streamed Songs,1,spotify-top-10000-streamed-songs,Spotify_final_dataset.csv,CC0-1.0,"One of the biggest music streaming platform, but who's the biggest streamed here? This dataset which is webscrapped and accumulated all the stream metrics of each artist and their respective songs.

**Position**         -  Spotify Ranking
**Artist Name**  - Artist Name
**Song Name**  - Song Name
**Days**            - No of days since the release of the song (Updated)
**Top 10 (xTimes)**  - No of times inside top 10
**Peak Position**  -  Peak position attained
**Peak Position (xTimes)** - No of times Peak position attained
**Peak Streams** -  Total no of streams during Peak position 
**Total Streams **-  Total song streams",.csv
Spotify Top 50 Tracks 2023,1,spotify-top-tracks-2023,top_50_2023.csv,other,"💁‍♀️Please take a moment to carefully read through this description and metadata to better understand the dataset and its nuances before proceeding to the Suggestions and Discussions section.

# Dataset Description:
This dataset compiles the tracks from Spotify's official ""Top Tracks of 2023"" playlist, showcasing the most popular and influential music of the year according to Spotify's streaming data. 
It represents a wide range array of genres, artists, and musical styles that have defined the musical landscapes of 2023. 
Each track in the dataset is detailed with a variety of features, popularity, and metadata. This dataset serves as an excellent resource for music enthusiasts, data analysts, and researchers aiming to explore music trends or develop music recommendation systems based on empirical data. 

# Data Collection and Processing:
## Obtaining the Data:
The data was obtained directly from the Spotify Web API, specifically from the ""Top Tracks of 2023"" official playlist curated by Spotify. The Spotify API provides detailed information about tracks, artists, and albums through various endpoints. 
## Data Processing:
To process and structure the data, I developed Python scripts using data science libraries such as `pandas` for data manipulation and `spotipy` for API interactions specifically for Spotify data retrieval.
## Workflow:
1. Authentification
2. API Requests
3. Data Cleaning and Transformation
4. Saving the Data

# Attribute Descriptions:
- artist_name: the artist name
- track_name: the title of the track
- is_explicit: Indicates whether the track contains explicit content
- album_release_date: The date when the track was released
- genres: A list of genres associated with the track's artist(s)
- danceability: A measure from 0.0 to 1.0 indicating how suitable a track is for dancing based on a combination of musical elements
- valence: A measure from 0.0 to 1.0 indicating the musical positiveness conveyed by a track
- energy: A measure from 0.0 to 1.0 representing a perceptual measure of intensity and activity
- loudness: The overall loudness of a track in decibels (dB)
- acousticness: A measure from 0.0 to 1.0 whether the track is acoustic. 
- instrumentalness: Predicts whether a track contains no vocals
- liveness: Detects the presence of an audience in the recordings
- speechiness: Detects the presence of spoken words in a track
- key: The key the track is in. Integers map to pitches using standard Pitch Class notation. 
- tempo: The overall estimated tempo of a track in beats per minute (BPM)
- mode: Modality of the track
- duration_ms: The length of the track in milliseconds
- time_signature: An estimated overall time signature of a track
- popularity: A score between 0 and 100, with 100 being the most popular

# Possible Data Projects
- Trends Analysis
- Genre Popularity
- Mood and Music
- Comparison with other tracks

# Disclaimer and Responsible Use:
- This dataset, derived from Spotify's ""Top Tracks of 2023"" playlist, is intended for **educational, research, and analysis purposes only**. Users are urged to use this data responsibly and ethically.
- Users should comply with Spotify's Terms of Service and Developer Policies when using this dataset.
- The dataset includes music track information such as names and artist details, which are subject to copyright. While the dataset presents this information for analytical purposes, it does not convey any rights to the music itself.
- Users of the dataset must ensure that their use does not infringe on the rights of copyright holders. Any analysis, distribution, or derivative work should respect the intellectual property rights of all parties and comply with applicable laws.
- The dataset is provided ""as is,"" without warranty, and the creator disclaims any legal liability for the use of the dataset by others. Users are responsible for ensuring their use of the dataset is legal and ethical.
- For the most accurate and up-to-date information regarding Spotify's music, playlists, and policies, users are encouraged to refer directly to Spotify's official website. This ensures that users have access to the latest details directly from the source.
- The creator/maintainer of this dataset is not affiliated with Spotify, any third-party entities, or artists mentioned within the dataset. This project is independent and has not been authorized, sponsored, or otherwise approved by Spotify or any other mentioned entities.

# Contribution
I encourage users who discover new insights, propose dataset enhancements, or craft analytics that illuminate aspects of the dataset's focus to share their findings with the community.
- **Kaggle Notebooks:** To facilitate sharing and collaboration, users are encouraged to create and share their analyses through Kaggle notebooks. For ease of use, start your notebook by clicking ""New Notebook"" atop this dataset’s page on Kaggle, which automatically loads the dataset as input.
- **Suggestions & Feedback:** The 'Suggestions' tab on this dataset’s Kaggle page is your dedicated space for feedback, suggestions, or questions.

# Resouces Links
2023 Wrapped: https://newsroom.spotify.com/2023-11-29/top-songs-artists-podcasts-albums-trends-2023/

Top Tracks 2023: https://open.spotify.com/playlist/37i9dQZF1DX18jTM2l2fJY

Spotify Web API: https://developer.spotify.com/documentation/web-api",.csv
Spotify's Long Hits (2014-2024) 🎶,1,spotifys-long-hits-2014-2024,spotify_long_tracks_2014_2024.csv,ODC Attribution License (ODC-By),"This dataset, ""Spotify's Long Hits (2014-2024) 🎶,"" offers a unique collection of over 800 tracks, each standing out for its extended playtime, marking the years from 2014 to 2024. It serves as a unique lens through which the evolution of musical duration and listener preferences can be observed over a significant period. Each track in this dataset not only surpasses the conventional lengths but also encapsulates the essence of its time, making it a valuable resource for in-depth musical analysis.

**Data Science Applications:**
The dataset's structure lends itself to various analytical pursuits within the data science realm. Researchers and enthusiasts can delve into trend analysis to uncover shifts in musical durations over the years, perform genre-based studies to explore the relationship between genre and track length, or even train machine learning models to predict track popularity based on various features. However, make sure to use the dataset only for educational purposes as per Spotify guidelines.

**Column Descriptors:**
- **ID**: The unique identifier for each track on Spotify, facilitating direct access to the track.
- **Name**: The title of the track, revealing its identity.
- **Duration (Minutes)**: The length of each track, provided in minutes, highlighting the extended nature of these compositions.
- **Artists**: The names of the artists involved, offering insights into the collaborative landscape of each piece.

**Ethically Mined Data:**
This dataset has been compiled with strict adherence to ethical data mining practices, utilizing Spotify's public API in full compliance with their guidelines. It represents a harmonious blend of technology and creativity, showcasing the vast musical archive that Spotify offers.

Gratitude is extended to Spotify for the data provided and the usage of their logo in the dataset thumbnail, which adds a recognizable visual cue to this academic resource. This dataset stands as a testament to the power of music and data combined, inviting exploration into the depths of musical analysis.",.csv
Stanford Open Policing Project,1,stanford-open-policing-project,police_project.csv,other,"### Context

On a typical day in the United States, police officers make more than 50,000 traffic stops. Our team is gathering, analyzing, and releasing records from millions of traffic stops by law enforcement agencies across the country. Our goal is to help researchers, journalists, and policymakers investigate and improve interactions between police and the public.


### Content

This dataset includes 9 Mb of stop data from Rhode Island, covering all of 2013 onwards. Please see the data readme for the full details of the available fields.

### Acknowledgements

This dataset was kindly made available by the [Stanford Open Policing Project](https://openpolicing.stanford.edu/). If you use it for a research publication, please cite their [working paper](https://5harad.com/papers/traffic-stops.pdf): E. Pierson, C. Simoiu, J. Overgoor, S. Corbett-Davies, V. Ramachandran, C. Phillips, S. Goel. (2017) “A large-scale analysis of racial disparities in police stops across the United States”.

### Inspiration

- Do men or women speed more often?
- Does gender affect who gets searched during a stop?
- During a search, how often is the driver frisked?
- Which year had the least number of stops?
- How does drug activity change by time of day?
- Do most stops occur at night?

Those all are question waiting for you to answer them, Good Luck😃 ",.csv
Star Set ⭐,1,star-set-v2,labels.csv,MIT,"**This is 1000 renders of the night sky and their corresponding galactic coordinates.**

# Stars

The stars and their positions that were used are from the Yale Bright Star Catalog. 
[Yale Bright Star Catalog](https://www.kaggle.com/datasets/anavid7/yale-bright-star-catalog)

The Bright Star Catalogue (BSC) is widely used as a source of basic astronomical and astrophysical data for stars brighter than magnitude 6.5. The BSC contains 9110 objects (9096 stars + 14 novae or extragalactic objects for historical numbering).

For the render the 14 non star objects were removed and all-stars with a negative visual magnitude were given a value equal to 0.01. 

# Render

The stars are rendered using the Godot game engine. In short, they are low poly spheres rendered at the latitude and longitude according to the dataset. The distance from the camera viewpoint is determined by the visual magnitude, meaning that stars with a lower visual magnitude are further away. The environment has a global light that reflects off the spheres to give them contrast against the black background.  The Camera has a 15-degree FOV.

The code for the rendering software is located [here](https://github.com/dj-ryan/sat-sight-view)

# Capture

The images were captured at roughly even spacing around the entirety of the sphere by following a Fibonacci lattice.

Mapping the Fibonacci lattice (aka Golden Spiral, aka Fibonacci Sphere) onto the surface of a sphere is an extremely fast and effective approximate method to evenly distribute points on a sphere.

",.csv
Star Type Classification / NASA,1,star-type-classification,Stars.csv,DbCL-1.0,"## Star Type Classification
For comparing all models of ML
It can be used for prediction

Temperature -- K
L -- L/Lo
R --  R/Ro
AM -- Mv
Color -- General Color of Spectrum
Spectral_Class -- O,B,A,F,G,K,M / SMASS - https://en.wikipedia.org/wiki/Asteroid_spectral_types
Type  -- Red Dwarf, Brown Dwarf, White Dwarf, Main Sequence , Super Giants, Hyper Giants

TARGET:
Type 

from 0 to 5

- Red Dwarf - 0
- Brown Dwarf - 1
- White Dwarf - 2
- Main Sequence - 3
- Super Giants - 4
- Hyper Giants - 5

MATH:

Lo = 3.828 x 10^26 Watts
(Avg Luminosity of Sun)
Ro = 6.9551 x 10^8 m
(Avg Radius of Sun)",.csv
Star Wars 36k Reviews,1,star-wars-36k-reviews,star_wars_reviews.csv,Apache 2.0,"Introducing the **Star Wars 36k Reviews** dataset, a comprehensive collection comprising **36,927 realistic entries** meticulously assembled to capture the sentiments and preferences of Star Wars enthusiasts. Each entry provides valuable insights into various aspects of the Star Wars universe, as reflected in **the dataset's columns**:

- **review_id**: An identifier for each review entry.
- **fav_heroe**: Indicates the favorite heroic character chosen by respondents.
- **fav_villain**: Reveals the preferred antagonists, showcasing the villains that resonate most with fans.
- **fav_film**: Specifies the favored film installment of the Star Wars series, offering a glimpse into which cinematic journeys are most cherished by viewers.
- **fav_soundtrack**: Highlights the preferred musical compositions from the franchise.
- **fav_spaceship**: Provides insights into the favorite spacecraft within the Star Wars universe.
- **fav_planet**: Indicates the favored celestial locales.
- **fav_robot**: Showcases the preferred robotic characters.

Through the **Star Wars 36k Reviews** dataset, you can study and delve into the multifaceted landscape of *Star Wars fandom*, exploring the preferences and sentiments that shape this enduring cultural phenomenon.

**Hope you enjoy it! :)**

If you find value in this dataset, please consider giving it an *UP-VOTE*. Thanks!",.csv
Star Wars Characters,1,star-wars-characters,star_wars_character_dataset.csv,Attribution 4.0 International (CC BY 4.0),"The star wars movies inspired a generation. George Lucas' universe is vast and is home to many different species. From robots and humans to alien species, many with unique traits.

**Can you predict a characters homeworld based on their attributes?**",.csv
Starbucks,1,starbucks,starbucks.csv,Community Data License Agreement - Sharing - Version 1.0,"👏 **Upvote this dataset if you find it interesting!**

This dataset contains the **nutrition info for Starbucks menu items.**

 The 'Beverage_category' column classifies the type of beverage, such as coffee, tea, or smoothie. The 'Beverage' column provides the specific name of the drink, for instance, Caramel Macchiato or Green Tea Latte.

The **'Beverage_prep'** column details the preparation method of the beverage, including whether it's served hot or cold, and any additional ingredients or toppings like whipped cream or syrup. The **'Calories'** column lists the total caloric content of each beverage, providing insight into the energy provided by each drink.

The next three columns, **'Total Fat (g)', 'Trans Fat (g)', and 'Saturated Fat (g)'**, provide a breakdown of the fat content in each beverage. These columns are crucial for those monitoring their fat intake for health or dietary reasons. The **'Sodium (mg)'** column indicates the amount of sodium in each beverage, which is essential information for individuals on low-sodium diets.

The **'Total Carbohydrates (g)'** column provides the total carbohydrate content, including sugars, which is particularly useful for people managing diabetes or following a low-carb diet. Lastly, the **'Cholesterol (mg)'** column lists the amount of cholesterol in each beverage, a critical factor for those monitoring their cholesterol levels.

This dataset serves as a comprehensive guide to the nutritional content of Starbucks beverages, making it a valuable resource for researchers, dietitians, and health-conscious consumers.",.csv
Starbucks Corp. 🌟 Stock 2022-2024 📈,1,starbucks-corp-stock-2022-present,sbux_stock_data.csv,Apache 2.0,"## Overview
This analysis focuses on Starbucks stock performance from January 1, 2022, to the present date. By analyzing historical stock data, we aim to provide insights into  financial trends, market volatility, and factors influencing its stock price over this period.

## Column Names
- **Date:** The date of the stock data.
- **Open:** The opening price of stock on the given date.
- **High:** The highest price of stock during the trading day.
- **Low:** The lowest price of  stock during the trading day.
- **Close:** The closing price of  stock on the given date.
- **Adj Close:** The adjusted closing price of  stock, accounting for any corporate actions such as dividends or stock splits.
- **Volume:** The trading volume of  stock on the given date.",.csv
Starbucks Corporation,1,starbucks-corporation,Starbucks Corporation.csv,Apache 2.0,"**Overview of company**

Starbucks Corporation is a global coffeehouse chain, known for offering high-quality coffee, tea, and food items in a welcoming environment. Their role is to provide customers with a unique coffee experience while selling a variety of beverages and snacks.

 **Dataset** 

 Explore the historical daily stock data, including opening, closing, high, and low prices, along with adjusted close prices and trading volumes. Ideal for conducting market analysis, financial research, and building predictive models. Gain valuable insights into Starbucks' market behavior and investor sentiment over time.""",.csv
Starbucks Nutrition Facts,1,starbucks-nutrition,starbucks.csv,CC0-1.0,"```
Nutrition facts for several Starbucks food items
```
| Column  | Description                                                  |
| ------- | ------------------------------------------------------------ |
| item    | The name of the food item.                                   |
| calories| The amount of calories in the food item.                      |
| fat     | The quantity of fat in grams present in the food item.       |
| carb    | The amount of carbohydrates in grams found in the food item.  |
| fiber   | The quantity of dietary fiber in grams in the food item.      |
| protein | The amount of protein in grams contained in the food item.    |
| type    | The category or type of food item (bakery, bistro box, hot breakfast, parfait, petite, salad, or sandwich). |
",.csv
Starbucks Reviews Dataset,1,starbucks-reviews-dataset,reviews_data.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"This dataset contains a comprehensive collection of consumer reviews and ratings for Starbucks, a renowned coffeehouse chain. The data was collected through web scraping and includes textual reviews, star ratings, location information, and image links from multiple pages on the ConsumerAffairs website. It offers valuable insights into customer sentiment and feedback about Starbucks locations.

**Content:**

- **Name:** The reviewer's name, if available.
- **Location:** The location or city associated with the reviewer, if provided.
- **Date:** The date when the review was posted.
- **Rating:** The star rating given by the reviewer, ranges from 1 to 5.
- **Review:** The textual content of the review, captures the reviewer's experience and opinions.
- **Image Links:** Links to images associated with the reviews, if available.

**Use Cases:**

**Sentiment Analysis:** Researchers and data analysts can use this dataset to perform sentiment analysis to understand customer sentiment towards Starbucks.
**Consumer Insights:** Businesses can gain valuable insights into customer preferences and areas for improvement based on the reviews and ratings.
**Natural Language Processing (NLP):** NLP practitioners can utilize textual reviews for various NLP tasks, such as text classification, summarization, and topic modelling.

**Source:**

The data was collected by web scraping customer reviews and ratings from the ConsumerAffairs website. Please note that this dataset is for research and analysis purposes and may be subject to the terms and conditions specified by ConsumerAffairs.",.csv
StartUp Investments (Crunchbase),1,startup-investments-crunchbase,investments_VC.csv,CC0-1.0,"### Tableau giving us access to the link of the file:

[Download the file (again)](https://public.tableau.com/s/sites/default/files/media/Resources/crunchbase_monthly_export_d43b4klo2ade53.xlsx)
",.csv
Startup Success Prediction,1,startup-success-prediction,startup data.csv,CC0-1.0,"
### Context

A startup or start-up is a company or project begun by an entrepreneur to seek, develop, and validate a scalable economic model. While entrepreneurship refers to all new businesses, including self-employment and businesses that never intend to become registered, startups refer to new businesses that intend to grow large beyond the solo founder. Startups face high uncertainty and have high rates of failure, but a minority of them do go on to be successful and influential. Some startups become unicorns: privately held startup companies valued at over US$1 billion. [Source of information: Wikipedia]
![startup image](https://images.unsplash.com/photo-1556761175-5973dc0f32e7?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=500&q=60)
&nbsp;Startups play a major role in economic growth. They bring new ideas, spur innovation, create employment thereby moving the economy. There has been an exponential growth in startups over the past few years. Predicting the success of a startup allows investors to find companies that have the potential for rapid growth, thereby allowing them to be one step ahead of the competition.

### Objective

The objective is to predict whether a startup which is currently operating turns into a success or a failure. The success of a company is defined as the event that gives the company's founders a large sum of money through the process of M&A (Merger and Acquisition) or an IPO (Initial Public Offering). A company would be considered as failed if it had to be shut down.

### About the Data
The data contains industry trends, investment insights and individual company information. There are 48&nbsp;columns/features. Some of the features are:

- age_first_funding_year – quantitative
- age_last_funding_year – quantitative
- relationships – quantitative
- funding_rounds – quantitative
- funding_total_usd – quantitative
- milestones – quantitative
- age_first_milestone_year – quantitative
- age_last_milestone_year – quantitative
- state – categorical
- industry_type – categorical
- has_VC – categorical
- has_angel – categorical
- has_roundA – categorical
- has_roundB – categorical
- has_roundC – categorical
- has_roundD – categorical
- avg_participants – quantitative
- is_top500 – categorical
- status(acquired/closed) – categorical (the target variable, if a startup is ‘acquired’ by some other organization, means the startup succeed)&nbsp;

### Acknowledgements

- I would like to thank Ramkishan Panthena, for providing us this dataset. He is a Machine Learning Engineer at GMO.
- This dataset was used in data sprint #5 at [DPhi](https://dphi.tech//).


### Inspiration

Predicting the success of a startup allows investors to find companies that have the potential for rapid growth, thereby allowing them to be one step ahead of the competition.",.csv
State of Data Brazil 2021,1,state-of-data-2021,State of Data 2021 - Dataset - Pgina1.csv,CC-BY-NC-SA-4.0,"## 1 Sobre a Pesquisa

Sejam bem-vindos ao **State of Data Brazil 2021**, o maior e mais completo panorama sobre o mercado de trabalho brasileiro na área de dados. Veja mais detalhes no site da pesquisa: www.stateofdata.com.br - No site da pesquisa você também encontra um relatório completo onde exploramos esse dataset e chegamos a conclusões interessantes sobre o mercado de trabalho brasileiro na área de dados.

A presente pesquisa é o resultado de um esforço conjunto da **Data Hackers**, a maior comunidade de dados do Brasil, e da **Bain & Company**, consultoria global que ajuda empresas e organizações a promover mudanças que definam o futuro dos negócios, para mapear o mercado de trabalho de dados no Brasil.

A pesquisa foi realizada entre 18 de outubro de 2021 e 6 de dezembro de 2021 através de um questionário online e reuniu indicadores relacionados a perfil demográfico, formação, atuação no setor, remuneração, rotatividade e fatores de satisfação no ambiente de trabalho, incluindo o impacto do trabalho remoto nas preferências profissionais de 2.645 respondentes de todo o Brasil. A amostra reflete a visão de variados papéis de atuação em empresas, como os de analista de dados, cientista de dados e engenheiro de dados, bem como diferentes perfis de experiência profissional, incluindo analistas júnior, pleno, sênior e gestores.

Gostaríamos de agradecer a toda a comunidade Data Hackers e a todos os parceiros que nos apoiaram durante a pesquisa, incluindo André Sionek, Karine Lago, Canal Let's Data, Canal Programação Dinâmica, Canal do Mario Filho, Alura, Canal Estatidados e professora Fernanda Maciel, sem o apoio de vocês nunca teríamos chegado a uma pesquisa tão completa e abrangente.

## 2 Sobre o processamento e anonimização dos dados

O dataset foi anonimizado com o objetivo de garantir a privacidade dos respondentes, para isso foi necessário em alguns casos remover outliers que poderiam identificar o entrevistado e, portanto, nem todos os dados coletados na pesquisa estarão disponíveis aqui. Estados com menor incidência de resposta, como aqueles das regiões Norte, terão apenas sua região indicada no dataset, também como consequência do processo de anonimização, o mesmo aconteceu em algumas outras perguntas.

As perguntas cujas respostas são multi-valoradas ocupam mais de uma coluna no dataset. Portanto, para diferenciar quais colunas pertencem a quais perguntas, cada coluna é identificada com uma tupla. Sendo o primeiro identificador o da pergunta, e, no caso de várias respostas, o segundo identificador referencia a alternativa escolhida. As perguntas mapeadas são mostradas abaixo (lembrando que algumas foram removidas e outras tiveram alguns outliers transformados/apagados no processo de anonimização)

## 3 Sobre os dados da Pesquisa

O questionário foi dividido em 9 partes, e dentro de cada uma das partes temos as perguntas e opções de escolha.

Parte 1 - Dados demográficos
Parte 2 - Dados sobre carreira
Parte 3 - Desafios dos gestores de times de dados
Parte 4 - Conhecimentos na área de dados
Parte 5 - Objetivos na área de dados
Parte 6 - Conhecimentos em Engenharia de Dados/DE
Parte 7 - Conhecimentos em Análise de Dados/DA
Parte 8 - Conhecimentos em Ciências de Dados/DS
Parte 9 - Sobre a comunidade Data Hackers

Cada pergunta é dividida em Parte, Letra da Pergunta, Letra da Opção escolhida
Exemplo: P3a_a = Parte 3, pergunta (a), opção (a)

## 4 Próximos passos

Fique atento aos canais do Data Hackers pois entre Abril e Maio vamos divulgar o State of Data Challenge 2021, uma competição que vai premiar as melhores e mais interessantes análises feitas a partir do data set da pesquisa State of Data 2021.

Em caso de qualquer dúvida entre em contato no email: falecom@datahackers.com.br
",.csv
State of Data Brazil 2022,1,state-of-data-2022,State_of_data_2022.csv,Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO),"## 1 Sobre a Pesquisa

Sejam bem-vindos ao **State of Data Brazil 2022**, o maior e mais completo panorama sobre o mercado de trabalho brasileiro na área de dados. Veja mais detalhes no site da pesquisa: www.stateofdata.com.br - No site da pesquisa você também encontra um relatório completo onde exploramos esse dataset e chegamos a conclusões interessantes sobre o mercado de trabalho brasileiro na área de dados.

A presente pesquisa é o resultado de um esforço conjunto da **Data Hackers**, a maior comunidade de dados do Brasil, e da **Bain & Company**, consultoria global que ajuda empresas e organizações a promover mudanças que definam o futuro dos negócios, para mapear o mercado de trabalho de dados no Brasil.

A pesquisa foi realizada entre 10 de outubro de 2022 e 28 de novembro de 2022 através de um questionário online e reuniu indicadores relacionados a perfil demográfico, formação, atuação no setor, remuneração, rotatividade e fatores de satisfação no ambiente de trabalho, incluindo o impacto do trabalho remoto nas preferências profissionais de 4.271 respondentes de todo o Brasil. A amostra reflete a visão de variados papéis de atuação em empresas, como os de analista de dados, cientista de dados e engenheiro de dados, bem como diferentes perfis de experiência profissional, incluindo analistas júnior, pleno, sênior e gestores.

Gostaríamos de agradecer a toda a comunidade Data Hackers e a todos os parceiros que nos apoiaram durante a pesquisa, incluindo André Sionek, Karine Lago, Canal Let's Data, Canal Programação Dinâmica, Canal do Mario Filho, Alura, Canal Estatidados, Comunidade Mulheres em Dados, Teo Calvo, Flai, QuantitativaMente, Preditiva e professora Fernanda Maciel, sem o apoio de vocês nunca teríamos chegado a uma pesquisa tão completa e abrangente.

## 2 Sobre o processamento e anonimização dos dados

O dataset foi anonimizado com o objetivo de garantir a privacidade dos respondentes, para isso foi necessário em alguns casos remover outliers que poderiam identificar o entrevistado e, portanto, nem todos os dados coletados na pesquisa estarão disponíveis aqui. Estados com menor incidência de resposta, como alguns da região Norte por exemplo, terão apenas sua região indicada no dataset, também como consequência do processo de anonimização, o mesmo aconteceu em algumas outras perguntas.

As perguntas cujas respostas são multi-valoradas ocupam mais de uma coluna no dataset. Portanto, para diferenciar quais colunas pertencem a quais perguntas, cada coluna é identificada com uma tupla. Sendo o primeiro identificador o da pergunta, e, no caso de várias respostas, o segundo identificador referencia a alternativa escolhida. As perguntas mapeadas são mostradas abaixo (lembrando que algumas foram removidas e outras tiveram alguns outliers transformados/apagados no processo de anonimização)

## 3 Sobre os dados da Pesquisa

O questionário foi dividido em 8 partes, e dentro de cada uma das partes temos as perguntas e opções de escolha.

Parte 1 - Dados demográficos
Parte 2 - Dados sobre carreira
Parte 3 - Desafios dos gestores de times de dados
Parte 4 - Conhecimentos na área de dados
Parte 5 - Objetivos na área de dados
Parte 6 - Conhecimentos em Engenharia de Dados/DE
Parte 7 - Conhecimentos em Análise de Dados/DA
Parte 8 - Conhecimentos em Ciências de Dados/DS

Cada pergunta é dividida em Parte, Letra da Pergunta, Número da Opção escolhida
Exemplo: P3a_1 = Parte 3, pergunta (a), opção (1)

## 4 Próximos passos

Fique atento aos canais do Data Hackers pois entre Abril e Maio vamos divulgar o State of Data Challenge 2022, uma competição que vai premiar as melhores e mais interessantes análises feitas a partir do dataset da pesquisa State of Data 2022.

Em caso de qualquer dúvida entre em contato no email: falecom@datahackers.com.br",.csv
State-Sponsored Cyber Operations (2005-Present),1,state-sponsored-cyber-operations-2005-present,cyber-operations-incidents.csv,CC-BY-NC-SA-4.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F12064410%2Fc0b68fca805595f3a02e9be27019983d%2Fcyber%20operations%20flag.png?generation=1675671804167087&alt=media)

# YEAR 18 (August 25, 2005 - Present)
This is a dataset that tracks **state-sponsored cyber operations** across the globe since 2005.

All data are official figures from the **Council of Foreign Relations** that have been compiled and structured by myself. I decided to create this dataset to explore how countries around the world are **funding cyber operations to gain political leverage**. As human civilization becomes further entrenched into the Digital Age, the necessity for *increased government spending on cybersecurity* becomes equally apparent. I hope that this dataset not only highlights the widespread usage of cyber operations by states, but also how cybersecurity will protect a government's **own interests** in the process. 

# Data Sources
##### The primary data source used was the **Council on Foreign Relations**, an independent and nonpartisan American think tank specializing in U.S. foreign policy and international relations. Founded in 1921, the organization does not take policy positions but instead sponsors discussion, analysis, and research on various topics regarding foreign affairs.

1. [Cyber Operations Tracker](https://www.cfr.org/cyber-operations/) - The Council on Foreign Relations's Digital and Cyberspace Policy program offers a database of publicly known state-sponsored cyber operations since 2005. Through its meticulous compilation of information from various accredited institutions, the Council on Foreign Relations has created one of the most complete databases on cyber incidents to date.

# Statistics Being Tracked
- Title: Title/Summary of the cyber operation.
- Date: Date when the cyber operation was conducted.
- Affiliations: Affiliations behind the cyber operation, if known.
- Descriptions: Description of the cyber operation conducted.
- Response: Response of the suspects behind the cyber operation, if any.
- Victims: Victims that were targeted by the cyber operation, if known.
- Sponsor: The suspected state sponsor of the cyber operation.
- Type: Type of cyber operation conducted.
- Category: Demographic category of the cyber operation's victims.
- Sources_1: Source that reported the cyber operation.
- Sources_2: Source #2 that reported the cyber operation, if any.
- Sources_3: Source #3 that reported the cyber operation, if any.

# Dataset History
2023-02-06 - Dataset is created (17 years after the coverage start date).

[GitHub Repository](https://github.com/justin-2028/State-Sponsored-Cyber-Operations-2005-Present) - The same data but on GitHub.

# Code Starter
[Link to Notebook](https://www.kaggle.com/code/justin2028/state-sponsored-cyber-operations-code-starter)

# Acknowledgements
I would like to give acknowledgements to the sources that the Council of Foreign Relations used for their own data:
- [Florian Roth’s APT Groups and Operations spreadsheet](https://docs.google.com/spreadsheets/d/1H9_xaxQHpWaa4O_Son4Gx0YOIzlcBWMsdvePFX68EKU/pubhtml)
- [Center for Strategic and International Studies’ list of significant cyber events](https://www.csis.org/programs/technology-policy-program/cybersecurity/other-projects-cybersecurity/significant-cyber)
- [Kaspersky Lab’s Targeted Cyberattacks Logbook](https://apt.securelist.com/)",.csv
Steam Video Games,1,steam-video-games,steam-200k.csv,DbCL-1.0,"# Context 

Steam is the world's most popular PC Gaming hub, with over 6,000 games and a community of millions of gamers. With a massive collection that includes everything from AAA blockbusters to small indie titles, great discovery tools are a highly valuable asset for Steam. How can we make them better?


# Content

This dataset is a list of user behaviors, with columns: user-id, game-title, behavior-name, value. The behaviors included are 'purchase' and 'play'. The value indicates the degree to which the behavior was performed - in the case of 'purchase' the value is always 1, and in the case of 'play' the value represents the number of hours the user has played the game.


# Acknowledgements

This dataset is generated entirely from public Steam data, so we want to thank Steam for building such an awesome platform and community!


# Inspiration

The dataset is formatted to be compatible with [Tamber][1]. Build a Tamber engine and take it for a spin! 

Combine our collaborative filter's results with your favorite Machine Learning techniques with Ensemble Learning, or make Tamber do battle with something else you've built.

Have fun,
The Tamber Team


  [1]: https://tamber.com",.csv
Steel Dataset,1,steel-dataset,Steel_industry.csv,other,"**Additional Information**

The information gathered is from the DAEWOO Steel Co. Ltd in Gwangyang, South Korea. It produces several types of coils, steel plates, and iron plates. The information on electricity consumption is held in a cloud-based system. The information on energy consumption of the industry is stored on the website of the Korea Electric Power Corporation (pccs.kepco.go.kr), and the perspectives on daily, monthly, and annual data are calculated and shown.",.csv
Steel Fatigue Strength Prediction,1,steel-fatigue-strength-prediction,data.csv,Apache 2.0,"This dataset is a cleaned version of steel fatigue strength dataset from [National Institute for Materials Science (NIMS)](https://www.nims.go.jp/mits/%BB%B0%CA%DE%B0bak20030903/english/fatigue_lst_e.htm), Japan, provided by (this paper)[https://link.springer.com/article/10.1186/2193-9772-3-8#additional-information].

This dataset contains various experimental conditions during steel preparation, involving features of:

- Chemical composition - %C, %Si, %Mn, %P, %S, %Ni, %Cr, %Cu, %Mo (all in wt. %)
- Upstream processing details - ingot size, reduction ratio, non-metallic inclusions
- Heat treatment conditions - temperature, time and other process conditions for normalizing, through-hardening, carburizing-quenching and tempering processes
- Mechanical properties - YS, UTS, %EL, %RA, hardness, Charpy impact value (J/cm2), fatigue strength.

Specifically,

| Abbreviation | Property Details                                        |
|--------------|--------------------------------------------------------|
| C            | % Carbon                                               |
| Si           | % Silicon                                              |
| Mn           | % Manganese                                            |
| P            | % Phosphorus                                           |
| S            | % Sulphur                                              |
| Ni           | % Nickel                                               |
| Cr           | % Chromium                                             |
| Cu           | % Copper                                               |
| Mo           | % Molybdenum                                           |
| NT           | Normalizing Temperature                                |
| THT          | Through Hardening Temperature                          |
| THt          | Through Hardening Time                                 |
| THQCr        | Cooling Rate for Through Hardening                     |
| CT           | Carburization Temperature                              |
| Ct           | Carburization Time                                     |
| DT           | Diffusion Temperature                                  |
| Dt           | Diffusion time                                         |
| QmT          | Quenching Media Temperature (for Carburization)       |
| TT           | Tempering Temperature                                  |
| Tt           | Tempering Time                                         |
| TCr          | Cooling Rate for Tempering                             |
| RedRatio     | Reduction Ratio (Ingot to Bar)                         |
| dA           | Area Proportion of Inclusions Deformed by Plastic Work|
| dB           | Area Proportion of Inclusions Occurring in Discontinuous Array|
| dC           | Area Proportion of Isolated Inclusions                |
| Fatigue      | Rotating Bending Fatigue Strength (10^7 Cycles)       |

Please refer to the paper for more data preprocessing details.

Citation:
A. Agrawal, P. D. Deshpande, A. Cecen, G. P. Basavarsu, A. N. Choudhary and S. R. Kalidindi, Integr Mater Manuf Innov 3, 90 (2014).",.csv
Steel Industry datasets,1,steel-industry-datasets,Steel_industry.csv,CC0-1.0,"Date_Time: Timestamp indicating when the energy consumption data was recorded.

Usage_kWh: Energy usage in kilowatt-hours (kWh), representing the amount of electricity consumed during a specific period, likely related to steel production processes or facility operations.

Lagging_Current_Reactive.Power_kVarh: Reactive power consumption in kilovolt-amperes reactive hour (kVarh). Reactive power is essential in steel industry equipment for tasks such as magnetization and induction heating.

Leading_Current_Reactive_Power_kVarh: Similar to lagging current reactive power but likely refers to leading reactive power consumption, which can occur in capacitive loads.

CO2(tCO2): Carbon dioxide emissions in metric tons of CO2. This could indicate the environmental impact of energy consumption in steel production, as CO2 emissions are a concern in terms of greenhouse gas emissions and climate change.

Lagging_Current_Power_Factor: Power factor measures the efficiency of electrical power usage. A lagging power factor indicates inefficient use of electricity, which could signify inefficiencies in certain steel production processes or equipment.

Leading_Current_Power_Factor: Similar to lagging power factor but likely refers to leading power factor, which indicates more efficient use of electricity.

NSM (Normalized Solar Energy): This could be a derived feature representing solar energy normalized against some baseline. It might indicate the integration of renewable energy sources like solar power into the steel production process or facility operations.

WeekStatus: Indicates whether the data corresponds to a weekday or a weekend. This could be useful for analyzing energy consumption patterns based on the day of the week.

Day_Of_Week: Indicates the day of the week when the data was recorded, providing further granularity for analyzing energy consumption patterns over weekdays.",.csv
Stock List Dataset,1,stock-list-dataset,Stocks_data.csv,MIT,"Symbol: This acts as a unique identifier for a particular stock on a specific exchange. Just like AAPL represents Apple Inc. on the NASDAQ exchange.
Name: This is the full name of the company that issued the stock.
Currency: This indicates the currency in which the stock is traded. Examples include USD (US Dollar), EUR (Euro), and JPY (Japanese Yen).
Exchange: This refers to the stock exchange where the stock is traded. NASDAQ and NYSE are some well-known exchanges.
MIC Code: This stands for Market Identifier Code and is used to uniquely identify a specific exchange or trading venue.
Country: This specifies the country of incorporation of the company that issued the stock.
Type: the type of the st0ck",.csv
Stock Market Analysis,1,stock-market-analysis,stocks.csv,Apache 2.0,"The given dataset is a rich resource for performing in-depth quantitative analysis, offering comprehensive insights into market trends and stock behaviour. Key characteristics of the dataset are:

1. Ticker: The stock ticker symbol.
2. Date: The specific trading date.
3. Open: Opening price of the stock for the day.
4. High: Highest price point of the stock during the day.
5. Low: Lowest price point during the day.
6. Close: Closing price of the stock.
7. Adj Close: Adjusted closing price, factoring in corporate actions like splits.
8. Volume: Total trading volume of the stock.


Your task is to perform quantitative analysis to gain a deeper understanding of stock market dynamics and to inform investment strategies. The specific goals include:

Trend Analysis: Identifying long-term trends in stock prices and market movements.
Volatility Assessment: Evaluating the stability and risk associated with different stocks based on their price fluctuations.
Correlation Study: Investigating how different stocks correlate with each other, understanding market segments and diversification opportunities.
Risk-Return Trade-off Analysis: Analyzing the balance between the potential risks and rewards of different stocks, aiding in portfolio management.",.csv
Stock Market Analysis Data,1,stock-market-analysis-data,stocks.csv,other,"Given historical stock price data for Apple, Microsoft, Netflix and Google over the past three months, your task is to analyze and compare the performance of these companies in the stock market using various data science techniques.

Specifically, the goal is to identify trends and patterns in stock price movements, calculate moving averages and volatility for each company, and conduct correlation analysis to examine the relationships between different stock prices.

You can also download the latest data using the yfinance API instead of using the provided dataset.",.csv
Stock Market Dataset (NIFTY-500),1,nifty500-stocks-dataset,nifty_500.csv,other,"### Context

NIFTY 500 is India’s first broad-based stock market index of the Indian stock market. It contains the top 500 listed companies on the NSE. The NIFTY 500 index represents about 96.1% of free-float market capitalization and 96.5% of the total turnover on the National Stock Exchange (NSE).

NIFTY 500 companies are disaggregated into 72 industry indices. Industry weights in the index reflect industry weights in the market. For example, if the banking sector has a 5% weight in the universe of stocks traded on the NSE, banking stocks in the index would also have an approximate representation of 5% in the index. NIFTY 500 can be used for a variety of purposes such as benchmarking fund portfolios, launching index funds, ETFs, and other structured products.

- Other Notable Indices - 
    * <b>NIFTY 50</b>: Top 50 listed companies on the NSE. A diversified 50-stock index accounting for 13 sectors of the Indian economy.
    * <b>NIFTY Next 50</b>: Also called NIFTY Juniors. Represents 50 companies from NIFTY 100 after excluding the NIFTY 50 companies.
    * <b>NIFTY 100</b>: Diversified 100 stock index representing major sectors of the economy. NIFTY 100 represents the top 100 companies based on full market capitalization from NIFTY 500.
    * <b>NIFTY 200</b>: Designed to reflect the behavior and performance of large and mid-market capitalization companies.

### Content

The dataset comprises various parameters and features for each of the NIFTY 500 Stocks, including Company Name, Symbol, Industry, Series, Open, High, Low, Previous Close, Last Traded Price, Change, Percentage Change, Share Volume, Value in Indian Rupee, 52 Week High, 52 Week Low, 365 Day Percentage Change, and 30 Day Percentage Change.

### Dataset Glossary (Column-Wise)

<b>Company Name</b>: Name of the Company.

<b>Symbol</b>: A stock symbol is a unique series of letters assigned to a security for trading purposes.

<b>Industry</b>: Name of the industry to which the stock belongs.

<b>Series</b>: <b>EQ</b> stands for Equity. In this series intraday trading is possible in addition to delivery and <b>BE</b> stands for Book Entry. Shares falling in the Trade-to-Trade or T-segment are traded in this series and no intraday is allowed. This means trades can only be settled by accepting or giving the delivery of shares.

<b>Open</b>: It is the price at which the financial security opens in the market when trading begins. It may or may not be different from the previous day's closing price. The security may open at a higher price than the closing price due to excess demand for the security.

<b>High</b>: It is the highest price at which a stock is traded during the course of the trading day and is typically higher than the closing or equal to the opening price.

<b>Low</b>: Today's low is a security's intraday low trading price. Today's low is the lowest price at which a stock trades over the course of a trading day.

<b>Previous Close</b>: The previous close almost always refers to the prior day's final price of a security when the market officially closes for the day. It can apply to a stock, bond, commodity, futures or option co-contract, market index, or any other security.

<b>Last Traded Price</b>: The last traded price (LTP) usually differs from the closing price of the day. This is because the closing price of the day on NSE is the weighted average price of the last 30 mins of trading. The last traded price of the day is the actual last traded price.

<b>Change</b>: For a stock or bond quote, change is the difference between the current price and the last trade of the previous day. For interest rates, change is benchmarked against a major market rate (e.g., LIBOR) and may only be updated as infrequently as once a quarter.

<b>Percentage Change</b>: Take the selling price and subtract the initial purchase price. The result is the gain or loss. Take the gain or loss from the investment and divide it by the original amount or purchase price of the investment. Finally, multiply the result by 100 to arrive at the percentage change in the investment.

<b>Share Volume</b>: Volume is an indicator that means the total number of shares that have been bought or sold in a specific period of time or during the trading day. It will also involve the buying and selling of every share during a specific time period.

<b>Value (Indian Rupee)</b>: Market value—also known as market cap—is calculated by multiplying a company's outstanding shares by its current market price.

<b>52-Week High</b>: A 52-week high is the highest share price that a stock has traded at during a passing year. Many market aficionados view the 52-week high as an important factor in determining a stock's current value and predicting future price movement. 52-week High prices are adjusted for Bonus, Split & Rights Corporate actions.

<b>52-Week Low</b>: A 52-week low is the lowest share price that a stock has traded at during a passing year. Many market aficionados view the 52-week low as an important factor in determining a stock's current value and predicting future price movement. 52-week low prices are adjusted for Bonus, Split & Rights Corporate actions.

<b>365 Day Percentage Change</b>: Percent change is calculated with respect to adjusted price on ex-date for Corporate Actions like Dividend, Bonus, Rights & Face Value Split and also adjusted for Past  Dividend, Bonus, Rights & Face Value Split and also adjusted for Past 365 days.

<b>30 Day Percentage Change</b>: Percent change is calculated with respect to adjusted price on ex-date for Corporate Actions like Dividend, Bonus, Rights & Face Value Split and also adjusted for the Past 30 days.

### Structure of the Dataset

![](https://i.imgur.com/8Wryczg.png)

### Acknowledgment

This Dataset is created from: https://www.nseindia.com/. If you want to learn more, you can visit the website of the National Stock Exchange of India Limited (NSE)

Cover Photo by <b>Nataliya Vaitkevich</b>: https://www.pexels.com/photo/black-and-white-remote-control-beside-white-pen-6120182/",.csv
Stock Past One Year Data ( Daily updates ),1,stock-past-one-year-data,stocks_2023-05-17_to_2024-05-16.csv,Apache 2.0,"Every time , we invest in a stock , we always see its performance in past , and compare to other to make choices . but this task is complicated . Let us simplify it with help of data science !!",.csv
Stock Price Prediction,1,stock-price-prediction,stock_data.csv,Apache 2.0,"The stock price data represents the daily closing prices of multiple stocks over a specified time period. Each stock's price fluctuates based on various factors such as market demand, company performance, economic conditions, and investor sentiment. The dataset provides a snapshot of stock price movements, allowing analysts to observe trends, patterns, and potential relationships between different stocks over time.",.csv
Stock Prices for META Ticker Symbol,1,stock-prices-for-meta-ticker-symbol,META_stock_data.csv,Apache 2.0,"### Dataset Description:

This dataset contains historical stock price data for the Meta (META) ticker symbol. The data includes daily stock prices over a one-year period, from [start date] to [end date]. Each row in the dataset represents one trading day and includes information such as the date, opening price, high price, low price, closing price, and trading volume.

**Columns:**
1. **Date:** The date of the trading day.
2. **Open:** The opening price of the stock on that trading day.
3. **High:** The highest price of the stock reached during that trading day.
4. **Low:** The lowest price of the stock reached during that trading day.
5. **Close:** The closing price of the stock on that trading day.
6. **Volume:** The trading volume of the stock on that trading day.

**Use Case:**
This dataset can be used for various financial analyses, including trend analysis, volatility assessment, and forecasting. Researchers and analysts interested in understanding the historical performance of Meta stock can utilize this dataset to derive insights and make informed investment decisions.

**Data Source:**
The data is sourced from Yahoo Finance using the `yfinance` library in Python.
",.csv
Store Sales,1,store-sales,s.csv,MIT,"Dive into the dynamic world of retail as we harness the power of time series forecasting to anticipate store sales, unveiling insights that drive strategic decisions and maximize profit potential.",.csv
Store Sales Forecast Dataset,1,store-sales-forecast-dataset,stores_sales_forecasting.csv,Apache 2.0,"This dataset offers a valuable resource for businesses operating in the retail furniture sector. By analyzing historical sales data from the superstore dataset, users can gain insights into future sales patterns and trends. This information can be utilized to optimize inventory management strategies, anticipate customer demand, and enhance overall operational efficiency. Whether for retail managers, analysts, or data scientists, this dataset provides a foundation for informed decision-making, helping businesses maintain stability and drive sustained growth in the dynamic retail environment.",.csv
Store Sales Forecasting Dataset,1,store-sales-forecasting-dataset,stores_sales_forecasting.csv,Apache 2.0,"This dataset offers a valuable resource for businesses operating in the retail furniture sector. By analyzing historical sales data from the superstore dataset, users can gain insights into future sales patterns and trends. This information can be utilized to optimize inventory management strategies, anticipate customer demand, and enhance overall operational efficiency. Whether for retail managers, analysts, or data scientists, this dataset provides a foundation for informed decision-making, helping businesses maintain stability and drive sustained growth in the dynamic retail environment.",.csv
Store database,1,store-database,Stores.csv,CC-BY-SA-4.0,"The ""Stores.csv"" dataset comprises information about various stores. It includes several features for each store, such as:

""Store Number"": Which likely serves as a unique identifier
""AreaStore"": Denoting the store's physical area in square meters
""Property"": Specifying whether the store is owned or rented
""Type"": Classifying the store's category
""Old/New"": Indicating whether the store is a new or established one
""Checkout Number"": Potentially representing the number of cash registers
""Revenue"": Revealing the financial performance or earnings of each store

",.csv
Street Light Fault Prediction Dataset,1,street-light-fault-prediction-dataset,street_light_fault_prediction_dataset.csv,MIT,"This synthetic dataset contains information related to street light operations for 94 bulbs over the course of 365 days in the year 2023. The features include:

**bulb_number**: The unique identifier for each street light bulb.

**timestamp**: The timestamp of data recording.

**power_consumption** (Watts): The amount of electrical power consumed by the street light.
**voltage_levels** (Volts): The voltage levels supplied to the street light.

**current_fluctuations** (Amperes): Fluctuations in the electric current flowing through the street light.

**temperature** (Celsius): The ambient temperature surrounding the street light.

**environmental_conditions**: The weather conditions at the location (Clear, Cloudy, Rainy).

**current_fluctuations_env** (Amperes): Environmental factors contributing to fluctuations in electric current.

**fault_type**: The type of fault observed (0: No fault, 1: Short circuit, 2: Voltage Surge, 3: Bulb failure, 4: Light Flickering).",.csv
Stroke Prediction,1,stroke-prediction,stroke_prediction_dataset.csv,Apache 2.0,"Welcome to Incribo's synthetic tourism dataset! Crafted with precision, this dataset offers a realistic representation of travel history, making it an ideal playground for various analytical tasks.

Use the cybersecurity attacks dataset to help you assess the heatmaps, attack signatures, types, and more!

Remember, this is just a sample! If you're intrigued and want access to the complete dataset or have specific requirements, don't hesitate to contact us(info@incribo.com). Happy building!",.csv
Student Attitude and Behavior,1,student-attitude-and-behavior,Student Attitude and Behavior.csv,other,"
📊 **Student Attitude and Behavior Dataset 🎓**

 This dataset contains information collected from university students through a Google form. It includes details such as certification courses, gender, department, height (in cm), weight (in kg), marks in 10th and 12th grade, college marks, hobbies, daily studying time, preferred study environment, salary expectations, satisfaction with their degree, willingness to pursue a career related to their degree, social media and video usage, traveling time, stress levels, and financial status. The dataset aims to provide insights into student behavior and can be used for analysis and research purposes.

**Column Descriptions:**

1. Certification Course: Indicates whether the student has completed any certification course or not. ✅
2. Gender: The gender of the student. 🚻
3. Department: The department or field of study the student is enrolled in. 📚
4. Height (CM): The height of the student in centimeters. 📏
5. Weight (KG): The weight of the student in kilograms. ⚖️
6. 10th Mark: The student's marks obtained in the 10th grade. 📝
7. 12th Mark: The student's marks obtained in the 12th grade. 🎓
8. College Mark: The student's marks obtained in their college or university. 🏫
9. Hobbies: The hobbies or interests of the student. 🎨
10. Daily Studying Time: The amount of time the student spends studying on a daily basis. ⏰
11. Prefer to Study in: The preferred study environment or location of the student. 📚🌳
12. Salary Expectation: The student's expectation for their future salary. 💰
13. Do you like your degree?: The student's opinion on whether they like their degree or not. 👍👎
14. Willingness to pursue a career based on their degree: The student's willingness to pursue a career related to their degree. 🏢
15. Social Media & Video: The student's engagement with social media and video platforms. 📱📺
16. Traveling Time: The time it takes for the student to commute or travel to their educational institution. 🚗
17. Stress Level: The perceived stress level of the student. 😓
18. Financial Status: The financial status or economic background of the student. 💵
19. Part-time Job: Whether the student is engaged in a part-time job or not. 💼

Feel free to utilize this dataset for analysis and research purposes! 📈🔍",.csv
Student Behavior,1,student-behavior,Student_Behaviour.csv,CC0-1.0,"This dataset contains information collected from university students through a Google form. It includes details such as certification courses, gender, department, height (in cm), weight (in kg), marks in 10th and 12th grade, college marks, hobbies, daily studying time, preferred study environment, salary expectations, satisfaction with their degree, willingness to pursue a career related to their degree, social media and video usage, traveling time, stress levels, and financial status. The dataset aims to provide insights into student behavior and can be used for analysis and research purposes.

The small description for each column in the dataset:
1. Certification Course: Indicates whether the student has completed any certification course or not.
2. Gender: The gender of the student.
3. Department: The department or field of study the student is enrolled in.
4. Height (CM): The height of the student in centimeters.
5. Weight (KG): The weight of the student in kilograms.
6. 10th Mark: The student's marks obtained in the 10th grade.
7. 12th Mark: The student's marks obtained in the 12th grade.
8. College Mark: The student's marks obtained in their college or university.
9. Hobbies: The hobbies or interests of the student.
10. Daily Studying Time: The amount of time the student spends studying on a daily basis.
11. Prefer to Study in: The preferred study environment or location of the student.
12. Salary Expectation: The student's expectation for their future salary.
13. Do you like your degree?: The student's opinion on whether they like their degree or not.
14. Willingness to pursue a career based on their degree: The student's willingness to pursue a career related to their degree.
15. Social Media & Video: The student's engagement with social media and video platforms.
16. Traveling Time: The time it takes for the student to commute or travel to their educational institution.
17. Stress Level: The perceived stress level of the student.
18. Financial Status: The financial status or economic background of the student.
19. Part-time Job: Whether the student is engaged in a part-time job or not.",.csv
Student Classification Dataset,1,student-classification-dataset,student.csv,Apache 2.0,"This dataset encompasses various aspects related to student performance. Each entry is uniquely identified by an 'Id'. The dataset includes demographic information such as 'Student_Age' and 'Sex'. 'High_School_Type' categorizes the type of high school attended, while 'Scholarship' indicates whether the student has a scholarship. Details about 'Additional_Work' and involvement in 'Sports_activity' provide insights into extracurricular commitments.

'Transportation' outlines the mode of commuting for each student. Academic aspects are captured through 'Weekly_Study_Hours', 'Attendance', and evaluations of 'Reading', 'Notes', and 'Listening_in_Class'. The culmination of these factors is reflected in the 'Grade' column, providing a comprehensive overview of student performance. This dataset serves as a valuable resource for exploring the multifaceted dynamics influencing academic outcomes.",.csv
Student General Degree College Data ,1,real-student-mbb-degree-college-data,Student Degree College Data.csv,other,"This dataset presents student information from a General Degree College, where subjects are selected according to high school performance. Included are categories, gender, year of passing, marks for the first choice subject, the first choice subject itself, marks for the second choice subject, and subsequent choices. 📊 Ideal for in-depth data analysis in Excel, this dataset offers insights into academic preferences and trends. Let's dive in and craft a compelling dashboard to unlock its full potential! 🚀",.csv
Student Marks Dataset,1,student-marks-dataset,Student_Marks.csv,CC0-1.0,"![](https://raw.githubusercontent.com/Masterx-AI/Project_Student_Marks_Prediction_/main/smp.jpg)

### Description:

The data consists of Marks of students including their study time & number of courses. The dataset is downloaded from UCI Machine Learning Repository.

**Properties of the Dataset:** \
Number of Instances: 100\
Number of Attributes: 3 including the target variable.

The project is simple yet challenging as it is has very limited features & samples. Can you build regression model to capture all the patterns in the dataset, also maitaining the generalisability of the model?


### Objective:
- Understand the Dataset & cleanup (if required).
- Build Regression models to predict the student marks wrt multiple features.
- Also evaluate the models & compare their respective scores like R2, RMSE, etc.",.csv
Student Performance (Multiple Linear Regression),1,student-performance-multiple-linear-regression,Student_Performance.csv,other,"# **Description:**
The Student Performance Dataset is a dataset designed to examine the factors influencing academic student performance. The dataset consists of 10,000 student records, with each record containing information about various predictors and a performance index.


## **Variables:**

- **Hours Studied**: The total number of hours spent studying by each student.
- **Previous Scores**: The scores obtained by students in previous tests.
- **Extracurricular Activities**: Whether the student participates in extracurricular activities (Yes or No).
- **Sleep Hours**: The average number of hours of sleep the student had per day.
- **Sample Question Papers Practiced**: The number of sample question papers the student practiced.

**Target Variable**:
- **Performance Index**: A measure of the overall performance of each student. The performance index represents the student's academic performance and has been rounded to the nearest integer. The index ranges from 10 to 100, with higher values indicating better performance.

The dataset aims to provide insights into the relationship between the predictor variables and the performance index. Researchers and data analysts can use this dataset to explore the impact of studying hours, previous scores, extracurricular activities, sleep hours, and sample question papers on student performance.

**P.S**: Please note that this dataset is synthetic and created for illustrative purposes. The relationships between the variables and the performance index may not reflect real-world scenarios

## **License**: 
Anyone is free to share and use the data",.csv
Student Performance Dataset,1,student-performance-data,student_data.csv,CC0-1.0,"Student Performance Data was obtained in a survey of students' math course in secondary school.
It consists of **33 Column** 
Dataset Contains Features like
- school ID 
- gender
- age 
- size of family
- Father education
- Mother education
- Occupation of Father and Mother
- Family Relation
- Health
- Grades

This dataset can be used for Regression (as target variable **Grade**) as well as Analysis tasks. it might contain imbalanced category features.

**Please do Upvote if this Dataset really helpful to you.**",.csv
Student Satisfaction Survey,1,student-satisfaction-survey,Student_Satisfaction_Survey.csv,CC0-1.0,"The dataset is regarding survey conducted at an autonomous college on college faculties performance and treatment towards students at the college. Questionnaire of 20 being rolled out to each department available at the college and randomly given to sampled list of students for the feedback.


| Column |Description  |
| --- | --- |
| SN | Serial Number of the Survey Question  |
| Total Feedback Given | Selected number of sample students for the feedback per Course|
| Total Configured | Total Strength of the batch of the Course |
| Questions | List of 20 Survey Questions in Total  |
| Weightage 1 | Lowest grade on scale  |
| Weightage 2 | better than lowest but below average rating  |
| Weightage 3 | Average  |
| Weightage 4 | Above Average  |
| Weightage 5 | Best rating  |
| Average/ Percentage | Weighted Average shown in absolute as well as in percentage terms  |
| Course Name | Current Year of the Graduation/Post Graduation  |
| Basic Course | Graduation/Post Graduation Stream  |

",.csv
Student School Attendance,1,student-school-attendance,School_Attendance_by_Student_Group.csv,Apache 2.0,"This dataset includes the attendance rate for public school students PK-12 by student group and by district during the 2021-2022 school year.

Student groups include:

- Students experiencing homelessness
- Students with disabilities
- Students who qualify for free/reduced lunch
- English learners
- All high needs students
- Non-high needs students
- Students by race/ethnicity (Hispanic/Latino of any race, Black or African American, White, All other races)

Attendance rates are provided for each student group by district and for the state. Students who are considered high needs include students who are English language learners, who receive special education, or who qualify for free and reduced lunch.

When no attendance data is displayed in a cell, data have been suppressed to safeguard student confidentiality, or to ensure that statistics based on a very small sample size are not interpreted as equally representative as those based on a sufficiently larger sample size.",.csv
Student Stress Factors: A Comprehensive Analysis,1,student-stress-factors-a-comprehensive-analysis,StressLevelDataset.csv,Apache 2.0,":grinning:Unlock the secrets of student stress with our easy-to-understand dataset! Dive into real-life factors like sleep quality, study load, and even bullying. Discover how the environment or even friendships can impact stress. Perfect for beginners eager to explore and make a difference. Start your data journey with us and uncover stories that matter!

:grinning:This dataset contains around 20 features that create the most impact on the Stress of a Student. The features are selected scientifically considering 5 major factors, they are Psychological, Physiological, Social, Environmental, and Academic Factors. Some of them are: 
Psychological Factors =&gt; 'anxiety_level', 'self_esteem', 'mental_health_history', 'depression', 
Physiological Factors =&gt; 'headache', 'blood_pressure', 'sleep_quality', 'breathing_problem
Environmental Factors =&gt; 'noise_level', 'living_conditions', 'safety', 'basic_needs',
Academic Factors =&gt; 'academic_performance', 'study_load', 'teacher_student_relationship', 'future_career_concerns', 
Social Factor =&gt; 'social_support', 'peer_pressure', 'extracurricular_activities', 'bullying'

**Task for the beginners:**
*Time to rise and shine. Best of Luck. Comment down your notebook, if you are able to solve them.*

**Descriptive Statistics:**

1) How many students are in the dataset?
2) What is the average anxiety level of students in the dataset?
3) How many students have reported a history of mental health issues?
**Psychological Factors:**

1) How many students have a self-esteem level below the average?
2) What percentage of students have reported experiencing depression?
**Physiological Factors:**

1) How many students experience headaches frequently?
2) What is the average blood pressure reading among the students?
3) How many students rate their sleep quality as poor?
**Environmental Factors:**

1) How many students live in conditions with high noise levels?
2) What percentage of students feel unsafe in their living conditions?
3) How many students have reported not having their basic needs met?
**Academic Factors:**

1) How many students rate their academic performance as below average?
2) What is the average study load reported by students?
3) How many students have concerns about their future careers?
**Social Factors:**

1) How many students feel they have strong social support?
2) What percentage of students have experienced bullying?
3) How many students participate in extracurricular activities?
**Comparative Analysis:**

1) Is there a correlation between anxiety level and academic performance?
2) Do students with poor sleep quality also report higher levels of depression?
3) Are students who experience bullying more likely to have a history of mental health issues?
**General Exploration:**

1) Which factor (Psychological, Physiological, Environmental, Academic, Social) has the highest number of students reporting negative experiences or conditions?
2) Are there any noticeable trends or patterns when comparing different factors?
3) Which specific feature within each factor has the most significant impact on student stress, based on the dataset?


",.csv
Student Studeis Recommendation,1,student-studeis-recommendation,student-scores.csv,Apache 2.0,"Dataset Description:
This dataset contains information about students enrolled in an academy, including their personal details, academic scores, extracurricular activities, and career aspirations.

Features Information:
id: Unique identifier for each student.
first_name: First name of the student.
last_name: Last name of the student.
email: Email address of the student.
gender: Gender of the student (male/female).
part_time_job: Indicates whether the student has a part-time job (True/False).
absence_days: Number of days the student has been absent.
extracurricular_activities: Indicates whether the student participates in extracurricular activities (True/False).
weekly_self_study_hours: Number of hours the student spends on self-study per week.
career_aspiration: Aspirational career path of the student.
math_score: Score achieved by the student in mathematics.
history_score: Score achieved by the student in history.
physics_score: Score achieved by the student in physics.
chemistry_score: Score achieved by the student in chemistry.
biology_score: Score achieved by the student in biology.
english_score: Score achieved by the student in English.
geography_score: Score achieved by the student in geography.
Usage in ML Projects:
This dataset can be used for various machine learning projects, including but not limited to:

Predicting students' career aspirations based on their academic performance and extracurricular activities.
Predicting students' absenteeism based on their personal and academic characteristics.
Exploring the relationship between students' academic scores and their participation in extracurricular activities or part-time jobs.
Note:
Before using this dataset for any analysis or machine learning projects, it's essential to preprocess the data, handle missing values, encode categorical variables, and split the data into training and testing sets appropriately. Additionally, ensure compliance with any privacy or ethical considerations when working with personal data such as email addresses.",.csv
Student Study Performance,1,student-study-performance,study_performance.csv,Attribution 4.0 International (CC BY 4.0),"# Problem Statement:
This project understands how the student's performance (test scores) is affected by other variables such as Gender, Ethnicity, Parental level of education, Lunch and Test preparation course.

# Content
This data set consists of the marks secured by the students in various subjects.
- gender : sex of students -&gt; (Male/female)
- race/ethnicity : ethnicity of students -&gt; (Group A, B,C, D,E)
- parental level of education : parents' final education -&gt;(bachelor's degree,some college,master's degree,associate's degree,- high school)
- lunch : having lunch before test (standard or free/reduced)
- test preparation course : complete or not complete before test
- math score
- reading score
- writing score

# Inspiration:
To understand the influence of the parent's background, test preparation etc on students' performance",.csv
Student performance (PIP),1,student-performance-pip,Student performance (Polytechnic Institute of Portalegre).csv,Attribution 4.0 International (CC BY 4.0),"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16192307%2Fb1a84007520b6f589dcb5d01b842d1b5%2FThinkstock_475924741-CampusUSA-multiethnic-college-students-in-caps-and-gowns-1068x712.jpg?generation=1712443672494495&alt=media)

A dataset created at a higher education institution - 'Polytechnic Institute of Portalegre (Portugal)' (derived from several disparate databases) relating to students studying in various undergraduate degrees such as agronomy, design, education, nursing, journalism, management, social services and technology. The dataset includes information known at the time of student enrollment (academic path, demographics, and social-economic factors) and the students' academic performance at the end of the first and second semesters. The data is used to build classification models to predict students' dropout and academic sucess. The problem is formulated as a three category classification task, in which there is a strong imbalance towards one of the classes.

**For what purpose was the dataset created?**

The dataset was created in a project that aims to contribute to the reduction of academic dropout and failure in higher education, by using machine learning techniques to identify students at risk at an early stage of their academic path, so that strategies to support them can be put into place. 
The dataset includes information known at the time of student enrollment – academic path, demographics, and social-economic factors. 
The problem is formulated as a three category classification task (dropout, enrolled, and graduate) at the end of the normal duration of the course. 

**Columns:**

**Marital status:** 1 – single 2 – married 3 – widower 4 – divorced 5 – facto union 6 – legally separated. 

**Application mode:** 1 - 1st phase - general contingent 2 - Ordinance No. 612/93 5 - 1st phase - special contingent (Azores Island) 7 - Holders of other higher courses 10 - Ordinance No. 854-B/99 15 - International student (bachelor) 16 - 1st phase - special contingent (Madeira Island) 17 - 2nd phase - general contingent 18 - 3rd phase - general contingent 26 - Ordinance No. 533-A/99, item b2) (Different Plan) 27 - Ordinance No. 533-A/99, item b3 (Other Institution) 39 - Over 23 years old 42 - Transfer 43 - Change of course 44 - Technological specialization diploma holders 51 - Change of institution/course 53 - Short cycle diploma holders 57 - Change of institution/course (International). 

**Application order:** Application order (between 0 - first choice; and 9 last choice).

**Course:** 33 - Biofuel Production Technologies 171 - Animation and Multimedia Design 8014 - Social Service (evening attendance) 9003 - Agronomy 9070 - Communication Design 9085 - Veterinary Nursing 9119 - Informatics Engineering 9130 - Equinculture 9147 - Management 9238 - Social Service 9254 - Tourism 9500 - Nursing 9556 - Oral Hygiene 9670 - Advertising and Marketing Management 9773 - Journalism and Communication 9853 - Basic Education 9991 - Management (evening attendance). 

**Daytime/evening attendance:** 1 – daytime 0 - evening. 

**Previous qualification:**	 1 - Secondary education 2 - Higher education - bachelor's degree 3 - Higher education - degree 4 - Higher education - master's 5 - Higher education - doctorate 6 - Frequency of higher education 9 - 12th year of schooling - not completed 10 - 11th year of schooling - not completed 12 - Other - 11th year of schooling 14 - 10th year of schooling 15 - 10th year of schooling - not completed 19 - Basic education 3rd cycle (9th/10th/11th year) or equiv. 38 - Basic education 2nd cycle (6th/7th/8th year) or equiv. 39 - Technological specialization course 40 - Higher education - degree (1st cycle) 42 - Professional higher technical course 43 - Higher education - master (2nd cycle).

**Previous qualification (grade)**: Grade of previous qualification (between 0 and 200).

**Nacionality:** 1 - Portuguese; 2 - German; 6 - Spanish; 11 - Italian; 13 - Dutch; 14 - English; 17 - Lithuanian; 21 - Angolan; 22 - Cape Verdean; 24 - Guinean; 25 - Mozambican; 26 - Santomean; 32 - Turkish; 41 - Brazilian; 62 - Romanian; 100 - Moldova (Republic of); 101 - Mexican; 103 - Ukrainian; 105 - Russian; 108 - Cuban; 109 - Colombian. 

**Mother's qualification:** 1 - Secondary Education - 12th Year of Schooling or Eq. 2 - Higher Education - Bachelor's Degree 3 - Higher Education - Degree 4 - Higher Education - Master's 5 - Higher Education - Doctorate 6 - Frequency of Higher Education 9 - 12th Year of Schooling - Not Completed 10 - 11th Year of Schooling - Not Completed 11 - 7th Year (Old) 12 - Other - 11th Year of Schooling 14 - 10th Year of Schooling 18 - General commerce course 19 - Basic Education 3rd Cycle (9th/10th/11th Year) or Equiv. 22 - Technical-professional course 26 - 7th year of schooling 27 - 2nd cycle of the general high school course 29 - 9th Year of Schooling - Not Completed 30 - 8th year of schooling 34 - Unknown 35 - Can't read or write 36 - Can read without having a 4th year of schooling 37 - Basic education 1st cycle (4th/5th year) or equiv. 38 - Basic Education 2nd Cycle (6th/7th/8th Year) or Equiv. 39 - Technological specialization course 40 - Higher education - degree (1st cycle) 41 - Specialized higher studies course 42 - Professional higher technical course 43 - Higher Education - Master (2nd cycle) 44 - Higher Education - Doctorate (3rd cycle). 

**Father's qualification:** 1 - Secondary Education - 12th Year of Schooling or Eq. 2 - Higher Education - Bachelor's Degree 3 - Higher Education - Degree 4 - Higher Education - Master's 5 - Higher Education - Doctorate 6 - Frequency of Higher Education 9 - 12th Year of Schooling - Not Completed 10 - 11th Year of Schooling - Not Completed 11 - 7th Year (Old) 12 - Other - 11th Year of Schooling 13 - 2nd year complementary high school course 14 - 10th Year of Schooling 18 - General commerce course 19 - Basic Education 3rd Cycle (9th/10th/11th Year) or Equiv. 20 - Complementary High School Course 22 - Technical-professional course 25 - Complementary High School Course - not concluded 26 - 7th year of schooling 27 - 2nd cycle of the general high school course 29 - 9th Year of Schooling - Not Completed 30 - 8th year of schooling 31 - General Course of Administration and Commerce 33 - Supplementary Accounting and Administration 34 - Unknown 35 - Can't read or write 36 - Can read without having a 4th year of schooling 37 - Basic education 1st cycle (4th/5th year) or equiv. 38 - Basic Education 2nd Cycle (6th/7th/8th Year) or Equiv. 39 - Technological specialization course 40 - Higher education - degree (1st cycle) 41 - Specialized higher studies course 42 - Professional higher technical course 43 - Higher Education - Master (2nd cycle) 44 - Higher Education - Doctorate (3rd cycle). 

**Mother's occupation:** 0 - Student 1 - Representatives of the Legislative Power and Executive Bodies, Directors, Directors and Executive Managers 2 - Specialists in Intellectual and Scientific Activities 3 - Intermediate Level Technicians and Professions 4 - Administrative staff 5 - Personal Services, Security and Safety Workers and Sellers 6 - Farmers and Skilled Workers in Agriculture, Fisheries and Forestry 7 - Skilled Workers in Industry, Construction and Craftsmen 8 - Installation and Machine Operators and Assembly Workers 9 - Unskilled Workers 10 - Armed Forces Professions 90 - Other Situation 99 - (blank) 122 - Health professionals 123 - teachers 125 - Specialists in information and communication technologies (ICT) 131 - Intermediate level science and engineering technicians and professions 132 - Technicians and professionals, of intermediate level of health 134 - Intermediate level technicians from legal, social, sports, cultural and similar services 141 - Office workers, secretaries in general and data processing operators 143 - Data, accounting, statistical, financial services and registry-related operators 144 - Other administrative support staff 151 - personal service workers 152 - sellers 153 - Personal care workers and the like 171 - Skilled construction workers and the like, except electricians 173 - Skilled workers in printing, precision instrument manufacturing, jewelers, artisans and the like 175 - Workers in food processing, woodworking, clothing and other industries and crafts 191 - cleaning workers 192 - Unskilled workers in agriculture, animal production, fisheries and forestry 193 - Unskilled workers in extractive industry, construction, manufacturing and transport 194 - Meal preparation assistants. 

**Father's occupation:** 0 - Student 1 - Representatives of the Legislative Power and Executive Bodies, Directors, Directors and Executive Managers 2 - Specialists in Intellectual and Scientific Activities 3 - Intermediate Level Technicians and Professions 4 - Administrative staff 5 - Personal Services, Security and Safety Workers and Sellers 6 - Farmers and Skilled Workers in Agriculture, Fisheries and Forestry 7 - Skilled Workers in Industry, Construction and Craftsmen 8 - Installation and Machine Operators and Assembly Workers 9 - Unskilled Workers 10 - Armed Forces Professions 90 - Other Situation 99 - (blank) 101 - Armed Forces Officers 102 - Armed Forces Sergeants 103 - Other Armed Forces personnel 112 - Directors of administrative and commercial services 114 - Hotel, catering, trade and other services directors 121 - Specialists in the physical sciences, mathematics, engineering and related techniques 122 - Health professionals 123 - teachers 124 - Specialists in finance, accounting, administrative organization, public and commercial relations 131 - Intermediate level science and engineering technicians and professions 132 - Technicians and professionals, of intermediate level of health 134 - Intermediate level technicians from legal, social, sports, cultural and similar services 135 - Information and communication technology technicians 141 - Office workers, secretaries in general and data processing operators 143 - Data, accounting, statistical, financial services and registry-related operators 144 - Other administrative support staff 151 - personal service workers 152 - sellers 153 - Personal care workers and the like 154 - Protection and security services personnel 161 - Market-oriented farmers and skilled agricultural and animal production workers 163 - Farmers, livestock keepers, fishermen, hunters and gatherers, subsistence 171 - Skilled construction workers and the like, except electricians 172 - Skilled workers in metallurgy, metalworking and similar 174 - Skilled workers in electricity and electronics 175 - Workers in food processing, woodworking, clothing and other industries and crafts 181 - Fixed plant and machine operators 182 - assembly workers 183 - Vehicle drivers and mobile equipment operators 192 - Unskilled workers in agriculture, animal production, fisheries and forestry 193 - Unskilled workers in extractive industry, construction, manufacturing and transport 194 - Meal preparation assistants 195 - Street vendors (except food) and street service providers. 

**Admission grade:** Admission grade (between 0 and 200).

**Displaced:** 1 – yes 0 – no.

**Educational special needs:** 1 – yes 0 – no. 

**Debtor:** 1 – yes 0 – no. 

**Tuition fees up to date:** 1 – yes 0 – no. 

**Gender:** 1 – male 0 – female. 

**Scholarship holder:** 1 – yes 0 – no. 

**Age at enrollment:** Age of studend at enrollment. 

**International:** 1 – yes 0 – no. 

**Curricular units 1st sem (credited):** Number of curricular units credited in the 1st semester.

**Curricular units 1st sem (enrolled):** Number of curricular units enrolled in the 1st semester.

**Curricular units 1st sem (evaluations):** Number of evaluations to curricular units in the 1st semester. 

**Curricular units 1st sem (approved):** Number of curricular units approved in the 1st semester.

**Curricular units 1st sem (grade):** Grade average in the 1st semester (between 0 and 20).

**Curricular units 1st sem (without evaluations):** Number of curricular units without evalutions in the 1st semester. 

**Curricular units 2st sem (credited):** Number of curricular units credited in the 2nd semester.

**Curricular units 2st sem (enrolled):** Number of curricular units enrolled in the 2nd semester.

**Curricular units 2st sem (evaluations):** Number of evaluations to curricular units in the 2nd semester. 

**Curricular units 2st sem (approved):** Number of curricular units approved in the 2nd semester.

**Curricular units 2st sem (grade):** Grade average in the 2nd semester (between 0 and 20).

**Curricular units 2st sem (without evaluations):** Number of curricular units without evalutions in the 2st semester

**Unemployment rate:** Unemployment rate (%).

**Inflation rate:** Inflation rate (%).

**GDP:** GDP.

**Target:** Target. The problem is formulated as a three category classification task (dropout, enrolled, and graduate) at the end of the normal duration of the course.

Citations/Acknowledgements
If you use this dataset, please cite:

If you use this dataset in experiments for a scientific publication, please kindly cite our paper: 
M.V.Martins, D. Tolledo, J. Machado, L. M.T. Baptista, V.Realinho. (2021) ""Early prediction of student’s performance in higher education: a case study"" Trends and Applications in Information Systems and Technologies, vol.1, in Advances in Intelligent Systems and Computing series. Springer. DOI: 10.1007/978-3-030-72657-7_16.

Creators:

Valentim Realinho (Instituto Politécnico de Portalegre)

Mónica Vieira Martins (Instituto Politécnico de Portalegre)

Jorge Machado (Instituto Politécnico de Portalegre)

Luís Baptista (Instituto Politécnico de Portalegre)",.csv
Student performance prediction,1,student-performance-in-mathematics,exams.csv,other,"Description: This dataset contains information on the performance of high school students in mathematics, including their grades and demographic information. The data was collected from three high schools in the United States.

Columns:

•	**Gender:** The gender of the student (male/female)

•	**Race/ethnicity:** The student's racial or ethnic background (Asian, African-American, Hispanic, etc.)

•	**Parental level of education:** The highest level of education attained by the student's parent(s) or guardian(s)

•	**Lunch:** Whether the student receives free or reduced-price lunch (yes/no)

•	**Test preparation course:** Whether the student completed a test preparation course (yes/no)

•	**Math score:** The student's score on a standardized mathematics test

•	**Reading score:** The student's score on a standardized reading test

•	**Writing score:** The student's score on a standardized writing test

This dataset could be used for various research questions related to education, such as examining the impact of parental education or test preparation courses on student performance. It could also be used to develop machine learning models to predict student performance based on demographic and other factors.

source: http://roycekimmons.com/tools/generated_data/exams
",.csv
Student spending habits dataset.,1,student-spending-dataset,student_spending (1).csv,Apache 2.0,"**- Title: Student Spending Habits Dataset**
**Description**:
This dataset contains fictional data representing the spending habits of 1000 students across various demographic groups and academic backgrounds.
The dataset includes information such as age, gender, year in school, major, monthly income, financial aid received, and expenses in different spending categories.
Spending categories include tuition, housing, food, transportation, books & supplies, entertainment, personal care, technology, health & wellness, and miscellaneous expenses.
Additionally, the dataset includes the preferred payment method for each student.
**Columns**:
1. Age: Age of the student (in years)
1. Gender: Gender of the student (Male, Female, Non-binary)
1. Year in School: Year of study (Freshman, Sophomore, Junior, Senior)
1. Major: Field of study or major
1. Monthly Income: Monthly income of the student (in dollars)
1. Financial Aid: Financial aid received by the student (in dollars)
1. Tuition: Expenses for tuition (in dollars)
1. Housing: Expenses for housing (in dollars)
1. Food: Expenses for food (in dollars)
1. Transportation: Expenses for transportation (in dollars)
1. Books & Supplies: Expenses for books and supplies (in dollars)
1. Entertainment: Expenses for entertainment (in dollars)
1. Personal Care: Expenses for personal care items (in dollars)
1. Technology: Expenses for technology (in dollars)
1. Health & Wellness: Expenses for health and wellness (in dollars)
1. Miscellaneous: Miscellaneous expenses (in dollars)
1. Preferred Payment Method: Preferred payment method (Cash, Credit/Debit Card, Mobile Payment App)
Usage:
This dataset can be used for various analyses related to student spending habits, financial literacy, budgeting strategies, and payment preferences.
Researchers, educators, and students can utilize this dataset for exploratory data analysis, predictive modeling, and developing insights into the financial behaviors of students.
Acknowledgements:
This dataset was generated for educational and research purposes, and all data is entirely fictional.",.csv
Student's Dropout and Academic Success Dataset,1,students-dropout-and-academic-success-dataset,data.csv,Apache 2.0,"This dataset contains information on students' marital status, application details, previous qualifications, family background, admission grades, financial status, and academic performance. The target variable indicates whether a student dropped out or achieved academic success. The data spans multiple semesters and includes economic indicators such as unemployment rate, inflation rate, and GDP. Researchers can leverage this dataset to develop models for predicting dropout and academic success, contributing to the understanding of factors influencing educational outcomes.",.csv
Student's Scores,1,students-score,student_marks.csv,CC-BY-NC-SA-4.0,"Scores of students of 12 tests.<br>
Collected from actual data. Only changed the names to ID
<br>
See More:
- [Countries GDP 1960 to 2021](https://www.kaggle.com/datasets/yapwh1208/countries-gdp-2012-to-2021)
- [Chatbot Dataset (AI Q&A)](https://www.kaggle.com/datasets/yapwh1208/chatbot-ai-q-and-a)
- [Cat's Breed Dataset](https://www.kaggle.com/datasets/yapwh1208/cats-breed-dataset)
- [Dog's Breed Dataset](https://www.kaggle.com/datasets/yapwh1208/dogs-breed-dataset)
- [Education with assistive technology](https://www.kaggle.com/datasets/yapwh1208/availability-of-education-for-assistive-technology)
- [Household air pollution](https://www.kaggle.com/datasets/yapwh1208/household-air-pollution-attributable-deaths)
- [Supermarket Sales Data](https://www.kaggle.com/datasets/yapwh1208/supermarket-sales-data)
<br><br>
Please upvote this if it helps you. Thanks😄",.csv
Students Adaptability Level in Online Education,1,students-adaptability-level-in-online-education,students_adaptability_level_online_education.csv,CC-BY-SA-4.0,"### Context
Since as a beginner in machine learning it would be a great opportunity to try some techniques to predict the outcome of Students’ Adaptability Level Prediction in Online Education using Machine Learning Approaches

### Content
**The target feature is**
Adaptivity level

**The feature sets are:**
Gender
Age
Education Level
Institution Type
IT Student
Location in Town
Load-shedding
Financial Condition
Internet Type
Network Type
Class Duration
Self LMS
Device

### Acknowledgements
You are free to use this dataset for any analysis or research purpose but please cite the original research paper. [Students' Adaptability Level Prediction in Online Education using Machine Learning Approaches](https://www.researchgate.net/publication/355891881_Students'_Adaptability_Level_Prediction_in_Online_Education_using_Machine_Learning_Approaches) or DOI: **10.1109/ICCCNT51525.2021.9579741**

### Inspiration
To get an idea about the effectiveness of online education

",.csv
Students Data Analysis,1,students-data-analysis,Students data.csv,other,"A little paragraph from one real dataset, with a few little changes to protect students' private information. Permissions are given. 

# Goals
You are going to help teachers with **only** the data:
1. Prediction: To tell **what makes a brilliant student** who can apply for a graduate school, whether abroad or not.
2. Application: To help those who fails to apply for a graduate school with advice in job searching.

#Tips 
1. Educational data may have subtle structures, **hierarchies and heterogeneity** are probably involved. Simple regressions can hardly make any difference. Also, you should keep an eye on the **collinearity** in some indicators collected by teachers who have already forgot statistics.
2. **Not all students are free to choose** to apply for a graduate school, but some were born with privileges.
3. Some of the students are trying (or planning to try) to apply for a graduate school for years, you should be responsible to **give advice accurately** under their circumstances

#About the Data
Some of the original structure are deleted or censored. For those are left:
Basic data like:
- ID
- class: categorical, initially students were divided into 2 classes, yet teachers suspect that of different classes students may performance significant differently.
- gender
- race: categorical and censored
- GPA: real numbers, float

Some teachers assume that scores of math curriculums can represent one's likelihood perfectly:
- Algebra: real numbers, Advanced Algebra
- ......

Some assume that background of students can affect their choices and likelihood significantly, which are all censored as:
- from1: students' home locations
- from2: a probably bad indicator for preference on mathematics
- from 3: how did students apply for this university (undergraduate)
- from4: a probably bad indicator for family background. 0 with more wealth, 4 with more poverty

The final indicator y:
- 0, one fails to apply for the graduate school, who may apply again or search jobs in the future
- 1, success, inland
- 2, success, abroad

",.csv
Students Performance,1,students-performance,StudentsPerformance_with_headers.csv,Attribution 4.0 International (CC BY 4.0),"For what purpose was the dataset created?

The purpose is to predict students' end-of-term performances using ML techniques.

**Additional Information**

1-10 of the data are the personal questions, 11-16. questions include family questions, and the remaining questions include education habits.

**Class Labels**

Student ID

1- Student Age (1: 18-21, 2: 22-25, 3: above 26)

2- Sex (1: female, 2: male)

3- Graduated high-school type: (1: private, 2: state, 3: other)

4- Scholarship type: (1: None, 2: 25%, 3: 50%, 4: 75%, 5: Full)

5- Additional work: (1: Yes, 2: No)

6- Regular artistic or sports activity: (1: Yes, 2: No)

7- Do you have a partner: (1: Yes, 2: No) 

8- Total salary if available (1: USD 135-200, 2: USD 201-270, 3: USD 271-340, 4: USD 341-410, 5: above 410)

9- Transportation to the university: (1: Bus, 2: Private car/taxi, 3: bicycle, 4: Other)

10- Accommodation type in Cyprus: (1: rental, 2: dormitory, 3: with family, 4: Other)

11- Mothersâ€™ education: (1: primary school, 2: secondary school, 3: high school, 4: university, 5: MSc., 6: Ph.D.)

12- Fathersâ€™ education: (1: primary school, 2: secondary school, 3: high school, 4: university, 5: MSc., 6: Ph.D.)

13- Number of sisters/brothers (if available): (1: 1, 2:, 2, 3: 3, 4: 4, 5: 5 or above)

14- Parental status: (1: married, 2: divorced, 3: died - one of them or both)

15- Mothersâ€™ occupation: (1: retired, 2: housewife, 3: government officer, 4: private sector employee, 5: self-employment, 6: other)

16- Fathersâ€™ occupation: (1: retired, 2: government officer, 3: private sector employee, 4: self-employment, 5: other)

17- Weekly study hours: (1: None, 2: &lt;5 hours, 3: 6-10 hours, 4: 11-20 hours, 5: more than 20 hours)

18- Reading frequency (non-scientific books/journals): (1: None, 2: Sometimes, 3: Often)

19- Reading frequency (scientific books/journals): (1: None, 2: Sometimes, 3: Often)

20- Attendance to the seminars/conferences related to the department: (1: Yes, 2: No)

21- Impact of your projects/activities on your success: (1: positive, 2: negative, 3: neutral)

22- Attendance to classes (1: always, 2: sometimes, 3: never)

23- Preparation to midterm exams 1: (1: alone, 2: with friends, 3: not applicable)

24- Preparation to midterm exams 2: (1: closest date to the exam, 2: regularly during the semester, 3: never)

25- Taking notes in classes: (1: never, 2: sometimes, 3: always)

26- Listening in classes: (1: never, 2: sometimes, 3: always)

27- Discussion improves my interest and success in the course: (1: never, 2: sometimes, 3: always)

28- Flip-classroom: (1: not useful, 2: useful, 3: not applicable)

29- Cumulative grade point average in the last semester (/4.00): (1: &lt;2.00, 2: 2.00-2.49, 3: 2.50-2.99, 4: 3.00-3.49, 5: above 3.49)

30- Expected Cumulative grade point average in the graduation (/4.00): (1: &lt;2.00, 2: 2.00-2.49, 3: 2.50-2.99, 4: 3.00-3.49, 5: above 3.49)

31- Course ID

32- OUTPUT Grade (0: Fail, 1: DD, 2: DC, 3: CC, 4: CB, 5: BB, 6: BA, 7: AA)

**Citation Requests/Acknowledgements**

YÄ±lmaz N., Sekeroglu B. (2020) Student Performance Classification Using Artificial Intelligence Techniques. In: Aliev R., Kacprzyk J., Pedrycz W., Jamshidi M., Babanli M., Sadikoglu F. (eds) 10th International Conference on Theory and Application of Soft Computing, Computing with Words and Perceptions - ICSCCW-2019. ICSCCW 2019. Advances in Intelligent Systems and Computing, vol 1095. Springer, Cham",.csv
Students Performance in Exams,1,students-performance-in-exams,StudentsPerformance.csv,CC0-1.0,"This data set consists of the marks secured by the students in various subjects.

Example Research Questions:
- How effective is the test preparation course?
- Which major factors contribute to test outcomes?
- What would be the best way to improve student scores on each test?
- What patterns and interactions in the data can you find? Let me know in the comments section below.

&gt; More
- Find More Exciting🙀 Datasets [Here](https://www.kaggle.com/whenamancodes/datasets)
- An Upvote👍 A Dayᕙ(`▿´)ᕗ , Keeps Aman Hurray Hurray..... ٩(˘◡˘)۶Haha",.csv
Students Score Dataset - Linear Regression,1,students-score-dataset-linear-regression,student_scores.csv,other,"### Context

There's a story behind every dataset and here's your opportunity to share yours.


### Content

This contains only two columns Hours and Scores. Linear regression very effective used to predict the scores based on the number of hours.


### Acknowledgements

We wouldn't be here without the help of others. If you owe any attributions or thanks, include them here along with any citations of past research.


### Inspiration

Your data will be in front of the world's largest data science community. What questions do you want to see answered?",.csv
Students Test Data,1,students-test-data,Private_data.csv,ODC Public Domain Dedication and Licence (PDDL),"Dataset Overview: This dataset pertains to the examination results of students who participated in a series of academic assessments at a fictitious educational institution named ""University of Exampleville."" The assessments were administered across various courses and academic levels, with a focus on evaluating students' performance in general management and domain-specific topics.

Columns: The dataset comprises 12 columns, each representing specific attributes and performance indicators of the students. These columns encompass information such as the students' names (which have been anonymized), their respective universities, academic program names (including BBA and MBA), specializations, the semester of the assessment, the type of examination domain (general management or domain-specific), general management scores (out of 50), domain-specific scores (out of 50), total scores (out of 100), student ranks, and percentiles.

Data Collection: The examination data was collected during a standardized assessment process conducted by the University of Exampleville. The exams were designed to assess students' knowledge and skills in general management and their chosen domain-specific subjects. It involved students from both BBA and MBA programs who were in their final year of study.

Data Format: The dataset is available in a structured format, typically as a CSV file. Each row represents a unique student's performance in the examination, while columns contain specific information about their results and academic details.

Data Usage: This dataset is valuable for analyzing and gaining insights into the academic performance of students pursuing BBA and MBA degrees. It can be used for various purposes, including statistical analysis, performance trend identification, program assessment, and comparison of scores across domains and specializations. Furthermore, it can be employed in predictive modeling or decision-making related to curriculum development and student support.

Data Quality: The dataset has undergone preprocessing and anonymization to protect the privacy of individual students. Nevertheless, it is essential to use the data responsibly and in compliance with relevant data protection regulations when conducting any analysis or research.

Data Format: The exam data is typically provided in a structured format, commonly as a CSV (Comma-Separated Values) file. Each row in the dataset represents a unique student's examination performance, and each column contains specific attributes and scores related to the examination. The CSV format allows for easy import and analysis using various data analysis tools and programming languages like Python, R, or spreadsheet software like Microsoft Excel.

Here's a column-wise description of the dataset:

Name OF THE STUDENT: The full name of the student who took the exam. (Anonymized)

UNIVERSITY: The university where the student is enrolled.

PROGRAM NAME: The name of the academic program in which the student is enrolled (BBA or MBA).

Specialization: If applicable, the specific area of specialization or major that the student has chosen within their program.

Semester: The semester or academic term in which the student took the exam.

Domain: Indicates whether the exam was divided into two parts: general management and domain-specific.

GENERAL MANAGEMENT SCORE (OUT of 50): The score obtained by the student in the general management part of the exam, out of a maximum possible score of 50.

Domain-Specific Score (Out of 50): The score obtained by the student in the domain-specific part of the exam, also out of a maximum possible score of 50.

TOTAL SCORE (OUT of 100): The total score obtained by adding the scores from the general management and domain-specific parts, out of a maximum possible score of 100.

",.csv
Students' Academic Performance Dataset,1,xAPI-Edu-Data,xAPI-Edu-Data.csv,CC-BY-SA-4.0,"Students' Academic Performance Dataset (xAPI-Edu-Data)
=======================================

Data Set Characteristics: Multivariate

Number of Instances: 480

Area: E-learning, Education, Predictive models, Educational Data Mining

Attribute Characteristics: Integer/Categorical 

Number of Attributes: 16

Date: 2016-11-8

Associated Tasks: Classification

Missing Values? No

File formats: xAPI-Edu-Data.csv

Source:
=======
Elaf Abu Amrieh, Thair Hamtini, and Ibrahim Aljarah, The University of Jordan, Amman, Jordan, http://www.Ibrahimaljarah.com
www.ju.edu.jo

Dataset Information:
=====================
This is an educational data set which is collected from learning management system (LMS) called Kalboard 360. Kalboard 360 is a multi-agent LMS, which has been designed to facilitate learning through the use of leading-edge technology. Such system provides users with a synchronous access to educational resources from any device with Internet connection. 

The data is collected using a learner activity tracker tool, which called experience API (xAPI). The xAPI is a component of the training and learning architecture (TLA) that enables to monitor learning progress and learner’s actions like reading an article or watching a training video. The experience API helps the learning activity providers to determine the learner, activity and objects that describe a learning experience.
The dataset consists of 480 student records and 16 features. The features are classified into three major categories: (1) Demographic features such as gender and nationality. (2) Academic background features such as educational stage, grade Level and section. (3) Behavioral features such as raised hand on class, opening resources, answering survey by parents, and school satisfaction.

The dataset consists of 305 males and 175 females. The students come from different origins such as 179 students are from Kuwait, 172 students are from Jordan, 28 students from Palestine, 22 students are from Iraq, 17 students from Lebanon, 12 students from Tunis, 11 students from Saudi Arabia, 9 students from Egypt, 7 students from Syria, 6 students from USA, Iran and Libya, 4 students from Morocco and one student from Venezuela.

The dataset is collected through two educational semesters: 245 student records are collected during the first semester and 235 student records are collected during the second semester. 

The data set includes also the school attendance feature such as the students are classified into two categories based on their absence days: 191 students exceed 7 absence days and 289 students their absence days under 7.

This dataset includes also a new category of features; this feature is parent parturition in the educational process. Parent participation feature have two sub features: Parent Answering Survey and Parent School Satisfaction. There are 270 of the parents answered survey and 210 are not, 292 of the parents are satisfied from the school and 188 are not. 

(See the related papers for more details).

Attributes
============
1 Gender - student's gender (nominal: 'Male' or 'Female’) 

2 Nationality- student's nationality (nominal:’ Kuwait’,’ Lebanon’,’ Egypt’,’ SaudiArabia’,’ USA’,’ Jordan’,’ 
Venezuela’,’ Iran’,’ Tunis’,’ Morocco’,’ Syria’,’ Palestine’,’ Iraq’,’ Lybia’)

3 Place of birth- student's Place of birth (nominal:’ Kuwait’,’ Lebanon’,’ Egypt’,’ SaudiArabia’,’ USA’,’ Jordan’,’ 
Venezuela’,’ Iran’,’ Tunis’,’ Morocco’,’ Syria’,’ Palestine’,’ Iraq’,’ Lybia’)

4 Educational Stages- educational level student belongs (nominal: ‘lowerlevel’,’MiddleSchool’,’HighSchool’) 

5 Grade Levels- grade student belongs (nominal: ‘G-01’, ‘G-02’, ‘G-03’, ‘G-04’, ‘G-05’, ‘G-06’, ‘G-07’, ‘G-08’, ‘G-09’, ‘G-10’, ‘G-11’, ‘G-12 ‘) 

6 Section ID- classroom student belongs (nominal:’A’,’B’,’C’)

7 Topic- course topic (nominal:’ English’,’ Spanish’, ‘French’,’ Arabic’,’ IT’,’ Math’,’ Chemistry’, ‘Biology’, ‘Science’,’ History’,’ Quran’,’ Geology’)

8 Semester- school year semester (nominal:’ First’,’ Second’)

9 Parent responsible for student (nominal:’mom’,’father’)

10 Raised hand- how many times the student raises his/her hand on classroom (numeric:0-100)

11- Visited resources- how many times the student visits a course content(numeric:0-100)

12 Viewing announcements-how many times the student checks the new announcements(numeric:0-100)

13 Discussion groups- how many times the student participate on discussion groups (numeric:0-100)

14 Parent Answering Survey- parent answered the surveys which are provided from school or not 
(nominal:’Yes’,’No’)

15 Parent School Satisfaction- the Degree of parent satisfaction from school(nominal:’Yes’,’No’)

16 Student Absence Days-the number of absence days for each student (nominal: above-7, under-7)

# The students are classified into three numerical intervals based on their total grade/mark:

Low-Level: interval includes values from 0 to 69, 

Middle-Level: interval includes values from 70 to 89, 

High-Level: interval includes values from 90-100.

Relevant Papers:
================
- Amrieh, E. A., Hamtini, T., & Aljarah, I. (2016). Mining Educational Data to Predict Student’s academic Performance using Ensemble Methods. International Journal of Database Theory and Application, 9(8), 119-136.

- Amrieh, E. A., Hamtini, T., & Aljarah, I. (2015, November). Preprocessing and analyzing educational data set using X-API for improving student's performance. In Applied Electrical Engineering and Computing Technologies (AEECT), 2015 IEEE Jordan Conference on (pp. 1-5). IEEE.

Citation Request:
=================
Please include these citations if you plan to use this dataset:

- Amrieh, E. A., Hamtini, T., & Aljarah, I. (2016). Mining Educational Data to Predict Student’s academic Performance using Ensemble Methods. International Journal of Database Theory and Application, 9(8), 119-136.

- Amrieh, E. A., Hamtini, T., & Aljarah, I. (2015, November). Preprocessing and analyzing educational data set using X-API for improving student's performance. In Applied Electrical Engineering and Computing Technologies (AEECT), 2015 IEEE Jordan Conference on (pp. 1-5). IEEE.",.csv
StudentsPerformance,1,studentsperformance,StudentsPerformance.csv,Apache 2.0,"A basic dataset with marks of students in various examinations, the dataset can be used for data wrangling and learning purposes.
5 rows and 31 columns",.csv
Studio Ghibli Dataset ⭐️🫧🌀,1,studio-ghibli-dataset,Studio Ghibli.csv,Apache 2.0,"**Studio Ghibli Films Dataset**

This dataset provides comprehensive information on various Studio Ghibli films, spanning different years and genres. It includes details such as the film's name, release year, director, screenplay writer, budget, revenue, primary genre, secondary genre, additional genre (if applicable), and duration.

![](https://i.pinimg.com/originals/38/3b/ff/383bff6fa50bb473772f7d5cf3000bfb.jpg)

- **Name**: The title of the Studio Ghibli film.
- **Year**: The release year of the film.
- **Director**: The director of the film.
- **Screenplay**: The screenplay writer of the film.
- **Budget**: The budget allocated for the production of the film.
- **Revenue**: The revenue generated by the film.
- **Genre 1, Genre 2, Genre 3**: The primary, secondary, and additional genres of the film, respectively.
- **Duration**: The duration of the film.


### Potential Use Cases:
1. **Film Analysis:** Study trends and patterns in Studio Ghibli films over the years.
2. **Genre Exploration:** Analyze the popularity of different genres within Studio Ghibli's filmography.
3. **Director Comparison:** Compare the performance of different directors in terms of budget, revenue, and critical acclaim.",.csv
Stunting Toddler (Balita) Detection (121K rows),1,stunting-balita-detection-121k-rows,data_balita.csv,MIT,"This ""Stunting Baby/Toddler Detection"" dataset is based on the z-score formula for determining stunting according to WHO (World Health Organization), that focuses on stunting detection in children under five years old. It consists of 121,000 rows of data, detailing information on the age, sex, height, and nutritional status of toddlers. This dataset aims to help researchers, nutritionists, and policymakers understand and address the problem of stunting in children under five years old.

Dataset Column Details:

**Age (Month)**: Indicates the age of a baby/toddler in months. This age range is important for determining a child's growth phase and comparing it to healthy growth standards. (ages 0 to 60 months)

**Gender**: There are two categories in this column, 'male' and 'female'. Gender is an important factor in analyzing growth patterns and stunting risk.

**Height**: Recorded in centimeters, height is a key indicator for assessing the physical growth of children under five. This data allows researchers to determine whether a child's growth is in line with age standards.

**Nutrition Status**: This column is categorized into 4 statuses - 'severely stunted', 'stunted', 'normal', and 'tall'. 'Severely stunted' indicates a very serious condition (&lt;-3 SD), 'stunted' indicates a stunted condition (-3 SD to &lt;-2 SD), 'normal' indicates a healthy nutritional status (-2 SD to +3 SD), and 'tall' indicates above-average growth (&gt;+3 SD). These categories help in the rapid identification and intervention of children at risk or experiencing stunting.

**Use of Dataset**:
This dataset is very useful for researchers and practitioners in the field of child health and nutrition, providing important insights for the development of nutrition intervention programs and public health policies. With accurate and detailed data, interventions can be more targeted and effective.

This dataset is designed to be a valuable resource in childhood stunting research and assist in the planning of better prevention and treatment strategies.

**Notebook example:
[https://www.kaggle.com/rendiputra/stunting-detection-with-knn-algorithm](https://www.kaggle.com/rendiputra/stunting-detection-with-knn-algorithm)**

---

Dataset ""Stunting Toddler (Balita) Detection"" ini kumpulan data berdasarkan rumus z-score penentuan stunting menurut WHO (World Health Organization), yang berfokus pada deteksi stunting pada balita (bayi dibawah lima tahun). Dataset ini terdiri dari 121.000 baris data, yang merinci informasi mengenai umur, jenis kelamin, tinggi badan, dan status gizi balita. Dataset ini bertujuan untuk membantu peneliti, ahli gizi, dan pembuat kebijakan dalam memahami dan mengatasi masalah stunting pada anak-anak di bawah lima tahun.

Rincian Kolom Dataset:

**Umur (Bulan)**: Mengindikasikan usia balita dalam bulan. Rentang usia ini penting untuk menentukan fase pertumbuhan anak dan membandingkannya dengan standar pertumbuhan yang sehat. (Umur 0 sampai 60 bulan)

**Jenis Kelamin**: Terdapat dua kategori dalam kolom ini, 'laki-laki' (male) dan 'perempuan' (female). Jenis kelamin merupakan faktor penting dalam analisis pola pertumbuhan dan risiko stunting.

**Tinggi Badan**: Dicatat dalam centimeter, tinggi badan adalah indikator utama untuk menilai pertumbuhan fisik balita. Data ini memungkinkan peneliti untuk menentukan apakah pertumbuhan anak sesuai dengan standar usianya.

**Status Gizi**: Kolom ini dikategorikan menjadi 4 status - 'severely stunting', 'stunting', 'normal', dan 'tinggi'. 'Severely stunting' menunjukkan kondisi sangat serius (&lt;-3 SD), 'stunting' menunjukkan kondisi stunting (-3 SD sd &lt;-2 SD), 'normal' mengindikasikan status gizi yang sehat (-2 SD sd +3 SD), dan 'tinggi' (height) menunjukkan pertumbuhan di atas rata-rata (&gt;+3 SD). Kategori ini membantu dalam identifikasi cepat dan intervensi bagi anak-anak yang berisiko atau mengalami masalah pertumbuhan.

**Kegunaan Dataset**:
Dataset ini sangat berguna bagi peneliti dan praktisi di bidang kesehatan dan gizi anak, memberikan wawasan penting untuk pengembangan program intervensi gizi dan kebijakan kesehatan publik. Dengan data yang akurat dan terperinci, intervensi dapat lebih ditargetkan dan efektif.

Dataset ini dirancang untuk menjadi sumber daya berharga dalam penelitian stunting pada anak-anak dan membantu dalam perencanaan strategi pencegahan dan pengobatan yang lebih baik.

**Notebook example:
[https://www.kaggle.com/rendiputra/stunting-detection-with-knn-algorithm](https://www.kaggle.com/rendiputra/stunting-detection-with-knn-algorithm)**   ",.csv
Sub Sandwich Customer Satisfaction Score,1,sub-sandwich-customer-satisfaction-score,Sub_Sandwiches_OSAT.csv,MIT,"This dataset offers a comprehensive look at customer satisfaction levels across various sub sandwich brands. It delves into the nitty-gritty of what makes a sub sandwich experience delightful, covering a wide array of factors such as food quality, service efficiency, ambiance, and overall customer sentiment.

Key features of the dataset include:

Brand Analysis: It compares popular sub sandwich brands, providing insights into how each brand fares in terms of customer satisfaction.

Detailed Metrics: The dataset includes detailed metrics like food appearance, taste quality, ingredient proportions, menu variety, health options, and changes in food quality.

Customer Experience Factors: It assesses elements beyond food, like decor, modernity of the restaurant environment, curb appeal, and whether the environment feels welcoming to the customers.

Quality of Ingredients: Special focus on the freshness and quality of ingredients, including meats, veggies, toppings, and bread.

Customer Value and Perception: Measures how valued customers feel and their willingness to be associated with the brand in a public setting",.csv
Suicidal Tweet Detection Dataset,1,suicidal-tweet-detection-dataset,Suicide_Ideation_Dataset(Twitter-based).csv,CC-BY-NC-SA-4.0,"**Dataset Description**: ***Suicidal Tweet Detection***
- This dataset provides a collection of tweets along with an annotation indicating whether each tweet is related to suicide or not. The primary objective of this dataset is to facilitate the development and evaluation of machine learning models for the classification of tweets as either expressing suicidal sentiments or not. This dataset has been internally generated by our team members specifically for our NLP project.

**Columns**:
1. *Tweet*: This column contains the text content of the tweets obtained from various sources. The tweets cover a wide range of topics, emotions, and expressions.
2. *Suicide*: This column provides annotations indicating the classification of the tweets. The possible values are:
- Not Suicide post: This label is assigned to tweets that do not express any suicidal sentiments or intentions.
- Potential Suicide post: This label is assigned to tweets that exhibit indications of suicidal thoughts, feelings, or intentions.

**Usage**:
This dataset can be used for various natural language processing (NLP) and sentiment analysis tasks. It is particularly suitable for training and evaluating machine learning models that can automatically classify tweets as either non-suicidal or potentially suicidal. Researchers, data scientists, and developers can use this dataset to develop systems that can identify and flag concerning content on social media platforms, potentially contributing to early intervention and support for individuals in distress.

**Potential Applications**:
- *Suicidal Ideation Detection*: The dataset can be used to train models to automatically detect and flag tweets containing potential suicidal content, enabling platforms to take appropriate actions.
- *Mental Health Support*: Insights from this dataset can be used to develop tools that offer mental health resources or interventions to users who express signs of distress.
- *Sentiment Analysis Research*: Researchers can analyze the linguistic patterns and sentiment of both non-suicidal and potentially suicidal tweets to gain insights into the language used by individuals in different emotional states.
- *Public Health Awareness*: The dataset can be used to raise awareness about mental health issues and the importance of responsible social media usage.

[N.B.: Please note that the annotations provided in the ""Suicide"" column are based on indicators present in the tweet text. However, the dataset does not provide any personal or identifying information about the users who posted the tweets. Researchers and developers should handle this data responsibly and ethically while considering potential user privacy concerns.]",.csv
Suicide Rates Overview (1985 to 2021),1,suicide-rates-overview-1985-to-2021,master.csv,CC0-1.0,"**Content**
This dataset is an addition to the [original dataset](https://www.kaggle.com/datasets/russellyates88/suicide-rates-overview-1985-to-2016). This compiled dataset was pulled from four other datasets linked by time and place and was built to find signals correlated to increased suicide rates among different cohorts globally, across the socio-economic spectrum.

**References**
United Nations Development Program. (2018). Human development index (HDI). Retrieved from [http://hdr.undp.org/en/indicators/137506](http://hdr.undp.org/en/indicators/137506)

World Bank. (2018). World development indicators: GDP (current US$) by country:1985 to 2016. Retrieved from [http://databank.worldbank.org/data/source/world-development-indicators#](http://databank.worldbank.org/data/source/world-development-indicators#)

[Szamil]. (2017). Suicide in the Twenty-First Century [dataset]. Retrieved from [https://www.kaggle.com/szamil/suicide-in-the-twenty-first-century/notebook](https://www.kaggle.com/szamil/suicide-in-the-twenty-first-century/notebook)

World Health Organization. (2018). Suicide prevention. Retrieved from [http://www.who.int/mental_health/suicide-prevention/en/](http://www.who.int/mental_health/suicide-prevention/en/)

**Inspiration**
Suicide Prevention.

If you're reading this, please upvote.",.csv
Suicide Rates Overview 1985 to 2016 ,1,suicide-rates-overview-1985-to-2016,master.csv,world-bank,"### Content

This compiled dataset pulled from four other datasets linked by time and place, and was built to find signals correlated to increased suicide rates among different cohorts globally, across the socio-economic spectrum.

### References
United Nations Development Program. (2018). Human development index (HDI). Retrieved from http://hdr.undp.org/en/indicators/137506

World Bank. (2018). World development indicators: GDP (current US$) by country:1985 to 2016. Retrieved from http://databank.worldbank.org/data/source/world-development-indicators#

[Szamil]. (2017). Suicide in the Twenty-First Century [dataset]. Retrieved from https://www.kaggle.com/szamil/suicide-in-the-twenty-first-century/notebook

World Health Organization. (2018). Suicide prevention. Retrieved from http://www.who.int/mental_health/suicide-prevention/en/ 

### Inspiration

Suicide Prevention.",.csv
Suicides in India,1,suicides-in-india,Suicides in India 2001-2012.csv,CC-BY-SA-4.0,"<div>
<a href=""https://link.rajanand.org/sql-challenges"" target=""_blank"">
<img src=""https://link.rajanand.org/banner-01"" alt=""SQL Data Challenges"" style=""width: 700px; height: 120px""></a>
</div>

###Context###

This data set contains yearly suicide detail of all the states/u.t of India by various parameters from 2001 to 2012.

###Content###

Time Period: 2001 - 2012 
Granularity: Yearly
Location: States and U.T's of India 

Parameters:

a) Suicide causes
b) Education status
c) By means adopted
d) Professional profile
e) Social status

###Acknowledgements###

National Crime Records Bureau (NCRB), Govt of India has shared this [dataset](https://data.gov.in/dataset-group-name/accidental-deaths-and-suicides) under [Govt. Open Data License - India](https://data.gov.in/government-open-data-license-india).
NCRB has also shared the historical data on their [website](http://ncrb.nic.in/StatPublications/ADSI/PrevPublications.htm)

<div>
<a href=""https://link.rajanand.org/sql-challenges"" target=""_blank"">
<img src=""https://link.rajanand.org/banner-02"" alt=""SQL Data Challenges"" style=""width: 700px; height: 120px""></a>
</div>",.csv
Summer Olympic Medals 1896 - 2020,1,summer-olympic-medals-1986-2020,Summer_olympic_Medals.csv,CC0-1.0,"### Inspiration

I wanted to create this dataset due to the recent Olympic Edition in Japan. I decided to take a look on how countries performed while playing in their home country.

** SPOILER ALERT **

They performed better. Now go check it out!

I have also created a dataset containing tabular data for Winter Olympic Editions: 

https://www.kaggle.com/ramontanoeiro/winter-olympic-medals-1924-2018",.csv
Summer Olympics Medals (1976-2008),1,summer-olympics-medals,Summer-Olympic-medals-1976-to-2008.csv,CC0-1.0,"This dataset is a list of all the medal winners in the Summer Olympics from 1976 Montreal to 2008 Beijing. It includes each and every medal awarded within the period. This dataset is intended for beginners so that they can get a taste of advanced Excel functions which is perhaps one of the key skills required to be a great data scientist. I too got my hands dirty with the dataset and played with some advanced Excel functions. Further, this dataset can also be used for a predictive model as to which country is likely to fetch the highest number of gold in a particular sports category (just an example), etc. ",.csv
Summer Sports Experience Dataset,1,summer-sports-experience-dataset,Summer_Sports_Experience.csv,CC0-1.0,"Summer sports for children offer a wide array of physical, mental, and social benefits. They provide an excellent opportunity for kids to have fun, stay active, and learn important life skills. 

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F1610208%2F923991955835364128e3c14f338892de%2FSummer_Time.gif?generation=1699250193574301&alt=media)

Engaging in sports during the summer season not only contributes to a child's physical well-being but also helps them develop crucial qualities such as teamwork, discipline, and self-confidence. Whether it's swimming, soccer, baseball, or any other sport, the memories and experiences gained from participating in summer sports can last a lifetime.

This dataset is on this very theme sourced from **data.cityofnewyork.us** available publically. The dataset first published on 2018-10-31 and last modified on 2020-02-08 under the recreation category.

# Dataset Description :

&gt;Activity and attendance records from the ""Summer Sports Experience"" program, which provides sports instruction to children ages 8 to 14.


|**Column Name**|**Description**|**Type**|
|---|---|---|
|Borough Location	|Borough in which Summer Sports Experience program occurred	|Plain Text|
|Park Location	|Name of park or playground where Summer Sports Experience program occurred	|Plain Text|
|Sports Played	|Specific sport that was part of the day's activities	|Plain Text|
|Week Start Date	|The start date of the week for which attendance was recorded	|Date & Time|
|Week End Date	|The end date of the week for which attendance was recorded	|Date & Time|
|Sunday's Attendance	|Attendance count for Sunday	|Number|
|Monday's Attendance	|Attendance count for Monday	|Number|
|Tuesday's Attendance	|Attendance count for Tuesday	|Number|
|Wednesday's Attendance|	Attendance count for Wednesday	|Number|
|Thursday's Attendance|	Attendance count for Thursday	|Number|
|Friday's Attendance|	Attendance count for Friday	|Number|
|Saturday's Attendance|	Attendance count for Saturday	|Number|
|Attendance Sum|	Sum of attendance for the week	|Number|


## Display Image Credits -
Image by Joshua Choate from Pixabay
",.csv
Sunspots,1,sunspots,Sunspots.csv,CC0-1.0,"#Context

Sunspots are temporary phenomena on the Sun's photosphere that appear as spots darker than the surrounding areas. They are regions of reduced surface temperature caused by concentrations of magnetic field flux that inhibit convection. Sunspots usually appear in pairs of opposite magnetic polarity. Their number varies according to the approximately 11-year solar cycle.

Source: https://en.wikipedia.org/wiki/Sunspot

#Content :

Monthly Mean Total Sunspot Number, from 1749/01/01 to 2017/08/31

#Acknowledgements :

SIDC and Quandl.

Database from SIDC - Solar Influences Data Analysis Center - the solar physics research department of the Royal Observatory of Belgium. [SIDC website][1]

  [1]: http://sidc.oma.be/",.csv
Super Market Sales,1,super-market-sales,supermarket_sales.csv,DbCL-1.0,"Here's a brief description of each of the attributes or labels in the dataset:

1. **Invoice ID**: A unique identifier for each invoice or transaction.
2. **Branch**: The branch or location where the transaction occurred.
3. **City**: The city where the branch is located.
4. **Customer Type**: Indicates whether the customer is a regular or new customer.
5. **Gender**: The gender of the customer.
6. **Product Line**: The category or type of product purchased.
7. **Unit Price**: The price of a single unit of the product.
8. **Quantity**: The number of units of the product purchased.
9. **Tax 5%**: The amount of tax (5% of the total cost) applied to the transaction.
10. **Total**: The total cost of the transaction, including tax.
11. **Date**: The date when the transaction took place.
12. **Time**: The time of day when the transaction occurred.
13. **Payment**: The payment method used (e.g., credit card, cash).
14. **COGS (Cost of Goods Sold)**: The direct costs associated with producing or purchasing the products sold.
15. **Gross Margin Percentage**: The profit margin percentage for the transaction.
16. **Gross Income**: The total profit earned from the transaction.
17. **Rating**: Customer satisfaction rating or feedback on the transaction.

 For instance, if you were interested in predicting customer satisfaction, **Rating** might be a suitable label. If you were trying to predict sales or revenue, **Total** or **Gross Income** could be a potential label.",.csv
Super Store,1,super-store,SampleSuperstore.csv,DbCL-1.0,"## About the data and what to do…

A superstore is a very large supermarket, often selling household goods, clothes, and electrical goods, as well as food. Superstores typically charge anywhere from 15 to 45 percent less than their smaller counterparts.
As a business manager, try to find out the weak areas where you can work to make more profit. Perform ‘Exploratory Data Analysis’.
What all business problems you can derive by exploring the data?",.csv
SuperStore Sales Dataset,1,superstore-sales-dataset,SuperStoreOrders.csv,GNU Lesser General Public License 3.0,"By Superstore Dataset, I thought I could learn and experiment with different offerings and functionalities available in Python, Matplotlib, Seaborn and Numpy. The vast dataset provides a base to interact with visualizations, drill down into the specifics of Data handling and provide samples for performing Data transformations.
The sample Dataset includes data for the Sales of multiple products sold by the store along with subsequent information related to geography, Product categories, and subcategories, sales, and profits, segmentation amongst the consumers, etc. This sample Dataset presents a common use case, from which I could gather useful insights from the Sales data in order to improve the Marketing and Sales strategies. I can learn about various operations and elements using this sample Dataset and come up with better strategies to improve and grow the business more.
 
The Dataset:
Link of the Dataset: https://www.kaggle.com/datasets/aditisaxena20/superstore-sales-dataset

The dataset has 51,291 rows and 21 columns.
",.csv
Superbowl History 1967 - 2020,1,superbowl-history-1967-2020,superbowl.csv,CC0-1.0,"### Context

The Super Bowl is an annual American football game that determines the champion of the National Football League (NFL). The game culminates a season that begins in the previous calendar year, and is the conclusion of the NFL playoffs. The contest is held in an American city, chosen three to four years beforehand, usually at warm-weather sites or domed stadiums. Since January 1971, the winner of the American Football Conference (AFC) Championship Game has faced the winner of the National Football Conference (NFC) Championship Game in the culmination of the NFL playoffs.

### Content

This dataset contains data about the Superbowl finals from 1967 to 2020. It's pretty simple and straightforward, one row per superbowl. 

### Acknowledgements

Data from https://www.pro-football-reference.com/super-bowl.
",.csv
Superheroes NLP Dataset,1,superheroes-nlp-dataset,superheroes_nlp_dataset.csv,CC0-1.0,"# Superheroes NLP dataset

1400+ Superheroes history and powers description to apply text mining and NLP


## Context

The aim of this dataset is to make text analytics and NLP even funnier. All of us have dreamed to be like a superhero and save the world, yet we are still on Kaggle figuring out how python works. Then, why not improve our NLP competences by analyzing Superheros' history and powers? 

The particularity of this dataset is that it contains **categorical and numerical features** such as  `overall_score`, `intelligence_score`, `creator`, `alignment`, `gender`, `eye_color` but also *text features* `history_text` and `powers_text`. By combining the two, a lot of interesting insights can be gathered!


## Content   

We collected all data from [superherodb](https://www.superherodb.com/) and cooked for you in a nice and clean tabular format.

The dataset contains *1447* different Superheroes. Each superhero row has:
- `overall_score` - derivated by superherodb from the  _power stats_ features. Can you find the relationship?
- `history_text` - History of the Superhero (text features)
- `powers_text` - Description of Superheros' powers (text features)
- `intelligence_score`, `strength_score`, `speed_score`, `durability_score`, `power_score` and `combat_score`. (_power stats_ features)
- ""Origin"" (`full_name`, `alter_egos`, ...)
- ""Connections"" (`occupation`, `base`, `teams`, ...)
- ""Appareance"" (`gender`, `type_race`, `height`, `weight`, `eye_color`, ...)

## Your turn

There are numerous ways you can have fun with this dataset. Now is up to you! 

Some ideas to start:

### - Who is the coolest superhero?
   Given only the two text columns, can you find a formula to find the coolest superhero?

### - Who is the stronger superhero of all time?
   By combining _text_ features with the _power stats_ features, can you try to say who is the most strong superhero of all time?

### - Text classification: can you predict who is the Superhero `creator` just by using the text columns? (yes, you can!)
   Moreover, can you find a good way to cluster data in an unsupervised manner?

### - Who is the top 10 Woman Superheroes?
   23% of the Superheroes are woman, can you spot who is the top 10?

## Acknowledgements

The following [Github repository](https://github.com/jbesomi/texthero/tree/master/dataset/Superheroes%20NLP%20Dataset) contains the code used to scrape this Dataset. ",.csv
Supermarket store branches sales analysis,1,stores-area-and-sales-data,Stores.csv,CC-BY-SA-3.0,"## Context

A supermarket is a self-service shop offering a wide variety of food, beverages and household products, organized into sections. This kind of store is larger and has a wider selection than earlier grocery stores, but is smaller and more limited in the range of merchandise than a hypermarket or big-box market. In everyday U.S. usage, however, ""grocery store"" is synonymous with supermarket, and is not used to refer to other types of stores that sell groceries.

## Content

In the dataset, You'll get data of different stores of a supermarket company as per their store IDs which for ease has been converted to positive integers. 

Store ID: (Index) ID of the particular store.

Store_Area: Physical Area of the store in yard square. 

Items_Available: Number of different items available in the corresponding store. 

Daily_Customer_Count: Number of customers who visited to stores on an average over month. 

Store_Sales: Sales in (US $) that stores made. 

## Acknowledgement
The data is obtained from the project from the University after seeking proper permission.

## Inspiration
Analyzing the performances of stores in the past on basis of which will try to rectify defects as well as to leverage the positives. Who doesn't want to increase their profits right? ",.csv
Superstore Dataset,1,superstore-dataset-final,Sample - Superstore.csv,other,"### Context

With growing demands and cut-throat competitions in the market, a Superstore Giant is seeking your knowledge in understanding what works best for them. They would like to understand which products, regions, categories and customer segments they should target or avoid.

You can even take this a step further and try and build a Regression model to predict Sales or Profit. 

Go crazy with the dataset, but also make sure to provide some business insights to improve. 


### Metadata

Row ID =&gt; Unique ID for each row.
Order ID =&gt; Unique Order ID for each Customer.
Order Date =&gt; Order Date of the product.
Ship Date =&gt; Shipping Date of the Product.
Ship Mode=&gt; Shipping Mode specified by the Customer.
Customer ID =&gt; Unique ID to identify each Customer.
Customer Name =&gt; Name of the Customer.
Segment =&gt; The segment where the Customer belongs.
Country =&gt; Country of residence of the Customer.
City =&gt; City of residence of of the Customer.
State =&gt; State of residence of the Customer.
Postal Code =&gt; Postal Code of every Customer.
Region =&gt; Region where the Customer belong.
Product ID =&gt; Unique ID of the Product.
Category =&gt; Category of the product ordered.
Sub-Category =&gt; Sub-Category of the product ordered.
Product Name =&gt; Name of the Product
Sales =&gt; Sales of the Product.
Quantity =&gt; Quantity of the Product.
Discount =&gt; Discount provided.
Profit =&gt; Profit/Loss incurred.

### Acknowledgements

I do not own this data. I merely found it from the <a href=""https://community.tableau.com/s/question/0D54T00000CWeX8SAL/sample-superstore-sales-excelxls"">Tableau</a> website. All credits to the original authors/creators. For educational purposes only.",.csv
Superstore Marketing Campaign Dataset,1,superstore-marketing-campaign-dataset,superstore_data.csv,CC0-1.0,"**Context**- A superstore is planning for the year-end sale. They want to launch a new offer - gold membership, that gives a 20% discount on all purchases, for only $499 which is $999 on other days. It will be valid only for existing customers and the campaign through phone calls is currently being planned for them. The management feels that the best way to reduce the cost of the campaign is to make a predictive model which will classify customers who might purchase the offer.
**Objective** - The superstore wants to predict the likelihood of the customer giving a positive response and wants to identify the different factors which affect the customer's response. You need to analyze the data provided to identify these factors and then build a prediction model to predict the probability of a customer will give a positive response.",.csv
Superstore Sales Dataset,1,sales-forecasting,train.csv,GPL-2.0,"### Context

Retail dataset of a global superstore for 4 years.
Perform EDA and Predict the sales of the next 7 days from the last date of the Training dataset!


### Content

Time series analysis deals with time series based data to extract patterns for predictions and other characteristics of the data. It uses a model for forecasting future values in a small time frame based on previous observations. It is widely used for non-stationary data, such as economic data, weather data, stock prices, and retail sales forecasting.

## Dataset
The dataset is easy to understand and is self-explanatory

### Inspiration

Perform EDA and Predict the sales of the next 7 days from the last date of the Training dataset!",.csv
Superstore Sales 🛒🏷️🛍️📦🏪,1,superstore-sales,Superstore.csv,ODC Public Domain Dedication and Licence (PDDL),"""Superstore Sales"" generally refers to the sales data and performance of a superstore or a large retail store that offers a wide range of products and merchandise. These superstores are typically known for their extensive inventory, competitive pricing, and one-stop shopping experience.

Analyzing superstore sales data is essential for store owners, managers, and analysts to understand the store's performance, identify trends, and make informed business decisions. Here are some key aspects of superstore sales analysis:

1. **Sales Revenue:** Tracking the total sales revenue over time provides insights into the overall financial performance of the superstore. It helps identify peak seasons and periods of high or low sales.

2. **Sales by Product Category:** Analyzing sales by product category (e.g., electronics, apparel, home goods) helps understand which categories are driving revenue and which may require improvement.

3. **Sales by Region:** Superstores often have multiple locations. Analyzing sales by region helps identify the best-performing stores and areas for expansion or improvement.

4. **Sales by Customer Segments:** Understanding sales patterns among different customer segments can inform targeted marketing strategies and customer engagement.

5. **Sales Trends:** Identifying sales trends over time, such as monthly or seasonal variations, can help in inventory management and marketing planning.

6. **Product Performance:** Analyzing individual product sales can help identify popular products, slow-moving items, and potential stockouts.

7. **Customer Behavior:** Studying customer behavior, such as purchase frequency, average transaction value, and repeat purchases, provides insights into customer preferences and loyalty.

8. **Promotions and Discounts:** Evaluating the impact of promotions and discounts on sales can help optimize marketing strategies.

9. **Sales Forecasting:** Using historical sales data, superstore owners and managers can forecast future sales, plan inventory levels, and make data-driven decisions.

To conduct thorough sales analysis, superstores often use data visualization tools, spreadsheets, or specialized retail analytics software. These tools help present the data in a visually appealing and easy-to-understand format, enabling better decision-making and strategic planning. Additionally, by integrating sales data with other metrics like profitability, inventory turnover, and customer satisfaction, superstore owners can gain a comprehensive view of their business performance.",.csv
Supply Chain Analysis,1,supply-chain-analysis,supply_chain_data.csv,CC0-1.0,"Supply chain analytics is a valuable part of data-driven decision-making in various industries such as manufacturing, retail, healthcare, and logistics. It is the process of collecting, analyzing and interpreting data related to the movement of products and services from suppliers to customers.

Here is a dataset we collected from a Fashion and Beauty startup. The dataset is based on the supply chain of Makeup products. Below are all the features in the dataset:

- Product Type
- SKU
- Price
- Availability
- Number of products sold
- Revenue generated
- Customer demographics
- Stock levels
- Lead times
- Order quantities
- Shipping times
- Shipping carriers
- Shipping costs
- Supplier name
- Location
- Lead time
- Production volumes
- Manufacturing lead time
- Manufacturing costs
- Inspection results
- Defect rates
- Transportation modes
- Routes
- Costs",.csv
Supply Chain DataSet,1,supply-chain-dataset,supply_chain_data.csv,other,"Supply chain analytics is a valuable part of data-driven decision-making in various industries such as manufacturing, retail, healthcare, and logistics. It is the process of collecting, analyzing and interpreting data related to the movement of products and services from suppliers to customers.",.csv
Swedish Crime Rates,1,swedishcrime,reported.csv,CC0-1.0,"# Context 

Swedish crime statistics from 1950 to 2015


# Content

This data set contains statistics on reported crimes in Sweden (by 100.000) from 1950 to 2015. It contains the following columns:

1. crimes.total: total number of reported crimes
2. crimes.penal.code: total number of reported crimes against the criminal code
3. crimes.person: total number of reported crimes against a person
4. murder: total number of reported murder
5. sexual.offences: total number of reported sexual offences
6. rape: total number of reported rapes
7. assault: total number of reported aggravated assaults
8. stealing.general: total number of reported crimes involving stealing or robbery
9. robbery: total number of reported armed robberies
10. burglary: total number of reported armed burglaries
11. vehicle.theft: total number of reported vehicle thefts
12. house.theft: total number of reported theft inside a house
13. shop.theft: total number of reported theft inside a shop
14. out.of.vehicle.theft: total number of reported theft from a vehicle
15. criminal.damage: total number of reported criminal damages
16. other.penal.crimes: number of other penal crime offenses
17. fraud: total number of reported frauds
18. narcotics: total number of reported narcotics abuses
19. drunk.driving: total number of reported drunk driving incidents
20. Year: the year
21. population: the total estimated population of Sweden at the time


# Acknowledgements

Raw data taken from: https://www.bra.se/bra/bra-in-english/home/crime-and-statistics/crime-statistics.html",.csv
Swiggy Restuarants dataset,1,swiggy-restuarant-dataset,swiggy.csv,CC0-1.0,"The Swiggy Restaurant Dataset is a comprehensive collection of data related to restaurants available on the Swiggy food delivery platform. 
This dataset provides valuable information about various aspects of restaurants, enabling users to explore, analyze, and gain insights into the restaurant landscape on Swiggy.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F13571604%2Ffa1e53e581a80f20d4370c6cf150c39b%2FScreenshot%202023-07-17%20051712.png?generation=1689605256522300&alt=media)",.csv
Sydney House Prices,1,sydney-house-prices,SydneyHousePrices.csv,CC0-1.0,"### Context

200,000 Sydney property sales from 2000-2019 scraped from realestate.com.au
",.csv
Symptom2Disease,1,symptom2disease,Symptom2Disease.csv,CC0-1.0,"The dataset consists of 1200 datapoints and has two columns: ""label"" and ""text"". 

1. **label** : contains the disease labels
2. **text** : contains the natural language symptom descriptions.

The dataset comprises **24 different diseases**, and each disease has **50 symptom descriptions**, resulting in a total of **1200 datapoints**.

The following 24 diseases have been covered in the dataset:

Psoriasis, Varicose Veins, Typhoid, Chicken pox, Impetigo, Dengue, Fungal infection, Common Cold, Pneumonia, Dimorphic Hemorrhoids, Arthritis, Acne, Bronchial Asthma, Hypertension, Migraine, Cervical spondylosis, Jaundice, Malaria, urinary tract infection, allergy, gastroesophageal reflux disease, drug reaction, peptic ulcer disease, diabetes

## Task

The task is to develop a language model to accurately predict the disease given a short description of the symptoms faced by the user.  

Such models can be used to identify potential diseases early on, allowing patients to seek medical attention and treatment promptly. Also, In situations where in-person consultations are not possible or desirable, the app can be used to provide remote diagnosis and treatment recommendations based on the user's symptoms.",.csv
Symptoms and COVID Presence (May 2020 data),1,symptoms-and-covid-presence,Covid Dataset.csv,other,COVID is a contagious disease. The purpose of this dataset is to provide symptoms as input and it should be able to predict if COVID is possibly present or not. It cannot be used for serious medical purposes. ,.csv
Synthetic Indian Automobile Crash Data,1,synthetic-indian-automobile-crash-data,synthetic_automobile_crash_data_india.csv,MIT,"The Synthetic Indian Automobile Crash Data dataset is a simulated collection of data aimed at exploring automobile crash characteristics and safety features within the context of India. With a diverse array of features, it offers a comprehensive view of various factors influencing automobile crashes and their severity. This dataset is particularly valuable for researchers, analysts, and policymakers seeking to gain insights into road safety dynamics, identify trends, and develop strategies for mitigating the impact of traffic accidents.",.csv
TED Talks,1,ted-talks,data.csv,CC-BY-NC-SA-4.0,"### Context

This dataset is created for beginner students of Data Analysis who can explore the field with real-life data. Using TED talk data will help them to analyze the talks and they can also watch the talks of their favorite author with the help of the dataset as well.


### Content

This dataset contains 6 different features of each talk available on TED's website which you can find below

- title        -  Title of the Talk
- author    - Author of Talk
- date       - Date when the talk took place
- views      - Number of views of the Talk
- likes        - Number of likes of the Talk
- link          - Link of the talk from ted.com


### Acknowledgements

The data has been scraped from the official TED Website and is available under the Creative Commons License.


### Inspiration

As TED is one of the best learning platforms for the best people in their field so I always wanted to learn from the best that's why I've created this dataset so that learners can learn both Data Analytics and also from the speakers of TED talks. 

This dataset can help you to answer the following question

1. Finding the most popular TED talks
2. Finding the most popular TED talks Speaker (in terms of number of talks)
3. Month-wise Analysis of TED talk frequency
4. Year-wise Analysis of TED talk frequency
5. Finding TED talks of your favorite Author
6. Finding TED talks with the best view to like ration
7. Finding TED talks based on tags(like climate)
8. Finding the most popular TED talks Speaker (in terms of number of views)

Enjoy Learning!
Thumbnail Reference Image: https://tedxwinterpark.com/what-is-the-difference-between-ted-and-tedx/",.csv
TESLA Stock Data,1,tesla-stock-data-updated-till-28jun2021,TSLA.csv,other,"## What is TESLA?
Tesla, Inc. is an American electric vehicle and clean energy company based in Palo Alto, California. Tesla's current products include electric cars, battery energy storage from home to grid-scale, solar panels and solar roof tiles, as well as other related products and services. 

## Information about this dataset
This dataset provides historical data of TESLA INC. stock (TSLA). The data is available at a daily level. Currency is USD.
",.csv
THE BILLIONAIRES LIST,1,the-billionaires-list,Billionaires.csv,CC0-1.0,"Explore the dynamic landscape of global wealth with our meticulously curated dataset sourced from the Forbes Billionaires List. Delve into the lives and fortunes of the individuals, uncovering key insights into their net worth, age, country or territory of origin, primary sources of wealth, and respective industries. This dataset, meticulously web scraped from Forbes, provides a comprehensive snapshot of the world's financial elite, offering a unique lens into the diverse sectors that contribute to their staggering fortunes. From tech moguls to fashion tycoons, this dataset presents a detailed panorama of the wealthiest personalities shaping the global economic stage.",.csv
TMDB Movies,1,tmdb-movies,TMDB - movies.csv,CC0-1.0,"This data was collected from TMDB's [website](https://www.themoviedb.org/?language=en-US). It contains the movie's name and year of release, movie's budget, revenue, my rating out of 100 and TMDB user score that is also out of 100.",.csv
TMDB Tv Shows,1,tmdb-tv-shows,TMDB - tv_shows.csv,CC0-1.0,This data set contains a small handful of Tv shows in the vast collection that can be found at TMDB's [website](https://www.themoviedb.org/?language=en-US). This data also contains my own personal and TMDB's user score ratings on shows.,.csv
TMKOC-The-famous-indian-family-show,1,tmoc-the-famous-indian-family-show,TMOC.csv,Apache 2.0,"Every family would like to watch the show on every night right ? So the show containing non-violence , friendly characters , showing and representing different states of India , - The Tarak Mehta ka Oolta Chashma show . Was a benchmark in indian TV industry . Let say and see what youtube audiance say about it on youtube . ",.csv
TOEFL Speaking Topics Dataset,1,toefl-speaking-topics-dataset,speaking_topics.csv,ODC Attribution License (ODC-By),"The TOEFL Speaking Topics Dataset is a comprehensive collection of prompts and topics designed to help English language learners prepare for the Speaking section of the Test of English as a Foreign Language (TOEFL). This dataset encompasses a wide range of themes and subjects commonly found in the TOEFL exam, providing test-takers with ample opportunities to practice and improve their speaking skills.

The dataset includes prompts covering various categories such as education, technology, health, environment, social issues, and personal experiences. Each prompt is carefully crafted to simulate the types of questions that may appear in the TOEFL Speaking section, offering learners the chance to familiarize themselves with the format and expectations of the test.

Overall, this dataset serves as a valuable resource for individuals preparing for the TOEFL exam, providing them with a diverse array of speaking topics to enhance their proficiency in English communication skills.





",.csv
TV Sales Forecasting,1,tv-sales-forecast,Date and model wise sale.csv,DbCL-1.0,"Given data contains Jan-2014 to Aug-2016 daily TV sales quantity. There are total 124 Models. This data is collected from one of the leading brand of Bangladesh. Annually there are two big festivals (EID) which follows Islamic lunar calendar. 
provided data are in csv format. it contains only three columns. 

1. Date: Date of Sale
2. Model: TV Model (not Original)
3. Count: Sale Quantity

I like to throw a challenge to Kagglers to device a effective sales forecasting model.",.csv
"TV shows on Netflix, Prime Video, Hulu and Disney+",1,tv-shows-on-netflix-prime-video-hulu-and-disney,tv_shows.csv,CC0-1.0,"### Content
The data scraped comprises a comprehensive list of tv shows available on various streaming platforms

### Inspiration

- Which streaming platform(s) can I find this tv show on?  
- Target age group tv shows vs the streaming application they can be found on
- The year during which a tv show was produced and the streaming platform they can be found on",.csv
Taipei Parking Lots & Income Generated (20yrs),1,taipei-parking-spaces-and-income-generated,Taipei Parking Dataset.csv,Apache 2.0,"Would add data to hold all parking figures in the near future(Uncharged, Disabled, etc.)

`Date`: Recorded **Monthly** data.

`Parking_Space`: Total number of Parking Spaces available in **Taipei Charged Parking Lots**.

`Income`: Total income generated from parking in **New Taiwan Dollar(NT$)**.

`Population`: Total people count in the region.

Possible for parking utilization, income generation, and demographic insights, which can be valuable for urban planning, business optimization, and transportation management.",.csv
Talent sourcing sales data,1,talent-sourcing-sales-data,Talent sourcing sales.csv,Apache 2.0,"This dataset was inspired by a similar but real business case.

In this hypothetical case study, we have a **talent sourcing company**, whose helps clients fill temporary vacancies especially in technical fields. The company has clients all over the world. Their **strategy** so far has been **to find highly qualified talents in cheaper countries near their clients**. This works especially well now that **remote working** has become common, and many clients welcome this change if it can help them cut costs while ensuring the quality of technical work.",.csv
Tarjeta_de_datos,1,tarjeta-de-datos,tarjeta_de_datos.csv,CC0-1.0,"The dataset is part of a final work for a master in bigdata. 

The title of the work is Data Mining techniques and feature engineering with mobility and climate data for studying the prediction of COVID19 cases in Spain.

Data covers the period from 1st March 2020 to 31st January 2021 for up to 21 provinces , a little big more than half the population of the country.

Features are the mobility and climate data.

Mobility data:

Travels by distance.

   - v_muy_cortos : from 0.5 to 2 km
   - v_cortos : from 2 to 5 km
   - v_medios :  from 5 to 10 km
   - v_largos : from 10 to 50 km
   - v_muy_largos :from 50 to 100 km
   - v_extra_largos : more than 100 km

Travels by distance with origin and destiny in different provinces.

   -  vext_muy_cortos : from 0.5 to 2 km
   -  vext_cortos : from 2 to 5 km
   -  vext_medios :  from 5 to 10 km
   -  vext_largos : from 10 to 50 km
   -  vext_muy_largos :from 50 to 100 km
   -  vext_extra_largos : more than 100 km

Travelers by distance : 

   - v_km_muy_cortos : from 0.5 to 2 km
   - v_km_cortos : from 2 to 5 km
   - v_km_medios :  from 5 to 10 km
   - v_km_largos : from 10 to 50 km
   - v_km_muy_largos :from 50 to 100 km
   - v_km_extra_largos : more than 100 km

Travelers by distance with origin and destiny in different provinces : 

   - vext_km_muy_cortos : from 0.5 to 2 km
   - vext_km_cortos : from 2 to 5 km
   - vext_km_medios :  from 5 to 10 km
   - vext_km_largos : from 10 to 50 km
   - vext_km_muy_largos :from 50 to 100 km
   - vext_km_extra_largos : more than 100 km

Travels by time :

   - v_noche  : travels from 0 to 4 am hours
   - v_madrugada: travels from 4 to 8 am hours
   - v_mañana : travels from 8 to 12 hours
   - v_mediodia:  travels from 12 to 16  hours
   - v_sobremesa: travels from 16 to 20 hours
   - v_tarde: travels from 20 to 24  hours

Travels by time with origin and destiny in different provinces : 

  - vext_noche  : travels from 0 to 4 am hours
  - vext_madrugada: travels from 4 to 8 am hours
  - vext_mañana : travels from 8 to 12 hours
  - vext_mediodia:  travels from 12 to 16  hours
  - vext_sobremesa: travels from 16 to 20 hours
  - vext_tarde: travels from 20 to 24  hours

Travelers by time

  - v_km_noche  : travelers from 0 to 4 am hours
  - v_km_madrugada: travelers from 4 to 8 am hours
  - v_km_mañana : travelers from 8 to 12 hours
  - v_km_mediodia:  travelers from 12 to 16  hours
  - v_km_sobremesa: travelers from 16 to 20 hours
  - v_km_tarde: travelers from 20 to 24  hours

Travelers by time with origin and destiny in different provinces :

  - vext_km_noche  : travelers from 0 to 4 am hours
  - vext_km_madrugada: travelers from 4 to 8 am hours
  - vext_km_mañana : travelers from 8 to 12 hours
  - vext_km_mediodia:  travelers from 12 to 16  hours
  - vext_km_sobremesa: travelers from 16 to 20 hours
  - vext_km_tarde: travelers from 20 to 24  hours

Climate data includes temperature, pressure, sun hours , precipitation and relative humidity. 

Labels : COVID19 data is the number of cases
",.csv
Tata Motors 1991-2024,1,tata-motors-1991-2024,TATAMOTORS.NS.csv,Apache 2.0,"Data Set contain Tata motors limited Stock Price from 1991 to 2024 . Tata Motors Limited is an Indian multinational automotive company, headquartered in Mumbai and part of the Tata Group. The company produces cars, trucks, vans, and busses. Subsidiaries include British Jaguar Land Rover and South Korean Tata Daewoo",.csv
Taxation: in Disguise,1,taxation-in-disguise,tax revenue national income new.csv,CC0-1.0,"this graph was created in OurdataWorld :

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Ff855373dbb82f4e2be8e2d15dd53ff37%2Fgraph3.png?generation=1710789763823993&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F8748e4a7bb22a75e1750e2188b9cd4f8%2Fgraph2.png?generation=1710789771083710&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F5a972b2d3cbed490d7d224e9d1b1fb7a%2Fgraph1.png?generation=1710789778454442&alt=media)

Taxation stands as the cornerstone of government revenue across nations, wielding profound influence over economic and societal landscapes. Recent estimates from the International Centre for Tax and Development underscore its pivotal role, revealing that tax revenues contribute significantly to government coffers worldwide. This discourse delves into the historical evolution of taxation, scrutinizes contemporary global trends, and explores the equity and efficiency implications of tax systems.

A Historical Perspective: Tracing Taxation's Evolution

The trajectory of taxation over the past two centuries mirrors the development of modern states, with governments progressively expanding their revenue collection efforts. Longitudinal data illustrates a notable shift towards broader tax bases, indicative of evolving fiscal policies aimed at sustaining government functions and facilitating economic growth.

Cross-Country Disparities: Developed vs. Developing Nations

Disparities in taxation patterns starkly demarcate the chasm between developed and developing economies. Developed nations exhibit a greater propensity for tax collection, primarily reliant on income taxation. Conversely, developing countries lean heavily on trade and consumption taxes, reflecting distinct economic structures and levels of fiscal capacity.

Analyzing Tax Revenue Disparities: Compliance, Efficiency, and Political Institutions

Despite comparable statutory tax rates, developed nations outstrip their developing counterparts in tax revenue collection. This incongruity underscores the pivotal role of compliance and the efficiency of tax collection mechanisms, which are intrinsically intertwined with the robustness of political institutions. A nuanced understanding of these dynamics is essential for elucidating cross-country variations in fiscal capacity.

Equity and Efficiency Implications: Redistributive Effects and Economic Incentives

Taxation serves as a potent redistributive tool, exerting a profound impact on societal equity. However, its influence extends beyond mere revenue generation, shaping individual behavior by altering economic incentives. Recent empirical studies underscore the potential efficiency losses incurred through taxation, particularly concerning the migration of high-income earners. Balancing redistributive imperatives with economic efficiency necessitates judicious tax system design, minimizing adverse consequences while maximizing societal welfare.

Conclusion: Towards Optimal Taxation Systems

In summation, taxation emerges as a multifaceted instrument, intricately interwoven with economic development, social equity, and political governance. Its historical evolution reflects the maturation of state apparatuses, while contemporary trends underscore the divergent paths traversed by nations on the global stage. Addressing the equity and efficiency implications of taxation mandates a nuanced approach, one that reconciles redistributive imperatives with economic imperatives. As nations navigate the complexities of taxation in the 21st century, informed policymaking and institutional robustness are indispensable for fostering sustainable economic growth and societal well-being.
",.csv
Taylor Concert Tours 🌎: Impact on Attendance & 💰,1,taylor-concert-tours-impact-on-attendance-and,Taylor_Train.csv,other,"
Dataset Description: Concert Tour Data

This dataset contains information about various concerts held during different tours, including details such as the city and country where the concert took place, the venue, the opening act(s) performing, the attendance (number of tickets sold and available), the revenue generated, and the name of the tour.

Column Descriptions:

**City**: The name of the city where the concert took place.

**Country**: The name of the country where the city is located.

**Venue**: The name of the venue where the concert was held.

**Opening act(s)**: The names of the artists or bands who performed as the opening act before the main performer(s).

**Attendance (tickets sold / available)**: The number of tickets sold and the total number of tickets available for the concert.

**Revenue**: The revenue generated from ticket sales during the concert.

**Tour**: The name of the concert tour associated with the event.",.csv
Taylor Swift - Released Song Discography (Genius),1,taylor-swift-released-song-discography-genius,ts_discography_released.csv,CC-BY-SA-4.0,"#### Changelog
* **2024-04-25**: Updated for first week post TTPD release (significant changes to Genius page views)
* **2024-04-21**: Initial data for The Tortured Poets Department songs have been added
* **2024-03-27**: 'song_lyrics' column is changed to be a list of lyrics (broken up by line) rather than one string 

#### Introduction
This dataset consists of data from [Genius](https://genius.com/) and contains information on all released songs by Taylor Swift. Scraping was done via Parsel and the accuracy of the data is up to Genius' discretion.

The code used to scrape this data, as well as some examples of EDAs, can be seen on [my Github](https://github.com/madroscla/taylor_swift_discography).

#### Example Use Cases
* Cross-referencing with streaming data (e.g. Spotify, Apple Music)
   * e.g. Possible relationships between song streams and page views
* Lyrical analysis/NLP
   * e.g. Most frequent color words/terms used across discography
   * e.g. Number of similes/metaphors used per album
* Correlation analysis
   * e.g. Possible relationships between song themes/lyrics and writers
* Exploratory data analysis

#### Constraints and Limitations of Discography
This discography prioritizes *song* coverage over *album* coverage; this means that deluxe versions of albums with more songs are preferred over standard versions, and that album releases are preferred over single/EP releases. While not all versions of a song's release will be covered in this dataset, it contains every unique song. Rerecorded songs count as separate entries from their original versions.

Please see table below for more information on what is and isn't included in the discography:

| Included in Discography | Not Included in Discography |
| -- | -- |
| Songs released on Taylor Swift studio albums  | Duplicate song entries (e.g. for single release, album release, deluxe album release, etc.) |
| Songs released on Taylor Swift rerecorded ""Taylor's Version"" albums | Unreleased/leaked songs and demos |
| Songs by Taylor Swift for soundtracks or released as non-album singles | Covers of Taylor Swift songs by other artists |
| Remixes of Taylor Swift songs featuring new performing artists | Remixes/acoustic versions of songs not featuring new performing artists|
| Songs written by Taylor Swift for other artists, even if they don't feature Taylor | Live versions of songs/song mashups previously accounted for |
| Songs by other artists featuring Taylor Swift | Songs that sample/interpolate Taylor Swift songs, even if they list her as a writer or feature |
| Song covers by or featuring Taylor Swift that have been officially recorded and released | Songs that only exist in video format (DVD, live show recording, etc.) |",.csv
Taylor Swift Song Information,1,taylor-swift-song-information,taylor_swift_songs.csv,MIT,"Hello! I'm a musician and swiftie that wondered:

- On which keys does Taylor Swift usually writes on?
- I have learned some of her songs and many were on C Major, is it her favorite? 
- Does she have another preferred key?

So I used Spotify's API and saved the musical columns to analyze them. You'll find:
- Track Name ------------------ String
- Album Name ----------------- String
- Key -------------------------- String
- Key Mode (Major or minor) --- String
- BPM ------------------------- Int Percentage 
- Energy ----------------------- Int Percentage
- Danceability ----------------- Int Percentage
- Duration in minutes ---------- Float
- Time Signature -------------- String
- Valence --------------------- Int Percentage

In my notebook I explain how I interacted with the API to get the correct amount of songs and avoid duplicates, as she has a lot of remix albums, acoustic versions, etc.

I'll update this dataset everytime she releases an album or a single. Will be updated soon after TTPD information is available in Spotify.

Check out my analysis in [Tableau Public](https://public.tableau.com/app/profile/gabriela.iriarte/viz/TaylorSwiftMusicalAnalysis/TaylorSwiftMusicalAnalysis_1)

Check out the code to extract information from Spotify in [Github](https://github.com/iri16009/Taylor-Swift-Song-Analysis/blob/main/README.md)",.csv
Taylor Swift Song Lyrics from all the albums,1,taylor-swift-song-lyrics-from-all-the-albums,taylor_swift_lyrics.csv,CC-BY-SA-4.0,"### Context

This data set was created by [PromptCloud][1] (a Data-as-a-Service provider), using the API exposed by Genius.com.

### Content

It has the following data fields:

 - album name 
 - track title 
 - track number 
 - lyric text 
 - line number of the lyric in the track
 - year of release of the album

### Initial analyses

You can check out [this article][2] to understand the following initial set of analysis:

– Exploratory analysis

 - word counts based on tracks and albums
 - time series analysis of word counts
 - distribution of word counts

– Text mining
 
 - word cloud
 - bigram network
 - sentiment analysis (includes chord diagram)

  [1]: https://www.promptcloud.com
  [2]: https://www.promptcloud.com/blog/data-visualization-text-mining-taylor-swift-song-lyrics",.csv
Taylor Swift Spotify Data,1,taylor-swift-spotify-data,spotify_taylorswift.csv,CC-BY-SA-4.0,"### Context

We gathered data from songs on Taylor Swift's albums. Concerts, studio sessions, and features songs will not be included. However, between the standard album and the deluxe album, we will be using the deluxe version. At the same time, between the standard album and the Taylor's version, we will be using the Taylor's version of the album. Hence, we will follow this list:
1. [Taylor Swift (2006)](https://open.spotify.com/album/5eyZZoQEFQWRHkV2xgAeBw?si=QMW62hX7RDuPq95Jgkh_Vw)
2. [Fearless (Taylor's Version) (2021)](https://open.spotify.com/album/4hDok0OAJd57SGIT8xuWJH?si=LTSeAgbUTeCTgBkuM5CWiA)
3. [Speak Now (Deluxe Package) (2010)](https://open.spotify.com/album/6S6JQWzUrJVcJLK4fi74Fw?si=gJFRCD94TDqUtOVYOxnE3w)
4. [Red (Deluxe Edition) (2012)](https://open.spotify.com/album/1KVKqWeRuXsJDLTW0VuD29?si=hbSetLVBTeCuoP5YLZXx7Q)
5. [1989 (Deluxe) (2014)](https://open.spotify.com/album/1yGbNOtRIgdIiGHOEBaZWf?si=tVrwXonTQ9KrddNh1JJShQ)
6. [reputation (2017)](https://open.spotify.com/album/6DEjYFkNZh67HP7R9PSZvv?si=1F4DPLl2QjeHiESDVV1dNw)
7. [Lover (2019)](https://open.spotify.com/album/1NAmidJlEaVgA3MpcPFYGq?si=4u6GlPl8S2iuMNvzwdi8XA)
8. [folklore (deluxe version) (2020)](https://open.spotify.com/album/1pzvBxYgT6OVwJLtHkrdQK?si=1jUpnSQsQsalcNOP297yvg)
9. [evermore (deluxe version) (2020)](https://open.spotify.com/album/6AORtDjduMM3bupSWzbTSG?si=0mjcdVJxTaqPeSkQcvNf4g)

### Content

To understand our data better, let's define each column.
* name - Name of song
* album - Name of album
* artist - Name of artist/s involved
* release_date - Release date of album
* length - Song length in milliseconds
* popularity - Percent popularity of the song based on Spotify's algorithm (possibly the number of stream  at a certain period of time)
* danceability - How suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity
* acousticness - How acoustic a song is
* energy - A perceptual measure of intensity and activity
* instrumentalness - Te amount of vocals in the song
* liveness - Probability that the song was recorded with a live audience
* loudness - Tdency o of music to be recorded at steadily higher volumes
* speechiness - Presence of spoken words in a track (if the speechiness of a song is above 0.66, it is probably made of spoken words, a score between 0.33 and 0.66 is a song that may contain both music and words, and a score below 0.33 means the song does not have any speech)
* valence - A measure of how happy or sad the song sounds
* tempo - Beats per minute

### Acknowledgements

All data were extracted from Spotify WebAPI using the spotipy Python library.

### Inspiration

You can try to do a valence analysis of each song, or find what makes a song popular. Have fun exploring questions!",.csv
Taylor Swift Spotify Dataset,1,taylor-swift-spotify-dataset,taylor_swift_spotify.csv,other,"This dataset consist of data from Spotify's API on all albums listed on Spotify for Taylor Swift. I set up the dataset to update monthly so that if any albums get added it will get added to the dataset too. At first it may look like there are song duplicates but I checked and all song IDs are unique.

*The columns in this dataset are*:

**name** - the name of the song

**album** - the name of the album

**release_date** - the day month and year the album was released

**track number** - the order the song appears on the album

**id** - the Spotify id for the song

**uri** - the Spotify uri for the song

**acousticness** - A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic.

**danceability** - Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable.

**energy** - Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy.

**instrumentalness** - Predicts whether a track contains no vocals. ""Ooh"" and ""aah"" sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly ""vocal"". The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0.

**liveness** - Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live.

**loudness** - The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typically range between -60 and 0 db.

**speechiness** - detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks.

**tempo** - The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration.

**valence** - A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).

**popularity** - the popularity of the song from 0 to 100

**duration_ms** - The duration of the track in milliseconds.

*Possible ways to use this data*:

**Data exploration**
**Data visualization**
**Recommendation systems**
**Cluster analysis**
**Popularity predictions**
**Data cleaning**

I hope you find this data to be useful, enjoy!",.csv
Taylor Swift | The Eras Tour Official Setlist Data,1,taylor-swift-the-eras-tour-official-setlist-data,era_tour_setlist.csv,other,"💁‍♀️Please take a moment to carefully read through this description and metadata to better understand the dataset and its nuances before proceeding to the Suggestions and Discussions section.

## Dataset Description:
This dataset provides a comprehensive collection of setlists from Taylor Swift’s official era tours, curated expertly by Spotify. The playlist, available on Spotify under the title ""Taylor Swift The Eras Tour Official Setlist,"" encompasses a diverse range of songs that have been performed live during the tour events of this global artist. Each dataset entry corresponds to a song featured in the playlist.

Taylor Swift, a pivotal figure in both country and pop music scenes, has had a transformative impact on the music industry. Her tours are celebrated not just for their musical variety but also for their theatrical elements, narrative style, and the deep emotional connection they foster with fans worldwide. This dataset aims to provide fans and researchers an insight into the evolution of Swift's musical and performance style through her tours, capturing the essence of what makes her tour unique.

## Data Collection and Processing:
Obtaining the Data: The data was obtained directly from the Spotify Web API, specifically focusing on the setlist tracks by the artist. The Spotify API provides detailed information about tracks, artists, and albums through various endpoints.

Data Processing: To process and structure the data, Python scripts were developed using data science libraries such as pandas for data manipulation and spotipy for API interactions, specifically for Spotify data retrieval.

Workflow:

Authentication
API Requests
Data Cleaning and Transformation
Saving the Data

## Attribute Descriptions:
- artist_name: the name of the artist (Taylor Swift)
- track_name: the title of the track
- is_explicit: Indicates whether the track contains explicit content
- album_release_date: The date when the track was released
- genres: A list of genres associated with Beyoncé
- danceability: A measure from 0.0 to 1.0 indicating how suitable a track is for - dancing based on a combination of musical elements
- valence: A measure from 0.0 to 1.0 indicating the musical positiveness conveyed by a track
- energy: A measure from 0.0 to 1.0 representing a perceptual measure of intensity and activity
- loudness: The overall loudness of a track in decibels (dB)
- acousticness: A measure from 0.0 to 1.0 whether the track is acoustic
- instrumentalness: Predicts whether a track contains no vocals
- liveness: Detects the presence of an audience in the recordings
speechiness: Detects the presence of spoken words in a track
- key: The key the track is in. Integers map to pitches using standard Pitch Class notation
- tempo: The overall estimated tempo of a track in beats per minute (BPM)
- mode: Modality of the track
- duration_ms: The length of the track in milliseconds
- time_signature: An estimated overall time signature of a track
- popularity: A score between 0 and 100, with 100 being the most popular

*Note: Popularity score reflects the score recorded on the day that retrieves this dataset. The popularity score could fluctuate daily.*

## Potential Applications:
- Predictive Analytics: Researchers might use this dataset to predict future setlist choices for tours based on album success, song popularity, and fan feedback.

## Disclaimer and Responsible Use:
This dataset, derived from Spotify focusing on Taylor Swift's The Eras Tour setlist data, is intended for educational, research, and analysis purposes only. Users are urged to use this data responsibly, ethically, and within the bounds of legal stipulations.

- Compliance with Terms of Service: Users should adhere to Spotify's Terms of Service and Developer Policies when utilizing this dataset.
- Copyright Notice: The dataset presents music track information including names and artist details for analytical purposes and does not convey any rights to the music itself. Users must ensure that their use does not infringe on the copyright holders' rights. Any analysis, distribution, or derivative work should respect the intellectual property rights of all involved parties and comply with applicable laws.
- No Warranty Disclaimer: The dataset is provided ""as is,"" without warranty, and the creator disclaims any legal liability for its use by others.
- Ethical Use: Users are encouraged to consider the ethical implications of their analyses and the potential impact on artists and the broader community.
- Data Accuracy and Timeliness: The dataset reflects a snapshot in time and may not represent the most current information available. Users are encouraged to verify the data's accuracy and timeliness.
- Source Verification: For the most accurate and up-to-date information, users are encouraged to refer directly to Spotify's official website.
- Independence Declaration: This project is independent and has not been authorized, sponsored, or otherwise approved by Spotify, Beyoncé, or any other entities mentioned. The creator/maintainer is not affiliated with these entities.

## Expected Update Frequency:
When I notice an update made in the setlist, I will do my best to reflect the changes to the data. 

## Contribution to Community:
Users who derive new insights, develop enhancements to the dataset, or create analytics that shed new light on Taylor's music are encouraged to contribute back to the community.
- Kaggle Notebooks: Users are encouraged to create and share their analysis in the form of Kaggle notebooks. When creating your notebook, please initiate your notebook by clicking ""New Notebook"" at the top of this dataset page, so that the action automatically loads this dataset as an input to your notebook.
- Suggestions Tab: For feedback and suggestions related to the dataset, the 'Suggestions' tab on the dataset's Kaggle page is your go-to platform.

## Resources
Spotify Web API: https://developer.spotify.com/documentation/web-api

Official setlist URL: https://open.spotify.com/playlist/37i9dQZF1DX0D996ZXujBy

## Last Update:
12/5/2024
",.csv
Tech Stock Market 📈💻,1,tech-stock-market,stock_data.csv,MIT,"Embark on a data-driven journey through the financial landscapes of the tech industry titans – Apple (AAPL), Amazon (AMZN), Google's parent company Alphabet (GOOGL), and Microsoft (MSFT). This comprehensive stock market dataset spans the period from January 1, 2020, to January 1, 2024, encapsulating a pivotal era in the technological and e-commerce spheres.

Dive into the intricacies of market dynamics with a wealth of key metrics at your fingertips. Uncover the adjusted close prices, providing insights into the true market value of each stock. Analyze daily highs and lows, shedding light on the peaks and troughs experienced by these industry leaders. Explore opening and closing prices, unraveling the story of each trading day's journey. Delve into trading volumes, the heartbeat of the market, reflecting the intensity and magnitude of investor activity.

This dataset not only captures the financial performance of these influential companies but also serves as a gateway for uncovering trends, patterns, and anomalies that have shaped their trajectories. Whether you're an experienced investor seeking to refine your strategies or a data enthusiast hungry for insights, this dataset provides a compelling narrative of the ebb and flow of the tech stock market.

Embark on a captivating exploration of these tech giants' financial narratives, and let the data guide you through the ever-evolving landscape of technology and commerce. Discover the nuances that set the stage for innovation, expansion, and resilience in the dynamic world of stock trading.",.csv
Tech layoffs 2020 - 2024,1,tech-layoffs-2020-2024,tech_layoffs_til_Q1_2024.csv,CC-BY-NC-SA-4.0,"Data is from https://layoffs.fyi/

Web scraping on Dec. 25th 2023 + Jan 14th 2024 + March 31th 2024

Added new columns: company size before layoff, company size after layoffs, GPS-Data (lat and lng), country, continent and coordinates

Deleted rows with NAs

EDA in R

Learning and practicing in R

Data format: xlsx (Excel) + csv",.csv
Telco customer churn (11.1.3+),1,telco-customer-churn-11-1-3,telco.csv,MIT,"# Telco Customer Churn Dataset

The Telco customer churn data contains information about a fictional telco company that provided home phone and Internet services to 7043 customers in California in Q3. It indicates which customers have left, stayed, or signed up for their service. Multiple important demographics are included for each customer, as well as a Satisfaction Score, Churn Score, and Customer Lifetime Value (CLTV) index.

# Columns Description: 

- CustomerID: A unique ID that identifies each customer.

- Gender: The customer’s gender: Male, Female

- Age: The customer’s current age, in years, at the time the fiscal quarter ended.

- Senior Citizen: Indicates if the customer is 65 or older: Yes, No

- Married: Indicates if the customer is married: Yes, No

- Dependents: Indicates if the customer lives with any dependents: Yes, No. Dependents could be children, parents, grandparents, etc.

- Number of Dependents: Indicates the number of dependents that live with the customer.

- CustomerID: A unique ID that identifies each customer.

- Count: A value used in reporting/dashboarding to sum up the number of customers in a filtered set.

- Country: The country of the customer’s primary residence.

- State: The state of the customer’s primary residence.

- City: The city of the customer’s primary residence.

- Zip Code: The zip code of the customer’s primary residence.

- Latitude: The latitude of the customer’s primary residence.

- Longitude: The longitude of the customer’s primary residence.

- Zip Code: The zip code of the customer’s primary residence.

- Population: A current population estimate for the entire Zip Code area.

- CustomerID: A unique ID that identifies each customer.

- Count: A value used in reporting/dashboarding to sum up the number of customers in a filtered set.

- Quarter: The fiscal quarter that the data has been derived from (e.g. Q3).

- Referred a Friend: Indicates if the customer has ever referred a friend or family member to this company: Yes, No

- Number of Referrals: Indicates the number of referrals to date that the customer has made.

- Tenure in Months: Indicates the total amount of months that the customer has been with the company by the end of the quarter specified above.

- Offer: Identifies the last marketing offer that the customer accepted, if applicable. Values include None, Offer A, Offer B, Offer C, Offer D, and Offer E.

- Phone Service: Indicates if the customer subscribes to home phone service with the company: Yes, No

- Avg Monthly Long Distance Charges: Indicates the customer’s average long distance charges, calculated to the end of the quarter specified above.

- Multiple Lines: Indicates if the customer subscribes to multiple telephone lines with the company: Yes, No

- Internet Service: Indicates if the customer subscribes to Internet service with the company: No, DSL, Fiber Optic, Cable.

- Avg Monthly GB Download: Indicates the customer’s average download volume in gigabytes, calculated to the end of the quarter specified above.

- Online Security: Indicates if the customer subscribes to an additional online security service provided by the company: Yes, No

- Online Backup: Indicates if the customer subscribes to an additional online backup service provided by the company: Yes, No

- Device Protection Plan: Indicates if the customer subscribes to an additional device protection plan for their Internet equipment provided by the company: Yes, No

- Premium Tech Support: Indicates if the customer subscribes to an additional technical support plan from the company with reduced wait times: Yes, No

- Streaming TV: Indicates if the customer uses their Internet service to stream television programing from a third party provider: Yes, No. The company does not charge an additional fee for this service.

- Streaming Movies: Indicates if the customer uses their Internet service to stream movies from a third party provider: Yes, No. The company does not charge an additional fee for this service.

- Streaming Music: Indicates if the customer uses their Internet service to stream music from a third party provider: Yes, No. The company does not charge an additional fee for this service.

- Unlimited Data: Indicates if the customer has paid an additional monthly fee to have unlimited data downloads/uploads: Yes, No

- Contract: Indicates the customer’s current contract type: Month-to-Month, One Year, Two Year.

- Paperless Billing: Indicates if the customer has chosen paperless billing: Yes, No

- Payment Method: Indicates how the customer pays their bill: Bank Withdrawal, Credit Card, Mailed Check

- Monthly Charge: Indicates the customer’s current total monthly charge for all their services from the company.

- Total Charges: Indicates the customer’s total charges, calculated to the end of the quarter specified above.

- Total Refunds: Indicates the customer’s total refunds, calculated to the end of the quarter specified above.

- Total Extra Data Charges: Indicates the customer’s total charges for extra data downloads above those specified in their plan, by the end of the quarter specified above.

- Total Long Distance Charges: Indicates the customer’s total charges for long distance above those specified in their plan, by the end of the quarter specified above.

- CustomerID: A unique ID that identifies each customer.

- Count: A value used in reporting/dashboarding to sum up the number of customers in a filtered set.

- Quarter: The fiscal quarter that the data has been derived from (e.g. Q3).

- Satisfaction Score: A customer’s overall satisfaction rating of the company from 1 (Very Unsatisfied) to 5 (Very Satisfied).

- Satisfaction Score Label: Indicates the text version of the score (1-5) as a text string.

- Customer Status: Indicates the status of the customer at the end of the quarter: Churned, Stayed, or Joined

- Churn Label: Yes = the customer left the company this quarter. No = the customer remained with the company. Directly related to Churn Value.

- Churn Value: 1 = the customer left the company this quarter. 0 = the customer remained with the company. Directly related to Churn Label.

- Churn Score: A value from 0-100 that is calculated using the predictive tool IBM SPSS Modeler. The model incorporates multiple factors known to cause churn. The higher the score, the more likely the customer will churn.

- Churn Score Category: A calculation that assigns a Churn Score to one of the following categories: 0-10, 11-20, 21-30, 31-40, 41-50, 51-60, 61-70, 71-80, 81-90, and 91-100

- CLTV: Customer Lifetime Value. A predicted CLTV is calculated using corporate formulas and existing data. The higher the value, the more valuable the customer. High value customers should be monitored for churn.

- CLTV Category: A calculation that assigns a CLTV value to one of the following categories: 2000-2500, 2501-3000, 3001-3500, 3501-4000, 4001-4500, 4501-5000, 5001-5500, 5501-6000, 6001-6500, and 6501-7000.

- Churn Category: A high-level category for the customer’s reason for churning: Attitude, Competitor, Dissatisfaction, Other, Price. When they leave the company, all customers are asked about their reasons for leaving. Directly related to Churn Reason.

- Churn Reason: A customer’s specific reason for leaving the company. Directly related to Churn Category.

",.csv
Telefon Bankacılığı - Mobile Bank (Classification),1,telefon-bankacl-mobile-bank,banka.csv,Apache 2.0,Telefon ile bankacılıktaki demo sesli komutlar sınıflandırılmıştır.,.csv
Temperature Readings : IOT Devices,1,temperature-readings-iot-devices,IOT-temp.csv,GNU Lesser General Public License 3.0,"### Context

`IIoT 4.0` is coming to cover all enterprise monitoring and maintenance system. Thus, we need bold and sustainable algorithms and approaches to *analyze the IOT sensor data* and find hidden patterns and insights. **Heat Index** ( *temperature + humidity* ) is one common data recorded on these IOT readers. The frequency of the upcoming data is very fast. The sensor reads *hundreds to millions of data per second*. There is a huge and versatile application of this data in real world. like:- Agriculture, weather forecasting, soil monitoring and treatment, enterprise maintenance, Data centres, and many more...

![Heat stress index of India](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F1746215%2F4efaeb944b88f63426aef6fc814bccbf%2Fhttp___com.ft.imagepublish.prod.s3.amazonaws.png?generation=1575282894304319&alt=media)


Therefore, Wrangling, analyzing, and grasping insights from these data are equally important for multiple application sectors. This dataset is a small snap ( **sample**) out of ocean-depth entries in the original dataset, which keeps increasing day by day. The purpose of this dataset is to allow fellow Scientists/ Analysts to play and ***Find the unfounds***. 🙏 


### Content

This dataset contains the temperature readings from IOT devices installed outside and inside of an anonymous Room (say -  admin room). The device was in the alpha testing phase. So, It was uninstalled or shut off several times during the entire reading period ( **28-07-2018 to 08-12-2018**). This random interval recordings and few mis-readings ( outliers) makes it more challanging to perform analysis on this data. Let's see, what you can present in the plate out of this messy data.

# ------------------------------------------------
***##### Technical Details:***

**columns = 5 | Rows = 97605**

`id` : unique IDs for each reading

`room_id/id` : room id in which device was installed (inside and/or outside) -&gt; currently 'admin room' only for example purpose.

`noted_date` : date and time of reading

`temp` : temperature readings

`out/in` : whether reading was taken from device installed inside or outside of room?


### Acknowledgements

I sincerely thank the team wokring at `**LimelightIT Research**` for providing me the device to record the data and helping me throughout the project.


### Inspiration
I have always been curious to know how climate changes day by day, year to year. One way to understnad this is by analysis and understanding the heat index of an area. Temperature data is a small part of it. But, The finidngs can lead to bigger and more serious inventions and outcomes!

***From this dataset , it would be intersting to find out:***

- what was the max and min temperature?

- How outside temperature was related to inside temperature? any relation between the two?

- What was the variance of temperature for inside and outside room temperature?

- What is the trend in the data?

- Can you use Time Series Forecast algo to predict the next scenario?

- which was the hottest/coolest month ?

- any warning signals fro climate disaster ?

- and many more... 

![Effects of Heat index on Body](https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcR-wlMHlJApWdWDOZ0pwsqAQUvN-ZTfY8ZdUhE8fD_8sC0gnqcr)

**Data Science is all about finding the possibilities and verifying the probabilities!**

### Thanks !

",.csv
Temperature and Ice Cream Sales,1,temperature-and-ice-cream-sales,Ice Cream Sales - temperatures.csv,MIT,"**Project is still being worked on.**

Initially, this dataset was just for a Google Data Analytics project, where I was given a task to accomplish with the data in a spreadsheet: look at the table given in the spreadsheet, and see if there's a correlation between temperature and revenue in ice cream sales. Eventually, I did see the pattern: higher temperatures usually meant more revenue, which seems realistic. However, I wanted to dig further into the data and perform a deeper analysis using a visualization, and maybe even a regression. My new questions were, ""How strong is this correlation?"" and ""Can we represent the data using a linear regression?""",.csv
Temperatures of INDIA,1,temperatures-of-india,temperatures.csv,other,"### Context

The Data is of INDIAN GOVT. collected from [indian govt website][1]. 

### Content

Data consists of temperatures of INDIA averaging the temperatures of all places. Recent updated temperature data is 2017. 
**Temperatures values are recorded in CELSIUS**



  [1]: https://data.gov.in/catalog/all-india-seasonal-and-annual-minmax-temperature-series",.csv
Tesla Stock Data 2016-2021,1,tesla-stock-data-20162021,TSLA.csv,other,"Source of Data :  [Tesla Stock](https://finance.yahoo.com/quote/TSLA/history?period1=1597536000&period2=1629072000&interval=1d&filter=history&frequency=1d&includeAdjustedClose=true)

",.csv
Tesla Stock Price With Indicators (10 Years),1,tesla-stock-price-with-indicators-10-years,tsla_2014_2023.csv,CC0-1.0,"This dataset provides a comprehensive look at Tesla's stock performance over the past ten years, incorporating a variety of technical indicators to analyze its movements. The data includes the date of recording and several key metrics: the opening price, the highest and lowest prices during the trading day, the closing price, and the trading volume. Additionally, it features momentum indicators like the 7-day and 14-day Relative Strength Index (RSI), which help assess whether the stock is overbought or oversold. The Commodity Channel Index (CCI) over 7 and 14 days is included to identify short- and medium-term trends by comparing the current price against the historical average. Moving averages are also a significant part of this dataset, with the 50-day and 100-day Simple Moving Average (SMA) and Exponential Moving Average (EMA) providing insights into the stock's direction. Other critical indicators include the Moving Average Convergence Divergence (MACD), Bollinger Bands for price volatility, the True Range, and the 7-day and 14-day Average True Range (ATR), offering a measure of market volatility. The dataset aims to predict the next day's closing price, serving as a valuable resource for forecasting future stock movements.",.csv
Text Classification,1,software-requirements,Dataset.csv,other,"## 🔶Context

&gt;The dataset contains information related to software requirements. It includes fields such as ***Scenario***, ***Requirement***, ***Requirement Type***, and ***Author***. 

&gt;- ✅There are a total of 20 different scenarios in the dataset. 
- ✅Each scenario consists of 10 functional and 10 non-functional requirements. 
- ✅Ad-ditionally, each requirement is labeled with its type, which can be either functional or non-functional. 
- ✅The authors of the requirements are classified into two categories: Human and ChatGPT.


## 🔶Content
&gt;The dataset comprises structured data on software requirements, offering a diverse range of scenarios and requirement types. It provides valuable insights into the characteristics and classifications of software requirements, including functional and non-functional aspects. With its comprehensive coverage of scenarios and requirement types, the dataset serves as a rich resource for research and analysis in the field of software engineering and natural language processing.

## 
##  🔶
## 
&gt;You can examine the work with 5 different machine learning methods on this dataset.",.csv
Text Document Classification Dataset,1,text-document-classification-dataset,df_file.csv,other,"This is text document classification dataset which contains 2225 text data and five categories of documents. Five categories are  politics, sport, tech, entertainment and  business. We can use this dataset for documents classification and document clustering.

**About Dataset**
- Dataset contains two features text and label.
- No. of Rows : 2225
- No. of Columns : 2

**Text:** It contains different categories of text data
**Label:** It contains labels for five different categories : 0,1,2,3,4

1.  Politics = 0
2. Sport  =  1
3. Technology  = 2 
4. Entertainment  =3
5. Business = 4
 ",.csv
Text classification documentation,1,text-classification-documentation,df_file.csv,Apache 2.0,"This is text document classification dataset which contains 2225 text data and five categories of documents. Five categories are politics, sport, tech, entertainment and business. We can use this dataset for documents classification and document clustering.

**Dataset contains two features text and label.**
No. of Rows : 2225
No. of Columns : 2


**Text**:It contains different categories of text data
**Label: **It contains labels for five different categories : 0,1,2,3,4

Politics = 0
Sport = 1
Technology = 2
Entertainment =3
Business = 4",.csv
Text with Sentiment,1,text-with-sentiment,emotion_dataset_raw.csv,other,"This dataset contains many text along with their respective sentiment.
The sentiment contains joy, fear, sadness, neutral etc.
The dataset contains 2 columns- Sentiment and the text.",.csv
The Battle Between LLMs ⚔️ Dataset,1,the-battle-between-llms-dataset,result_tictactoe.csv,Community Data License Agreement - Sharing - Version 1.0,"The  dataset contains data related to the games between the Gemini and Claude. It has 3 columns : 
- **Winner**: Denotes who won the game.
- **Chance_taken_by_Gemini**: Denotes the number of regeneration by Gemini
- **Chance_taken_by_Claude**: Denotes the number of regeneration by Claude",.csv
The Best Cities for a Workation,1,the-best-cities-for-a-workation,best cities for a workation.csv,CC0-1.0,"### Context

Finding a good place for your next ""workation"". Here is a list of ""The Best Cities In The World For A Workation"" as suggested by Holidu (https://www.holidu.co.uk/magazine/the-best-cities-for-a-workation).


### Acknowledgements
Data source: https://www.holidu.co.uk/magazine/the-best-cities-for-a-workation
Cover image credit: https://www.pexels.com/photo/laptop-with-copybook-and-cup-of-coffee-on-bed-sheet-4050430/


",.csv
The Big Mac Index,1,worldwide-big-mac-prices,big-mac-source-data.csv,Attribution 4.0 International (CC BY 4.0),"### Context

The Big Mac Index is published by The Economist as an informal way of measuring the purchasing power parity (PPP) between two currencies and provides a test of the extent to which market exchange rates result in goods costing the same in different countries. It ""seeks to make exchange-rate theory a bit more digestible"". 

### Content

Name: Country name 
iso_a3: Country code according to the ISO A3
currency_code: Currency 
local_price: Big mac price in the local currency
dollar_ex: Dollar exchange of the local currency
GDP_dollar: Gross Domestic Product in dollar currency
date: data recorded date


### Inspiration

Burgernomics. 

Thanks to the Economist.",.csv
The Bread Basket,1,the-bread-basket,bread basket.csv,CC0-1.0,"### Context

The dataset belongs to ""The Bread Basket"" a bakery located in Edinburgh. The dataset has 20507 entries, over 9000 transactions, and 4 columns.


### Content

The dataset has transactions of customers who ordered different items from this bakery online and the time period of the data is from 26-01-11 to 27-12-03.",.csv
The Economic Freedom Index,1,the-economic-freedom-index,economic_freedom_index2019_data.csv,DbCL-1.0,"Context
-------

The Economic Freedom Index is poised to help readers track over two decades of the advancement in economic freedom, prosperity, and opportunity and promote these ideas in their homes, schools, and communities. The Index covers 12 freedoms – from property rights to financial freedom – in 186 countries.

Content
-------

The data (last updated 26/02/2019) is presented in CSV format as follows: CountryID, Country Name, WEBNAME, Region, World Rank, Region Rank, 2019 Score, Property Rights, Judical Effectiveness, Government Integrity, Tax Burden, Gov't Spending, Fiscal Health, Business Freedom, Labor Freedom, Monetary Freedom, Trade Freedom, Investment Freedom, Financial Freedom, Tariff Rate (%), Income Tax Rate (%), Corporate Tax Rate (%), Tax Burden % of GDP, Gov't Expenditure % of GDP , Country, Population (Millions), ""GDP (Billions, PPP)"", GDP Growth Rate (%), 5 Year GDP Growth Rate (%), GDP per Capita (PPP), Unemployment (%), Inflation (%), FDI Inflow (Millions), Public Debt (% of GDP).

Acknowledgements
----------------

This dataset belongs to The Heritage Foundation: https://www.heritage.org/index. This dataset is freely available to download on their website.

Inspiration
-----------

A study into global economic prosperity. Please feel free to discuss any other findings you may want to contribute to.",.csv
The Estonia Disaster Passenger List,1,passenger-list-for-the-estonia-ferry-disaster,estonia-passenger-list.csv,CC0-1.0,"![](https://i.ibb.co/hB0CV9W/r-MS-Estonia-model.jpg)

# Introduction

On September 27 1994 the ferry Estonia set sail on a night voyage across the Baltic Sea from the port of Tallin in Estonia to Stockholm. She departed at 19.00 carrying 989 passengers and crew, as well as vehicles, and was due to dock at 09.30 the following morning, Tragically, the Estonia never arrived.

The weather was typically stormy for the time of year but, like all the other scheduled ferries on that day, the Estonia set off as usual. At roughly 01:00 a worrying sound of screeching metal was heard, but an immediate inspection of the bow visor showed nothing untoward. The ship suddenly listed 15 minutes later and soon alarms were sounding, including the lifeboat alarm. Shortly afterwards the Estonia rolled drastically to starboard. Those who had reached the decks had a chance of survival but those who had not were doomed as the angled corridors had become death traps. A Mayday signal was sent but power failure meant the ship’s position was given imprecisely. The Estonia disappeared from the responding ships’ radar screens at about 01:50.

The Marietta arrived at the scene at 02:12 and the first helicopter at 03:05. Of the 138 people rescued alive, one died later in hospital.

Of the 310 people who had reached the decks, almost a third died of hypothermia. The final death toll was shockingly high – more than 850 people.

An official inquiry found that failure of the locks on the bow visor, which broke away under the punishing waves, caused water to flood the car deck and quickly capsize the ship. The report also noted a lack of action, delay in sounding the alarm, lack of guidance from the bridge and a failure to light distress flares.

The sinking of the Estonia was Europe’s worst postwar maritime disaster.

Read more: https://en.wikipedia.org/wiki/MS_Estonia

# Facts

When was the Sinking of the Estonia: **September 28, 1994**
Where was the Sinking of the Estonia: **Near the Turku Archipelago, in the Baltic Sea**
What was the Sinking of the Estonia death toll: **852 passengers and crew**

Interesting things to investigate about the data:

* Who's more likely to survive the sinking based on data?
* Is age an indicator for survival?
* Is gender an indicator for survival?
* Did the crew aboard have a higher chance of survival than passengers?

Since the death toll is well above 80%, can you make a classifier that beats the baseline (all passengers died)?

# Data Dictionary

| Variable | Definition | Key |
| --- | --- |
| Country | Country of origin | |
| Firstname | Firstname of passenger | |
| Lastname | Lastname of passenger | |
| Sex | Gender of passenger | M = Male, F = Female |
| Age| Age of passenger at the time of sinking| |
| Category|  The type of passenger | C = Crew, P = Passenger |
| Survived |  Survival | 0 = No, 1 = Yes |

# Video

Watch the Zero Hour documentary about the disaster: https://www.youtube.com/watch?v=eFDGL_ehpkI

# Images

![](https://cdn.prod.www.spiegel.de/images/d0eed47d-0001-0005-0000-000001064832.gif)
![](https://www.vragguiden.dk/ThumbImage.aspx?sid=108&width=710)
![](https://www.vragguiden.dk/ThumbImage.aspx?sid=109&width=710)
![](https://www.vragguiden.dk/wreckimages/113.jpg)",.csv
The Heart Failure Prediction Dataset,1,mortality-rate-heart-patient-pakistan-hospital,FIC.Full CSV.csv,CC0-1.0,"## ****Context****
Heart disease is easier to treat when detected early, heart disease is the leading cause of death in the all over the world. The term “heart disease” refers to several types of heart conditions. In the Pakistan and some other countries, the most common type of heart disease is coronary artery disease (CAD), which can lead to heart attack. You can greatly reduce your risk for heart disease through lifestyle changes.
I have uploaded this dataset together to call my fellow data scientists to run their NLP algorithms and Kernels to find and explore the heart failure predictions etc. by them selves.

## ****Content****
The data contains complete history of heart patients (so data scientists from different parts of the world can work with it). The dataset is collected from Pakistan, Faisalabad hospital named institute of cardiology.

****### About this dataset****
- Age : Age of the patient
- Age Group: Such as 21-30 and 31-40 are grouped
- Gender : Sex of the patient
- Locality: Rural or Urban
- Marital status: Married or unmarried   
- Smoking: yes/no
- Depression: yes/no
- Mortality: Died=  0 and Alive= 1
- Follow.Up: Number of visiting time                 
- cp : Chest Pain type chest pain type
- Diabetes: 0 means yes and 1 means no 
- chol : cholestoral in mg/dl fetched via BMI sensor
- fbs : (fasting blood sugar &gt; 120 mg/dl) (1 = true; 0 = false)
- trestbps : resting blood pressure (in mm Hg)
- rest_ecg : resting electrocardiographic results
             Value 0: normal
             Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of &gt; 0.05 mV)
             Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria
- thalach : maximum heart rate achieved
- PLATELET_COUNT
- Hemoglobin
and much more, see dataset



## **Inspiration**
Here are some ideas to explore:
1. Create a model for predicting mortality caused by Heart Failure.
2. Can we compare the mortality rate with other famous old datasets and see the correlation
3. Can we compare the genders and ages with other datasets of multiple cities of Pakistan  to see the resemblance
4. Can we compare the genders and ages with other datasets of multiple countries  to see the resemblance

Any other ideas you can think of

I am looking forward to see your work and ideas and will keep adding more ideas to explore

Welcome on board to learn the finest text on earth with Data Sciences and Machine Learning!",.csv
The Holy Quran,1,the-holy-quran,The Holy Quran.csv,world-bank,"The Quran is divided into Surahs (chapters) and further divided into Ayahs (verses). The translation of the word Ayah is ""Sign [of Allah]"".[1] For a preliminary discussion about the chronological order of chapters, see Surah.[2]


The first surah of the Quran (Surah Al-Fatihah)
Each surah except the ninth (At-Tawba) is preceded by the Tasmiah, phrase: bismi-llāhi r-raḥmāni r-raḥīm (""In the name of Allah, the Most Gracious, the Most Merciful."").[3] Twenty-nine surahs are preceded by Muqatta'at (lit. abbreviated or shortened), unique letter combinations whose meanings are unknown. The first surah in the Quran is Surah al-Fatiha.[4]

Surahs of the Makkah period are more related to themes such as resurrection, judgment, and stories from Judaism and Christianity. Surahs of the Medina period focus more on laws for personal affairs, society, and the state.[5]",.csv
The Home Depot Products Dataset,1,the-home-depot-products-dataset,home_depot_data_1_2021_12.csv,other,"
### About this dataset
The Home Depot Products dataset contains more than 1 million records of products scraped from The Home Depot website. The dataset includes 13 columns such as url, title, images, description, product_id, sku, gtin13, brand, price, currency, availability, uniq_id, and scraped_at. This dataset can be used for research purposes such as online product classification and recommendations

### How to use the dataset
This dataset contains information about products available at The Home Depot. It includes the product name, price, description, and other relevant details. This dataset can be used to research consumer behavior or to develop marketing strategies

### Research Ideas
1. This dataset can be used to create a product catalog for the Home Depot.
2. This dataset can be used to monitor and compare prices of products across different retailers.
3. This dataset can be used to generate customer reviews for products sold by the Home Depot

### Columns


#### home_depot_data_1_2021_12.csv
- **index:** The index of the row
- **url:** The URL of the product
- **title:** The title of the product
- **images:** The images of the product
- **description:** The description of the product
- **product_id:** The product ID
- **sku:** The SKU of the product
- **gtin13:** The GTIN13 of the product
- **brand:** The brand of the product
- **price:** The price of the product
- **currency:** The currency of the product
- **availability:** The availability of the product
- **uniq_id:** The unique ID of the product
- **scraped_at:** The date the product was scraped

### Acknowledgements
If you use this dataset in your research, please credit Crawl Feeds for providing the data

> [Data Source](https://data.world/opensnippets)
",.csv
The Office Dataset,1,the-office-dataset,the_office_series.csv,CC0-1.0,"### Context

The Office is an American Mockumentary sitcom television series that depicts the everyday lives of office employees in the Scranton, Pennsylvania, branch of the fictional Dunder Mifflin Paper Company.

### Content

The dataset consists of 12 columns and 188 rows scrapped from IMDb. 


### Acknowledgements

IMDb : https://www.imdb.com/title/tt0386676/
",.csv
"The Oscar Award, 1927 - 2024",1,the-oscar-award,the_oscar_award.csv,CC0-1.0,"[![forthebadge made-with-python](http://ForTheBadge.com/images/badges/made-with-python.svg)](https://www.python.org/) [![ForTheBadge built-with-love](http://ForTheBadge.com/images/badges/built-with-love.svg)](https://GitHub.com/unanimad/)

---

Please, If you enjoyed this dataset, don't forget to upvote it.

---

### Context

[The Academy Awards](https://en.wikipedia.org/wiki/Academy_Awards), also officially and popularly known as the Oscars, are awards for artistic and technical merit in the film industry. Given annually by the Academy of Motion Picture Arts and Sciences (AMPAS), the awards are an international recognition of excellence in cinematic achievements as assessed by the Academy's voting membership. The various category winners are awarded a copy of a golden statuette, officially called the ""Academy Award of Merit"", although more commonly referred to by its nickname ""Oscar"". The statuette depicts a knight rendered in Art Deco style. 


### Content

This file contains a scrape of The Academy Awards Database, recorded of past Academy Award winners and nominees between 1927 and 2024.

### Acknowledgements

The awards data was scraped from the Official Academy Awards search site; nominees were listed with their name first and film following in some categories, such as Best Actor/Actress, and in the reverse for others.


### Inspiration

1. Do the Academy Awards reflect the diversity of American films or are the #OscarsSoWhite? 
2. Which actor/actress has received the most awards overall or in a single year? 
3. Which film has received the most awards in a ceremony?
4. Which country received the most awards at a ceremony and overall?
5.  Can you predict who will receive the awards next year?

---

Thank you @lopcio for the amazing helpful on fix this dataset missing values through the updates.",.csv
The Ultimate Halloween Candy Power Ranking,1,the-ultimate-halloween-candy-power-ranking,candy-data.csv,other,"# Context

What’s the best (or at least the most popular) Halloween candy? That was the question this dataset was collected to answer. Data was collected by creating a website where participants were shown [presenting two fun-sized candies and asked to click on the one they would prefer to receive](http://walthickey.com/2017/10/18/whats-the-best-halloween-candy/). In total, more than 269 thousand votes were collected from 8,371 different IP addresses.

# Content

`candy-data.csv` includes attributes for each candy along with its ranking. For binary variables, 1 means yes, 0 means no. The data contains the following fields: 

* chocolate: Does it contain chocolate?
* fruity: Is it fruit flavored?
* caramel: Is there caramel in the candy?
* peanutalmondy: Does it contain peanuts, peanut butter or almonds?
* nougat: Does it contain nougat?
* crispedricewafer: Does it contain crisped rice, wafers, or a cookie component?
* hard: Is it a hard candy?
* bar: Is it a candy bar?
* pluribus: Is it one of many candies in a bag or box?
* sugarpercent: The percentile of sugar it falls under within the data set.
* pricepercent: The unit price percentile compared to the rest of the set.
* winpercent: The overall win percentage according to 269,000 matchups.


### Acknowledgements: 

This dataset is Copyright (c) 2014 ESPN Internet Ventures and distributed under an [MIT license](https://github.com/fivethirtyeight/data/blob/master/LICENSE). Check out the analysis and write-up here: [The Ultimate Halloween Candy Power Ranking](http://fivethirtyeight.com/features/the-ultimate-halloween-candy-power-ranking/). Thanks to [Walt Hickey](http://walthickey.com/) for making the data available.

### Inspiration: 

* Which qualities are associated with higher rankings?
* What’s the most popular candy? Least popular?
* Can you recreate the [538 analysis](http://fivethirtyeight.com/features/the-ultimate-halloween-candy-power-ranking/) of this dataset?",.csv
The complete Pokemon dataset,1,the-complete-pokemon-dataset,Pokemon_data.csv,CC0-1.0,"### Context

I am currently learning Data Science concepts so I started my journey by doing some basic data visualisations. While I was looking for datasets online to visualise, I saw a Pokemon dataset. I have been a fan of this franchise since I was 3 and I have played it's every main series games so it was such a delight for me to start with a pokemon dataset as the start of my Data Visualisation work. 

But when I started the analysis of that data, I found that the data had quite a few missing values at places and it had information of only the first seven generation pokemon. This was kinda expected as the datasets were 3 years old and the latest generation was revealed last year. I thought that now is the need to update this data. I had the knowledge of web scraping so nothing was stopping me from doing that.

I scraped the data from pokemondb.net and bulbapedia and it took me two days of creating the logic, debugging and perfecting the code so that I can scrape data. I also included the data of all the mega and all the alternate forms too. This meant iterating through a single page multiple times and accessing the data which is visible only when the button is pressed. Most of my time went in creating this logic. 

Finally, once the file was generated, I did a manual work of checking and changing some names with unsupported symbols and arranged the columns. 

### Content

This dataset contains the names, Pokedex number, their generation, abilities physical stats like height and weight, their typing, their defence multiplier against each type etc. This data not only includes the 890 pokemon but also their mega evolutions, their galarian, alolan as well as their alternate forms. I have also added the columns of is_legendary, is_mythical and is_mega so that you can remove those pokemon by some queries if needed. 

The latest version includes the new Pokemon from Sword and Shield DLC and the alternate forms from Pokemon Legends Arceus. 

Note: The capture_rate, base_happiness and base_egg_steps data for Legends Arceus Pokemon is not available as of now so the values for those columns is NaN.

### Acknowledgements

The data was taken from- 
* https://pokemondb.net/
* https://bulbapedia.bulbagarden.net/wiki/Main_Page
*https://www.serebii.net/


",.csv
The freeCodeCamp 2017 New Coder Survey,1,the-freecodecamp-2017-new-coder-survey,2017-fCC-New-Coders-Survey-Data.csv,DbCL-1.0,"Free Code Camp is an open source community where you learn to code and build projects for nonprofits.

We surveyed more than 20,000 people who started coding within the past 5 years. We reached them through the twitter accounts and email lists of various organizations that help people learn to code.

Our goal was to understand these people's motivations in learning to code, how they're learning to code, their demographics, and their socioeconomic background.

We've written in depth about this dataset here: https://medium.freecodecamp.com/we-asked-20-000-people-who-they-are-and-how-theyre-learning-to-code-fff5d668969",.csv
"Threads, an Instagram app Reviews",1,threads-an-instagram-app-reviews,threads_reviews.csv,Attribution-NoDerivatives 4.0 International (CC BY-ND 4.0),"The Threads, an Instagram App Reviews dataset is a comprehensive collection of user reviews from the Threads mobile app on Google Play Store & App Store, capturing valuable insights and sentiments. The dataset enables the understanding of user satisfaction, evaluation of app performance, and identification of emerging patterns.

###### The way data was collected
Scraping Threads App reviews on Google Play Store & App Store

###### Ideas for using this dataset
- Sentiment analysis
- What makes the application receive 1-star and 5-star

####Note - It was last updated on July 26th 2023",.csv
TikTok User Engagement Data,1,tiktok,tiktok_dataset.csv,CC0-1.0,"TikTok is the leading destination for short-form mobile video. The platform is built to help imaginations thrive. TikTok's mission is to create a place for inclusive, joyful, and authentic content–where people can safely discover, create, and connect.

|**Column name**|**Type**|**Description**|
|---------|----|-----|
|#|int|TikTok assigned number for video with claim/opinion.|
|claim_status|obj|Whether the published video has been identified as an “opinion” or a “claim.” In this dataset, an “opinion” refers to an individual’s or group’s personal belief or thought. A “claim” refers to information that is either unsourced or from an unverified source.|
|video_id|int|Random identifying number assigned to video upon publication on TikTok.|
|video_duration_sec|int|How long the published video is measured in seconds.|
|video_transcription_text|obj|Transcribed text of the words spoken in the published video.|
|verified_status|obj|Indicates the status of the TikTok user who published the video in terms of their verification, either “verified” or “not verified.” |
|author_ban_status|obj|Indicates the status of the TikTok user who published the video in terms of their permissions: “active,” “under scrutiny,” or “banned.” |
|video_view_count|float|The total number of times the published video has been viewed. |
|video_like_count|float|The total number of times the published video has been liked by other users. |
|video_share_count|float|The total number of times the published video has been shared by other users. |
|video_download_count|float|The total number of times the published video has been downloaded by other users. |
|video_comment_count|float|The total number of comments on the published video. |",.csv
TikTok popular songs 2020,1,tiktok-popular-songs-2020,TikTok_songs_2020.csv,CC0-1.0,"This dataset provides all important information that can be needed for further analysis, starting from the basic knowledge such as track name and artist name, ending with the most advance  stuff such as tempo, time_signature etc etc 
",.csv
Tiktok Reviews [DAILY UPDATED],1,tiktok-reviews-daily-updated,tiktok_reviews.csv,Apache 2.0,"The dataset primarily encompasses daily-refreshed reviews and ratings from users of the Tiktok App. Supplementary data, such as the relevancy of the reviews and the dates they were published, is also part of the dataset.",.csv
Tiktok popular songs 2022,1,tiktok-popular-songs-2022,TikTok_songs_2022.csv,CC0-1.0,"This dataset provides all important information that can be needed for further analysis, starting from the basic knowledge such as track name and artist name, ending with the most advance stuff such as tempo, time_signature etc etc
this dataset have been used in my [project](https://github.com/Sveta151/TikTok_impact_on_the_top_charts) ""TikTok impact on top charts""",.csv
Time Series Forecasting with Yahoo Stock Price ,1,time-series-forecasting-with-yahoo-stock-price,yahoo_stock.csv,CC0-1.0,"### Context

Stocks and financial instrument trading is a lucrative proposition. Stock markets across the world facilitate such trades and thus wealth exchanges hands. Stock prices move up and down all the time and having ability to predict its movement has immense potential to make one rich.
Stock price prediction has kept people interested from a long time. There are hypothesis like the Efficient Market Hypothesis, which says that it is almost impossible to beat the market consistently and there are others which disagree with it.

There are a number of known approaches and new research going on to find the magic formula to make you rich. One of the traditional methods is the time series forecasting. Fundamental analysis is another method where numerous performance ratios are analyzed to assess a given stock. On the emerging front, there are neural networks, genetic algorithms, and ensembling techniques. 

Another challenging problem in stock price prediction is **Black Swan Event**,  unpredictable events that cause stock market turbulence. These are events that occur from time to time, are unpredictable and often come with little or no warning. 

*A black swan event is an event that is completely unexpected and cannot be predicted. Unexpected events are generally referred to as black swans when they have significant consequences, though an event with few consequences might also be a black swan event. It may or may not be possible to provide explanations for the occurrence after the fact – but not before. In complex systems, like economies, markets and weather systems, there are often several causes. After such an event, many of the explanations for its occurrence will be overly simplistic.*

#  
#  

 <img src=""https://www.visualcapitalist.com/wp-content/uploads/2020/03/mm3_black_swan_events_shareable.jpg"">
#  
#  
New bleeding age state-of-the-art  deep learning models stock predictions is overcoming such  obstacles e.g. ""Transformer and Time Embeddings"". An objectives are to apply these novel models to forecast stock price. 


### Content

Stock price prediction is the task of forecasting the future value of a given stock. Given the historical daily close price for S&P 500 Index, prepare and compare forecasting solutions. S&P 500 or Standard and Poor's 500 index is an index comprising of 500 stocks from different sectors of US economy and is an indicator of US equities. Other such indices are the Dow 30, NIFTY 50, Nikkei 225, etc.
For the purpose of understanding, we are utilizing S&P500 index, concepts, and knowledge can be applied to other stocks as well.



### Dataset
The historical stock price information is also publicly available. For our current use case, we will utilize the pandas_datareader library to get the required S&P 500 index history using **Yahoo Finance databases**.  We utilize the closing price information from the dataset available though other information such as opening price, adjusted closing price, etc., are also available.
We prepare a utility function get_raw_data() to extract required information in a pandas dataframe. The function takes index ticker name as input. For S&P 500 index, the ticker name is ^GSPC. The following snippet uses the utility function to get the required data.(See [Simple LSTM Regression](https://www.kaggle.com/arashnic/simple-lstm-regression))

**Features and Terminology:**
In stock trading, the high and low refer to the maximum and minimum prices in a given time period. Open and close are the prices at which a stock began and ended trading in the same period. Volume is the total amount of trading activity. Adjusted values factor in corporate actions such as dividends, stock splits, and new share issuance.

 

### Starter Kernel(s)
- [Simple LSTM Regression](https://www.kaggle.com/arashnic/simple-lstm-regression)

### Acknowledgements

Mining and updating of this dateset will depend upon **Yahoo Finance** .


### Inspiration

Sort of variation of sequence modeling and bleeding age e.g. attention can be applied for research and forecasting

### Some Readings
- [Applications of deep learning in stock market prediction: recent progress](https://arxiv.org/pdf/2003.01859.pdf)
- [Stock predictions with state-of-the-art Transformer and Time Embeddings](https://towardsdatascience.com/stock-predictions-with-state-of-the-art-transformer-and-time-embeddings-3a4485237de6)
- https://arxiv.org/pdf/1712.02136.pdf
- https://catanacapital.com/blog/unpredictable-black-swan-event-stock-market/
- https://par.nsf.gov/servlets/purl/10149715
- https://arxiv.org/pdf/1712.02136.pdf

#  <hr style=""border: 2px solid gray""> 
#### *If you download and find the data useful your **upvote** is an explicit feedback for future works*
",.csv
Time Series starter dataset,1,time-series-starter-dataset,Month_Value_1.csv,CC0-1.0,"### Context

Machine learning can be applied to time series datasets.


### Content

A problem when getting started in time series forecasting with machine learning is finding good quality standard datasets on which to practice.


### Acknowledgements

Almost every data scientist will encounter time series in their work and being able to effectively deal with such data is an important skill in the data science toolbox.Almost every data scientist will encounter time series in their work and being able to effectively deal with such data is an important skill in the data science toolbox.


### Inspiration

Let’s begin from basics.",.csv
Titanic Data set,1,titanic-data-set,train.csv,Apache 2.0,"Detail Description:

The Titanic dataset offers a comprehensive glimpse into the passengers aboard the ill-fated RMS Titanic, which famously sank on its maiden voyage in April 1912 after colliding with an iceberg. This dataset contains a wealth of information about individual passengers, including demographics, ticket class, cabin information, family relationships, fare details, and most notably, survival outcomes.

Key attributes within the dataset include:

1. **Passenger Class (Pclass)**: This categorical variable indicates the ticket class of each passenger, ranging from 1st class (wealthiest) to 3rd class (lower socioeconomic status).

2. **Name**: The names of passengers, providing insight into their identities.

3. **Sex**: Gender of passengers, categorized as male or female.

4. **Age**: Age of passengers, providing information about the demographic composition of the Titanic's passengers.

5. **SibSp**: Number of siblings/spouses aboard the Titanic, offering insight into family relationships.

6. **Parch**: Number of parents/children aboard the Titanic, indicating family size and composition.

7. **Ticket**: Ticket number, providing additional information about passenger accommodations and fare details.

8. **Fare**: Fare paid by each passenger, which can be indicative of their ticket class and economic status.

9. **Cabin**: Cabin number or location, offering insights into passenger accommodations.

10. **Embarked**: Port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton), providing information about passengers' embarkation points.

11. **Survived**: This binary variable indicates whether a passenger survived the disaster (1) or not (0), serving as the primary outcome variable for analyses.

Researchers and data analysts frequently utilize the Titanic dataset for various purposes, including:

- Exploratory data analysis to understand the demographic composition of passengers and their survival outcomes.
- Predictive modeling to develop algorithms that predict the likelihood of survival based on passenger characteristics.
- Feature engineering to derive new variables that may enhance predictive accuracy.
- Hypothesis testing to investigate factors associated with survival rates, such as passenger class, gender, age, and family size.

Overall, the Titanic dataset serves as a valuable resource for understanding historical events, exploring data analysis techniques, and teaching machine learning concepts. Its accessibility and rich contextual information make it a popular choice for both educational and research purposes within the data science community.",.csv
Titanic: all ones csv file,1,gender-submisson,All 1.csv,CC0-1.0,"### Context
The score of the csv file is 0.37799. This is the number to beat, so make sure you don't have a number below this.

### Content
This is the titanic csv file, but everyone survives.

I also have another csv file: https://www.kaggle.com/brendan45774/test-file
This may help you on your mission to get a perfect score.",.csv
TitanicSurvivedDatasets,1,titanicsurviveddatasets,titanic.csv,MIT,"The data set contains information about passengers on the Titanic ship disaster in 1912. This information includes features such as the passengers' gender, age, class (1st, 2nd, or 3rd class), ticket prices, and the ports they embarked from. Additionally, information is provided on whether each passenger survived the disaster or not. This data set is used to train and test machine learning models. The aim of the model is to predict whether a passenger will survive or not based on the given features.
Variables in the Data Set:

PassengerId: Unique identifier for each passenger.

Survived: Survival status (0 = No; 1 = Yes).

Pclass: Passenger class (1 = 1st; 2 = 2nd; 3 = 3rd).

Name: Name of the passenger.

Sex: Sex of the passenger (male or female).

Age: Age of the passenger.

SibSp: Number of siblings/spouses aboard.

Parch: Number of parents/children aboard.

Ticket: Ticket number.

Fare: Passenger fare.

Cabin: Cabin number.

Embarked: Port of embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)",.csv
Tokyo 2020 Olympics Medals ,1,2021-olympics-medals-in-tokyo,Tokyo Medals 2021.csv,other,"The 2020 Summer Olympics , officially the Games of the XXXII Olympiad and branded as Tokyo 2020, is an ongoing international multi-sport event being held from 23 July to 8 August 2021 in Tokyo, Japan, with some preliminary events that began on 21 July.

Data is collected from [here](https://olympics.com/tokyo-2020/olympic-games/en/results/all-sports/medal-standings.htm) and updated at 8 August.",.csv
Top 10 AI Companies - Stocks,1,ai-stocks,top_10_ai_stocks.csv,CC0-1.0,"This dataset represent stock value of top 10 AI companies from 1990 until today.  You will notice that many of those companies didn't exist in 20th century.
However, today they represent the most important tech companies in the world, and their market capitalization is enormous. ",.csv
Top 100 Badminton Players,1,top-100-badminton-players,flashscore.csv,CC0-1.0,This dataset contains data related to top 100 badminton players on the basis of points and tournaments played. The data has been recoded by Badminton World Federation. ,.csv
Top 100 Cities Weather Dataset,1,top-100-cities-weather-dataset,top100cities_weather_data.csv,Apache 2.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F14839888%2F368cab89748d790e7462eee8ae40ecde%2FAdd%20a%20heading%20(3).png?generation=1714429352210149&alt=media)

**__Importance of Weather Data:__**
Weather data plays a crucial role in various fields such as agriculture, transportation, energy, and tourism. Farmers rely on weather forecasts to plan planting and harvesting schedules. Airlines and shipping companies use weather data to optimize routes and ensure passenger safety. Energy companies use weather forecasts to predict demand and manage resources efficiently. Additionally, weather data is essential for tourism, as travelers often base their destination choices and activities on current and forecasted weather conditions. Overall, accurate and reliable weather data is vital for making informed decisions and mitigating risks in various industries and everyday life.

**__Background:__**
My friend, a travel agent, often faces challenges when presenting travel destinations to clients. One common question from clients is about the weather conditions of their desired destinations. To address this, my friend asked me to collect data on the top 100 tourist destination cities worldwide for April 28th, 2024. This data will help him provide better presentations to his clients by offering detailed insights into the weather conditions of these cities on that specific date. With this information readily available, my friend can enhance his client consultations and ensure that travelers have a more enjoyable and hassle-free experience during their trips.

**__Introduction of Dataset:__**
This dataset provides temperature data for the top 100 cities worldwide as of April 28th, 2024. It consists of seven columns, each offering specific information to understand the weather conditions in different cities. The dataset includes the following columns:

**__1. City:__**
The name of the city in English language. This column provides the official or commonly used name of each city. City names are essential for identifying the geographical location associated with the weather data.

**__2. Temperature (°C):__**
The temperature recorded for each city on April 28th, 2024. Temperature is measured in degrees Celsius (°C) and represents the average atmospheric temperature at the specified location on the given date. It is an essential parameter in weather analysis, indicating the warmth or coldness of the air.

**__3.Wind Speed (m/s):__**
The average wind speed measured at each location in meters per second (m/s). Wind speed is a measure of the movement of air molecules and is an important factor in weather prediction and analysis.

**__4. Latitude (°):__**
The latitude coordinates of each city, expressed in degrees. Latitude measures the north-south position of a location on the Earth's surface relative to the equator. Positive values represent locations in the northern hemisphere, while negative values represent locations in the southern hemisphere. Latitude ranges from -90° (South Pole) to +90° (North Pole), with 0° at the equator.

**__5. Longitude (°):__**
The longitude coordinates of each city, expressed in degrees. Longitude measures the east-west position of a location on the Earth's surface relative to the Prime Meridian. Positive values represent locations east of the Prime Meridian, while negative values represent locations west of it. Longitude ranges from -180° (West) to +180° (East), with 0° at the Prime Meridian.

**__6. Description:__** 
This column provides details about the prevailing weather conditions in each city on April 28th, 2024. It includes descriptions such as clear sky, scattered clouds, broken clouds, overcast clouds, and few clouds, indicating the level of cloud cover and sky visibility at the time of observation.

**__7. Country:__**
 This column contains the name of the country to which each city belongs. It provides information about the city with its respective country.


 ",.csv
Top 100 Songs on Billboard,1,top-100-songs-on-billboard,billboard.csv,CC0-1.0,"
The ""Top 100 Songs on Billboard"" dataset compiles the most popular and influential songs of a given period, reflecting the dynamic landscape of contemporary music. Curated by Billboard, a leading authority in music charts, this dataset provides valuable insights into trends, artists' impact, and audience preferences across various genres and demographics.",.csv
Top 100 songs ,1,top-100-songs,top 100 streamed_songs.csv,CC0-1.0,"I wanted to make a recommendation system and used these features as my dependent variables and I thought this would be a good idea to share this dataset

The whole data extracted is from the Spotify API


The following data is of the year 2021

Ps. (For all time data you can check my dataset :- https://www.kaggle.com/datasets/amaanansari09/most-streamed-songs-all-time)",.csv
Top 1000 Highest Grossing Movies,1,top-1000-highest-grossing-movies,Highest Holywood Grossing Movies.csv,CC0-1.0,"Context
This dataset contains information about the top 1000 highest grossing holywood films. It is up to date as of 25th September 2023.

Acknowledgements
This data has been scraped from multiple site and has been added together for performing various data operations. The data has been taken from IMDB, rotten tomatoes and many other sites.

UPDATE:
The original data contained information about movies and some additional have been added by me. 'None' refers to datapoints that I could not scrape. If you wish to contribute to this dataset. Do contact me :)",.csv
Top 1000 Highest Grossing Movies Of All Time,1,top-1000-highest-grossing-movies-of-all-time,Top_1000_Highest_Grossing_Movies_Of_All_Time.csv,CC0-1.0,"This Dataset displays only the top 1000 highest grossing feature films of all time as of `September 5, 2022`.  It is in the same order as displayed on the Box Office Mojo website. **[SOURCE](https://www.imdb.com/list/ls098063263/)**.

**DATA DICTIONARY:**
`Movie Title`: The name of the movie.
`Year of Release`: The year the movie was released.
`Genre`: Categories where the movie belongs.
`Movie Rating`: Ratings given by IMDb registered users (on a scale of 1 to 10)
`Duration`: Movie running time in minutes.
`Gross`: Gross earnings in U.S. dollars.
`Worldwide LT Gross`: Worldwide Lifetime Gross (International + Domestic totals.
`Metascore`: Weighted average of many reviews coming from reputed critics (on a scale of 0 to 100)
`Votes`: Number of votes cast by IMDb registered users.
`Logline`: A one or two sentence summary of the film.
",.csv
Top 10000 Books - Good Reads Dataset,1,top-10000-books-good-reads-dataset,goodreads_cleaned.csv,MIT,"Delve into the literary world with our meticulously curated dataset featuring the top 10,000 books sourced from Goodreads, a leading platform renowned for its extensive collection of reader reviews and ratings. This dataset offers a comprehensive glimpse into the world of literature, showcasing titles that have garnered significant acclaim and admiration from readers worldwide.",.csv
Top 10000 Popular Movies Dataset,1,top-10000-popular-movies,Top_10000_Movies.csv,CC0-1.0,"### Context

Recommendation systems are used everywhere now a days. Netflix , Amazon Prime , YouTube , Online shopping sites etc. Datasets like this are great way to start working on Recommendation system. 
The Dataset was created from the official API provied by TMDB[](https://www.themoviedb.org/)

### Content

What's inside is more than just rows and columns. This is the dataset for 10000 Popular movies based on the TMDB ratings. Ideal database to start off with Recommendation algorithms.


| Column Name | Description |
| --- | --- |
| id | Every movie has its unique ID. |
| original_language | There are total 44 languages present in this column. Total 7771 movies with 'English' as original language. Values in this column are ISO 639-1 codes of languages. I.e 'en' for 'English' , 'hi' for 'Hindi' etc. |
| original_title | Title of the movie. |
| popularity | Popularity of movie. Bigger the number , higher the popularity. |
| release_date | Release date of the movie. If release date is not present for any movie , then that movie is not released yet. |
| vote_average | Average of rating/vote for the movie. |
| vote_count | Number of ratings/vote recorded for the movie. |
| genre | Genre of the movie. |
| overview | Brief description of movie in string format. |
| revenue | Revenue of Movie |
| runtime | Runtime of movie in minutes. |
| tagline | Tagline of the movie |



# Origin

The code which was used to extract this dataset can be found here - [Creating Dataset of top 10000 popular movies](https://www.kaggle.com/omkarborikar/creating-dataset-of-top-10000-movies)

# Update

Added Overview , Revenue , Runtime, tagline column for each movie.
",.csv
Top 10000 Songs on Spotify 1960-Now,1,top-10000-spotify-songs-1960-now,top_10000_1960-now.csv,CC0-1.0,"The ""Top 10000 Spotify Songs - ARIA and Billboard Charts"" is a comprehensive collection of 10,000 of the most popular songs that have dominated the music scene from 1960 to the present day. This dataset was curated based on rankings from both the ARIA (Australian Recording Industry Association) and Billboard charts, ensuring a diverse representation of songs that have achieved immense commercial success and cultural significance.

The dataset encompasses various music genres and showcases the evolution of musical trends over the years, providing valuable insights into the ever-changing landscape of popular music. It includes tracks from iconic artists and bands, representing a mix of timeless classics and contemporary hits that have left a lasting impact on music lovers worldwide.

Researchers, music enthusiasts, and data analysts can use this dataset for a wide range of applications, such as analyzing trends in music popularity, studying the influence of specific artists or albums, exploring genre shifts, and building recommendation systems based on historical music preferences.",.csv
Top 10000 popular Movies TMDB,1,top-10000-popular-movies-tmdb-05-2023,top_1000_popular_movies_tmdb.csv,CC0-1.0,"This is a collection of metadata about the top 10,000 most popular movies on **The Movie Database (TMDB)** . The dataset includes information such as movie titles, release dates, runtime, genres, production companies, budget, and revenue. This data is collected from TMDB's public [API](https://developer.themoviedb.org/docs) using a notebook available [here](https://www.kaggle.com/code/ursmaheshj/creating-dataset-using-tmdb-api/notebook). 

#### Little bit about [TMDB](https://www.themoviedb.org/)
TMDB (The Movie Database) is a popular online database and community platform that provides a vast collection of information about movies, TV shows, and other related content. TMDB allows users to browse and search for movies and TV shows, view information such as cast, crew, synopsis, and ratings, and also contribute to the community by adding their own reviews, ratings, and other content.

#### Purpose
The dataset is intended for use by data analysts, researchers, and developers who are interested in studying or analyzing the popularity and characteristics of movies. The dataset can be used to perform a wide range of analyses, such as exploring trends in movie genres over time, identifying patterns in movie budgets and revenues, and analyzing the impact of different attributes on a movie's popularity.

####Attributes
- **id**: Unique identifier assigned to each movie in the TMDB database.
- **title**: Title of the movie.
- **release_date**: Date on which the movie was released.
- **genres**: List of genres associated with the movie.
- **original_language**: Language in which the movie was originally produced.
- **vote_average**: Average rating given to the movie by TMDB users.
- **vote_count**: Number of votes cast for the movie on TMDB.
- **popularity**: Popularity score assigned to the movie by TMDB based on user engagement.
- **overview**: Brief description or synopsis of the movie.
- **budget**: Estimated budget for producing the movie in USD.
- **production_companies**: List of production companies involved in making the movie.
- **revenue**: Total revenue generated by the movie in USD.
- **runtime**: Total runtime of the movie in minutes.
- **tagline**: Short, memorable phrase associated with the movie, often used in promotional material.

#### [Dataset Creation](https://www.kaggle.com/code/ursmaheshj/creating-dataset-using-tmdb-api/notebook)
The dataset mentioned has been created by fetching raw data from TMDB's public API, and then cleaning and preprocessing the data to improve its quality and make it easier to work with. The cleaning process has been done using a notebook available [here](https://www.kaggle.com/code/ursmaheshj/creating-dataset-using-tmdb-api/notebook), which outlines the steps taken to transform the raw data into a more usable format.",.csv
Top 15 Indian States Petrol Prices (2017-2022) ⛽📈,1,top-15-indian-states-petrol-prices-2017-2022,petrol_price.csv,CC0-1.0,"This dataset provides a comprehensive overview of petrol prices across the top 15 states in India from the year 2017 to 2022. The dataset is meticulously curated to offer valuable insights into the fluctuations and trends in petrol pricing over the last five years.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F13571604%2Fec233bfc65fb81fc2b6cca7cea4f9ccf%2FScreenshot%202024-01-07%20151817.png?generation=1704620957502228&alt=media)
",.csv
Top 281 Michelin-Starred Restaurants Dataset,1,top-281-michelin-starred-restaurants-dataset,Untitled spreadsheet - Sheet1.csv,Apache 2.0,"Explore the world of culinary excellence with the ""Top 281 Michelin-Starred Restaurants Dataset."" This dataset presents a curated collection of the finest dining establishments recognized by the prestigious Michelin Guide, showcasing the pinnacle of gastronomic achievement across the globe. Discover renowned restaurants renowned for their exceptional cuisine, impeccable service, and memorable dining experiences. Whether you're a food enthusiast, a connoisseur, or a researcher in the hospitality industry, this dataset provides valuable insights into the world's top dining destinations.",.csv
Top 2k IMDB  TV Shows,1,top-2k-tv-shows,imdb_top_2000_TV_Shows.csv,other,"This dataset is scraped from [IMDB's official website](https://www.imdb.com/list/ls063619597/). It may be used for regression, classification, clustering, designing recommendation systems, etc.
It has 6 columns containing the following data:

1. The name of the TV show
2. The Airdate
3. The running time of the show (in minutes)
4. It's IMDB Rating
5. The number of votes it got
6. The Genre of the TV show",.csv
Top 32 Powerlifters,1,top-32-powerlifters,openpowerlifting.csv,CC0-1.0,This dataset contains data related to the top 32 powerlifters along with their performances in three kinds of competitions. They are divided into different categories according to their bodyweight,.csv
Top 5 European football leagues teams stats,1,big-5-european-football-leagues-stats,Big 5 European football leagues teams stats.csv,CC-BY-NC-SA-4.0,"### Context
This Dataset contains the data of top 5 European football leagues from 2010/11 season up to 2020/2021.

### Content

The columns contains stats of teams season by season and can be used to analyze performance of teams over the years.It consists of name of the team/club,games played,number of wins,number of losses,number of draws,points accumulated and other relevant football stats.


### Acknowledgements
Citation: Jordi Grau Escolano, & Albert Geli Taberner. (2021). Big 5 European football leagues: team and player stats [Data set]. Zenodo. https://doi.org/10.5281/zenodo.5651722

### Inspiration
I love watching football hence I was inspired to find a dataset related to football

### What can this dataset be used for?
It can be used for analyzing the performance of a team over the years,predicting the points of a team and other column labels,number of top 4 finishes and number of times the team finished 1st(rank=1),
total points accumlated over all seasons,team with highest points over all the seasons etc.
It can also be used to create visualizations on different columns of the dataset",.csv
Top 50 Bestselling Novels 2009-2020 of Amazon,1,amazons-top-50-bestselling-novels-20092020,AmazonBooks - Sheet1.csv,CC0-1.0,This file contains data on top 50 bestselling novels on Amazon each year from 2009 to 2020. The data is collected from amazon.com website and Kaggle. The inspiration behind it was Amazon top-selling books 2009-2019. I thought of updating it to recent. Both CSV and excel formats of the dataset are present for ease.,.csv
Top 50 Fast-Food Chains in USA,1,top-50-fastfood-chains-in-usa,Top 50 Fast-Food Chains in USA.csv,other,"### Context

Fast food is a type of mass-produced food designed for commercial resale, with a strong priority placed on speed of service. It is a commercial term, limited to food sold in a restaurant or store with frozen, preheated, or precooked ingredients and served in packaging for take-out/take-away. Fast food was created as a commercial strategy to accommodate large numbers of busy commuters, travelers, and wage workers. In 2018, the fast food industry was worth an estimated $570 billion globally.

The fastest form of ""fast food"" consists of pre-cooked meals which reduce waiting periods to mere seconds. Other fast food outlets, primarily hamburger outlets such as McDonald's, use mass-produced, pre-prepared ingredients (bagged buns and condiments, frozen beef patties, vegetables that are pre-washed, pre-sliced, or both; etc.) and cook the meat and french fries fresh, before assembling ""to order"".

Fast food restaurants are traditionally distinguished by the drive-through. Outlets may be stands or kiosks, which may provide no shelter or seating, or fast food restaurants (also known as quick service restaurants). Franchise operations that are part of restaurant chains have standardized foodstuffs shipped to each restaurant from central locations.

### Content

This dataset contains diverse details regarding the leading 50 fast-food chains in the USA for the year 2021. The primary attributes of this dataset include fast-food chains, U.S. systemwide sales (in millions of U.S. dollars), average sales per unit (in thousands of U.S. dollars), franchised stores, company stores, total units in 2021, and the overall change in units from 2020. It's worth noting that certain values have been estimated by QSR.

### Dataset Glossary (Column-wise)

* <b>Fast-Food Chains</b> - Name of the Fast-Food Chain
* <b>U.S. Systemwide Sales (Millions - U.S Dollars)</b> - Systemwide Sales in USA (Millions - U.S Dollars)
* <b>Average Sales per Unit (Thousands - U.S Dollars)</b> - Average Sales per Unit (Thousands - U.S Dollars)
* <b>Franchised Stores</b> - Number of Franchised Stores
* <b>Company Stores</b> - Number of Company Stores
* <b>2021 Total Units</b> - Number of Total Units in 2021
* <b>Total Change in Units from 2020</b> - Number of Total Changes from Previous Year (2020)

### Structure of the Dataset

![](https://i.imgur.com/fA7GIyc.png)

### Acknowledgement

This Dataset is created from <b>[QSR Magazine](https://www.qsrmagazine.com/)</b>. If you want to learn more, you can visit the above-mentioned Website.

Cover Photo by: <a href=""https://www.freepik.com/free-vector/fastfood-set-with-happy-face_26353582.htm#query=fast%20food&position=49&from_view=search&track=sph"">Image by brgfx</a> on Freepik

Thumbnail Photo by: <a href=""https://www.flaticon.com/free-icons/burger"">Burger icons created by Freepik - Flaticon</a>",.csv
Top 50 Sitcoms,1,top-50-sitcoms,sitcoms.csv,Apache 2.0,"Collection of most famous TV shows of all times,
 Sort by Number of Votes - Most Rated Movies and TV Shows tagged with keywords ""sitcom"", ""sitcom-comedy""

Please upvote if you download and use the dataset. Thanks",.csv
Top 50 Spotify Songs - 2019,1,top50spotify2019,top50.csv,other,"- Check the data extracted by **year**: https://www.kaggle.com/leonardopena/top-spotify-songs-from-20102019-by-year
- And by **country**: https://www.kaggle.com/leonardopena/top-50-spotify-songs-by-each-country

### Context

The top 50 most listened songs in the world by spotify. This dataset has several variables about the songs.

### Content
50 songs
13 variables
Data were stracted from: http://organizeyourmusic.playlistmachinery.com/


### Inspiration

What can we know about the genre? 
What is the mean of minutes that a top music has?",.csv
Top 50 Spotify songs BY EACH COUNTRY,1,top-50-spotify-songs-by-each-country,top50contry.csv,other,"##Context
The top songs BY COUNTRY by spotify. This dataset has several variables about the songs and is based on Billboard. The extraction was done at Christmas time, so the most played songs should be related to Christmas

##Content
There are the most popular songs by country and 13 variables to be explored. Data were stracted from: http://organizeyourmusic.playlistmachinery.com/

## Inspiration
What can we know about the genre? What is the mean of minutes that a top music has? And what about the cenario by country?",.csv
Top 50 stocks FY23-24,1,top-50-stocks-fy23-24,moneyworks4me.csv,CC0-1.0,"The data was gathered from various sources and after proper summarization of all the data, the file has been presented. It mainly focuses on various companies which had their names in the first 50 according to the prices of their stocks in India for the financial year 23-24",.csv
Top 500 Indian Cities,1,top-500-indian-cities,cities_r2.csv,CC0-1.0,"# Context 

I created this data set merging  **the census 2011 of Indian Cities with Population more than 1 Lac** and **City wise number of Graduates from the Census 2011**, to create a visualization of where the future cities of India stands today, I will try to add more columns [ fertility rate, religion distribution, health standards, number of schools, Mortality rate ] in the future, hope people will contribute.


# Content
![enter image description here][1]

![enter image description here][2]

Data of 500 Cities with population more than 1 Lac by Census 2011

	'name_of_city'					: Name of the City 
	'state_code' 					: State Code of the City
	'state_name' 					: State Name of the City
	'dist_code'						: District Code where the city belongs ( 99 means multiple district ) 
	'population_total' 				: Total Population
	'population_male' 				: Male Population 
	'population_female' 			: Female Population
	'0-6_population_total' 			: 0-6 Age Total Population
	'0-6_population_male' 			: 0-6 Age Male Population
	'0-6_population_female' 		: 0-6 Age Female Population
	'literates_total' 				: Total Literates
	'literates_male' 				: Male Literates
	'literates_female' 				: Female Literates 
	'sex_ratio' 					: Sex Ratio 
	'child_sex_ratio' 				: Sex ratio in 0-6
	'effective_literacy_rate_total' : Literacy rate over Age 7 
	'effective_literacy_rate_male' 	: Male Literacy rate over Age 7 
	'effective_literacy_rate_female': Female Literacy rate over Age 7 
	'location' 						: Lat,Lng
	'total_graduates' 				: Total Number of Graduates
	'male_graduates' 				: Male Graduates 
	'female_graduates' 				: Female Graduates
# Acknowledgements

1. Census 2011

http://censusindia.gov.in/2011-prov-results/paper2/data_files/India2/Table_2_PR_Cities_1Lakh_and_Above.xls

2. Google Geocoder for Location Fetching.

3. Graduation Data Census 2011 

http://www.censusindia.gov.in/2011census/C-series/DDWCT-0000C-08.xlsx


# Inspiration

What story do the top 500 cities of India tell to the world?
I wrote a [post][3] in my blog about the dataset . 


  [1]: http://arijitgeek.me/wp-content/uploads/2016/12/indian_cities_population.png
  [2]: http://arijitgeek.me/wp-content/uploads/2016/12/indian_cities_graduates_literacy_rate.png
  [3]: http://arijitgeek.me/index.php/2016/12/17/top-500-indian-cities-with-pandas-and-plotly/",.csv
Top 500 Movies by Production Budget,1,top-500-movies-budget,top-500-movies.csv,CC0-1.0,"These are the top 500 films by production budget, as judged by The Numbers. 

Data was scraped from [this page](https://www.the-numbers.com/movie/budgets/all) and all individual movie pages. Scraping was done in  R using the [`rvest`](https://rvest.tidyverse.org/) package.

Notes:
- Production budgets are not inflation adjusted
- Production budgets and box office numbers are hard to pin down specifically, as noted by The Numbers",.csv
Top 6 Economies in the world by GDP,1,top-6-economies-in-the-world-by-gdp,top_six_economies.csv,world-bank,"### **CONTENT**

This dataset contains data on key indicators of world's top 6 Economies (by GDP) which includes USA, China, Japan, Germany, United Kingdom, India between the time interval of  30 years from 1990 to 2020. Data scraped from World Bank Data website and processed using Python Pandas library. This dataset could be used to do Time Series Analysis and Forecasting.

### **Code notebook:**
 https://deepnote.com/workspace/charan-chandrasekaran-9b7f-9e1375d3-f150-44ca-a9fb-feb08a1e8585/project/Data-extraction-from-World-bank-data-on-Top-6-Economies-2cdf8112-d412-4044-a58e-5e464804e9b6

### **INDICATORS**

1. GDP (current US$)
2. GDP, PPP (current international $)
3. GDP per capita (current US$)
4. GDP growth (annual %)
5. Imports of goods and services (% of GDP)
6. Exports of goods and services (% of GDP)
7. Central government debt, total (% of GDP)
8. Total reserves (includes gold, current US$)
9. Unemployment, total (% of total labor force) (modelled ILO estimate)
10. Inflation, consumer prices (annual %)
11. Personal remittances, received (% of GDP)
12. Population, total
13. Population growth (annual %)
14. Life expectancy at birth, total (years)
15. Poverty headcount ratio at $1.90 a day (2011 PPP) (% of population)

### **SOURCE**
The World Bank : https://data.worldbank.org/country
             ",.csv
Top Active Football Players Data,1,top-active-football-players-data,finalized_data_in_csv.csv,Apache 2.0,"This dataset contains information about the top 380 active football players.
The dataset is collected using a web scraping script I wrote for this website. 
https://en.soccerwiki.org/ 

I excluded players' ratings as I wanted only to gather objectively accurate information (such as height, foot orientation, nationality, and more.)

PS: If you're interested in the Python script I used, email me about it.",.csv
Top Anime (myanimelist),1,top-anime-myanimelist,topAnime.csv,Apache 2.0,"Discover the Exciting World of Anime with MyAnimeList's Top Picks! Explore a diverse range of titles, from thrilling action-packed series to heartwarming slice-of-life tales. Dive into the rich storytelling and captivating characters that have captured the hearts of millions worldwide. Whether you're a seasoned anime enthusiast or just starting your journey, this curated collection is sure to delight and inspire!

### Features:

- **Title:** The title of the anime.
- **Picture URL:** The URL of the anime's cover picture.
- **MyAnimeList URL:**The URL of the anime's page on MyAnimeList.
- **MyAnimeList ID:** The unique ID assigned to the anime on MyAnimeList.
- **Rank:** The ranking of the anime.
- **Score:** The average score given to the anime by users on MyAnimeList.
- **Type:** The type of the anime (e.g., TV series, movie, OVA).
- **Aired On:** The airing dates of the anime.
- **Members:** The number of members who have added the anime to their MyAnimeList lists.",.csv
Top Anime Dataset 2024,1,top-anime-dataset-2024,Top_Anime_data.csv,Apache 2.0,"This dataset offers a comprehensive overview of the top animes of 2024, and is useful for building recommendation systems, visualizing trends in anime popularity and score, predicting scores and popularity, and such.

## Contents

**Update**: Did data sanity so all the features are in proper order now.

The dataset contains 22 features:

- **Score:** The rating or score assigned to each anime title.
- **Popularity:** Measure of how popular each anime is among viewers.
- **Rank:** Ranking of each anime title within the dataset.
- **Members:** The number of members or viewers associated with each anime.
- **Description:** A brief overview or summary of the plot and themes of each anime.
- **Synonyms:** Alternative titles or synonyms used for each anime.
- **Japanese Title:** Original title of the anime in Japanese.
- **English Title:** English-translated title of the anime.
- **Type:** Classification of anime type (e.g., TV series, movie, OVA, etc.).
- **Eps:** Total number of episodes in each anime series.
- **Status:** Current status of the anime (e.g., ongoing, completed, etc.).
- **Aired:** Date range of when the anime was aired.
- **Premiered:** Date when the anime premiered for the first time.
- **Broadcast:** Information about the broadcasting platform or channel.
- **Producers:** Companies or studios involved in producing the anime.
- **Licensors:** Organizations or companies holding the licensing rights for the anime.
- **Studios:** Animation studios responsible for producing the anime.
- **Source:** Original source material for the anime (e.g., manga, novel, original).
- **Genres:** Categories or genres that the anime belongs to.
- **Demographic:** Target demographic audience for the anime (e.g., shounen, shoujo, seinen, josei).
- **Duration:** Duration of each episode or movie.
- **Rating:** Content rating assigned to each anime (e.g., G, PG, PG-13, R).

## Acknowledgements
All of the information in this dataset has been gathered by scraping the [MyAnimeList](https://myanimelist.net/topanime.php) website, and is available under the Creative Commons License.

Cover Photo by: [Playground.ai](https://playground.com/)",.csv
Top Box Office Revenue Data - English Movies,1,top-box-office-revenue-data-english-movies,bomojobrandindices.csv,CC0-1.0,"#Top Box Office Mojo Movie revenue gross

Data Screenscraped from BoxOffice Mojo 

Includes 
1. Top Brand Indices
2. Top Franchises
3. Top 1000 international grossing movies
4. Top 1000 US Grossing Movies
5. Top Genres
 

Info from Wiki

Films generate income from several revenue streams, including theatrical exhibition, home video, television broadcast rights, and merchandising. However, theatrical box office earnings are the primary metric for trade publications in assessing the success of a film, mostly because of the availability of the data compared to sales figures for home video and broadcast rights, but also because of historical practice. Included on the list are charts of the top box-office earners (ranked by both the nominal and real value of their revenue), a chart of high-grossing films by calendar year, a timeline showing the transition of the highest-grossing film record, and a chart of the highest-grossing film franchises and series. All charts are ranked by international theatrical box-office performance where possible, excluding income derived from home video, broadcasting rights, and merchandise.

Traditionally, war films, musicals, and historical dramas have been the most popular genres, but franchise films have been among the best performers of the 21st century. There is strong interest in the superhero genre, with ten films in the Marvel Cinematic Universe featuring among the nominal top-earners. The most successful superhero film, Avengers: Endgame, is also the second-highest-grossing film on the nominal earnings chart, and there are four films in total based on the Avengers comic books charting in the top twenty. Other Marvel Comics adaptations have also had success with the Spider-Man and X-Men properties, while films based on Batman and Superman from DC Comics have generally performed well. Star Wars is also represented in the nominal earnings chart with five films, while the Harry Potter, Jurassic Park and Pirates of the Caribbean franchises feature prominently. Although the nominal earnings chart is dominated by films adapted from pre-existing properties and sequels, it is headed by Avatar, which is an original work. Animated family films have performed consistently well, with Disney films enjoying lucrative re-releases prior to the home-video era. Disney also enjoyed later success with films such as Frozen I and II, Zootopia, and The Lion King (with its computer-animated remake as the highest-grossing animated film), as well as its Pixar brand, of which Incredibles 2, Toy Story 3 and 4, and Finding Dory have been the best performers. Beyond Disney and Pixar animation, the Despicable Me, Shrek, and Ice Age series have met with the most success.

",.csv
Top Games on Google Play Store,1,top-play-store-games,android-games.csv,ODbL-1.0,"This is a dataset of top 100 games of each category of games on Google Play Store along with their ratings and other data like price and number of installs.

Data as of Jun 9, 2021.

[Photo by Garrett Morrow from Pexels](https://www.pexels.com/photo/silver-macbook-beside-black-sony-ps4-dualshock-4-silver-iphone-6-and-round-black-keychain-on-brown-wooden-table-682933/)",.csv
Top Goodreads Books Collection (1980-2023),1,ultimate-book-collection-top-100-books-up-to-2023,goodreads_top100_from1980to2023_final.csv,ODC Attribution License (ODC-By),"**UPVOTE if you find this dataset interesting!!** &lt;3 

Discover the literary treasures of the past four decades through our meticulously curated dataset, the Ultimate Book Collection, showcasing the top 100 books from each year FROM 1980 TO 2023 according to Goodreads ratings. 

**20 columns** are contained in this dataset including:

# Data Overview:
 **ISBN** : ISBN codes of the books.

**Title**: The title of the book, serving as the primary identifier for each literary work.

**Series**: Indicates whether the book is part of a series, with details on the series name.

**Release Number**: Specifies the position of the book within a series, offering insights into its chronological order.

**Publisher**: Publishers of the books.

**Language**: Language in which the books are written.

**Author**: The name of the author or authors associated with the book.

**Description**: A textual overview of the book's plot, providing a glimpse into its narrative.

**Num Pages**: The total number of pages in the book, offering insights into its length.

**Format**: Specifies the physical or digital format of the book, such as paperback, hardcover, or e-book.

**Genres**: he literary genres associated with the book, offering insights into its thematic categorization.

**Publication Date**: The date when the book was first published, providing historical context to its release.

**Rating**: The average rating of the book on Goodreads, reflecting reader assessments.

**Number of Voters**: The count of votes or ratings received by the book on Goodreads, indicating reader engagement.

**Current Readers**: The current number of readers of the book.

**Want to Read**: The number of people interested in reading the book.

**Price**: The price of the book.

**URL**: The URL of the book.

# A Glimpse into Literary Excellence:

The dataset is a curated selection of the most highly regarded books from each year, providing a panoramic view of the literary scene over the past forty years. Each entry has been meticulously chosen based on the ratings and reviews from the Goodreads community, offering readers a chance to explore not only popular bestsellers but also hidden gems that may have slipped under the radar.

# In-Depth Book Information:

Dive deep into each book's profile, gaining access to a wealth of information. Uncover series details, release numbers, and author profiles, allowing for a comprehensive understanding of the context surrounding each literary masterpiece. Whether you are a seasoned bibliophile or a researcher, this dataset provides a valuable resource for exploring the evolution of writing styles, genre preferences, and author contributions.

# Ratings and Reader Engagement:

The dataset includes detailed information on each book's ratings and the number of votes it has garnered on Goodreads. Gain insights into the reader's perspective and engagement, with a breakdown of the average rating and the quantity of votes received. This feature not only serves as a testament to a book's popularity but also offers a dynamic snapshot of the reader's reception over time.

# Versatility for Various Applications:
Ideal for a range of applications, from academic research to personalized book recommendations, the Ultimate Book Collection is a versatile dataset. Researchers can analyze trends in literary preferences, track the evolution of genres, and explore patterns in reader engagement. For book enthusiasts, it serves as a treasure trove, offering a curated list for diverse reading experiences.


# Conclusion:

The Ultimate Book Collection invites you on a literary journey that transcends time and genre. With meticulous curation and a focus on reader engagement, this dataset stands as a testament to the enduring power of storytelling. Explore, analyze, and unlock the magic of literature with the top 100 books from each year, a collection that encapsulates the essence of literary excellence from 1980 to 2023.",.csv
Top Grossing Movies Dataset,1,top-grossing-movies-dataset,Top_Highest_Openings.csv,Apache 2.0,"Phewww…

This is the 1st dataset that I've uploaded on Kaggle. I know there might be some ups and downs but yeah this is my 1st time. So I am pretty much proud of myself. No Bragging. Someone once said, **""If you don't blow the trumpet of your success no one else will.""**
 
I have been wandering around on the internet about getting the movie dataset, but it was a cumbersome task. I have decided to scrape this data and here it is now after a 2-midnight struggle. I am a newbie in this vast data science field and a little help giving bronze, silver, or gold medals would be kind of you. Although I am unaware of how this works or how to get this medal :)

The dataset contains information on the top-grossing movies at the box office, including their release dates, opening weekend earnings, total gross earnings, percentage of the total gross, number of theaters they were shown in, average earnings per theater, and the distributor.

From superhero epics like ""Avengers: Endgame"" to iconic franchises such as ""Star Wars"" and ""Harry Potter,"" the dataset provides a comprehensive overview of the commercial success of major cinematic releases over the years. Additionally, it features notable entries like Jurassic World, The Hunger Games, Frozen II, and Minions reflecting the diverse landscape of hollywood cinema.

# Columns:
- **Release**:  The title of the movie.
- **Opening**: The amount of money the movie earned during its opening weekend at the box office.
- **Total Gross**:  The total earnings of the movie throughout its theatrical run.
- **% of Total**: The percentage of the total gross earnings represented by the opening weekend earnings.
- **Theaters**: The total number of theaters where the movie was screened during its release.
- **Average**: The average earnings per theater for the movie during its opening weekend.
- **Date**: The date when the movie was officially released in theaters.
- **Distributor**: The company responsible for distributing the movie to theaters.

## Insights that can be drawn from the dataset:
- To predict box office revenue based on various features like budget, release date, distributor, etc.
- Analyze which distributors tend to dominate the top-grossing charts over different periods. Are action movies consistently popular, or do other distributors occasionally take the lead?
- To segment movies into groups based on their box office performance.",.csv
Top Hits Spotify from 2000-2019,1,top-hits-spotify-from-20002019,songs_normalize.csv,other,"# **Context**

This dataset contains audio statistics of the top 2000 tracks on Spotify from 2000-2019. The data contains about 18 columns each describing the track and it's qualities.

#**Content**

- artist: Name of the Artist.
- song: Name of the Track.
- duration_ms: Duration of the track in milliseconds.
- explicit: The lyrics or content of a song or a music video contain one or more of the criteria which could be considered offensive or unsuitable for children.
- year: Release Year of the track.
- popularity: The higher the value the more popular the song is.
- danceability: Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable.
- energy: Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. 
- key: The key the track is in. Integers map to pitches using standard Pitch Class notation. E.g. 0 = C, 1 = C♯/D♭, 2 = D, and so on. If no key was detected, the value is -1.
- loudness: The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typically range between -60 and 0 db.
- mode: Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0. 
- speechiness: Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks.
- acousticness: A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic.
- instrumentalness: Predicts whether a track contains no vocals. ""Ooh"" and ""aah"" sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly ""vocal"". The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0.
- liveness: Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live.
- valence: A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).
- tempo: The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration.
- genre: Genre of the track.",.csv
Top Instagram Influencers Data (Cleaned) ,1,top-instagram-influencers-data-cleaned,top_insta_influencers_data.csv,CC0-1.0,"Instagram is an American photo and video sharing social networking service founded in 2010 by Kevin Systrom and Mike Krieger, and later acquired by Facebook Inc.. The app allows users to upload media that can be edited with filters and organized by hashtags and geographical tagging. Posts can be shared publicly or with preapproved followers. Users can browse other users' content by tag and location, view trending content, like photos, and follow other users to add their content to a personal feed. 

Instagram network is very much used to influence people (the users followers) in a particular way for a specific issue - which can impact the order in some ways. ",.csv
Top Kaggle Notebooks dataset: R,1,top-kaggle-notebooks-dataset-r,Kaggle top 1-500 R Notebook datasets.csv,CC0-1.0,"**Source:** Kaggle
**Content:** Information about R notebooks
**Ranking:** Top 500 (criteria, OUTPUTS: Visualizations)
**Programming Language:** R
**Last Update:** April 23, 2024, at 7:32 AM GMT+6

This dataset can be useful for exploring popular R notebooks on Kaggle, finding inspiration for your own projects, and learning from other data scientists. By looking at the notebooks with high upvotes, views, and medals, you can get an idea of what topics are trending and what makes a successful Kaggle Notebook.",.csv
Top Movie Recommendation Dataset,1,top-movie-recommendation-dataset,movies.csv,CC-BY-SA-4.0,"This dataset consists of user ratings for various movies across different genres. Each row represents a single rating given by a user for a specific movie. The dataset includes the following columns:

- User_ID: A unique identifier for each user.
- Movie_ID: A unique identifier for each movie.
- Movie_Name: The name of the movie that the user has rated.
- Genre: The genre of the movie (e.g., Drama, Comedy, Sci-Fi, Crime, Romance, Fantasy, Animation, Horror, Musical, Action, Adventure, Thriller).
- Rating: The rating given by the user for the movie on a scale of 1 to 5, where 1 is the lowest and 5 is the highest.

The dataset is designed for various analysis tasks, including recommendation systems, genre-based analysis, and user behavior studies related to movie preferences. Each movie name is unique, ensuring no repetition within the dataset.",.csv
Top Movies with High Ratings,1,top-movies-with-high-ratings,movies.csv,other,"Content Overview: 🎬

Hey there! So, this dataset contains some juicy details about a whopping 1925 movies! 🍿 From their IDs to their titles and even their popularity scores, it's all here. Let me give you a sneak peek into what you can find:

id: Each movie gets its own special ID in this dataset.
name: That's the title you'll recognize from the big screen.
original_name: Sometimes, movies have different original titles. We've got those too!
popularity: Curious about how popular a movie is? This score gives you the inside scoop, blending viewer ratings, reviews, and social media buzz. 🌟
first_air_date: When did the magic first hit the screens? Find out here!
vote_average: Wondering how viewers rated the movie on average? This rating spills the beans.
vote_count: Total number of ratings or votes cast for each movie. The more, the merrier, right? 📊
Acknowledgment: 🙌

Kudos to TMDB API for hooking us up with this treasure trove of movie magic! 🎩🔮",.csv
Top Rated Movies,1,top-rated-movies,movies.csv,Apache 2.0,"This dataset presents a curated collection of top-rated movies spanning various genres and eras. Compiled from reputable sources, including IMDb ratings and critical acclaim, this dataset offers a comprehensive overview of some of the most celebrated films in cinematic history. From timeless classics like ""The Shawshank Redemption"" and ""The Godfather"" to modern masterpieces like ""Parasite"" and ""The Dark Knight,"" this dataset encompasses a diverse range of cinematic experiences. Each entry includes essential information such as the movie title, release date, overview, and critical ratings, providing valuable insights for movie enthusiasts, researchers, and data analysts alike. Whether you're exploring the evolution of cinema or seeking inspiration for your next movie night, this dataset offers a rich resource for discovering and appreciating the art of filmmaking.

## **File Structure**
The dataset is provided in a CSV format with the following columns:

| **Column Name** | **Description** |
| --- | --- |
| `id` |A unique identifier for the movie in the dataset|
| `original_language` |The original language in which the movie was filmed|
| `original_title` |The First Original Title of the movie|
| `overview` |A brief summary or synopsis of the movie's plot|
| `popularity` |A measure of the movie's popularity based on various factors such as user engagement, views, and social media activity|
| `release_date` |The date when the movie was officially released|
| `title` |The Title of the movie |
| `vote_average` |The average rating given to the movie by viewers|
| `vote_count` |The total number of votes or ratings received by the movie|





",.csv
Top Rated Movies From TMDB,1,top-rated-movies-from-tmdb,movies_top_rated.csv,MIT,"Description:

The Top-Rated Movies Dataset is a meticulously curated collection of critically acclaimed films sourced from The Movie Database (TMDB) API. Inspired by a passion for cinema and a desire to explore the most revered works in film history, this dataset compiles a selection of movies that have garnered widespread acclaim and admiration from audiences and critics alike.

The dataset originates from the extensive database maintained by TMDB, a comprehensive platform known for its vast collection of movie information, including plot summaries, release dates, ratings, and more. Leveraging the TMDB API, this dataset aggregates key attributes of top-rated movies, offering a snapshot of cinematic excellence across different genres, eras, and cultural landscapes.

The inspiration behind creating this dataset stems from a deep appreciation for the art of filmmaking and a fascination with the stories that captivate audiences worldwide. By assembling a diverse array of top-rated films, this dataset provides a valuable resource for cinephiles, researchers, and data enthusiasts interested in exploring the timeless classics and contemporary masterpieces that define the cinematic landscape.

**- Title:** The name of the movie, serving as its primary identifier.
**- Overview:** A succinct synopsis of the movie's plot, offering insight into its narrative arc and thematic elements.
**- Popularity:**A metric reflecting the movie's relative popularity within the TMDB community, based on user interactions and engagement.
**- Release Date:** The date when the movie was officially released to audiences, marking its debut on the big screen.
**- Vote Average:** The average rating assigned to the movie by TMDB users, providing an indication of its overall reception and perceived quality.
**- Vote Count:** The total number of user votes cast for the movie, indicating the level of engagement and audience feedback it has received.",.csv
Top Songs of the World,1,top-songs-of-the-world,Song.csv,CC0-1.0,"""Top Songs of the World"" is a collection of information about popular songs spanning various decades and genres. The dataset includes details such as the ranking of songs, the respective artists, titles, release years, sales figures, streaming statistics, download counts, radio play metrics, and a numerical rating. This dataset provides insights into the commercial success, digital presence, and overall popularity of each song, offering a comprehensive overview of the music industry's landscape over time. Researchers, analysts, and music enthusiasts can utilize this dataset to explore trends, patterns, and correlations within the context of the featured songs and artists.



",.csv
Top Spotify Songs,1,spotify-music,Popular_Spotify_Songs.csv,CC0-1.0,"**Context**

Dataset contains a comprehensive list of the most famous songs and most streamed songs as listed on Spotify.

**It provides insights into each song's**

- Attributes
- Popularity
- Presence on various music platforms

**The dataset includes information such as track name**

- Artist's name
- Release date
- Spotify playlists and charts
- Streaming statistics
- Apple Music presence
- Deezer presence
- Shazam charts
- Various audio features",.csv
Top Spotify songs from 2010-2019 - BY YEAR,1,top-spotify-songs-from-20102019-by-year,top10s.csv,other,"##Context
The top songs BY YEAR in the world by spotify. This dataset has several variables about the songs and is based on Billboard

##Content
There are the most popular songs in the world by year and 13 variables to be explored. Data were stracted from: http://organizeyourmusic.playlistmachinery.com/

##Inspiration
What can we know about the genre? What is the mean of minutes that a top music has? And what about the cenario by year?",.csv
Top Streamers on Twitch,1,twitchdata,twitchdata-update.csv,CC0-1.0,"### Context

Gaming is a very big industry now. Every year there are millions of Dollars invested in Esports and many new companies want to invest in the Esports scene now. One of bigegest ever deals was when Mixer opened up and brought Ninja and Shroud to their platform from twitch. But Twitch has been a home to streamers since day 1 and  now that Mixer has been shut down, streamers are returning to the platform again.Millions, if not billions, watch twitch streams everyday and i myself like to watch twitch streams. So i put together Top 1000 Streamers from past one year who were streaming on twitch.


### Content

This data consists of different things like number of viewers, number of active viewers, followers gained and many other relevant columns regarding a particular streamer. It has 11 different columns with all the necessary information that is needed.",.csv
Top Women Chess Players ,1,top-women-chess-players,top_women_chess_players_aug_2020.csv,CC0-1.0,"### Context
The [International Chess Federation (FIDE)](https://www.fide.com/) governs international chess competition. FIDE used [Elo rating](https://en.wikipedia.org/wiki/Elo_rating_system) system for calculating the relative skill levels of players.


### Content

The dataset contains details of Top women chess players in the world sorted by their Standard FIDE rating (highest to lowest above 1800 Elo) as updated in August 2020. The data includes all active and inactive players which can be identified by the *Inactive_flag* column. 

*Note: All ratings are updated as published by FIDE in August 2020.*


### Acknowledgements

FIDE: [https://www.fide.com/](https://www.fide.com/)",.csv
Top YouTubers Worldwide,1,top-youtuber-worldwide,Youtuber.csv,CC0-1.0,"This dataset provides detailed metrics and categories for a diverse range of popular YouTube channels. Explore key statistics such as subscriber count, video views, category, and geographical information for each channel. Ideal for analysis and insights into trends within the dynamic landscape of online content creation.",.csv
"Top, New and Hot posts on Reddit in r/datascience",1,top-new-and-hot-posts-on-reddit-in-rdatascience,reddit_datascience_newTopHot_posts.csv,MIT,This dataset was created to understand what questions and discussions happen in the data science subreddit. There could be potential insights or we could understand some difficulties that many people go through. ,.csv
Top_10_Populated_countries_1955to2050_forecasted,1,top-10-populated-countries-1955to2050-forcasted,Top_10_Populated_countries_1955to2050_forcasted.csv,CC-BY-SA-4.0,"this is the data of Top 10 populated countries of world as on 30 March 2024 with history of their population from 1955. it also have forecasted population values of these countries from 2025 to 2050.

here are the detail of columns

1: year:1955 to 2050

2: India: (population in millions)

3: china: (population in millions)

4: USA: (population in millions)

5: Indonesia: (population in millions)

6: Pakistan: (population in millions)

7: Nigeria: (population in millions)

8: Brazil: (population in millions)

9: Bangladesh: (population in millions)

10: Russia: (population in millions)

11: Mexico: (population in millions)

Acknowledgement This Dataset is created from https://www.worldometers.info/. If you want to learn more, you can visit the Website.",.csv
Topsis,1,topsis,Topsis Dataset.csv,MIT," TOPSIS dataset provides a structured representation of criteria, performance scores, weightages, and other relevant information necessary for the TOPSIS method to facilitate decision-making.

TOPSIS calculates the similarity scores for each alternative based on its proximity to the ideal and anti-ideal solutions. The similarity scores are then used to rank the alternatives.

The alternatives are ranked based on their similarity scores. The one with the highest similarity score is considered the most favorable and is chosen as the best alternative.




",.csv
Tortilla prices in Mexico,1,tortilla-prices-in-mexico,tortilla_prices.csv,CC0-1.0,"**Context**

This dataset consists of 270k+ records of tortilla prices from Mexico's national System of Information and Market Integration, which surveys 53 cities, 384 mom-and-pop stores, and 120 retail stores that sell ""tortillas"" throughout Mexico.

Mexico's Bureau of Economic Affairs publishes the information in [this](http://www.economia-sniim.gob.mx/Tortilla.asp) site based on a survey made across the whole country. Still, it is not very friendly so the information since 2007 was downloaded and stored it in one easy-to-use CSV file.

The price on each record consists of the mean prices for all observations made during that day, city, and state. The price shown on the file is for 1 (one) kilogram of tortilla in Mexican peso ($MXN).

If you don't know what a ""tortilla"" is, the article in [Wikipedia](https://en.wikipedia.org/wiki/Corn_tortilla) is a good start to get you up and running.

**Inspiration**

[Tortilla](https://www.ediblegeography.com/fueling-mexico-city-a-grain-revolution/) is one of Mexico's most important foods, it is made almost entirely of milled corn and water, which forms a dough that is cooked for some minutes before being stored and ready to sell. It is similar to Naan bread, commonly known for its use in Indian cuisine, but made out of corn instead of wheat. Tortillas are sold in packages of 1 kilogram, which, depending on their size, can have around 40 to 50 tortillas per kilogram. Mom-and-pop stores can sell tortillas in fractions of kilograms.

This dataset contains information from both mom-and-pop stores (small stores located near living areas dedicated only to selling fresh tortillas) as well as from big retailers (such as Walmart, which sells tortillas in Mexico in almost all of its stores). 

![mom-and-pop-store](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F2718659%2Ff918235c86a0d2183807b041a024f118%2Fmom-and-pop-store.png?generation=1709524219666519&alt=media)

*Example of a typical mom-and-pop store (aka ""Tortillería"") in Mexico*

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F2718659%2F6b16090673e26a509aaebc4e89b207b2%2FWalmart-Tortilleria.jpg?generation=1709524326553327&alt=media)

*Example of a stand selling tortillas in Walmart*

Several interesting facts can be made regarding the price of tortillas in these two types of stores... surprisingly, retail stores sell tortillas way below prices of mom-and-pop stores, while at the same time, mom-and-pop stores usually sell tortillas to people with less income than those who buy them in a retail store. 

The price difference between retailers and mom-and-pop stores has increased since the COVID-19 pandemic, as can be seen in the next figure.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F2718659%2F88cba385cef8b043ef662859e66a7b71%2Flineplot_by_type_2007-2024.png?generation=1709523281176095&alt=media)

The purpose of publishing this dataset is to raise awareness of the importance of food price monitoring and the impact those prices can have on people's lives. 

Thumbnail photo by <a href=""https://unsplash.com/@louishansel?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Louis Hansel</a> on <a href=""https://unsplash.com/photos/red-cherries-on-white-round-cake-6S8BEbV55YY?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv
Total Emissions Per Country (2000-2020),1,total-emissions-per-country-2000-2020,Total Emissions Per Country (2000-2020).csv,CC-BY-NC-SA-4.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F12064410%2Fb393d6267bc738b9b4f9537226d5fe9a%2Ftotal%20emissions%20per%20country%20flag.png?generation=1677824634020471&alt=media)

# 7670 DAYS (January 1st, 2000 to December 31st, 2020)
This is a dataset that tracks the **sources** of emission, **types** of emission, and **total emissions** (CH4, N2O, CO2, etc.) per country from **2000** to **2020**.

All data are official figures from the United Nations's Food and Agriculture Organization (FAO) that have been compiled and structured by myself. What sets this dataset apart from similar ones is the inclusion of emissions **OUTSIDE** of CO2 such as CH4 and N2O. Additionally, emission data for each country is separated depending on the source of the emissions, which heightens the analytical potential of the dataset. Just to make it clear, all units featured in this dataset are in *kilotonnes*.

Why did I create this dataset? As global warming becomes worse, countries across the globe will look to **shift the blame** for environmental consequences on one another. By providing a dataset that tracks emission per country, I hope to keep countries **accountable** for their contributions to the crisis. Additionally, achieving a **quantitative yet objective viewpoint** of a subject such as global warming is crucial to understanding the issues at hand.

# Data Sources
##### The primary data source used was the United Nations's Food and Agriculture Organization (FAO) website, which publishes tabular data pertaining to global environmental issues. Considering the meticulous documentation of government statistics by such a legally constituted IGO, no other authority is more equipped to provide insight on emission rates.

1. [The Food and Agriculture Organization's Emissions Total Data](https://www.fao.org/faostat/en/#data/GT) - The Food and Agriculture Organization (FAO) has published yearly updates on unemployment rates since 1961. However, I narrowed down the time period covered to 20 years for simplicity's sake. 
2. [The Food and Agriculture Organization's Definitions and Standards](https://www.fao.org/faostat/en/#definitions) - The Food and Agriculture Organization (FAO) released a detailed overview of their emissions data, the methodology behind their data, and the proper definitions and terminologies for the variables tracked. The guide mainly provided essential contextual knowledge needed to create a meaningful dataset.

# Statistics Being Tracked
- Area (Country)
- Item (Source of Emission)
- Element (Type of Emission)
- Unit (Emissions = Kilotonnes)
- Year (Total Emissions for Each Year, 2000 - 2020)

# Dataset History
2023-03-02 - Dataset is created (8,462 days after temporal coverage start date).

[GitHub Repository](https://github.com/justin-2028/Total-Emissions-Per-Country-2000-2020) - The same data but on GitHub.

# Code Starter
[Link to Notebook](https://www.kaggle.com/code/justin2028/total-emissions-per-country-code-starter/notebook)",.csv
Total Worldwide Passenger Cars Sales,1,total-worldwide-passenger-cars-sales,scraped_data.csv,CC0-1.0,"This dataset provides comprehensive insights into total passenger car sales across 141 countries from the years 2005 to 2022. Each row represents a specific country, and the columns contain data for each year's passenger car sales. With 19 columns in total, including one for the country and the rest for sales data spanning 2005 to 2022, this dataset offers valuable information for analyzing global trends, conducting market research, and gaining insights into the automotive industry's dynamics over the years.
",.csv
TotalBrainHealthDataset,1,comprehensive-health-and-brain-imaging-dataset,main.csv,other,"### General Information:

- **age**: The age of the participants, shown as a number.
- **gender**: The gender of the participants, usually 'male' or 'female'.

### Health Status:

- **dementia and dementia_all**: Shows if participants have dementia. It is marked as 'yes' or 'no'.
- **diabetes**: Indicates if participants have diabetes, also marked as 'yes' or 'no'.
- **hypertension and hypercholesterolemia**: Indicates if participants have high blood pressure or high cholesterol.

### Lifestyle Habits:

- **smoking**: The smoking status of participants, divided into three categories: 'Smoker', 'Quit' (stopped smoking), and 'None' (never smoked).

### Imaging and Brain Health Metrics:

- **EF, PS, Global**: These columns show scores from mental and performance tests.
- **Lacunes_Presence and CMB_Presence**: Indicates the presence of small cavities in the brain tissue (lacunes) and microbleedings, marked as 'Present' or 'Absent'.
- **fazekas_cat**: A classification related to the Fazekas scale that indicates the severity of brain white matter changes.

### Related Studies:

- **Study_Name**: The name of the study the participant was involved in, including 'Neuroimaging Study', 'Cerebrovascular Study', among others.

### Additional Information:

- **SVD Simple Score and SVD Amended Score**: Scores related to the examination of small vessel damage, which might be used for further analysis.",.csv
Tour & Travels Customer Churn Prediction,1,tour-travels-customer-churn-prediction,Customertravel.csv,CC0-1.0,"A Tour & Travels Company Wants To Predict Whether A Customer Will Churn Or Not Based On Indicators Given Below.
Help Build Predictive Models And Save The Company's Money.
Perform Fascinating EDAs.
The Data Was Used For Practice Purposes And Also During A Mini Hackathon, Its Completely Free To Use",.csv
Tour de France  - Rider Information,1,tour-de-france-rider-information,tdf_riders.csv,CC0-1.0,"The data is gathered from [Pro Cycling Stats](https://www.procyclingstats.com/index.php)  and the individual Wikipedia entries of the riders. Unfortunately, weight and height information is missing for some of them.

The rating for each rider type is determined by race points. Age is calculated based on the rider's age at the time of winning the race. In cases where a rider has multiple victories, the year of their best performance by rider type is considered.

İmage: [jackmac34](https://pixabay.com/users/jackmac34-483877/)",.csv
Tourism Page Engagement,1,customer-behaviour-tourism-portal,Customer behaviour Tourism.csv,other,"This dataset provides complete information about Customer behaviour for a typical Social Media page of tourism company. 


Data Dictionary:-

| Variable                          | Description                                                          |
|-----------------------------------|----------------------------------------------------------------------|
| UserID                            | Unique ID of the user                                               |
| Buy_ticket                        | Buy a ticket in the next month (target variable)                     |
| Yearly_avg_view_on_travel_page    | Average yearly views on any travel-related page by the user           |
| preferred_device                  | Preferred device for user login                                     |
| total_likes_on_outstation_checkin_given | Total number of likes given by the user on out-of-station check-ins in the last year |
| yearly_avg_Outstation_checkins    | Average number of out-of-station check-ins done by the user          |
| member_in_family                  | Total number of relationships mentioned by the user in the account   |
| preferred_location_type           | Preferred type of location for traveling by the user                 |
| Yearly_avg_comment_on_travel_page | Average yearly comments on any travel-related page by the user       |
| total_likes_on_outofstation_checkin_received | Total number of likes received by the user on out-of-station check-ins in the last year |
| week_since_last_outstation_checkin | Number of weeks since the last out-of-station check-in update by the user |
| following_company_page            | Whether the customer is following the company page (Yes or No)      |
| montly_avg_comment_on_company_page | Average monthly comments on the company page by the user             |
| working_flag                      | Whether the customer is working or not                               |
| travelling_network_rating         | The rating indicating if the user has close friends who also like traveling. 1 is high, 4 is lowest |
| Adult_flag                        | Whether the customer is an adult or not                               |
| Daily_Avg_mins_spend_on_traveling_page | Average time spent on the company's travel page by the user          |
",.csv
Tourism has,1,tourism-has,international-tourist new.csv,CC0-1.0,"this graph was created in PowerBi,Loocker studio and Tableau:

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fe7d162bc21e3a705d65a6b9c7e6ff7a9%2Fgraph2.jpg?generation=1714938638670315&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Ff40c5635aa4f12121b7ee667c9c504f8%2Fgraph1.jpg?generation=1714938645751303&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F75f403c0ca739214b1c064222a04f77a%2Fgraph3.png?generation=1714938653224474&alt=media)

Tourism has massively increased in recent decades. Aviation has opened up travel from domestic to international. Before the COVID-19 pandemic, the number of international visits had more than doubled since 2000.

Tourism can be important for both the travelers and the people in the countries they visit.

For visitors, traveling can increase their understanding of and appreciation for people in other countries and their cultures.

And in many countries, many people rely on tourism for their income. In some, it is one of the largest industries.

But tourism also has externalities: it contributes to global carbon emissions and can encroach on local environments and cultures.

On this page, you can find data and visualizations on the history and current state of tourism across the world.

All visualizations, data, and code produced by Our World in Data are completely open access under the Creative Commons BY license. You have the permission to use, distribute, and reproduce these in any medium, provided the source and authors are credited.

The data produced by third parties and made available by Our World in Data is subject to the license terms from the original third-party authors. We will always indicate the original source of the data in our documentation, so you should always check the license of any such third-party data before use and redistribution.

All of our charts can be embedded in any site.",.csv
Toy Dataset,1,toy-dataset,toy_dataset.csv,CC0-1.0,"## Context

A fictional dataset for exploratory data analysis (EDA) and to test simple prediction models.

This toy dataset features 150000 rows and 6 columns.

## Columns

Note: All data is fictional. The data has been generated so that their distributions are convenient for statistical analysis.

*Number:* A simple index number for each row

*City:* The location of a person (Dallas, New York City, Los Angeles, Mountain View, Boston, Washington D.C., San Diego and Austin)

*Gender:* Gender of a person (Male or Female) 

*Age:* The age of a person (Ranging from 25 to 65 years)

*Income:* Annual income of a person (Ranging from -674 to 177175)

*Illness:* Is the person Ill? (Yes or No)

## Acknowledgements

[Stock photo][1] by Mika Baumeister on Unsplash.


  [1]: https://unsplash.com/photos/Wpnoqo2plFA",.csv
Toyota Corolla Car Price Prediction,1,toyota-corolla-car-price-prediction,ToyotaCorolla1.csv,MIT,"Tim runs a  large Toyota car dealership which interested in a new promotion to offers purchasers of new Toyota cars the option to buy their used cars as part of a trade-in. In particular, the promotion promises to pay high prices for used Toyota Corolla car for purchasers of new cars. Tim then sells the used cars for  a small profit. To ensure a reasonable profit, Tim needs to be able to predict the price the dealership will be able to get for the used cars. For that reason, data were collected on previous sales of the used Toyota Corolla cars at the dealership. 

",.csv
Toyota used car listing,1,toyota-used-car-listing,toyota.csv,CC0-1.0,"### Data set contains information of price, transmission, mileage, fuel type, road tax, miles per gallon (mpg), and engine size
data description:
model Toyota model.
year registraion year.
price price in Euros.
transmission type of gear box.
mileage distance used.
fuelType engine fuel.
tax road tax.
mpg miles per galoon.
engineSize size in litres.

It'd be cool to have some insights and vizualisations of the data. Also, am open to ideas on how to expand the data set.

",.csv
Tracking_global,1,tracking-global,electric-car-sales-share NEW.csv,CC0-1.0,"this graph was created in PowerBi and OurDataWorld :

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F658baa873f9443aee31bf10fa4c5c250%2Fgraph1.png?generation=1713123716132613&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F23d2ed8ae7f077a2a8dc0852875969a7%2Fgraph2.png?generation=1713123723180483&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F1da5e38bf15436333b168b6623b16ce3%2Fgraph3.jpg?generation=1713123729476026&alt=media)

As the world grapples with the urgent need to reduce carbon emissions and combat climate change, electric vehicles (EVs) emerge as a pivotal solution in decarbonizing transport. Despite initial concerns about their manufacturing process emitting more carbon, EVs swiftly offset this ""carbon debt"" once they hit the road, offering a significantly lower carbon footprint compared to their petrol or diesel counterparts over their lifespan.

The transition to electrified transport is gaining momentum across the globe, albeit at varying paces. Nations are increasingly recognizing the imperative to embrace EVs as a cornerstone of sustainable mobility, with some leading the charge towards a cleaner, greener future.

Data from the International Energy Agency (IEA) sheds light on the rapid growth of EV adoption worldwide. Each year, the IEA's Global EV Outlook provides invaluable insights into EV sales and the burgeoning fleet of electric vehicles on the roads. This ongoing analysis allows us to track the progress and identify the frontrunners in the electrification of transport.

In terms of new car sales, the shift towards electric propulsion is unmistakable. While electric cars initially represented a small fraction of total sales, their market share is escalating rapidly in numerous regions. Globally, approximately one in seven new cars sold in 2022 was electric, with early estimates for 2023 suggesting an even more impressive figure of one in five. Remarkably, in Norway, over four out of every five new cars sold were electric, underscoring the country's commitment to sustainable mobility. Similarly, in China, electric vehicles accounted for approximately one in three new car purchases, reflecting the nation's ambitious efforts to curb emissions and foster technological innovation.

The chart below provides a comprehensive overview of these trends across different countries, illustrating the dynamic evolution of electric vehicle adoption on a global scale. It's important to note that the term ""electric cars"" encompasses both fully battery-electric vehicles and plug-in hybrids, reflecting the diversity of electrified options available to consumers.

As countries continue to prioritize decarbonization and invest in renewable energy infrastructure, the trajectory of electrified transport is poised to accelerate further. With concerted efforts and innovative policies, the vision of a world powered by clean, sustainable mobility is within reach. Electric vehicles stand as a beacon of hope, offering a tangible pathway towards a brighter, more sustainable future for generations to come.",.csv
Traditional Chilean Recipes,1,traditional-chilean-recipes,chilean_recipes.csv,CC0-1.0,"# Context

Chilean food has elements that are characteristic of this country's gastronomy. Whether in empanadas, pastel de choclo or mote con huesillo, Chileans enjoy their food in a variety of forms and flavors. This dataset contains information about typical Chilean food recipes, compiled from the blog ""Mi Diario de Cocina"" (https://www.midiariodecocina.com/recetas-chilenas/).

# Contents

- **recipe name**: the name of the recipe.
- **preparation time**: time required for the preparation of the recipe in minutes.
- **min_portion**: estimated minimum servings per recipe.
- **max_portion**: estimated maximum servings per recipe. If nan, then the recipe has a exact number of servings (value in **min_portion** column).
- **ingredients**: list of ingredients for the estimated value of servings per recipe.
- **steps**: list of instructions for the recipe.


# Inspiration

Food data holds a lot of insight related to a country's culture and gastronomy. You can do many things with this information: learn about the key ingredients of traditional food and contrast it with cultural features, analyze its nutritional values for evaluating healthiness, or categorize recipes based on different criteria.

# Acknowledgements

The data was obtained from the blog ""Mi Diario de Cocina"" (https://www.midiariodecocina.com/recetas-chilenas/).",.csv
Train Stations in Europe,1,train-stations-in-europe,train_stations_europe.csv,ODbL-1.0,"### Context

Many European countries possess an extensive net of public transport railroads which connect large and small cities. This dataset contains the names, coordinates, and basic properties of more than 36000 train stations in (and adjacent to) Europe. It was derived from data provided by the [Trainline EU](https://www.trainline.eu/) ticketing website that has been [published on github](https://github.com/trainline-eu/stations). I will update this dataset regularly. 

Note, that the data contains a few train stations in the European parts of Russia and Turkey, as well as a small number of stations in the African country of Morocco.


### Content

The dataset `train_stations_europe.csv` is based on the [Trainline EU github repo](https://github.com/trainline-eu/stations). It contains 36k+ stations at the time of creation of this Kaggle Dataset. The github dataset contains many more columns, most of which are covering operator-specific properties (e.g. Renfe or Trenitalia) or translations into different languages (most of which are missing, though). I decided to extract this subset to provide a more focussed and complete data source.


### Column Description

Most of those descriptions have been taken verbatim from the github repo. I have added some extra context info or explanations where I felt they were necessary. Note, that some columns contain a significant percentage of NA values.

- `id`: Numeric internal unique identifier. Primary key.

- `name`: Name of the station as it is locally known. These names include accents and other special characters.

- `name_norm`: Normalised version of `name`; transformed into [A-Za-z] character space (aka 'Latin-ASCII') to replace special characters with their standard-Latin counterparts (e.g. è become e, ü becomes u).

- `uic`: The UIC code of the station. UIC is the [International Union of Railways](https://en.wikipedia.org/wiki/International_Union_of_Railways), ""an international rail transport industry body"". About 1/3 of all stations have no UIC code in this dataset.

- `longitude` & `latitude`: Station coordinates. About 5% of all stations have no coordinates in this dataset.

- `parent_station_id`: A station can belong to a meta station whose `id` is this value, i.e. Paris Gare d’Austerlitz (`id = 4921`) belongs to the meta-station Paris (`id = 4916`). About 92% of rows have NA entries.

- `country`: Country codes in ISO 3166-1 alpha-2 format (2 digits). 

- `time_zone`: Continent/Country ISO codes. Those appear to be equivalent to Olson names (e.g. ""Europe/Berlin"").

- `is_city`: Marked as ""unreliable"" in the source dataset. Might be worth investigating what exactly that means.

- `is_main_station`: Marked as ""unreliable"" in the source dataset. Might be worth investigating what exactly that means.


### Acknowledgements

All credit for creating this dataset and providing the public version goes to the [Trainline EU team](https://github.com/trainline-eu/stations). 

Banner and vignette photo by [Michał Parzuchowski](https://unsplash.com/@mparzuchowski) on Unsplash.


### Licence

Data is distributed under the Open Database License (ODbL) licence, see [here](https://github.com/trainline-eu/stations/blob/master/LICENCE.txt). In short, any modification to this data source must be published.
",.csv
Transport  move,1,transport-move,air-passengers-carried new.csv,CC0-1.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F19e3f49ec8bfbdcede75f3a68b7af4c3%2Fgraph2.png?generation=1714516289788969&alt=media)this graph was created in OurDataWorld:

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fcb97fc53c90882c2c10fb2e64bf26779%2Fgraph1.png?generation=1714516262293313&alt=media)

Transport allows people to move across cities, countries, and continents. It allows us to trade goods and products across the world by road, rail, sea or air.

It has become an essential part of our lives, whether it’s getting to work or school; delivering essential services or necessities to different communities; or connecting people and industries across the world. It’s now a key driver of economic development.

But transport also negatively affects our health and the environment through road injuries and fatalities, air pollution, and CO₂ emissions which drive climate change.

On this page, you can find data, visualizations, and writing on transport patterns across the world, how this is changing, and its environmental impacts.",.csv
Travel Dataset: Guide to India's Must See Places,1,travel-dataset-guide-to-indias-must-see-places,Top Indian Places to Visit.csv,DbCL-1.0,"Dataset Description:
This dataset is a curated exploration guide that encompasses must visit destinations across India. It serves as an extensive resource for travelers and enthusiasts alike, offering detailed insights into each location's unique characteristics. From historical landmarks to religious shrines and natural wonders, this dataset is a window to India's diverse and rich cultural heritage.

Column Descriptions:

Zone: Geographical region of the place within India, categorizing it into zones like Northern, Southern, etc.
State: The state in which the place is located, providing a regional context.
City: The city or town where the destination is situated.
Name: The name of the tourist spot or landmark.
Type: Classification of the place, such as Temple, War Memorial, or Natural Park.
Establishment Year: The year in which the place was established or discovered.
Time Needed to Visit (hrs): Estimated duration in hours to thoroughly visit the place.
Google Review Rating: The average Google review rating for the place, indicative of its popularity and visitor satisfaction.
Entrance Fee in INR: The cost of admission in Indian Rupees.
Airport within 50km Radius: Indicates if there is an airport within 50 kilometers of the place for accessibility.
Weekly Off: The day of the week when the place is closed to visitors.
Significance: The importance or role of the place, such as Historical, Religious, or Environmental.
DSLR Allowed: Indicates whether visitors are permitted to use DSLR cameras at the location.
Number of Google Reviews (in lakhs): The total number of Google reviews in lakhs (hundreds of thousands) that the place has received.
Best Time to Visit: Suggested time of the day for visiting the place to have the best experience.

Enhance your data visualization, perform exploratory data analysis (EDA), and apply classification algorithms using this diverse dataset to uncover captivating insights into India's top destinations.

Image attribue : Photo by Flo Maderebner: https://www.pexels.com/photo/couple-sitting-on-rock-beside-lake-238622/",.csv
Travel Insurance,1,travel-insurance,travel insurance.csv,ODbL-1.0,"A third-party travel insurance servicing company that is based in Singapore.

The attributes:

 1. Target: Claim Status (Claim.Status) 
 2. Name of agency (Agency)
 3. Type of travel insurance agencies (Agency.Type)
 4. Distribution channel of travel insurance agencies (Distribution.Channel)
 5. Name of the travel insurance products (Product.Name)
 6. Duration of travel (Duration)
 7. Destination of travel (Destination)
 8. Amount of sales of travel insurance policies (Net.Sales)
 9. Commission received for travel insurance agency (Commission)
 10. Gender of insured (Gender)
 11. Age of insured (Age)",.csv
Travel Insurance Prediction Data,1,travel-insurance-prediction-data,TravelInsurancePrediction.csv,CC0-1.0,"### Context
A Tour & Travels Company Is Offering Travel Insurance Package To Their Customers.
The New Insurance Package Also Includes Covid Cover. 
The Company Requires To Know The Which Customers Would Be Interested To Buy It Based On Its Database History.
The Insurance Was Offered To Some Of The Customers In 2019 And The Given Data Has Been Extracted From The Performance/Sales Of The Package During That Period.
The Data Is Provided For Almost 2000 Of Its Previous Customers And You Are Required To Build An Intelligent Model That Can Predict If The Customer Will Be Interested To Buy The Travel Insurance Package Based On Certain Parameters Given Below. 
Image Credits-Unsplash(free to use)
### Content
Age- Age Of The Customer 
Employment Type- The Sector In Which Customer Is Employed
GraduateOrNot- Whether The Customer Is College Graduate Or Not
AnnualIncome- The Yearly Income Of The Customer In Indian Rupees[Rounded To Nearest 50 Thousand Rupees]
FamilyMembers- Number Of Members In Customer's Family
ChronicDisease- Whether The Customer Suffers From Any Major Disease Or Conditions Like Diabetes/High BP or Asthama,etc.
FrequentFlyer- Derived Data Based On Customer's History Of Booking Air Tickets On Atleast 4 Different Instances In The Last 2 Years[2017-2019].
EverTravelledAbroad- Has The Customer Ever Travelled To A Foreign Country[Not Necessarily Using The Company's Services]
TravelInsurance- Did The Customer Buy Travel Insurance Package During Introductory Offering Held In The Year 2019.

### Inspiration

The Solution Offered By You May Be Used For Customer Specific Advertising Of The Package.
Exploratory Data Analysis Performed On The Data Would Help Find Interesting Insights.
Predict Whether A Given Customer Would Like To Buy The Insurance Package, Once The Corona Lockdown Ends And Travelling Resumes.
Your Work Could Probably Help Save Thousands Of Rupees Of A Family.
",.csv
Travel Review Rating Dataset,1,travel-review-rating-dataset,google_review_ratings.csv,other,"### Context

This data set has been sourced from the Machine Learning Repository of University of California, Irvine (UC Irvine) : Travel Review Ratings Data Set. This data set is populated by capturing user ratings from Google reviews. Reviews on attractions from 24 categories across Europe are considered. Google user rating ranges from 1 to 5 and average user rating per category is calculated.


### Content

Attribute 1 : Unique user id
Attribute 2 : Average ratings on churches
Attribute 3 : Average ratings on resorts
Attribute 4 : Average ratings on beaches
Attribute 5 : Average ratings on parks
Attribute 6 : Average ratings on theatres
Attribute 7 : Average ratings on museums
Attribute 8 : Average ratings on malls
Attribute 9 : Average ratings on zoo
Attribute 10 : Average ratings on restaurants
Attribute 11 : Average ratings on pubs/bars
Attribute 12 : Average ratings on local services
Attribute 13 : Average ratings on burger/pizza shops
Attribute 14 : Average ratings on hotels/other lodgings
Attribute 15 : Average ratings on juice bars
Attribute 16 : Average ratings on art galleries
Attribute 17 : Average ratings on dance clubs
Attribute 18 : Average ratings on swimming pools
Attribute 19 : Average ratings on gyms
Attribute 20 : Average ratings on bakeries
Attribute 21 : Average ratings on beauty & spas
Attribute 22 : Average ratings on cafes
Attribute 23 : Average ratings on view points
Attribute 24 : Average ratings on monuments
Attribute 25 : Average ratings on gardens

### Acknowledgements

This data set has been sourced from the Machine Learning Repository of University of California, Irvine (UC Irvine) : Travel Review Ratings Data Set

The UCI page mentions the following publication as the original source of the data set: Renjith, Shini, A. Sreekumar, and M. Jathavedan. 2018. Evaluation of Partitioning Clustering Algorithms for Processing Social Media Data in Tourism Domain. In 2018 IEEE Recent Advances in Intelligent Computational Systems (RAICS), 12731. IEEE


### Inspiration

I'm kind of people who love traveling. But sometimes I've problems like where should I visit? Are there somewhere interesting places matched with my lifestyle? Often I spent hours to search for interesting place to go out. Such a waste of time.

What if we can build a recommender system which can recommend you several interesting venue based on your preferences. With information from Google review, I'll try to divide Google review user into cluster of similar interest for further work of building recommender system based on thier preference.",.csv
Traveler Trip Dataset ,1,traveler-trip-data,Travel details dataset.csv,Attribution 4.0 International (CC BY 4.0),"The travel dataset provides detailed information on various trips taken by travelers, including their destination, travel dates, duration of the trip in days, traveler demographics (name, age, gender, and nationality), as well as the type and cost of accommodation and transportation. This dataset can be used to gain insights into travel patterns, preferences, and behaviors of different types of travelers. It can also be helpful for travel-related businesses, such as travel agencies, to create tailored marketing strategies and travel packages that meet the needs and preferences of different travelers.

Column details:

•	**Trip ID:** A unique identifier for each trip taken by a traveler.

•	**Destination:** The name of the city or country visited by the traveler.

•	**Start date:** The date the traveler started the trip.

•	**End date:** The date the traveler ended the trip.

•	**Duration (days):** The number of days the traveler spent on the trip.

•	**Traveler name:** The name of the traveler.

•	**Traveler age:** The age of the traveler at the time of the trip.

•	**Traveler gender:** The gender of the traveler.

•	**Traveler nationality:** The nationality of the traveler.

•	**Accommodation type:** The type of accommodation the traveler stayed in, such as hotel, hostel, or Airbnb.

•	**Accommodation cost:** The cost of the accommodation for the entire trip.

•	**Transportation type:** The mode of transportation used by the traveler, such as plane, train, or car.

•	**Transportation cost:** The cost of transportation for the entire trip.

** The purpose of creating this dataset is solely for educational use, and any commercial use is strictly prohibited
and this dataset was large language models generated and not collected from actual data sources.
",.csv
Tree Survival Prediction,1,tree-survival-prediction,Tree_Data.csv,CC0-1.0,"**Tree Survival Prediction** dataset - Tree seedling functional traits mediate plant-soil feedback survival responses across a gradient of light availability.

[**Tree Survival Prediction 2** dataset](https://www.kaggle.com/datasets/yekenot/tree-survival-prediction-2/data) - Tree seedling shade tolerance arises from interactions with microbes and is mediated by functional traits.

**Methodology:**

*(the following information provided by the authors of the experiment)*

We conducted a factorial blocked design field experiment, consisting of four tree species, seven soil sources (sterilized conspecific, live conspecific, and five heterospecific), and a gradient of forest understory light levels (low, medium, and high), for a total of 3,024 seedlings. We monitored seedling survival twice per week over one growing season, and we randomly selected subsets of seedlings to measure mycorrhizal colonization and phenolics, lignin, and NSC measurements at three weeks. We used Cox proportional hazards survival models to evaluate survival and linear mixed effects models to test how light availability and soil source influence traits. 

**Detailed information about each column follows:**

* **No**: Seedling unique ID number.
* **Plot**: Number of the field plot the seedling was planted in (1-18).
* **Subplot**: Subplot within the main plot the seedling was planted in. Broken into 5 subplots (1 per corner, plus 1 in the middle) (A-E).
* **Species**: Includes Acer saccharum, Prunus serotina, Quercus alba, and Quercus rubra.
* **Light ISF**: Light level quantified with HemiView software. Represents the amount of light reaching each subplot at a height of 1m.
* **Light Cat**: Categorical light level created by splitting the range of Light\_ISF values into three bins (low, med, high).
* **Core**: Year the soil core was removed from the field.
* **Soil**: Species from which the soil core was taken. Includes all species, plus Acer rubrum, Populus grandidentata, and a sterilized conspecific for each species.
* **Adult**: Individual tree that soil was taken from. Up to 6 adults per species. Used as a random effect in analyses.
* **Sterile**: Whether the soil was sterilized or not.
* **Conspecific**: Whether the soil was conspecific, heterospecific, or sterilized conspecific.
* **Myco**: Mycorrhizal type of the seedling species (AMF or EMF).
* **SoilMyco**: Mycorrhizal type of the species culturing the soil (AMF or EMF).
* **PlantDate**: The date that seedlings were planted in the field pots.
* **AMF**: Percent arbuscular mycorrhizal fungi colonization on the fine roots of harvested seedlings.
* **EMF**: Percent ectomycorrhizal fungi colonization on the root tips of harvested seedlings.
* **Phenolics**: Calculated as nmol Gallic acid equivalents per mg dry extract (see manuscript for detailed methods).
* **NSC**: Calculated as percent dry mass nonstructural carbohydrates (see manuscript for detailed methods).
* **Lignin**: Calculated as percent dry mass lignin (see manuscript for detailed methods).
* **Census**: The census number at which time the seedling died or was harvested.
* **Time**: The number of days at which time the seedling died or was harvested.
* **Event**: Used for survival analysis to indicate status of each individual seedling at a given time (above)
    * 0 = harvested or experiment ended
    * 1 = dead
* **Harvest**: Indicates whether the seedling was harvested for trait measurement.
* **Alive**: Indicates if the seedling was alive at the end of the second growing season. ""X"" in this field indicates alive status.

Missing data is coded as NA.

**Acknowledgements:**

All data was collected from single experiment and is presented in the associated manuscript: *Wood, Katherine; Kobe, Richard; Ibáñez, Inés; McCarthy-Neumann, Sarah (2023). Tree seedling functional traits mediate plant-soil feedback survival responses across a gradient of light availability*.

If you use this dataset in your research, please credit the original authors.
https://doi.org/10.5061/dryad.xd2547dpw",.csv
Trending TV Shows on Netflix,1,trending-tv-shows-on-netflix,TV Shows - Netflix.csv,CC0-1.0,"### Context

The Dataset is Collected from:
* The dataset is scraped from Reelgood.com


### Content

This Data is a collection of top 50 trending Tv shows currently streaming on Netflix.

### Dataset Distribution:
* **Titles**: It contains the name of the Top Tv shows.
* **Year**: Which Year this Tv Show Released?
* **Netflix_Rating**: Rated By Netflix.
* **IMDB_Rating**: Rated By IMDB.
* **Netflix**: Currently Streaming on Netflix or Not.

### Inspiration
* The year during which a TV Show was released.
* IMDB Ratings for all TV Shows.
* https://www.kaggle.com/ruchi798/movies-on-netflix-prime-video-hulu-and-disney

",.csv
Trending eBay Watch Listings 2024,1,trending-ebay-watch-listings-2024,ebay_watches.csv,ODC Attribution License (ODC-By),"**Dataset Overview:**
Dive into the intricate world of horology with the ""Trending eBay Watch Listings 2024"" dataset, encompassing a curated collection of 2000 listings from eBay's vibrant marketplace. This dataset offers a panoramic view of the watch market, capturing a diverse array of brands, models, and price points, reflecting the latest trends and preferences within the global watch community as of 2024.

**Data Science Applications:**
Ideal for market analysis, price prediction, and consumer behavior studies, this dataset is a treasure trove for data scientists and enthusiasts alike. Analyze brand popularity, track price fluctuations, uncover sales patterns, and delve into regional market differences to extract actionable insights and forecast emerging trends in the watch industry.

**Column Descriptors:**
- `availableText`: Availability status and quantity sold.
- `itemLocation`: Geographic location of the item.
- `itemNumber`: Unique identifier for each listing.
- `lastUpdated`: Timestamp of the last update to the listing.
- `priceWithCurrency`: Listed price, including currency notation.
- `seller`: eBay username of the seller.
- `sold`: Number of units sold.
- `title`: Title of the listing, often including brand and model.
- `subTitle`: Additional details provided by the seller.
- `type`: General category of the item, primarily watches.

**Ethical Consideration:**
This dataset is ethically mined, strictly adhering to public data collection norms. It comprises solely public data with no sensitive information, ensuring respect for privacy and data use ethics.

**Acknowledgements:**
Heartfelt thanks to eBay for facilitating a transparent and dynamic marketplace, enabling the aggregation of this rich dataset. Special acknowledgment for the thumbnail image used in the dataset listing, courtesy of Time4Diamonds, capturing the essence of luxury and precision through a Rolex Submariner, symbolizing the depth and allure of the watch market.

Explore, analyze, and unlock the stories woven through time by these meticulous timepieces.",.csv
Truck Sales for Time Series,1,dummy-truck-sales-for-time-series,Truck_sales.csv,other,"The dataset below contains monthly sales data for trucks from a specific company throughout the year .

The dataset can be used to develop an ARIMA/SARIMA forecasting model for predicting the future sales

&gt;**Do explore pinned 📌 notebook under code section for quick📊 reference**

&gt;_Consider an upvote ^ if you find the dataset useful_


",.csv
Trust_is_now,1,trust-is-now,self-reported-trust-attitudes new.csv,CC0-1.0,"this graph was created in OurDataWorld and PowerBi:

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fdfcd3daf5aec0e2b420bbd8548f87bdc%2Fgraph1.png?generation=1712692802726394&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F7477417eba7cecd5fa45329874ec0683%2Fgraph3.jpg?generation=1712692809429576&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fe076c10567126e242dfe5d0f9b20f5c7%2Fgraph2.png?generation=1712692817442391&alt=media)

Trust is a fundamental element of social capital – a key contributor to sustaining well-being outcomes, including economic development. In this entry we discuss available data on trust, as measured by attitudinal survey questions; that is, estimates from surveys asking about trusting attitudes.

Global comparisons of trust attitudes around the world today suggest very large time-persistent cross-country heterogeneity. In one extreme, in countries such as Norway and Sweden more than 60% of respondents in the World Value Survey agree that “most people can be trusted”. And in the other extreme, in countries such as Colombia, Brazil, Ecuador and Peru, less than 10% think that this is the case.

Data from European countries shows that average trust in the police tends to be higher than trust in the political and the legal systems. And trust in the political system is particularly low – in fact much lower than interpersonal trust for all countries except Switzerland. On the other hand, trust in the police is notably high, and in the majority of European countries people trust the police more than they trust each other.

Long-run data from the US, where the General Social Survey (GSS) has been gathering information about trust attitudes since 1972, suggests that people trust each other less today than 40 years ago. This decline in interpersonal trust in the US has been coupled with a long-run reduction in public trust in government – according to estimates compiled by the Pew Research Center since 1958, today trust in the government in the US is at historically low levels.

Interpersonal trust attitudes correlate strongly with religious affiliation and upbringing. Some studies have shown that this strong positive relationship remains after controlling for several survey-respondent characteristics.1

This, in turn, has led researchers to use religion as a proxy for trust, in order to estimate the extent to which economic outcomes depend on trust attitudes. Estimates from these and other studies using an instrumental-variable approach, suggest that trust has a causal impact on economic outcomes.2 This suggests that the remarkable cross-country heterogeneity in trust that we observe today, can explain a significant part of the historical differences in cross-country income levels.

Measures of trust from attitudinal survey questions remain the most common source of data on trust. Yet academic studies have shown that these measures of trust are generally weak predictors of actual trusting behaviour. Interestingly, however, questions about trusting attitudes do seem to predict trustworthiness. In other words, people who say they trust other people tend to be trustworthy themselves.3",.csv
Tuberculosis,1,tuberculosis,incidenceoftuberculosis new.csv,CC0-1.0,"this graph was created in OurDataWorld and loocker : 

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F0816fae8ca5c8001eba5f5f190e71bf3%2Fgraph4.jpg?generation=1712086186710261&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F43e7c9f007dff6a1dd29388869da8ce1%2Fgraph3.jpg?generation=1712086192645068&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Ffb76960c7d40a164cc95b52ef9f86533%2Fgraph2.png?generation=1712086198602879&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F6a1ec80a7da39ade5a4382ff4dc37eac%2Fgraph1.png?generation=1712086204973980&alt=media)


Tuberculosis (TB) stands as a persistent global health challenge, disproportionately affecting vulnerable populations in poorer regions while persisting as a threat even in more developed nations. Despite significant strides in reducing its impact over history, TB remains a leading cause of mortality worldwide, claiming an estimated 1.2 million lives annually. This enduring scourge is primarily attributed to the bacterium Mycobacterium tuberculosis, which spreads through respiratory particles, particularly affecting individuals with predisposing risk factors such as undernourishment, HIV/AIDS, smoking, and pre-existing chronic conditions.

The clinical manifestations of TB encompass a spectrum of symptoms, ranging from persistent coughing and fatigue to debilitating night sweats. However, the insidious nature of the disease lies in its potential to inflict severe damage on vital organs such as the lungs, brain, and kidneys, often culminating in fatal outcomes if left untreated. Fortunately, TB is eminently treatable through a regimen of specific antibiotics. Nevertheless, the efficacy of treatment hinges crucially on accurate diagnosis. Failure to promptly identify and address TB not only exposes afflicted individuals to heightened vulnerability but also exacerbates the peril of fostering antibiotic-resistant strains, which pose formidable challenges in terms of both management and cost.

To consign TB to the annals of history demands concerted efforts aimed at addressing its multifaceted risk factors while bolstering testing and treatment initiatives on a global scale. Central to this endeavor is the imperative of enhancing public awareness regarding TB and its associated risks, particularly in underserved communities where access to healthcare services may be limited. Moreover, proactive measures targeting the mitigation of prevalent risk factors such as malnutrition and tobacco use are indispensable in curbing the spread of TB and preventing its resurgence.

Crucially, the cornerstone of TB control lies in the expansion of comprehensive testing and diagnostic capabilities, thereby ensuring early detection and prompt initiation of treatment. Innovations in diagnostic modalities, including rapid molecular tests and point-of-care technologies, hold immense promise in bolstering the efficacy and efficiency of TB diagnosis, particularly in resource-constrained settings where conventional laboratory infrastructure may be lacking. By democratizing access to accurate and timely diagnostics, we can circumvent the perils of misdiagnosis and empower healthcare providers to deliver targeted interventions tailored to individual patient needs.

Furthermore, the provision of equitable access to affordable and efficacious treatment regimens constitutes a linchpin of TB control efforts. This necessitates sustained investment in research and development aimed at advancing novel therapeutics and optimizing existing drug protocols to mitigate the emergence of drug-resistant strains. Additionally, concerted efforts are warranted to surmount logistical barriers impeding the delivery of treatment, including the establishment of robust supply chains and the implementation of community-based care models tailored to local contexts.

In tandem with these efforts, vaccination remains a pivotal strategy in the arsenal against TB. The Bacillus Calmette-Guérin (BCG) vaccine, despite its limitations in conferring lifelong immunity, has demonstrated efficacy in reducing the incidence of severe forms of TB in children. However, the pursuit of next-generation vaccines capable of conferring durable protection against TB represents a pressing research priority, underscoring the imperative of sustained investment in vaccine development and deployment.

Moreover, the global fight against TB necessitates a coordinated, multisectoral approach, leveraging partnerships across governmental, non-governmental, and international organizations to harmonize efforts and maximize impact. By fostering synergies between healthcare systems, research institutions, and grassroots organizations, we can forge a unified front against TB, transcending geographic boundaries and socioeconomic disparities.

Ultimately, the eradication of TB demands not merely the containment of its immediate manifestations but a holistic commitment to addressing its root causes and underlying determinants of health. By redoubling our efforts to tackle poverty, inequality, and social marginalization, we can create an environment conducive to the prevention and control of TB, thereby realizing our collective vision of a world free from the scourge of this ancient malady.

In conclusion, the battle against TB is far from over, yet with unwavering resolve and concerted action, we can consign this age-old scourge to the annals of history. By harnessing the power of innovation, solidarity, and collective action, we can realize a future where TB is relegated to the realms of bygone epidemics, ensuring health and prosperity for generations to come.",.csv
Tunisian Real Estate,1,tunisian-real-estate,data_prices_cleaned.csv,Apache 2.0,"To address the scarcity of datasets on Tunisia, particularly in the realm of real estate, I developed a solution by scraping data from Tayara. This involved extracting relevant information from the platform to build a comprehensive dataset, enabling deeper analysis and insights into the real estate market dynamics within Tunisia.",.csv
Turkey Car Market 2020,1,turkey-car-market-2020,turkey_car_market.csv,ODbL-1.0,"Hello to everyone,

Car market in Turkey for the 2020 data in this data set are available. ***Our goal is to estimate vehicle prices.***

The variables in the data set are as follows:

İlan Tarihi: Date
Marka: Brand
Arac Tip Grubu: Vehicle Type Group
Arac Tip: Vehicle Type
Model Yıl: Model Year
Yakıt Turu: Fuel Type (Benzin: Petrol, Dizel: Diesel, Benzin / LPG: Gasoline, Hibrit: Hybrid, Elektrik: Electricity)
Vites: Transmission (Otomatik: Automatic, Yarı Otomatik: Semi Automatic, Düz: Manual)
CCM: CCM
Beygir Gucu: Horse Power
Renk: Color
Kasa Tipi: Body Type
Kimden: Seller
Durum: Seller Status
KM: Kilometers
Fiyat: Price

Enjoy!

=========================================================================================================

Herkese merhaba,

Bu veri setinde Türkiye'de internette satışa çıkan araçların bilgileri ve fiyatları mevcuttur. Amacımız veri seti içerisindeki değişkenler ile **fiyatları** en iyi şekilde tahmin etmeye çalışmaktır.

Veri seti içerisindeki değişkenler aşağıdaki gibidir.

İlan Tarihi, Marka, Araç Tip Grubu, Araç Tip, Model Yıl, Yakıt Türü, Vites, CCM, Beygir Gücü, Renk, Kasa Tipi, Kimden, Durum, KM, Fiyat

İyi eğlenceler.


",.csv
Turkey Earthquakes (1915 - Feb 2024),1,turkey-earthquakes-1915-2024-feb,turkey_earthquakes(1915-2024_feb).csv,other,"**Context**
Kandilli Observatory, or more formally Kandilli Observatory and Earthquake Research Institute (KOERI, Turkish: Kandilli Rasathanesi ve Deprem Araştırma Enstitüsü) is a Turkish observatory, which is also specialized on earthquake research. It is situated in Kandilli neighborhood of Üsküdar district on the Anatolian side of Istanbul, atop a hill overlooking Bosporus.

**Content**
The dataset includes the Earthquakes that occurred in Turkey and the close coverage area. This data includes only the earthquakes in the range from 1915 to February 2024 and greater than 3.5 magnitudes.

**Acknowledgements**
All the data here is owned by ""Boğaziçi Üniversitesi Rektörlüğü"" and it can only be used for uncommercial issues with regards to ""Boğaziçi Üniversitesi Kandilli Rasathanesi ve Deprem Araştırma Enstitüsü Bölgesel Deprem-Tsunami İzleme ve Değerlendirme Merkezi"".

**Inspiration**
Data Visualization, Exploration and Analysis.

Cover Image Resource: http://cografyaharita.com/turkiye-dogal-afet-haritalari.html",.csv
Twitter Sentiment Analysis Dataset ,1,twitter-analysis-dataset-2022,twitter.csv,DbCL-1.0,"The Twitter Sentiment Analysis Dataset is a widely used dataset in the field of natural language processing and sentiment analysis. It consists of a collection of tweets, each labeled with the sentiment expressed in the tweet, which can be positive, negative, or neutral. This dataset is commonly used for training and evaluating machine learning models that aim to automatically analyze and classify the sentiment behind Twitter messages.

The dataset contains a diverse range of tweets, capturing the opinions, emotions, and attitudes of Twitter users on various topics such as movies, products, events, or general daily experiences. The tweets cover a broad spectrum of sentiments, including expressions of joy, satisfaction, anger, disappointment, sarcasm, or indifference.",.csv
Twitter Sentiment Analysis in Spanish Tweets,1,sentiment-analysis-in-spanish-tweets,sentiment_analysis_dataset.csv,MIT,"This dataset was created with the purpose of building a Sentiment Analysis model in Spanish for the [""bitacora-diarIA""](https://github.com/Kevin-Palacios/bitacora-diarIA) project. The project involves a system based on AI models to recognize voice, store it in a log with its sentiment, provide advice (using RNN and word2vec), and replicate your voice and way of expressing yourself.

-------------------(Spanish)------------------


Este dataset fue creado con el proposito de crear un modelo de Analisis de Sentimiento en Español, para el proyecto de [""bitacora-diarIA""](https://github.com/Kevin-Palacios/bitacora-diarIA), el cual consiste en un sistema con base en modelos de IA, para poder reconocer la voz, guardarla en una bitacora con su sentimeinto, darte consejos (RNN y word2vec) y poder replicar tu voz y forma de expresarte.",.csv
Twitter Tweets Sentiment Dataset,1,twitter-tweets-sentiment-dataset,Tweets.csv,CC0-1.0,"![](https://raw.githubusercontent.com/Masterx-AI/Project_Twitter_Sentiment_Analysis_/main/twitt.jpg)
### Description:

Twitter is an online Social Media Platform where people share their their though as tweets. It is observed that some people misuse it to tweet hateful content. Twitter is trying to tackle this problem and we shall help it by creating a strong NLP based-classifier model to distinguish the negative tweets & block such tweets. Can you build a strong classifier model to predict the same?

Each row contains the text of a tweet and a sentiment label. In the training set you are provided with a word or phrase drawn from the tweet (selected_text) that encapsulates the provided sentiment.

Make sure, when parsing the CSV, to remove the beginning / ending quotes from the text field, to ensure that you don't include them in your training.

You're attempting to predict the word or phrase from the tweet that exemplifies the provided sentiment. The word or phrase should include all characters within that span (i.e. including commas, spaces, etc.)

#### Columns:
1. textID - unique ID for each piece of text 
2. text - the text of the tweet 
3. sentiment - the general sentiment of the tweet 

#### Acknowledgement:
The dataset is download from Kaggle Competetions:\
https://www.kaggle.com/c/tweet-sentiment-extraction/data?select=train.csv

### Objective:
- Understand the Dataset & cleanup (if required).
- Build classification models to predict the twitter sentiments.
- Compare the evaluation metrics of vaious classification algorithms.",.csv
Twitter US Airline Sentiment,1,twitter-airline-sentiment,Tweets.csv,CC-BY-NC-SA-4.0,"*This data originally came from [Crowdflower's Data for Everyone library](http://www.crowdflower.com/data-for-everyone).*

As the original source says,

> A sentiment analysis job about the problems of each major U.S. airline. Twitter data was scraped from February of 2015 and contributors were asked to first classify positive, negative, and neutral tweets, followed by categorizing negative reasons (such as ""late flight"" or ""rude service"").

The data we're providing on Kaggle is a slightly reformatted version of the original source. It includes both a CSV file and SQLite database. The code that does these transformations is [available on GitHub](https://github.com/benhamner/crowdflower-airline-twitter-sentiment)

For example, it contains whether the sentiment of the tweets in this set was positive, neutral, or negative for six US airlines:

[![airline sentiment graph](https://www.kaggle.io/svf/136065/a6e055ee6d877d2f7784dc42a15ecc43/airlineSentimentPlot.png)](https://www.kaggle.com/benhamner/d/crowdflower/twitter-airline-sentiment/exploring-airline-twitter-sentiment-data)",.csv
Twitter User Gender Classification,1,twitter-user-gender-classification,gender-classifier-DFE-791531.csv,CC0-1.0,"This data set was used to train a CrowdFlower AI gender predictor. [You can read all about the project here](https://www.crowdflower.com/using-machine-learning-to-predict-gender/). Contributors were asked to simply view a Twitter profile and judge whether the user was a male, a female, or a brand (non-individual). The dataset contains 20,000 rows, each with a user name, a random tweet, account profile and image, location, and even link and sidebar color.

## Inspiration

Here are a few questions you might try to answer with this dataset:

- how well do words in tweets and profiles predict user gender?
- what are the words that strongly predict male or female gender?
- how well do stylistic factors (like link color and sidebar color) predict user gender?

## Acknowledgments

Data was provided by the [Data For Everyone Library](https://www.crowdflower.com/data-for-everyone/) on [Crowdflower](https://www.crowdflower.com).

Our Data for Everyone library is a collection of our favorite open data jobs that have come through our platform. They're available free of charge for the community, forever.

## The Data
The dataset contains the following fields:

- **_unit_id**: a unique id for user
- **_golden**: whether the user was included in the gold standard for the model; TRUE or FALSE
- **_unit_state**: state of the observation; one of *finalized* (for contributor-judged) or *golden* (for gold standard observations)
- **_trusted_judgments**: number of trusted judgments (int); always 3 for non-golden, and what may be a unique id for gold standard observations
- **_last_judgment_at**: date and time of last contributor judgment; blank for gold standard observations
- **gender**: one of *male*, *female*, or *brand* (for non-human profiles)
- **gender:confidence**: a float representing confidence in the provided gender
- **profile_yn**: ""no"" here seems to mean that the profile was meant to be part of the dataset but was not available when contributors went to judge it
- **profile_yn:confidence**: confidence in the existence/non-existence of the profile
- **created**: date and time when the profile was created
- **description**: the user's profile description
- **fav_number**: number of tweets the user has favorited
- **gender_gold**: if the profile is golden, what is the gender?
- **link_color**: the link color on the profile, as a hex value
- **name**: the user's name
- **profile_yn_gold**: whether the profile y/n value is golden 
- **profileimage**: a link to the profile image
- **retweet_count**: number of times the user has retweeted (or possibly, been retweeted)
- **sidebar_color**: color of the profile sidebar, as a hex value
- **text**: text of a random one of the user's tweets
- **tweet_coord**: if the user has location turned on, the coordinates as a string with the format ""[*latitude*, *longitude*]""
- **tweet_count**: number of tweets that the user has posted
- **tweet_created**: when the random tweet (in the **text** column) was created
- **tweet_id**: the tweet id of the random tweet
- **tweet_location**: location of the tweet; seems to not be particularly normalized
- **user_timezone**: the timezone of the user",.csv
Twitter-Dataset,1,twitter-dataset,twitter_dataset.csv,CC0-1.0,"Welcome to our Twitter dataset, a curated collection of tweets carefully gathered from the vast Twitter ecosystem. This comprehensive dataset offers a valuable resource for researchers, data scientists, and enthusiasts interested in exploring the dynamics of social media communication. Spanning diverse topics, industries, and regions, our dataset provides an in-depth understanding of trends, sentiments, and user behavior within the Twitterverse. Analyze engagement metrics, track the evolution of hashtags, uncover influential users, and gain insights into the ever-changing landscape of online conversations. With our Twitter dataset, you can unlock the power of social media data to fuel research, drive innovation, and gain a deeper understanding of the world through the lens of Twitter.",.csv
Twitter_Airline_Sentiment_Analysis,1,twitter-airline-sentiment-analysis,Tweets.csv,MIT,"```
The dataset you're referring to is a sentiment analysis dataset that focuses on the problems associated with major U.S. airlines. Here are some key details about this dataset:

Source: The original data came from Crowdflower's Data for Everyone library. This library is a collection of datasets made available for public use.

Data Collection Period: The Twitter data used in this sentiment analysis was scraped from February of 2015. This means that the tweets in this dataset were posted on Twitter during that specific time period.

Task Description: Contributors were tasked with performing two main classifications on the tweets. First, they were asked to classify each tweet into one of three sentiment categories: positive, negative, or neutral. Second, for tweets categorized as negative, contributors were further asked to categorize the specific reasons for the negativity. Examples of negative reasons could include ""late flight"" or ""rude service"".

Airlines Covered: The dataset covers six major U.S. airlines. These airlines are not specified in the provided information, but they would likely include carriers like American Airlines, Delta, United, Southwest, and others.

Data Formats: The data is available in two formats - a CSV file and an SQLite database. This provides flexibility for users who may prefer working with one format over the other.

Reformatting: The version provided on Kaggle is a slightly reformatted version of the original source. This could involve adjustments to the data structure, cleaning, or other modifications to improve its usability.

Code Availability: The code used for these transformations is available on GitHub. This is valuable for transparency and allows users to understand how the data was processed and transformed.

In summary, this dataset is a valuable resource for sentiment analysis tasks related to U.S. airlines, particularly in understanding the specific problems or issues that customers were discussing on Twitter in February 2015. It provides labeled data that can be used to train and evaluate sentiment analysis models.
```",.csv
U.S. Airline Traffic Data (2003-2023),1,u-s-airline-traffic-data,air traffic.csv,U.S. Government Works,"# **Context**  
This dataset provides U.S. monthly airline traffic from 2003 to 2023, including number of passengers, number of flights, revenue passenger-miles (RPM), available seat-miles (ASM) and load factor.

# **Inspiration**  
Time series analysis is a statistical method used to analyse data points collected or recorded at specific time intervals. This method can reveal trends, patterns and other significant information from the data as it evolves over time.

In the context of airline traffic data, time series analysis can be used to predict future air passenger numbers based on historical data, which can help with capacity planning, pricing strategies and other business decisions.

# **Possible Explorations**
- Determine the month with the highest and lowest travel frequency.
- Detect seasonal trends or patterns in air traffic.
- Predict future trends in air traffic.
- Analyze the impact of COVID-19 on the aviation industry.

# **Acknowledgements**  
The data were publicly visible and published by the U.S. Department of Transportation’s (DOT) Bureau of Transportation Statistics.",.csv
U.S. Chronic Disease Indicators,1,u-s-chronic-disease-indicators,U.S._Chronic_Disease_Indicators.csv,Apache 2.0,"CDC's Division of Population Health provides a cross-cutting set of 115 indicators developed by consensus among CDC, the Council of State and Territorial Epidemiologists, and the National Association of Chronic Disease Directors. These indicators allow states and territories to uniformly define, collect, and report chronic disease data that are important to public health practice in their area.

This dataset is extremely useful for public health data science as it enables the study of prevalence and distribution of chronic diseases across different demographics and geographical areas. Analysts can assess health outcomes, identify risk factors, and measure the impact of public health interventions.

Some analysis that can be performed include:

- **Epidemiological Studies**: Understand the distribution and determinants of health-related states or events.
- **Geospatial Analysis**: Map disease prevalence to geographic locations to identify hotspots or areas in need of targeted interventions.
- **Longitudinal Analysis**: Study trends over time to see how health indicators change in response to public health policies or other external factors.",.csv
U.S. Electricity Prices,1,electricity-prices,clean_data.csv,U.S. Government Works,"## US Electricity Prices and Sales by State, Sector, and Year
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F8734253%2Fdba0dac3571f37e79f2891a6ffd80d5c%2Fus%20electric%20flag.png?generation=1712518711362350&alt=media)
This comprehensive dataset offers a detailed look at the United States electricity market, providing valuable insights into prices, sales, and revenue across various states, sectors, and years. With data spanning from 2001 onwards to 2024, this dataset is a powerful tool for analyzing the complex dynamics of the US electricity market and understanding how it has evolved over time.

The dataset includes eight key variables:
- year: The year of the observation
- month: The month of the observation
- stateDescription: The name of the state
- sectorName: The sector of the electricity market (residential, commercial, industrial, other, or all sectors)
- customers: The number of customers (missing for some observations)
- price: The average price of electricity per kilowatt-hour (kWh) in cents
- revenue: The total revenue generated from electricity sales in millions of dollars
- sales: The total electricity sales in millions of kilowatt-hours (kWh)

By providing such granular data, this dataset enables users to conduct in-depth analyses of electricity market trends, comparing prices and consumption patterns across different states and sectors, and examining the impact of seasonality on demand and prices.

One of the primary applications of this dataset is in forecasting future electricity prices and sales based on historical trends. By leveraging the extensive time series data available, researchers and analysts can develop sophisticated models to predict how prices and demand may change in the coming years, taking into account factors such as economic growth, population shifts, and policy changes. This predictive power is invaluable for policymakers, energy companies, and investors looking to make informed decisions in the rapidly evolving electricity market.

Another key use case for this dataset is in investigating the complex relationships between electricity prices, sales volumes, and revenue. By combining the price, sales, and revenue data, users can explore how changes in prices impact consumer behavior and utility company bottom lines. This analysis can shed light on important questions such as the price elasticity of electricity demand, the effectiveness of energy efficiency programs, and the potential impact of new technologies like renewable energy and energy storage on the market.

Beyond its immediate applications in the energy sector, this dataset also has broader implications for understanding the US economy and society as a whole. Electricity is a critical input for businesses and households across the country, and changes in electricity prices and consumption can have far-reaching effects on economic growth, competitiveness, and quality of life. By providing such a rich and detailed portrait of the US electricity market, this dataset opens up new avenues for research and insights that can inform public policy, business strategy, and academic inquiry.

I hope you all enjoy using this dataset and find it useful! 🤗",.csv
U.S. Gasoline and Diesel Retail Prices 1995-2021,1,us-gasoline-and-diesel-retail-prices-19952021,PET_PRI_GND_DCUS_NUS_W.csv,U.S. Government Works,"### Context

Source: U.S. Energy Information Administration (Jan 2021).


### Content
The data contains the following information:
- A1: Weekly U.S. All Grades All Formulations Retail Gasoline Prices  (Dollars per Gallon)
- A2: Weekly U.S. All Grades Conventional Retail Gasoline Prices  (Dollars per Gallon)
- A3: Weekly U.S. All Grades Reformulated Retail Gasoline Prices  (Dollars per Gallon)
- R1: Weekly U.S. Regular All Formulations Retail Gasoline Prices  (Dollars per Gallon)
- R2: Weekly U.S. Regular Conventional Retail Gasoline Prices  (Dollars per Gallon)
- R3: Weekly U.S. Regular Reformulated Retail Gasoline Prices  (Dollars per Gallon)
- M1: Weekly U.S. Midgrade All Formulations Retail Gasoline Prices  (Dollars per Gallon)
- M2: Weekly U.S. Midgrade Conventional Retail Gasoline Prices  (Dollars per Gallon)
- M3: Weekly U.S. Midgrade Reformulated Retail Gasoline Prices  (Dollars per Gallon)
- P1: Weekly U.S. Premium All Formulations Retail Gasoline Prices  (Dollars per Gallon)
- P2: Weekly U.S. Premium Conventional Retail Gasoline Prices  (Dollars per Gallon)
- P3: Weekly U.S. Premium Reformulated Retail Gasoline Prices  (Dollars per Gallon)
- D1: Weekly U.S. No 2 Diesel Retail Prices  (Dollars per Gallon)


### Acknowledgements

Source: U.S. Energy Information Administration (Jan 2021) 
https://www.eia.gov/dnav/pet/pet_pri_gnd_dcus_nus_w.htm

#### Copyrights and Reuse
https://www.eia.gov/about/copyrights_reuse.php

Public domain and use of EIA content

U.S. government publications are in the public domain and are not subject to copyright protection. You may use and/or distribute any of our data, files, databases, reports, graphs, charts, and other information products that are on our website or that you receive through our email distribution service. However, if you use or reproduce any of our information products, you should use an acknowledgment, which includes the publication date, such as: ""Source: U.S. Energy Information Administration (Oct 2008).""

Quoting EIA content and translations

When quoting EIA text, the acknowledgment should clearly indicate which text is EIA content and which is not. When translating EIA content into another language, please indicate the organization responsible for the translation and provide a link back to the original EIA web page in the acknowledgment.

### Inspiration

What makes the price of the diesel fluctuate so much?
",.csv
U.S. Incomes by Occupation and Gender,1,incomes-by-career-and-gender,inc_occ_gender.csv,CC0-1.0,"Many people say the gender gap in income levels is overstated in the United States, where some say that inequality in the labor force is a thing of the past. Is there a gender gap at all? Is it stronger in some industries than in others?

This dataset, retrieved from the [Bureau of Labor Statistics][1], shows the median weekly incomes for 535 different occupations. The data encompasses information for all working American citizens as of January 2015. The incomes are broken into male and female statistics, preceded by the total median income when including both genders. The data has been re-formatted from the original PDF-friendly arrangement to make it easier to clean and analyze.

Analysis thus far has found that there is indeed a sizable gender gap between male and female incomes. Use of this dataset should cite the Bureau of Labor Statistics as per their [copyright information][2]:

> The Bureau of Labor Statistics (BLS) is a Federal government agency and everything that we publish, both in hard copy and electronically, is in the public domain, except for previously copyrighted photographs and illustrations. You are free to use our public domain material without specific permission, although we do ask that you cite the Bureau of Labor Statistics as the source.


  [1]: http://www.bls.gov/cps/cpsaat39.xlsx
  [2]: http://www.bls.gov/opub/",.csv
U.S. News and World Report’s College Data,1,us-news-and-world-reports-college-data,College.csv,GPL-2.0,"### Context

Statistics for a large number of US Colleges from the 1995 issue of US News and World Report.

### Content

A data frame with 777 observations on the following 18 variables.

**Private** A factor with levels No and Yes indicating private or public university

**Apps** Number of applications received

**Accept** Number of applications accepted

**Enroll** Number of new students enrolled

**Top10perc** Pct. new students from top 10% of H.S. class

**Top25perc** Pct. new students from top 25% of H.S. class

**F.Undergrad** Number of fulltime undergraduates

**P.Undergrad** Number of parttime undergraduates

**Outstate** Out-of-state tuition

**Room.Board** Room and board costs

**Books** Estimated book costs

**Personal** Estimated personal spending

**PhD** Pct. of faculty with Ph.D.’s

**Terminal** Pct. of faculty with terminal degree

**S.F.Ratio** Student/faculty ratio

**perc.alumni** Pct. alumni who donate

**Expend** Instructional expenditure per student

**Grad.Rate** Graduation rate


### Source

This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.

The dataset was used in the ASA Statistical Graphics Section’s 1995 Data Analysis Exposition.",.csv
U.S. Renewable Energy Consumption,1,renewable-energy-consumption-in-the-u-s,dataset.csv,U.S. Government Works,"# U.S. Monthly Renewable Energy Consumption by Source and Sector (1973-2024)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F8734253%2F0fe60a09cda8f60e446422f6721e68f5%2Frenewable%20energy%20consumption%20flag.png?generation=1715139420693463&alt=media)
This dataset provides monthly data on renewable energy consumption in the United States from January 1973 to December 2024, broken down by energy source and consumption sector. The data is sourced from the U.S. Energy Information Administration (EIA).

Renewable energy has become an increasingly important part of the U.S. energy mix in recent years as the country seeks to reduce its greenhouse gas emissions and dependence on fossil fuels. This dataset allows for detailed analysis of renewable energy trends over time and across different sectors of the economy.

### IMPORTANT: Dataset Info
- Every entry that has a value of `0` means that the datapoint was either ""Not Available,"" ""No Data Reported,"" or ""Not Meaningful""
- You most likely want to exclude the column titled `Total Renewable Energy` from your comparative analysis across fuel types as it represents the sum of the others

## Columns

| Column Name                          | Description                                                                                                                                                |
|--------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------|
| `Year`                               | The calendar year of the data point                                                                                                                        |
| `Month`                              | The month number (1-12) of the data point                                                                                                                  |
| `Sector`                             | The energy consumption sector (Commercial, Electric Power, Industrial, Residential, or Transportation)                                                     |
| `Hydroelectric Power`                | Hydroelectric power consumption in the given sector and month, in trillion BTUs                                                                            |
| `Geothermal Energy`                  | Geothermal energy consumption in the given sector and month, in trillion BTUs                                                                              |
| `Solar Energy`                       | Solar energy consumption in the given sector and month, in trillion BTUs                                                                                   |
| `Wind Energy`                        | Wind energy consumption in the given sector and month, in trillion BTUs                                                                                    |
| `Wood Energy`                        | Wood energy consumption in the given sector and month, in trillion BTUs                                                                                    |
| `Waste Energy`                       | Waste energy consumption in the given sector and month, in trillion BTUs                                                                                   |
| `""Fuel Ethanol, Excluding Denaturant""` | Fuel ethanol (excluding denaturant) consumption in the given sector and month, in trillion BTUs                                                            |
| `Biomass Losses and Co-products`     | Biomass losses and co-products in the given sector and month, in trillion BTUs                                                                             |
| `Biomass Energy`                     | Total biomass energy consumption (sum of wood, waste, ethanol, and losses/co-products) in the given sector and month, in trillion BTUs                     |
| `Total Renewable Energy`             | Total renewable energy consumption (sum of hydroelectric, geothermal, solar, wind, and biomass) in the given sector and month, in trillion BTUs            |
| `Renewable Diesel Fuel`              | Renewable diesel fuel consumption in the given sector and month, in trillion BTUs                                                                          |
| `Other Biofuels`                     | Other biofuels consumption in the given sector and month, in trillion BTUs                                                                                 |
| `Conventional Hydroelectric Power`   | Conventional hydroelectric power consumption in the given sector and month, in trillion BTUs                                                               |
| `Biodiesel`                          | Biodiesel consumption in the given sector and month, in trillion BTUs                                                                                      |

## Potential Use Cases
This dataset can be used for a variety of analyses related to renewable energy in the United States, such as:

- Examining trends in renewable energy consumption over time, both overall and by specific source
- Comparing renewable energy usage across different sectors of the economy
- Forecasting future renewable energy consumption based on historical trends and projections
- Analyzing the impact of policies and incentives on renewable energy adoption
- Identifying opportunities for growth and investment in renewable energy technologies
- Studying the seasonality of renewable energy consumption and how it varies by source and sector
- Evaluating progress towards renewable energy goals and targets at the national and state level

Researchers, policymakers, industry analysts, and investors may all find value in this dataset for understanding and driving the transition to a clean energy future in the United States.

## Credits
- This data was sourced from the [U.S. Energy Information Administration](https://www.eia.gov/).
- Image credits: [Earth.Org](https://earth.org/the-present-and-future-of-renewable-energy-a-2023-update/), [Environment America](https://environmentamerica.org/articles/renewables-are-on-the-rise-in-the-united-states/)",.csv
U.S. Software Developer Salaries,1,u-s-software-developer-salaries,SofwareDeveloperIncomeExpensesperUSACity.csv,CC0-1.0,"_____
# U.S. Software Developer Salaries
### Analyzing Regional Variations
By  [[source]](https://zenodo.org/record/7412091#.Y9Y3ZNJBwUE)
_____

### About this dataset
> This dataset provides an extensive look into the financial health of software developers in major cities and metropolitan areas around the United States. We explore disparities between states and cities in terms of mean software developer salaries, median home prices, cost of living avgs, rent avgs, cost of living plus rent avgs and local purchasing power averages. Through this data set we can gain insights on how to better understand which areas are more financially viable than others when seeking employment within the software development field. Our data allow us to uncover patterns among certain geographic locations in order to identify other compelling financial opportunities that software developers may benefit from

### More Datasets
> For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).

### Featured Notebooks
> - 🚨 **Your notebook can be here!** 🚨! 

### How to use the dataset
> This dataset contains valuable information about software developer salaries across states and cities in the United States. It is important for recruiters and professionals alike to understand what kind of compensation software developers are likely to receive, as it may be beneficial when considering job opportunities or applying for a promotion. This guide will provide an overview of what you can learn from this dataset. 
>  
> The data is organized by metropolitan areas, which encompass multiple cities within the same geographical region (e.g., “New York-Northern New Jersey” covers both New York City and Newark). From there, each metro can be broken down further into a number of different factors that may affect software developer salaries in the area: 
>  
> - Mean Software Developer Salary (adjusted): The average salary of software developers in that particular metro area after accounting for cost of living differences within the region. 
> - Mean Software Developer Salary (unadjusted): The average salary of software developers in that particular metro area before adjusting for cost-of-living discrepancies between locales.   
> - Number of Software Developer Jobs: This column lists how many total jobs are available to software developers in this particular metropolitan area.  		    		     	      
> - Median Home Price: A metric which shows median value of all homes currently on the market within this partcular city or state. It helps gauge how expensive housing costs might be to potential residents who already have an idea about their income/salary range expectations when considering a move/relocation into another location or potentially looking at mortgage/rental options etc..  	      	            5) Cost Of Living Avg: A metric designed to measure affordability using local prices paid on common consumer goods like food , transportation , health care , housing & other services etc.. Also prominent here along with rent avg ,cost od living plus rent avg helping compare relative cost structures between different locations while assessing potential remunerations & risk associated with them .        6)Local Purchasing Power Avg : A measure reflecting expected difference in discretionary spending ability among households regardless their income level upon relocation due to price discrepancies across locations allows individual assessment critical during job search particularly regarding relocation as well as comparison based decision making across prospective candidates during any hiring process .               7 ) Rent Avg : Average rental costs for homes / apartments dealbreakers even among prime job prospects particularly medium income earners.(basis family size & other constraints )    8 ) Cost Of Living Plus Rent Avg : Used here as one sized fits perspective towards measuring overall cost structure including items

### Research Ideas
> - Comparing salaries of software developers in different cities to determine which city provides the best compensation package. 
> - Estimating the cost of relocating to a new city by looking at average costs such as rent and cost of living. 
> - Predicting job growth for software developers by analyzing factors like local purchasing power, median home price and number of jobs available

### Acknowledgements
> If you use this dataset in your research, please credit the original authors.
> [Data Source](https://zenodo.org/record/7412091#.Y9Y3ZNJBwUE)
> 
>


### License
> 
> 
> **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**
> No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).

### Columns

**File: SofwareDeveloperIncomeExpensesperUSACity.csv**
| Column name                                     | Description                                                                                                          |
|:------------------------------------------------|:---------------------------------------------------------------------------------------------------------------------|
| **Metro**                                       | The metropolitan area of the city. (String)                                                                          |
| **Mean Software Developer Salary (adjusted)**   | The average salary for software developers adjusted for cost of living differences between cities. (Number)          |
| **Mean Software Developer Salary (unadjusted)** | The average salary for software developers without adjusting for cost of living differences between cities. (Number) |
| **Mean Unadjusted Salary (all occupations)**    | The average salary for all occupations without adjusting for cost of living differences between cities. (Number)     |
| **Number of Software Developer Jobs**           | The number of software developer jobs in the city. (Number)                                                          |
| **Median Home Price**                           | The median home price in the city. (Number)                                                                          |
| **City**                                        | The name of the city. (String)                                                                                       |
| **Cost of Living avg**                          | The average cost of living in the city. (Number)                                                                     |
| **Rent avg**                                    | The average rent in the city. (Number)                                                                               |
| **Cost of Living Plus Rent avg**                | The average cost of living plus rent in the city. (Number)                                                           |
| **Local Purchasing Power avg**                  | The average local purchasing power in the city. (Number)                                                             |

### Acknowledgements
> If you use this dataset in your research, please credit the original authors.
> If you use this dataset in your research, please credit [](https://zenodo.org/record/7412091#.Y9Y3ZNJBwUE).

",.csv
"U.S. Suicide Rates by Sex, Race, Age, Origin.",1,u-s-suicide-rates-by-sex-race-age-origin,Death_rates_for_suicide__by_sex__race__Hispanic_origin__and_age__United_States.csv,U.S. Government Works,"This dataset provides a comprehensive view of suicide rates in the United States from 1950 onwards, categorized by demographics such as sex, race, age, and Hispanic origin. It includes both age-adjusted and crude rates per 100,000 residents, allowing for detailed trend analysis over decades. The data is broken down into various segments to help identify demographic patterns and changes in suicide rates over time. Each entry is carefully coded to facilitate complex statistical analysis and reporting.",.csv
UAE Auto Market Sales Data for Advanced Analytics,1,uae-auto-market-sales-data-for-advanced-analytics,dubizzle_cars_dataset.csv,Apache 2.0,"<h1 style=""font-family: &quot;poppins&quot;; font-weight: bold; color: rgba(0, 128, 0, 1)"">👨‍💻 Author: Azhar Saleem</h1>

[![GitHub](https://img.shields.io/badge/GitHub-Profile-blue?style=for-the-badge&logo=github)](https://github.com/azharsaleem18) [![Kaggle](https://img.shields.io/badge/Kaggle-Profile-blue?style=for-the-badge&logo=kaggle)](https://www.kaggle.com/azharsaleem) [![LinkedIn](https://img.shields.io/badge/LinkedIn-Profile-blue?style=for-the-badge&logo=linkedin)](https://www.linkedin.com/in/azhar-saleem/) 

[![YouTube](https://img.shields.io/badge/YouTube-Profile-red?style=for-the-badge&logo=youtube)](https://www.youtube.com/@AzharSaleem19) [![Facebook](https://img.shields.io/badge/Facebook-Profile-blue?style=for-the-badge&logo=facebook)](https://www.facebook.com/azhar.saleem1472/) [![TikTok](https://img.shields.io/badge/TikTok-Profile-black?style=for-the-badge&logo=tiktok)](https://www.tiktok.com/@azhar_saleem18) 

[![Twitter/X](https://img.shields.io/badge/Twitter-Profile-blue?style=for-the-badge&logo=twitter)](https://twitter.com/azhar_saleem18) [![Instagram](https://img.shields.io/badge/Instagram-Profile-blue?style=for-the-badge&logo=instagram)](https://www.instagram.com/azhar_saleem18/) [![Email](https://img.shields.io/badge/Email-Contact%20Me-red?style=for-the-badge&logo=email)](mailto:azharsaleem6@gmail.com)

## Dataset Overview
Unlock the potential of the UAE's vibrant vehicle market with our freshly scraped dataset, updated as of April 12, 2024. Derived from dubizzle.com, this primary dataset offers a comprehensive snapshot of current vehicle sales across the United Arab Emirates, providing valuable insights into automotive market trends and consumer preferences.

### Key Features of the Dataset
- **Rich Content**: Includes detailed listings of cars available for sale, offering a panoramic view of the UAE auto market.
- **Frequent Updates**: Data is freshly scraped and reflects the market status up to April 2024, making it highly relevant for current analysis.
- **Wide Coverage**: Encompasses a variety of vehicles sold across the entire UAE, making it ideal for regional market studies.

### Data Columns and Descriptions
- **Price**: The asking price of each vehicle.
- **Brand**: Manufacturer of the vehicle.
- **Model**: Specific model of the vehicle.
- **Trim**: Trim level of the vehicle, indicating different features or packages.
- **Kilometers**: Mileage of the vehicle, indicating how much it has been used.
- **Year**: Year of manufacture.
- **Vehicle Age Years**: The age of the vehicle calculated from the current year.
- **Regional Specs**: Specifications tailored to the GCC or other regions.
- **Doors**: Number of doors in the vehicle.
- **Body Type**: Type of vehicle body (e.g., SUV, hatchback).
- **Fuel Type**: Type of fuel the vehicle uses (e.g., petrol, diesel).
- **Seating Capacity**: Number of seats in the vehicle.
- **Transmission Type**: Manual or automatic transmission.
- **Engine Capacity CC**: Engine size in cubic centimeters.
- **Horsepower**: Power output of the vehicle's engine.
- **No of Cylinders**: Number of engine cylinders.
- **Exterior Color**: Color of the vehicle's exterior.
- **Interior Color**: Color of the vehicle's interior.
- **Warranty**: Indicates if the vehicle comes with a warranty.
- **Address/Country/City/Area Name/Location Name**: Detailed location information where the vehicle is sold.
- **Latitude/Longitude**: Geographical coordinates of the listed vehicle.
- **Seller Type**: Indicates if the seller is a dealership or a private individual.

### Ideal for Use In
- Market trend analysis
- Predictive analytics
- Consumer behavior studies
- Geographic analysis of vehicle sales
- Comparative studies between brands and models

Leverage this dataset to conduct thorough exploratory data analysis, develop machine learning models, or simply gain a deeper understanding of the UAE vehicle market dynamics. This dataset serves as a perfect starting point for anyone looking to delve into automotive sales analytics.
",.csv
UBER Stock Data,1,uber-stock-data,UBER.csv,other,"## What is UBER?
Uber Technologies, Inc., commonly known as Uber, is an American technology company. Its services include ride-hailing, food delivery (Uber Eats and Postmates), package delivery, couriers, freight transportation, and, through a partnership with Lime, electric bicycle and motorized scooter rental. The company is based in San Francisco and has operations in over 900 metropolitan areas worldwide. It is one of the largest firms in the gig economy. Uber is estimated to have over 93 million monthly active users worldwide. In the United States, Uber has a 71% market share for ride-sharing and a 22% market share for food delivery. Uber has been so prominent in the sharing economy that changes in various industries as a result of Uber have been referred to as uberisation, and many startups have described their offerings as ""Uber for X"".

## Information about this dataset
This dataset provides historical data of Uber Technologies, Inc. (UBER). The data is available at a daily level. Currency is USD.",.csv
UCI ML Datasets,1,uci-ml-datasets,hou_all.csv,DbCL-1.0,"# Context 

This is a Data Set from UCI Machine Learning Repository which concerns housing values in suburbs of Boston.


# Content

Number of Instances: 506

Attribute Information:

1. CRIM: per capita crime rate by town
2. ZN: proportion of residential land zoned for lots over 25,000 sq.ft.
3. INDUS: proportion of non-retail business acres per town
4. CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)
5. NOX: nitric oxides concentration (parts per 10 million)
6. RM: average number of rooms per dwelling
7. AGE: proportion of owner-occupied units built prior to 1940
8. DIS: weighted distances to five Boston employment centres
9. RAD: index of accessibility to radial highways
10. TAX: full-value property-tax rate per $10,000
11. PTRATIO: pupil-teacher ratio by town
12. B: 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town
13. LSTAT: % lower status of the population
14. MEDV: Median value of owner-occupied homes in $1000's

Missing Attribute Values:  None

# Acknowledgements

Source: https://archive.ics.uci.edu/ml/datasets/Housing
Origin: This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University. 
Creator:
Harrison, D. and Rubinfeld, D.L.
'Hedonic prices and the demand for clean air', J. Environ. Economics & Management, vol.5, 81-102, 1978.",.csv
UCI SECOM Dataset,1,uci-semcom,uci-secom.csv,DbCL-1.0,"### Context
Manufacturing process feature selection and categorization

### Content
Abstract: Data from a semi-conductor manufacturing process

- Data Set Characteristics: Multivariate 
- Number of Instances: 1567
- Area: Computer 
- Attribute Characteristics: Real 
- Number of Attributes: 591 
- Date Donated: 2008-11-19 
- Associated Tasks: Classification, Causal-Discovery 
- Missing Values? Yes

A complex modern semi-conductor manufacturing process is normally under consistent 
surveillance via the monitoring of signals/variables collected from sensors and or 
process measurement points. However, not all of these signals are equally valuable 
in a specific monitoring system. The measured signals contain a combination of 
useful information, irrelevant information as well as noise. It is often the case 
that useful information is buried in the latter two. Engineers typically have a 
much larger number of signals than are actually required. If we consider each type 
of signal as a feature, then feature selection may be applied to identify the most 
relevant signals. The Process Engineers may then use these signals to determine key 
factors contributing to yield excursions downstream in the process. This will 
enable an increase in process throughput, decreased time to learning and reduce the 
per unit production costs.

To enhance current business improvement techniques the application of feature 
selection as an intelligent systems technique is being investigated.

The dataset presented in this case represents a selection of such features where 
each example represents a single production entity with associated measured 
features and the labels represent a simple pass/fail yield for in house line 
testing, figure 2, and associated date time stamp. Where .1 corresponds to a pass 
and 1 corresponds to a fail and the data time stamp is for that specific test 
point.


Using feature selection techniques it is desired to rank features according to 
their impact on the overall yield for the product, causal relationships may also be 
considered with a view to identifying the key features.

Results may be submitted in terms of feature relevance for predictability using 
error rates as our evaluation metrics. It is suggested that cross validation be 
applied to generate these results. Some baseline results are shown below for basic 
feature selection techniques using a simple kernel ridge classifier and 10 fold 
cross validation.

Baseline Results: Pre-processing objects were applied to the dataset simply to 
standardize the data and remove the constant features and then a number of 
different feature selection objects selecting 40 highest ranked features were 
applied with a simple classifier to achieve some initial results. 10 fold cross 
validation was used and the balanced error rate (*BER) generated as our initial 
performance metric to help investigate this dataset.


SECOM Dataset: 1567 examples 591 features, 104 fails

FSmethod (40 features) BER % True + % True - %
S2N (signal to noise) 34.5 +-2.6 57.8 +-5.3 73.1 +2.1
Ttest 33.7 +-2.1 59.6 +-4.7 73.0 +-1.8
Relief 40.1 +-2.8 48.3 +-5.9 71.6 +-3.2
Pearson 34.1 +-2.0 57.4 +-4.3 74.4 +-4.9
Ftest 33.5 +-2.2 59.1 +-4.8 73.8 +-1.8
Gram Schmidt 35.6 +-2.4 51.2 +-11.8 77.5 +-2.3

-----------------------------------------------------

Attribute Information:

Key facts: Data Structure: The data consists of 2 files the dataset file SECOM 
consisting of 1567 examples each with 591 features a 1567 x 591 matrix and a labels 
file containing the classifications and date time stamp for each example.

As with any real life data situations this data contains null values varying in 
intensity depending on the individuals features. This needs to be taken into 
consideration when investigating the data either through pre-processing or within 
the technique applied.

The data is represented in a raw text file each line representing an individual 
example and the features seperated by spaces. The null values are represented by 
the 'NaN' value as per MatLab.

### Acknowledgements
Authors: Michael McCann, Adrian Johnston 

### Inspiration

- Semiconductor manufacturing has multi dimensional description of each process. Can we find key performance index by using big data techniques?",.csv
UEFA Champions League All Finals (1955 - 2023),1,uefa-champions-league-all-finals-1955-2023,ucl-finals.csv,CC0-1.0,"The source of the data is [here](https://en.wikipedia.org/wiki/List_of_European_Cup_and_UEFA_Champions_League_finals)

The data has these features:

- season: The years of the season, i.e. 1976-77
- winner-country: The country of winner team
- winner: The name of the winner club
- score: Final match score 1973-74 season has 2 matches, so there are two scores in separated with semicolon form 
- runner-up: The name of the runner up club
- runner-up-country: The country of the runner up team
- stadium: The stadium which final match was played
- final-city: The city where the stadium is located
- final-country: The country where the city is located
- attendance: The attendance in final match, 1973-74 season has 2 matches, so there are two attendances data in separated with semicolon form
- winning-way: normal time or extra time or penalty
",.csv
UFC Fight Data,1,ufcdataset,data.csv,CC0-1.0,"# Context 
List of all UFC fights since 2013 with summed up entries of each fighter's round by round record preceding that fight. Created in the attempt to create a UFC fight winner predictor. Dataset may not be great, I'm still new to this thing so appreciate any tips on cleaning up the set. 

# Content
Each row represents a single fight - with each fighter's previous records summed up  prior to the fight. blank stats mean its the fighter's first fight since 2013 which is where granular data for UFC fights beings

# Acknowledgements

https://github.com/valish/ufc-api for the UFC api 
Beautifulsoup and it's creators and Hitkul my partner in crime


# Inspiration

Can we draw decent predictions from this dataset?",.csv
UFC Fighters' Statistics Dataset,1,ufc-fighters-statistics,ufc-fighters-statistics.csv,ODC Attribution License (ODC-By),"Mixed Martial Arts (MMA) is a popular combat sport, and the Ultimate Fighting Championship (UFC) is the premier organization in the MMA world. 

This dataset provides detailed statistics of UFC fighters, including information on their wins, losses, draws, physical attributes, fighting style, and career achievements.

&gt; If you find this dataset valuable, don't forget to hit the upvote button! 😊💝

## Interesting Task Ideas:

1. Analyze the relationship between fighters' physical attributes (height, weight, reach) and their fighting performance.
2. Determine which stances are more effective and analyze the impact of striking accuracy on fight outcomes.
3. Compare the takedown defense of different fighters and identify trends in takedown accuracy.
4. Analyze striking accuracy and defense to identify fighters with the best stand-up game.
5. Investigate the correlation between takedown accuracy and the ability to defend against takedowns.
6. Identify fighters with high submission attempt rates and explore their success in executing submissions.
7. Train models to predict fight outcomes based on fighter statistics.

---

Photo by <a href=""https://unsplash.com/@dylan_nolte?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">dylan nolte</a> on <a href=""https://unsplash.com/photos/person-wrapping-bandage-qxYDhV0rBPk?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv
UK Fuel prices ,1,uk-fuel-price-weekly-statistics20032020,fuel price.csv,other,"### Context

Fuel Prices are often reflective of the political and economic state of a country,  BREXIT and COVID are  major events that took place recently, so I thought why don't we look into the Fuel Prices  of the UK so that we can derive some insights, this dataset  is also a very good place to practice your exploratory data analytical skills as this is a very simple dataset


### Content

It is a very simple dataset to both explore and understand the columns are themselves descriptive in nature
the only abbreviaation that you must understand is
ULSP = Ultra low sulpur unleaded petrol, ULSD = Ultra low sulphur diesel


### Acknowledgements
SOURCE:

https://www.gov.uk/government/statistical-data-sets


### Inspiration

Just Explore the dataset, practice your skills using this really simple real world dataset

### License
http://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/",.csv
UK MET Office Weather Data,1,uk-met-office-weather-data,MET Office Weather Data.csv,other,"### Copyright Notice & Acknowledgements

All information regarding MET Office copyright policy can be found at: [https://www.metoffice.gov.uk/about-us/legal#licences](https://www.metoffice.gov.uk/about-us/legal#licences)
All data was sourced from: [https://www.metoffice.gov.uk/research/climate/maps-and-data/historic-station-data](https://www.metoffice.gov.uk/research/climate/maps-and-data/historic-station-data)

### Context

The MET Office has been responsible for monitoring UK Weather since it's inception in 1854. 36 stations in the UK (often located in RAF bases) gather information that is used to predict future weather patterns and issue public advice. More recently, these large datasets have become useful to investigate how the UK climate has changed over the past 150+ years.


### Content

Columns:
- **year**: Year in which the measurements were taken
- **month**: Month in which the measurements were taken
- **tmax**: Mean daily maximum temperature (°C)
- **tmin**: Mean daily minimum temperature (°C)
- **af**: Days of air frost recorded that month (days)
- **rain**: Total rainfall (mm)
- **sun**: Total sunshine duration (hours)
- **station**: Station location where measurement was recorded

Data was collected from the MET Office website as separate station csv files and combined to one data frame with a station label assigned. All characters (*,#,---) that denoted things such as the equipment used were removed from the set. Some sections include significant amounts of NA values. Note that a 0 entry does not denote an NA value but a score of 0 in that measured field.

### Inspiration

Has the UK climate changed since the Victorian era?
How does any climate change impact the UK in terms of weather risks?
Are some regions more affected than others?

A good starting point: The monthly mean temperature is calculated from the average of the mean daily maximum and mean daily minimum temperature i.e. (tmax+tmin)/2.",.csv
UN Global Water Data 2012-2022,1,un-global-water-data-2012-2022,water.csv,Attribution 3.0 IGO (CC BY 3.0 IGO),"**Dataset Overview:**
The ""UN Global Water Data 2012-2022"" dataset compiles global water access and sanitation metrics, highlighting changes over a decade.

**Data Science Applications:**
Useful for predictive modeling, geographic analysis, and trend visualization in water access and public health sectors. Further data will require cleaning to remove null columns etc .

**Column Descriptors:**
- DATAFLOW: Data collection framework
- REF_AREA: Geographic area covered
- INDICATOR: Specific metric measured
- SEX: Gender breakdown, if applicable
- TIME_PERIOD: Year of data collection
- OBS_VALUE: The observed value or measurement
- UNIT_MEASURE: Units of measurement used
- Additional columns include details on data sources, observation status, and methodological notes.

**Ethically Collected Data:**
Ensures adherence to ethical standards in data collection, respecting privacy and consent.

**Acknowledgments:**
Thanks to UNICEF Data Warehouse for providing this dataset. Explore more at [UNICEF Data Explorer](https://data.unicef.org/resources/data_explorer/unicef_f/?ag=UNICEF&df=GLOBAL_DATAFLOW&ver=1.0&dq=.WS_HCF_WM-N+WS_HCF_W-B+WS_HCF_W-L+WS_HCF_W-N+WS_PPL_W-SM+WS_PPL_S-SEW+WS_PPL_W-UI+WS_PPL_S-WWT+WS_PPL_W-B+WS_PPL_W-QUA+WS_PPL_W-I+WS_PPL_W-ALB+WS_PPL_S-DIS+WS_PPL_H-N+WS_PPL_S-LAT+WS_PPL_W-PRE+WS_PPL_W-L+WS_PPL_S-SEP+WS_PPL_W-P+WS_PPL_S-B+WS_PPL_S-SM+WS_PPL_S-L+WS_PPL_S-FST+WS_PPL_W-AVA+WS_PPL_W-NP+WS_PPL_W-SW+WS_PPL_H-B+WS_PPL_S-I+WS_SCH_H-L+WS_SCH_S-B+WS_SCH_H-N+WS_SCH_S-L+WS_SCH_W-B+WS_SCH_S-N+WS_SCH_W-L+WS_SCH_W-N+WS_SCH_H-B..&startPeriod=2012&endPeriod=2023).

Also thank you to the Daily News archives for the dataset image used here [article](https://archives1.dailynews.lk/2019/04/12/local/183064/salty-tap-water-50000-families-kalutara).",.csv
UPI Transactions Dataset,1,upi-transactions-dataset,MyTransaction.csv,Apache 2.0,"The dataset provided encompasses a comprehensive record of Unified Payments Interface (UPI) transactions spanning the period from January 2023 to December 2023. Unified Payments Interface (UPI) has emerged as a prominent digital payment system in India, facilitating seamless fund transfers between bank accounts instantly.


Columns Descriptions:

1. Date : The date on which the transaction occurred.
2. Category : The category or type of transaction (e.g., groceries, utilities, transportation).
3. RefNo : The reference number associated with the transaction for tracking and identification purposes.
4. Withdrawal : The amount withdrawn from the account in the transaction.
5. Deposit : The amount deposited into the account in the transaction.
6. Balance : The remaining balance in the account after the transaction has been processed.
",.csv
"US Births 👶 by Year, State, and Education Level",1,temporary-us-births,us_births_2016_2021.csv,CC0-1.0,"## Introduction
This dataset provides birth rates and related data across the 50 states and DC from 2016 to 2021. The data was sourced from the Centers for Disease Control and Prevention (CDC) and includes detailed information such as number of births, gender, birth weight, state, and year of the delivery. A particular emphasis is given to detailed information on the mother's educational level. With this dataset, one can, for example, examine trends and patterns in birth rates across different academic groups and geographic locations. 

## Important Note
Each row in the dataset is considered a category defined by the state, birth year, baby's gender, and educational level of the mother. Three quantities are given for each category: number of births, mother's average age, and average baby weight. The CDC is sensitive to potentially disclosing personal information, so any category with less than ten births is suppressed. For this reason, you will find 12 rows missing out of an expected 5,508
$$ \text{51 states * 6 years * 2 genders * 9 edu levels = 5,508} $$
Those missing rows all had the mother's educational level listed as ""unknown or not stated"" and their absence should not significantly impact studies or conclusions made using the dataset.

## Origin
The data in this dataset was obtained using CDC's WONDER retrieval tool on the [CDC Natality](https://wonder.cdc.gov/natality-current.html) page



## Column Descriptions
- **State** ➡️ state name in full (includes District of Columbia)
- **State Abbreviation** ➡️ 2-character state abbreviation
- **Year** ➡️ 4-digit year
- **Gender** ➡️ Gender of baby
- **Education Level of Mother** ➡️ See table below
- **Education Level Code** ➡️ See table below
- **Number of Births** ➡️ Number of births for the category
- **Average Age of Mother (years)** ➡️ Mother's average age in the category
-  **Average Birth Weight (g)** ➡️ Average birth weight in the category
<br>
## Education levels and codes used in dataset
| Code | Mother's Education Level |
|:--- |:--- |
|1 |8th grade or less |
|2 |9th through 12th grade with no diploma |
|3 |High school graduate or GED completed  |
|4 |Some college credit, but not a degree  |
|5 |Associate degree (AA, AS)        |
|6 |Bachelor's degree (BA, AB, BS)    |
|7 |Master's degree (MA, MS, MEng, MEd, MSW, MBA) |
|8 |Doctorate (PhD, EdD) or Professional Degree (MD, DDS, DVM, LLB, JD) |
|-9 |Unknown or Not Stated |

## Acknowledgement
Image by <a href=""https://pixabay.com/users/sarahrichterart-1546275/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=3058712"">Sarah Richter</a> from <a href=""https://pixabay.com//?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=3058712"">Pixabay</a>",.csv
US Candy Production by Month,1,us-candy-production-by-month,candy_production.csv,CC0-1.0,"### Context: 

Halloween begins frenetic candy consumption that continues into the Christmas holidays and New Year’s Day, when people often make (usually short-lived) resolutions to lose weight. But all this consumption first needs production. The graph shows the relevant data from the industrial production index and its stunning seasonality

### Content: 

The industrial production (IP) index measures the real output of all relevant establishments located in the United States, regardless of their ownership, but not those located in U.S. territories. This dataset tracks industrial production every month from January 1972 to August 2017. 

### Acknowledgements: 

Board of Governors of the Federal Reserve System (US), Industrial Production: Nondurable Goods: Sugar and confectionery product [IPG3113N], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/IPG3113N, October 13, 2017.

### Inspiration: 

* Can you correct for the seasonality in this data?
* Which months have the highest candy production?
* Can you predict production for September through December 2017?
",.csv
US Cars Dataset,1,usa-cers-dataset,USA_cars_datasets.csv,other,"### Context
US Cars'data was scraped from AUCTION EXPORT.com. This dataset included Information about 28 brands of clean and used vehicles for sale in US. Twelve features were assembled for each car in the dataset.


### Content
 - This dataset includes 12 features:

|Feature|Type|Description|
|-------|---|---|
|Price|Integer|The sale price of the vehicle in the ad| 
|Years|Integer|The vehicle registration year| 
|Brand|String|The brand of car|
|Model|String|model of the vehicle|
|Color|String|Color of the vehicle|
|State/City|String|The location in which the car is being available for purchase| 
|Mileage|Float|miles traveled by vehicle|
|Vin|String|The vehicle identification number is a collection of 17 characters (digits and capital letters)|
|Title Status|String|This feature included binary classification, which are clean title vehicles and salvage insurance|
|Lot|Integer|A lot number is an identification number assigned to a particular quantity or lot of material from a single manufacturer.For cars, a lot number is combined with a serial number to form the Vehicle Identification Number.
|
|Condition|String|Time|


### Acknowledgements

I would like to thank my colleague Waleed and my GA instructors( Husain M. Al-Amer, Muhammad Irfan Mohamed Noordin, Amjad K. Alsulami, Yazeid Alqahtani) for keeping up with my complaints and pushing me to work harder. Also, I would like to thank my friends for supporting me.
",.csv
US Company Bankruptcy Prediction Dataset,1,american-companies-bankruptcy-prediction-dataset,american_bankruptcy.csv,CC0-1.0,"```
A novel dataset for bankruptcy prediction related to American public companies listed on the New York Stock Exchange and NASDAQ is provided. The dataset comprises accounting data from 8,262 distinct companies recorded during the period spanning from 1999 to 2018.

According to the Security Exchange Commission (SEC), a company in the American market is deemed bankrupt under two circumstances. Firstly, if the firm's management files for Chapter 11 of the Bankruptcy Code, indicating an intention to ""reorganize"" its business. In this case, the company's management continues to oversee day-to-day operations, but significant business decisions necessitate approval from a bankruptcy court. Secondly, if the firm's management files for Chapter 7 of the Bankruptcy Code, indicating a complete cessation of operations and the company going out of business entirely.

In this dataset, the fiscal year prior to the filing of bankruptcy under either Chapter 11 or Chapter 7 is labeled as ""Bankruptcy"" (1) for the subsequent year. Conversely, if the company does not experience these bankruptcy events, it is considered to be operating normally (0). The dataset is complete, without any missing values, synthetic entries, or imputed added values.

The resulting dataset comprises a total of 78,682 observations of firm-year combinations. To facilitate model training and evaluation, the dataset is divided into three subsets based on time periods. The training set consists of data from 1999 to 2011, the validation set comprises data from 2012 to 2014, and the test set encompasses the years 2015 to 2018. The test set serves as a means to assess the predictive capability of models in real-world scenarios involving unseen cases.
```
| Variable Name           | Description                                                                                               |
|-------------------------|-----------------------------------------------------------------------------------------------------------|
| X1                      | Current assets - All the assets of a company that are expected to be sold or used as a result of standard |
|                         | business operations over the next year                                                                    |
| X2                      | Cost of goods sold - The total amount a company paid as a cost directly related to the sale of products  |
| X3                      | Depreciation and amortization - Depreciation refers to the loss of value of a tangible fixed asset over   |
|                         | time (such as property, machinery, buildings, and plant). Amortization refers to the loss of value of    |
|                         | intangible assets over time.                                                                              |
| X4                      | EBITDA - Earnings before interest, taxes, depreciation, and amortization. It is a measure of a company's  |
|                         | overall financial performance, serving as an alternative to net income.                                   |
| X5                      | Inventory - The accounting of items and raw materials that a company either uses in production or sells.  |
| X6                      | Net Income - The overall profitability of a company after all expenses and costs have been deducted from |
|                         | total revenue.                                                                                            |
| X7                      | Total Receivables - The balance of money due to a firm for goods or services delivered or used but not    |
|                         | yet paid for by customers.                                                                                |
| X8                      | Market value - The price of an asset in a marketplace. In this dataset, it refers to the market          |
|                         | capitalization since companies are publicly traded in the stock market.                                  |
| X9                      | Net sales - The sum of a company's gross sales minus its returns, allowances, and discounts.              |
| X10                     | Total assets - All the assets, or items of value, a business owns.                                        |
| X11                     | Total Long-term debt - A company's loans and other liabilities that will not become due within one year    |
|                         | of the balance sheet date.                                                                                |
| X12                     | EBIT - Earnings before interest and taxes.                                                                 |
| X13                     | Gross Profit - The profit a business makes after subtracting all the costs that are related to             |
|                         | manufacturing and selling its products or services.                                                       |
| X14                     | Total Current Liabilities - The sum of accounts payable, accrued liabilities, and taxes such as Bonds     |
|                         | payable at the end of the year, salaries, and commissions remaining.                                      |
| X15                     | Retained Earnings - The amount of profit a company has left over after paying all its direct costs,        |
|                         | indirect costs, income taxes, and its dividends to shareholders.                                          |
| X16                     | Total Revenue - The amount of income that a business has made from all sales before subtracting expenses.  |
|                         | It may include interest and dividends from investments.                                                   |
| X17                     | Total Liabilities - The combined debts and obligations that the company owes to outside parties.          |
| X18                     | Total Operating Expenses - The expenses a business incurs through its normal business operations.          |
",.csv
US Cost of Living Dataset (1877 Counties),1,us-cost-of-living-dataset-3171-counties,cost_of_living_us.csv,CC0-1.0,"The US Family Budget Dataset provides insights into the cost of living in different US counties based on the Family Budget Calculator by the Economic Policy Institute (EPI). 

This dataset offers community-specific estimates for ten family types, including one or two adults with zero to four children, in all 1877 counties and metro areas across the United States.

## Interesting Task Ideas:

1. See how family budgets compare to the federal poverty line and the Supplemental Poverty Measure in different counties.
2. Look into the money challenges faced by different types of families using the budgets provided.
3. Find out which counties have the most affordable places to live, food, transportation, healthcare, childcare, and other things people need.
4. Explore how the average income of families relates to the overall cost of living in different counties.
5. Investigate how family size affects the estimated budget and find counties where bigger families have higher costs.
6. Create visuals showing how the cost of living varies across different states and big cities.
7. Check whether specific counties are affordable for families of different sizes and types.
8. Use the dataset to compare living standards and economic security in different US counties.

---

If you find this dataset valuable, don't forget to hit the upvote button! 😊💝 

---

### Checkout my other datasets

[Employment-to-Population Ratio for USA ](https://www.kaggle.com/datasets/asaniczka/employment-to-population-ratio-for-usa-1979-2023)

[Productivity and Hourly Compensation ](https://www.kaggle.com/datasets/asaniczka/productivity-and-hourly-compensation-1948-2021)

[130K Kindle Books](https://www.kaggle.com/datasets/asaniczka/amazon-kindle-books-dataset-2023-130k-books)

[900K TMDb Movies](https://www.kaggle.com/datasets/asaniczka/tmdb-movies-dataset-2023-930k-movies)

[USA Unemployment Rates by Demographics & Race](https://www.kaggle.com/datasets/asaniczka/unemployment-rates-by-demographics-1978-2023)

---

Photo by [Alev Takil](https://unsplash.com/@alevisionco?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash) on [Unsplash](https://unsplash.com/photos/-6f5q7-Cw_g?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)

",.csv
US Data Science and Analytics Master's Programs,1,us-data-science-and-analytics-masters-programs,ds_masters_usa.csv,CC0-1.0,"This dataset provides comprehensive information about various Data Science and Analytics master's programs offered in the United States. It includes details such as the program name, university name, annual tuition fees, program duration, location of the university, and additional information about the programs.

**Column Descriptions:**

- `Subject Name:` The name or field of study of the master's program, such as Data Science, Data Analytics, or Applied Biostatistics.

- `University Name:` The name of the university offering the master's program.

- `Per Year Fees:` The tuition fees for the program, usually given in euros per year. For some programs, the fees may be listed as ""full"" or ""full-time,"" indicating a lump sum for the entire program or for full-time enrollment, respectively.

- `About Program:` A brief description or overview of the master's program, providing insights into its curriculum, focus areas, and any unique features.

- `Program Duration:` The duration of the master's program, typically expressed in years or months.

- `University Location:` The location of the university where the program is offered, including the city and state.

- `Program Name:` The official name of the master's program, often indicating its degree type (e.g., M.Sc. for Master of Science) and format (e.g., full-time, part-time, online).",.csv
US Economic Data,1,us-economic-data,fredmeta.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"Data was collected from the FRED website.

Contains economic indicators often associated with recessions along with recession status data. Data collected on smallest time unit and earliest time date available for each indicator which results in many nulls but increased flexibility for the users of this dataset.

- recession: ""1"" recessionary period, ""0"" non-recessionary period (Monthly)
- cpi: CPI (1982-1984=INDEX 100) (Monthly)
- gdp: Real GDP Billions of Chained 2017 Dollars (Quarterly)
- unemployment: Unemployment Rate (Monthly)
- m2: M2 Billions of Dollars (Monthly)
- fed_funds: Federal Funds Rate (Monthly)
- ten_two: 10-Year Treasury Constant Maturity Minus 2-Year Treasury Constant Maturity (Monthly)
- residential: Real Residential Property Price Rate (Quarterly)

Comprehensive description of each variable can be found at&nbsp;https://fred.stlouisfed.org/",.csv
US Fast Food Chains - Franchise & Revenue Info,1,top50fastfood,top_50_fast_food_US.csv,other,"Small, clean dataset for learning purposes. 

Data sourced from QSR Magazine, a business-to-business magazine in the quick service restaurant industry. This dataset includes the top 50 fast food chains in the U.S. in 2020. Contains information on the total sales, sales per unit, franchise units, company owned units, and unit change from 2018.  

Columns include:
- Company Name
- Category (pizza, burger, etc)
- Sales in Millions (2019)
- Sales Per Unit in Thousands (2019)
- # of Franchised Units (2019)
- # of Company Owned Units (2019)
- # of Total Units (2019)
- Unit # Change from 2018",.csv
US Food Imports 2023-1999,1,us-food-imports-2024-1999,US food imports 1999-23.csv,CC0-1.0,"This dataset offers a comprehensive overview of US food imports spanning over two decades, sourced from the US Department of Commerce and the US Census Bureau. It provides valuable insights into the evolving landscape of consumer preferences, economic dynamics, and international trade patterns shaping the US food market. Analysts can explore trends in specific food categories, identify key trading partners, and track long-term growth patterns in the importation of edible products.
![
](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F6286349%2Ff1b0250d74193e5c32659cf06ce6fac3%2FScreenshot%202024-04-24%20194742.png?generation=1713981061063682&alt=media)

## Column Information:

- Column 1: Rank
- Column 2: Country
- Column 3: Measurement Unit (e.g., Million dollars, 1,000 metric tons)
- Columns 4 to 27: Import values for each year from 1999 to 2023, representing the calendar years for food imports.",.csv
US Health Insurance Dataset,1,ushealthinsurancedataset,insurance.csv,CC0-1.0,"### Context

The venerable insurance industry is no stranger to data driven decision making. Yet in today's rapidly transforming digital landscape, Insurance is struggling to adapt and benefit from new technologies compared to other industries, even within the BFSI sphere (compared to the Banking sector for example.) Extremely complex underwriting rule-sets that are radically different in different product lines, many non-KYC environments with a lack of centralized customer information base, complex relationship with consumers in traditional risk underwriting where sometimes customer centricity runs reverse to business profit, inertia of regulatory compliance  - are some of the unique challenges faced by Insurance Business.

Despite this, emergent technologies like AI and Block Chain have brought a radical change in Insurance, and Data Analytics sits at the core of this transformation. We can identify 4 key factors behind the emergence of Analytics as a crucial part of InsurTech:

 - **Big Data:** The explosion of unstructured data in the form of images, videos, text, emails, social media
 - **AI:** The recent advances in Machine Learning and Deep Learning that can enable businesses to gain insight, do predictive analytics and build cost and time - efficient innovative solutions
 - **Real time Processing:** Ability of real time information processing through various data feeds (for ex. social media, news)
 - **Increased Computing Power:** a complex ecosystem of new analytics vendors and solutions that enable carriers to combine data sources, external insights, and advanced modeling techniques in order to glean insights that were not possible before.

This dataset can be helpful in a simple yet illuminating study in understanding the risk underwriting in Health Insurance, the interplay of various attributes of the insured and see how they affect the insurance premium.

### Content

This dataset contains 1338 rows of insured data, where the Insurance charges are given against the following attributes of the insured: Age, Sex, BMI, Number of Children, Smoker and Region. There are no missing or undefined values in the dataset.

### Inspiration

This relatively simple dataset should be an excellent starting point for EDA, Statistical Analysis and Hypothesis testing and training Linear Regression models for predicting Insurance Premium Charges.

Proposed Tasks:
 - Exploratory Data Analytics
 - Statistical hypothesis testing
 - Statistical Modeling
 - Linear Regression",.csv
US Holiday Dates (2004 - 2021),1,us-holiday-dates-2004-2021,US Holiday Dates (2004-2021).csv,CC0-1.0,"### Context

The purpose of this dataset is to identify how holidays impact Americans Behavior.

### Content
This list of holidays includes 18 years of US Holidays dated between January 1st, 2004 and December 31st, 2021. Each record has Date, Holiday, Weekday, Month, Day and Year. 

Included Holidays
 - 4th of July
 - Christmas Eve & Christmas Day
 - Columbus Day
 - Eastern & Western Easter
 - Juneteenth
 - Labor Day & Labor Day Weekend
 - Martin Luther King, Jr. Day
 - Memorial Day
 - New Year’s Eve & New Year's Day
 - Thanksgiving Eve & Thanksgiving Day
 - Valentine’s Day
 - Veterans Day
 - Washington's Birthday

### Acknowledgements

Original Source  'Federal Holidays USA 1966-2020' https://www.kaggle.com/gsnehaa21/federal-holidays-usa-19662020

",.csv
US Honey Production 1995-2021,1,us-honey-production-19952021,US_honey_dataset_updated.csv,CC0-1.0,"Honey is the natural product made by bees—one of our planet's most important species. Honey bees visit millions of blossoms in their lifetimes, making pollination of plants possible and collecting nectar to bring back to the hive to produce honey.

Honey bees use honey as their primary energy source and their instinct is to make more than their colony needs. Beekeepers harvest the excess and bottle it for consumption, just like they’ve been doing since the beginning of time. Harvesting honey is good for the bees and also part of what makes successful beekeeping businesses.

This dataset provides insights into honey production, demand, and supply across different states of America. ",.csv
US Household Income Statistics,1,us-household-income-stats-geo-locations,kaggle_income.csv,other,"### New Upload:
Added +32,000 more locations. For information on data calculations please refer to the methodology pdf document. Information on how to calculate the data your self is also provided as well as how to buy data for $1.29 dollars.

### What you get:
The database contains 32,000 records on US Household Income Statistics & Geo Locations. The field description of the database is documented in the attached pdf file. **To access, all 348,893 records on a scale roughly equivalent to a neighborhood (census tract) see link below** and *make sure to up vote*. Up vote right now, please. *Enjoy*!


###Household & Geographic Statistics:


 - Mean Household Income (double)
 - Median Household Income (double)
 - Standard Deviation of Household Income (double)
 - Number of Households (double) 
 - Square area of land at location (double) 
 - Square area of water at location (double) 


###Geographic Location:

 - Longitude (double)
 - Latitude (double)
 - State Name (character)
 - State abbreviated (character) 
 - State_Code (character) 
 - County Name (character)
 - City Name (character)
 - Name of city, town, village or CPD  (character)
 - Primary, Defines if the location is a track and block group.
 - Zip Code (character)
 - Area Code (character)                      


### Abstract
The dataset originally developed for real estate and business investment research. Income is a vital element when determining both quality and socioeconomic features of a given geographic location. The following data was derived from over **+36,000 files** and covers 348,893 location records.

### License
Only proper citing is required please see the documentation for details.
Have Fun!!!

Golden Oak Research Group, LLC. “U.S. Income Database Kaggle”. Publication: 5, August 2017. Accessed, day, month year.

### Sources, don't have 2 dollars? Get the full information yourself!
2011-2015 ACS 5-Year Documentation was provided by the U.S. Census Reports. Retrieved August 2, 2017, from https://www2.census.gov/programs-surveys/acs/summary_file/2015/data/5_year_by_state/

###Found Errors?
Please tell us so we may provide you the most accurate data possible. You may reach us at:  research_development@goldenoakresearch.com 

for any questions you can reach me on at 585-626-2965


*please note: it is my personal number and email is preferred*

Check our data's accuracy:
[Census Fact Checker][1]


###Access all 348,893 location records and more:
**Don't settle. Go big and win big.  Optimize your potential. Overcome limitation and outperform expectation**. *Access all household income records on a scale roughly equivalent to a neighborhood, see link below*:


*Website*: [Golden Oak Research][2] *Kaggle Deals all databases $1.29 Limited time only*


A small startup with big dreams, giving the every day, up and coming data scientist professional grade data at affordable prices It's what we do. 

  [1]: https://factfinder.census.gov/
  [2]:https://www.goldenoakresearch.com/shop/",.csv
US Immigration Statistics (1980-2021),1,us-immigration-statistics-1980-2021,US Immigration Statistics (Ver 1.7.23).csv,CC-BY-NC-SA-4.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F12064410%2F468b9ab69fbaa3eea94ab7c13537052f%2Fimmigration%20flag.png?generation=1673145948097950&alt=media)

# 15,341 DAYS (October 1st, 1979 - September 30th, 2021)
This is a dataset that describes annual statistics regarding US immigration between the 1980-2021 fiscal years.

All data are **official** figures from the Department of Homeland Security's government website that have been compiled and structured by myself. There are several reasons for the decision to only examine immigration data from 1980 to 2021. Since 1976, a fiscal year for the US government has always started on October 1st and ended the following year on September 30th. If the years prior to 1976 were included, the data may be incorrectly represented and cause further confusion for viewers. Additionally, the United States only tracked refugee arrivals after the Refugee Act of 1980, a statistic that is prominently featured in the dataset. As a result, the start date of 1980 was chosen instead of 1976. 

# Data Sources
##### The primary data sources used were the ""Yearbook of Immigration Statistics"" webpages from the Department of Homeland Security. As a whole, the website not only provided figures about US immigration that were perfect for making time series analyses, but also explored the logistics behind the annual trends found.

1. [The Department of Homeland Security's 2021 Yearbook of Immigration Statistics](https://www.dhs.gov/immigration-statistics/yearbook/2021) - The Office of Immigration Statistics' 2021 Flow Reports and Population Estimates provide text, tables, and charts on lawful permanent residents, refugees and asylees, nonimmigrant admissions, naturalizations, enforcement actions, and the unauthorized population. Being the latest version released to date, the 2021 yearbook is the most comprehensive report publicly available and tends to feature data of past years for reference.
2. [The Department of Homeland Security's Directory of Past Immigration Yearbooks](https://www.dhs.gov/immigration-statistics/yearbook) - Past yearbooks were referenced in order to find the missing data from the fiscal years during 2000-2021. There is a single yearbook covering the fiscal years during 1996-1999, but that was the oldest publications featured in the directory.
3. [The Center for Immigration Studies's File Library](https://cis.org/) - In order to procure immigration data during the fiscal years of 1980-1999, I found free versions of the Immigration and Naturalization Service's paywalled yearbooks from the Center for Immigration Studies. By doing so, I was able fill in the missing values and finish the dataset. 

# Statistics Being Tracked
- **Immigrants Obtaining Lawful Permanent Resident Status** - Number of immigrants who obtained lawful permanent resident status in the United States, otherwise known as green card holders. 
- **Refugee Arrivals** - Number of refugees who arrived in the United States. Excludes Amerasian immigrants except for the fiscal years of 1989 and 1991. Figures are based on refugee's arrival date.
- **Noncitizen Apprehensions** - Number of noncitizens apprehended in the United States. Data from 2020 to 2021 includes U.S. Customs and Border Protection (CBP) encounters that resulted in expulsion on public health grounds (due to the pandemic).
- **Noncitizen Removals** - Number of noncitizens removed from the United States. Removals are the compulsory and confirmed movement of an inadmissible or deportable noncitizen out of the United States based on an order of removal. 
- **Noncitizen Returns** - Number of noncitizen returns from the United States. Returns are the confirmed movement of an inadmissible or deportable noncitizen out of the United States not based on an order of removal. 

# Dataset History
2023-01-07 - Dataset is created (465 days after the end of the 2021 fiscal year).

[GitHub Repository](https://github.com/justin-2028/US-Immigration-Statistics-1980-2021) - The same data but on GitHub.

# Code Starter
[Link to Notebook](https://www.kaggle.com/code/justin2028/us-immigration-statistics-1980-2021-code-starter)",.csv
US Inflation Dataset (1947 - 2023),1,us-inflation-dataset-1947-present,US_inflation_rates.csv,CC0-1.0,"This dataset contains historical inflation rates for the United States, from January 1947 to 2023. The inflation rate is a significant economic indicator, offering insights into the health of the economy and the purchasing power of a currency. The CPI is a measure of the average change over time in the prices paid by urban consumers for a market basket of consumer goods and services.

Content:
The dataset has two columns:

Date: The end of the respective month (in MM-DD-YYYY format).
Value: The Consumer Price Index (CPI) at the end of the respective month.
Acknowledgements:
Data is provided by the Federal Reserve Economic Data (FRED), Federal Reserve Bank of St. Louis.

Inspiration:
The U.S. CPI is a critical economic indicator, often used to adjust other economic figures for inflation or to measure the purchasing power of money over time. Analysis of this data can offer insights into the economic health of the country and its monetary policy. This dataset is of interest to economists, financial analysts, data scientists, students, and anyone interested in the U.S. economy or macroeconomic phenomena.

Usability:
The CPI data can be used for a variety of purposes:

Economic Analysis: It can be used for macroeconomic analysis and forecasting. CPI is one of the most important indicators of a country's economic health.
Investment Analysis: The CPI impacts the real return of investments. This data can help investors adjust their expectations and strategies accordingly.
Policy Understanding: It can help understand the impact and effectiveness of monetary policy implemented by the Federal Reserve.
Education: It can be used in classrooms for teaching economics, finance, and related disciplines.",.csv
US Minimum Wage by State from 1968 to 2020,1,us-minimum-wage-by-state-from-1968-to-2017,Minimum Wage Data.csv,CC0-1.0,"# US Minimum Wage by State from 1968 to 2020

## The Basics
- **What is this?** In the United States, states and the federal government set minimum hourly pay (""minimum wage"") that workers can receive to ensure that citizens experience a minimum quality of life. This dataset provides the minimum wage data set by each state and the federal government from 1968 to 2020.

- **Why did you put this together?** While looking online for a clean dataset for minimum wage data by state, I was having trouble finding one. I decided to create one myself and provide it to the community.

- **Who do we thank for this data?** The United States Department of Labor compiles a table of this data on [their website](https://www.dol.gov/whd/state/stateMinWageHis.htm). I took the time to clean it up and provide it here for you. :) [The GitHub repository (with R Code for the cleaning process) can be found here!](https://github.com/Lislejoem/Minimum-Wage-by-State-1968-to-2020/tree/master)

### Content

This is a cleaned dataset of US state and federal minimum wages from 1968 to 2020 (including 2020 equivalency values). The data was scraped from the [United States Department of Labor's table of minimum wage by state](https://www.dol.gov/whd/state/stateMinWageHis.htm). 

## Description of Data
The values in the dataset are as follows:
- **Year**: The year of the data. All minimum wage values are as of January 1 except 1968 and 1969, which are as of February 1.
- **State**: The state or territory of the data.
- **State.Minimum.Wage:** The actual State's minimum wage on January 1 of Year.
- **State.Minimum.Wage.2020.Dollars**: The State.Minimum.Wage in 2020 dollars.
- **Federal.Minimum.Wage**: The federal minimum wage on January 1 of Year.
- **Federal.Minimum.Wage.2020.Dollars**: The Federal.Minimum.Wage in 2020 dollars.
- **Effective.Minimum.Wage**: The minimum wage that is enforced in State on January 1 of Year. Because the federal minimum wage takes effect if the State's minimum wage is lower than the federal minimum wage, this is the higher of the two.
- **Effective.Minimum.Wage.2020.Dollars**: The Effective.Minimum.Wage in 2020 dollars.
- **CPI.Average**: The average value of the [Consumer Price Index](https://www.investopedia.com/terms/c/consumerpriceindex.asp) in Year. When I pulled the data from the [Bureau of Labor Statistics](https://www.bls.gov/cpi/home.htm), I selected the dataset with ""all items in U.S. city average, all urban consumers, not seasonally adjusted"".
- **Department.Of.Labor.Uncleaned.Data**: The unclean, scraped value from the [Department of Labor's website](https://www.dol.gov/whd/state/stateMinWageHis.htm).
- **Department.Of.Labor.Cleaned.Low.Value**: The State's lowest enforced minimum wage on January 1 of Year. If there is only one minimum wage, this and the value for Department.Of.Labor.Cleaned.High.Value are identical. (Some states enforce different minimum wage laws depending on the size of the business. In states where this is the case, generally, smaller businesses have slightly lower minimum wage requirements.)
- **Department.Of.Labor.Cleaned.Low.Value.2020.Dollars**: The Department.Of.Labor.Cleaned.Low.Value in 2020 dollars.
- **Department.Of.Labor.Cleaned.High.Value**: The State's higher enforced minimum wage on January 1 of Year. If there is only one minimum wage, this and the value for Department.Of.Labor.Cleaned.Low.Value are identical.
- **Department.Of.Labor.Cleaned.High.Value.2020.Dollars**: The Department.Of.Labor.Cleaned.High.Value in 2020 dollars.
- **Footnote**: The footnote provided on the [Department of Labor's website](https://www.dol.gov/whd/state/stateMinWageHis.htm). [See more below](README.md#data-footnotes).

### Data Footnotes
As laws differ significantly from territory to territory, especially relating to whom is protected by minimum wage laws, the following footnotes are located throughout the data in Footnote to add more context to the minimum wage. [The original footnotes can be found here.](https://www.dol.gov/whd/state/stateMinWageHis.htm)",.csv
US Monthly Unemployment Rate 1948 - Present,1,us-monthly-unemployment-rate-1948-present,USUnemployment.csv,U.S. Government Works,"### Overview

This repository contains file of monthly US Unemployment rates going back to 1948

### Acknowledgment 

Would like to thank the book ""Practical Time Series Analysis"" for alerting me to this dataset.",.csv
US Police Shootings,1,us-police-shootings,shootings.csv,other,"### Context

In the recent killings, a hot topic came into being, ""Racism"".
So, I chose to gather some data to take out some insights and analyze the story around racism in America.
I downloaded the raw data from kaggle and prepared it for visualization while correcting values, handling missing content, normalization and categorization

### Content

It contains basic data about people like their name, age, gender and race. Along with it, is the shooting/killing information, like date of event, where it happened? how they were shot? did they attack? Were they holding weapons? Did they show any mental illness? Was the policeman wearing a camera/was the incident recorded? Did the suspect flee? Apart from that, a category column holds type of weapon used by the suspect


### Acknowledgements
Kagglers
",.csv
US Real Estate (Census Data),1,us-real-estate-incomepriceregion-census-data,RealEstateUnitedStates.CSV,CC0-1.0,"This dataset captures the relationship between home cost and average income across geographic regions of the United States over time. Ultimately I intend to augment this dataset with relevant economic indicators from Federal Reserve Economic Data (FRED) to better elucidate insights about the US Real Estate Market, the status of the US Economy, and the interaction between these constructs.",.csv
US Regional Sales Data,1,us-regional-sales-data,US_Regional_Sales_Data.csv,CC0-1.0,"This dataset provides comprehensive insights into US regional sales data across different sales channels, including In-Store, Online, Distributor, and Wholesale. With a total of 17,992 rows and 15 columns, this dataset encompasses a wide range of information, from order and product details to sales performance metrics. It offers a comprehensive overview of sales transactions and customer interactions, enabling deep analysis of sales patterns, trends, and potential opportunities.

Columns in the dataset:
- **OrderNumber:** A unique identifier for each order.
- **Sales Channel:** The channel through which the sale was made (In-Store, Online, Distributor, Wholesale).
- **WarehouseCode:** Code representing the warehouse involved in the order.
- **ProcuredDate:** Date when the products were procured.
- **OrderDate:** Date when the order was placed.
- **ShipDate:** Date when the order was shipped.
- **DeliveryDate:** Date when the order was delivered.
- **SalesTeamID**: Identifier for the sales team involved.
- **CustomerID:** Identifier for the customer.
- **StoreID:** Identifier for the store.
- **ProductID:** Identifier for the product.
- **Order Quantity:** Quantity of products ordered.
- **Discount Applied:** Applied discount for the order.
- **Unit Cost:** Cost of a single unit of the product.
- **Unit Price:** Price at which the product was sold.

This dataset serves as a valuable resource for analysing sales trends, identifying popular products, assessing the performance of different sales channels, and optimising pricing strategies for different regions.

Visualization Ideas:

- Time Series Analysis: Plot sales trends over time to identify seasonal patterns and changes in demand.
- Sales Channel Comparison: Compare sales performance across different channels using bar charts or line graphs.
- Product Analysis: Visualise the distribution of sales across different products using pie charts or bar plots.
- Discount Analysis: Analyse the impact of discounts on sales using scatter plots or line graphs.
- Regional Performance: Create maps to visualise sales performance across different regions.

Data Modelling and Machine Learning Ideas (Price Prediction):
- Linear Regression: Build a linear regression model to predict the unit price based on features such as order quantity, discount applied, and unit cost.
- Random Forest Regression: Use a random forest regression model to predict the price, taking into account multiple features and their interactions.
- Neural Networks: Train a neural network to predict unit price using deep learning techniques, which can capture complex relationships in the data.
- Feature Importance Analysis: Identify the most influential features affecting price prediction using techniques like feature importance scores from tree-based models.
- Time Series Forecasting: Develop a time series forecasting model to predict future prices based on historical sales data.
- These visualisation and modelling ideas can help you gain valuable insights from the sales data and create predictive models to optimise pricing strategies and improve sales performance.",.csv
US Stock Market 2020 to 2024,1,us-stock-market-2020-to-2024,US Stock Market Dataset.csv,DbCL-1.0,"The provided dataset is a CSV file titled ""US Stock Market Dataset"" containing financial data for various stocks and indices from January 1, 2020, to January 26, 2024. The dataset includes the following columns:
Date
Natural Gas Price
Natural Gas Vol.
Crude Oil Price
Crude Oil Vol.
Copper Price
Copper Vol.
Bitcoin Price
Bitcoin Vol.
Platinum Price
Platinum Vol.
Ethereum Price
Ethereum Vol.
S&P 500 Price
Nasdaq 100 Price
Nasdaq 100 Vol.
Apple Price
Apple Vol.
Tesla Price
Tesla Vol.
Microsoft Price
Microsoft Vol.
Silver Price
Silver Vol.
Google Price
Google Vol.
Nvidia Price
Nvidia Vol.
Berkshire Price
Berkshire Vol.
Netflix Price
Netflix Vol.
Amazon Price
Amazon Vol.
Meta Price
Meta Vol.
Gold Price
Gold Vol.
Bitcoin Price (5 Minute)
Bitcoin Vol. (5 Minute)",.csv
US Stores Sales,1,us-stores-sales,sales.csv,CC0-1.0,"<h1>🛍️ US Stores Sales 🛍️</h1>

<br>

    US Stores Sales Between 2010 and 2011

----

<h2>🔐 Dataset File 🔐</h2><h2>

    sales.csv

<br>

</h2><h2>❓ Description ❓</h2>

This dataset contains information about Sales Values in Dollars on American Stores between 2010 and 2011. In particular, this dataset contains:

- Stores' Area, State, Region and Size;
- Products' ID, Description, Type, Category and Sale Date;
- Accounting Info, such as Budget Margin, Profit, Total Expenses and Marking.

<br>

    The data was extracted between January 1th in 2010 and December 31th in 2011.

<br>

<h2>📝 Variables 📝</h2>

The file `sales.csv` contains a huge table of US Stores Sales info in the following columns:

<br>

- `Area Code`: Store's Code;
- `State`: Store's State;
- `Market`: Store's Region;
- `Market Size`: Store's Size;
- `Profit`: Profits in Dollars ($);
- `Margin`: Profit + Total Expenses ($) OR Sales - COGS ($);
- `Sales`: Values Acquired in Sales ($);
- `COGS`: Cost of Goods Sold ($);
- `Total Expenses`: Total Expenses to get the Product to Sell ($);
- `Marketing`: Expenses in Marketing ($);
- `Inventory`: Inventory Value of the Product in the Sale Moment ($);
- `Budget Profit`: Expected Profit ($);
- `Budget COGS`: Expected COGS ($);
- `Budget Margin`: Expected Profit + Expected Total Expenses ($) OR Expected Sales - Expected COGS ($);
- `Budget Sales`: Expected Value Acquired in Sales ($);
- `ProductID`: Product ID;
- `Date`: Sale Date;
- `Product Type`: Product Category;
- `Product`: Product Description;
- `Type`: Type;",.csv
US Tornado Dataset 1950-2021,1,us-tornado-dataset-1950-2021,us_tornado_dataset_1950_2021.csv,CC0-1.0,"## Introduction
Tornadoes frequently occur in the United States, resulting in vast destruction and often injuries and death. They occur more often in the United States and Canada than in other countries with the most tornado-prone regions in the US being the central and southeastern states along a corridor sometimes called ""Tornado Alley.""

A tornado's destructiveness is derived largely from the wind speed within it. For this reason, meteoroligists rate tornadoes using a scale based on wind speed. In the US, tornadoes were originally rated on the Fujita Scale, and since February 2007 on the Enhanced Fujita Scale. The two scales cover slightly different speed ranges, but for practical purposes are the same. The enhanced Fujita scale is shown below.

## The Enhance Fujita Scale
|Rating |Wind Speed |Damage |
|--- |--- | --- |
|EF0 |65–85 mph	|Light damage |
|EF1 |86–110 mph	|Moderate damage |
|EF2 |111–135 mph	 |Considerable damage |
|EF3 |136–165 mph	|Severe damage |
|EF4 |166–200 mph	|Devastating damage |
|EF5 |&gt;200 mph	|Incredible damage |

## Origin
This dataset was derived from a dataset produced by NOAA's Storm Prediction Center. The primary changes made to create this dataset were the deletion of some columns, change of some data types, and sorting by date.

## <b>Column Definitions</b>
* <b>yr   </b> - 4-digit year
* <b>mn   </b> - Month (1-12)
* <b>dy   </b> - Day of month
* <b>date </b> - Datetime object (e.g. 1950-01-01)
* <b>st   </b> - State where tornado originated; 2-digit abbreviation
* <b>mag  </b> - F rating thru Jan 2007; EF rating after Jan 2007 (-9 if unknown rating)
* <b>inj  </b> - Number of injuries
* <b>fat  </b> - Number of fatalities
* <b>slat </b> - Starting latitude in decimal degrees
* <b>slon </b> - Starting longitude in decimal degrees
* <b>elat </b> - Ending latitude in decimal degrees (value of 0 if missing)
* <b>elon </b> - Ending longitude in decimal degrees (value of 0 if missing)
* <b>len  </b> - Length of track in miles
* <b>wid  </b> - Width in yards

## References
[NOAA Storm Prediction Center](https://www.spc.noaa.gov/wcm/#data)
[WIkipedia - Tornado](https://en.wikipedia.org/wiki/Tornado)
[Wikipedia - Fujita Scale](https://en.wikipedia.org/wiki/Fujita_scale)
[Wikipedia - Enhanced Fujita Scale](https://en.wikipedia.org/wiki/Enhanced_Fujita_scale)",.csv
US Zipcodes to County State to FIPS Crosswalk,1,zipcodes-county-fips-crosswalk,ZIP-COUNTY-FIPS_2017-06.csv,CC0-1.0,"### Context

Dataset created to link between County - State Name, State-County FIPS, and ZIP Code.

### Acknowledgements
#### Data Sources

 - US HUD

https://www.huduser.gov/portal/datasets/usps.html

 - Census Bureau

https://www2.census.gov/geo/docs/reference/codes/files/national_county.txt https://www.census.gov/geo/reference/codes/cou.html

Data cleaned by Data4Democracy and hosted originally on Data.World:
[https://github.com/Data4Democracy/zip-code-to-county][1]
[https://data.world/niccolley/us-zipcode-to-county-state][2]

ZCTA data from USPS 6.2017 release.

Image from Reddit.

  [1]: https://github.com/Data4Democracy/zip-code-to-county
  [2]: https://data.world/niccolley/us-zipcode-to-county-state",.csv
US graduate school's admission parameters,1,us-graduate-schools-admission-parameters,US_graduate_schools_admission_parameters_dataset.csv,other,"### Context

A dataset to play with how an applicant's different parameters (e.g. GRE score, SOP, CGPA) may impact the admission decision 


### Content



### Acknowledgements

The dataset is collected from www.kaggle.com/mohansacharya/ graduate-admissions


### Inspiration

",.csv
USA Hospitals,1,usa-hospitals,Hospitals.csv,U.S. Government Works,"### Context

This dataset contains locations of Hospitals for 50 US states, Washington D.C., US territories of Puerto Rico, Guam, American Samoa, Northern Mariana Islands, Palau, and Virgin Islands. 

### Content

This feature class/shapefile contains locations of Hospitals for 50 US states, Washington D.C., US territories of Puerto Rico, Guam, American Samoa, Northern Mariana Islands, Palau, and Virgin Islands. The dataset only includes hospital facilities based on data acquired from various state departments or federal sources which has been referenced in the SOURCE field. Hospital facilities which do not occur in these sources will be not present in the database. The source data was available in a variety of formats (pdfs, tables, webpages, etc.) which was cleaned and geocoded and then converted into a spatial database. The database does not contain nursing homes or health centers. Hospitals have been categorized into children, chronic disease, critical access, general acute care, long term care, military, psychiatric, rehabilitation, special, and women based on the range of the available values from the various sources after removing similarities.In this version any information contained in ADDRESS2 field found in earlier versions of this dataset has been merged with the ADDRESS field and the ADDRESS2 field has been deleted.In this update 75 additional records were added and the TRAUMA field was populated for 574 additional hospitals.

### Acknowledgements

This dataset was downloaded on March 23, 2019 from:
https://hifld-geoplatform.opendata.arcgis.com/datasets/a2817bf9632a43f5ad1c6b0c153b0fab_0

This dataset is provided by the Homeland Infrastructure Foundation-Level Data (HIFLD) without a license and for Public Use.

HIFLD Open GP - Public Health
Shared By: jrayer_geoplatform
Data Source: services1.arcgis.com

Users are advised to read the data set's metadata thoroughly to understand appropriate use and data limitations.",.csv
USA Mercedes Benz Prices Dataset,1,usa-mercedes-benz-prices-dataset,usa_mercedes_benz_prices.csv,Apache 2.0,"This dataset provides information about car listings in the USA, focusing on various models of Mercedes-Benz vehicles. The dataset includes the following fields:

- Name: The name and model of the car.
- Mileage: The mileage of the car in miles.
- Rating: The average rating of the car dealer.
- Review Count: The number of reviews for the car dealer.
- Price: The price of the car in US dollars.
The dataset covers a range of Mercedes-Benz models from different years, providing insights into their mileage, ratings, reviews, and prices",.csv
USA Wage Comparison for College vs. High School,1,usa-wage-comparison-for-college-vs-high-school,college_wage_premium.csv,CC0-1.0,"This dataset provides a comprehensive view of wage differences between college graduates and high school graduates in the United States from 1973 to 2022. 

The data is sourced from the Economic Policy Institute's State of Working America Data Library and includes adjusted wages.

## Interesting Task Ideas:

1. Analyze the overall trend in the wage gap between college graduates and high school graduates over the years.
2. Investigate whether the wage gap has been narrowing or widening for different genders.
3. Determine the year(s) when the wage gap was at its lowest and highest points.
4. Identify the demographic group(s) that have experienced the largest increase in wages over time.
5. Compare the wage gap between men and women within each educational group and analyze how it has changed over the years.
6. Create visualizations to visualize and compare wage trends for high school graduates and college graduates across different time periods.

---

If you find this dataset valuable, don't forget to hit the upvote button! 😊💝

---

### Checkout my other datasets

[13K Reddit Tips](https://www.kaggle.com/datasets/asaniczka/helpful-life-tips-from-reddit-dataset-13k-tips)

[150K TMDb TV Shows](https://www.kaggle.com/datasets/asaniczka/full-tmdb-tv-shows-dataset-2023-150k-shows)

[Employment-to-Population Ratio for USA ](https://www.kaggle.com/datasets/asaniczka/employment-to-population-ratio-for-usa-1979-2023)

[Clash of Clans Clans Dataset 2023 (3.5M Clans)](https://www.kaggle.com/datasets/asaniczka/clash-of-clans-clans-dataset-2023-3-5m-clans)

[Gender Wage Gap in the USA](https://www.kaggle.com/datasets/asaniczka/gender-wage-gap-in-the-usa-1973-2022)

---

Photo by [Omar Lopez](https://unsplash.com/@omarlopez1?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash) on [Unsplash](https://unsplash.com/photos/Q92R1693oSI?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)",.csv
USD Iranian Rial Historical Dataset: 2011-2024,1,usd-iranian-rial-historical-dataset-2011-2024,USDIRR(1390-1402).csv,Apache 2.0,"This dataset provides a comprehensive record of the exchange rate between the **United States Dollar (USD) and the Iranian Rial (IRR)** spanning from November 26, 2011 (Jalali date: 1390/09/05) to March 19, 2024 (Jalali date: 1402/12/29). The data is recorded on a daily timeframe, offering insights into the fluctuations and trends in the exchange rate over this period.

**Key Features**:

- **Temporal Coverage**: The dataset covers a significant time span, enabling researchers and analysts to observe long-term trends, seasonal variations, and historical patterns in the USD to IRR exchange rate.
- **Granularity**: Data is provided at a daily frequency, offering fine-grained insights into the currency pair's performance.
- **Jalali Calendar Dates**: In addition to Gregorian calendar dates, Jalali calendar dates are included, catering to users familiar with the Persian calendar system.
- **Currency Pair**: Focus is specifically on the exchange rate between the USD and the Iranian Rial, facilitating analyses and predictions related to these currencies.


**Potential Applications**:

- **Financial Analysis**: Traders, economists, and financial analysts can utilize this dataset to conduct in-depth analyses of the USD-IRR exchange rate, identify patterns, and make informed decisions.
- **Economic Research**: Researchers studying the Iranian economy, monetary policy, and international trade can leverage this dataset to explore the impact of currency fluctuations on various economic indicators.
- **Forecasting Models**: The dataset can serve as a valuable resource for developing predictive models aimed at forecasting future movements in the USD to IRR exchange rate, aiding businesses and policymakers in risk management and strategic planning.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F7986509%2Fb5555b9bd9c171f76777f9e0c339815d%2FUSDIRR.png?generation=1713996249401661&alt=media)",.csv
USPTO-explainable-ai-validation-index,1,uspto-explainable-ai-validation-index,neighbors_small.csv,Attribution-NonCommercial 4.0 International (CC BY-NC 4.0),"Validation index for the competition https://www.kaggle.com/competitions/uspto-explainable-ai. The index provided by the competition host does not contain enough neighbors for an given patent number to accurately validate solutions. This dataset provides an index built from the neighbors of ~4000 publication numbers. The patent numbers can be found in `validation_publication_numbers.csv`. For convenience I also included a small subset of `nearest_neighbors.csv` containing only rows for the validation patents. This can be found in the file `neighbors_small.csv` 

Code to generate your own index can be found at the following: https://www.kaggle.com/code/devinanzelmo/uspto-create-validation-index",.csv
US_Crime_Rates_1960_2014,1,us-crime-rates-1960-2014,US_Crime_Rates_1960_2014.csv,Apache 2.0,"The ""1960_2014 Crimes Data"" dataset contains information about reported crimes in US through the year 1960_2014. This dataset aims to provide insights into crime trends,murder,population,patterns, and rates for analysis and predictive modeling. The data can be used for exploratory data analysis (EDA), trend identification, and forecasting future crime activities and rates. The dataset is particularly valuable for law enforcement agencies, researchers, and analysts interested in understanding crime dynamics.

Usage:
This dataset is suitable for a wide range of analyses, including exploratory data analysis, trend visualization, and predictive modeling. Analysts and researchers can use this data to uncover crime patterns in US, identify hotspots, and develop models for predicting crime rates in upcoming years. Law enforcement agencies, such as the FBI, can benefit from insights gained through this dataset to improve crime prevention and resource allocation strategies.",.csv
Uber Data Analysis🚗 🚕,1,uber-data-analysis,UberDataset.csv,ODC Public Domain Dedication and Licence (PDDL),"**Uber** is a multinational transportation network company that operates a platform connecting riders with drivers through a mobile app. It was founded in 2009 and has since become one of the most well-known examples of a ride-hailing service. Uber allows users to request a ride from their current location to a desired destination using their smartphone. The app matches the user with an available driver in the area, and the driver arrives to pick up the passenger.

Uber offers various types of services, including UberX (standard car), UberXL (larger vehicles), UberBlack (luxury vehicles), and UberPOOL (shared rides with other passengers traveling in the same direction). The fares for rides are calculated based on factors such as distance traveled, time spent on the trip, and demand at the time of the request.

Uber has gained popularity for its convenience, ease of use, and competitive pricing compared to traditional taxi services. It has expanded its operations to numerous cities around the world and has also introduced other services like food delivery (Uber Eats) and package delivery (Uber Connect).",.csv
Ulabox orders with categories' partials 2017,1,ulabox-orders-with-categories-partials-2017,ulabox_orders_with_categories_partials_2017.csv,other,"### Context

__Ulabox__ is the most successful pure-player __online grocery__ in Spain. It picks up more than €1 million in monthly revenue and asserts a customer satisfaction above 95%. It currently serves Madrid and Barcelona with fresh food and the rest of Spain's peninsula with non perishable items.


### Content

The __ulabox_orders_with_categories_partials_2017__ dataset includes a subset of anonymized __30k orders__ from the beginning of 2017. All kind of customers (around 10k) are represented in this dataset: from urban and rural areas, from first-timers to loyal customers.



### Acknowledgements

*Ulabox* was kindly enough to publish this dataset in Kaggle. However if you use this dataset in a paper or research, please use the following citation:

The Ulabox Online Supermarket Dataset 2017, accessed from https://www.github.com/ulabox/datasets",.csv
Unclean Airline Customer Dataset,1,unclean-airline-customer-dataset,flight.csv,CC0-1.0,"## Overview
The dataset originates from https://github.com/Pyluxi/aviation3, where the number of features has been intentionally reduced to streamline information. It encompasses comprehensive customer data along with aggregated activity records spanning two years, up to 2014. Key attributes encompassed in the dataset include the inaugural flight date, membership tier, geographical location, flight frequency, revenue generated within the previous year window, and subsequent year window.

This dataset presents an opportune platform for refining proficiency in data exploration, cleansing methodologies, and employing clustering techniques for customer RFM analysis.

## Columns

| Variable Name            | Description                                                                       |
|--------------------------|-----------------------------------------------------------------------------------|
| MEMBER_NO                | Membership Card Number                                                            |
| FFP_DATE                 | Enrollment Date                                                                   |
| FIRST_FLIGHT_DATE        | First Flight Date                                                                 |
| GENDER                   | Gender                                                                            |
| FFP_TIER                 | Membership Tier                                                                   |
| WORK_CITY                | Work City                                                                         |
| WORK_PROVINCE            | Work Province                                                                     |
| WORK_COUNTRY             | Work Country                                                                      |
| age                      | Age                                                                               |
| LOAD_TIME                | Observation window end time                                                       |
| FLIGHT_COUNT             | Number of flights                                                                 |
| LAST_TO_END+             | Time from last flight to observation window end                                    |
| avg_discount             | Average discount rate                                                             |
| SUM_YR_1                 | Total fare for the first year                                                     |
| SUM_YR_2                 | Total fare for the second year                                                    |
| SEG_KM_SUM               | Total flight distance in observation window                                        |
| LAST_FLIGHT_DATE         | Last flight date                                                                  |
| AVG_INTERVAL             | Average time interval between flights                                              |
| MAX_INTERVAL             | Maximum time interval between flights in observation window                        |
| EXCHANGE_COUNT           | Number of points exchanges                                                         |
| Points_Sum               | Total cumulative points                                                           |
| BP_SUM                   | Total basic points in observation window                                           |
| Point_NotFlight          | Number of non-flight point changes                                                 |


thumbnail is generated with hotpot.ai",.csv
Undersampled_BRFSS 2021 Survey Data,1,undersampled-data,Undersampled_Data.csv,CC0-1.0,"This ([https://www.kaggle.com/datasets/alphiree/cardiovascular-diseases-risk-prediction-dataset/data](url)) dataset was undersampled using the NearMiss-3 algorithm considering the target class to be **Heart_Disease**. The class of **Heart_Disease** was highly imbalanced, with only 9% of the people having heart disease. This caused a significant bias in the performance of any model towards the majority class.

This dataset achieved an average 10-fold cross validation score of 0.68 over 5 models (Logistic regression, decision tree, 5-NN, GaussianNB, and Random Forest) - as compared to a score of about 0.02 on the original dataset. Hence, this may be used for training models for predicting heart diseases or perform statistical analysis and hypothesis testing related to heart diseases.",.csv
Unemployment by Age Groups Dataset,1,unemployment-by-age-groups-dataset,unemployment_rate_by_age_groups.csv,Apache 2.0,"This dataset contains non-seasonally adjusted California Unemployment Rate by age groups, from the Current Population Survey (CPS). The age group ranges are as follows; 16-19 ; 20 - 24; 25 - 34; 35 - 44; 45 - 54; 55 -64; 65+. This data is based on a 12-month moving average.

This dataset is invaluable for data science applications due to its granularity and the historical depth it offers. With detailed monthly data on unemployment rates by age groups, data scientists can perform a myriad of analyses:

- **Time Series Analysis**: Analyzing trends over time to forecast future unemployment rates or identify cyclic patterns.
- **Demographic Analysis**: Understanding which age groups are most affected by unemployment and how this changes through economic conditions.
- **Geographic Analysis**: Although the dataset currently focuses on California, if similar data is available for other regions, comparisons can be made to understand regional economic differences.

The dataset can also be merged with other socioeconomic indicators like GDP, education levels, and industry growth metrics to examine broader economic narratives or policy impacts.",.csv
Unemployment dataset,1,unemployment-dataset,unemployment analysis.csv,Attribution 4.0 International (CC BY 4.0),"## Introduction

Unemployment is a situation when a person actively searches for a job and is unable to find work. Unemployment indicates the health of the economy. 
The unemployment rate is the most frequent measure of unemployment. The unemployment rate is the number of people unemployed divided by the working population or people working under labor.

## Why does unemployment occur?
- Large population.
- Lack of vocational skills or low educational levels of the working population.
- Legal complexities, Inadequate state support, and low infrastructural, financial, and market linkages to small businesses make such enterprises unviable with cost and compliance overruns.
- Inadequate growth of infrastructure and low investments in the manufacturing sector, hence restricting the employment potential of the secondary sector.
- The huge workforce of the country is associated with the informal sector because of a lack of required education or skills, and this data is not captured in employment statistics.
- The main cause of structural unemployment is the education provided in schools and colleges is not as per the current requirements of the industries. 
",.csv
"Unemployment in America, Per US State",1,unemployment-in-america-per-us-state,Unemployment in America Per US State.csv,CC-BY-NC-SA-4.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F12064410%2Fe1c439d356d34481d8343cfcc5f32bb2%2Funemployment%20flag.png?generation=1677706474308274&alt=media)

# DAY ~17,000 (January 1976 to December 2022)
This is a dataset that tracks **relevant population statistics** and **employment rates** per US state since 1976. 

All data are official figures from the Bureau of Labor Statistics that have been compiled and structured by myself. Besides the 50 US states, the unemployment data of *three other areas* are also being tracked in order to increase the analytical potential of the dataset: the **District of Columbia**, the **Los Angeles-Long Beach-Glendale metropolitan division**, and **New York City**.

Why did I create this dataset? Employment continues to be a **significant issue** in America today and contributes to other predicaments such as the homelessness crisis. By uploading time-series data regarding American unemployment over the past four decades, I hope that the community is able to determine the various statistical trends offered. In my personal opinion, achieving a **quantitative yet objective viewpoint** of a subject such as unemployment is crucial to understanding the issues at hand.

# Data Sources
##### The primary data source used was the Bureau of Labor Statistics's official website, which publishes employment data pertaining to America. Considering the meticulous documentation of federal statistics by such a accredited government agency, no other authority is more equipped to provide insight on US unemployment.

1. [The Bureau of Labor Statistics's Economic News Release on (Monthly) State Employment and Unemployment](https://www.bls.gov/web/laus.supp.toc.htm) - The Bureau of Labor Statistics has published monthly updates on unemployment rates since January 1976. 
2. [The Bureau of Labor Statistics's State Employment and Unemployment Technical Note](https://www.bls.gov/news.release/laus.tn.htm) - The Bureau of Labor Statistics released a detailed overview of their unemployment data, the methodology behind their data, and the proper definitions and terminologies for the variables tracked. The guide mainly provided essential contextual knowledge needed to create a meaningful dataset.

# Statistics Being Tracked
- FIPS Code of State/Area
- Year/Month of Statistic
- Total Civilian Non-Institutional Population in State/Area
- Total Civilian Labor Force in State/Area
- Percent (%) of State/Area's Population
- Total Employment in State/Area
- Percent (%) of Labor Force Employed in State/Area
- Total Unemployment in State/Area
- Percent (%) of Labor Force Unemployed in State/Area

# Dataset History
2023-03-01 - Dataset is created (17,227 days after temporal coverage start date).

[GitHub Repository](https://github.com/justin-2028/Unemployment-in-America-Per-US-State) - The same data but on GitHub.

# Code Starter
[Link to Notebook](https://www.kaggle.com/code/justin2028/unemployment-in-america-per-us-state-code-starter)
",.csv
Unicorn Companies Dataset,1,unicorn-companies-dataset,Unicorn_Companies.csv,CC0-1.0,"### Context

A complete list of unicorn companies in the world.

### Content

A unicorn company, or unicorn startup, is a private company with a valuation over $1 billion. As of March 2022, there are 1,000 unicorns around the world. Popular former unicorns include Airbnb, Facebook and Google. Variants include a decacorn, valued at over $10 billion, and a hectocorn, valued at over $100 billion. Download the full list today to see each company's valuation, investors, and more.

### Acknowledgements

[Image Credit 
](https://www.google.com/url?sa=i&url=https%3A%2F%2Fmolo17.com%2F2020%2F09%2Fthe-next-unicorn-startups-for-forbes%2F&psig=AOvVaw0QzCWyhsajAqLTSmbW86Th&ust=1646821986313000&source=images&cd=vfe&ved=0CAwQjhxqFwoTCNCh4IyotvYCFQAAAAAdAAAAABAD)",.csv
Unicorn Startups,1,unicorn-startups,unicorns till sep 2022.csv,CC0-1.0,"""Unicorn"" is a term used in the venture capital industry to describe a privately held startup company with a value of over $1 billion. The term was first popularized by venture capitalist Aileen Lee, founder of Cowboy Ventures, a seed-stage venture capital fund based in Palo Alto, California.


Unicorns can also refer to a recruitment phenomenon within the human resources (HR) sector. HR managers may have high expectations to fill a position, leading them to look for candidates with qualifications that are higher than required for a specific job. In essence, these managers are looking for a unicorn, which leads to a disconnect between their ideal candidate versus who they can hire from the pool of people available.


<img src=""https://64.media.tumblr.com/bac335874ef2027808929dae97be5edc/tumblr_mqseckyDQX1r8q1s0o1_500.gifv"" alt=""Computer man"" style=""width: 600px; height: 300px"">
",.csv
United Nations Crime-Data,1,crimes-un-datacsv,Crimes_UN_data.csv,CC0-1.0,https://archive.ics.uci.edu/ml/index.php,.csv
United Nations Refugee Data 1951-2023,1,united-nations-refugee-data-unhcr,United Nations Refugee Data.csv,Apache 2.0,"The UN Refugee Agency, UNHCR, collates population data relating to persons who are forcibly displaced or stateless. The data is sourced primarily from governments and also from UNHCR operations.",.csv
United States E-Commerce records 2020,1,us-ecommerce-record-2020,US  E-commerce records 2020.csv,CC0-1.0,"### Context

A detailed United States e-commerce  records in 2020 . I hope this will help in finding trends and hidden patterns .  


### Content

This Dataset consists of 15+ columns which provides us almost everything we need to know like Sales, Profit, Discounts, State name, City name etc.


### Inspiration
What is the overall  Trend in US E-Commerce market Place?",.csv
"United States Energy, Census, and GDP 2010-2014",1,us_energy_census_gdp_10-14,Energy Census and Economic Data US 2010-2014.csv,CC0-1.0,"The purpose of this data set is to allow exploration between various types of data that is commonly collected by the US government across the states and the USA as a whole. The data set consists of three different types of data:

* Census and Geographic Data;
* Energy Data; and 
* Economic Data.

When creating the data set, I combined data from many different types of sources, all of which are cited below. I have also provided the fields included in the data set and what they represent below. I have not performed any research on the data yet, but am going to dive in soon. I am particularly interested in the relationships between various types of data (i.e. GDP or birth rate) in prediction algorithms. Given that I have compiled 5 years’ worth of data, this data set was primarily constructed with predictive algorithms in mind.

*An additional note before you delve into the fields:* 
* There could have been many more variables added across many different fields of metrics. I have stopped here, but it could potentially be beneficial to observe the interaction of these variables with others (i.e. the GDP of certain industries, the average age in a state, the male/female gender ratio, etc.) to attempt to find additional trends.

**Census and Geographic Data**
------------------------------

* StateCodes: The state 2-letter abbreviations. **Note that I added ""US"" for the United States.**
* Region: The number corresponding to the region the state lies within, according to the 2010 census. (1 = Northeast, 2 = Midwest, 3 = South, 4 = West)
* Division: The number corresponding to the division the state lies within, according to the 2010 census. (1 = New England, 2 = Middle Atlantic, 3 = East North Central, 4 = West North Central, 5 = South Atlantic, 6 = East South Central, 7 = West South Central, 8 = Mountain, 9 = Pacific)
* Coast: Whether the state shares a border with an ocean. (1 = Yes, 0 = No)
* Great Lakes: Whether the state shares a border with a great lake. (1 = Yes, 0 = No
* CENSUS2010POP: 4/1/2010 resident total Census 2010 population
* POPESTIMATE{year}: 7/1/{year} resident total population estimate
* RBIRTH{year}: Birth rate in period 7/1/{year - 1} to 6/30/{year}
* RDEATH{year}: Death rate in period 7/1/{year - 1} to 6/30/{year}
* RNATURALINC{year}: Natural increase rate in period 7/1/{year - 1} to 6/30/{year}
* RINTERNATIONALMIG{year}: Net international migration rate in period 7/1/{year - 1} to 6/30/{year}
* RDOMESTICMIG{year}: Net domestic migration rate in period 7/1/{year - 1} to 6/30/{year}
* RNETMIG{year}: Net migration rate in period 7/1/{year - 1} to 6/30/{year}

*As noted from the census:*

> Net international migration for the United States includes the international migration of both native and foreign-born populations. Specifically, it includes: (a) the net international migration of the foreign born, (b) the net migration between the United States and Puerto Rico, (c) the net migration of natives to and from the United States, and (d) the net movement of the Armed Forces population between the United States and overseas. Net international migration for Puerto Rico includes the migration of native and foreign-born populations between the United States and Puerto Rico.

Codes for most of the data, information about the geographic terms and coditions, and more information about the methodology behind the population estimates can be found on the US Census website.

**Energy Data**
-----------

* TotalC{year}: Total energy consumption in billion BTU in given year.
* TotalP{year}: Total energy production in billion BTU in given year.
* TotalE{year}: Total Energy expenditures in million USD in given year.
* TotalPrice{year}: Total energy average price in USD/million BTU in given year.
* TotalC{first year}–{second year}: The first year’s total energy consumption divided by the second year’s total energy consumption, times 100. (The percent change between years in total energy consumption.)
* TotalP{first year}–{second year}: The first year’s total energy production divided by the second year’s total energy production, times 100. (The percent change between years in total energy production.)
* TotalE{first year}–{second year}: The first year’s total energy expenditure divided by the second year’s total energy expenditure, times 100. (The percent change between years in total energy expenditure.)
* TotalPrice{first year}–{second year}: The first year’s total energy average price divided by the second year’s total energy average price, times 100. (The percent change between years in total energy average price.)
* BiomassC{year}: Biomass total consumption in billion BTU in given year.
* CoalC{year}: Coal total consumption in billion BTU in given year.
* CoalP{year}: Coal total production in billion BTU in given year.
* CoalE{year}: Coal total expenditures in million USD in given year.
* CoalPrice{year}: Coal average price in USD per million BTU in given year.
* ElecC{year}: Electricity total consumption in billion BTU in given year.
* ElecE{year}: Electricity total expenditures in million USD in given year.
* ElecPrice{year}: Electricity average price in USD per million BTU in given year.
* FossFuelC{year}: Fossil fuels total consumption in billion BTU in given year.
* GeoC{year}: Geothermal energy total consumption in billion BTU in given year.
* GeoP{year}: Geothermal energy net generation in the electric power sector in million kilowatt hours in given year.
* HydroC{year}: Hydropower total consumption in billion BTU in given year.
* HydroP{year}: Hydropower total net generation in million kilowatt hours in given year.
* NatGasC{year}: Natural gas total consumption (including supplemental gaseous fuels) in billion BTU in given year.
* NatGasE{year}: Natural gas total expenditures in million USD in given year.
* NatGasPrice{year}: Natural gas average price in USD per million BTU in given year. 
* LPGC{year}: LPG total consumption in billion BTU in given year.
* LPGE{year}: LPG total expenditures in million USD in given year.
* LPGPrice{year}: LPG average price in USD per million BTU in given year. 

*Notes:*

* BTU stands for British Thermal Unit and is a unit of measurement for energy. One BTU is equal to the amount of energy used to raise the temperature of one pound of water on degree Fahrenheit.
* Many other types of energy and their associated consumption, production, expenditure, and price totals can be found from the EIA; this is where I received the data I used in compiling this dataset.

**Economic Data**
-------------

* GDP{year}{quarter}: The GDP in the provided quarter of the given year (in million USD).
* GDP{year}: The average GDP throughout the given year (in million USD).

*Notes:*

* The GDP is reported by the Bureau of Economic Analysis from the U.S. Department of Commerce and measures the value of the goods and services produced by the economy in a given period.
* The quarterly GDP data can be downloaded from the BEA.
* The yearly GDP data can be downloaded from the BEA.

Image credit: http://www.freelargeimages.com/wp-content/uploads/2014/11/Map_of_united_states-3.jpg",.csv
United States crime rates by county,1,united-states-crime-rates-by-county,crime_data_w_population_and_crime_rate.csv,CC0-1.0,"

# Content

Data Sources : 
 - Crime (2016): https://www.icpsr.umich.edu/icpsrweb/ 
 - Population (2013):  https://census.gov",.csv
University Employee Salaries (2011 - Present),1,university-employee-salaries-2011-present,higher_ed_employee_salaries.csv,Apache 2.0,"Explore the salaries of higher education employees from Ohio's public universities dating back to 2011. 

This dataset offers insights into the earnings of various positions across multiple institutions. Please note that benefits are not included in the reported salaries.

&gt;  Don't forget to upvote this dataset if you find it useful for your analysis! 😊📊

## Key Insights:

1. Track salary trends over the years at different universities in Ohio.
2. Compare earnings across schools, departments, and job positions.
3. Identify the highest-earning employees in the public university sector.
4. Analyze the distribution of earnings by year.

---

Photo by <a href=""https://unsplash.com/@thutra0803?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Tra  Nguyen</a> on <a href=""https://unsplash.com/photos/womens-blue-dress-shirt-TVSRWmnW8Us?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv
University Rankings 2017👩‍🎓👨‍⚕️,1,university-rankings-2017,National Universities Rankings.csv,other,"DESCRIPTION
US News Universities Rankings 2017 edition
SUMMARY
National Universities Rankings
In-the-News From 9/13/16 press release:

U.S. News & World Report today announced the 2017 Best Colleges rankings to help students worldwide compare the academic quality of more than 1,800 U.S.-based schools. Princeton University remains No. 1 in the Best National Universities category. For the 14th consecutive year, Williams College takes the top spot on the Best National Liberal Arts Colleges list.

Source: U.S. News Best College Rankings

Schools in the National Universities category, such as Columbia University and the University of Pennsylvania, offer a full range of undergraduate majors, plus master's and doctoral programs. These colleges also are committed to producing groundbreaking research.

About the data
Name - institution name

Location - City, State where located

Rank Read methodology here. This dataset does not include unranked schools or any data that requires purchase / special access (i.e., exclusive to the U.S. News College Compass product).

Description Snippet of text overview from U.S. News

Tuition and fees Combined tuition and fees. For public universities with different tuition structure for in-state vs. out-of-state students, this number reflects out-of-state tutition.

In-stateFor public universities with different tuition structure for in-state vs. out-of-state students, this number reflects in-state tuition.

Undergrad Enrollment Number of enrolled undergratuate students

Read the Best Colleges Methodology

More from press release (quoted verbatim):

The average six-year graduation rate is 95 percent for the top 10 National Universities and 93.9 percent for the top 10 National Liberal Arts Colleges.
The average freshman retention rate is 98.1 percent for the top 10 National Universities and 96.6 percent for the top 10 National Liberal Arts Colleges.
For comparison, the average six-year graduation rate among all numerically ranked schools on the National Universities list is 71.3 percent, and the average freshman retention rate is 86.9 percent.
For comparison, the average six-year graduation rate among all numerically ranked schools on the National Liberal Arts Colleges list is 75.2 percent, and the average freshman retention rate is 85.6 percent.
",.csv
University Students Data,1,university-students-data,Kmeans_assignment_data.csv,Apache 2.0,"**Data Description**

Private A factor with levels No and Yes indicating private or public university
* Apps Number of applications received
* Accept Number of applications accepted
* Enroll Number of new students enrolled
* Top10perc Pct. new students from top 10% of H.S. class
* Top25perc Pct. new students from top 25% of H.S. class
* F.Undergrad Number of fulltime undergraduates
* P.Undergrad Number of parttime undergraduates
* Outstate Out-of-state tuition
* Room.Board Room and board costs
* Books Estimated book costs
* Personal Estimated personal spending
* PhD Pct. of faculty with Ph.D.’s
* Terminal Pct. of faculty with terminal degree
* S.F.Ratio Student/faculty ratio
* perc.alumni Pct. alumni who donate
* Expend Instructional expenditure per student
* Grad.Rate Graduation rate

You can Use it for clustering projects",.csv
University of Waterloo Enrolment,1,university-of-waterloo-enrolement,waterloo-enrolement-2024.csv,Apache 2.0,This dataset includes information about student enrolments at the University of Waterloo. All the data is available publicly from https://uwaterloo.ca/institutional-analysis-planning/university-data-and-statistics/student-data/student-headcounts,.csv
University world ranking (2108_2019),1,university-world-ranking,eighteen_nineteen_university_datasets.csv,CC-BY-NC-SA-4.0," this data was collected by CWRU: Since 2012, CWUR has been publishing the only academic ranking of global universities that assesses the quality of education, employability, quality of faculty, and research without relying on surveys and university data submissions. The ranking started out as a project in Jeddah, Saudi Arabia with the aim of rating the top 100 world universities.



Columns description :



World Rank:Ranking in world

Institution: Name of University

Location: Country

National Rank: Ranking in its Country

Quality of Education: University's alumi who have won major awards(12.5%)

Alumni Employment:Average number (per year) of a university's alumni who have held CEO position(12.5%)

Quality of Faculty: Faculty members of an institution who won awards(25%)

Research Output: Measured by the total number of research papers(10%)

Quality Publications: Measured by the total number of research papers appearing in top-tier Journals(10%)

Influence: Measured by the total number of research papers appearing in highly-influential Journals(10%)

Citations: Measured by the total number of highly-cited research papers(10%)

Score: Score



",.csv
Unreal Engine - From Past to Future,1,unreal-engine-from-past-to-future,UE_Future.csv,CC0-1.0,"This dataset shows the Unreal Engine from 1998 to 2024. It shows the number of users, the versions released each year, and famous games published using the engine in that specific year. The columns are:

```Year``` - The year

```Version Released``` - The version(s) released 

```Add Features``` - The changes made to the version(s) published in that year

```Games``` - Famous games published that year using the engine

```Num Users``` - The number of users

The num users column might not be very accurate due to lack of documentation. Very sorry for that. God bless you.",.csv
Updated Resume Dataset,1,updated-resume-dataset,UpdatedResumeDataSet.csv,CC0-1.0,"### Context ### Content ### Acknowledgements  ### Inspiration


Companies often receive thousands of resumes for each job posting and employ dedicated screening officers to screen qualified candidates.

Hiring the right talent is a challenge for all businesses. This challenge is magnified by the high volume of applicants if the business is labor-intensive, growing, and facing high attrition rates.

IT departments are short of growing markets. In a typical service organization, professionals with a variety of technical skills and business domain expertise are hired and assigned to projects to resolve customer issues. This task of selecting the best talent among many others is known as Resume Screening.

Typically, large companies do not have enough time to open each CV, so they use machine learning algorithms for the Resume Screening task.",.csv
Upvoted Kaggle Datasets,1,voted-kaggle-dataset,voted-kaggle-dataset.csv,CC0-1.0,"### Context

Kaggle dataset becomes a popular growing place to share datasets. Almost every day there will be new datasets uploaded. I am curious to explore what can be extracted from the information of each dataset.

### Content
This dataset consists 2150 datasets information in 15 columns:

 - Title

 - Subtitle

 - Owner

 - Vote

 - Version History

 - Tags

 - Datatype

 - Size

 - License

 - Views

 - Downloads

 - Kernels

 - Topics

 - URL

 - Description

### Acknowledgements
All data were taken from Kaggle website. Collected on 26 Feb 2018

### Inspiration
With this dataset, we may try to predict the upcoming datasets uploaded, including its topics, number of votes, number of downloads, etc. Data visualization involving clustering may be performed also.",.csv
Upvoted Kaggle Kernels,1,upvoted-kaggle-kernels,voted-kaggle-kernels.csv,CC0-1.0,"### Context

Beside datasets, kernels in Kaggle are interesting features. We can learn, share, and furthermore, contribute to others. I collected metadata from highly voted kernels in Kaggle so that people can explore many things.


### Content

This dataset contains 971 most favorited kernels in 12 columns:  
* Votes (number of votes)    
* Owner  
* Kernel (name of the kernel)    
* Dataset  
* Version History  
* Tags  
* Output  
* Code type (script/notebook)    
* Language (Python/R)  
* Comments (number of comments)    
* Views (number of views)    
* Forks (number of forks)    


### Acknowledgements

All data were taken from Kaggle's website on 26 Feb 2018.


### Inspiration

What makes people vote your kernel? What are the trends of highly voted kernels? Who has the biggest number of accumulated votes? etc",.csv
Used Bikes Prices in India,1,used-bikes-prices-in-india,Used_Bikes.csv,CC0-1.0,"### Context

This dataset contains information about approx 32000 used bikes scraped from www.droom.in


### Content

This dataset comprises bikes a range of all used bikes sold on droom.in. It includes features like power, kilometers drive, Age of the bike etc.


### Acknowledgements

All data was scraped from www.droom.in using Webscraper.io and Instant Data Scraper tools


### Inspiration

The aim to model a resale valuation for used bikes and predict the price of used bikes. This can be helpful while selling a used bike or buying a used bike.",.csv
Used Car Price Dataset,1,used-car-dataset,Used Car Dataset.csv,CC0-1.0,"## 🚗 **Used Car Price Dataset: A dataset for predicting used car price** 📊

Dive into the world of used cars with our dataset, perfect for predicting prices. It's a carefully selected set of data that car enthusiasts, analysts, and data scientists will find valuable. Whether you're curious or looking to analyze, this dataset is your guide to understanding the dynamics of how used cars are valued.

**Key Features:**

- 🛣️ **Rich Attributes:** Explore a number of attributes, including mileage, model year, fuel type, transmission, and more, providing a 360-degree view of each vehicle's specifications.
- 📉 **Depreciation Insights:** Uncover patterns in vehicle depreciation over time and across different makes and models, empowering you to make informed predictions about future price trends.
- 📱 **Technological Integration:** Seamlessly integrate our dataset into your predictive modeling pipelines, harnessing the power of technology to foresee changes in the used car market.

**Potential Applications:**
- 📈 **Market Research:** Conduct in-depth market research to identify trends, fluctuations, and hotspots in the used car industry.
- 🤖 **Predictive Modeling:** Build robust machine learning models to predict resale values, assisting buyers, sellers, and dealerships in making informed decisions.
- 🚀 **Business Strategy:** Inform business strategies for used car dealerships, insurance companies, and financial institutions by understanding the underlying factors influencing pricing.

**How to Use:**
1. 🧑‍💻 **Data Science Projects:** Integrate this dataset into your data science projects to explore and analyze factors impacting used car prices.
2. 🚀 **Predictive Modeling:** Train machine learning models to predict resale values based on historical data and a wide array of vehicle attributes.
3. 🚗 **Market Insights:** Gain valuable insights into market dynamics, allowing you to stay ahead of trends and developments in the used car space.

#### Dataset Description:
1552 Rows, 15 Columns

**Attributes:**

1. car_name
2. registration_year
3. insurance_validity
4. fuel_type
5. seats
6. kms_driven
7. ownership
8. transmission
9. manufacturing_year
10. mileage(kmpl)
11. engine(cc)
12. max_power(bhp)
13. torque(Nm)
14. price(in lakhs)

#### Steps you can do:

**1. Data Preprocessing**
**2. Data Visualization**
**3. Explarotary Data Analysis**
**4. Feature Selection and Transformation**
**5. Train-Test-Split**
**6. Model Creation (eg: Multiple Linear Regression)**
**7. Model Prediction**

Give an upvote if it helps !!

",.csv
Used Car Price Prediction,1,used-car-price-prediction,cardekho_data.csv,ODbL-1.0,"This project aims to predict the selling price of used cars with high accuracy using decision tree regression and random forest regression models. a comprehensive dataset containing various car features like model, year, km_driven, fuel type, and ownership history. By analyzing these features and their relationships with the selling price, I aim to build a robust and generalizable model that can inform buyers, sellers, and other stakeholders in the used car market.",.csv
Used Car Price Prediction Dataset,1,used-car-price-prediction-dataset,used_cars.csv,Attribution 4.0 International (CC BY 4.0),"Used Car Price Prediction Dataset is a comprehensive collection of automotive information extracted from the popular automotive marketplace website, [https://www.cars.com](https://www.cars.com). This dataset comprises 4,009 data points, each representing a unique vehicle listing, and includes nine distinct features providing valuable insights into the world of automobiles.

- **Brand & Model:** Identify the brand or company name along with the specific model of each vehicle.
- **Model Year:** Discover the manufacturing year of the vehicles, crucial for assessing depreciation and technology advancements.
- **Mileage:** Obtain the mileage of each vehicle, a key indicator of wear and tear and potential maintenance requirements.
- **Fuel Type:** Learn about the type of fuel the vehicles run on, whether it's gasoline, diesel, electric, or hybrid.
- **Engine Type:** Understand the engine specifications, shedding light on performance and efficiency.
- **Transmission:** Determine the transmission type, whether automatic, manual, or another variant.
- **Exterior & Interior Colors:** Explore the aesthetic aspects of the vehicles, including exterior and interior color options.
- **Accident History:** Discover whether a vehicle has a prior history of accidents or damage, crucial for informed decision-making.
- **Clean Title:** Evaluate the availability of a clean title, which can impact the vehicle's resale value and legal status.
- **Price:** Access the listed prices for each vehicle, aiding in price comparison and budgeting.

This dataset is a valuable resource for automotive enthusiasts, buyers, and researchers interested in analyzing trends, making informed purchasing decisions or conducting studies related to the automotive industry and consumer preferences. Whether you are a data analyst, car buyer, or researcher, this dataset offers a wealth of information to explore and analyze.",.csv
Used Phones & Tablets Pricing Dataset,1,used-handheld-device-data,used_device_data.csv,CC0-1.0,"**CONTEXT**- The used and refurbished device market has grown considerably over the past decade as it provide cost-effective alternatives to both consumers and businesses that are looking to save money when purchasing one. Maximizing the longevity of devices through second-hand trade also reduces their environmental impact and helps in recycling and reducing waste. Here is a sample dataset of normalized used and new pricing data of refurbished / used devices.

**OBJECTIVE**- The objective is to do Exploratory Data Analytics and apply Linear Regression to create a model which can help in pricing of such devices.

**META DATA**
**device_brand**: *Name of manufacturing brand*
**os**: *OS on which the device runs*
**screen_size**: *Size of the screen in cm*
**4g**: *Whether 4G is available or not*
**5g**: *Whether 5G is available or not*
**front_camera_mp**: *Resolution of the rear camera in megapixels*
**back_camera_mp**: *Resolution of the front camera in megapixels*
**internal_memory**: *Amount of internal memory (ROM) in GB*
**ram**: *Amount of RAM in GB*
**battery**: *Energy capacity of the device battery in mAh*
**weight**: *Weight of the device in grams*
**release_year**: *Year when the device model was released*
**days_used**: *Number of days the used/refurbished device has been used*
**normalized_new_price**: *Normalized price of a new device of the same model*
**normalized_used_price (TARGET)**: *Normalized price of the used/refurbished device*",.csv
Used-Car Data,1,usedcar-data,UserCarData.csv,DbCL-1.0,"Based on various market surveys, the consulting firm has gathered a large dataset of different types of used cars across the market.

Data Dictionary:
1. Sales_ID  (Sales ID)
2. name   (Name of the used car)
3. year   (Year of the car purchase)
4. selling_price   (Current selling price for used car)
5. km_driven   (Total km driven)
6. Region     (Region where it is used)
7. State or Province     (State or Province where it is used)
8. City      (City where it is used)
9. fuel    (Fuel type)
10. seller_type   (Who is selling the car)
11. transmission  (Transmission type of the car)
12. owner   (Owner type)
13. mileage   (Mileage of the car)
14. engine    (engine power)
15. max_power  (max power)
16. seats    (Number of seats)
17. sold     (used car sold or not)

",.csv
User churn,1,user-churn,User churn.csv,other,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16192307%2F757e6d6a62611ebbb907c7615600c2c1%2FCustomer-Churn.png?generation=1714576362595003&alt=media)

**Columns:**

**CustomerID:** Client ID

**Gender:** Client gender

**SeniorCitizen:** Is the client retired or not?

**Partner:** Does the client have a partner?

**Dependents:** Does the client have dependents?

**Tenure:** How long has a person been a client of the company?

**PhoneService:** Client's use of telephony services

**MultipleLines:** Client's use of multiline telephony services

**InternetService:** Client's use of Internet services

**OnlineSecurity:** Customer use of online security

**OnlineBackup:** Client use of online backup

**DeviceProtection:** Client use of device security

**TechSupport:** Customer use of technical support

**StreamingTV:** Customer Usage Streaming TV

**StreamingMovies:** Customer Usage Streaming Movies

**Contract:** Payment for the period of time for services under the contract

**PaperlessBilling:** Client use of paperless billing

**PaymentMethod:** Payment method

**MonthlyCharges:** Client monthly payments under contract

**TotalCharges:** Total client expenses

**Churn:** Whether this customer left or not",.csv
User_Data,1,user-data,User_Data.csv,CC0-1.0,"The dataset consists of information about users who are potential customers for a product or service. It contains four input features - User ID, Gender, Age, and Estimated Salary - which are used to predict whether or not the user purchased the product, indicated by the output or target column 'Purchased'.

The User ID is a unique identifier assigned to each user, while Gender is the user's gender, which can be either male or female. Age is the age of the user in years, and Estimated Salary is an estimate of the user's annual salary.

The dataset is likely used for binary classification tasks to determine whether or not a user is likely to purchase a particular product or service. The features provided could potentially be used to create a model that predicts the probability of a user purchasing the product based on their age, gender, and estimated salary.",.csv
VW insights,1,vw-insights,gcar_data.csv,MIT,l understand that Vw is quickly becoming a prominent brand in the car economics industry a over the world.It is very important for many of us to understand its qualities hence l took the time to convey this dataset as a third party.,.csv
Vaccines have saved,1,vaccines-have-saved,lives-saved-vaccines new.csv,CC0-1.0,"this graph was created in OurDataWorld:

By the time you finish reading this, around 30 children will have been saved thanks to vaccines.1

Over the last 50 years, that adds up to 150 million children.2 That’s more than twice the population of the United Kingdom.

That’s 150 million children who will grow up, experience life, and contribute to the world; over a hundred million sets of parents who were spared the tragedy of having to bury their children.

This figure comes from a new study from Andrew Shattock and other researchers from around the world. They estimated the number of lives saved from vaccinations against different diseases over the past 50 years.3

The two charts below show the number of lives saved, broken down by disease and region.

Vaccination against measles has had the biggest impact, saving 94 million lives over the last 50 years — more than 60% of the total.4

This has been a truly global effort, with more than 5 million children saved in every region, including over 50 million in Africa and 38 million in Southeast Asia. You can see the cumulative number of lives saved by WHO region in the chart below.


![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F24b6c96b3fd0e58dd161d8cb934882cb%2Fgraph3.png?generation=1715119326055067&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fa33b2c97afabf6e6a00ae874d60dab18%2Fgraph2.png?generation=1715119332087809&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fde366244f40beb4f2d9421366c744712%2Fgraph1.png?generation=1715119339366194&alt=media)",.csv
"Vehicle Fuel Economy Estimates, 1984-2017",1,fuel-economy,fuel.csv,CC0-1.0,"# Content

The purpose of EPA’s fuel economy estimates is to provide a reliable basis for comparing vehicles. Most vehicles in the database (other than plug-in hybrids) have three fuel economy estimates: a “city” estimate that represents urban driving, in which a vehicle is started in the morning (after being parked all night) and driven in stop-and-go traffic; a “highway” estimate that represents a mixture of rural and interstate highway driving in a warmed-up vehicle, typical of longer trips in free-flowing traffic; and a “combined” estimate that represents a combination of city driving (55%) and highway driving (45%). Estimates for all vehicles are based on laboratory testing under standardized conditions to allow for fair comparisons.

The database provides annual fuel cost estimates, rounded to the nearest $50, for each vehicle. The estimates are based on the assumptions that you travel 15,000 miles per year (55% under city driving conditions and 45% under highway conditions) and that fuel costs $2.33/gallon for regular unleaded gasoline, $2.58/gallon for mid-grade unleaded gasoline, and $2.82/gallon for premium.

EPA’s fuel economy values are good estimates of the fuel economy a typical driver will achieve under average driving conditions and provide a good basis to compare one vehicle to another. However, your fuel economy may be slightly higher or lower than EPA’s estimates. Fuel economy varies, sometimes significantly, based on driving conditions, driving style, and other factors.


# Acknowledgements

Fuel economy data are produced during vehicle testing at the Environmental Protection Agency's National Vehicle and Fuel Emissions Laboratory in Ann Arbor, Michigan, and by vehicle manufacturers with EPA oversight.",.csv
Vehicle Fuel consumption,1,vehcile-fuel-consumption,fuel.csv,Apache 2.0,"This dataset provides a detailed overview of fuel economy in the automotive industry, featuring information on a wide range of vehicles from different years, makes, and models. It includes details about engine specifications, fuel types, transmission systems, as well as factors such as fuel economy, CO2 emissions, and technological features.",.csv
Vehicle Insurance Claim Fraud Detection,1,vehicle-claim-fraud-detection,fraud_oracle.csv,CC0-1.0,"### Vehicle Insurance Fraud Detection

Vehicle insurance fraud involves conspiring to make false or exaggerated claims involving property damage or personal injuries following an accident. Some common examples include staged accidents where fraudsters deliberately “arrange” for accidents to occur; the use of phantom passengers where people who were not even at the scene of the accident claim to have suffered grievous injury, and make false personal injury claims where personal injuries are grossly exaggerated.


### About this dataset

This dataset contains vehicle dataset - attribute, model, accident details, etc along with policy details - policy type, tenure etc. The target is to detect if a claim application is fraudulent or not - FraudFound_P
",.csv
Vehicle Insurance Fraud Detection,1,vehicle-insurance-fraud-detection,carclaims.csv,CC0-1.0,"The dataset is an automobile insurance dataset “carclaims”, which is publically available and is provided by Angoss Knowledge Seeker. It has 15420 samples, of which 14497 are legitimate and 923 fraudulent, which indicates high class imbalance.",.csv
Vehicle Maintenance Data,1,vehicle-maintenance-data,vehicle_maintenance_data.csv,MIT,"### Vehicle Maintenance Dataset

#### Overview
This dataset provides synthetic data related to vehicle maintenance to help predict whether a vehicle requires maintenance or not based on various features.

#### Features

1. **Vehicle_Model**: Type of the vehicle (Car, SUV, Van, Truck, Bus, Motorcycle)
2. **Mileage**: Total mileage of the vehicle
3. **Maintenance_History**: Maintenance history of the vehicle (Good, Average, Poor)
4. **Reported_Issues**: Number of reported issues
5. **Vehicle_Age**: Age of the vehicle in years
6. **Fuel_Type**: Type of fuel used (Diesel, Petrol, Electric)
7. **Transmission_Type**: Transmission type (Automatic, Manual)
8. **Engine_Size**: Size of the engine in cc (Cubic Centimeters)
9. **Odometer_Reading**: Current odometer reading of the vehicle
10. **Last_Service_Date**: Date of the last service
11. **Warranty_Expiry_Date**: Date when the warranty expires
12. **Owner_Type**: Type of vehicle owner (First, Second, Third)
13. **Insurance_Premium**: Insurance premium amount
14. **Service_History**: Number of services done
15. **Accident_History**: Number of accidents the vehicle has been involved in
16. **Fuel_Efficiency**: Fuel efficiency of the vehicle in km/l (Kilometers per liter)
17. **Tire_Condition**: Condition of the tires (New, Good, Worn Out)
18. **Brake_Condition**: Condition of the brakes (New, Good, Worn Out)
19. **Battery_Status**: Status of the battery (New, Good, Weak)
20. **Need_Maintenance**: Target variable indicating whether the vehicle needs maintenance (1 = Yes, 0 = No)

#### Target Variable
- **Need_Maintenance**: Indicates whether the vehicle requires maintenance or not based on specified conditions.

#### Data Range
- Total number of records: 50,000

#### Source
This dataset is synthetic and was generated using Python. It is intended for educational and research purposes.

#### Acknowledgements
- The dataset was generated using Python and the data is synthetic.


",.csv
Vehicle Manufacturing Dataset,1,vehicle-manufacturing-dataset,Car Data.csv,Apache 2.0,"he dataset provides a synthetic representation of car data, encompassing various attributes such as car brand, model, manufacturing year, color, mileage, price, and location. Each row represents a unique car, identified by the Car ID. The dataset includes information about popular car brands such as Toyota, Honda, Ford, Chevrolet, and Hyundai, along with their respective models.

Additional columns capture key details, including the manufacturing year, color, mileage, price, and location of each car. These details offer insights into the variety of cars available in different regions. The dataset comprises a mix of sedans, SUVs, and hatchbacks, showcasing a range of options for potential buyers.

It is important to note that this is a synthetic dataset, created for demonstration purposes only. The values provided for attributes like mileage, price, and location are fictional and do not represent real-world data. However, this dataset can be utilized for various analytical tasks, such as market research, trend analysis, and data modeling in the automotive industry.",.csv
Vehicle_Sales_Count by Year 2002-2023,1,vehicle-sales-count-by-year-2002-2023,MVA_Vehicle_Sales_Counts_by_Month_for_Calendar_Year_2002_through_December_2023.csv,Apache 2.0,"The dataset ""Vehicle_Sales_Count by Year 2002-2023"" provides a comprehensive record of the annual sales counts of vehicles spanning from 2002 to 2023. It offers valuable insights into the trends and patterns of vehicle sales over the years, allowing analysts and stakeholders to understand the dynamics of the automotive market and make informed decisions. With this dataset, researchers can explore how factors such as economic conditions, technological advancements, and consumer preferences have influenced vehicle sales trends over the specified timeframe.",.csv
Vehicles For Hire Dataset,1,vehicles-dataset,For_Hire_Vehicles__FHV__-_Active_20240407.csv,Apache 2.0,"This dataset provides a comprehensive registry of For-Hire Vehicles operating in New York City, including license numbers, vehicle VINs, certification dates, and more. For Hire Vehicles encompass various transportation services, including black car services, livery vehicles, and those affiliated with ride-hailing companies like Uber.

This dataset, which includes all TLC licensed for-hire vehicles which are in good standing and able to drive.

",.csv
Vending Machine Sales,1,vending-machine-sales,vending_machine_sales.csv,CC0-1.0,"This dataset represents vending machine data from various locations in Central New Jersey. The locations include a library, a mall, office location and a manufacturing locations. Data scientists can make use of the data to understand trends, user behavior and overall preferences by consumers at different locations. 

The location and machine data is as follows 
(1) Gutten Plans - Frozen dough specialist company that operates 24/5 .  Vending machine assigned is GuttenPlans x1367
(2) EB Public Library - Public library that has high foot traffic 5-6 days a week. Vending machine : EB Public Library x1380
(3) Brunswick Sq Mall - Mall with average foot traffic 7 days a week. Vending machine(s) : BSQ Mall x1364 - Zales & BSQ Mall x1366 - ATT
(4) Earle Asphalt - A construction engineering firm that operates 5 days a week. Vending machine :  Earle Asphalt x1371
",.csv
Video Game Sales 2024,1,video-game-sales-2024,vgchartz-2024.csv,ODC Attribution License (ODC-By),"This dataset is a continuation of @[baynebrannen](https://www.kaggle.com/baynebrannen)'s [2020 Video Game Sales](https://www.kaggle.com/datasets/baynebrannen/video-game-sales-2020) dataset and @ashaheedq's  [2019 Video Games Sales](https://www.kaggle.com/datasets/ashaheedq/video-games-sales-2019)  dataset.

Creation of this dataset was inspired by @[VinceTheCat02](https://www.reddit.com/user/VinceTheCat02/).

Data was collected by running the spider written by @baynebrannen to create his version of the dataset. 

- I haven't made any major modification to the collection methodology or the dataset structure. 
- I have removed a few unhelpful columns such as `'vg_score', 'user_score', and 'total_shipped'` as these columns mostly contained null values. 
- All the other columns remain the same.


---

Photo by <a href=""https://unsplash.com/@jeshoots?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">JESHOOTS.COM</a> on <a href=""https://unsplash.com/photos/two-people-playing-sony-ps4-game-console-eCktzGjC-iU?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv
Video Game Sales Dataset Updated -Extra Feat,1,video-games-sales-dataset-2022-updated-extra-feat,Video_Games.csv,CC0-1.0,"### Video Games Sales Dataset 

##### ***About Dataset***
&gt; This Dataset provides up-to-date information on the sales performance and popularity of various video games worldwide. The data includes the name, platform, year of release, genre, publisher, and sales in North America, Europe, Japan, and other regions. It also features scores and ratings from both critics and users, including average critic score, number of critics reviewed, average user score, number of users reviewed, developer, and rating. This comprehensive and essential dataset offers valuable insights into the global video game market and is a must-have tool for gamers, industry professionals, and market researchers. 
*by [source](https://data.world/sumitrock/video-games-sales/workspace/file?filename=Video_Games.csv)*

______

**More Datasets**
&gt; For more datasets, click [here](https://www.kaggle.com/ibriiee/datasets).

_____________

##### ***Columns***
|Column Name | Description |
--- | ---
**Name** | The name of the video game.
**Platform** | The platform on which the game was released, such as PlayStation, Xbox, Nintendo, etc.
**Year of Release** | The year in which the game was released.
**Genre** | The genre of the video game, such as action, adventure, sports, etc.
**Publisher** | The company responsible for publishing the game.
**NA Sales** | The sales of the game in North America.
**EU Sales** |The sales of the game in Europe.
**JP Sales** |The sales of the game in Japan.
**Other Sales**| The sales of the game in other regions.
**Global Sales**| The total sales of the game across the world.
**Critic Score** |The average score given to the game by professional critics.
**Critic Count**|The number of critics who reviewed the game.
**User Score**|The average score given to the game by users.
**User Count**|The number of users who reviewed the game.
**Developer**|The company responsible for developing the game.
**Rating**| The rating assigned to the game by organizations such as the ESRB or PEGI.

_____

##### ***Research Ideas / Data Use***
&gt; - **Market Analysis:** The video game sales data can be used to analyze market trends and identify popular genres, platforms, and publishers. This can be useful for industry professionals to make informed decisions about game development and marketing strategies.
- **Sales Forecasting:** The sales data can be used to forecast future trends and predict the success of upcoming games.
- **Consumer Insights:** The data can be analyzed to gain insights into consumer preferences and buying habits, which can be used to tailor marketing strategies and improve customer satisfaction.
- **Comparison of Competitors:** The data can be used to compare the sales performance of competing video games and identify market leaders.
- **Gaming Industry Performance:** The data can be used to evaluate the overall performance of the gaming industry and track its growth over time.
- **Gaming Popularity by Region:** The data can be analyzed to determine which regions are the largest markets for video games and which genres are most popular in each region.
- **Impact of Reviews:** The data can be used to study the impact of critic and user reviews on sales and the relationship between scores and sales performance.
- **Gaming Trends over Time:** The data can be used to identify trends in the gaming industry over time and to track the evolution of the market.
- **Gaming Demographics:** The data can be used to analyze the demographic makeup of the gaming audience, including age, gender, and income.
- **Impact of Gaming Industry on the Economy:** The data can be used to evaluate the impact of the gaming industry on the economy and to assess its contribution to job creation and economic growth.

_____

#####***Acknowledgements***
&gt;*if this dataset was used in your work or studies, please credit the original [source](https://data.world/sumitrock/video-games-sales)*
**Please Credit ↑**  ⠀⠀⠀
",.csv
Video Games Sales,1,video-games-sales,Video_Games.csv,Attribution 4.0 International (CC BY 4.0),"Are you a gamer or a video game enthusiast? Then, you're in for a treat! The dataset we have here provides a treasure trove of information about video game sales, spanning multiple years and different regions and platforms.

This dataset is a dream come true for anyone who wants to gain insights into the dynamic world of video games. With data on the number of units sold, revenue generated, and other key metrics, the dataset can help answer burning questions such as: What are the top-selling video games of all time? Which platforms are the most popular among gamers? How do video game sales vary by region?

But that's not all. This dataset is also a goldmine for video game developers and publishers who want to stay ahead of the curve in this highly competitive industry. By analyzing the data, they can gain valuable insights into the preferences and behaviors of gamers, and use this information to inform their marketing and development strategies.

And let's not forget investors and other stakeholders, who can use this dataset to evaluate the performance of video game companies and make informed investment decisions.

So, whether you're a gamer, a developer, an investor, or just someone curious about the world of video games, this dataset is a must-have resource that will not disappoint!",.csv
Violent Crime Rates by US State,1,violent-crime-rates-by-us-state,US_violent_crime.csv,DbCL-1.0,"### Context

Violent Crime Rates by US State


### Content

This data set contains statistics, in arrests per 100,000 residents for assault, murder, and rape in each of the 50 US states in 1973. Also given is the percent of the population living in urban areas. 

A data frame with 50 observations on 4 variables. 
&gt; Murder is numeric and Murder arrests (per 100,000)
&gt; Assault is numeric and Assault arrests (per 100,000)
&gt; UrbanPop is numeric and UrbanPop arrests (per 100,000)
&gt; Rape is numeric and Rape arrests (per 100,000)

### Source

World Almanac and Book of facts 1975. (Crime rates).

Statistical Abstracts of the United States 1975. (Urban rates).


### References

McNeil, D. R. (1977) Interactive Data Analysis. New York: Wiley. ",.csv
Virat-Kohli-All-International-Cricket-Centuries,1,virat-kohli-all-international-cricket-centuries,Virat-Kohli-International-Cricket-Centuries.csv,CC-BY-SA-3.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F14601120%2F9e84f56e62aa0a5506d19e275d9952a7%2F5811475%20(1).jpg?generation=1686683233400144&alt=media)

Hello Kaggle community!

I am excited to announce the latest update to the **""Virat-Kohli-All-International-Cricket-Centuries""** dataset. This dataset provides comprehensive information about every century scored by the legendary **Indian** cricketer, Virat Kohli, in international cricket. Whether you're a cricket enthusiast, data analyst, or just a fan of Virat Kohli, this dataset is a valuable resource for analyzing his remarkable career.

**Dataset Information:**
- **Dataset Name:** Virat-Kohli-All-International-Cricket-Centuries
- **Updated Version:** 5.0
- **Last Update:** 27 November, 2023

**Key Features:**
1. **Match Details:** This dataset includes details such as match date, opposition team, venue, and match format (Test, ODI, or T20I).
2. **Innings Information:** For each century, you'll find information about the innings number (1st or 2nd) and whether it was in a winning cause.
3. **Match Result:** The result of the match (Win, Lose, or Draw).

**How to Use the Dataset:**
- Analyze Virat Kohli's century-scoring patterns.
- Check if his centuries had an impact on match outcomes.
- Compare his centuries against specific opponents or in different venues.

**Acknowledgment:**
I want to express my gratitude to the Kaggle community for their support and feedback in improving this dataset. Your contributions have been instrumental in making this dataset a valuable resource for cricket enthusiasts and data analysts alike.

**Feedback and Contributions:**
I encourage everyone to provide feedback, report issues, or contribute to this dataset. Your insights and additions can help make this dataset even more comprehensive and insightful.

**Stay Updated:**
To stay informed about future updates and cricket-related datasets, don't forget to follow my Kaggle profile.

Thank you for your continued interest in the ""Virat-Kohli-All-International-Cricket-Centuries"" dataset. Enjoy exploring Virat Kohli's incredible journey in international cricket through the power of data!

Happy Analyzing!",.csv
Virtual Reality Experiences,1,virtual-reality-experiences,data.csv,Community Data License Agreement - Sharing - Version 1.0,"The dataset consists of user experiences in virtual reality (VR) environments. It includes data related to physiological responses, such as heart rate and skin conductance, emotional states, and user preferences. The purpose of the dataset is to enhance VR technology by analyzing user experiences. This analysis aims to improve VR design, user comfort, and customization by understanding how users physiologically and emotionally respond to different VR environments. The dataset enables developers to optimize VR systems and create tailored experiences to enhance immersion and overall user satisfaction.


1. User ID: This variable represents a unique identifier for each user participating in the VR experience. It assigns a distinct ID to each user to differentiate their data in the dataset.

2. Age: This variable captures the age of the user who participated in the VR experience. It represents the user's age at the time of the VR experience and can be an integer value.

3. Gender: This variable denotes the gender of the user. It can have categories such as 'Male', 'Female', or 'Other', representing the gender identity of the user.

4. VR Headset Type: This variable specifies the type of VR headset used by the user during the VR experience. It can include options like 'Oculus Rift', 'HTC Vive', 'PlayStation VR', or other types of VR headsets.

5. Duration: This variable represents the duration of the VR experience in minutes. It captures the length of time the user spent engaged in the virtual reality environment.

6. Motion Sickness Rating: This variable indicates the user's self-reported rating of motion sickness experienced during the VR experience. It can be on a scale of 1 to 10, with higher values indicating a higher level of motion sickness.

Dependent Variable:

7. Immersion Level: This variable measures how immersed the user felt during the VR experience. It represents the subjective level of immersion reported by the user and can be measured on a scale of 1 to 5, with 5 indicating the highest level of immersion.",.csv
Void formation process data in welding,1,void-formation-process-data-in-welding,Welding_process_parameters.csv,Community Data License Agreement - Sharing - Version 1.0,"The dataset contains the various welding parameters that may or may not lead to void defects in welding. The specific type of welding is Friction Stir Welding, a modern form of solid-state welding technique. This process is a widely used technique in state-of-the-art modern technologies. However, while such a solid-state technique has many advantages over conventional welding techniques, it is also susceptible to welding defects such as void defects. This kind of defect often leads to catastrophic failure of mechanical structures. Hence, it is important to be able to predict such instances by analysing and predicting the correct conditions of process parameters that may lead to a safe welding joint.

Kindly refer to a published study on the above problem statement for more details: https://doi.org/10.1016/j.matpr.2023.03.386 ",.csv
Volcanic Eruptions in the Holocene Period,1,volcanic-eruptions,database.csv,CC0-1.0,"# Content

The Smithsonian Institution's Global Volcanism Program (GVP) documents Earth's volcanoes and their eruptive history over the past 10,000 years. The GVP reports on current eruptions from around the world and maintains a database repository on active volcanoes and their eruptions. The GVP is housed in the Department of Mineral Sciences, part of the National Museum of Natural History, on the National Mall in Washington, D.C.

The GVP database includes the names, locations, types, and features of more than 1,500 volcanoes with eruptions during the Holocene period (approximately the last 10,000 years) or exhibiting current unrest.",.csv
WHO Suicide Statistics,1,who-suicide-statistics,who_suicide_statistics.csv,other,"### Context and inspiration

This dataset was necessary for me to write my [Suicide in the Twenty-First Century][1] piece. 

Looking at the data, you can observe long-time trends and differences between countries, as well as within countries across a few demographic groups - in both cases you will see that these differences may be very large.


### Content

Basic aggregate numbers covering 1979-2016, by country, year, age groups and sex. There is only one file, with only a few columns. I made this file using the [WHO Mortality Database online tool][2].


### Acknowledgements and license

I prepared and uploaded the data file without WHO's knowledge, let alone approval or endorsement. Yet, the data itself belongs to WHO, so please see the [WHO copyrights, permission and licensing][3] pages if you want to use it.

Photo by [Daniela Rocha][4] on Unsplash.


  [1]: https://www.kaggle.com/szamil/suicide-in-the-twenty-first-century/
  [2]: http://apps.who.int/healthinfo/statistics/mortality/whodpms/
  [3]: http://www.who.int/about/copyright/en/
  [4]: https://unsplash.com/@danirocha16",.csv
Wages by Education in the USA (1973-2022),1,wages-by-education-in-the-usa-1973-2022,wages_by_education.csv,CC0-1.0,"The Wages by Education dataset provides insight into the average hourly wages of workers in the USA, disaggregated by the highest level of education attained. 

This dataset covers the period from 1973 to 2022 and is sourced from the Economic Policy Institute’s State of Working America Data Library.

## Interesting Insights & Research Areas:

1. Explore the wage gap based on education level and identify trends over time.
2. Analyze the impact of education on wages for different demographic groups (gender, race/ethnicity).
3. Investigate changes in wage inequality between education groups over the decades.
4. Examine the relationship between wages and economic indicators such as inflation and GDP.
5. Compare wage trends in different sectors or industries based on education levels.
6. Visualize the wage premiums associated with advanced degrees and their changes over time.
7. Explore how educational attainment affects wage disparity.

---

If you find this dataset valuable, don't forget to hit the upvote button! 😊💝 

---

### Checkout my other datasets

[Employment-to-Population Ratio for USA ](https://www.kaggle.com/datasets/asaniczka/employment-to-population-ratio-for-usa-1979-2023)

[USA Hispanic-White Wage Gap Dataset ](https://www.kaggle.com/datasets/asaniczka/usa-hispanic-white-wage-gap-dataset-1973-2022)

[USA Wage Comparison for College vs. High School](https://www.kaggle.com/datasets/asaniczka/usa-wage-comparison-for-college-vs-high-school)

[USA Unemployment Rates by Demographics & Race](https://www.kaggle.com/datasets/asaniczka/unemployment-rates-by-demographics-1978-2023)

[13K Reddit Tips](https://www.kaggle.com/datasets/asaniczka/helpful-life-tips-from-reddit-dataset-13k-tips)

---

Photo by [Vasily Koloda](https://unsplash.com/@napr0tiv?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash) on [Unsplash](https://unsplash.com/photos/8CqDvPuo_kI?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)",.csv
Walmart Cleaned Data,1,walmartcleaned,walmart_cleaned.csv,CC0-1.0,"## Description:
One of the leading retail stores in the US, Walmart, would like to predict the sales and demand accurately. There are certain events and holidays which impact sales on each day. There are sales data available for 45 stores of Walmart. The business is facing a challenge due to unforeseen demands and runs out of stock some times, due to the inappropriate machine learning algorithm. An ideal ML algorithm will predict demand accurately and ingest factors like economic conditions including CPI, Unemployment Index, etc.

Walmart runs several promotional markdown events throughout the year. These markdowns precede prominent holidays, the four largest of all, which are the Super Bowl, Labour Day, Thanksgiving, and Christmas. The weeks including these holidays are weighted five times higher in the evaluation than non-holiday weeks. Part of the challenge presented by this competition is modeling the effects of markdowns on these holiday weeks in the absence of complete/ideal historical data. Historical sales data for 45 Walmart stores located in different regions are available.

## Acknowledgements
The dataset is taken from world.data

## Objective:
- Understand the Dataset.
- Time Series Forecasting.
- Anomaly Detection.
- Build Regression models to predict the sales w.r.t single & multiple features.
- Also evaluate the models & compare their respective scores like R2, RMSE, etc.",.csv
Walmart Data Analysis and Forcasting,1,walmart-data-analysis-and-forcasting,Walmart Data Analysis and Forcasting.csv,CC0-1.0,"A retail store that has multiple outlets across the country are facing issues in managing the
inventory - to match the demand with respect to supply. You are a data scientist, who has to
come up with useful insights using the data and make prediction models to forecast the sales for
X number of months/years.",.csv
Walmart Dataset,1,walmart-dataset,Walmart.csv,CC0-1.0,"![](https://raw.githubusercontent.com/Masterx-AI/Project_Retail_Analysis_with_Walmart/main/Wallmart1.jpg)

### Description:

One of the leading retail stores in the US, Walmart, would like to predict the sales and demand accurately. There are certain events and holidays which impact sales on each day. There are sales data available for 45 stores of Walmart. The business is facing a challenge due to unforeseen demands and runs out of stock some times, due to the inappropriate machine learning algorithm. An ideal ML algorithm will predict demand accurately and ingest factors like economic conditions including CPI, Unemployment Index, etc.

Walmart runs several promotional markdown events throughout the year. These markdowns precede prominent holidays, the four largest of all, which are the Super Bowl, Labour Day, Thanksgiving, and Christmas. The weeks including these holidays are weighted five times higher in the evaluation than non-holiday weeks. Part of the challenge presented by this competition is modeling the effects of markdowns on these holiday weeks in the absence of complete/ideal historical data. Historical sales data for 45 Walmart stores located in different regions are available.

### Acknowledgements
The dataset is taken from Kaggle.

### Objective:
- Understand the Dataset & cleanup (if required).
- Build Regression models to predict the sales w.r.t single & multiple features.
- Also evaluate the models & compare their respective scores like R2, RMSE, etc.",.csv
Walmart Sales,1,walmart-sales,Walmart_sales.csv,other,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16192307%2Fcffdbe90e777479a7cfca50b15a20f4e%2FWalmart5-scaled-1.jpg?generation=1707928578479827&alt=media)

We will study the sales data of one of the largest retailers in the world. Let's figure out what factors influence its revenue. Can factors such as air temperature and fuel cost influence the success of a huge company along with the purchasing power index and seasonal discounts? And how does machine learning minimize costs and increase economic impact?

The data contains the following columns:

- Store: Store number
- Date: Sales week start date
- Weekly_Sales: Sales
- Holiday_Flag: Mark on the presence or absence of a holiday
- Temperature: Air temperature in the region
- Fuel_Price: Fuel cost in the region
- CPI: Consumer price index
- Unemployment: Unemployment rate
___",.csv
Walmart Stocks from 2000,1,walmart-stocks-from-2000,WMT.csv,CC0-1.0,"This dataset contains the Walmart stock prices from 01/01/2000 to 04/27/2024. The columns are as follows:

```Date``` - The date

```Open``` - The opening value

```High``` - The highest value

```Low``` - The lowest value

```Close``` - The closing value

```Adj Close``` - The adjusted closing value

```Volume``` - The trading volume of the stocks

I hope you will like this dataset. God bless you.",.csv
Walmart commerce data,1,walmart-commerce-data,WalmartSQL repository..csv,CC0-1.0,"The dataset provides comprehensive information on sales transactions conducted by Walmart, one of the leading retail chains globally. It encompasses various attributes including Invoice ID, Branch, City, Customer Type, Gender, Product Line, Unit Price, Quantity, Tax (5%), Total Price, Date, Time, Payment Method, Cost of Goods Sold (COGS), Gross Margin Percentage, Gross Income, and Rating. This rich dataset facilitates detailed analysis and insights into sales patterns, customer preferences, revenue generation, and performance evaluation, empowering businesses to make informed decisions and strategies to enhance their operational efficiency and customer satisfaction.",.csv
Wase Navigation App Dataset,1,wase-navigation-app-dataset,waze_app_dataset.csv,Apache 2.0,"The dataset offers a comprehensive insight into user interactions within the Waze navigation app, crucial for understanding and mitigating user churn. Waze, renowned for its free navigation services, fosters a dynamic community of contributors, including map editors, beta testers, and partners, united in the mission to enhance global travel efficiency and safety.

Ideal for both exploratory data analysis (EDA) and **machine learning (ML)**, the dataset enables the development of accurate models to pinpoint factors contributing to churn. These models address critical questions such as **who, why, and when users churn**, empowering proactive retention strategies.

**Note: This dataset has been created for educational purposes**.",.csv
Water Potability Dataset,1,water-potability-dataset-with-10-parameteres,water_potability.csv,CC0-1.0,"######  📚 **Context**
Access to safe drinking-water is essential to health, a basic human right and a component of effective policy for health protection. This is important as a health and development issue at a national, regional and local level. In some regions, it has been shown that investments in water supply and sanitation can yield a net economic benefit, since the reductions in adverse health effects and health care costs outweigh the costs of undertaking the interventions.

######  📝 **Content**
The water_potability.csv file contains water quality metrics for 3276 different water bodies.

1. **pH value:**
PH is an important parameter in evaluating the acid–base balance of water. It is also the indicator of acidic or alkaline condition of water status. WHO has recommended maximum permissible limit of pH from 6.5 to 8.5. The current investigation ranges were 6.52–6.83 which are in the range of WHO standards.

2. **Hardness:**
Hardness is mainly caused by calcium and magnesium salts. These salts are dissolved from geologic deposits through which water travels. The length of time water is in contact with hardness producing material helps determine how much hardness there is in raw water. Hardness was originally defined as the capacity of water to precipitate soap caused by Calcium and Magnesium.

3. **Solids (Total dissolved solids - TDS):**
Water has the ability to dissolve a wide range of inorganic and some organic minerals or salts such as potassium, calcium, sodium, bicarbonates, chlorides, magnesium, sulfates etc. These minerals produced un-wanted taste and diluted color in appearance of water. This is the important parameter for the use of water. The water with high TDS value indicates that water is highly mineralized. Desirable limit for TDS is 500 mg/l and maximum limit is 1000 mg/l which prescribed for drinking purpose.

4. **Chloramines:**
Chlorine and chloramine are the major disinfectants used in public water systems. Chloramines are most commonly formed when ammonia is added to chlorine to treat drinking water. Chlorine levels up to 4 milligrams per liter (mg/L or 4 parts per million (ppm)) are considered safe in drinking water.

5. **Sulfate:**
Sulfates are naturally occurring substances that are found in minerals, soil, and rocks. They are present in ambient air, groundwater, plants, and food. The principal commercial use of sulfate is in the chemical industry. Sulfate concentration in seawater is about 2,700 milligrams per liter (mg/L). It ranges from 3 to 30 mg/L in most freshwater supplies, although much higher concentrations (1000 mg/L) are found in some geographic locations.

6. **Conductivity:**
Pure water is not a good conductor of electric current rather’s a good insulator. Increase in ions concentration enhances the electrical conductivity of water. Generally, the amount of dissolved solids in water determines the electrical conductivity. Electrical conductivity (EC) actually measures the ionic process of a solution that enables it to transmit current. According to WHO standards, EC value should not exceeded 400 μS/cm.

7. **Organic_carbon:**
Total Organic Carbon (TOC) in source waters comes from decaying natural organic matter (NOM) as well as synthetic sources. TOC is a measure of the total amount of carbon in organic compounds in pure water. According to US EPA &lt; 2 mg/L as TOC in treated / drinking water, and &lt; 4 mg/Lit in source water which is use for treatment.

8. **Trihalomethanes:**
THMs are chemicals which may be found in water treated with chlorine. The concentration of THMs in drinking water varies according to the level of organic material in the water, the amount of chlorine required to treat the water, and the temperature of the water that is being treated. THM levels up to 80 ppm is considered safe in drinking water.

9. **Turbidity:**
The turbidity of water depends on the quantity of solid matter present in the suspended state. It is a measure of light emitting properties of water and the test is used to indicate the quality of waste discharge with respect to colloidal matter. The mean turbidity value obtained for Wondo Genet Campus (0.98 NTU) is lower than the WHO recommended value of 5.00 NTU.

10. **Potability:**
Indicates if water is safe for human consumption where 1 means Potable and 0 means Not potable.",.csv
Water Probability,1,water-probability,water_potability.csv,CC0-1.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F12038776%2F8b7d6cf60b9cc0d9c5c95fdf21f4a826%2FIndependent-Water-analysis.jpg?generation=1713161403384080&alt=media)

# **Water Quality Dataset**
- This dataset contains information about water quality features and potability. It consists of 3276 entries with 10 columns:

```python
pH: pH of the water (measured in pH units).
Hardness: Hardness of the water (measured in mg/L).
Solids: Total dissolved solids in the water (measured in ppm).
Chloramines: Amount of chloramines in the water (measured in ppm).
Sulfate: Amount of sulfate in the water (measured in mg/L).
Conductivity: Conductivity of the water (measured in μS/cm).
Organic_carbon: Amount of organic carbon in the water (measured in ppm).
Trihalomethanes: Amount of trihalomethanes in the water (measured in μg/L).
Turbidity: Turbidity of the water (measured in NTU).
Potability: Potability of the water (1 indicates potable, 0 indicates non-potable).
```
**Summary Statistics:**
- The dataset contains 3276 entries.
- The columns ""pH"", ""Sulfate"", and ""Trihalomethanes"" have missing values.
- The data types of the columns are float64 for features and int64 for the target variable (Potability).

**Usage:**
- This dataset can be used for various tasks, including:
- Exploratory data analysis (EDA) to understand the distributions and relationships between features.
- Predictive modeling to predict water potability based on its features.
- Feature engineering to create new features or handle missing values.
- Model evaluation to assess the performance of machine learning models in predicting water potability.",.csv
Water Quality & Potability Dataset,1,crop-water-management-and-quality,water_quality.csv,Apache 2.0,"&gt;**Water Quality & Potability (CODE & DATASET)**

This type of dataset is invaluable for water quality monitoring agencies, researchers, environmental organizations, and policymakers who are concerned with assessing and ensuring the safety of drinking water supplies. Machine learning models can also be trained on this data to predict water potability based on TDS, pH, turbidity levels, etc., facilitating early detection of water quality issues and informed decision-making regarding water treatment and management.

Dataset size : 3276 rows × 10 columns

**Github Link -**
Code & description : https://github.com/TusharPaul01/Water-Quality-IoT-ML

Dataset Info :
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F11965067%2Fd80e8dc47f98b0ec8c6a185c2691867b%2FCapture.JPG?generation=1704955109447938&alt=media)


![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F11965067%2F4fe77a9c440c5504f495360635e4d8f2%2FCapture2.JPG?generation=1704955655870974&alt=media)


&gt;IEEE Research paper link for further reference : https://ieeexplore.ieee.org/abstract/document/10165824",.csv
Water Quality Testing,1,water-quality-testing,Water Quality Testing.csv,CC0-1.0,"Water quality is a crucial aspect of environmental management, and it is essential to measure various physical, chemical, and biological parameters to monitor it effectively. This dataset of 200 rows contains measurements of six critical water quality parameters widely used in water quality monitoring and analysis. The dataset provides a representative snapshot of water quality and can be used for various research, education, and decision-making purposes.

The six parameters measured in this dataset are:

pH: pH measures the acidity or basicity of a liquid on a scale from 0 to 14. Values less than 7 indicate acidic conditions, values greater than 7 suggest primary needs and a value of 7 indicates a neutral state.

Dissolved Oxygen (DO): DO measures the amount of oxygen dissolved in water and is essential for aquatic life. High DO levels are crucial for the survival of fish and other marine organisms.

Temperature: Temperature affects various physical, chemical, and biological processes in water bodies. It is an essential factor that influences the rate of many aquatic processes.

Biochemical Oxygen Demand (BOD): BOD measures the amount of oxygen microorganisms require to decompose organic matter in water. High BOD levels can indicate that the water is polluted with organic matter and may not be suitable for consumption or recreation.

Total Suspended Solids (TSS): TSS measures the amount of solids suspended in water, including organic matter, sediment, and other pollutants. High TSS levels can indicate poor water quality and affect aquatic life and other uses of water.

Nitrate-Nitrogen (NO3-N): NO3-N measures the amount of nitrate in water. Nitrate is an essential nutrient for plant growth, but high nitrate levels in drinking water can harm human health.

The dataset contains 200 rows, each representing a unique water quality measurement across all six parameters. The dataset suits various data science applications such as data visualization, machine learning, and statistical analysis. It can be used to explore and analyze water quality trends, patterns, and relationships and can help researchers and analysts gain insights into the complex dynamics of water quality.

**Please upvote this dataset if you like it**",.csv
Water Quality and Potability,1,water-quality-and-potability,water_potability.csv,Apache 2.0,"&gt;****Don't forget to upvote when you find this useful****

This dataset contains water quality measurements and assessments related to potability, which is the suitability of water for human consumption. The dataset's primary objective is to provide insights into water quality parameters and assist in determining whether the water is potable or not. Each row in the dataset represents a water sample with specific attributes, and the ""Potability"" column indicates whether the water is suitable for consumption.

**Columns:**

pH: The pH level of the water.
Hardness: Water hardness, a measure of mineral content.
Solids: Total dissolved solids in the water.
Chloramines: Chloramines concentration in the water.
Sulfate: Sulfate concentration in the water.
Conductivity: Electrical conductivity of the water.
Organic_carbon: Organic carbon content in the water.
Trihalomethanes: Trihalomethanes concentration in the water.
Turbidity: Turbidity level, a measure of water clarity.
Potability: Target variable; indicates water potability with values 1 (potable) and 0 (not potable).

**Objective:**
The main objective of this dataset is to assess and predict water potability based on water quality attributes. It can be used for evaluating the safety and suitability of water sources for human consumption, making informed decisions about water treatment, and ensuring compliance with water quality standards.

**Machine Learning Task:**
This dataset is suitable for a supervised binary classification task, where machine learning models can be trained to predict water potability based on the provided water quality attributes. The models aim to classify water samples as potable (1) or not potable (0).

**Data Usage:**
This dataset is valuable for water quality assessment, water treatment planning, and ensuring the safety of drinking water supplies. It can be utilized by water treatment plants, environmental agencies, and researchers to make data-driven decisions regarding water quality and potability.

**Data Source:**
The data was collected from [here](https://github.com/MainakRepositor/Datasets/blob/master/water_potability.csv)
Credits go to them.

",.csv
Water Scarcity - Water Footprint,1,cusersmarildownloadsscarcitycsv,scarcity.csv,other,"### Context

Dataset showing blue water scarcity in the world on a monthly basis at high spatial resolution.

https://waterfootprint.org/en/resources/waterstat/water-scarcity-statistics/


### Content

Monthly blue water scarcity for the world’s major river basins (1996-2005)

### Acknowledgements

Reference: Hoekstra, A.Y., Mekonnen, M.M., Chapagain, A.K., Mathews, R.E. & Richter, B.D. (2012) Global monthly water scarcity: Blue water footprints versus blue water availability, PLoS ONE, 7(2): e32688.

https://waterfootprint.org/en/resources/waterstat/water-scarcity-statistics/

Photo by Tomas Eidsvold on Unsplash

### Inspiration

FLOW: For Love of Water documentary.",.csv
Water bodies quality data - India,1,water-quality-data-india,Water_pond_tanks_2021.csv,CC0-1.0,"# Context

Water quality is one of the most important factors in a healthy ecosystem. Clean water supports a diversity of plants and wildlife. Though it may seem unrelated at first, our actions on land affect the quality of our water. Pollutants, excessive nutrients from fertilizers, and sediment frequently get carried into local lakes and rivers via runoff from urban areas or agricultural fields.

Scientists measure a variety of properties to determine water quality. These include temperature, acidity (pH), dissolved solids (specific conductance), particulate matter (turbidity), dissolved oxygen, hardness, and suspended sediment. Each reveals something different about the health of a water body.

The following water properties are important in determining water quality:

`Temperature:` Water temperature is important to fish and aquatic plants. Temperature can affect the level of oxygen, as well as the ability of organisms to resist certain pollutants.

`Acidity – pH:` The measurement of pH is a measure of the amount of hydrogen ions (H+) present in a substance such as water. Knowing the amount of hydrogen in a substance allows us to judge whether it is acidic, neutral, or basic.

`Dissolved Oxygen:` A small amount of oxygen, about ten molecules of oxygen per million molecules of water, is dissolved in water. Fish and microscopic organisms need dissolved oxygen to survive.

`Turbidity:` Turbidity makes the water cloudy or opaque. Turbidity is the amount of particulate matter (such as clay, silt, plankton, or microscopic organisms) suspended in water. 

`Specific Conductance:` Specific conductance measures the capacity of water to conduct an electrical current. It depends on the number of dissolved solids, such as salt, in the water.

`Biochemical Oxygen Demand (BOD)` is a measure of the amount of oxygen required to remove waste organic matter from water in the process of decomposition by aerobic bacteria (those bacteria that live only in an environment containing oxygen). Higher BOD indicates more oxygen is required, which is less for oxygen-demanding species to feed on, and signifies lower water quality. Inversely, low BOD means less oxygen is being removed from water, so water is generally purer.

`Nitrite and Nitrate` - Nitrate and nitrite are soluble compounds containing nitrogen and oxygen. In the environment, nitrite (NO2 - ) generally converts to nitrate (NO3 - ), which means nitrite occurs very rarely in groundwater. Nitrate is essential for plant growth and is present in all vegetables and grains. For this reason, the predominant use of nitrate in industry is for fertilizer. Nitrite is used for curing meats, manufacturing explosives, and for maintenance of industrial boilers. According to the World Health Organization, the average American male consumes 9-22 milligrams of nitrate-N per day primarily from leafy greens and root vegetables like carrots, beets, and radishes. Average nitrite-N consumption is much lower at 0.1-0.8 mg per day, primarily from cured meats. Intake at these levels is not considered a health risk.

`Fecal coliform` - A fecal coliform is a facultatively anaerobic, rod-shaped, gram-negative, non-sporulating bacterium. Coliform bacteria generally originate in the intestines of warm-blooded animals. In general, increased levels of fecal coliforms provide a warning of failure in water treatment, a break in the integrity of the distribution system, and possible contamination with pathogens. When levels are high there may be an elevated risk of waterborne gastroenteritis. Tests for the bacteria are cheap, reliable,  and rapid (1-day incubation).

For context, coliform must be below 104 MPN/100 mL, preferably absent from water for it to be considered safe for general human use, and for irrigation where coliform may cause disease outbreaks from contaminated-water in agriculture.

References:
1. [Factors affect the water quality](https://www.michiganseagrant.org/lessons/lessons/by-broad-concept/earth-science/water-quality/)
2. [BOD](https://www.usgs.gov/special-topics/water-science-school/science/biological-oxygen-demand-bod-and-water#:~:text=BOD%20is%20a%20measure%20of,in%20an%20environment%20containing%20oxygen)
3. [Nitrite and Nitrate](https://waterquality.montana.edu/well-ed/interpreting_results/fs_nitrate_nitrite.html#:~:text=The%20drinking%20water%20standard%20for%20nitrate%2DN%20is%2010.0%20mg,under%206%20months%20of%20age.)
4. [Fecal coliform](https://en.wikipedia.org/wiki/Fecal_coliform)
5. [Water quality in India](https://en.wikipedia.org/wiki/Water_pollution_in_India#cite_note-9)
6. [Data source](http://www.cpcbenvis.nic.in/water_quality_data.html#)",.csv
Waterloo Enrolment,1,waterloo-enrolment,waterloo-enrolement-2024.csv,CC0-1.0,"this graph was created in Tabelau:

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F31dab6ee8b5e3bfbb926b8fe57e08193%2FUD_Headcount.png?generation=1715038392789640&alt=media)


This public report has been modified to exclude gender filters. The original version of the report, including gender, is located here. You will need to use your WatIAM credentials to view the report

Most recent data available: Winter 2024
Update frequency: Each term
Next update: August 2024

Definitions and Notes
Information on ""program grouping""
The report shows the head count of students per academic term given the filters selected on the right-hand side of the report.
Students are counted once in each term they ﻿register﻿. Adding across terms would result in counting the same student multiple times. For a unique count of students over a fiscal year, refer to the Annual FTE report.
Students on a work term are considered to be full-time. If you want to include/exclude students on a work-term, please use the filter on the bottom right of the report.
Students registered directly at the Affiliated and Federated Institutions of Waterloo (these students are not included in the Performance Indicators)
Data Sources
IAP Count Data Database, based on the Student Administration System (Quest)

Inclusions and Exclusions
Inclusions:

Primary plans only
Non co-op Engineering enrolment is reported in the co-op total; these are generally non-degree and qualifying students
Co-op includes students on a work term and students scheduled for an official work term regardless of whether or not they have a co-op job as of count date
Exclusions:

Non-primary plans (options, minors, etc.)
Wilfrid Laurier University students who are cross-registered at the University of Waterloo
Inactive graduate students
Visiting graduate students",.csv
Watermelon price prediction from weight,1,watermelon-price-prediction-from-weight,melon.csv,other,I use this dataset for Linear Regression model. It is a very small and simple dataset to learn Linear Regression. Actually this dataset can use to learn what is machine learning as beginner. Using this dataset we can describe the differences between traditional programming and machine learning.,.csv
Waves Measuring Buoys Data ,1,waves-measuring-buoys-data-mooloolaba,Coastal Data System - Waves (Mooloolaba) 01-2017 to 06 - 2019.csv,Attribution 4.0 International (CC BY 4.0),"### Content

This dataset contains Measured/Calculated wave parameters. 
Measured and derived wave data from data collected by oceanographic wave measuring buoys anchored at Mooloolaba.
Coverage period: 30 months.


### Acknowledgements

This data comes from Queensland Government Data - https://data.qld.gov.au/dataset. ",.csv
Weapons Used in Crimes in LA,1,weapons-used-in-crimes-in-la,crime totals - total_weapons_used.csv,CC0-1.0,This dataset contains all the different kinds of weapons and how many times they were used to commit crimes in Los Angeles between the years 2020 to early 2024. This dataset was created from the data published by the LAPD and you can find the original dataset [here](https://catalog.data.gov/dataset/crime-data-from-2020-to-present).,.csv
Weather Data in India,1,weather-data-in-india-from-1901-to-2017,Weather Data in India from 1901 to 2017.csv,other,"### Context

This dataset contain mean temperature in india from 1901 to 2017


### Content

Weather data collected from the government data portal. It contains month wise mean weather all over India.


### Acknowledgements

The data was retrieved from the website https://data.gov.in/.

",.csv
Weather Data💧 🌊💦,1,weather-data,Weather Data.csv,Apache 2.0,"Subtitle: Understanding and Utilizing Weather Data

Introduction:

Weather data plays a crucial role in our daily lives and various industries, from agriculture to transportation and emergency preparedness. Understanding and effectively utilizing weather data can help individuals and organizations make informed decisions, improve safety, and optimize operations.

1. Types of Weather Data:

Weather data encompasses a wide range of information collected from various sources, including meteorological stations, satellites, weather balloons, and weather radars. The key types of weather data include:

a. Temperature: Information about the current and forecasted temperature, which impacts clothing choices, heating and cooling needs, and agricultural practices.

b. Precipitation: Data on rainfall, snowfall, and other forms of precipitation, critical for water resource management, flood forecasting, and agricultural planning.

c. Humidity: Measures the amount of moisture in the air, influencing human comfort, crop health, and weather patterns.

d. Wind Speed and Direction: Wind data is vital for aviation, renewable energy generation, and understanding weather patterns.

e. Atmospheric Pressure: Information about the pressure exerted by the atmosphere, useful for weather predictions and altimeter settings for aviation.

f. Cloud Cover: Indicates the fraction of the sky covered by clouds and helps determine potential rainfall and solar radiation.

g. UV Index: Measures the strength of ultraviolet radiation from the sun, important for skin protection and outdoor activities.

2. Weather Data Sources:

Weather data comes from a variety of sources, including:

a. National Meteorological Agencies: Government agencies responsible for collecting and disseminating weather information for specific regions or countries.

b. Weather Stations: Ground-based installations that monitor local weather conditions, including temperature, humidity, and precipitation.

c. Satellites: Orbiting satellites capture images and data from space, providing a broader perspective on weather patterns and storms.

d. Weather Radars: Used to detect precipitation, measure wind speed, and identify severe weather events such as tornadoes and thunderstorms.

e. Weather Balloons: Instruments attached to weather balloons collect atmospheric data at different altitudes.

f. Weather Apps and Websites: Online platforms that provide real-time weather updates and forecasts based on data from various sources.

3. Applications of Weather Data:

Weather data has numerous applications across various industries and activities, including:

a. Agriculture: Farmers use weather data to schedule irrigation, plan planting and harvesting, and mitigate the impact of extreme weather on crops.

b. Transportation: Airlines, shipping companies, and road networks rely on weather data to optimize routes, avoid hazardous conditions, and ensure passenger safety.

c. Renewable Energy: Wind and solar energy generation depend on weather data to predict energy production and manage power grids efficiently.

d. Disaster Preparedness: Weather data is vital for early warning systems and emergency response planning during hurricanes, floods, and other severe weather events.

e. Tourism: Tour operators and travelers use weather forecasts to plan outdoor activities and make the most of their trips.

4. Challenges in Weather Data Analysis:

While weather data is invaluable, analyzing and interpreting it can be complex due to:

a. Data Volume: Weather data is vast and constantly updating, requiring powerful computing systems for processing and analysis.

b. Data Quality: Ensuring the accuracy and reliability of weather data is crucial, as errors can lead to significant consequences.

c. Forecasting Accuracy: Weather forecasting involves uncertainties, and improving prediction accuracy is an ongoing challenge for meteorologists.

Conclusion:

Weather data is a valuable resource that influences our daily lives and various industries. By understanding the types of weather data, its sources, and its applications, individuals and organizations can harness its power to make informed decisions, enhance safety, and optimize operations in a changing climate.",.csv
Weather in AUS,1,weather-in-aus,weatherAUS.csv,CC0-1.0,Dataset to predict tomorrow's rainfall using dataset available for area : Australia ,.csv
Weather in Szeged 2006-2016,1,szeged-weather,weatherHistory.csv,CC-BY-NC-SA-4.0,"# Context 

This is a dataset for a larger project I have been working on. My idea is to analyze and compare real historical weather with weather folklore.

# Content

The CSV file includes a hourly/daily summary for [Szeged, Hungary][1] area, between 2006 and 2016.

Data available in the hourly response:

- time
- summary
- precipType
- temperature
- apparentTemperature
- humidity
- windSpeed
- windBearing
- visibility
- loudCover
- pressure

# Acknowledgements

Many thanks to [Darksky.net][2] team for their awesome API.

 [1]: https://en.wikipedia.org/wiki/Szeged?oldformat=true
 [2]: http://darksky.net/dev/",.csv
Weather_Data (Nov 2015 - June 2017),1,weather-data-nov-2015,weather_data_filtered.csv,Attribution 4.0 International (CC BY 4.0),"**Notes:**


- This data package contains radiation and temperature data, at hourly resolution, for Europe, aggregated by Renewables.ninja from the NASA MERRA-2 reanalysis. It covers the European countries using a population-weighted mean across all MERRA-2 grid cells within the given country.



**1. This data package:**


- We provide data in different chunks, or [data packages](http://frictionlessdata.io/data-packages/).
- The one you are looking at right now, [Weather Data](http://data.open-power-system-data.org/weather_data/), contains geographically aggregated weather variables relevant for power system modelling. The main focus of this data package is Germany and neighboring European countries.


**2. Data sources:**


- The data source for the pre-computed country-aggregated weather datasets is [Renewables.ninja](https://www.renewables.ninja/), which in turn is based on weather data from the [NASA MERRA-2 reanalysis](https://gmao.gsfc.nasa.gov/reanalysis/MERRA-2/).


**3. License:**


-This notebook as well as all other documents in this repository is published under the [MIT License](https://nbviewer.org/github/Open-Power-System-Data/weather_data/blob/master/LICENSE.md).


**4. More Info:**


- For detailed weather data and to perform custom filtering, please visit [Open Power System Data's Weather Data](https://data.open-power-system-data.org/weather_data/).


**Credit:**


- [Header & Thumbnail Image](https://dribbble.com/heykoshelev)
",.csv
Web Page Phishing Dataset,1,web-page-phishing-dataset,web-page-phishing.csv,Attribution 4.0 International (CC BY 4.0),"#  **Dataset Origin**
This dataset is the result of merging two datasets with identical features. However, not all features from the original datasets have been retained in the merged dataset. This selective feature inclusion was done to focus on the most relevant data and to avoid redundancy. The resulting dataset provides a comprehensive view of the shared characteristics between the two original datasets, while maintaining a streamlined and focused set of features.


Dataset 1 : [Web page phishing detection](https://data.mendeley.com/datasets/c2gw7fy2j4/3)
Hannousse, Abdelhakim; Yahiouche, Salima (2021), “Web page phishing detection”, Mendeley Data, V3, doi: 10.17632/c2gw7fy2j4.3


Dataset 2: [Phishing Websites Dataset](https://data.mendeley.com/datasets/72ptz43s9v/1)
Vrbančič, Grega (2020), “Phishing Websites Dataset”, Mendeley Data, V1, doi: 10.17632/72ptz43s9v.1


# **Data Format**
The data is provided in CSV format, with each row representing a website and each column representing a feature. The last column contains the label for each website.


# **Features**
This dataset contains the following features:
1. url_length: The length of the URL.
2. n_dots: The count of ‘.’ characters in the URL.
3. n_hypens: The count of ‘-’ characters in the URL.
4. n_underline: The count of ‘_’ characters in the URL.
5. n_slash: The count of ‘/’ characters in the URL.
6. n_questionmark: The count of ‘?’ characters in the URL.
7. n_equal: The count of ‘=’ characters in the URL.
8. n_at: The count of ‘@’ characters in the URL.
9. n_and: The count of ‘&’ characters in the URL.
10. n_exclamation: The count of ‘!’ characters in the URL.
11. n_space: The count of ’ ’ characters in the URL.
12. n_tilde: The count of ‘~’ characters in the URL.
13. n_comma: The count of ‘,’ characters in the URL.
14. n_plus: The count of ‘+’ characters in the URL.
15. n_asterisk: The count of ‘*’ characters in the URL.
16. n_hastag: The count of ‘#’ characters in the URL.
17. n_dollar: The count of ‘$’ characters in the URL.
18. n_percent: The count of ‘%’ characters in the URL.
19. n_redirection: The count of redirections in the URL.
20. phishing: The Labels of the URL. 1 is phishing and 0 is legitimate.
",.csv
Web page Phishing Detection Dataset,1,web-page-phishing-detection-dataset,dataset_phishing.csv,Attribution 4.0 International (CC BY 4.0),"### Context

Phishing continues to prove one of the most successful and effective ways for cybercriminals to defraud us and steal our personal and financial information.
Our growing reliance on the internet to conduct much of our day-to-day business has provided fraudsters with the perfect environment to launch targeted phishing attacks. The phishing attacks taking place today are sophisticated and increasingly more difficult to spot. A study conducted by Intel found that 97% of security experts fail at identifying phishing emails from genuine emails.

### Content

The provided dataset includes 11430 URLs with 87 extracted features. The dataset is designed to be used as benchmarks for machine learning-based phishing detection systems. Features are from three different classes: 56 extracted from the structure and syntax of URLs, 24 extracted from the content of their correspondent pages, and 7 are extracted by querying external services. The dataset is balanced, it contains exactly 50% phishing and 50% legitimate URLs. 

### Acknowledgements

Hannousse, Abdelhakim; Yahiouche, Salima (2021), “Web page phishing detection”, Mendeley Data, V3, doi: 10.17632/c2gw7fy2j4.3
* The Source of the dataset is available [here.](https://data.mendeley.com/datasets/c2gw7fy2j4/3)",.csv
Website Classification,1,website-classification,website_classification.csv,CC0-1.0,"### Context

This dataset was created by scraping different websites and then classifying them into different categories based on the extracted text.


### Content

Below are the values each column has. The column names are pretty self-explanatory.
website_url: URL link of the website.
cleaned_website_text: the cleaned text content extracted from the ",.csv
Weekly Top Trending ML Papers,1,weekly-top-trending-ml-papers,ml-potw-10232023.csv,Apache 2.0,"The original address is: https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/research/ml-potw-10232023.csv
Adapted by: Aisuko

Academic Research only.
",.csv
Whatssap Reviews [DAILY UPDATED],1,whatssap-reviews-daily-updated,whatssap_reviews.csv,Apache 2.0,"This dataset predominantly features user-generated reviews and ratings of the Whatssap Android App, with updates made on a daily basis. It also provides details on the relevancy of the reviews and the dates when they were uploaded.",.csv
White Wine Quality,1,white-wine-quality,winequality-white.csv,DbCL-1.0,"### Context
The two datasets are related to red and white variants of the Portuguese ""Vinho Verde"" wine. For more details, refer to [Cortez et al., 2009]. Due to privacy and logistic issues, only physicochemical (inputs) and sensory (the output) variables are available (e.g. there is no data about grape types, wine brand, wine selling price, etc.).

These datasets can be viewed as classification or regression tasks. The classes are ordered and not balanced (e.g. there are many more normal wines than excellent or poor ones). Outlier detection algorithms could be used to detect the few excellent or poor wines. Also, we are not sure if all input variables are relevant. So it could be interesting to test feature selection methods.

### Content

For more information, read [Cortez et al., 2009].
Input variables (based on physicochemical tests):
1 - fixed acidity
2 - volatile acidity
3 - citric acid
4 - residual sugar
5 - chlorides
6 - free sulfur dioxide
7 - total sulfur dioxide
8 - density
9 - pH
10 - sulphates
11 - alcohol
Output variable (based on sensory data):
12 - quality (score between 0 and 10)


### Acknowledgements

This dataset is also available from the UCI machine learning repository, https://archive.ics.uci.edu/ml/datasets/wine+quality, to get both the dataset i.e. red and white vinho verde wine samples, from the north of Portugal, please visit the above link.

**Please include this citation if you plan to use this database:**

P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis.
Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.

### Inspiration

We kagglers can apply several machine-learning algorithms to determine which physiochemical properties make a wine 'good'!

### Relevant papers
P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling wine preferences by data mining from physicochemical properties.
In Decision Support Systems, Elsevier, 47(4):547-553, 2009.",.csv
Who eats the food we grow?,1,world-foodfeed-production,FAO.csv,CC0-1.0,"### Context

Our world population is expected to grow from [7.3 billion today to 9.7 billion in the year 2050][1]. Finding solutions for feeding the growing world population has become a hot topic for [food and agriculture organizations][2], [entrepreneurs][3] and [philanthropists][4]. These solutions range from changing the way we [grow our food][5] to changing the [way we eat][6]. To make things harder, the world's climate is changing and it is both affecting and affected by the way we grow our food – agriculture. 
**This dataset provides an insight on our worldwide food production** - focusing on a comparison between food produced for human consumption and feed produced for animals.



### Content

The Food and Agriculture Organization of the United Nations provides [free access to food and agriculture data][7] for over 245 countries and territories, from the year 1961 to the most recent update (depends on the dataset). One dataset from the FAO's database is the Food Balance Sheets. It presents a comprehensive picture of the pattern of a country's food supply during a specified reference period, the last time an update was loaded to the FAO database was in 2013. The food balance sheet shows for each food item the sources of supply and its utilization. This chunk of the dataset is focused on two utilizations of each food item available:

 - **Food** - refers to the total amount of the food item available as human food during the reference period.
 - **Feed** - refers to the quantity of the food item available for feeding to the livestock and poultry during the reference period.

### Acknowledgements

This dataset was meticulously gathered, organized and published by the Food and Agriculture Organization of the United Nations. 

### Inspiration

Animal agriculture and factory farming is a a growing interest of the public and of world leaders.

 - Can you find interesting outliers in the data?
 - What are the fastest growing countries in terms of food production\consumption?
 - Compare between food and feed consumption.

  [1]: http://www.un.org/en/development/desa/news/population/2015-report.html
  [2]: http://www.fao.org/fileadmin/templates/wsfs/docs/expert_paper/How_to_Feed_the_World_in_2050.pdf
  [3]: https://www.entrepreneur.com/article/251515
  [4]: https://canwefeedtheworld.wordpress.com/tag/bill-gates/
  [5]: https://www.forbes.com/sites/christinatroitino/2017/08/24/memphis-meats-lab-grown-meat-raises-17m-with-help-from-bill-gates-and-richard-branson/#2f8186d43fd0
  [6]: https://www.peta.org/issues/animals-used-for-food/global-warming/
  [7]: http://www.fao.org/faostat/en/#home",.csv
Wholesale Customers Data,1,wholesale-customers-data,Wholesale customers data.csv,Apache 2.0,"**Description:**
Dive into the world of wholesale customer data and uncover insights into purchasing behavior across different channels and regions. This dataset offers a comprehensive view of annual spending on various product categories, providing valuable information for market segmentation and customer classification.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F15666745%2Fb675374e71be1f3bf897276dbe36c4e7%2Fclark-young-ueZXMrZFFKQ-unsplash.jpg?generation=1713949802855577&alt=media)

**Features:**
- **Region:** Categorical feature indicating the region of purchase, with options including Lisbon, Oporto, or Other.
  
- **Fresh:** Continuous feature representing annual spending (in monetary units) on fresh products.
  
- **Milk:** Continuous feature representing annual spending (in monetary units) on milk products.
  
- **Grocery:** Continuous feature representing annual spending (in monetary units) on grocery products.
  
- **Frozen:** Continuous feature representing annual spending (in monetary units) on frozen products.
  
- **Detergents_Paper:** Continuous feature representing annual spending (in monetary units) on detergents and paper products.
  
- **Delicassen:** Continuous feature representing annual spending (in monetary units) on delicatessen products.
  
- **Target Feature:** Channel - Categorical feature indicating the type of channel, either Horeca (Hotel/Restaurant/Cafe) or Retail channel.



**How the data can be used:**
- Market Segmentation: Analyze spending patterns to segment customers based on their purchasing behavior, helping businesses tailor their marketing strategies accordingly.
- Channel Classification: Develop machine learning models to classify customers into Hotel/Restaurant/Cafe (HoReCa) or Retail channels, enabling businesses to optimize their supply chain and distribution strategies.
- Predictive Analytics: Utilize the dataset to build predictive models that forecast future spending trends, aiding businesses in inventory management and demand forecasting.
- Customer Insights: Gain insights into the preferences and buying habits of wholesale customers, allowing businesses to identify growth opportunities and improve customer satisfaction.",.csv
Wild blueberry Yield Prediction Dataset,1,wild-blueberry-yield-prediction-dataset,WildBlueberryPollinationSimulationData.csv,Attribution 4.0 International (CC BY 4.0),"### Context

Blueberries are perennial flowering plants with blue or purple berries. They are classified in the section Cyanococcus within the genus Vaccinium. Vaccinium also includes cranberries, bilberries, huckleberries, and Madeira blueberries. Commercial blueberries—both wild (lowbush) and cultivated (highbush)—are all native to North America. The highbush varieties were introduced into Europe during the 1930s.

Blueberries are usually prostrate shrubs that can vary in size from 10 centimeters (4 inches) to 4 meters (13 feet) in height. In the commercial production of blueberries, the species with small, pea-size berries growing on low-level bushes are known as ""lowbush blueberries"" (synonymous with ""wild""), while the species with larger berries growing on taller, cultivated bushes are known as ""highbush blueberries"". Canada is the leading producer of lowbush blueberries, while the United States produces some 40% of the world s supply of highbush blueberries.

### Content

""The dataset used for predictive modeling was generated by the Wild Blueberry Pollination Simulation Model, which is an open-source, spatially-explicit computer simulation program that enables exploration of how various factors, including plant spatial arrangement, outcrossing and self-pollination, bee species compositions and weather conditions, in isolation and combination, affect pollination efficiency and yield of the wild blueberry agroecosystem. The simulation model has been validated by the field observation and experimental data collected in Maine USA and Canadian Maritimes during the last 30 years and now is a useful tool for hypothesis testing and theory development for wild blueberry pollination researches.""

Features 	Unit	Description
Clonesize	m2	The average blueberry clone size in the field
Honeybee	bees/m2/min	Honeybee density in the field
Bumbles	bees/m2/min	Bumblebee density in the field
Andrena	bees/m2/min	Andrena bee density in the field
Osmia	bees/m2/min	Osmia bee density in the field
MaxOfUpperTRange	℃	The highest record of the upper band daily air temperature during the bloom season
MinOfUpperTRange	℃	The lowest record of the upper band daily air temperature
AverageOfUpperTRange	℃	The average of the upper band daily air temperature
MaxOfLowerTRange	℃	The highest record of the lower band daily air temperature
MinOfLowerTRange	℃	The lowest record of the lower band daily air temperature
AverageOfLowerTRange	℃	The average of the lower band daily air temperature
RainingDays	Day	The total number of days during the bloom season, each of which has precipitation larger than zero
AverageRainingDays	Day	The average of raining days of the entire bloom season

### Acknowledgements

Qu, Hongchun; Obsie, Efrem; Drummond, Frank (2020), “Data for: Wild blueberry yield prediction using a combination of computer simulation and machine learning algorithms”, Mendeley Data, V1, doi: 10.17632/p5hvjzsvn8.1

Dataset is outsourced from [here.](https://data.mendeley.com/datasets/p5hvjzsvn8/1)
",.csv
Wild mammals,1,wild-mammals,children-per-woman-un new.csv,CC0-1.0,"this graph was created in OurDataWorld and Loocker studio:

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fb8e15480978bf8d39cb77a94cb77538c%2Fgraph1.png?generation=1713986693946914&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fd2adf1a0b6f29392ecdcb2ede755ba3b%2Fgraph2.png?generation=1713986699781135&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F6aa30f3a8899e92bbf39e04316c6e145%2Fgraph3.png?generation=1713986705591156&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fcfbc004458e43144fd36422a1f92d2bc%2Fgraph4.jpg?generation=1713986712901373&alt=media)

making a comeback in Europe thanks to conservation efforts

The European bison is the continent’s largest herbivore. It was once abundant across the region. Archaeological evidence suggests that the bison was widespread, stretching from France to Ukraine, down to the tip of the Black Sea.1 The earliest fossils date back to the Early Holocene period – around 9,000 BC.

Bison populations steadily declined over millennia, but experienced the most dramatic decline over the last 500 years. Deforestation and hunting of this iconic mammal nearly drove it to extinction. Look at old cave paintings and we find that hunters had etched bison next to bison in charcoal. They had gone extinct in Hungary by the 16th century; in Ukraine by the 18th century. And by the early 20th century they had gone completely extinct in the wild, with only tens of individuals kept in captivity.

The overhunting of the bison is no outlier. It’s part of a long history. Look at the size of mammals through millions of years of human history and we find that they get smaller and smaller. Humans preferentially hunted the largest mammals, often to extinction.2

This is still the case today. It is the largest mammals that are most threatened by hunting.

But it doesn’t have to be this way, and the bison shows it. The European bison has made an impressive comeback over the last 50 years. Successful conservation efforts have seen their numbers rebound. By the end of 2021, there were almost 10,000 of them.3

It’s not the only one. Across the world, we find examples of successful conservation programs that have restored animal populations.

Here I look at the change in mammal populations across Europe. Many species are making a comeback. Once on the brink, iconic animals such as the European bison, Brown bear, and elk are thriving once again.
",.csv
Windows Store,1,windows-store,msft.csv,CC0-1.0,"### Context

This dataset is inspired by the https://www.kaggle.com/gauthamp10/google-playstore-apps dataset. I thought of creating like it similar to it/


### Content

-  **Name**: Name of the app.
- **Rating**:  Rating for the app.
-  **No of People Rated** : No of people who rated the app.
-    **Category** :   Category of the app.
-    **Date**.        :  Date when it is posted.
-     **Price**.      :   Price of the app.

### Acknowledgements
I would like to thank  @gauthamp10 for giving an awesome dataset . and @ruchi798, @pratik1120 for being mentors and reviewing my work and providing feedbacks constantly.
### Inspiration

 - App with the highest rating. 
-  Which year has the most no of downloads.",.csv
Wind💨 & Solar☀️ Daily Power Production,1,wind-solar-electricity-production,intermittent-renewables-production-france.csv,EU ODP Legal Notice,"⚡️**About The Dataset**⚡️
This dataset consists of wind 💨 and solar ☀️ energy production (in MW)⚡️ records on an hourly basis for the French grid since 2020. Its primary purpose is to enable the Commission de Régulation de l'Énergie (CRE) to calculate the reference price used in the calculation of additional remuneration for the wind and solar sectors.

The additional remuneration is a support mechanism for wind and solar energy producers, as defined in Articles L. 314-18 to L. 314-27 of the Energy Code. This mechanism was introduced by the Law on Energy Transition for Green Growth (LTECV). It allows renewable energy producers who directly market their electricity to receive a premium that compensates for the difference between their income from sales and a reference remuneration level. The reference remuneration is fixed by public authorities through a tariff decree or by the producer through a competition procedure, depending on the type of installation.

This additional compensation is generally classified as a variable bonus, or ex post, as its amount is adjusted to account for the variance between the reference compensation and the actual income derived from the market. The system's main objective is to expose producers to short-term market price signals while ensuring they receive reasonable remuneration for their renewable energy production.

⚡️**Dataset Loading**⚡️

You can simply load the dataset by running the following script :

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('ggplot')

class CONFIG:

    NAMES_DTYPES = {
        ""Source"" : str,
        ""Production"" : np.float32
    }

data = pd.read_csv(
    ""/kaggle/input/intermittent-renewables-production-france/intermittent-renewables-production-france.csv"",
    index_col=""Date and Hour"",
    parse_dates=[""Date and Hour"", ""Date""],
    infer_datetime_format=True,
    dtype=CONFIG.NAMES_DTYPES
    )
```

⚡️**Dataset Usage for Machine Learning**⚡️
The dataset offers valuable opportunities for various machine learning applications in the domain of renewable energy and power market analysis. Here are some potential use cases:

1. **Time Series Forecasting:** Machine learning models can be trained on the hourly production records to forecast future wind and solar energy production levels. These predictions are crucial for grid operators, energy traders, and policymakers to plan and optimize energy distribution and utilization efficiently.

2. **Anomaly Detection:** By employing machine learning algorithms, anomalies in energy production patterns can be detected. Anomalies may indicate equipment malfunctions, weather-related issues, or other irregularities that require attention.

3. **Price Signal Analysis:** Using the reference price data, machine learning models can analyze market price signals and their impact on renewable energy producers. This analysis can assist stakeholders in making informed decisions about energy selling strategies and profit optimization.

4. **Optimization of Renewable Energy Production:** Machine learning models can optimize the operation of renewable energy installations, considering factors such as weather forecasts, market prices, and production costs. This will help determine the most favorable times for energy production.

5. **Performance Comparison of Energy Installations:** Machine learning can be used to compare the performance of different types of renewable energy installations. This analysis can provide insights into the efficiency of various technologies under different conditions and market dynamics.

6. **Policy Impact Assessment:** The dataset's information on the additional remuneration support mechanism can be leveraged to assess the effectiveness of policies promoting renewable energy. Machine learning models can help identify the influence of such policies on energy production, market participation, and financial outcomes for producers.

7. **Energy Market Price Prediction:** By integrating this dataset with other relevant market data, machine learning models can predict energy market prices. Such predictions can assist renewable energy producers in making informed decisions about when and how much energy to sell.

To achieve optimal results for these tasks, data preprocessing, handling of missing values, and potential integration with other datasets or external factors (e.g., weather data, economic indicators) are crucial for enhancing the performance and accuracy of machine learning models.",.csv
Wine Quality Data Set (Red & White Wine),1,wine-quality-data-set-red-white-wine,wine-quality-white-and-red.csv,Attribution 4.0 International (CC BY 4.0),"### Data Set Information

This data set contains records related to red and white variants of the Portuguese *[Vinho Verde](https://www.vinhoverde.pt/en/)* wine. It contains information from 1599 red wine samples and 4898 white wine samples. Input variables in the data set consist of the type of wine (either red or white wine) and metrics from objective tests (e.g. acidity levels, PH values, ABV, etc.), while the target/output variable is a numerical score based on sensory data—median of at least 3 evaluations made by wine experts. Each expert graded the wine quality between 0 (very bad) and 10 (very excellent). Due to privacy and logistic issues, there is no data about grape types, wine brand, and wine selling price.

This data set is a *combined* version of the two separate files (distinct red and white wine data sets) originally shared in the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/wine+quality).

The following are some existing data sets on Kaggle from the same source (with notable differences from this data set):
- [Red Wine Quality](https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009) (contains **red wine data only**)
- [Wine Quality](https://www.kaggle.com/rajyellow46/wine-quality) (combination of red and white wine data but with **some values randomly removed**)
- [Wine Quality](https://www.kaggle.com/danielpanizzo/wine-quality) (red and white wine data **not combined**)
 

### Contents

Input variables:

1 - type of wine: type of wine (categorical: 'red', 'white')

(continuous variables based on physicochemical tests)

2 - fixed acidity: The acids that naturally occur in the grapes used to ferment the wine and carry over into the wine. They mostly consist of tartaric, malic, citric or succinic acid that mostly originate from the grapes used to ferment the wine. They also do not evaporate easily. (g / dm^3)

3 - volatile acidity: Acids that evaporate at low temperatures—mainly acetic acid which can lead to an unpleasant, vinegar-like taste at very high levels. (g / dm^3)

4 - citric acid: Citric acid is used as an acid supplement which boosts the acidity of the wine. It's typically found in small quantities and can add 'freshness' and flavor to wines. (g / dm^3)

5 - residual sugar: The amount of sugar remaining after fermentation stops. It's rare to find wines with less than 1 gram/liter. Wines residual sugar level greater than 45 grams/liter are considered sweet. On the other end of the spectrum, a wine that does not taste sweet is considered as dry. (g / dm^3)

6 - chlorides: The amount of chloride salts (sodium chloride) present in the wine. (g / dm^3)

7 - free sulfur dioxide: The free form of SO2 exists in equilibrium between molecular SO2 (as a dissolved gas) and bisulfite ion; it prevents microbial growth and the oxidation of wine. All else constant, the higher the free sulfur dioxide content, the stronger the preservative effect. (mg / dm^3)

8 - total sulfur dioxide: The amount of free and bound forms of S02; in low concentrations, SO2 is mostly undetectable in wine, but at free SO2 concentrations over 50 ppm, SO2 becomes evident in the nose and taste of wine. (mg / dm^3)

9 - density: The density of wine juice depending on the percent alcohol and sugar content; it's typically similar but higher than that of water (wine is 'thicker'). (g / cm^3)

10 - pH: A measure of the acidity of wine; most wines are between 3-4 on the pH scale. The lower the pH, the more acidic the wine is; the higher the pH, the less acidic the wine. (The pH scale technically is a logarithmic scale that measures the concentration of free hydrogen ions floating around in your wine. Each point of the pH scale is a factor of 10. This means a wine with a pH of 3 is 10 times more acidic than a wine with a pH of 4)

11 - sulphates: Amount of potassium sulphate as a wine additive which can contribute to sulfur dioxide gas (S02) levels; it acts as an antimicrobial and antioxidant agent.(g / dm3)

12 - alcohol: How much alcohol is contained in a given volume of wine (ABV). Wine generally contains between 5–15% of alcohols. (% by volume)

Output variable:

13 - quality: score between 0 (very bad) and 10 (very excellent) by wine experts


### Acknowledgements

Source: P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.

Data credit goes to UCI. Visit their website to access the original data set directly: https://archive.ics.uci.edu/ml/datasets/wine+quality


### Context

So much about wine making remains elusive—taste is very subjective, making it extremely challenging to predict exactly how consumers will react to a certain bottle of wine. There is no doubt that winemakers, connoisseurs, and scientists have greatly contributed their expertise to the process, but there is still more to be discovered about the art and science of winemaking. Use this data to gain a better understanding of what makes a good quality or bad quality wine *according to wine experts' taste-buds and brains*.

The data set can be used to solve classification or regression tasks. Note that the classes are ordered and **not balanced** (e.g. there are many more normal wines than excellent or poor ones). Outlier detection algorithms could be used to detect the few excellent or poor wines. Moreover, some input variables may or may not be relevant—it could be interesting to test feature selection methods.",.csv
Wine Quality Dataset,1,wine-quality-dataset,WineQT.csv,MIT,"Delve into the world of wine quality prediction with this exciting exploration of ordinal regression. Using a comprehensive tabular dataset encompassing various attributes of wine, we embark on a journey to uncover the intricate relationships between these features and the perceived quality ratings.",.csv
Wisconsin Breast Cancer Database,1,breast-cancer-csv,breastCancer.csv,CC0-1.0,"### Context

This breast cancer databases was obtained from the University of Wisconsin
   Hospitals, Madison from Dr. William H. Wolberg.

### Content

Past Usage:

   Attributes 2 through 10 have been used to represent instances.
   Each instance has one of 2 possible classes: benign or malignant.

   1. Wolberg,~W.~H., \& Mangasarian,~O.~L. (1990). Multisurface method of 
      pattern separation for medical diagnosis applied to breast cytology. In
      {\it Proceedings of the National Academy of Sciences}, {\it 87},
      9193--9196.
      -- Size of data set: only 369 instances (at that point in time)
      -- Collected classification results: 1 trial only
      -- Two pairs of parallel hyperplanes were found to be consistent with
         50% of the data
         -- Accuracy on remaining 50% of dataset: 93.5%
      -- Three pairs of parallel hyperplanes were found to be consistent with
         67% of data
         -- Accuracy on remaining 33% of dataset: 95.9%

   2. Zhang,~J. (1992). Selecting typical instances in instance-based
      learning.  In {\it Proceedings of the Ninth International Machine
      Learning Conference} (pp. 470--479).  Aberdeen, Scotland: Morgan
      Kaufmann.
      -- Size of data set: only 369 instances (at that point in time)
      -- Applied 4 instance-based learning algorithms 
      -- Collected classification results averaged over 10 trials
      -- Best accuracy result: 
         -- 1-nearest neighbor: 93.7%
         -- trained on 200 instances, tested on the other 169
      -- Also of interest:
         -- Using only typical instances: 92.2% (storing only 23.1 instances)
         -- trained on 200 instances, tested on the other 169

4. Relevant Information:

   Samples arrive periodically as Dr. Wolberg reports his clinical cases.
   The database therefore reflects this chronological grouping of the data.
   This grouping information appears immediately below, having been removed
   from the data itself:

     Group 1: 367 instances (January 1989)
     Group 2:  70 instances (October 1989)
     Group 3:  31 instances (February 1990)
     Group 4:  17 instances (April 1990)
     Group 5:  48 instances (August 1990)
     Group 6:  49 instances (Updated January 1991)
     Group 7:  31 instances (June 1991)
     Group 8:  86 instances (November 1991)
     -----------------------------------------
     Total:   699 points (as of the donated datbase on 15 July 1992)

   Note that the results summarized above in Past Usage refer to a dataset
   of size 369, while Group 1 has only 367 instances.  This is because it
   originally contained 369 instances; 2 were removed.  The following
   statements summarizes changes to the original Group 1's set of data:

   #####  Group 1 : 367 points: 200B 167M (January 1989)
   #####  Revised Jan 10, 1991: Replaced zero bare nuclei in 1080185 & 1187805
   #####  Revised Nov 22,1991: Removed 765878,4,5,9,7,10,10,10,3,8,1 no record
   #####                  : Removed 484201,2,7,8,8,4,3,10,3,4,1 zero epithelial
   #####                  : Changed 0 to 1 in field 6 of sample 1219406
   #####                  : Changed 0 to 1 in field 8 of following sample:
   #####                  : 1182404,2,3,1,1,1,2,0,1,1,1

5. Number of Instances: 699 (as of 15 July 1992)

6. Number of Attributes: 10 plus the class attribute

7. Attribute Information: (class attribute has been moved to last column)

   #  Attribute                     Domain
   -- -----------------------------------------
   1. Sample code number            id number
   2. Clump Thickness               1 - 10
   3. Uniformity of Cell Size       1 - 10
   4. Uniformity of Cell Shape      1 - 10
   5. Marginal Adhesion             1 - 10
   6. Single Epithelial Cell Size   1 - 10
   7. Bare Nuclei                   1 - 10
   8. Bland Chromatin               1 - 10
   9. Normal Nucleoli               1 - 10
  10. Mitoses                       1 - 10
  11. Class:                        (2 for benign, 4 for malignant)

8. Missing attribute values: 16

   There are 16 instances in Groups 1 to 6 that contain a single missing 
   (i.e., unavailable) attribute value, now denoted by ""?"".  

9. Class distribution:
 
   Benign: 458 (65.5%)
   Malignant: 241 (34.5%)


### Acknowledgements

 1. O. L. Mangasarian and W. H. Wolberg: ""Cancer diagnosis via linear 
      programming"", SIAM News, Volume 23, Number 5, September 1990, pp 1 & 18.

   2. William H. Wolberg and O.L. Mangasarian: ""Multisurface method of 
      pattern separation for medical diagnosis applied to breast cytology"", 
      Proceedings of the National Academy of Sciences, U.S.A., Volume 87, 
      December 1990, pp 9193-9196.

   3. O. L. Mangasarian, R. Setiono, and W.H. Wolberg: ""Pattern recognition 
      via linear programming: Theory and application to medical diagnosis"", 
      in: ""Large-scale numerical optimization"", Thomas F. Coleman and Yuying
      Li, editors, SIAM Publications, Philadelphia 1990, pp 22-30.

   4. K. P. Bennett & O. L. Mangasarian: ""Robust linear programming 
      discrimination of two linearly inseparable sets"", Optimization Methods
      and Software 1, 1992, 23-34 (Gordon & Breach Science Publishers).

### Inspiration

Rouse Tek Bio informatics Cytogenomics Project is an attempt to bring the human genome to the understanding of how cancers develop.
All of our bodies are composed of cells. The human body has about 100 trillion cells within it. And usually those cells behave in a certain fashion. They observe certain rules, they divide when they’re told to divide, they’re quiescent when they’re told to remain dormant, they stay within a particular position within their tissue and they don’t move out of that. 

Occassionally however, a single cell, of those 100 trillion cells, behave in a different way. That cell keeps dividing when all its signals around it tell it to stop dividing. That cell ignores its counterparts around it and pushes them out of the way. That cell stops observing the rules of the tissue within which it is located and begins to move out of its normal position, invading into the tissues around it and sometimes entering the bloodstream and becoming a metastasis, depositing in another tissue of the body..

The reason the cell has gone rogue is because it has acquired within its genome, within its DNA, a number of abnormalities that cause it to behave as a cancer cell.

All 100 trillion cells in the human body have got a copy of the human genome, they have 2 copies, 1 maternal, 1 paternal. Throughout Life all those copies of the genome in those 100 trillion cells, are acquiring abnormal changes or somatic mutations. These mutations are present in the cell and are not transmitted from parents to offspring. They are constrained to that individual cell. Those mutations occur in every cell of the body, normal and abnormal, for a number of different reasons. They occur because every time a cell divides possibly one letter of code out of 3 billion is replicated incorrectly. And that’s 1 source of somatic mutations.

Another source is that our 100 trillion cells are being exposed to a number of different onslaughts like radiation, self generated chemicals from inhalation of things like tobacco smoke or even an unhealthy diet over time. Occasionally mechanisms in a particular cell make breakdown and the DNA of that cell begins to acquire somatic mutations rather more commonly than other cells.

So in summary, every cell in the body acquires mutations throughout a lifetime, and as we get older we acquire more and more somatic mutations in which occasionally  a particular type of gene is mutated where the protein that it makes is abnormal and drives the cell to behave in a rogue fashion that we call cancer.
",.csv
Wisconsin breast cancer cytology features,1,wisconsin-breast-cancer-cytology-features,wisconsin_breast_cancer.csv,CC0-1.0,"### Context
Cytology features of breast cancer biopsy. It can be used to predict breast cancer from cytology features.

The data was obtained from https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Original) 

Data description can be found at https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.names


### Content

Data contains cytology features of breast cancer biopsies - clump thickness, uniformity of cell size, uniformity of cell shape, marginal adhesion, single epithelial cell size, bare nuclei, bland chromatin, normal nuceloli, mitosis. The class variable denotes whether it was cancer or not. Cancer = 1 and not cancer = 0

Attribute Information:

1. Sample code number: id number 
2. Clump Thickness: 1 - 10 
3. Uniformity of Cell Size: 1 - 10 
4. Uniformity of Cell Shape: 1 - 10 
5. Marginal Adhesion: 1 - 10 
6. Single Epithelial Cell Size: 1 - 10 
7. Bare Nuclei: 1 - 10 
8. Bland Chromatin: 1 - 10 
9. Normal Nucleoli: 1 - 10 
10. Mitoses: 1 - 10 
11. Class: (0 for benign, 1 for malignant)

### Acknowledgements
Data obtained from : UCI machine learning repository 
Dua, D. and Karra Taniskidou, E. (2017). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.

Picture courtesy: Photo by Pablo Heimplatz on Unsplash",.csv
Women Entrepreneurship and Labor Force,1,women-entrepreneurship-and-labor-force,Dataset3.csv,other,"### Context

The data were obtained from the Women Entrepreneurship Index and Global Entrepreneurship Index report published in 2015.
The research is limited to OECD countries where all data for 2015 are available at the same time in the database.

You can check dataset below for a similar type data
https://www.kaggle.com/babyoda/healthcare-investments-and-length-of-hospital-stay",.csv
Women major,1,women-major,countries-tovotelexical new.csv,CC0-1.0,"this graph was created in PowerBi,Loocker and OurDataWorld :

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fa566d4a0851fd779be5961ace06c4c66%2Fgraph2.jpg?generation=1713294719870575&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F50f08b7b1c8c7a899f3490503502b10d%2Fgraph1.png?generation=1713294726052169&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F2950f14593209f5d2852cfce074636be%2Fgraph3.jpg?generation=1713294733002883&alt=media)

Women have gained the right to vote and sit in parliament almost everywhere.

How much progress has been made toward women’s political equality? How far do we still have to go?

In this article, I show global data on women’s political rights and representation.

In the 18th and 19th centuries, women did not have the right to vote or sit in parliaments, and only very few — of royal descent — led their countries.

Women became much better represented in the later 20th century, gaining the right to vote and seats in parliaments in almost all countries, and making it to their country’s highest political office more frequently.

However, the data also shows that this progress has been uneven and limited: women still do not have the right to vote in a handful of countries; women parliamentarians continue to be a small minority in most countries; and women political leaders remain rare.

Let’s look at how far we have come and what remains to be done.

Women have gained the right to vote in almost all countries
A fundamental political right is choosing one’s political representatives in elections. Until recently, women did not have this right to vote in countries’ elections.

Using data from political scientist Svend-Erik Skaaning and colleagues, the chart shows that neither women nor men had the universal right to vote almost anywhere until the middle of the 19th century.

Then a gap in political participation opened: men gained voting rights in some countries, while women remained mostly excluded. New Zealand became the first exception to this, where women gained the universal right to vote in 1893.

The gap between women and men further opened in the early 20th century, as women gained the right to vote in more countries, but men’s voting rights spread even farther. By the beginning of World War II, men had the right to vote in 1 out of 3 countries, while women only had the right to vote in 1 out of 6 countries.

The gap rapidly closed in the decades after World War II, when the voting-rights discrimination against women ended in many countries, and both women and men gained the right to vote in many others.

Today there are no countries that formally discriminate between men and women regarding the right to vote. In 2006, Kuwait was the last country that extended the right to vote to women. The corresponding area in the chart therefore disappears in recent years.

However, six countries and territories still have no right to vote for women or men: Brunei, Gaza, Qatar, Saudi Arabia, Somalia, and the United Arab Emirates.

When it comes to voting rights, what is needed is more of a general expansion of rights rather than ending discrimination against women.

On this map, you can see the voting rights in each country. You can explore how each country changed over time by moving the time slider.",.csv
Word Happines Report,1,word-happines-report,World-Happiness-Report-Dataset.csv,MIT,"**World Happiness Report Dataset**

**Description:**
The World Happiness Report Dataset contains data related to the happiness levels of countries worldwide. It includes various factors such as social support, healthy life expectancy at birth, freedom to make life choices, generosity, and perceptions of corruption, which are used to assess the overall happiness index of each country.
**
Content:**
The dataset consists of six columns:

Country Name: Name of the country.
Social Support: Measure of social support available to citizens.
Healthy Life Expectancy At Birth: Average number of healthy years expected to live at birth.
Freedom To Make Life Choices: Degree of freedom individuals have in making life choices.
Generosity: Measure of generosity within the population.
Perceptions Of Corruption: Perception of corruption within the country.",.csv
World Air Quality Data 2024 (Updated),1,world-air-quality-data-2024-updated,world_air_quality.csv,Attribution 4.0 International (CC BY 4.0),"The ""World Air Quality Data 2024 (Updated)"" dataset provides a comprehensive overview of air quality measurements from various locations around the globe. It encompasses over 50,000 records, each detailing critical air quality parameters that are pivotal for environmental analysis, health studies, and policy-making.

### Dataset Overview:
This extensive dataset captures a wide array of pollutants, including but not limited to PM2.5, NO2, SO2, CO, and O3, offering insights into the atmospheric conditions of cities worldwide. With data points dating up to March 2024, it serves as a crucial resource for understanding the current state and trends in global air quality.


### Data Science Applications:
- **Predictive Modeling**: Utilizing historical air quality data to forecast future pollution levels under varying environmental and anthropogenic conditions.
- **Trend Analysis**: Identifying patterns and trends in air quality over time and across different geographic locations to understand the impact of seasonal changes, policy implementations, and other factors.
- **Environmental Risk Assessment**: Evaluating areas at high risk of pollution and its potential impacts on health, ecosystems, and climate, aiding in targeted intervention strategies.
- **Air Quality Improvement Strategies**: Informing the development of effective air quality management and improvement strategies by analyzing the correlation between pollutants and various contributing factors.
- **Machine Learning Projects**: Enhancing projects aimed at understanding the complex relationships between air quality indicators and external variables, such as traffic density, industrial activities, and meteorological conditions.

### Column Descriptors:
Each record in the dataset includes detailed information structured across several columns: Country Code, City, Location, Coordinates, Pollutant, Source Name, Unit, Value, Last Updated, and Country Label. These descriptors provide a clear understanding of the measurement context, allowing for nuanced analysis and interpretation.

### Ethically Obtained Data:
The data has been ethically sourced from OpenDataSoft, a platform dedicated to making publicly available data accessible and usable. You can explore the dataset further at [OpenDataSoft's Air Quality Dataset](https://public.opendatasoft.com/explore/dataset/openaq/export/?disjunctive.city&disjunctive.location&disjunctive.measurements_parameter&sort=measurements_lastupdated&dataChart=eyJxdWVyaWVzIjpbeyJjaGFydHMiOlt7InR5cGUiOiJsaW5lIiwiZnVuYyI6IkFWRyIsInlBeGlzIjoibWVhc3VyZW1lbnRzX3ZhbHVlIiwic2NpZW50aWZpY0Rpc3BsYXkiOnRydWUsImNvbG9yIjoicmFuZ2UtY3VzdG9tIn1dLCJ4QXhpcyI6Im1lYXN1cmVtZW50c19sYXN0dXBkYXRlZCIsIm1heHBvaW50cyI6IiIsInRpbWVzY2FsZSI6ImRheSIsInNvcnQiOiIiLCJzZXJpZXNCcmVha2Rvd24iOiJtZWFzdXJlbWVudHNfcGFyYW1ldGVyIiwiY29uZmlnIjp7ImRhdGFzZXQiOiJvcGVuYXEiLCJvcHRpb25zIjp7ImRpc2p1bmN0aXZlLmNpdHkiOnRydWUsImRpc2p1bmN0aXZlLmxvY2F0aW9uIjp0cnVlLCJkaXNqdW5jdGl2ZS5tZWFzdXJlbWVudHNfcGFyYW1ldGVyIjp0cnVlLCJzb3J0IjoibWVhc3VyZW1lbnRzX2xhc3R1cGRhdGVkIn19fV0sImRpc3BsYXlMZWdlbmQiOnRydWUsImFsaWduTW9udGgiOnRydWV9).

### Acknowledgements:
We extend our deepest gratitude to OpenDataSoft for facilitating access to this dataset, enabling a broader understanding of air quality issues. Their platform plays a pivotal role in democratizing data access, thereby empowering researchers, policymakers, and the public to make informed decisions towards a healthier planet.",.csv
World Air Quality Index by City and Coordinates,1,world-air-quality-index-by-city-and-coordinates,AQI and Lat Long of Countries.csv,CC-BY-NC-SA-4.0,"The goal of this dataset is to provide valuable insights into the air quality of different regions, allowing researchers and policymakers to make informed decisions on how to address the issue of air pollution.
This dataset is a merger of two separate datasets, one containing information about cities and their corresponding latitude and longitude coordinates, and the other containing data on air pollution levels in countries across the world. By combining these two datasets, we can now analyze and compare air quality indices across different cities in various countries.
The inspiration for creating this dataset came from the growing concern over the impact of air pollution on our health and the environment. By making this data easily accessible and understandable, I hope to contribute to the ongoing efforts to improve air quality and create a cleaner, healthier world for future generations.

### Explanation of common AQI terms
- PM2.5: PM2.5 refers to tiny particles or droplets in the air that are 2.5 micrometers or less in width. They can be harmful to human health when inhaled, especially in high concentrations.
- Ozone: Ozone is a gas that can form in the atmosphere through a chemical reaction between sunlight and other pollutants. High levels of ozone can be harmful to human health, particularly for those with respiratory issues.
- Carbon Monoxide (CO): CO is a colorless, odorless gas that is produced by the incomplete burning of fossil fuels. High levels of CO can be toxic to humans and can cause headaches, dizziness, and nausea",.csv
World Bank World Development Indicators,1,world-bank-world-development-indicators,world_bank_development_indicators.csv,world-bank,"Data about World Development Indicators measured from 1960 to 2022, extracted from the World Bank database. It includes macro-economical, social, political and environmental data from all the countries and regions the world bank has data about.

It contains information about 268 countries and regions, including 48 features, all numerical. Several entries are missing for different reasons, so you may want to extract only the columns you are interested in.

The columns included in this dataset are:

- **country**: The country or geographic region.
- **date**: Date of the measurement. This column along with country can be used as index.
- **agricultural_land%**: Agricultural land as a % of land area of the country/region.
- **forest_land%**: Forest area as the % of land area of the country/region.
- **land_area**: Land area, measured in km^2.
- **avg_precipitation**: Average precipitation in depth, measured in mm per year.
- **trade_in_services%**: Trade in services as a % of GDP.
- **control_of_corruption_estimate**: Index that makes an estimate of the control of corruption.
- **control_of_corruption_std**: Standard error of the estimate of control of corruption.
- **access_to_electricity%**: Percentage of the population that has access to electricity.
- **renewvable_energy_consumption%**: Renewable energy consumption as a % of total final energy consumption.
- **electric_power_consumption**: Electric power consumption, measured in kWh per capita.
- **CO2_emisions**: CO2 emisions measured in kt.
- **other_greenhouse_emisions**: Total greenhouse gas emissions, measured in kt of CO2 equivalent.
- **population_density**: Population density, measured in people per km^2 of land area.
- **inflation_annual%**: Inflation, consumer prices, as annual %.
- **real_interest_rate**: Real interest rate (%).
- **risk_premium_on_lending**: Risk premium on lending (lending rate minus treasury bill rate, %).
- **research_and_development_expenditure%**: Research and development expenditure, as a percentage of GDP.
- **central_goverment_debt%**: Central government debt, total , as a % of GDP.
- **tax_revenue%**: Tax revenue as a % of GDP.
- **expense%**: Expense as a % of GDP.
- **goverment_effectiveness_estimate**: Index that makes an estimate of the Government Effectiveness.
- **goverment_effectiveness_std**: Standard error of the estimate of Government Effectiveness.
- **human_capital_index**: Human Capital Index (HCI) (scale 0-1).
- **doing_business**: Ease of doing business score (0 = lowest performance to 100 = best performance).
- **time_to_get_operation_license**: Days required to obtain an operating license.
- **statistical_performance_indicators**: Statistical performance indicators (SPI): Overall score (scale 0-100).
- **individuals_using_internet%**: Percentage of population using the internet.
- **logistic_performance_index**: Logistics performance index: Overall (1=low to 5=high).
- **military_expenditure%**: Military expenditure as a % of GDP.
- **GDP_current_US**: GDP (current US$).
- **political_stability_estimate**: Index that makes an estimate of the Political Stability and Absence of Violence/Terrorism.
- **political_stability_std**: Standard error of the estimate of Political Stability and Absence of Violence/Terrorism.
- **rule_of_law_estimate**: Index that makes an estimate of the Rule of Law.
- **rule_of_law_std**: Standard error of the estimate of Rule of Law.
- **regulatory_quality_estimate**: Index that makes an estimate of Regulatory Quality.
- **regulatory_quality_std**: Standard error of the estimate of Regulatory Quality.
- **government_expenditure_on_education%**: Government expenditure on education, total, as a % of GDP.
- **government_health_expenditure%**: Domestic general government health expenditure as a % of GDP.
- **multidimensional_poverty_headcount_ratio%**: Multidimensional poverty headcount ratio (% of total population).
- **gini_index**: Gini index.
- **birth_rate**: Birth rate, crude (per 1,000 people).
- **death_rate**: Death rate, crude (per 1,000 people).
- **life_expectancy_at_birth**: Life expectancy at birth, total (years).
- **population**: Total population.
- **rural_population**: Rural population.
- **voice_and_accountability_estimate**: Index that makes an estimate of Voice and Accountability.
- **voice_and_accountability_std**: Standard error of the estimate of Voice and Accountability.
- **intentional_homicides**: Intentional homicides (per 100,000 people).",.csv
World Bank Youth Unemployment Rates,1,world-bank-youth-unemployment,API_ILO_country_YU.csv,other,"**Context** 
A data driven look into answering the common question while travelling overseas: 
*""how easy is it to get a job in your country?""*

**Content**
This dataset contains youth unemployment rates (% of total labor force ages 15-24) (modeled ILO estimate)
Latest data available from 2010 to 2014.

**Acknowledgements**
International Labour Organization.

http://data.worldbank.org/indicator/SL.UEM.TOTL.ZS

Released under Open license.",.csv
World Cities Datasets,1,world-cities-datasets,worldcities.csv,Attribution 4.0 International (CC BY 4.0),"### Context

This Dataset contains demographic details of about 15,000 cities around the world. The location of the cities, the countries to which the City belongs to, its populations etc.,


### Content
city                -     The name of the city/town as a Unicode string (e.g. Goiânia).
city_ascii       -     city as an ASCII string (e.g. Goiania). Left blank if ASCII representation is not possible.
lat                  -     The latitude of the city/town.
lng                 -     The longitude of the city/town.
country         -     The name of the city/town's country.
iso2               -     The alpha-2 iso code of the country. (Two letter Country Code as per ISO 3166-1).
iso3               -     The alpha-3 iso code of the country. (Three letter Country Code as per ISO 3166-1).
admin_name -    The name of the highest level administration region of the city town (e.g. a US state or Canadian province). 
population    -     An estimate of the city's urban population. Only available for some (prominent) cities.
capital           -    Blank string if not a capital, otherwise:
                                  primary - country's capital (e.g. Washington D.C.)
                                  admin - first-level admin capital (e.g. Little Rock, AR)
                                  minor - lower-level admin capital (e.g. Fayetteville, AR)
id                   -     A 10-digit unique id generated by SimpleMaps. 





### Acknowledgements

simplemaps.com has a good sets of maps and associated products.  I would like to acknowledge them for the data. It was last updated on December 2019 and is available under CC Attribution 4.0
source - https://simplemaps.com/data/world-cities


### Inspiration

You can use this data to 
* locate the cities in your map
* Find distance between two cities
* Map cities to their Countries
* Do Demographic and Spatial analysis
*Population of a city can be included for analysis involving cities",.csv
World Coordinates,1,world-coordinates,world_coordinates.csv,CC0-1.0,"### Context

The dataset consists of the Latitudes and Longitudes of all the countries of the world. This might come handy for visualizing geographical data.

",.csv
World Countries Rankings by Suicide Rate 2023,1,world-countries-rankings-by-suicide-rate-2023,world_suicide_rate_2023.csv,CC0-1.0,"**Suicide rates by gender and country (age-standardized, per 100,000 population, World Health Organization, 2023)**

**Columns:**

* **Country** - Region;
* **All** - Male + Female;
* **Male** - Only Male;
* **Female** - Only Female;
* **M/F** - Female to Male ratio;
* **2000** - All in 2000;
* **Change%** - Percent change from 2000 to 2023.",.csv
World Deaths and Causes (1990 - 2019),1,world-deaths-and-causes-1990-2019,annual_deaths_by_causes.csv,CC0-1.0,"Around 56 million people die each year.

This Dataset contains the causes of death and how the causes of death changed over time between different countries and world regions.",.csv
World Demographic Indicators Extract,1,world-demographic-indicators-extract,wdi_wide.csv,Attribution 4.0 International (CC BY 4.0),"This dataset is an extract of 11 development indicators across 217 countries from [World Bank](https://data.worldbank.org/). The most recently available data point for each indicator for each country has been taken, to make as much data available as possible. This does mean that not all the data within a row or column is always from the same year.

We have added geographical information to help group countries by region, subregion and intermediate region ([thanks to this repo](https://github.com/lukes/ISO-3166-Countries-with-Regional-Codes)). Region is the largest division and intermediate region the most local. For example, Antigua and Barbuda is in the region 'Americas', the subregion 'Latin America and the Caribbean', and intermediate region 'Caribbean'.

We have also added a binary feature 'High income economy' which uses the [World Bank definition](https://en.wikipedia.org/wiki/World_Bank_high-income_economy) of GNI per capita greater than US$12,696.

## Research questions

What features are associated with greater carbon emissions?

What features could be used to predict high income economies?

Where do women have the most access to education or participation in government?",.csv
World Economic Classifications,1,world-economic-classifications,World Economic Classifications v2.csv,Apache 2.0,"This UN and IMF-sourced dataset was created as an easy-to-use and versatile source for many types of projects - social justice, economics, public policy, education, and more. When I posted my notebook about class inequality and university choice, I looked high and low for an economic classification dataset that I could merge with my base data, but couldn't find one - not even in the U.N. dataset collection. I made this to fill that need, and I hope it helps you out.

All data is sourced from the most recent info and numbers I could find from highly reputable sources. I'll definitely update it when new info comes available, so bookmark this and watch for updates.

`<h1>Dictionary</h1>

The World Economic Classifications dataset is organized into nine columns:

| Column | Description |
| :-- | :-- | 
| **country_name** | Country name as commonly known. When applicable, any variations appear in parentheses after the most common name.
| **un_class_2014** | Classifications from the Development Policy and Analysis Division (DPAD) of the Department of Economic and Social Affairs of the United Nations Secretariat (UN/DESA), 2014. It describes basic economic conditions and is based on World Economic Situation and Prospects (WESP) data.
| **imf_class_2023** | Classifications from the International Monetary Fund (IMF)'s April 2023 report, ""World Economic Outlook Database: Groups and Aggregates Information."" 
| **g7** | Denotes countries that are part of the United Nations Gang of 7, or G7, and are ranked as Major World Economies by the IMF.  
| **eu_member** | Member states of the European Union, both established and new.
| **fuel_exp_country** | Fuel exporter country. According to DPAD, ""An economy is classified as a fuel exporter if the share of fuel exports in its total merchandise exports is greater than 20 per cent and the level of fuel exports is at least 20 per cent higher than that of the country’s fuel imports. This criterion is drawn from the share of fuel exports in the total value of world merchandise trade.""
| **wealth_rank** | Wealth ranking according to gross domestic product (GDP) at Purchasing Power Parity, or PPP. Worldometer states, ""PPP takes into account the relative cost of living, rather than using only exchange rates, therefore providing a more accurate picture of the real differences in income.""
| **gdp_ppp_2022** | Per capita GDP at PPP as of 2022.
| **gdp_pc_2022** | Per capita GDP as of 2022.`

This set contains no null values and uses N/A as a filler for any missing information. There are several of these countries at the bottom of the ranking list because I wanted to list every country I could with at least some useful info. Feel free to chop these if you'd like.

`<h1>Sources</h1>

Development Policy and Analysis Division (DPAD) of the Department of Economic and Social Affairs of the United Nations Secretariat (UN/DESA), ""[Country Classification](https://www.un.org/en/development/desa/policy/wesp/wesp_current/2014wesp_country_classification.pdf),"" 2014.

International Monetary Fund, ""[World Economic Outlook Database: Groups and Aggregates Information](https://www.imf.org/en/Publications/WEO/weo-database/2023/April/groups-and-aggregates#mae),"" April 2023.

Worldometer, ""[GDP per Capita](https://www.worldometers.info/gdp/gdp-per-capita/)."" 

Photo by <a href=""https://unsplash.com/@ibrahimboran?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Ibrahim Boran</a> on <a href=""https://unsplash.com/photos/100-us-dollar-bill-YVnvtMA2mok?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
    
`
",.csv
World Educational Data,1,world-educational-data,Global_Education.csv,other,"# Description

&gt; This meticulously curated dataset offers a **panoramic view of education on a global scale** , delivering profound insights into the dynamic landscape of education across diverse countries and regions. Spanning a rich tapestry of educational aspects, it encapsulates crucial metrics including out-of-school rates, completion rates, proficiency levels, literacy rates, birth rates, and primary and tertiary education enrollment statistics. A treasure trove of knowledge, this dataset is an indispensable asset for discerning researchers, dedicated educators, and forward-thinking policymakers, enabling them to embark on a transformative journey of assessing, enhancing, and reshaping education systems worldwide.



<div>
    
</div>



# Key Features

The dataset includes the following key features:

&gt;1. **Countries and Areas**: Name of the countries and areas.
2. **Latitude**: Latitude coordinates of the geographical location.
3. **Longitude**: Longitude coordinates of the geographical location.
4. **OOSR_Pre0Primary_Age_Male**: Out-of-school rate for pre-primary age males.
5. **OOSR_Pre0Primary_Age_Female**: Out-of-school rate for pre-primary age females.
6. **OOSR_Primary_Age_Male**: Out-of-school rate for primary age males.
7. **OOSR_Primary_Age_Female**: Out-of-school rate for primary age females.
8. **OOSR_Lower_Secondary_Age_Male**: Out-of-school rate for lower secondary age males.
9. **OOSR_Lower_Secondary_Age_Female**: Out-of-school rate for lower secondary age females.
10. **OOSR_Upper_Secondary_Age_Male**: Out-of-school rate for upper secondary age males.
11. **OOSR_Upper_Secondary_Age_Female**: Out-of-school rate for upper secondary age females.
12. **Completion_Rate_Primary_Male**: Completion rate for primary education among males.
13. **Completion_Rate_Primary_Female**: Completion rate for primary education among females.
14. **Completion_Rate_Lower_Secondary_Male**: Completion rate for lower secondary education among males.
15. **Completion_Rate_Lower_Secondary_Female**: Completion rate for lower secondary education among females.
16. **Completion_Rate_Upper_Secondary_Male**: Completion rate for upper secondary education among males.
17. **Completion_Rate_Upper_Secondary_Female**: Completion rate for upper secondary education among females.
18. **Grade_2_3_Proficiency_Reading**: Proficiency in reading for grade 2-3 students.
19. **Grade_2_3_Proficiency_Math**: Proficiency in math for grade 2-3 students.
20. **Primary_End_Proficiency_Reading**: Proficiency in reading at the end of primary education.
21. **Primary_End_Proficiency_Math**: Proficiency in math at the end of primary education.
22. **Lower_Secondary_End_Proficiency_Reading**: Proficiency in reading at the end of lower secondary education.
23. **Lower_Secondary_End_Proficiency_Math**: Proficiency in math at the end of lower secondary education.
24. **Youth_15_24_Literacy_Rate_Male**: Literacy rate among male youths aged 15-24.
25. **Youth_15_24_Literacy_Rate_Female**: Literacy rate among female youths aged 15-24.
26. **Birth_Rate**: Birth rate in the respective countries/areas.
27. **Gross_Primary_Education_Enrollment**: Gross enrollment in primary education.
28. **Gross_Tertiary_Education_Enrollment**: Gross enrollment in tertiary education.
29. **Unemployment_Rate**: Unemployment rate in the respective countries/areas.

# Potential Use Cases

&gt;- **Global Education Analysis:** Evaluate the status of education in different countries and regions, identifying disparities and trends.
- **Gender Disparities:** Analyze gender-based differences in education, including out-of-school rates and literacy.
- **Education Policy Evaluation:** Use completion rates to assess the effectiveness of education policies.
- **Proficiency Analysis:** Investigate students' proficiency in reading and math at different education levels.
- **Socioeconomic Impact:** Study the relationship between education and unemployment rates.
- **Geospatial Analysis:** Explore geographical patterns of education indicators.

If you find this dataset useful, your support through an upvote would be greatly appreciated ❤️🙂 <br>
Thank you
",.csv
World Energy Consumption,1,world-energy-consumption,World Energy Consumption.csv,Attribution 4.0 International (CC BY 4.0),"# Data on Energy by *Our World in Data*

Our complete Energy dataset is a collection of key metrics maintained by [*Our World in Data*](https://ourworldindata.org/energy). It is updated regularly and includes data on energy consumption (primary energy, per capita, and growth rates), energy mix, electricity mix and other relevant metrics.

## The complete *Our World in Data* Energy dataset

### 🗂️ Download our complete Energy dataset : [CSV](https://nyc3.digitaloceanspaces.com/owid-public/data/energy/owid-energy-data.csv) | [XLSX](https://nyc3.digitaloceanspaces.com/owid-public/data/energy/owid-energy-data.xlsx) | [JSON](https://nyc3.digitaloceanspaces.com/owid-public/data/energy/owid-energy-data.json)

The CSV and XLSX files follow a format of 1 row per location and year. The JSON version is split by country, with an array of yearly records.

The variables represent all of our main data related to energy consumption, energy mix, electricity mix as well as other variables of potential interest.

We will continue to publish updated data on energy as it becomes available. Most metrics are published on an annual basis.

A [full codebook](https://github.com/owid/energy-data/blob/master/owid-energy-codebook.csv) is made available, with a description and source for each variable in the dataset.

## Our source data and code

The dataset is built upon a number of datasets and processing steps:
- Statistical review of world energy (Energy Institute, EI):
  - [Source data](https://www.energyinst.org/statistical-review)
  - [Ingestion code](https://github.com/owid/etl/blob/master/snapshots/energy_institute/2023-06-26/statistical_review_of_world_energy.py)
  - [Basic processing code](https://github.com/owid/etl/blob/master/etl/steps/data/meadow/energy_institute/2023-06-26/statistical_review_of_world_energy.py)
  - [Further processing code](https://github.com/owid/etl/blob/master/etl/steps/data/garden/energy_institute/2023-06-26/statistical_review_of_world_energy.py)
- International energy data (U.S. Energy Information Administration, EIA):
  - [Source data](https://www.eia.gov/opendata/bulkfiles.php)
  - [Ingestion code](https://github.com/owid/etl/blob/master/snapshots/eia/2023-07-10/international_energy_data.py)
  - [Basic processing code](https://github.com/owid/etl/blob/master/etl/steps/data/meadow/eia/2023-07-10/energy_consumption.py)
  - [Further processing code](https://github.com/owid/etl/blob/master/etl/steps/data/garden/eia/2023-07-10/energy_consumption.py)
- Energy from fossil fuels (The Shift Dataportal):
  - [Source data](https://www.theshiftdataportal.org/energy)
  - [Ingestion code](https://github.com/owid/etl/blob/master/snapshots/shift/2023-07-10/energy_production_from_fossil_fuels.py)
  - [Basic processing code](https://github.com/owid/etl/blob/master/etl/steps/data/meadow/shift/2023-07-10/energy_production_from_fossil_fuels.py)
  - [Further processing code](https://github.com/owid/etl/blob/master/etl/steps/data/garden/shift/2023-07-10/energy_production_from_fossil_fuels.py)
- Yearly Electricity Data (Ember):
  - [Source data](https://ember-climate.org/data-catalogue/yearly-electricity-data/)
  - [Ingestion code](https://github.com/owid/etl/blob/master/snapshots/ember/2023-07-10/yearly_electricity.py)
  - [Basic processing code](https://github.com/owid/etl/blob/master/etl/steps/data/meadow/ember/2023-07-10/yearly_electricity.py)
  - [Further processing code](https://github.com/owid/etl/blob/master/etl/steps/data/garden/ember/2023-07-10/yearly_electricity.py)
- European Electricity Review (Ember):
  - [Source data](https://ember-climate.org/insights/research/european-electricity-review-2022/)
  - [Ingestion code](https://github.com/owid/walden/blob/master/owid/walden/index/ember/2022-02-01/european_electricity_review.json)
  - [Basic processing code](https://github.com/owid/etl/blob/master/etl/steps/data/meadow/ember/2022-08-01/european_electricity_review.py)
  - [Further processing code](https://github.com/owid/etl/blob/master/etl/steps/data/garden/ember/2022-08-01/european_electricity_review.py)
- Combined Electricity (Our World in Data based on Ember's Yearly Electricity Data and European Electricity Review):
  - [Processing code](https://github.com/owid/etl/blob/master/etl/steps/data/garden/ember/2023-07-10/combined_electricity.py)
- Energy mix (Our World in Data based on EI's Statistical review of world energy):
  - [Processing code](https://github.com/owid/etl/blob/master/etl/steps/data/garden/energy/2023-07-10/energy_mix.py)
- Fossil fuel production (Our World in Data based on EI's Statistical review of world energy & The Shift Dataportal's Energy from fossil fuels):
  - [Processing code](https://github.com/owid/etl/blob/master/etl/steps/data/garden/energy/2023-07-10/fossil_fuel_production.py)
- Primary energy consumption (Our World in Data based on EI's Statistical review of world energy & EIA's International energy data):
  - [Processing code](https://github.com/owid/etl/blob/master/etl/steps/data/garden/energy/2023-07-10/primary_energy_consumption.py)
- Electricity mix (Our World in Data based on EI's Statistical Review & Ember's Combined Electricity):
  - [Processing code](https://github.com/owid/etl/blob/master/etl/steps/data/garden/energy/2023-07-10/electricity_mix.py)
- Energy dataset (Our World in Data based on all sources above):
  - [Processing code](https://github.com/owid/etl/blob/master/etl/steps/data/garden/energy/2023-07-10/owid_energy.py)
  - [Exporting code](https://github.com/owid/energy-data/blob/master/scripts/make_dataset.py)
  - [Uploading code](https://github.com/owid/energy-data/blob/master/scripts/upload_datasets_to_s3.py)

Additionally, to construct region aggregates and variables per capita and per GDP, we use the following datasets and processing steps:
- Regions (Our World in Data).
  - [Processing code](https://github.com/owid/etl/blob/master/etl/steps/data/garden/regions/2023-01-01/regions.py)
- Population (Our World in Data based on [a number of different sources](https://ourworldindata.org/population-sources)).
  - [Processing code](https://github.com/owid/etl/blob/master/etl/steps/data/garden/demography/2023-03-31/population/__init__.py)
- Income groups (World Bank).
  - [Processing code](https://github.com/owid/etl/blob/master/etl/steps/data/garden/wb/2023-04-30/income_groups.py)
- GDP (University of Groningen GGDC's Maddison Project Database, Bolt and van Zanden, 2020).
  - [Source data](https://www.rug.nl/ggdc/historicaldevelopment/maddison/releases/maddison-project-database-2020)
  - [Ingestion code](https://github.com/owid/walden/blob/master/ingests/ggdc_maddison.py)
  - [Processing code](https://github.com/owid/etl/blob/master/etl/steps/data/garden/ggdc/2020-10-01/ggdc_maddison.py)

## Changelog

- On July 7, 2023:
  - Replaced BP's data by the new Energy Institute Statistical Review of World Energy 2023.
  - Updated Ember's yearly electricity data.
  - Updated all datasets accordingly.
- On June 1, 2023:
  - Updated Ember's yearly electricity data.
  - Renamed countries 'East Timor' and 'Faroe Islands', and added 'Middle East (Ember)'.
  - Population and per capita variables are now calculated using an updated version of our population dataset.
- On March 1, 2023:
  - Updated Ember's yearly electricity data and fixed some minor issues.
- On December 30, 2022:
  - Fixed some minor issues with BP's dataset. Regions like ""Other North America (BP)"" have been removed from the data, since, in the original Statistical Review of World Energy, these regions represented different sets of countries for different variables.
- On December 16, 2022:
  - The column `electricity_share_energy` (electricity as a share of primary energy) was added to the dataset.
  - Fixed some minor inconsistencies in electricity data between Ember and BP, by prioritizing data from Ember.
  - Updated Ember's yearly electricity data.
- On August 9, 2022:
  - All inconsistencies due to different definitions of regions among different datasets (especially Europe) have been fixed.
    - Now all regions follow [Our World in Data's definitions](https://ourworldindata.org/world-region-map-definitions).
    - We also include data for regions as defined in the original datasets; for example, `Europe (BP)` corresponds to Europe as defined by BP.
  - All data processing now occurs outside this repository; the code has been migrated to be part of the [etl repository](https://github.com/owid/etl).
  - Variable `fossil_cons_per_capita` has been renamed `fossil_elec_per_capita` for consistency, since it corresponds to electricity generation.
  - The codebook has been updated following these changes.
- On April 8, 2022:
  - Electricity data from Ember was updated (using the Global Electricity Review 2022).
  - Data on greenhouse-gas emissions in electricity generation was added (`greenhouse_gas_emissions`).
  - Data on emissions intensity is now provided for most countries in the world.
- On March 25, 2022:
  - Data on net electricity imports and electricity demand was added.
  - BP data was updated (using the Statistical Review of the World Energy 2021).
  - Maddison data on GDP was updated (using the Maddison Project Database 2020).
  - EIA data on primary energy consumption was included in the dataset.
  - Some issues in the dataset were corrected (for example some missing data in production by fossil fuels).
- On February 14, 2022:
  - Some issues were corrected in the electricity data, and the energy dataset was updated accordingly.
  - The json and xlsx dataset files were removed from GitHub in favor of an external storage service, to keep this repository at a reasonable size.
  - The `carbon_intensity_elec` column was added back into the energy dataset.
- On February 3, 2022, we updated the [Ember global electricity data](https://ember-climate.org/data/global-electricity/), combined with the [European Electricity Review from Ember](https://ember-climate.org/project/european-electricity-review-2022/).
  - The `carbon_intensity_elec` column was removed from the energy dataset (since no updated data was available).
  - Columns for electricity from other renewable sources excluding bioenergy were added (namely `other_renewables_elec_per_capita_exc_biofuel`, and `other_renewables_share_elec_exc_biofuel`).
  - Certain countries and regions have been removed from the dataset, because we identified significant inconsistencies in the original data.
- On March 31, 2021, we updated 2020 electricity mix data.
- On September 9, 2020, the first version of this dataset was made available.

## Data alterations

- **We standardize names of countries and regions.** Since the names of countries and regions are different in different data sources, we harmonize all names to the [*Our World in Data* standard entity names](https://ourworldindata.org/world-region-map-definitions).
- **We create aggregate data for regions (e.g. Africa, Europe, etc.).** Since regions are defined differently by our sources, we create our own aggregates following [*Our World in Data* region definitions](https://ourworldindata.org/world-region-map-definitions).
  - We also include data for regions as defined in the original datasets; for example, `Europe (EI)` corresponds to Europe as defined by the Energy Institute.
- **We recalculate primary energy in terawatt-hours.** The primary data sources on energy—the Energy Institute Statistical review of world energy, for example—typically report consumption in terms of exajoules. We have recalculated these figures as terawatt-hours using a conversion factor of 277.8.
  - Primary energy for renewable sources is reported using [the 'substitution method'](https://ourworldindata.org/energy-substitution-method).
- **We calculate per capita figures.** All of our per capita figures are calculated from our `population` metric, which is included in the complete dataset.
  - We also calculate energy consumption per gdp, and include the corresponding `gdp` metric used in the calculation as part of the dataset.
- **We remove inconsistent data.** Certain data points have been removed because their original data presented anomalies. They may be included again in further data releases if the anomalies are amended.

## License

All visualizations, data, and code produced by _Our World in Data_ are completely open access under the [Creative Commons BY license](https://creativecommons.org/licenses/by/4.0/). You have the permission to use, distribute, and reproduce these in any medium, provided the source and authors are credited.

The data produced by third parties and made available by _Our World in Data_ is subject to the license terms from the original third-party authors. We will always indicate the original source of the data in our database, and you should always check the license of any such third-party data before use.

## Authors

This data has been collected, aggregated, and documented by Hannah Ritchie, Pablo Rosado, Edouard Mathieu, Max Roser.

*Our World in Data* makes data and research on the world’s largest problems understandable and accessible. [Read more about our mission](https://ourworldindata.org/about).

## How to cite this data?

If you are using this dataset, please cite both [Our World in Data](https://ourworldindata.org/energy#citation) and the underlying data source(s).

Please follow [the guidelines in our FAQ](https://ourworldindata.org/faqs#citing-work-produced-by-third-parties-and-made-available-by-our-world-in-data) on how to cite our work.
",.csv
World Food Production,1,world-food-production,world food production.csv,world-bank,"This dataset contains data of total production of different types of foods in per year in each country from 1961-2023 of all country.
**The foods are:**
1. Maize 	
2. Rice 	
3. Yams  	
4. Wheat 
5. Tomatoes 
6. Tea  	
7. Sweet potatoes  	
8. Sunflower seed  	
9. Sugar cane
10. Soybeans  
11. Rye  	
12. Potatoes  	
13. Oranges  	
14. Peas dry 	
15. Palm oil 	  
16. Grapes 
17. Coffee green	
18. Cocoa beans 	
19. Meat chicken  	
20. Bananas 	
21. Avocados 	
22. Apples 
",.csv
World GDP Growth,1,world-gdp-growth,world_gdp_data.csv,other,"### Context
Understanding how the world's economies are doing, especially the trends in World GDP Growth, is crucial for decision-makers, economists, and researchers. This dataset covers the years 1980 to 2024 and gives a complete picture of how the GDP of different countries has been growing. The main goal is to break down the information using specific indicators for each country, providing useful insights into the various factors that influence the global economy.

### Content
In this dataset, you'll find important information like the name of the country, the type of indicator, and the average yearly growth of their economy from 1980 to 2024. This treasure trove of data makes it easy for researchers to do in-depth studies and find connections between different factors. By exploring how country-specific indicators relate to the growth of their economies, we can draw valuable conclusions about the complicated world of global economics throughout the years.

### Dataset Structure:
This dataset (`world_gdp_data.csv`) covering from 1980 to 2024 consists of the following columns:

| Column Name  | Description                                   |
| -------------- | --------------------------------------------- |
| `country_name`   | Name of the Country                            |
| `indicator_name` | Type of Inflation Indicator                |
| `1980`           | Annual GDP growth in 1980 (in %)    |
| `1981`            | Annual GDP growth in 1981 (in %)    |
| `1982`           | Annual GDP growth in 1982 (in %)    |
|  ' ' ' |    ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' |
| `2022`           | Annual GDP growth in 2022 (in %)   |
| `2023`           | Annual GDP growth in 2023 (in %)   |
| `2024`           | Annual GDP growth in 2024 (in %)   |


### Acknowledgment
The primary dataset was sourced from the [International Monetary Fund](https://www.imf.org/en/Home). I extend sincere gratitude to the team for providing the core data used in this dataset.

© Image credit: [Freepik](https://www.freepik.com/free-vector/gross-domestic-product-concept-growth-arrow-chart-with-globe-stacks-money-happy-tiny-professional_11235458.htm)",.csv
World Happiness Report 2019,1,world-happiness-report-2019,world-happiness-report-2019.csv,CC0-1.0,"The data has been released by SDSN and extracted by [PromptCloud][1]'s custom web crawling solution.

### Context

The World Happiness Report is a landmark survey of the state of global happiness that ranks 156 countries by how happy their citizens perceive themselves to be. This year’s World Happiness Report focuses on happiness and the community: how happiness has evolved over the past dozen years, with a focus on the technologies, social norms, conflicts and government policies that have driven those changes.

### Content

**What is Dystopia?**

Dystopia is an imaginary country that has the world’s least-happy people. The purpose in establishing Dystopia is to have a benchmark against which all countries can be favorably compared (no country performs more poorly than Dystopia) in terms of each of the six key variables, thus allowing each sub-bar to be of positive (or zero, in six instances) width. The lowest scores observed for the six key variables, therefore, characterize Dystopia. Since life would be very unpleasant in a country with the world’s lowest incomes, lowest life expectancy, lowest generosity, most corruption, least freedom, and least social support, it is referred to as “Dystopia,” in contrast to Utopia.

**What are the residuals?**

The residuals, or unexplained components, differ for each country, reflecting the extent to which the six variables either over- or under-explain average 2016-2018 life evaluations. These residuals have an average value of approximately zero over the whole set of countries. Figure 2.7 shows the average residual for each country if the equation in Table 2.1 is applied to average 2016- 2018 data for the six variables in that country. We combine these residuals with the estimate for life evaluations in Dystopia so that the combined bar will always have positive values. As can be seen in Figure 2.7, although some life evaluation residuals are quite large, occasionally exceeding one point on the scale from 0 to 10, they are always much smaller than the calculated value in Dystopia, where the average life is rated at 1.88 on the 0 to 10 scale. Table 7 of the online Statistical Appendix 1 for Chapter 2 puts the Dystopia plus residual block at the left side, and also draws the Dystopia line, making it easy to compare the signs and sizes of the residuals in different countries.

**Why do we use these six factors to explain life evaluations?**

The variables used reflect what has been broadly found in the research literature to be important in explaining national-level differences in life evaluations. Some important variables, such as unemployment or inequality, do not appear because comparable international data are not yet available for the full sample of countries. The variables are intended to illustrate important lines of correlation rather than to reflect clean causal estimates, since some of the data are drawn from the same survey sources, some are correlated with each other (or with other important factors for which we do not have measures), and in several instances there are likely to be two-way relations between life evaluations and the chosen variables (for example, healthy people are overall happier, but as Chapter 4 in the World Happiness Report 2013 demonstrated, happier people are overall healthier). In Statistical Appendix 1 of World Happiness Report 2018, we assessed the possible importance of using explanatory data from the same people whose life evaluations are being explained. We did this by randomly dividing the samples into two groups, and using the average values for .e.g. freedom gleaned from one group to explain the life evaluations of the other group. This lowered the effects, but only very slightly (e.g. 2% to 3%), assuring us that using data from the same individuals is not seriously affecting the results.

Data source: http://worldhappiness.report/ed/2019/

  [1]: https://www.promptcloud.com/?utm_source=kaggle&utm_medium=happiness-report

More such datasets can be downloaded from [DataStock][2].

  [2]: http://www.datastock.shop",.csv
World Happiness Report 2023,1,world-happiness-report-2023,WHR2023.csv,CC0-1.0,"**Context**
The World Happiness Report is a landmark survey of the state of global happiness . The report continues to gain global recognition as governments, organizations and civil society increasingly use happiness indicators to inform their policy-making decisions. Leading experts across fields – economics, psychology, survey analysis, national statistics, health, public policy and more – describe how measurements of well-being can be used effectively to assess the progress of nations. The reports review the state of happiness in the world today and show how the new science of happiness explains personal and national variations in happiness.

**Content**
The happiness scores and rankings use data from the Gallup World Poll . The columns following the happiness score estimate the extent to which each of six factors – economic production, social support, life expectancy, freedom, absence of corruption, and generosity – contribute to making life evaluations higher in each country than they are in Dystopia, a hypothetical country that has values equal to the world’s lowest national averages for each of the six factors. They have no impact on the total score reported for each country, but they do explain why some countries rank higher than others.",.csv
"World Happiness Report, 2005-Present",1,world-happiness-report-2005-present,World Happiness Report.csv,CC0-1.0,"**Detailed information about each of the Predictors**

**1. Log GDP per capita** is in terms of Purchasing Power Parity (PPP) adjusted to a constant 2017 international dollars, taken from the World Development Indicators (WDI) by the World Bank (version 17, metadata last updated on January 22, 2023). See Statistical Appendix 1 for more details. GDP data for 2022 are not yet available, so we extend the GDP time series from 2021 to 2022 using country-specific forecasts of real GDP growth from the OECD Economic Outlook No. 112 (November 2022) or, if missing, from the World Bank’s Global Economic Prospects (last updated: January 10, 2023), after adjustment for population growth. The equation uses the natural log of GDP per capita, as this form fits the data significantly better than GDP per capita.
**2.** The time series for **Healthy life expectancy at birth** is constructed based on data from the World Health Organization (WHO) Global Health Observatory data repository, with data available for 2005, 2010, 2015, 2016, and 2019. To match this report’s sample period (2005-2022), interpolation and extrapolation are used. See Statistical Appendix 1 for more details.
**3. Social support (0-1)** is the national average of the binary responses (0=no, 1=yes) to the Gallup World Poll (GWP) question “If you were in trouble, do you have relatives or friends you can count on to help you whenever you need them, or not?”
**4. Freedom to make life choices (0-1)** is the national average of binary responses to the GWP question “Are you satisfied or dissatisfied with your freedom to choose what you do with your life?”
**5. Generosity** is the residual of regressing the national average of GWP responses to the donation question “Have you donated money to a charity in the past month?” on log GDP per capita.
**6. Perceptions of corruption (0-1)** are the average of binary answers to two GWP questions: “Is corruption widespread throughout the government or not?” and “Is corruption widespread within businesses or not?” Where data for government corruption are missing, the perception of business corruption is used as the overall corruption perception measure.
**7. Positive affect** is defined as the average of previous-day effects measures for laughter, enjoyment, and interest. The inclusion of interest (first added for World Happiness Report 2022), gives us three components in each of positive and negative affect, and slightly improves the equation fit in column 4. The general form for the affect questions is: Did you experience the following feelings during a lot of the day yesterday?
**8. Negative affect** is defined as the average of previous-day effects measures for worry, sadness, and anger.

The World Happiness Report is a publication of the Sustainable Development Solutions Network, powered by the Gallup World Poll data. The World Happiness Report reflects a worldwide demand for more attention to happiness and well-being as criteria for government policy. It reviews the state of happiness in the world today and shows how the science of happiness explains personal and national variations in happiness.

Life evaluations from the Gallup World Poll provide the basis for the annual happiness rankings. They are based on answers to the main life evaluation question. The Cantril ladder asks respondents to think of a ladder, with the best possible life for them being a 10 and the worst possible life being a 0. They are then asked to rate their own current lives on a 0 to 10 scale. The rankings are from nationally representative samples over three years.

We use observed data on the six variables and estimates of their associations with life evaluations to explain the variation across countries. They include GDP per capita, social support, healthy life expectancy, freedom, generosity, and corruption. Our happiness rankings are not based on any index of these six factors – the scores are instead based on individuals’ own assessments of their lives, in particular, their answers to the single-item Cantril ladder life-evaluation question, much as epidemiologists estimate the extent to which life expectancy is affected by factors such as smoking, exercise, and diet.

The World Happiness Report and much of the growing international interest in happiness exist thanks to Bhutan. They sponsored Resolution 65/309, “Happiness: Towards a holistic approach to development,” adopted by the General Assembly of the United Nations on 19 July 2011, inviting national governments to “give more importance to happiness and well-being in determining how to achieve and measure social and economic development.”

On 2 April 2012, chaired by Prime Minister Jigmi Y. Thinley and Jeffrey D. Sachs, the first World Happiness Report was presented to review evidence from the emerging science of happiness for the ‘Defining a New Economic Paradigm: The Report of the High-Level Meeting on Well-being and Happiness.’ On 28 June 2012, the United Nations General Assembly adopted Resolution 66/281, proclaiming the 20 March International Day of Happiness to be observed annually. The World Happiness Report is released annually around March 20th as part of the International Day of Happiness celebration.

Published by the Sustainable Development Solutions Network, the preparation of the World Happiness Report is at the Center for Sustainable Development at Columbia University, with research support from the Centre for Economic Performance at the London School of Economics; the Vancouver School of Economics at the University of British Columbia; the Wellbeing Research Centre at the University of Oxford; and the Helping and Happiness Lab at Simon Fraser University.

The editorial team includes three founding editors, John F. Helliwell, Richard Layard, and Jeffrey D. Sachs, and editors Jan-Emmanuel De Neve, Lara B. Aknin, and Shun Wang. Sharon Paculor manages operations as Production Editor.",.csv
World Marathons Majors,1,world-marathons-majors,world_marathon_majors.csv,CC0-1.0,"### Introduccion
Una o un maratón​ es una carrera de larga distancia que consiste en recorrer una distancia de 42 195 metros (42 km y 195 m). Forma parte del programa de atletismo en los Juegos Olímpicos desde Atenas 1896, en la categoría masculina, y desde Los Ángeles 1984, en la categoría femenina.

Su origen se encuentra en la gesta del soldado griego Filípides, quien en el año 490 a. C. habría muerto de fatiga tras haber corrido 42 km y 195 m desde Maratón hasta Atenas para anunciar la victoria sobre el ejército persa. En realidad Filípides recorrió el camino desde Atenas hasta Esparta para pedir refuerzos,2​ lo que serían unos 213 kilómetros.

El keniata Eliud Kipchoge posee la mejor marca de maratón masculina de todos los tiempos (2:01:39), obtenida en Berlín el 16 de septiembre de 2018;3​ y la keniata Brigid Kosgei es poseedora de la mejor marca femenina (2:14:04), conseguida en Chicago el 13 de octubre de 2019.4​ 

### Contenido

El data set incluye los tiempos y los nombre y su pais de origen de todos los ganadores delos maratones mas importantes del mundo .


### Agradecimientos

Se ha limpiado los datos sim embargo pueden encontrar la informacion original en:
data set original:
https://data.world/newns92/abbott-world-marathon-majors-winners
Informacion:
https://es.wikipedia.org/wiki/Marat%C3%B3n",.csv
World Population Data,1,world-population-data,world_population_data.csv,CC0-1.0,"### Context
The world's population has undergone remarkable growth, exceeding 7.5 billion by mid-2019 and continuing to surge beyond previous estimates. Notably, China and India stand as the two most populous countries, with China's population potentially facing a decline while India's trajectory hints at surpassing it by 2030. This significant demographic shift is just one facet of a global landscape where countries like the United States, Indonesia, Brazil, Nigeria, and others, each with populations surpassing 100 million, play pivotal roles.

The steady decrease in growth rates, though, is reshaping projections. While the world's population is expected to exceed 8 billion by 2030, growth will notably decelerate compared to previous decades. Specific countries like India, Nigeria, and several African nations will notably contribute to this growth, potentially doubling their populations before rates plateau.

### Content
This dataset provides comprehensive historical population data for countries and territories globally, offering insights into various parameters such as area size, continent, population growth rates, rankings, and world population percentages. Spanning from 1970 to 2023, it includes population figures for different years, enabling a detailed examination of demographic trends and changes over time.

### Dataset
Structured with meticulous detail, this dataset offers a wide array of information in a format conducive to analysis and exploration. Featuring parameters like population by year, country rankings, geographical details, and growth rates, it serves as a valuable resource for researchers, policymakers, and analysts. Additionally, the inclusion of growth rates and world population percentages provides a nuanced understanding of how countries contribute to global demographic shifts.

This dataset is invaluable for those interested in understanding historical population trends, predicting future demographic patterns, and conducting in-depth analyses to inform policies across various sectors such as economics, urban planning, public health, and more.

### Structure

This dataset (`world_population_data.csv`) covering from 1970 up to 2023 includes the following columns:

| Column Name            | Description                                                     |
|------------------------|-----------------------------------------------------------------|
| `Rank`                 | Rank by Population                                               |
| `CCA3`                 | 3 Digit Country/Territories Code                                 |
| `Country`  | Name of the Country                                |
| `Continent`            | Name of the Continent                                            |
| `2023 Population`      | Population of the Country in the year 2023           |
| `2022 Population`      | Population of the Country in the year 2022           |
| `2020 Population`      | Population of the Country in the year 2020           |
| `2015 Population`      | Population of the Country in the year 2015           |
| `2010 Population`      | Population of the Country in the year 2010           |
| `2000 Population`      | Population of the Country in the year 2000           |
| `1990 Population`      | Population of the Country in the year 1990           |
| `1980 Population`      | Population of the Country in the year 1980           |
| `1970 Population`      | Population of the Country in the year 1970           |
| `Area (km²)`           | Area size of the Country/Territories in square kilometer         |
| `Density (km²)`    | Population Density per square kilometer                          |
| `Growth Rate`          | Population Growth Rate by Country                  |
| `World Population Percentage` | The population percentage by each Country         |

### Acknowledgment
The primary dataset was retrieved from the [World Population Review](https://worldpopulationreview.com/). I sincerely thank the team for providing the core data used in this dataset.

© Image credit: [Freepik](https://www.freepik.com/premium-photo/large-group-people-divers_2707036.htm)",.csv
World Population Growth,1,world-population-growth,World Population Growth.csv,ODC Public Domain Dedication and Licence (PDDL),"The World Population Growth Dataset provides comprehensive data on global population dynamics from the year 1951 to 2023. It includes key attributes such as total population count, annual percentage growth rate, population density (population per square kilometer), and the corresponding years.

Content:
This dataset encompasses the following attributes:
- Year: The calendar year for which population data is recorded, ranging from 1951 to 2023.
- Population: The total population count for the specified year.
- Yearly Growth %: The annual percentage growth rate of the population, representing the rate of change in population size from one year to the next.
- Number: The population increase.
- Density (Pop/km2): Population density, measured as the number of individuals per square kilometer of land area.

Use Cases:
The World Population Growth Dataset serves a variety of purposes, including:
- Demographic analysis: Researchers can analyze population trends, growth rates, and density patterns over time to understand demographic shifts and their implications.
- Policy formulation: Policymakers can utilize population data to develop strategies for urban planning, resource allocation, and social welfare programs.
- Environmental studies: Environmental researchers can examine population density data in relation to land use, habitat conservation, and sustainability efforts.

Dataset Information:
- Title: World Population Growth Dataset
- Version: 1.0
- License: Open Database License (ODbL) or Creative Commons Attribution-ShareAlike (CC BY-SA) (depending on the source)
- Format: CSV (Comma-Separated Values) or Excel spreadsheet
- Size: Variable (depending on the scope and granularity of data)
- Columns: 
  1. Year: Integer (1951-2023)
  2. Population: Integer (Total population count)
  3. Yearly Growth %: Float (Annual percentage growth rate)
  4. Number: increase in popultation
  5. Density (Pop/km2): Float (Population density in individuals per square kilometer)

**Disclaimer:**
While efforts have been made to ensure data accuracy and reliability, no guarantee is provided regarding completeness or correctness. Users are advised to verify the data and exercise caution when interpreting or utilizing the dataset.

",.csv
World Population Growth (Annual %),1,world-population-growth-annual,The_World_Bank_Population_growth_(annual_).csv,Attribution 4.0 International (CC BY 4.0),"This dataset contains the growth rate (in %) of all the Countries around the Globe and also some sub-categories like based on financial status.
The data is from 1961 to all the way to 2022, with step=1

Original version
Credit -&gt; The World Bank: Population Growth (Annual %); Data Source:
Derived from total population. Population source: ( 1 ) United Nations Population Division. World Population Prospects: 2022 Revision, ( 2 ) Census reports and other statistical publications from national statistical offices, ( 3 ) Eurostat: Demographic Statistics, ( 4 ) United Nations Statistical Division. Population and Vital Statistics Reprot ( various years ), ( 5 ) U.S. Census Bureau: International Database, and ( 6 ) Secretariat of the Pacific Community: Statistics and Demography Programme.
[Term of Use](https://www.worldbank.org/en/about/legal/terms-of-use-for-datasets)

Data was collected from [this](https://data.worldbank.org/indicator/SP.POP.GROW).

I have made some changes like rename columns and drop some incomplete entries and columns.

Thank you.",.csv
World Population Live Dataset 2022,1,world-population-live-dataset,World Population Live Dataset.csv,CC0-1.0,"The current US Census Bureau world population estimate in June 2019 shows that the current global population is 7,577,130,400 people on earth, which far exceeds the world population of 7.2 billion from 2015. Our own estimate based on UN data shows the world's population surpassing 7.7 billion.

China is the most populous country in the world with a population exceeding 1.4 billion. It is one of just two countries with a population of more than 1 billion, with India being the second. As of 2018, India has a population of over 1.355 billion people, and its population growth is expected to continue through at least 2050. By the year 2030, the country of India is expected to become the most populous country in the world. This is because India’s population will grow, while China is projected to see a loss in population.

The next 11 countries that are the most populous in the world each have populations exceeding 100 million. These include the United States, Indonesia, Brazil, Pakistan, Nigeria, Bangladesh, Russia, Mexico, Japan, Ethiopia, and the Philippines. Of these nations, all are expected to continue to grow except Russia and Japan, which will see their populations drop by 2030 before falling again significantly by 2050.

Many other nations have populations of at least one million, while there are also countries that have just thousands. The smallest population in the world can be found in Vatican City, where only 801 people reside.

In 2018, the world’s population growth rate was 1.12%. Every five years since the 1970s, the population growth rate has continued to fall. The world’s population is expected to continue to grow larger but at a much slower pace. By 2030, the population will exceed 8 billion. In 2040, this number will grow to more than 9 billion. In 2055, the number will rise to over 10 billion, and another billion people won’t be added until near the end of the century. The current annual population growth estimates from the United Nations are in the millions - estimating that over 80 million new lives are added each year.

This population growth will be significantly impacted by nine specific countries which are situated to contribute to the population growth more quickly than other nations. These nations include the Democratic Republic of the Congo, Ethiopia, India, Indonesia, Nigeria, Pakistan, Uganda, the United Republic of Tanzania, and the United States of America. Particularly of interest, India is on track to overtake China's position as the most populous country by the year 2030. Additionally, multiple nations within Africa are expected to double their populations before fertility rates begin to slow entirely.

Global life expectancy has also improved in recent years, increasing the overall population life expectancy at birth to just over 70 years of age. The projected global life expectancy is only expected to continue to improve - reaching nearly 77 years of age by the year 2050. Significant factors impacting the data on life expectancy include the projections of the ability to reduce AIDS/HIV impact, as well as reducing the rates of infectious and non-communicable diseases.

Population aging has a massive impact on the ability of the population to maintain what is called a support ratio. One key finding from 2017 is that the majority of the world is going to face considerable growth in the 60 plus age bracket. This will put enormous strain on the younger age groups as the elderly population is becoming so vast without the number of births to maintain a healthy support ratio.

Although the number given above seems very precise, it is important to remember that it is just an estimate. It simply isn't possible to be sure exactly how many people there are on the earth at any one time, and there are conflicting estimates of the global population in 2016.

Some, including the UN, believe that a population of 7 billion was reached in October 2011. Others, including the US Census Bureau and World Bank, believe that the total population of the world reached 7 billion in 2012, around March or April.


| Columns | Description |
| --- | --- |
| CCA3 | 3 Digit Country/Territories Code |
| Name| Name of the Country/Territories |
| 2022 | Population of the Country/Territories in the year 2022. |
| 2020 | Population of the Country/Territories in the year 2020. |
| 2015 | Population of the Country/Territories in the year 2015. |
| 2010 | Population of the Country/Territories in the year 2010. |
| 2000 | Population of the Country/Territories in the year 2000. |
| 1990 | Population of the Country/Territories in the year 1990. |
| 1980 | Population of the Country/Territories in the year 1980. |
| 1970 | Population of the Country/Territories in the year 1970. |
| Area (km²) | Area size of the Country/Territories in square kilometer. |
| Density (per km²) | Population Density per square kilometer. |
| Growth Rate | Population Growth Rate by Country/Territories. |
| World Population Percentage | The population percentage by each Country/Territories. |
| Rank | Rank by Population |

&gt; More
- Find More Exciting🙀 Datasets [Here](https://www.kaggle.com/whenamancodes/datasets)
- An Upvote👍 A Dayᕙ(`▿´)ᕗ , Keeps Aman Hurray Hurray..... ٩(˘◡˘)۶Haha",.csv
World Population by Country 2023,1,world-population-by-country-2023,WorldPopulation2023.csv,DbCL-1.0,"This list includes both countries and dependent territories. Data based on the latest United Nations Population Division estimates.


-    Country - Name of countries and dependent territories.
-    Population2023 - Population in the year 2023
-    YearlyChange - Percentage Yearly Change in Population
-    NetChange - Net Change in Population
-    Density(P/Km²)- Population density (population per square km)
-    Land Area(Km²) - Land area of countries / dependent territories.
-    Migrants(net) - Total number of migrants
-    Fert.Rate - Fertility rate
-    Med.Age - Median age of the population
-    UrbanPop%- Percentage of urban population
-    WorldShare - Population share
",.csv
World Sustainability Dataset,1,worldsustainabilitydataset,WorldSustainabilityDataset.csv,CC0-1.0,"A ‘global sustainability’ dataset has been put together for the TrueCue Women+Data Hackathon. The dataset tracks the performance of 173 countries against a range of sustainability metrics over a 19-year period. 

The dataset was generated from several merged data sources. While there 54 fields included, participants are not expected, nor advised to analyse the whole data. On the contrary, the wide nature of the dataset should give rise to a range of analytical possibilities. 

Please note that the data is real. This presents all the challenges of working with data in professional world, such as missing values. For instance, a given country may not have data available for every field and every year. 
",.csv
World University Rankings 2023,1,world-university-rankings-2023,World University Rankings 2023.csv,ODbL-1.0,"**About Dataset**
The  World University Rankings 2023 dataset include 1,799 universities across 104 countries and regions, making them the largest and most diverse university rankings to date. The table is based on 13 carefully calibrated performance indicators that measure an institution’s performance across four areas: teaching, research, knowledge transfer and international outlook. This year’s ranking analyzed over 121 million citations across more than 15.5 million research publications and included survey responses from 40,000 scholars globally. Overall, we collected over 680,000 datapoints from more than 2,500 institutions that submitted data.
**Features**
This dataset includes following 13 features:
**1)**University Rank**2)**Name of University**3)**Location**4)**No of student**5)**No of student per staff**6)**International Student**7)**Female :Male Ratio**8)**OverAll Score**9)**Teaching Score**10)**Research Score**11)**Citations Score**12)**Industry Income Score**13)**International Outlook Score",.csv
World Weather Repository ( Daily Updating ),1,global-weather-repository,GlobalWeatherRepository.csv,other,"# Description

&gt;This dataset provides **daily weather information for capital cities around the world**.  Unlike forecast data, this dataset offers a comprehensive set of features that reflect the **current weather conditions around the world**. <br>**Starting from August 29, 2023.** <br> **It provides over 40+ features** , including temperature, wind, pressure, precipitation, humidity, visibility, air quality measurements and more. **The dataset is valuable for analyzing Global weather patterns**, exploring climate trends, and understanding the relationships between different weather parameters.

# Key Features

&gt;- **country**: Country of the weather data
- **location_name**: Name of the location (city)
- **latitude**: Latitude coordinate of the location
- **longitude**: Longitude coordinate of the location
- **timezone**: Timezone of the location
- **last_updated_epoch**: Unix timestamp of the last data update
- **last_updated**: Local time of the last data update
- **temperature_celsius**: Temperature in degrees Celsius
- **temperature_fahrenheit**: Temperature in degrees Fahrenheit
- **condition_text**: Weather condition description
- **wind_mph**: Wind speed in miles per hour
- **wind_kph**: Wind speed in kilometers per hour
- **wind_degree**: Wind direction in degrees
- **wind_direction**: Wind direction as a 16-point compass
- **pressure_mb**: Pressure in millibars
- **pressure_in**: Pressure in inches
- **precip_mm**: Precipitation amount in millimeters
- **precip_in**: Precipitation amount in inches
- **humidity**: Humidity as a percentage
- **cloud**: Cloud cover as a percentage
- **feels_like_celsius**: Feels-like temperature in Celsius
- **feels_like_fahrenheit**: Feels-like temperature in Fahrenheit
- **visibility_km**: Visibility in kilometers
- **visibility_miles**: Visibility in miles
- **uv_index**: UV Index
- **gust_mph**: Wind gust in miles per hour
- **gust_kph**: Wind gust in kilometers per hour
- **air_quality_Carbon_Monoxide**: Air quality measurement: Carbon Monoxide
- **air_quality_Ozone**: Air quality measurement: Ozone
- **air_quality_Nitrogen_dioxide**: Air quality measurement: Nitrogen Dioxide
- **air_quality_Sulphur_dioxide**: Air quality measurement: Sulphur Dioxide
- **air_quality_PM2.5**: Air quality measurement: PM2.5
- **air_quality_PM10**: Air quality measurement: PM10
- **air_quality_us-epa-index**: Air quality measurement: US EPA Index
- **air_quality_gb-defra-index**: Air quality measurement: GB DEFRA Index
- **sunrise**: Local time of sunrise
- **sunset**: Local time of sunset
- **moonrise**: Local time of moonrise
- **moonset**: Local time of moonset
- **moon_phase**: Current moon phase
- **moon_illumination**: Moon illumination percentage

# Potential Use Cases

&gt;- **Climate Analysis:** Study long-term climate patterns and variations in different regions.
- **Weather Prediction:** Build models for weather forecasting based on historical data.
- **Environmental Impact:** Analyze air quality and its correlation with various weather parameters.
- **Tourism Planning:** Use weather data to help travelers plan their trips more effectively.
- **Geographical Patterns:** Explore how weather conditions differ across countries and continents.


If you find this dataset useful, please consider giving it an upvote! 🙂❤️
",.csv
World cities database,1,world-cities,worldcities.csv,Attribution 4.0 International (CC BY 4.0),"The data is from:

https://simplemaps.com/data/world-cities

We're proud to offer a simple, accurate and up-to-date database of the world's cities and towns. We've built it from the ground up using authoritative sources such as the NGIA, US Geological Survey, US Census Bureau, and NASA.
   
Our database is:

- Up-to-date: It was last refreshed on March 19, 2024.
- Comprehensive: Over 4 million unique cities and towns from every country in the world (about 47 thousand in basic database).
- Accurate: Cleaned and aggregated from official sources. Includes latitude and longitude coordinates.
- Simple: A single CSV file, concise field names, only one entry per city.",.csv
World data population,1,world-data-population,world_population_data.csv,MIT,"**Context**
The world's population has undergone remarkable growth, exceeding 7.5 billion by mid-2019 and continuing to surge beyond previous estimates. Notably, China and India stand as the two most populous countries, with China's population potentially facing a decline while India's trajectory hints at surpassing it by 2030. This significant demographic shift is just one facet of a global landscape where countries like the United States, Indonesia, Brazil, Nigeria, and others, each with populations surpassing 100 million, play pivotal roles.

The steady decrease in growth rates, though, is reshaping projections. While the world's population is expected to exceed 8 billion by 2030, growth will notably decelerate compared to previous decades. Specific countries like India, Nigeria, and several African nations will notably contribute to this growth, potentially doubling their populations before rates plateau.

**Content**
This dataset provides comprehensive historical population data for countries and territories globally, offering insights into various parameters such as area size, continent, population growth rates, rankings, and world population percentages. Spanning from 1970 to 2023, it includes population figures for different years, enabling a detailed examination of demographic trends and changes over time.

**Dataset**
Structured with meticulous detail, this dataset offers a wide array of information in a format conducive to analysis and exploration. Featuring parameters like population by year, country rankings, geographical details, and growth rates, it serves as a valuable resource for researchers, policymakers, and analysts. Additionally, the inclusion of growth rates and world population percentages provides a nuanced understanding of how countries contribute to global demographic shifts.

This dataset is invaluable for those interested in understanding historical population trends, predicting future demographic patterns, and conducting in-depth analyses to inform policies across various sectors such as economics, urban planning, public health, and more.",.csv
World's Largest Empires by Area,1,worlds-largest-empires-by-area,largest_empires_by_area.csv,CC0-1.0,"# Context
This dataset has been sourced from [this Wikipedia page](https://en.wikipedia.org/wiki/List_of_largest_empires). All the credit for the collection and preservation of this data goes to the respective page authors and/or owners for the aforementioned page. 

It contains a list of 172 empires throughout the world's history along with their area coverage at the greatest point. It has been brought here to kaggle in an attempt to simply make it available in a more consumable format.

### *Please Upvote if this helps you!*

# Content
The most (Total 21 features) prominent features are:
1. **Empire** 
2. **Maximum Land area (million km^2)**
3. **Maximum Land area (million sq mi)**
4. **Maximum Land area - % of the world** 
5. **Year** 

# Acknowledgements
The data was collected from Wikipedia from the page - *List of Largest Empires*",.csv
Worldwide Meat Consumption,1,meatconsumption,meat_consumption_worldwide.csv,DbCL-1.0,"### Context

Meat consumption is related to living standards, diet, livestock production and consumer prices, as well as macroeconomic uncertainty and shocks to GDP. Compared to other commodities, meat is characterised by high production costs and high output prices. Meat demand is associated with higher incomes and a shift - due to urbanisation - to food consumption changes that favour increased proteins from animal sources in diets. While the global meat industry provides food and a livelihood for billions of people, it also has significant environmental and health consequences for the planet.

This dataset was refreshed in 2018, with world meat projections up to 2026 are presented for beef and veal, pig, poultry, and sheep. Meat consumption is measured in thousand tonnes of carcass weight (except for poultry expressed as ready to cook weight) and in kilograms of retail weight per capita. Carcass weight to retail weight conversion factors are: 0.7 for beef and veal, 0.78 for pig meat, and 0.88 for both sheep meat and poultry meat. **Excludes** Iceland but **includes** all EU 28 member countries.

### Content

The csv file has 5 columns:

- LOCATION = the country code name
- SUBJECT = The type of meat(pig, beef, etc)
- TIME = the year the data was recorded
- MEASURE = the measure used to show the value
- VALUE = The value, according to the measure


### Acknowledgements

https://data.oecd.org/agroutput/meat-consumption.htm
OECD/FAO (2017), “OECD-FAO Agricultural Outlook”, OECD Agriculture statistics (database). doi: dx.doi.org/10.1787/agr-outl-data-en (Accessed on 24 January 2018)

### Inspiration

Ask questions such as:

1. What country had the most meat consumption?
2. What years had the most worldwide meat consumption?
3. Is there any correlation between the type of meat and the amount being consumed?",.csv
Worldwide Traffic Congestion Ranking,1,worldwide-traffic-congestion-ranking,TrafficIndex_19Jun2022-26Jun2022.csv,CC0-1.0,"# Worldwide Traffic Congestion Ranking [between: 19Jun2022 & 26Jun2022]

TCI, calculated only for the center of the tracked location (the city image is split in 9 equal rectangles, forming a 3x3 grid. The central rectangle is taken into consideration when calculating TCI).

Every 20 minutes, the web app saves an image for each tracked location, containing the traffic data reported by Google Maps. After a couple of minutes, the images are analyzed, and the percentages of the 4 traffic colors are calculated.

Let's call these percentages:
green → P0
orange → P1
red → P2
dark red → P3

Obviously , the sum of all these percentages is 100:
P0 + P1 + P2 + P3 = 100
Based on these percentages, the TCI (Traffic Congestion Index) is calculated:

TCI = (0 * P0) + (1 * P1) + (2 * P2) + (3 * P3)

So the minimum value of TCI is 0, and the maximum value of TCI is 300 (highly improbable to happen). Examples:

| P0    | P1    | P2   | P3    | TCI    | Comments                                                |
|-------|-------|------|-------|--------|---------------------------------------------------------|
| 100   | 0     | 0    | 0     | 0      | Awesome traffic (very unlikely to happen in big cities) |
| 85.42 | 7.21  | 2.51 | 4.86  | 26.81  | Low traffic congestion                                  |
| 41.78 | 13.08 | 6.42 | 38.72 | 142.08 | High traffic congestion                                 |


",.csv
YouTube Sports Channels Statistics,1,youtube-sports-channels-statistics,yt_sports_channels_stats.csv,ODC Attribution License (ODC-By),"


**Dataset Overview:**
- **Scope:** Explore a vast set of sports channels on YouTube, each a beacon of engagement and community in the sports world.
- **Utility:** Ideal for data enthusiasts looking to analyze trends in sports broadcasting, understand audience engagement, and uncover growth patterns among the most popular sports channels on YouTube.

**Data Science Applications:**
- **Trend Forecasting:** Predict future growth and engagement trends within the sports broadcasting domain on YouTube.
- **Audience Insights:** Gain a deeper understanding of viewer preferences and behaviors.
- **Content Strategy Optimization:** Leverage video and subscriber count metrics to inform content creation and channel growth strategies.

**Column Descriptors:**
- **Channel ID:** Unique identifier for each YouTube channel.
- **Channel Title:** Name of the channel.
- **Start Date:** The inception date of the channel on YouTube.
- **Video Count:** Total number of videos uploaded by the channel.
- **View Count:** Cumulative number of views across all videos.
- **Subscriber Count:** Total number of channel subscribers.

**Ethical Considerations:**
- Data has been ethically mined, adhering to privacy norms and YouTube's data use policies, ensuring responsible use of digital information.

**Acknowledgements:**
- A heartfelt thanks to YouTube for fostering a dynamic platform that brings together sports fans and content creators from around the globe.
- The dataset's thumbnail, featuring the YouTube logo, is a tribute to the platform's pivotal role in the dissemination of sports content.

Embark on an analytical expedition through the ""YouTube Sports Channels Statistics"" dataset, where every number narrates the passion and dynamism of the global sports community on YouTube.
",.csv
Youth Tobacco Dataset (2 Decades),1,youth-tobacco-survey,Youth_Tobacco_Survey__YTS__Data.csv,Apache 2.0,"This dataset was developed to provide states with comprehensive data on both middle school and high school students regarding tobacco use, exposure to environmental tobacco smoke, smoking cessation, school curriculum, minors' ability to purchase or otherwise obtain tobacco products, knowledge and attitudes about tobacco, and familiarity with pro-tobacco and anti-tobacco media messages. The dataset uses a two-stage cluster sample design to produce representative samples of students in middle schools (grades 6–8) and high schools (grades 9–12)

This dataset is valuable for data science due to its coverage of youth tobacco use over nearly two decades. Its rich demographic details and broad geographical spread enable researchers and policymakers to identify trends, behaviors, and risk factors associated with tobacco use among the youth. 

For instance, it can help in understanding how tobacco use prevalence varies across different age groups, genders, races, and educational backgrounds. The stratification of data by location and demographic characteristics allows for targeted analysis that can inform public health strategies and educational campaigns aimed at reducing tobacco use among young people.

Some analysis of this dataset can include:

- Statistical assessments of tobacco use trends, examining changes in attitudes towards tobacco, and identifying high-risk groups based on demographic characteristics. 
- Performing time-series analyses to understand how tobacco use has evolved over the years or spatial analyses to identify geographical variations in tobacco use trends. 
- Correlation studies can help uncover associations between tobacco use and factors like education levels, race, and gender. 
- Advanced machine learning models could predict future trends in youth tobacco use or evaluate the potential impact of new tobacco control measures.",.csv
Youth Tobacco Survey (YTS) Data (USA),1,youth-tobacco-survey-yts-data-usa,Youth_Tobacco_Survey__YTS__Data.csv,ODC Attribution License (ODC-By),"
1999-2017. Centers for Disease Control and Prevention (CDC). State Tobacco Activities Tracking and Evaluation (STATE) System. YTS Data. The YTS was developed to provide states with comprehensive data on both middle school and high school students regarding tobacco use, exposure to environmental tobacco smoke, smoking cessation, school curriculum, minors' ability to purchase or otherwise obtain tobacco products, knowledge and attitudes about tobacco, and familiarity with pro-tobacco and anti-tobacco media messages. The YTS uses a two-stage cluster sample design to produce representative samples of students in middle schools (grades 6–8) and high schools (grades 9–12). The data for the STATE System were extracted from Youth Tobacco Surveys from participating states. Tobacco topics included are cigarette smoking prevalence, cigarette smoking frequency, smokeless tobacco products prevalence and quit attempts.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16192307%2F74ae4621ebb6a56085b36468b63d6521%2F41599_2019_326_Fig1_HTML.png?generation=1707330334821379&alt=media)",.csv
"Youtube Channel ""Yoga with Kassandra""",1,youtube-channel-yoga-with-kassandra,youtube_yoga_with_kassandra_2024_03_16_V02.csv,CC-BY-NC-SA-4.0,"Data is from the Youtube Channel ""Yoga with Kassandra"".

I started watching the yoga videos on youtube during the covid pandemic, when I couldn't go to a yoga studio. Since than I personally watch less the channel. The channel exits more than 10 years, which makes it for me a great analysis object.

Data scraping was on March 16th 2024 using an API via fetching the channels ID, using node.js code.

Data cleaning:

Deleted columns: ""channelId"", ""publishedAt"", ""position"", ""duration"", ""dimension"", ""definition"", ""defaultLanguage"", ""thumbnail_maxres"", ""licensedContent"", ""locationDescription"", ""latitude"", ""longitude"", ""dislikeCount"", ""favoriteCount""

Split column publishedAtSQL into Date (release_date) and Time (release_time).

Changed durationSec - duration of video in seconds - to duration - duration of video mm:ss.

Added columns yogaSubject - Style of yoga in video - and YogaChallenge - if this video is part of a yoga challenge (series).",.csv
Youtube toxic comments,1,youtube-toxicity-data,youtoxic_english_1000.csv,Attribution 4.0 International (CC BY 4.0),"This is a hand-labelled toxicity data set containing 1000 comments crawled from YouTube videos about the Ferguson unrest in 2014. In addition to toxicity, this data set contains labels for multiple subclassifications of toxicity which form a hierarchical structure. Each comment can have multiple of these labels assigned. The structure can be seen in the following enumeration:

*IsToxic
       - IsAbusive
            IsThreat
            IsProvocative
            IsObscene
       - IsHatespeech
            IsRacist
            IsNationalist
            IsSexist
            IsHomophobic
            IsReligiousHate
        - IsRadicalism",.csv
ZARA Sales,1,data-penjualan-zara,zara.csv,MIT,"This Zara sales dataset contains information about product sales from Zara stores over a specific period of time. The dataset includes various attributes relevant to sales, such as product ID, product name, product category, price, sales volume, sales date, and store location. This data can be used to analyze product sales trends, sales performance across different product categories, the effectiveness of promotions, customer purchasing patterns, and other factors that influence Zara's sales performance. Analyzing this dataset can provide valuable insights for Zara management in optimizing marketing strategies, inventory management, and other decision-making processes to enhance revenue and profitability.",.csv
Zika Virus Epidemic,1,zika-virus-epidemic,cdc_zika.csv,CC0-1.0,"An outbreak of the Zika virus, an infection transmitted mostly by the *Aedes* species mosquito (*Ae. aegypti* and *Ae. albopictus*), has been sweeping across the Americas and the Pacific since mid-2015. Although first isolated in 1947 in Uganda, a lack of previous research has challenged the scientific community to quickly understand its devastating effects as the epidemic [continues to spread][1].

**All Countries & Territories with Active Zika Virus Transmission**
<img src=""http://www.cdc.gov/zika/images/zikamain_071416_880.jpg"" width=""600"">

#The data
This dataset shares publicly available data related to the ongoing Zika epidemic. It is being provided as a resource to the scientific community engaged in the public health response. The data provided here is not official and should be considered provisional and non-exhaustive. The data in reports may change over time, reflecting delays in reporting or changes in classifications. And while accurate representation of the reported data is the objective in the machine readable files shared here, that accuracy is not guaranteed. Before using any of these data, it is advisable to review the original reports and sources, which are provided whenever possible along with further information on the [CDC Zika epidemic GitHub repo][3].

The dataset includes the following fields:

* **report_date** - The report date is the date that the report was published. The date should be specified in standard ISO format (YYYY-MM-DD).

* **location** - A location is specified for each observation following the specific names specified in the country place name database. This may be any place with a 'location_type' as listed below, e.g. city, state, country, etc. It should be specified at up to three hierarchical levels in the following format: [country]-[state/province]-[county/municipality/city], always beginning with the country name. If the data is for a particular city, e.g. Salvador, it should be specified: Brazil-Bahia-Salvador.

* **location_type** - A location code is included indicating: city, district, municipality, county, state, province, or country. If there is need for an additional 'location_type', open an Issue to create a new 'location_type'.

* **data_field** - The data field is a short description of what data is represented in the row and is related to a specific definition defined by the report from which it comes.

* **data_field_code** - This code is defined in the country data guide. It includes a two letter country code (ISO-3166 alpha-2, [list][4]), followed by a 4-digit number corresponding to a specific report type and data type.

* **time_period** - Optional. If the data pertains to a specific period of time, for example an epidemiological week, that number should be indicated here and the type of time period in the 'time_period_type', otherwise it should be NA.

* **time_period_type** - Required only if 'time_period' is specified. Types will also be specified in the country data guide. Otherwise should be NA.

* **value** - The observation indicated for the specific 'report_date', 'location', 'data_field' and when appropriate, 'time_period'.

* **unit** - The unit of measurement for the 'data_field'. This should conform to the 'data_field' unit options as described in the country-specific data guide.

If you find the data useful, please support data sharing by referencing this dataset and the original data source. If you're interested in contributing to the Zika project from GitHub, you can [read more here][5]. The source for the Zika virus structure is available [here][6].


  [1]: http://www.cdc.gov/zika/geo/active-countries.html ""continues to spread""
  [2]: http://www.cdc.gov/zika/images/zikamain_071416_880.jpg
  [3]: https://github.com/cdcepi/zika ""CDC Zika epidemic GitHub repo""
  [4]: http://www.iso.org/iso/home/standards/country_codes/country_names_and_code_elements_txt-temp.htm ""list""
  [5]: https://github.com/cdcepi/zika/blob/master/how_to_contribute.md ""read more here""
  [6]: http://www.rcsb.org/pdb/explore/explore.do?structureId=5IRE ""here""",.csv
Zomato Delivery Operations Analytics Dataset,1,zomato-delivery-operations-analytics-dataset,Zomato Dataset.csv,other,"**Description:** Delve into the world of food delivery with the Zomato Delivery Dataset. This dataset provides a comprehensive view of delivery operations, including delivery person details, order timestamps, weather conditions, and more. Explore patterns, optimize delivery routes, and enhance customer satisfaction with insights from this dataset.
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F15666745%2Faf8ed6235f39120f91fe6272e86f5991%2Fblog-cover.png?generation=1713952223078962&alt=media)

**Features:**
- **ID:** Unique identifier for each delivery.
- **Delivery_person_ID:** Unique identifier for each delivery person.
- **Delivery_person_Age:** Age of the delivery person.
- **Delivery_person_Ratings:** Ratings assigned to the delivery person.
- **Restaurant_latitude:** Latitude of the restaurant.
- **Restaurant_longitude:** Longitude of the restaurant.
- **Delivery_location_latitude:** Latitude of the delivery location.
- **Delivery_location_longitude:** Longitude of the delivery location.
- **Order_Date:** Date of the order.
- **Time_Ordered:** Time the order was placed.
- **Time_Order_picked:** Time the order was picked up for delivery.
- **Weather_conditions:** Weather conditions at the time of delivery.
- **Road_traffic_density:** Density of road traffic during delivery.
- **Vehicle_condition:** Condition of the delivery vehicle.
- **Type_of_order:** Type of order (e.g., dine-in, takeaway, delivery).
- **Type_of_vehicle:** Type of vehicle used for delivery.
- **Multiple_deliveries:** Indicator of whether multiple deliveries were made in the same trip.
- **Festival:** Indicator of whether the delivery coincided with a festival.
- **City:** City where the delivery took place.
- **Time_taken (min):** Time taken for delivery in minutes.


**How the data can be used:**
- Delivery Performance Analysis: Analyze delivery person ratings, delivery times, and vehicle conditions to evaluate performance and identify areas for improvement.
- Route Optimization: Utilize location data and traffic density information to optimize delivery routes and minimize delivery times.
- Customer Experience Enhancement: Explore correlations between weather conditions, festival seasons, and delivery times to enhance customer satisfaction and service quality.
- Operational Insights: Gain insights into order volumes, types of orders, and multiple deliveries to streamline operations and improve efficiency.
- Predictive Analytics: Build predictive models to forecast delivery times based on various factors such as weather conditions, traffic density, and order volumes, enabling proactive management of delivery operations.

",.csv
Zomato Restaurants Dataset,1,zomato-restaurants-dataset,zomato.csv,CC0-1.0,"The Zomato Restaurant Dataset is a comprehensive collection of restaurant data sourced from the popular online food delivery platform, Zomato. 

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F13571604%2F8baa8a38ce326f7bf82d8a028165a31f%2FScreenshot%202023-07-20%20064231.png?generation=1689859178257287&alt=media)

This dataset contains information about various restaurants listed on the platform, including their location, cuisine type, ratings, user reviews, and other essential attributes.
 The data is designed to help researchers, data enthusiasts, and analysts gain insights into the restaurant industry, customer preferences, and regional culinary trends.",.csv
Zombies Apocalypse,1,zombies-apocalypse,zombies.csv,GPL-2.0,"### Context

News reports suggest that the impossible has become possible…zombies have appeared on the streets of the US! What should we do? The Centers for Disease Control and Prevention (CDC) zombie preparedness website recommends storing water, food, medication, tools, sanitation items, clothing, essential documents, and first aid supplies. Thankfully, we are CDC analysts and are prepared, but it may be too late for others!


### Content

Our team decides to identify supplies that protect people and coordinate supply distribution. A few brave data collectors volunteer to check on 200 randomly selected adults who were alive before the zombies. We have recent data for the 200 on age and sex, how many are in their household, and their rural, suburban, or urban location. Our heroic volunteers visit each home and record zombie status and preparedness. Now it's our job to figure out which supplies are associated with safety!


### Acknowledgements

DataCamp

",.csv
[AAPL Stock Dataset 📈 ] | Stock Market Data 📊,1,apple-dataset,AAPL.csv,Apache 2.0,"*Introduction:**

The AAPL Stock Dataset offers a comprehensive view of historical stock market data for Apple Inc. (AAPL) from January 1, 2010, to April 15, 2024. This dataset provides a rich resource for analyzing price trends, volume patterns, and various technical indicators, aiding in the understanding of Apple's stock performance over the years.

**Dataset Overview:**

- **Date Range:** January 1, 2010, to April 15, 2024
- **Ticker Symbol:** AAPL (Apple Inc.)
- **Data Granularity:** Daily
- **Data Features:** Open, High, Low, Close prices, Volume, Adjusted Close, and various technical indicators.
",.csv
ability of governments,1,ability-of-governments,share-of-gdp-unu-wider new.csv,CC0-1.0,"this graph was created in PowerBI,Loocker Studio and Tableau &lt;&gt;

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F66d135656595a97784d403fd549a02e2%2Fgraph2.jpg?generation=1715544519559742&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F3d8ba82149b26bea8c7bf8f1949fe4e2%2Fgraph3.jpg?generation=1715544525554547&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F9b130f646510a14859e337e5a84da6b0%2Fgraph1.png?generation=1715544531263277&alt=media)

State capacity is the ability of governments to effectively implement their policies and achieve their goals.

The goals of governments vary a lot, and some governments are much more ambitious than others. However, they typically include protecting their citizens against internal and external threats and encouraging economic activity.

The policies they pursue to achieve these goals range from keeping other governments from interfering in their actions, disarming other violent actors within their territory, upholding the rule of law, and providing infrastructure and other public goods.

To do that, states must sustainably raise sufficient resources, usually by collecting taxes; hire skilled and impartial security forces and public servants; and gather accurate information about their populations, among other things.

Understanding state capacity is crucial because it shapes a country's ability to address its many challenges. On this page, you can find related data and visualizations on how state capacity differs around the globe and how this has been changing over time.

Countries differ a lot in how much taxes they collect
Governments must sustainably raise sufficient resources to pay for their employees and policies, such as providing infrastructure and public services. They usually do so by collecting taxes.

The map, drawing on data from the UN, shows that countries differ greatly in how much taxes they collect. Here, this is expressed as government tax revenues as a share of gross domestic product (GDP).

In many European countries, tax revenues sum up to over a third of GDP. In France and Denmark, it is about half.

In most other countries in the world, it is much less. In a few, taxes make up only a few percent of GDP.

Importantly, differences in tax revenues only partially reflect different abilities to collect them. Some of these differences are also due to policy choices and political preferences for higher or lower taxation.

But because other types of revenues, such as natural resources and foreign aid, can be volatile, collecting taxes remains at the heart of countries’ ability to finance their actions.",.csv
all_bikez_curated_data_cleaning,1,all-bikez-curated-data-cleaning,all_bikez_curated (1).csv,Apache 2.0,"1.	Brand - brand name of the motorcycle
2.	Model - model name of the motorcycle
3.	Year - year the motorcycle was built
4.	Category - sub-class the motorcycle belongs to in the market (style of motorcycle)
5.	Displacement (ccm) - engine size of the motorcycle in cubic centimeters (ccm)
6.	Power (hp) - max power output in horsepower (hp) and kilowatt (kW) along with peak power rpm
7.	Engine cylinder - number of cylinders in the engine as well as configuration
8.	Engine stroke - number of stages to complete one power stroke of the engine
9.	Gearbox - number of gears in transmission
10.	Transmission type - type of transmission of the motorcycle
11.	Dry weight (kg) - weight of the motorcycle, without any fluids, in kilograms (kg) and pounds (lbs)
12.	Wheelbase (mm) - distance between the points where the front and rear wheels touch the ground in millimeters (mm)
13.	Fuel capacity (lts) - maximum capacity of fuel tank in liters (lts)
14.	Fuel system - fuel delivery system into engine
15.	Fuel control - valve configuration fo the engine
16.	Seat height (mm) - height from bottom of seat to the ground in millimeters (mm)
17.	Cooling system - engine cooling system
dtypes: float64(9), int64(1), object(18)

",.csv
amazon reviews for sentiment analysis,1,amazon,amazon_reviews.csv,CC-BY-NC-SA-4.0,"One of the most important problems in e-commerce is the correct calculation of the points given to after-sales products. The solution to this problem is to provide greater customer satisfaction for the e-commerce site, product prominence for sellers, and a seamless shopping experience for buyers. Another problem is the correct ordering of the comments given to the products. The prominence of misleading comments will cause both financial losses and customer losses. In solving these 2 basic problems, e-commerce site and sellers will increase their sales, while customers will complete their purchasing journey without any problems. 

This dataset consists of ranking product ratings and reviews on Amazon. Please review this notebook to observe how I came up with this [dataset](https://www.kaggle.com/code/tarkkaanko/rating-product-sorting-reviews-in-amazon) This dataset containing Amazon Product Data includes product categories and various metadata. 

----

### What is expected of you?

The product with the most comments in the electronics category has user ratings and comments. In this way, we expect you to perform sentiment analysis with your specific methods.",.csv
apple_twitter_sentiment_texts,1,appletwittersentimenttexts,apple-twitter-sentiment-texts.csv,other,"### Context

There's a story behind every dataset and here's your opportunity to share yours.


### Content

What's inside is more than just rows and columns. Make it easy for others to get started by describing how you acquired the data and what time period it represents, too.


### Acknowledgements

dataset is from crowdflower, but filtered a lot.
https://data.world/crowdflower/apple-twitter-sentiment",.csv
aqalds,1,aqalds,AQA-large-data-set.csv,other,"### Content

Data for 3827 cars including make, engine size, mass, year registered and emissions. The data features five different makes of car from two years (2002 and 2016).

This is the large data set for the AQA A level Mathematics specification: [https://www.aqa.org.uk/subjects/mathematics/as-and-a-level/mathematics-7357/assessment-resources?f.Resource+type%7C6=Assessment+materials](https://www.aqa.org.uk/subjects/mathematics/as-and-a-level/mathematics-7357/assessment-resources?f.Resource+type%7C6=Assessment+materials)

Guidance on current European emissions standards applicable to vehicles in the UK can be found at the link below:
[[http://www.dft.gov.uk/vca/fcb/exhaust-emissions-testing.asp](http://www.dft.gov.uk/vca/fcb/exhaust-emissions-testing.asp)]()

### Acknowledgements

An extract from the UK Department for Transport Stock Vehicle Database,  2017. Contains public sector information licensed under the Open Government Licence v3.0",.csv
barcelona_car_accident_2023,1,barcelona-car-accident-2023,2023_accidents_causa_conductor_gu_bcn_.csv,Apache 2.0,"Accidentes según causa conductor gestionados por la Guàrdia Urbana a la ciutat de Barcelona
Accidents by driver cause managed by the Guàrdia Urbana in the city of Barcelona

https://opendata-ajuntament.barcelona.cat/data/es/dataset/accidents_causa_conductor_gu_bcn/resource/5a040155-38b3-4b19-a4b0-c84a0618d363

",.csv
best-selling-books,1,best-selling-books,best-selling-books.csv,CC0-1.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F14601120%2Fb31574d613385af49d25c679431b3313%2Fclose-up-opened-book-library.jpg?generation=1687198503124618&alt=media)

This dataset contains lists of best-selling books and book series in any language. The term ""best-selling"" refers to the expected number of copies sold for each book, not the number of books printed or currently owned. This list excludes comic books and textbooks. The books are arranged in the order of the greatest sales estimate reported by credible, independent sources.",.csv
best-selling-manga,1,best-selling-manga,best-selling-manga.csv,CC-BY-SA-3.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F14601120%2F027aeee1e5c80a8164f545909f042098%2FManga-Wallpaper-Desktop.jpg?generation=1689440417013482&alt=media)
The following is a list of the **best-selling Japanese manga series** in terms of collected tankbon volumes sold to date. All of the series on this list have at least 20 million copies in print. This list only includes Japanese manga and excludes manhwa, manhua, and original English-language manga. Unless otherwise stated, the series are listed according to the largest circulation (copies in print) estimate of their collected tankbon volumes as recorded in credible sources. The series with the same total number of circulation or sales are organised alphabetically.",.csv
bookstore dataset,1,bookstore-dataset,books_scraped.csv,CC0-1.0,"This data set was scrapped using python from http://books.toscrape.com/ which is a fictional book store. It contains 1000 books, with different categories, star ratings and prices. This data set can be used by anyone who wants to practice data cleaning and simple data manipulations.

The code I used to scrap this data can be found on my github: https://github.com/Sbonelondhlazi/dummybooks",.csv
call of duty players skills,1,call-of-duty-players,cod.csv,CC0-1.0,"


###  Description
- This dataset contains more than 1K playes b behaviors  from Call of Duty: Modern Warfare multiplayer leader board  
- I gather this using rapid API made By [elreco ](https://rapidapi.com/elreco/api/call-of-duty-modern-warfare/details) , this is a great API with regular updates, very stable, and with high performance.

### Data fields

- name: this is the name for each player 
- wins : number of times the player win a match 
- kills : number of kills the player made in all his matches 
- kdRatio : kill/deaths ratio that means, if a player has 10 kills and 5 deaths, his KD ratio is equal to 2. A KD ratio of 1 means that the player got killed exactly as many times as he successfully eliminated his opponents
- killstreak : kill a number of enemy players without dying. 
- level : is the player grade
- losses : total number of losing 
- prestige: it is an optional Mode that players can choose after they progress to Level 55 and max 
- hits : number of times the player damaged another player
- timePlayed : the time spent by every player playing Call of Duty in hours 
- headshots : number of times the player hit the others with headshots
- averageTime : avrage time 
- gamesPlayed : number of times the player play multiplyer match 
- assists :  number of times player damaging an enemy but a teammate gets the kill.
- misses : the number of times the player miss the hit
- xp : Experience Points (XP) are a numerical quantity exclusive to multiplayer that dictates a player's level and progress in the game.
- scorePerMinute :a measure of how many points players are gaining per unit time.
- shots : number of shots the player did
- deaths : number of time the player gots killed in the game.

",.csv
causes of death registered,1,causes-of-death-registered,share-of-deaths-registered new.csv,CC0-1.0,"this graph was created in OurDataWorld and Loocker studio :

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fbf2bbf685462f8f8b0185d0b87ab326e%2Fgraph1.png?generation=1713467123050308&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F700ca118d36682706c87c751b04ba9a7%2Fgraph2.png?generation=1713467129348537&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F74db1a910019bec324d85d28aea2808b%2Fgraph3.png?generation=1713467136055169&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F891d5c155bc8aa2617860efde53d0cde%2Fgraph4.jpg?generation=1713467143114462&alt=media)

In many countries, when people die, the cause of their death.

To guide decisions in public health – whether that’s by governments, organizations, or individuals – it’s vital to know what people are dying from.

This helps us understand which conditions are going untreated, or how much investment is needed to address diseases; to see how much progress we’re making, and whether new challenges are emerging.

The ideal way to find out is by aggregating knowledge of the causes of death from medical professionals who know about each patient, their medical conditions and risk factors, and the circumstances in which they died.

But officially registering a death, and attributing a cause to it, can be difficult and complex. The process is affected by legal and cultural norms, access to healthcare, and advances in medical knowledge. Because of this, in many countries a large share of deaths are not registered at all.

How do medical practitioners identify the cause of death? How is the cause of death officially certified and registered? Why are these procedures lacking in many parts of the world? In this article, I summarise the answers to these questions.

In the additional information section, I also explain how researchers attribute the cause of death in countries where death registration is limited.

How is the cause of a death officially registered?
In many countries, when someone dies the cause of their death is determined by the medical practitioner who cared for them (such as a physician or nurse), or a coroner.

They look at evidence from the circumstances of the death, and use their medical knowledge and guidelines to certify the cause of death on a certificate.

The World Health Organization (WHO) provides international guidelines called the International Classification of Diseases (ICD) to guide practitioners on how the cause of death should be described. Death certificates in most countries are structured to follow these guidelines.",.csv
chicago house price,1,chicago-house-price,realest.csv,CC0-1.0," if you found it useful, Make an upvote 🔼.

 you are given dataset which contains information about houses  prices in the suburbs of chicago 
 your task is first analysis the data ,and then to apply a regression model to it.

## DATA OVERVIEW:
 dataset consists of following variables:

* Price : price of house
* Bedroom: number of bedrooms
* Room: number of rooms
* Space : size of house (in square feet)
* Lot : width of a lot
* Tax : amount of annual tax
* Bathroom : number of bathrooms
* Garage : number of garage
* Condition: condition of house (1 if good , 0 otherwise)",.csv
children did not die,1,children-did-not-die,youth-mortality-rate new.csv,CC0-1.0,"this graph was created in OurDataWorld:

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F6c407b55ce32b1db44bca1d50409eca0%2Fgraph1.png?generation=1714428976838646&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fe795bfc6949e3e047014262652f6e128%2Fgraph2.png?generation=1714428982739267&alt=media)

Declining death rates among children have been one of humanity’s most important achievements. Across the world, countries have dramatically reduced child mortality. I think we should celebrate this extraordinary achievement, using it as encouragement to reduce child mortality further.

But it can seem hard to celebrate something that is not happening. So, I wanted to turn things around. Rather than focusing on the absence of child deaths, I want to highlight the presence of people who are here today thanks to the progress in global health.

To make the millions who were saved by progress in global health visible, I am asking a simple question: how many more children would have died if the global child mortality rate had not declined?

To answer this question, we have to pick a baseline. Let’s start in 1990. If I had gone back further in time, this figure would have been even higher because the rate of child mortality was much higher in the past.

The chart shows the answer. A generation ago, in 1990, the global child mortality rate was 9.3%. The dashed purple line shows the number of children who would have died if the mortality rate had stayed constant. More than 12 million children would have died every year.

The actual number of child deaths declined to 5 million per year. This is shown by the dark red line. This was achieved because the global mortality rate of children declined to 3.7% in 2021.

The difference between the two lines shows us how many more children would have died if the world had made no progress. In total, 132 million more children would have died across these 31 years.1

In short, thanks to progress in global health since 1990, 132 million more people are alive in our world today.
",.csv
college placement,1,college-placement,placement-dataset.csv,Apache 2.0,"
This dataset comprises records of students' attributes and their corresponding placement status. It includes information such as the city of residence or educational institution location, the Cumulative Grade Point Average (CGPA), Intelligence Quotient (IQ) scores, and a binary indicator denoting whether the student secured placement in a job or internship. The dataset exhibits a combination of numerical and categorical data, with instances of missing values present within certain entries.",.csv
companies Information,1,companies-information,companies_dataset.csv,Apache 2.0,"# Employee Reviews and Ratings for Top Indian Companies

**Description:**

###### This dataset provides a comprehensive overview of employee reviews and ratings for top Indian companies. It is a valuable resource for anyone interested in exploring the job satisfaction, work culture, and overall employee experiences within these organizations. The data is sourced from AmbitionBox, a platform where employees and job seekers can review and rate companies. The dataset contains information on multiple companies and includes the following columns:

1.**Rating**: Average company rating (out of 5)

2.**Branches**: Number of company branches

3.**Highly_rated**: Aspects highly rated by employees (comma-separated)

4.**Critically_rated**: Aspects critically rated by employees (comma-separated)

5.**Reviews**: Total number of employee reviews

6.**Salaries**: Total salaries reported

7.**Interviews**: Total interview experiences shared

8.**Jobs**: Total job listings for the company

9.**Benefits**: Total reported employee benefits

10.**Logo_URL**: URL to the company's logo

**Use Case:**
       This dataset can be used for various data analysis and visualization tasks, such as understanding the factors that contribute to employee satisfaction, identifying trends in job listings, and comparing companies based on different criteria. Researchers, job seekers, and HR professionals may find this dataset useful for making informed decisions regarding employment and company culture.",.csv
countries_poluation,1,countries-poluation,air_pollution new.csv,CC0-1.0,"
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F7601ea1bf3ac86b9851f775897579a5f%2Fmap.png?generation=1704140696716076&alt=media)


Air quality is a critical aspect of environmental health that directly impacts the well-being of people worldwide. The quality of the air we breathe is influenced by a myriad of factors, ranging from industrial activities and vehicular emissions to natural phenomena. Examining the global scenario reveals both progress and challenges in the quest for cleaner air.

One of the primary indicators used to assess air quality is the Air Quality Index (AQI), a numerical scale that quantifies the concentration of pollutants in the air. The major pollutants considered in AQI calculations include particulate matter (PM10 and PM2.5), nitrogen dioxide (NO2), sulfur dioxide (SO2), carbon monoxide (CO), and ozone (O3). By evaluating these pollutants, experts can gauge the potential health risks associated with breathing the air in a specific location.

Over the past few decades, there has been a growing awareness of the importance of monitoring and improving air quality globally. Numerous countries have implemented stringent regulations and adopted cleaner technologies to reduce emissions from industries and transportation. The transition to renewable energy sources has also played a crucial role in mitigating air pollution, with a focus on reducing reliance on fossil fuels.

In regions such as North America and Europe, substantial progress has been made in curbing air pollution through the implementation of stringent environmental policies and the development of advanced technologies. Air quality monitoring networks in these regions provide real-time data, allowing authorities to take prompt action when pollution levels exceed acceptable limits.

However, despite these advancements, many parts of the world continue to face severe air quality challenges. In rapidly industrializing regions, such as parts of Asia and Africa, the concentration of pollutants often surpasses safe limits, leading to adverse health effects. Urbanization and population growth contribute to increased vehicular emissions, industrial activities, and energy consumption, all of which exacerbate air pollution.

The impact of climate change further complicates the global air quality scenario. Changes in weather patterns, such as heatwaves and wildfires, can elevate pollutant levels and worsen air quality. The increasing frequency and intensity of extreme weather events pose a significant threat to the efforts aimed at improving air quality worldwide.

The COVID-19 pandemic also provided a unique opportunity to observe the effects of reduced human activities on air quality. Lockdowns and travel restrictions led to a temporary decline in pollution levels in various cities globally, offering insights into the potential benefits of sustainable practices and reduced emissions.

To address the challenges associated with global air quality, international collaboration and information exchange are crucial. Initiatives like the World Air Quality Index project provide a platform for sharing real-time air quality data from around the world, fostering a collective effort to combat air pollution.

In conclusion, the state of global air quality is a multifaceted issue that demands continuous attention and concerted efforts. While some regions have made significant strides in improving air quality through regulatory measures and technological advancements, others face persistent challenges due to rapid industrialization and urbanization. The ongoing impact of climate change and unforeseen events, such as pandemics, further underscore the need for a coordinated, global approach to safeguarding air quality and, consequently, the health of our planet and its inhabitants.",.csv
covid19 global forecasting: locations population,1,covid19-global-forecasting-locations-population,locations_population.csv,Attribution 4.0 International (CC BY 4.0),"## Population counts for the [covid19-global-forecasting challenge](https://www.kaggle.com/c/covid19-global-forecasting-week-3)

Manually googled population of the distinct location sites (unique pairs of 'Province/State' and 'Country/Region' column values) used in train.csv and test.csv of [covid19 global forecasting challenge](https://www.kaggle.com/c/covid19-global-forecasting-week-1).

You can join this dataset with train.csv or test.csv on the columns ('Province/State', 'Country/Region') to supply the initial data with the population data.

*Dataset image photo by Markus Spiske on Unsplash*",.csv
credit_risk_customers,1,credit-risk-customers,credit_customers.csv,other,"This dataset consists of 20 features of the customers.
It could be used to predict if the customer could be given credit.
Many features require data cleaning.
This is a great dataset for practicing data cleaning and feature engineering and building a binary classification model.",.csv
databricks dolly 15k,1,databricksdatabricks-dolly-15k,dolly_15k.csv,other,"**Summary**
databricks-dolly-15k is an open source dataset of instruction-following records generated by thousands of Databricks employees in several of the behavioral categories outlined in the InstructGPT paper, including brainstorming, classification, closed QA, generation, information extraction, open QA, and summarization.

This dataset can be used for any purpose, whether academic or commercial, under the terms of the Creative Commons Attribution-ShareAlike 3.0 Unported License.

**Supported Tasks:**

Training LLMs
Synthetic Data Generation
Data Augmentation
Languages: English Version: 1.0

**Owner: Databricks, Inc.**

**Dataset Overview**
databricks-dolly-15k is a corpus of more than 15,000 records generated by thousands of Databricks employees to enable large language models to exhibit the magical interactivity of ChatGPT. Databricks employees were invited to create prompt / response pairs in each of eight different instruction categories, including the seven outlined in the InstructGPT paper, as well as an open-ended free-form category. The contributors were instructed to avoid using information from any source on the web with the exception of Wikipedia (for particular subsets of instruction categories), and explicitly instructed to avoid using generative AI in formulating instructions or responses. Examples of each behavior were provided to motivate the types of questions and instructions appropriate to each category.

Halfway through the data generation process, contributors were given the option of answering questions posed by other contributors. They were asked to rephrase the original question and only select questions they could be reasonably expected to answer correctly.

For certain categories contributors were asked to provide reference texts copied from Wikipedia. Reference text (indicated by the context field in the actual dataset) may contain bracketed Wikipedia citation numbers (e.g. [42]) which we recommend users remove for downstream applications.

Intended Uses
While immediately valuable for instruction fine tuning large language models, as a corpus of human-generated instruction prompts, this dataset also presents a valuable opportunity for synthetic data generation in the methods outlined in the Self-Instruct paper. For example, contributor--generated prompts could be submitted as few-shot examples to a large open language model to generate a corpus of millions of examples of instructions in each of the respective InstructGPT categories.

Likewise, both the instructions and responses present fertile ground for data augmentation. A paraphrasing model might be used to restate each prompt or short responses, with the resulting text associated to the respective ground-truth sample. Such an approach might provide a form of regularization on the dataset that could allow for more robust instruction-following behavior in models derived from these synthetic datasets.

**Dataset**
Purpose of Collection
As part of our continuing commitment to open source, Databricks developed what is, to the best of our knowledge, the first open source, human-generated instruction corpus specifically designed to enable large language models to exhibit the magical interactivity of ChatGPT. Unlike other datasets that are limited to non-commercial use, this dataset can be used, modified, and extended for any purpose, including academic or commercial applications.

**Sources**
Human-generated data: Databricks employees were invited to create prompt / response pairs in each of eight different instruction categories.
Wikipedia: For instruction categories that require an annotator to consult a reference text (information extraction, closed QA, summarization) contributors selected passages from Wikipedia for particular subsets of instruction categories. No guidance was given to annotators as to how to select the target passages.
Annotator Guidelines
To create a record, employees were given a brief description of the annotation task as well as examples of the types of prompts typical of each annotation task. Guidelines were succinct by design so as to encourage a high task completion rate, possibly at the cost of rigorous compliance to an annotation rubric that concretely and reliably operationalizes the specific task. Caveat emptor.

The annotation guidelines for each of the categories are as follows:

**Creative Writing**: Write a question or instruction that requires a creative, open-ended written response. The instruction should be reasonable to ask of a person with general world knowledge and should not require searching. In this task, your prompt should give very specific instructions to follow. Constraints, instructions, guidelines, or requirements all work, and the more of them the better.

**Closed QA**: Write a question or instruction that requires factually correct response based on a passage of text from Wikipedia. The question can be complex and can involve human-level reasoning capabilities, but should not require special knowledge. To create a question for this task include both the text of the question as well as the reference text in the form.

**Open QA**: Write a question that can be answered using general world knowledge or at most a single search. This task asks for opinions and facts about the world at large and does not provide any reference text for consultation.

**Summarization**: Give a summary of a paragraph from Wikipedia. Please don't ask questions that will require more than 3-5 minutes to answer. To create a question for this task include both the text of the question as well as the reference text in the form.
Information Extraction: These questions involve reading a paragraph from Wikipedia and extracting information from the passage. Everything required to produce an answer (e.g. a list, keywords etc) should be included in the passages. To create a question for this task include both the text of the question as well as the reference text in the form.

**Classification**: These prompts contain lists or examples of entities to be classified, e.g. movie reviews, products, etc. In this task the text or list of entities under consideration is contained in the prompt (e.g. there is no reference text.). You can choose any categories for classification you like, the more diverse the better.
Brainstorming: Think up lots of examples in response to a question asking to brainstorm ideas.
Personal or Sensitive Data
This dataset contains public information (e.g., some information from Wikipedia). To our knowledge, there are no private person’s personal identifiers or sensitive information.

**Language**
American English

Known Limitations
Wikipedia is a crowdsourced corpus and the contents of this dataset may reflect the bias, factual errors and topical focus found in Wikipedia
Some annotators may not be native English speakers
Annotator demographics and subject matter may reflect the makeup of Databricks employees
",.csv
depression,1,depression,b_depressed.csv,GPL-2.0,"### Context

Hi, 

The original Dataset wad published by [Frankcc](https://www.kaggle.com/francispython) in the following link: [Link Kaggle](https://www.kaggle.com/francispython/b-depression)

The dataset is involved into the analysis of depression. The data was consists as a study about the life conditions of people who live in rurales zones. Because all the columns were not explicated in this challenge so We can´t understand them. We proceded to delete them or ignoring. Fhe final features or columns were the following:

### Content


Survey_id
Ville_id
sex
Age
Married
Number_children
education_level
total_members (in the family)
gained_asset
durable_asset
save_asset
living_expenses
other_expenses
incoming_salary
incoming_own_farm
incoming_business
incoming_no_business
incoming_agricultural
farm_expenses
labor_primary
lasting_investment
no_lasting_investmen
depressed: [ Zero: No depressed] or [One: depressed] (Binary for target class)
the main objective is to show statistic analysis and some data mining techniques. 

The dataset has 23 columns or dimensions  and a total of 1432 rows or objects.


### Acknowledgements

The original attribution is to [Frankcc](https://www.kaggle.com/francispython) i

### Inspiration

",.csv
diabetesDataAnslysis,1,diabetesdataanslysis,diabetes.csv,other,"my dataset is about diabetes in people's youngs in worlds, because more youngs this very diabetes more early. EVER clinical is development analyses about blood.
grandparents ever sad with youngs or yours soon with problem in home, because your family need see exam ever.
",.csv
down forests,1,down-forests,region-share-tropical-deforestation new.csv,CC0-1.0,"this graph was created in OurDataWorld and R:

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Ff7a0441e12b2e4f773a860e3554b4fb4%2Fgraph2.png?generation=1713900977795354&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fe6ad2841c65d1347ac55055ac7ef60dd%2Fgraph1.png?generation=1713900983651518&alt=media)

Every year the world loses around 5 million hectares of forest. 95% of this occurs in the tropics. At least three-quarters of this is driven by agriculture – clearing forests to grow crops, raise livestock and produce products such as paper.1

If we want to tackle deforestation we need to understand two key questions: where we’re losing forests, and what activities are driving it. This allows us to target our efforts towards specific industries, products, or countries where they will have the greatest impact.

In a study published in Global Environmental Change, Florence Pendrill and colleagues addressed both of these questions.2 They quantified how much and where deforestation occurs from the expansion of croplands, pasture and tree plantations (for logging), and what products are grown on this converted land. They also combined this with global trade flows to assess how much of this deforestation was driven by international trade – we look at the role of trade specifically in a related article.

Here we’ll look at both where tropical deforestation is happening and what products are driving it.

Brazil and Indonesia account for almost half of tropical deforestation
The study by Pendrill et al. (2019) found that, between 2005 and 2013, the tropics lost an average of 5.5 million hectares of forest per year to agricultural land. That was a decade ago, but the world is still losing a similar amount today: using satellite data, researchers at Global Forest Watch estimate that global deforestation in 2019 was around 5.4 million hectares.3 95% of this was in the tropics. But where in the tropics did we lose this forest?

In the chart we see the share of tropical deforestation by country and region. It's measured as the annual average between 2010 and 2014.

One-third of tropical deforestation happened in Brazil. That was 1.7 million hectares each year. The other single country where large forest areas are lost is Indonesia – it accounted for 14%. This means around half (47%) of tropical deforestation took place in Brazil and Indonesia. Again, if we look at more recent satellite data we find that this is still true today: in 2019, the world lost 5.4 million hectares to deforestation, with Brazil and Indonesia accounting for 52% of it.4 As we will see later, the expansion of pasture for beef production, croplands for soy and palm oil, and increasingly conversion of primary forest to tree plantations for paper and pulp have been the key drivers of this.

The expansion of pasture lands have also had a major impact on land use in the rest of the Americas – outside of Brazil, Latin America accounted for around one-fifth of deforestation.

The expansion of agricultural land in Africa accounted for around 17.5% of deforestation. This may slightly underestimate the loss of forests in Africa, for two reasons. Much of Africa’s deforestation has been driven by subsistence agricultural activities, which are not always fully captured in national statistics. Secondly, depending on the permanence of agricultural activities such as slash-and-burn farming, some of this forest loss might be classified as temporary forest degradation rather than permanent deforestation.",.csv
e-shop clothing 2008,1,e-shop-clothing-2008,e-shop clothing 2008 - e-shop clothing 2008.csv,MIT,"The online shopping dataset consists of data from an e-commerce platform that sells clothes for pregnant women. The data has been collected over five months, from april to August 2008&nbsp; and&nbsp; consists&nbsp; of&nbsp; 165474&nbsp; entries&nbsp; (rows)&nbsp; and&nbsp; 14&nbsp; columns, with&nbsp; each&nbsp; column representing a feature. 

The features are:

- **Year:** It represents the year in which the data is collected, which is 2008
- **Month:** the features indicates the month when data was recorded from April (4) to August (9)
- **Day:** It shows the specific day in the month, ranging from 1 to 31
- **Order:** Sequence of clicks during one session
- **Country:** The country from which the website was accessed were Australia, Austria and 45 other places
- **Session ID:** Indicates the user sessions
- **Page 1 (Main Category):** The feature represents the category of products like trousers , skirts, blouses and other products that are on sale represented by 1, 2, 3, and 4.
- **Page 2 (Clothing Model):** The variable represents the code for each product. The dataset has a total of 217 products
- **Color:** the explanatory variable states the colour of the product. The products are available in a total of 14 colours for the clothing items
- **Location:** The variable indicates the location of the product in the webpage. The screen is divided in 6 parts, such that 3 products are displayed in the top left, right, and middle, and 3 products are displayed in the bottom left, right and middle
- **Model Photography:** The feature states how the product was photographed. Products are photographed in two fashions, namely face-to-face, which means that the picture was taken full-on where the products directly faces the camera. The other type is profile, where the picture was taken from the side, indicating the outline of the product
- **Price:** Indicates the price of the specific product in US Dollars.
- **Price 2:** The variable states if the price of the product is greater than the average price of the category to which it belongs.
- **Page:** Specifies the page number of the store website, which ranges from 1 to 5",.csv
early_stage_diabetes_risk_prediction,1,early-stage-diabetes-risk-prediction,diabetes_risk_prediction_dataset.csv,Attribution 4.0 International (CC BY 4.0),"**Dataset Description: Early Stage Diabetes Risk Prediction**

This dataset comprises crucial sign and symptom data of individuals who either exhibit early signs of diabetes or are at risk of developing diabetes. The variables included in the dataset provide valuable insights into potential indicators of diabetes onset. The dataset encompasses diverse information, ranging from demographic details to specific symptoms associated with diabetes.

**Attributes Description:**

- Age (1-20 to 65): Age range of the individuals.
- Sex (1. Male, 2. Female): Gender information.
- Polyuria (1. Yes, 2. No): Presence of excessive urination.
- Polydipsia (1. Yes, 2. No): Excessive thirst.
- Sudden Weight Loss (1. Yes, 2. No): Abrupt weight loss.
- Weakness (1. Yes, 2. No): Generalized weakness.
- Polyphagia (1. Yes, 2. No): Excessive hunger.
- Genital Thrush (1. Yes, 2. No): Presence of genital thrush.
- Visual Blurring (1. Yes, 2. No): Blurring of vision.
- Itching (1. Yes, 2. No): Presence of itching.
- Irritability (1. Yes, 2. No): Display of irritability.
- Delayed Healing (1. Yes, 2. No): Delayed wound healing.
- Partial Paresis (1. Yes, 2. No): Partial loss of voluntary movement.
- Muscle Stiffness (1. Yes, 2. No): Presence of muscle stiffness.
- Alopecia (1. Yes, 2. No): Hair loss.
- Obesity (1. Yes, 2. No): Presence of obesity.
- Class (1. Positive, 2. Negative): Diabetes classification.

This dataset serves as a valuable resource for the development and validation of predictive models for early-stage diabetes risk assessment. Researchers and healthcare professionals can leverage this dataset to gain insights into the relationships between various symptoms and the likelihood of developing diabetes, ultimately contributing to the advancement of early intervention strategies.",.csv
echocardiogram-UCI,1,echocardiogram-uci,echocardiogram.csv,CC0-1.0,"## Context ##
All the patients suffered heart attacks at some point in the past. Some are still alive and some are not. The survival and still-alive variables, when taken together, indicate whether a patient survived for at least one year following the heart attack. 

## Content ##
This dataset consists of 132 instances of patients for 12 variables describing the patient's heart attack and condition.

## Acknowledgements ##
Dataset Link: https://archive.ics.uci.edu/ml/datasets/echocardiogram   
Banner Photo by [rawpixel.com on Unsplash][1]

## Insight ##
The problem addressed by past researchers was to predict from the other variables whether or not the patient will survive at least one year. The most difficult part of this problem is correctly predicting that the patient will NOT survive. (Part of the difficulty seems to be the size of the data set.)


  [1]: https://unsplash.com/photos/XNRHhomhRU4",.csv
fabiendaniels-mapping-locations-and-county-codes,1,fabiendaniels-mapping-locations-and-county-codes,county_lon_lats.csv,Apache 2.0,"#&nbsp;Generated from code heavily inspired by
#&nbsp;https://www.kaggle.com/code/fabiendaniel/mapping-locations-and-county-codes
import pandas as pd
from pathlib import Path
import json
from geopy.geocoders import Nominatim

pd.set_option('display.max_columns', 500)
files = list(Path(""../input/predict-energy-behavior-of-prosumers/"").glob(""*.csv""))
for file in files:
    print(f""creates: '{file.stem}'"")
    globals()[file.stem] = pd.read_csv(file)
f = open('../input/predict-energy-behavior-of-prosumers/county_id_to_name_map.json')
name_mapping = {
    ""valga"": ""valg"",
    ""põlva"": ""põlv"",
    ""jõgeva"": ""jõgev"",
    ""rapla"": ""rapl"",
    ""järva"": ""järv""
}

county_codes = json.load(f)
county_codes
parsed_counties = {v.lower().rstrip(""maa"") : k for k, v in county_codes.items()}
parsed_counties_clean = {name_mapping.get(k,k): v for k,v in parsed_counties.items()}
county_data = {v: [] for _,v in parsed_counties_clean.items()}


for i, coords in  forecast_weather[[""latitude"", ""longitude""]].drop_duplicates().iterrows():
    
    lat, lon = coords[""latitude""], coords[""longitude""]
    
    geoLoc = Nominatim(user_agent=""GetLoc"")
     
    # passing the coordinates
    locname = geoLoc.reverse(f""{lat}, {lon}"")   # lat, lon
    if locname is None: continue

    location = locname.raw[""address""]
    if location[""country""] == ""Eesti"":
        county = location['county'].split()[0].lower()
        county = name_mapping.get(county, county)
        print(f""county: '{county}', county code:"", parsed_counties_clean[county], (lat, lon))
        county_data[parsed_counties_clean[county]].append((lat, lon))
df_data = {""county"": [], ""longitude"": [], ""latitude"": []}
for k, v in county_data.items():
    df_data[""county""] += [k]*len(v)
    df_data[""latitude""] += [x[0] for x in v]
    df_data[""longitude""] += [x[1] for x in v]
pd.DataFrame(df_data).to_csv(""/kaggle/working/county_lon_lats.csv"")",.csv
fifa_data,1,fifa-data,fifa_data.csv,Apache 2.0,"this dataset about football players descripting there names ,Nationalities ,clubs and so on
This dataset provides a comprehensive collection of FIFA (Fédération Internationale de Football Association) data, covering various aspects of the world of soccer. Whether you're interested in player statistics, players performance, this dataset offers a rich source of information for research, analysis, and machine learning applications.",.csv
flipkart-dataset-laptops,1,flipkart-dataset-laptops,flipkart-laptops.csv,Apache 2.0,"This is a dataset , created my me , based on the flipkarts laptops availability using web scraping techniques",.csv
health test by blood dataset,1,diabetes-classification-dataset,Diabetes Classification.csv,CC0-1.0,"This dataset contains clinical data from a number of patients that have been analyzed to examine cardiovascular health and kidney function. This data is important for evaluating the risk of heart disease and diabetes, as well as the impaired kidney function often associated with these conditions.

This dataset was created to support research and development of risk prediction models for heart disease, diabetes and impaired kidney function. With relevant features and clear diagnosis labels, this dataset can be used to build and test accurate prediction models.",.csv
iGaming Analysis Report(TABLEAU),1,igaming-analysis-report,IGaming-Analyst-Data-Exercise.csv,CC0-1.0,"The customers are taken from  36 different markets/countries with a total number of active players is 14,434 players playing and patronizing all 3 products (Sport Book, Casino and Live Casino) between the Month of January to April 2024 concurrently. February was taken as to be the start until April for this analysis.
The Analysis could d be plotted in Months or in markets/countries as preferred respectively.
According to Top Active SportBook by Country, Finland had the highest percentage of active SportBook players (43%), followed by Norway (22%). According to Top Active LiveCasino by Country, Sweden had the highest percentage of active LiveCasino gamers (31%), followed by Finland (29%). According Top Active Casino by country, Finland had the highest percentage of active casino gamers (34%), followed by Sweden (32%).
The month of April recorded the highest active players obtained globally over all 3 products across the market leading at 37%; followed by March at 32%. The month of February recorded the highest number of winnings globally over all 3 products across the market leading at 40%; followed by April at 31%.
The month of April recorded the highest number of customers globally who did not followup with our product patronage on all 3 products across the market leading at 3,261; followed by February at 3,044. 
The month of April recorded the highest deposit made globally over all 3 products across the market leading at 35%; followed by March at 32% respectively.
The top 5 active players by countries according to performance ranking  include Finland, Sweden, Brazil, Norway and Canada; with Finland leading the chart with 3,985 Active players followed by Sweden with 2,953 active players.
Winnings to Turn Over/Deposit Ratio by Country record shows Peru, Malta and Sweden at the top with 6%; followed by Ireland, Brazil, Norwary, Canada, Finland, New Zealand at the same percentage range concurrently. 
Brazil lead with 77% of customers that went away following inactive signups; followed by Chile at 9%. The top 3 countries paying winnings according to performance ranking  include Sweden with 56%, Finland with 23%, Norway with 15%.


**Here is a summary of the metrics:**
year: The year of the data record or transaction
month: The month of the data record or transaction month.
site_id: An identifier for the site or country.
market: The market associated with the site. This refers to the country ISO codes, country ID
Countries: The country associated with the site. Where the transaction was carried out
registrations: Number of registrations/signups/newly registered customer.
ftds: FTDS (First-Time Depositors). First time depositing customers. The count of new users/signups that deposited. 
Churned Customer: The number of customers that went away: Number of inactive signups. 
Ftds Conversion: This shows the success ratio of converting a signup customer to a depositing customer.
Churned rate (%): The rate of inactive customers.
active_players: Number of active players (unique.). It consist of old(ftds) and new(ftds) players. Old and new active players. 
deposit_count: Count of deposits. The total number of deposits(not unique). The number of times deposit was made.
unique_depositors: Count of unique depositors. The unique numbers of customers depositing.
sports_active_players: Number of unique active sportsbook players.
casino_active_players: Number of unique active casino players.
live_casino_active_players: Number of unique active live casino players.
turnover_eur: The total turnover in euros.
winnings_eur: The total winnings in euros.
ggr_eur: Gross Gaming Revenue in euros.
withdrawal_adjustments_eur: Withdrawal adjustments in euros.
deposit_adjustments_eur: Deposit adjustments in euros.
bonus_withdrawn_eur: Amount of bonuses withdrawn in euros.
bonus_issued_eur: Amount of bonuses issued in euros.
cashback_eur: Cashback amount in euros.
goodwill_amount_eur: Goodwill amount in euros.
ngr_eur: Net Gaming Revenue in euros.
deposits_eur: Total deposits in euros.
ftd_amount_eur: First-Time Depositors' total amount in euros.(new customers)
reload_amount_eur: Reload deposit amount in euros.(old customers)
withdrawals_eur: Total withdrawals in euros.
net_deposits_eur: Net deposits in euros.
sports_turnover_eur: Sports turnover in euros.
sports_winnings_eur: Sports winnings in euros.
sports_ggr_eur: Sports Gross Gaming Revenue in euros.
sports_bonus_issued_eur: Sports bonuses issued in euros.
sports_bonus_withdrawn_eur: Sports bonuses withdrawn in euros.
sports_ngr_eur: Sports Net Gaming Revenue in euros.
casino_turnover_eur: Casino turnover in euros.
casino_winnings_eur: Casino winnings in euros.
casino_ggr_eur: Casino Gross Gaming Revenue in euros.
casino_bonus_issued_eur: Casino bonuses issued in euros.
casino_bonus_withdrawn_eur: Casino bonuses withdrawn in euros.
casino_ngr_eur: Casino Net Gaming Revenue in euros.
live_casino_turnover_eur: Live casino turnover in euros.
live_casino_winnings_eur: Live casino winnings in euros.
live_casino_ggr_eur: Live casino Gross Gaming Revenue in euros.
live_casino_ngr_eur: Live casino Net Gaming Revenue in euros.
vip_bonus_eur: VIP bonus amount in euros. This is the bonus amount paid to VIP customers. It is a subset of total_bonus_eur.
total_bonus_eur: Total bonus amount in euros.
BDR: Bonus to Total deposit ratio. This shows the % of bonus amount paid out from total deposits.
ABPU: Average Bonus per User. Cost of bonus paid to a single user.
VIPBR: VIP Bonus Ratio. What % of bonus is paid to VIP customers
ATPU_SB: Average SB Turnover per SB User. 
ATPU_Cas: Average Casino Turnover per User. 
ATPU_Live_Cas: Average Live Casino Turnover per User. 
AFTDPU: Average First Time Deposit per User. Aka DPA (Deposit per Acquisition). This is the cost of deposit for a single new customer.
ADPU: Average Deposit per User. Aka DPU (Deposit per User). This is the cost of deposit for a customer(new and old).
ARPU_NG: Average Net Gaming Revenue per User. Net revenue made from a single user.
ARPU_GG: Average Gross Gaming Revenue per User .Gross gaming revenue made from a single user
ReloadDep _Ratio: Reloaded Deposit Ratio. This shows the deposit % share btw old and ftds.
NetDep Ratio: Net deposit Ratio.
FtdDep Ratio: First Time Deposit Amount  Ratio.
WTD_Ratio: Withdrawal to Deposit Ratio (Total Withdrawal to Total Deposit). It shows the % of withdrawal from deposit.
",.csv
injection-molding-QA,1,injection-molding-qa,dataset.csv,Apache 2.0,"# injection-molding-QA

## Description
This dataset contains questions and answers related to injection molding, focusing on topics such as 'Materials', 'Techniques', 'Machinery', 'Troubleshooting', 'Safety','Design','Maintenance','Manufacturing','Development','R&D'. The dataset is provided in CSV format with two columns: Questions and Answers.


## Usage
Researchers, practitioners, and enthusiasts in the field of injection molding can utilize this dataset for tasks such as:

- Natural Language Processing (NLP) tasks such as question answering, text generation, and summarization.
- Training and evaluation of machine learning models for understanding and generating responses related to injection molding.

## Example pandas
```python
import pandas as pd

# Load the dataset
dataset = pd.read_csv('injection_molds_dataset.csv')

# Display the first few rows
print(dataset. Head())
```

## Example datasets
```python
from datasets import load_dataset

# Load the dataset
dataset = load_dataset(""mustafakeser/injection-molding-QA"")

# Display dataset info
print(dataset)

# Accessing the first few examples
print(dataset['train'][:5])
#or 
dataset['train'].to_pandas()

```

## Columns
1. **Questions**: Contains questions related to injection molding.
2. **Answers**: Provides detailed answers to the corresponding questions.

## Citation
If you use this dataset in your work, please consider citing it as:

```
@misc{injectionmold_dataset,
  author = {Your Name},
  title = {Injection Molds Dataset},
  year = {2024},
  publisher = {Hugging Face},
  journal = {Hugging Face Datasets},
  howpublished = {\url{link to the dataset}},
}
```
## Huggingface
https://huggingface.co/datasets/mustafakeser/injection-molding-QA
mustafakeser/injection-molding-QA

## Notes
This dataset curated with gemini-1.0-pro
---
license: apache-2.0
---
",.csv
liver disorders,1,liver-disorders,Indian Liver Patient Dataset (ILPD).csv,Attribution 4.0 International (CC BY 4.0),"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F18476702%2F24c4e9996c724800ba903562cb58d901%2FCHRONIC-LIVER-DISEASE.jpg?generation=1706458297095819&alt=media)


**Description**

Death by liver cirrhosis continues to increase, given the increase in alcohol consumption rates, chronic hepatitis infections, and obesity-related liver disease. Notwithstanding the high mortality of this disease, liver diseases do not affect all sub-populations equally. The early detection of pathology is a determinant of patient outcomes, yet female patients appear to be marginalized when it comes to early diagnosis of liver pathology. The dataset comprises 584 patient records collected from the NorthEast of Andhra Pradesh, India. The prediction task is to determine whether a patient suffers from liver disease based on the information about several biochemical markers, including albumin and other enzymes required for metabolism.

**Additional Information**

This data set contains records of 416 patients diagnosed with liver disease and 167 patients without liver disease. This information is contained in the class label named 'Selector'(167 healthy vs 416 diseased patients).  There are 10 variables per patient: age, gender, total Bilirubin, direct Bilirubin, total proteins, albumin, A/G ratio, SGPT, SGOT and Alkphos. Of the 583 patient records, 441 are male, and 142 are female. 

The current dataset has been used to study 
- differences in patients across US and Indian patients that suffer from liver diseases.
- gender-based disparities in predicting liver disease, as previous studies have found that biochemical markers do not have the same effectiveness for male and female patients.",.csv
lung cancer data,1,lung-cancer-data,survey lung cancer.csv,Apache 2.0,"The effectiveness of cancer prediction system helps the people to know their cancer risk with low cost and it also helps the people to take the appropriate decision based on their cancer risk status. The data is collected from the website online lung cancer prediction system .

Total no. of attributes:16 No .of instances:284 Attribute information: 1. Gender: M(male), F(female) 2. Age: Age of the patient 3. Smoking: YES=2 , NO=1. 4. Yellow fingers: YES=2 , NO=1. 5. Anxiety: YES=2 , NO=1. 6. Peer_pressure: YES=2 , NO=1. 7. Chronic Disease: YES=2 , NO=1. 8. Fatigue: YES=2 , NO=1. 9. Allergy: YES=2 , NO=1. 10. Wheezing: YES=2 , NO=1. 11. Alcohol: YES=2 , NO=1. 12. Coughing: YES=2 , NO=1. 13. Shortness of Breath: YES=2 , NO=1. 14. Swallowing Difficulty: YES=2 , NO=1. 15. Chest pain: YES=2 , NO=1. 16. Lung Cancer: YES , NO.",.csv
mastodon.social alt text use by client app,1,mastodon-social-alt-text-use-by-client-app,fediverse-client-alt-text-data-2024-05-13.csv,MIT,"Comparing the presence of image description based on which apps people use to post in the fediverse. The results highlight the importance of design that makes it easy to add image description, and availability of tools such as image and text recognition algorithms.

More details are available [on my blog](https://stefanbohacek.com/blog/impact-of-fediverse-clients-on-the-use-of-alt-text/).",.csv
medical_examination.csv,1,medical-examination-csv,medical_examination.csv,MIT,"**
The dataset comprises health-related information of individuals, particularly focusing on factors that could contribute to cardiovascular disease. It consists of 12 unique features, encompassing both objective and subjective measurements:**

- 1. Age: Recorded in days, providing precise age information of the individuals.
- Height: measured in centimeters, offering insights into the physical stature of the subjects.
- Weight: represented in kilograms, indicating the body mass of each individual.
- Gender: Categorized to distinguish between male and female participants.
- Systolic Blood Pressure (ap_hi): an objective feature denoting the higher value in blood pressure readings, crucial for assessing cardiovascular health.
- Diastolic Blood Pressure (ap_lo): an objective feature representing the lower value in blood pressure readings.
- Cholesterol: Indicates the cholesterol level in the blood, categorized into three levels: normal, above normal, and well above normal.
- Glucose: Reflects the glucose level in the blood, categorized similarly to cholesterol.
- Smoking: Subjective feature denoting whether the individual smokes or not.
- Alcohol Intake: Subjective feature indicating whether the individual consumes alcohol.
- Physical Activity: A subjective feature representing the level of physical activity of the individual.
- Presence or Absence of Cardiovascular Disease (cardio): The target variable, binary in nature, indicating the presence or absence of cardiovascular disease in the individual.

The dataset is structured to provide a comprehensive overview of various factors that could influence cardiovascular health, including demographic information like age and gender, physiological measurements like blood pressure, cholesterol, and glucose levels, as well as lifestyle choices such as smoking, alcohol consumption, and physical activity.

This dataset could be invaluable for conducting exploratory data analysis, identifying patterns or correlations between different features and the presence of cardiovascular disease, and potentially developing predictive models to assess an individual's risk of developing cardiovascular issues based on their characteristics and lifestyle factors.",.csv
penguins,1,penguins,penguins.csv,CC0-1.0,"Data were collected and made available by Dr. Kristen Gorman and the Palmer Station, Antarctica LTER, a member of the Long Term Ecological Research Network.",.csv
pima-indians-diabetes.data,1,pimaindiansdiabetesdata,pima-indians-diabetes.data.csv,DbCL-1.0,"### Context

About whether the horse will be in the next 5 years, whether the occurrence of diabetes data set

### Content

What's inside is more than just rows and columns. Make it easy for others to get started by describing how you acquired the data and what time period it represents, too.


### Acknowledgements

We wouldn't be here without the help of others. If you owe any attributions or thanks, include them here along with any citations of past research.


### Inspiration

Your data will be in front of the world's largest data science community. What questions do you want to see answered?",.csv
policies in reducing,1,policies-in-reducing,fertilizer-use-per-hectare-of-cropland new.csv,CC0-1.0,"this graph was created in OurDataWorld:

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F6857e794a4d364a22a317712757eaee3%2Fgraph1.png?generation=1713811320498142&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fcaacd675a7d67157ab8034479084ef3d%2Fgraph2.png?generation=1713811328841379&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F7e8ba6cd08a45f09614a0ce4881841e3%2Fgraph3.png?generation=1713811334859292&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F3523bb8ce00a86b02618505c2a8b5480%2Fgraph4.png?generation=1713811340505462&alt=media)

Agriculture is a difficult problem to solve. It feeds 8 billion people but is also one of the world’s most environmentally damaging sectors. It’s the leading driver of deforestation, biodiversity loss, land use, freshwater withdrawals, and water pollution.

The world will need effective governmental policies — called agro-environmental policies — and innovations in sustainable food technologies if we want to reduce these impacts while feeding 9 or 10 billion people.

You might think, then, that the obvious thing to do is to have more and more policies focused on reducing its environmental impacts. But this assumes that all policies are effective and don’t impose trade-offs with food production or socioeconomic outcomes. This is not always the case.

Sri Lanka is a particularly dramatic case showing how rash and poorly designed policies can lead to tragic consequences. In mid-2021, the government abruptly banned the import of chemical fertilizers. On an agri-environmental policy scorecard, this might have looked good. Fertilizer use — which can cause pollution — plummeted.

But it caused dramatic losses in the country’s food supplies. Rice production fell by almost 40% from 2021 to 2022. The production of key export crops, such as tea and rubber, also fell significantly. The country spiraled into an economic crisis. While this crisis is not entirely the result of its fertilizer ban — the import ban was partly in response to economic problems — it made things worse.1

The lack of planning or foresight made this policy so damaging. Farmers had no time to find nutrient alternatives or learn how to optimize organic production. It illustrates clearly that just because a country has a policy in place doesn’t mean it produces good outcomes.

I’ve written previously about how different national priorities are when it comes to food production. Farmers in most low-income countries don’t have access to fertilizers, pesticides, irrigation, or other vital inputs, and their yields suffer as a result. In middle- and high-income countries, farmers often overuse fertilizers and pesticides, causing lots of water pollution.

Effective policies must consider trade-offs and priorities, not just in terms of national outcomes but also the global environmental and socioeconomic impacts.

In this article, I look at global data on agricultural policies, some success stories, and what policymakers need to consider to prevent environmental damage from being offshored to other countries.",.csv
polynomial regression ,1,polynomial-regression,Ice_cream selling data.csv,CC0-1.0,"The **Ice Cream Selling** dataset is a simple and well-suited dataset for  **beginners** in machine learning who are looking to practice **polynomial regression**. It consists of two columns: **temperature** and **the corresponding number of units of ice cream sold.**

The dataset captures the relationship between temperature and ice cream sales. It serves as a practical example for understanding and implementing polynomial regression, a powerful technique for modeling **nonlinear relationships** in data.

The dataset is designed to be straightforward and easy to work with, making it ideal for **beginners**. The simplicity of the data allows beginners to focus on the **fundamental concepts** and steps involved in polynomial regression without overwhelming complexity.

By using this dataset, beginners can gain hands-on experience in ***preprocessing the data, splitting it into training and testing sets, selecting an appropriate degree for the polynomial regression model, training the model, and evaluating its performance.*** They can also explore techniques to address potential challenges such as overfitting.

With this dataset, beginners can practice making predictions of ice cream sales based on temperature inputs and visualize the polynomial regression curve that represents the relationship between temperature and ice cream sales.

Overall, the Ice Cream Selling dataset provides an accessible and practical learning resource for beginners to grasp the concepts and techniques of polynomial regression in the context of analyzing ice cream sales data.",.csv
restaurants sales forecast  trending menu,1,restaurants-sales-forecast-trending-menu,Food_Sales_trending.csv,Apache 2.0,"The dataset seems to represent transactional data from a food and beverage business.
This dataset appears to be rich in transactional information related to food and beverage purchases, including details about items, prices, quantities, transaction types, payment methods, customer titles, and transaction times.
",.csv
salary_data_analist,1,salary-data-analist,ds_salaries new.csv,CC0-1.0,"Landing high-paying jobs at these top tech giants requires a fine blend of education, skills, and practical experience. You need to have a deep understanding of data and its analysis, something that can be massively boosted by applying for a degree at IU. The data science degrees we offer, ranging from a Bachelor's in Data Science to an MBA in Big Data Management, provide hands-on, applicable knowledge which these top tech leaders value

Networking, demonstrating creative problem-solving, ability to identify patterns, and showcasing a portfolio of practical projects can also go a long way in getting noticed. Remember, these companies are looking for innovative minds who can use data to drive their companies forward!

IBM, a veteran of the tech industry, has long since recognised the value of data and employs data scientists to keep them on the cutting edge of technology. The average salary of a data scientist at IBM is $155,869[3] per year, along with other incentives such as bonuses.

Google, requires data scientists to improve its user experience, advertising platform and search algorithms among other things. Data scientists at Google can expect to earn $135,287[2] annually, as per recent figures provided by Glassdoor [2023].

As one of the world's largest and most successful e-commerce corporations, Amazon has a high demand for data scientists to analyse and interpret the vast volume of data they generate. The average base salary for a Data Scientist in Amazon is $128,059[1] per year in the United States, with additional compensation like bonuses and benefits [2023].",.csv
sales data,1,online-store-sales-data,Sales-Export_2019-2020.csv,EU ODP Legal Notice,"Deluxe is an online retailer based in UK that deals in a wide range of products in the following categories:
1. Clothing 
2. Games
3. Appliances 
4. Electronics 
5. Books 
6. Beauty products
7. Smartphones
8. Outdoors products 
9. Accessories 
10. Other
Basic household products are classified as 'Other' in the category column since they have small value to the business.

Data Description:
dates: sale date
order_value_EUR : sale price in EUR
cost: cost of goods sold in EUR
category: item category
country: customers' country at the time of purchase
customer_name: name of customer
device_type: The gadget used by customer to access our online store(PC, mobile, tablet)
sales_manager: name of the sales manager for each sale
sales_representative: name of the sales rep for each sale
order_id: unique identifier of an order

The data was recorded for the period 1/2/2019 and 12/30/2020 with an aim to generate business insights  to guide business direction. We would like to see what interesting insights the Kaggle community members can produce from this data. ",.csv
seattle-weather,1,seattle-weather,seattle-weather.csv,other,"🟪🟨Seattle usually has rainy and dry weather, November to March has the worst weather conditions. The coldest month of the year is January and November is the wettest month, accompanied by strong wind waves and rain storms. The best time to travel is from April to October when the weather is pleasant and wonderful.",.csv
soil test report with weather for crop prediction,1,soil-test-report-with-weather-for-crop-prediction,Crop_recommendation.csv,Apache 2.0,"Dataset Description
Overview
The dataset used for this project consists of soil attribute data collected from various agricultural fields. The goal of collecting this data is to develop a model that can provide personalized crop recommendations to farmers based on their soil conditions. The dataset includes information on nitrogen (N), phosphorus (P), potassium (K) levels, and pH values, which are key factors influencing crop growth and yield.

Data Collection
The soil attribute data was collected through soil testing conducted in collaboration with farmers across different regions. Soil samples were taken from agricultural fields, and laboratory tests were performed to measure the levels of nitrogen, phosphorus, potassium, and pH. The data collection process aimed to capture a diverse range of soil conditions prevalent in agricultural areas.

Data Pre-processing
Before being used for model training, the dataset underwent pre-processing steps to ensure consistency and quality. This involved data cleaning to remove any inconsistencies or outliers, normalization to scale the values within a standardized range, and feature engineering to extract relevant features from the raw data. Missing values, if any, were also handled appropriately through imputation techniques.

Dataset Characteristics
Size: The dataset consists of a large number of samples, with each sample containing measurements of nitrogen, phosphorus, potassium, and pH values.
Features: The main features of the dataset include nitrogen level (N), phosphorus level (P), potassium level (K), and soil pH.
Target: The target variable is the crop recommendation based on the soil attributes provided. This could be a categorical variable representing different crop types or a numerical value indicating the suitability of specific crops.
Distribution: The dataset covers a diverse range of soil conditions found in agricultural fields, including variations in nutrient levels and pH values across different regions.
Data Usage
The dataset serves as the foundation for training and evaluating the crop recommendation model. It provides the necessary input features for the model to learn the relationships between soil attributes and crop suitability. Additionally, the dataset facilitates the testing and validation of the model's performance, ensuring its effectiveness in providing accurate and personalized crop recommendations to farmers.

Ethical Considerations
Ethical considerations regarding data privacy and confidentiality were paramount throughout the data collection process. Farmers' consent was obtained before collecting soil samples, and measures were taken to anonymize and protect sensitive information. Additionally, efforts were made to ensure equitable representation of diverse agricultural regions and farming practices in the dataset to mitigate biases in the model's recommendations.",.csv
synthetic credit score of thin-file consumers,1,synthetic-credit-score-of-thin-file-consumers,500Credit_Score_Dataset.csv,MIT,"**Research Context**
The dataset in question is designed to facilitate a study in the development of machine learning algorithms specifically tailored for credit scoring of ""thin-file"" consumers. ""Thin-file"" consumers are individuals who have little to no credit history, which makes traditional credit scoring models less effective or entirely inapplicable. These consumers often face difficulties in accessing credit products because they cannot be easily assessed by standard credit risk evaluation methods. 

**Sources**
The data contained in the attached file is synthetically created using Python code. This approach is often employed to generate comprehensive datasets where real data is either unavailable or too sensitive to use for research purposes. Synthetic data generation allows for controlled experiments and analysis by enabling the inclusion of varied and extensive scenarios that might not be represented in real-world data, ensuring both privacy compliance and rich diversity in data attributes.

[*Python libraries such as Pandas, NumPy, and Faker is used to create this dataset. These tools help in generating realistic data patterns and distributions, simulating a range of consumer profiles from those with stable financial behaviors to those with erratic financial histories, which are typical of thin-file scenarios.*]

**Inspiration**
The inspiration behind generating and utilising this dataset is to refine and enhance machine learning models that can effectively score thin-file consumers. This aligns with broader financial inclusivity goals, aiming to bridge the gap in financial services by providing fair credit opportunities to underserved segments of the population. By developing algorithms that can accurately predict creditworthiness in the absence of extensive credit histories, the study aims to propel the financial industry towards more equitable practices.

This dataset, therefore, serves as a foundational element in a research effort that not only seeks to innovate in the technical realm of machine learning but also to contribute positively to societal progress by enhancing financial inclusion.",.csv
tesla_stock_data,1,tesla-stock-data,tesla_data.csv,Community Data License Agreement - Sharing - Version 1.0,"The ""Tesla Stock Price Data (Last One Year)"" dataset is a comprehensive collection of historical stock market information, focusing on Tesla Inc. (TSLA) for the past year. This dataset serves as a valuable resource for financial analysts, investors, researchers, and data enthusiasts who are interested in studying the trends, patterns, and performance of Tesla's stock in the financial markets.",.csv
time the Internet,1,time-the-internet,numberofinternetusers new.csv,CC0-1.0,"this graphs was created in R and Ourdataworld:

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F1ad74af652d524e84410babe6ac5fe61%2Fgraph1.png?generation=1711651132634613&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F7c2b6427cb38f50eae417d741d09cd8d%2Fgraph2.png?generation=1711651140030127&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Ffea08aaf9fe8038659f6a081729f1bb2%2Fgraph3.gif?generation=1711651145884218&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F6cbb7538ed8f73a5bfed936ef7396a6d%2Fgraph4.gif?generation=1711651153848054&alt=media)



Introduction:

The dawn of the internet era has heralded an unprecedented age of connectivity, transforming the way we live, communicate, and interact on a global scale. As of 2020, approximately 60% of the world's population had access to the internet, marking a significant milestone in the digital revolution. From facilitating seamless communication to enabling cross-border collaborations, the internet has become an indispensable tool in our daily lives. This essay explores the multifaceted impact of the internet across various domains, highlighting its role as a catalyst for global connectivity and innovation.

Communication and Collaboration:

One of the most profound implications of the internet is its ability to bridge geographical distances and facilitate instant communication. Platforms such as email, social media, and messaging apps have revolutionized how we interact with one another, transcending borders and time zones. Whether it's connecting with loved ones halfway across the globe or collaborating with colleagues on a project, the internet has made communication more accessible and efficient than ever before. Video conferencing tools have further enhanced remote collaboration, enabling teams to work seamlessly regardless of their physical location. As a result, businesses have embraced remote work models, unlocking new possibilities for flexibility and productivity.

Financial Inclusion and Remittances:

The internet has democratized access to financial services, empowering individuals to participate in the global economy irrespective of their location. Online banking, mobile payment apps, and digital wallets have revolutionized the way we manage our finances, offering convenience and security. Moreover, the internet has facilitated international money transfers, including remittances, which play a vital role in supporting families and economies worldwide. Platforms like PayPal, TransferWise, and Western Union have streamlined the process of sending and receiving money across borders, reducing transaction costs and increasing efficiency. This newfound accessibility to financial services has contributed to greater financial inclusion and economic empowerment, particularly in underserved communities.

Education and Knowledge Sharing:

The internet has democratized access to education, breaking down traditional barriers to learning and knowledge dissemination. Online courses, tutorials, and educational platforms have made quality education accessible to anyone with an internet connection. Whether it's acquiring new skills, pursuing higher education, or accessing resources for self-improvement, the internet offers a wealth of learning opportunities. Open educational resources (OERs) and Massive Open Online Courses (MOOCs) have revolutionized the way we approach education, fostering a culture of lifelong learning and skill development. Furthermore, online forums and communities provide avenues for knowledge sharing and collaboration, enabling individuals to learn from experts and peers across the globe. This democratization of education holds the promise of narrowing the digital divide and fostering global innovation and prosperity.

Cross-Border Social Connections:

The internet has transcended cultural and linguistic barriers, facilitating cross-border social connections and fostering a sense of global citizenship. Social media platforms have become virtual gathering spaces where people from diverse backgrounds can connect, share experiences, and engage in meaningful dialogue. Whether it's forming friendships with individuals from different countries or participating in online communities centered around shared interests, the internet has enriched our social interactions in unprecedented ways. Moreover, platforms like language exchange forums and cultural exchange programs promote intercultural understanding and empathy, bridging gaps between people of different nationalities and backgrounds. By facilitating cross-border social connections, the internet has the potential to foster a more inclusive and interconnected global community.

Information Sharing and News Dissemination:

The internet has democratized access to information, empowering individuals to stay informed and engaged with current events on a global scale. Online news portals, blogs, and social media have transformed the way we consume and share news, providing real-time updates and diverse perspectives on global issues. Citizen journalism and user-generated content have enriched the media landscape, enabling ordinary citizens to contribute to public discourse and hold power to account. However, the proliferation of misinformation and fake news poses challenges to the integrity of online information, highlighting the importance of digital literacy and critical thinking skills. Nonetheless, the internet remains a powerful tool for amplifying marginalized voices, raising awareness about social injustices, and fostering democratic participation.

Conclusion:

In conclusion, the internet has emerged as a transformative force, reshaping the way we communicate, collaborate, and connect on a global scale. From facilitating seamless communication to democratizing access to education and information, the internet has become an indispensable tool for social, economic, and cultural exchange. However, as we embrace the opportunities afforded by the internet, it is imperative to address digital divides and ensure equitable access to its benefits. By harnessing the power of the internet responsibly, we can build a more inclusive and interconnected world, where knowledge knows no boundaries and opportunities abound for all.",.csv
top companies rating and reviews,1,top-companies-rating-and-reviews,1000 companies list and rating.csv,other,"Introducing the newest dataset from AmbitionBox.com, offering a refreshed look at top companies. This comprehensive collection includes key details like company name, type, rating, reviewer count, company age, and noteworthy insights into highly rated and critically rated aspects. Stay informed with this enriched dataset for a comprehensive view of the corporate landscape.",.csv
top_odi_batsman_cricinfo,1,top-odi-batsman-cricinfo,Top_odi_batsman.csv,CC0-1.0,"this dataset has been prepared for the learning purpose. This dataset consists of top oneday international cricket batsman with highest total score,highest individual score, strike rate, boundaries, centuries, fifties etc.any suggestion to edit the dataset is most welcome.
features in this dataset are
1. name
2.matches
3.runs
4.highest score
5.average
6.not out
7.zeros
8.strike rate
9.fifties
10. centuries
11.fours
12.sixes
13.innings
14.career span ",.csv
universitiesRanking,1,univercitiesranking,universitydatasets.csv,Apache 2.0,"**Analyzing the Dataset of the Top 1000 Global Universities**
In this project, the ranking of the top 1000 universities in the world has been reviewed and analyzed.
The current project, within the framework of a scientific and research exercise in the field of machine learning, which was held in the summer of 1402 under the supervision of professor Mohammad Reza Momeni and under the guidance of mentor Amirreza Lotfi, in this exercise, the study and analysis of data related to university rankings We have discussed the effective factors.

This exercise, with the aim of cleaning the data and better understanding of the existing patterns, has been a fundamental step towards a deeper understanding of the available data in the field of machine learning.

The current dataset contains 1000 rows and 12 columns, which contains a variety of university information maps, including their names and geographic locations, scores, and various rankings.

This initial analysis reveals a dynamic and complex field of data, providing an accurate representation of the complexity and diversity of universities and guiding us in the next sections.",.csv
us population by state,1,us-population-by-state,us_pop_by_state.csv,CC0-1.0,"This is a utility dataset that I often use when I want to create the per inhabitant value
**Columns**

* rank, the rank of the state by population
* state, the name of the state
* state_code, the abbreviation of the state name
* 2020_census, population in 2020
* percent__o_f_total, share of the state population in the US population",.csv
usa-container-ports-2000-2017,1,usacontainerports20002017,container-ports-2000-2017.csv,CC0-1.0,"USA container ports 2000-2017

US Dept. of Transportation Maritime Administration
US Waterborne Foreign Container Trade by US customs ports 2000-2017

Imports are in Metric Tons (Loaded containers only)",.csv
va_pension_recipients,1,galactic-test-dataset-1,va_pension.csv,CC0-1.0,"**Analyzing Pension Recipients by State**

**Overview**

This work focuses on investigating and analyzing the distribution of pension beneficiaries in various US states for the fiscal year 2023. The data includes information about the total number of pension beneficiaries in each state.

**1. Load the JSON data into Pandas and check for any missing or inconsistent entries.**

```python
import pandas as pd
import json
import matplotlib.pyplot as plt
```
```python
# Load JSON data
file_path = r'C:\Users\vladi\Desktop\va_pension.json'
with open(file_path, 'r') as file:
    json_data = json.load(file)
```
```python
# Extract the data from the nested structure
data_rows = json_data['data']
columns = [col['fieldName'] for col in json_data['meta']['view']['columns'] if 'fieldName' in col]
pension_data = pd.DataFrame(data_rows, columns=columns)
```
```python
# Convert data types
pension_data['total_pension_recipients'] = pd.to_numeric(pension_data['total_pension_recipients'], errors='coerce')
```
```python
# Define future behaviour for downcasting
pd.set_option('future.no_silent_downcasting', True)
```
```python
# Filling missing values
pension_data.fillna(0, inplace=True)
```

**2. Convert and save the data into Excel and CSV formats.**

```python
# Convert data to excel and csv
excel_path = r'C:\Users\yourname\Desktop\va_pension.xlsx'
csv_path = r'C:\Users\yourname\Desktop\va_pension.csv'
pension_data.to_excel(excel_path, index=False)
pension_data.to_csv(csv_path, index=False)
```

**3. Generate statistical summary and create a bar chart.**

```python
# Statistical summary
print(""\nStatistical summary:"")
print(pension_data.describe())
```

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F17427131%2F529785be3c66ac4cf525454f0f79f8c1%2FStatistical%20Summary.png?generation=1714388928180585&alt=media)

```python
# Bar chart
plt.figure(figsize=(12, 8))
plt.bar(pension_data['state'], pension_data['total_pension_recipients'], color='skyblue')
plt.xlabel('State')
plt.ylabel('Number of Pension Recipients')
plt.title('Pension Recipients by State - FY 2023')
plt.xticks(rotation=90)
plt.show()
```

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F17427131%2Fe02d660716016daaf24119e0836531ff%2FBar%20Chart.png?generation=1714388962664213&alt=media)

**4. Construct a pie chart to show the proportion of pension recipients by state.**

```python
# Pie chart
plt.figure(figsize=(10, 8))
plt.pie(pension_data['total_pension_recipients'], labels=pension_data['state'], autopct='%1.1f%%')
plt.title('Distribution of Pension Recipients by State - FY 2023')
plt.axis('equal')
plt.show()
```

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F17427131%2Fec9ad8b2be4fe3035cbd68c8434e90ef%2FPie%20Chart.png?generation=1714388980451818&alt=media)

**5. Identify the top 5 states with the highest number of pension recipients.**

```python
# Top five states with the highest number of pension recipients
top_states = pension_data.sort_values(by='total_pension_recipients', ascending=False).head(5)
print(""\nTop 5 states with the highest number of pension recipients:"")
print(top_states[['state', 'total_pension_recipients']])
```

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F17427131%2F5c06766297ccd2c68fee58c63d05f3f0%2Fimage_2024-04-29_131023211.png?generation=1714389022902430&alt=media)
",.csv
vulnerable groups,1,vulnerable-groups,number-of-homeless-status new.csv,CC0-1.0,"this graph was created in PowerBi,R and Loocker studio:

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Ff21bb298c472dbc4bed21ef6dda71d5e%2Fgraph1.jpg?generation=1715375554075996&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fea25ef2b4f987b1c37d85ce0b24180ce%2Fgraph2.jpg?generation=1715375559925771&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F69022bdb532b6b315c2ac7261d211868%2Fgraph3.png?generation=1715375565218326&alt=media)

This topic page studies available data and empirical evidence on homelessness, focusing specifically on how it affects people in high-income countries. Homeless people are among the most vulnerable groups in high-income countries.

You can read our topic page on Extreme Poverty if you are interested in a broader perspective on economic deprivation and a perspective beyond high-income countries.

Homeless people in the US
What data is available?
One of the most common ways to measure homelessness is through so-called 'point-in-time' counts of people who are sleeping in shelters or on the streets. These are figures that are intended to reflect the number of people who are homeless 'on any given night'.

The main source of point-in-time estimates in the US is the Department of Housing and Urban Development, which releases the Annual Homeless Assessment Report to Congress (AHARC). They calculate 'point-in-time' estimates by counting homeless people in late January of each year.

The main underlying sources of data used to produce the figures published in the AHARC are (i) registries from shelters and (ii) counts and estimates of sheltered and unsheltered homeless persons provided by care organizations, as part of their applications for government funding.

The counts from the care organizations (called 'Continuums of Care' in the US) come from active counts that are undertaken at the community level, by walking around the streets, using pre-established methodologies.1

In these figures, 'Sheltered Homelessness' refers to people who are staying in emergency shelters, transitional housing programs, or safe havens. 'Unsheltered Homelessness', on the other hand, refers to people whose primary nighttime residence is a public or private place not designated for, or ordinarily used as, a regular sleeping accommodation for people – for example, the streets, vehicles, or parks.2",.csv
web log dataset,1,web-log-dataset,weblog.csv,CC0-1.0,"### Context

I have developed an online judge for my university named [RUET OJ][1] . I am sharing the server log dataset of RUET OJ


### Content

This dataset has 16008 rows and 4 columns. Columns are IP, Time, URL, Response Status.


### Acknowledgements

This dataset is too small for research . But I hope others people will also share larger dataset for web log as web log dataset is rare here . 

### Inspiration

This dataset will inspire other people to share their collected web log dataset .


  [1]: https://github.com/shawon100/RUET-OJ",.csv
world happiness report 2022,1,world-happiness-report-2022,World Happiness Report 2022.csv,CC0-1.0,"###Context
The World Happiness Report is a landmark survey of the state of global happiness . The report continues to gain global recognition as governments, organizations and civil society increasingly use happiness indicators to inform their policy-making decisions. Leading experts across fields – economics, psychology, survey analysis, national statistics, health, public policy and more – describe how measurements of well-being can be used effectively to assess the progress of nations. The reports review the state of happiness in the world today and show how the new science of happiness explains personal and national variations in happiness.

###Content
The happiness scores and rankings use data from the Gallup World Poll . The columns following the happiness score estimate the extent to which each of six factors – economic production, social support, life expectancy, freedom, absence of corruption, and generosity – contribute to making life evaluations higher in each country than they are in Dystopia, a hypothetical country that has values equal to the world’s lowest national averages for each of the six factors. They have no impact on the total score reported for each country, but they do explain why some countries rank higher than others.",.csv
world’s energy problem?,1,worlds-energy-problem,abs-change-energy-consumption new.csv,CC0-1.0,"this graph was created in Tableau and OurDataWorld:

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F98a825f4322b0e01e421eb35be33a663%2Fgraph1.png?generation=1713039036066069&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fa2ac0324b60dd0523de5a7c68f8b484a%2Fgraph3.png?generation=1713039042733698&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F168ce3936a83a836f8eea66c4b85614e%2Fgragh2.png?generation=1713039050311505&alt=media)

In the tapestry of global challenges that humanity faces, few loom as large as the imperative for sustainable energy. The contemporary world is marked by an acute deficiency: a dearth of secure, low-carbon, and economically viable large-scale energy infrastructure. This insufficiency not only perpetuates disparities in energy access, leaving hundreds of millions marginalized and deprived, but also fuels the inexorable march of climate change and its attendant health crises, notably air pollution.

At the nexus of these intertwined crises lies a paradox: the very source of human progress, energy, is now both the enabler and the impediment to a sustainable future. Until we embark on a concerted effort to amplify and democratize access to clean energy sources, the dual specters of energy poverty and environmental degradation will persist unabated, casting a shadow over the prospects of equitable development and planetary well-being.

To comprehend the magnitude of this challenge, it is imperative to delineate the contours of global energy consumption, its attendant impacts, and the trajectory of its evolution. A comprehensive understanding of these dynamics forms the bedrock upon which effective interventions can be crafted and implemented.

In this digital age, where data serves as the currency of informed decision-making, access to reliable, comprehensive energy data is indispensable. It is the lifeblood that nourishes evidence-based policymaking and catalyzes public discourse. Visualizations, statistics, and rigorous analysis serve as the guiding stars in navigating the complex terrain of global energy dynamics.

The plight of energy poverty afflicts vast swathes of humanity, relegating millions to lives of darkness and deprivation. In remote villages and sprawling urban slums alike, the absence of reliable energy infrastructure consigns communities to the margins of economic opportunity and social progress.

For these marginalized populations, the quest for energy transcends mere convenience; it is a matter of survival, dignity, and empowerment. Clean and accessible energy holds the key to unlocking a myriad of possibilities: from illuminating homes and powering schools to driving economic productivity and enhancing healthcare delivery.

Moreover, the scourge of climate change, exacerbated by the wanton combustion of fossil fuels, casts a long and foreboding shadow over the future of our planet. The relentless emission of greenhouse gases imperils ecosystems, disrupts weather patterns, and exacts a heavy toll on human health and well-being.

The imperative to decarbonize our energy systems has never been more urgent. Transitioning to renewable sources such as solar, wind, and hydroelectric power is not merely an environmental imperative but a moral imperative—one that demands concerted action and unwavering commitment from the global community.

However, the transition to a sustainable energy future is not devoid of challenges. Chief among these is the imperative to reconcile economic imperatives with environmental stewardship. Historically, fossil fuels have held sway as the bedrock of global energy infrastructure, owing to their abundance and affordability.

Yet, the true costs of this dependency are only now becoming apparent: from the hidden toll of air pollution on public health to the existential threat posed by climate change. The transition to renewable energy sources necessitates a paradigm shift—one that transcends short-term economic calculus and embraces the imperatives of intergenerational equity and ecological resilience.

In charting a course towards a sustainable energy future, the role of innovation and technological advancement cannot be overstated. Breakthroughs in energy storage, grid integration, and efficiency hold the promise of unlocking new frontiers in renewable energy deployment, making clean energy not only desirable but economically competitive.

Moreover, the imperative for international cooperation and solidarity looms large. The challenges posed by energy poverty and climate change are inherently global in scope, transcending national borders and geopolitical divides. Only through collective action and shared responsibility can we hope to surmount these formidable challenges and forge a more equitable and sustainable future for all.

In conclusion, the imperative for a safe, low-carbon, and economically viable large-scale energy infrastructure is undeniable. Until we muster the collective will and resolve to confront this challenge head-on, the specters of energy poverty and environmental degradation will continue to haunt us, casting a pall over the prospects of a more equitable and sustainable future.

Yet, in the face of adversity lies opportunity. By harnessing the power of innovation, cooperation, and collective action, we can forge a path towards a brighter tomorrow—one powered by clean, abundant, and sustainable energy for all.",.csv
world’s wildlife?,1,worlds-wildlife,yields-of-important-staple-crops new.csv,CC0-1.0,"this graph was created in R, OurDataWorld and loocker : 

Considering this immense transformation, this article’s first sentence is not surprising: agricultural land use has been the main driver of the destruction of wildlife and nature over the last millennia.

This environmental problem — agricultural land use — does not get the attention it deserves. It’s mentioned far less than other environmental challenges like climate change or plastic pollution. But if we want a future in which we preserve the world’s wildlife, this is the key problem we must focus on.

We can't look at this problem in isolation. At the same time, as we protect the world’s environment, we also have to find ways to produce the food needed to end hunger and malnutrition. But — and this is the point of this article — these two goals are no longer at odds with one another.

For our ancestors they were at odds with one another: our ancestors had to take natural land and convert it into agricultural land if they wanted to produce more food. This is not the case for us today: we can produce more from less.

More from less
To increase food production while restoring wild habitats, we must find ways to produce more food on less land. We have to increase agricultural productivity.

This is possible. In fact, we have already achieved a lot, as the following chart shows.

After centuries of stagnation, humanity has recently achieved a large increase in land productivity. The chart shows that land use per person declined by more than half. At the same time, food supply per person increased in every region of the world.

The world has already achieved large increases, but thanks to the research on “yield gaps”, we know that more is possible. Yield gaps are estimated by agricultural researchers and represent the difference between the current yields that a region achieves and the yields that are attainable using currently available crops, technologies, and farming practices. In our Crop Yields Data Explorer, you can explore the yield gap for countries around the world for crops, including wheat, barley, potato, and rice.

What stands in the way of closing yield gaps?

The binding constraints differ significantly between different regions. It often hinges on adopting technologies like irrigation, fertilizers, and better seeds. But one level deeper, what is needed are changes to the finance systems that make the adoption of technology possible and provide access to markets; political changes that enable fair trade arrangements and strengthen the land rights of farmers; and scientific efforts to produce high-yielding crops suitable for the climate and soil of each particular agricultural region.6

We could free up a lot of land if we’d reduce global meat production
Not just changes to production can make a big difference. Changes in consumption, too, could spare much more agricultural land.

Most of the world’s farmland today is used for the production of meat and dairy, either as grazing land or cropland to grow animal feed.7 77% of all agricultural land is used to raise livestock for meat and dairy.

In total, this is an area of 38 million km². For comparison, that’s the size of the total land area of the Americas — from Alaska in the North all the way to Tierra del Fuego in the South.8


![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F03b33763db42e9905245de71275ac975%2Fgraph1.png?generation=1712951215897894&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2F358d45aeee6267bd3795a83d027cc848%2Fgraph2.jpg?generation=1712951223518877&alt=media)

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F16731800%2Fd502557fac7ce828945ab5c59a74d8d8%2Fgraph3.png?generation=1712951231390673&alt=media)",.csv
ℹ | Unlocking Investment Insights| PayPal Stocks🔰,1,paypal-datsets,pypl_stock_data.csv,Apache 2.0,"**Description:**
In this analysis, we explore PayPal's stock performance using historical market data from January 1, 2010, to March 1, 2024. The dataset consists of the following columns:


- **Date:** Represents the date of the stock data.
- **Open:** Denotes the opening price of the stock on that date.
- **High:** Signifies the highest price of the stock on that date.
- **Low:** Indicates the lowest price of the stock on that date.
- **Close:** Represents the closing price of the stock on that date.
- **Adj Close:** Refers to the adjusted closing price of the stock on that date, which accounts for any corporate actions such as dividends and stock splits.
- **Volume:** Represents the trading volume of the stock on that date, which indicates the number of shares traded.
",.csv
ℹ | 🔰Unlocking the Secrets of Microsoft Stocks 📊,1,microsft-dataset,msft_stock_data.csv,Apache 2.0,"## This Dataset is About mMcrosoft Stock prices 
About Columns:

- Date: The date of the stock data.
- Open: The opening price of Google stock on that date.
- High: The highest price of Google stock on that date.
- Low: The lowest price of Google stock on that date.
- Close: The closing price of Google stock on that date.
- Adj Close: The adjusted closing price of Google stock on that date, accounting for any corporate actions such as dividends and stock splits.
- Volume: The trading volume of Google stock on that date, i.e., the number of shares traded.",.csv
ℹ |📈Journey of the Future Trends of Netflix Stock,1,netflix-datset,netflix.csv,Apache 2.0,"## This Dataset is About Netflix Stock prices 
About Columns:

- Date: The date of the stock data.
- Open: The opening price of Google stock on that date.
- High: The highest price of Google stock on that date.
- Low: The lowest price of Google stock on that date.
- Close: The closing price of Google stock on that date.
- Adj Close: The adjusted closing price of Google stock on that date, accounting for any corporate actions such as dividends and stock splits.
- Volume: The trading volume of Google stock on that date, i.e., the number of shares traded.",.csv
ℹ🔰 |Google Ticker Dataset: Stock Price History 📈,1,google-stock-dataset,google_stock_data.csv,Apache 2.0,"We gather historical stock data from Yahoo Finance, preprocess it, and train various machine learning models to forecast future prices. By analyzing the Google dataset, we provide insights into potential trends and offer predictions valuable for investors.

### **About Columns:**

- Date: The date of the stock data.
- Open: The opening price of Google stock on that date.
- High: The highest price of Google stock on that date.
- Low: The lowest price of Google stock on that date.
- Close: The closing price of Google stock on that date.
- Adj Close: The adjusted closing price of Google stock on that date, accounting for any corporate actions such as dividends and stock splits.
- Volume: The trading volume of Google stock on that date, i.e., the number of shares traded.",.csv
☠️ US Cancer Analysis,1,us-cancer-analysis,cancer.csv,Apache 2.0,"As of my last update in January 2022, I don't have access to specific real-time datasets, including a specific ""US cancer analysis dataset."" However, there are several well-known sources where you might find such datasets:

1. **Surveillance, Epidemiology, and End Results (SEER) Program**: SEER is a comprehensive source of cancer statistics in the United States, operated by the National Cancer Institute (NCI). They provide a wide range of cancer-related data including incidence, mortality, survival, and population-based data on cancer cases.

2. **National Program of Cancer Registries (NPCR)**: This program, also managed by the Centers for Disease Control and Prevention (CDC), collects cancer incidence data at the state level.

3. **CDC WONDER**: The CDC's Wide-ranging Online Data for Epidemiologic Research (WONDER) platform provides access to a wide array of public health-related datasets, including cancer statistics.

4. **National Cancer Database (NCDB)**: This database, jointly sponsored by the American College of Surgeons and the American Cancer Society, contains hospital registry data from over 1,500 Commission on Cancer (CoC)-accredited facilities.

5. **National Health Interview Survey (NHIS)**: While not specific to cancer, the NHIS collects data on health and health-related behaviors, which may include information on cancer screenings, risk factors, and prevalence.

6. **Behavioral Risk Factor Surveillance System (BRFSS)**: Similar to NHIS, BRFSS collects state-based, cross-sectional data about U.S. residents regarding their health-related risk behaviors, chronic health conditions, and use of preventive services, which may include cancer-related data.

7. **National Health and Nutrition Examination Survey (NHANES)**: NHANES collects data on the health and nutritional status of a nationally representative sample of the U.S. population through interviews, physical examinations, and laboratory tests, which may include cancer-related information.

When accessing these datasets, it's essential to review their documentation thoroughly to understand the variables available, the methodology of data collection, any limitations or biases, and the terms of use. Additionally, many of these datasets require approval or registration before access is granted.",.csv
⚖️ Constitution Dataset 📜,1,constitution-dataset,Constitution Dataset.csv,CC0-1.0,"Data is sourced from [ Comparative Constitutions Project](https://comparativeconstitutionsproject.org/) (CCP). This dataset is useful for exploratory data analysis and NLP practices.

## Content

**Scope** — This is drawn from Elkins, Ginsburg and Melton, The Endurance of National Constitutions (Cambridge University Press, 2009). It measures the percentage of 701 major topics from the CCP survey that are included in any given constitution.

**Length (in Words)** — This is simply a report of the total number of words in the Constitution as measured by Microsoft Word.

**Executive Power**— This is an additive index drawn from a working paper, Constitutional Constraints on Executive Lawmaking. The index ranges from 0-7 and captures the presence or absence of seven important aspects of executive lawmaking: 
(1) the power to initiate legislation; 
(2) the power to issue decrees; 
(3) the power to initiate constitutional amendments; 
(4) the power to declare states of emergency; 
(5) veto power; 
(6) the power to challenge the constitutionality of legislation; and 
(7) the power to dissolve the legislature. 

The index score indicates the total number of these powers given to any national executive (president, prime minister, or assigned to the government) as a whole.

**Legislative Power**— This captures the formal degree of power assigned to the legislature by the Constitution. The indicator is drawn from Elkins, Ginsburg and Melton, The Endurance of National Constitutions (Cambridge University Press, 2009), in which we created a set of binary CCP variables to match the 32-item survey developed by M. Steven Fish and Mathew Kroenig in The Handbook of National Legislatures: A Global Survey (Cambridge University Press, 2009). The index score is simply the mean of the 32 binary elements, with higher numbers indicating more legislative power and lower numbers indicating less legislative power.

**Judicial Independence** — This index is drawn from a paper by Ginsburg and Melton, Does De Jure Judicial Independence Really Matter? A Reevaluation of Explanations for Judicial Independence. It is an additive index ranging from 0-6 that captures the constitutional presence or absence of six features thought to enhance judicial independence. 
The six features are: 
(1) whether the constitution contains an explicit statement of judicial independence; 
(2) whether the constitution provides that judges have lifetime appointments; 
(3) whether appointments to the highest court involve either a judicial council or two (or more) actors; 
(4) whether removal is prohibited or limited so that it requires the proposal of a supermajority vote in the legislature, or if only the public or judicial council can propose removal and another political actor is required to approve such a proposal; 
(5) whether removal explicitly limited to crimes and other issues of misconduct, treason, or violations of the constitution; and 
(6) whether judicial salaries are protected from reduction.

**Number of Rights** — In our ongoing book project on human rights, we analyze a set of 1172 different rights found in national constitutions. The rights index indicates the number of these rights found in any particular constitution.

**Preamble** - This is something I have extracted from the platform itself. It has the textual content of the preamble of every nation's Constitution. 

I may add a few more textual columns from available data from the CCP website and will update the current dataset in near future.",.csv
⚙️ Binary Classification for Sensor Signals,1,binary-classification-for-sensor-signals,dataset.csv,Attribution 4.0 International (CC BY 4.0),"The dataset is composed of digital signals obtained from a capacitive sensor electrodes that are immersed in water or in oil. Each signal, stored in one row, is composed of 10 consecutive intensity values and a label in the last column. The label is +1 for a water-immersed sensor electrode and -1 for an oil-immersed sensor electrode. This dataset should be used to train a classifier to infer the type of material in which an electrode is immersed in (water or oil), given a sample signal composed of 10 consecutive values.

Instructions: 
The dataset is acquired from a capacitive sensor array composed of a set of sensor electrodes immersed in three different phases: air, oil, and water. It is composed of digital signals obtained from one electrode while it was immersed in the oil and water phases at different times. 

## Experimental setup

The experimental setup is composed of a capacitive sensor array that holds a set of sensing cells (electrodes) distributed vertically along the sensor body (PCB). The electrodes are excited sequentially and the voltage (digital) of each electrode is measured and recorded. The voltages of each electrode are converted to intensity values by the following equation:

intensity = ( |Measured Voltage - Base Voltage| / Base Voltage ) x 100

Where the Base Voltage is the voltage of the electrode recorded while the electrode is immersed in air. The intensity values are stored in the dataset instead of the raw voltage values.

## Experimental procedure 

The aim of the experiments is to get fixed-size intensity signals from one electrode (target electrode) when being immersed in water and oil; labeled as +1 (water) or -1 (oil). For this purpose, the following procedure was applied:

-The linear actuator was programmed to move the sensor up and down at a constant speed (20 mm / second).

-The actuator stops when reaching the upper and bottom positions for a fixed duration of time (60 seconds).

-At the upper position, the target electrode is immersed in oil; intensity signals are labeled -1 and sent to the PC.

-At the bottom position, the target electrode is immersed in water; intensity signals are labeled +1 and sent to the PC.

-The sampling rate is 100 msec; since each intensity signal contains 10 values, it takes 1 second to record one intensity signal 

## Environmental conditions

The experiments were perfomed under indoors laboratory conditions with room temperature of around 23 degree Celsius. 

## Dataset structure 

The signals included in the dataset are composed of intensity signals each with 10 consecutive values and a label in the last column. The label is +1 for a water-immersed electrode and -1 for an oil-immersed electrode.

## Application

The dataset should be used to train a classifier to differentiate between electrodes immersed in water and oil phases given a sample signal.

# Acknowledgement

Foto von <a href=""https://unsplash.com/de/@giggiux?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Luigi Frunzio</a> auf <a href=""https://unsplash.com/de/fotos/gruner-und-schwarzer-computer-ram-stick-nLS8r16NCiM?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv
⚠️⚙️🔩🛠️🗜️ Steel Plates Faults from UCI,1,steel-plates-faults-from-uci,Steel Plates Faults.csv,Attribution 4.0 International (CC BY 4.0),"# ⚙️ A dataset of steel platesâ€™ faults, classified into 7 different types. The goal was to train machine learning for automatic pattern recognition.

### 🔩 Type of dependent variables (7 Types of Steel Plates Faults):
1. Pastry
2. Z_Scratch
3. K_Scatch
4. Stains
5. Dirtiness
6. Bumps
7. Other_Faults",.csv
✈️ Ryanair Passenger Experience Reviews,1,ryanair-reviews-ratings,ryanair_reviews.csv,ODC Attribution License (ODC-By),"😍**If you find INTERESTING this dataset, UPVOTE!!**😍

Welcome to this comprehensive dataset offering an in-depth exploration of the passenger experience with Ryanair, one of Europe's foremost low-cost airlines. This dataset compiles a diverse array of opinions and ratings provided directly by passengers themselves, covering various aspects of Ryanair flights **from 2012 to 2024.**

In this dataset, you'll find:

- Passenger-reported ratings on seat comfort, cabin crew service, food & beverages, ground service, and overall value for money.
- Detailed insights into the types of travelers, such as leisure, business, or family.
- Information on aircraft types, seat types, routes flown, and dates of travel.
- A breakdown of passenger nationalities and trip verification status.

From analyzing seat comfort to evaluating the overall value for money, this dataset provides a wealth of information to explore. Dive into the data to uncover trends, patterns, and valuable insights that can inform travelers, analysts, and aviation enthusiasts alike.

Explore, analyze, and discover firsthand what passengers have to say about their journeys with Ryanair!",.csv
🌌Space Missions🌌,1,space-missions,space_missions.csv,Apache 2.0,"**The dataset space_missions.csv contains information about various space missions. Here's a breakdown of the columns in the dataset:**

- Company: The organization responsible for the launch.
- Location: The geographical location of the launch site.
- Date: The date of the launch.
- Time: The time at which the launch occurred.
- Rocket: The model or name of the rocket used.
- Mission: The name or designation of the mission.
- RocketStatus: Indicates whether the rocket is still in use or has been retired.
- Price: The cost of the launch, if available.
- MissionStatus: Indicates the outcome of the mission, such as ""Success"" or ""Failure"".

**This dataset is useful for analyzing trends in space exploration, comparing the activities of different companies, and understanding the evolution of rocket technology.**",.csv
🌍 WhatsApp Business Reviews: App Store,1,whatsapp-business-reviews-app-store,hashed_wab_reviews.csv,ODC Attribution License (ODC-By),"

**Dataset Overview:**
This meticulously curated dataset amalgamates user reviews of the WhatsApp Business application from the App Stores of three distinct nations: Australia, Canada, and the United States. Encompassing a wealth of insights, the dataset is an invaluable resource for data scientists aiming to delve into consumer feedback, analyze sentiment trends, and extract meaningful patterns relevant to business strategies and app improvements.
The dataset brings together a comprehensive collection of user interactions and sentiments, shedding light on various facets of the user experience across different geographic locales. With data ethically mined and responsibly aggregated, it ensures a respectful approach towards user privacy while offering rich analytical opportunities.

**Data Science Applications:**
This dataset serves as a fertile ground for a multitude of data science endeavors including sentiment analysis, trend forecasting, natural language processing, and customer feedback analytics. Researchers and practitioners can employ this dataset to harness predictive insights, gauge app performance, and refine user engagement strategies.

**Column Descriptors:**
- **ID:** Unique identifier for each review entry.
- **Date:** Timestamp of the review.
- **UserName (Hashed):** Anonymized username of the reviewer.
- **UserUrl (Hashed):** Anonymized URL of the user's review profile.
- **Version:** App version the review pertains to.
- **Score:** User-provided rating for the app.
- **Title:** Title of the review.
- **Text:** Body text of the review, providing detailed feedback.
- **URL:** URL of the review on the App Store (anonymized if containing personal identifiers).
- **Country:** The country from which the review was posted.
- **AppId:** Unique identifier for the WhatsApp Business application.

**Ethical Considerations:**
In the assembly of this dataset, utmost care was taken to ensure the ethical sourcing of data, with a keen focus on maintaining the anonymity of the users. Personal identifiers such as usernames and user URLs have been hashed to uphold privacy and confidentiality. SHA-256 was used.

**Acknowledgements:**
Gratitude is extended to the platforms that facilitated the aggregation of this data, acknowledging their pivotal role in fostering a space where user feedback can thrive and inform better business and technological outcomes.

",.csv
🌎 GDP By Country 1999 - 2022,1,-gdp-by-country-1999-2022,GDP by Country 1999-2022.csv,CC0-1.0,"🇦🇨 🇦🇩 🇦🇪 🇦🇫 🇦🇬 🇦🇮 🇦🇱 🇦🇲 🇦🇴 🇦🇶 🇦🇷 🇦🇸 🇦🇹 🇦🇺 🇦🇼 🇦🇽 🇦🇿 🇧🇦 🇧🇧 🇧🇩 🇧🇪 🇧🇫 🇧🇬 🇧🇭 🇧🇮 🇧🇯 🇧🇱 🇧🇲 🇧🇳 🇧🇴 🇧🇶 🇧🇷 🇧🇸 🇧🇹 🇧🇻 🇧🇼 🇧🇾 🇧🇿 🇨🇦 🇨🇨 🇨🇩 🇨🇫 🇨🇬 🇨🇭 🇨🇮 🇨🇰 🇨🇱 🇨🇲 🇨🇳 🇨🇴 🇨🇵 🇨🇷 🇨🇺 🇨🇻 🇨🇼 🇨🇽 🇨🇾 🇨🇿 🇩🇪 🇩🇬 🇩🇯 🇩🇰 🇩🇲 🇩🇴 🇩🇿 🇪🇦 🇪🇨 🇪🇪 🇪🇬 🇪🇭 🇪🇷 🇪🇸 🇪🇹 🇪🇺 🇫🇮 🇫🇯 🇫🇰 🇫🇲 🇫🇴 🇫🇷 🇬🇦 🇬🇧 🇬🇩 🇬🇪 🇬🇫 🇬🇬 🇬🇭 🇬🇮 🇬🇱 🇬🇲 🇬🇳 🇬🇵 🇬🇶 🇬🇷 🇬🇸 🇬🇹 🇬🇺 🇬🇼 🇬🇾 🇭🇰 🇭🇲 🇭🇳 🇭🇷 🇭🇹 🇭🇺 🇮🇨 🇮🇩 🇮🇪 🇮🇱 🇮🇲 🇮🇳 🇮🇴 🇮🇶 🇮🇷 🇮🇸 🇮🇹 🇯🇪 🇯🇲 🇯🇴 🇯🇵 🇰🇪 🇰🇬 🇰🇭 🇰🇮 🇰🇲 🇰🇳 🇰🇵 🇰🇷 🇰🇼 🇰🇾 🇰🇿 🇱🇦 🇱🇧 🇱🇨 🇱🇮 🇱🇰 🇱🇷 🇱🇸 🇱🇹 🇱🇺 🇱🇻 🇱🇾 🇲🇦 🇲🇨 🇲🇩 🇲🇪 🇲🇫 🇲🇬 🇲🇭 🇲🇰 🇲🇱 🇲🇲 🇲🇳 🇲🇴 🇲🇵 🇲🇶 🇲🇷 🇲🇸 🇲🇹 🇲🇺 🇲🇻 🇲🇼 🇲🇽 🇲🇾 🇲🇿 🇳🇦 🇳🇨 🇳🇪 🇳🇫 🇳🇬 🇳🇮 🇳🇱 🇳🇴 🇳🇵 🇳🇷 🇳🇺 🇳🇿 🇴🇲 🇵🇦 🇵🇪 🇵🇫 🇵🇬 🇵🇭 🇵🇰 🇵🇱 🇵🇲 🇵🇳 🇵🇷 🇵🇸 🇵🇹 🇵🇼 🇵🇾 🇶🇦 🇷🇪 🇷🇴 🇷🇸 🇷🇺 🇷🇼 🇸🇦 🇸🇧 🇸🇨 🇸🇩 🇸🇪 🇸🇬 🇸🇭 🇸🇮 🇸🇯 🇸🇰 🇸🇱 🇸🇲 🇸🇳 🇸🇴 🇸🇷 🇸🇸 🇸🇹 🇸🇻 🇸🇽 🇸🇾 🇸🇿 🇹🇦 🇹🇨 🇹🇩 🇹🇫 🇹🇬 🇹🇭 🇹🇯 🇹🇰 🇹🇱 🇹🇲 🇹🇳 🇹🇴 🇹🇷 🇹🇹 🇹🇻 🇹🇼 🇹🇿 🇺🇦 🇺🇬 🇺🇲 🇺🇳 🇺🇸 🇺🇾 🇺🇿 🇻🇦 🇻🇨 🇻🇪 🇻🇬 🇻🇮 🇻🇳 🇻🇺 🇼🇫 🇼🇸 🇽🇰 🇾🇪 🇾🇹 🇿🇦 🇿🇲 🇿🇼 

This dataset contains GDP data for every country from 1999 to 2022 in billions of US dollars.

The dataset comes along with [this notebook](https://www.kaggle.com/alejopaullier/gpd-by-country-1999-2022) where I make a simple EDA with animations, geographical maps and more charts for a better understanding.

- `rows`: country names.
- `columns`: years (1999 to 2022).",.csv
🌎 Location Intelligence Data | From Google Map,1,location-intelligence-data-from-google-map,google_places_data.csv,Apache 2.0,"<h1 style=""font-family: &quot;poppins&quot;; font-weight: bold; color: rgba(0, 128, 0, 1)"">👨‍💻 Author: Azhar Saleem</h1>

[![GitHub](https://img.shields.io/badge/GitHub-Profile-blue?style=for-the-badge&logo=github)](https://github.com/azharsaleem18) [![Kaggle](https://img.shields.io/badge/Kaggle-Profile-blue?style=for-the-badge&logo=kaggle)](https://www.kaggle.com/azharsaleem) [![LinkedIn](https://img.shields.io/badge/LinkedIn-Profile-blue?style=for-the-badge&logo=linkedin)](https://www.linkedin.com/in/azhar-saleem/) 

[![YouTube](https://img.shields.io/badge/YouTube-Profile-red?style=for-the-badge&logo=youtube)](https://www.youtube.com/@AzharSaleem19) [![Facebook](https://img.shields.io/badge/Facebook-Profile-blue?style=for-the-badge&logo=facebook)](https://www.facebook.com/azhar.saleem1472/) [![TikTok](https://img.shields.io/badge/TikTok-Profile-black?style=for-the-badge&logo=tiktok)](https://www.tiktok.com/@azhar_saleem18) 

[![Twitter/X](https://img.shields.io/badge/Twitter-Profile-blue?style=for-the-badge&logo=twitter)](https://twitter.com/azhar_saleem18) [![Instagram](https://img.shields.io/badge/Instagram-Profile-blue?style=for-the-badge&logo=instagram)](https://www.instagram.com/azhar_saleem18/) [![Email](https://img.shields.io/badge/Email-Contact%20Me-red?style=for-the-badge&logo=email)](mailto:azharsaleem6@gmail.com)

# Dataset Overview
Welcome to the **Google Places Comprehensive Business Dataset**! This dataset has been meticulously scraped from Google Maps and presents extensive information about businesses across several countries. Each entry in the dataset provides detailed insights into business operations, location specifics, customer interactions, and much more, making it an invaluable resource for data analysts and scientists looking to explore business trends, geographic data analysis, or consumer behaviour patterns.

## Key Features

- **Business Details**: Includes unique identifiers, names, and contact information.
- **Geolocation Data**: Precise latitude and longitude for pinpointing business locations on a map.
- **Operational Timings**: Detailed opening and closing hours for each day of the week, allowing analysis of business activity patterns.
- **Customer Engagement**: Data on review counts and ratings, offering insights into customer satisfaction and business popularity.
- **Additional Attributes**: Links to business websites, time zone information, and country-specific details enrich the dataset for comprehensive analysis.

## Potential Use Cases

This dataset is ideal for a variety of analytical projects, including:
- **Market Analysis**: Understand business distribution and popularity across different regions.
- **Customer Sentiment Analysis**: Explore relationships between customer ratings and business characteristics.
- **Temporal Trend Analysis**: Analyze patterns of business activity throughout the week.
- **Geospatial Analysis**: Integrate with mapping software to visualise business distribution or cluster businesses based on location.

## Dataset Structure

The dataset contains 46 columns, providing a thorough profile for each listed business. Key columns include:

- `business_id`: A unique Google Places identifier for each business, ensuring distinct entries.
- `phone_number`: The contact number associated with the business. It provides a direct means of communication.
- `name`: The official name of the business as listed on Google Maps.
- `full_address`: The complete postal address of the business, including locality and geographic details.
- `latitude`: The geographic latitude coordinate of the business location, useful for mapping and spatial analysis.
- `longitude`: The geographic longitude coordinate of the business location.
- `review_count`: The total number of reviews the business has received on Google Maps.
- `rating`: The average user rating out of 5 for the business, reflecting customer satisfaction.
- `timezone`: The world timezone the business is located in, important for temporal analysis.
- `website`: The official website URL of the business, providing further information and contact options.
- `category`: The category or type of service the business provides, such as restaurant, museum, etc.
- `claim_status`: Indicates whether the business listing has been claimed by the owner on Google Maps.
- `plus_code`: A short code representing the area where the business is located, used for addressing without a street address.
- `google_rating`: Another field for the business's average rating, possibly redundant with `rating`.
- `user_ratings_total`: An alternative field for the total number of ratings, similar to `review_count`.

### Operational Hours by Day
Each day is split into three parts: morning, afternoon, and evening. The operational status during these times is represented as binary flags (0 or 1):
- `Monday_morning`: Indicates if the business is operational Monday morning.
- `Monday_afternoon`: Indicates if the business is operational Monday afternoon.
- `Monday_evening`: Indicates if the business is operational Monday evening.
- `Tuesday_morning`, `Tuesday_afternoon`, `Tuesday_evening`: Similar fields for Tuesday.
- `Wednesday_morning`, `Wednesday_afternoon`, `Wednesday_evening`: Similar fields for Wednesday.
- `Thursday_morning`, `Thursday_afternoon`, `Thursday_evening`: Similar fields for Thursday.
- `Friday_morning`, `Friday_afternoon`, `Friday_evening`: Similar fields for Friday.
- `Saturday_morning`, `Saturday_afternoon`, `Saturday_evening`: Similar fields for Saturday.
- `Sunday_morning`, `Sunday_afternoon`, `Sunday_evening`: Similar fields for Sunday.

### Additional Columns
- `geo_cluster`: A clustering identifier used to group similar businesses based on geographic or other clustering algorithms.
- `country`: The country where the business is located, important for regional analysis.


## Get Started!

Dive into this dataset to uncover hidden patterns, build predictive models, or explore the fascinating world of businesses as presented through Google Maps data. Whether you're a seasoned data scientist or a curious analyst, this dataset provides the tools to start your next data project!
",.csv
🌏 Countries- Intermediate 🗃️ Dataset,1,countries-intermediate-dataset,Country_Data.csv,other,"""Understanding Global Socioeconomic Dynamics: Exploring a Kaggle Dataset""

This dataset provides a comprehensive view of various socioeconomic indicators across different countries. It includes data on child mortality rates, export and import figures, healthcare expenditures, income levels, inflation rates, life expectancy, fertility rates, and Gross Domestic Product (GDP). Analyzing this dataset can offer insights into the interplay between economic factors, public health, and demographic trends on a global scale.",.csv
🌟Shining Bright | Illuminating Trends of Alibaba,1,baba-dat,baba_stock_data.csv,Apache 2.0,"## 🌟Shining Bright | Illuminating Trends of Alibaba
from 2022 to 2024 
### Columns:


1. **Date**: The date of the stock data.
2. **Open**: The opening price of the stock on that date.
3. **High**: The highest price of the stock during the trading day.
4. **Low**: The lowest price of the stock during the trading day.
5. **Close**: The closing price of the stock on that date.
6. **Adj Close**: The adjusted closing price of the stock,
",.csv
🌳 Global Forest Insights 1990-2020 | FAO,1,global-forest-insights-1990-2020-fao,Forest_Area.csv,other,"

### Overview:
Explore the dynamic landscape of global forests from 1990 to 2020. This compact dataset, derived from FAO's comprehensive assessments, provides a detailed view of forest areas across 236 countries and territories, highlighting changes over three decades.

### Data Science Applications:
Ideal for environmental analyses, trend spotting, and policy impact studies, this dataset offers a foundation for machine learning models predicting deforestation or reforestation trends, despite its small size.

### Column Descriptors:
- **Country and Area**: Name of the country or region.
- **Forest Area (1990-2020)**: Forest coverage in 1000 ha across different years.
- **Total Land Area (2020)**: Total land area in 1000 ha.
- **Forest Proportion (%)**: Forest area as a percentage of total land area.
- **Deforestation Rate**: Change in forest area over time.
- **Area Affected by Fire**: Forest area impacted by fires in 2015.

### Ethical Considerations:
This dataset is ethically sourced from the United Nations' FAO Global Forest Resources Assessment 2020, ensuring credible and responsible data usage.

### Acknowledgments:
Data courtesy of the FAO Global Forest Resources Assessments 2020. For more detailed insights and methodologies, visit [FAO's official website](http://www.fao.org/forest-resources-assessment) and the referenced DOI: [10.4060/ca9825en](https://doi.org/10.4060/ca9825en).
",.csv
🍅Price of Agricultural Commodities in India,1,current-daily-price-of-various-commodities-india,Price_Agriculture_commodities_Week.csv,Attribution 4.0 International (CC BY 4.0),"# Overview
&gt; The data refers to Daily prices of various commodities in India like Tomato, Potato, Brinjal, Wheat etc. It has the wholesale maximum price, minimum price and modal price on daily basis. the prices in the dataset refer to the wholesale prices of various commodities per quintal (100 kg) in Indian rupees. The wholesale price is the price at which goods are sold in large quantities to retailers or distributors.

.

# Features of the dataset include:

&gt;- **State**: The state in India where the market is located.
- **District**: The district in India where the market is located.
- **Market**: The name of the market.
- **Commodity**: The name of the commodity.
- **Variety**: The variety of the commodity.
- **Grade**: The grade or quality of the commodity.
- **Min Price**: (INR) The minimum wholesale price of the commodity on a given day, per quintal (100 kg).
- **Max Price**: (INR) The maximum wholesale price of the commodity on a given day, per quintal (100 kg).
- **Modal Price**: (INR) The most common or representative wholesale price of the commodity on a given day, per quintal (100 kg).

&gt;1 INR = 0.012 USD (as on 17 August, 2023)



# Use Cases

&gt;**Market analysis**: You can use this dataset to analyze trends and patterns in the wholesale prices of various commodities across different markets in India. This can help you understand factors that affect prices, such as supply and demand, seasonality, and market conditions.
**Commodity recommendation**: Develop recommender systems that suggest the best markets or commodities for farmers or traders to sell or buy based on their location, preferences, and market conditions.

<br>
*Licensed under the Government Open Data License - India (GODL) https://data.gov.in/government-open-data-license-india*

# Feel free to download the data and use it in your work. I will wait for interesting notebooks from your side. Thank you

",.csv
🍌 | Banana Quality,1,banana,banana_quality.csv,Apache 2.0,"![Bananas!](https://github.com/l3LlFF/kaggle/blob/main/datasets/banana_quality/banana_quality.jpeg?raw=true)

## Content 

Tabular dataset contains numerical information about bananas of different quality (size, weight, sweetness, softness, harvest time, ripeness, acidity, quality).

## Columns

- `Size` - size of fruit
- `Weight` - weight of fruit
- `Sweetness` - sweetness of fruit
- `Softness` - softness of fruit
- `HarvestTime` - amount of time passed from harvesting of the fruit
- `Ripeness` - ripness of fruit
- `Acidity` - acidity of fruit
- `Quality` - quality of fruit",.csv
🎥 MovieLens Small: Ratings (1995-2019),1,movielens-25m-ratings-1995-2019,ratings.csv,other,"🔍 Overview:
This dataset is part of the MovieLens Latest Datasets. It includes 100,000 ratings on 9,000 movies by 600 users, last updated in September 2018. It is designed for dynamic exploration and testing of machine learning models, particularly suitable for those interested in developing or testing recommender systems. This dataset provides a snapshot of user interactions with movies, ideal for academic purposes and casual experimentation in data science projects.

✨Conditions of Use:
- Research Use Only: The dataset may be used for any research purposes under the condition that it is not used for commercial or revenue-bearing purposes without explicit permission from a faculty member of the GroupLens Research Project at the University of Minnesota.
- No Endorsement: Users may not state or imply any endorsement from the University of Minnesota or the GroupLens Research Group.
- Mandatory Citation: Users must acknowledge the use of the dataset in any publications that result from the use of the data set, by citing:
F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS), 5, 4: 19:1–19:19. DOI
- No Redistribution: The dataset can be redistributed, including transformations, as long as it is distributed under these same license conditions.
- Disclaimer of Liability: Neither the University of Minnesota, its affiliates, nor employees are liable for any damages arising out of the use or inability to use the dataset (including but not limited to loss of data or data being rendered inaccurate).",.csv
🎨 WikiArt | All images (120k+) ,1,-wikiart-all-images-120k-link,wikiart_scraped.csv,ODbL-1.0,"# Context
WikiArt images links, scraped from [this page](https://www.wikiart.org/en/paintings-by-style)
Link example: [Mona Lisa](https://uploads8.wikiart.org/00339/images/leonardo-da-vinci/mona-lisa-c-1503-1519.jpg)
Useful for GANs -&gt; art images generation 

# Content
5 columns: Style, Artwork Name, Artist, Date, Link
124 170 rows -&gt; 116 667 unique rows

# Infos
- Maximum number of images per style with scrolling: 3600
- 71 lazy-loadings (just like NaN)",.csv
🏏 IPL Orange Cap Champions Dataset (2008-2023),1,ipl-orange-cap-champions-dataset-2008-2024,combined_ipl_stats.csv,CC0-1.0,"Dive into the thrilling world of IPL cricket with our comprehensive Orange Cap Champions Dataset, spanning from 2008 to 2023! 🏆 This dataset captures the top performances by batsmen each season, offering a detailed breakdown of matches played, innings, not outs, total runs, highest scores, averages, balls faced, strike rates, centuries, half-centuries, fours, and sixes. Perfect for cricket fans, sports analysts, and data enthusiasts looking to explore trends, player performances, and the evolving dynamics of T20 cricket. Whether you're crafting predictive models, writing insightful articles, or simply indulging in cricket statistics, this dataset serves as your ultimate IPL resource. Get your copy today and start exploring the statistical journey of IPL's finest hitters! 📊📈",.csv
🏗️Construction Investment - 💰Economics,1,construction-investment-amount-in-japan,Construction_investment_amount_in_japan.csv,DbCL-1.0,"## The amounts of construction investment in Japan for 60 years from 1960.

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F2993575%2F661ca6037a56a29ca6ec0b7a3db3bd82%2F2023-12-13%20190921.png?generation=1702462199239583&alt=media)
The amounts are divided into who and what purposes as each column such like ""Building Repairs by Government""

### Files
`Construction_investment_amount_in_japan.csv`  

### Data source  
[Japanese Government Statistics Portal](https://www.e-stat.go.jp/)
",.csv
🏙 Dubai Real Estate Sales Insights | UAE 🇦🇪 🏠 ,1,dubai-real-estate-sales-insights,bayut_selling_properties.csv,Apache 2.0,"## Dubai, UAE Real Estate Market Dataset
<h1 style=""font-family: &quot;poppins&quot;; font-weight: bold; color: rgba(0, 128, 0, 1)"">👨‍💻 Author: Azhar Saleem</h1>

[![GitHub](https://img.shields.io/badge/GitHub-Profile-blue?style=for-the-badge&logo=github)](https://github.com/azharsaleem18) [![Kaggle](https://img.shields.io/badge/Kaggle-Profile-blue?style=for-the-badge&logo=kaggle)](https://www.kaggle.com/azharsaleem) [![LinkedIn](https://img.shields.io/badge/LinkedIn-Profile-blue?style=for-the-badge&logo=linkedin)](https://www.linkedin.com/in/azhar-saleem/) 

[![YouTube](https://img.shields.io/badge/YouTube-Profile-red?style=for-the-badge&logo=youtube)](https://www.youtube.com/@AzharSaleem19) [![Facebook](https://img.shields.io/badge/Facebook-Profile-blue?style=for-the-badge&logo=facebook)](https://www.facebook.com/azhar.saleem1472/) [![TikTok](https://img.shields.io/badge/TikTok-Profile-black?style=for-the-badge&logo=tiktok)](https://www.tiktok.com/@azhar_saleem18) 

[![Twitter/X](https://img.shields.io/badge/Twitter-Profile-blue?style=for-the-badge&logo=twitter)](https://twitter.com/azhar_saleem18) [![Instagram](https://img.shields.io/badge/Instagram-Profile-blue?style=for-the-badge&logo=instagram)](https://www.instagram.com/azhar_saleem18/) [![Email](https://img.shields.io/badge/Email-Contact%20Me-red?style=for-the-badge&logo=email)](mailto:azharsaleem6@gmail.com)


# Dataset Description

This comprehensive dataset provides an exhaustive snapshot of property listings for sale across the United Arab Emirates, including major cities like Dubai, Abu Dhabi, and Al Ain. Sourced from Bayut.com, this dataset serves as an invaluable resource for Data Scientists, Real Estate Analysts, Urban Planners, and Developers keen on exploring real estate market dynamics, price fluctuations, and development trends in the UAE.

## Dataset Overview

The dataset contains over 41,000 entries, each representing a unique property for sale. It includes detailed information such as:

- **Price**: Listing price of the property in AED.
- **Type**: Specifies the property type, such as Apartment, Townhouse, etc.
- **Beds**: Number of bedrooms, with '0' indicating a studio flat.
- **Baths**: Number of bathrooms.
- **Address**: Full address of the property, providing insights into its precise location.
- **Furnishing**: Indicates whether the property is furnished or unfurnished.
- **Completion Status**: Current status of the property (Ready, Off-Plan).
- **Building Name, Area Name, City**: Provide contextual location details.
- **Year of Completion**: Year when the property was completed or is expected to be completed.
- **Total Floors, Parking Spaces, Building Area**: Key features of the property's building.
- **Latitude, Longitude**: Geographic coordinates for more refined location analysis.
- **Purpose**: Intended purpose of the listing, consistently noted as 'For Sale'.

## Usage

This dataset is ideal for a variety of applications, including:

- **Market Analysis**: Analyze trends in property prices and types across different regions.
- **Predictive Modeling**: Develop machine learning models to predict property prices or to classify types of properties based on their features.
- **Urban Development Studies**: Examine property distribution and characteristics to inform urban planning and development strategies.
- **Comparative Analysis**: Compare properties across different cities and districts to identify investment opportunities or to study market behavior.

## Data Accessibility

This dataset is publicly available and well-suited for anyone interested in conducting detailed analyses of the UAE real estate market, from academic researchers to industry professionals.

Feel free to dive into this dataset to unlock comprehensive insights into the vibrant and diverse property market of the UAE, supporting a wide range of real estate, economic, and geographic studies.",.csv
🏙️ Malaysian Condominium Prices Data,1,raw-malaysian-housing-prices-data,houses.csv,CC-BY-NC-SA-4.0,"Inspired by the quintessential [House Prices Starter Competition](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques) and the popular [Melbourne Housing Dataset](https://www.kaggle.com/datasets/dansbecker/melbourne-housing-snapshot), this dataset captures 4K+ condominium unit listings on the Malaysian housing website [mudah.my](https://www.mudah.my/). 

Like the above datasets, your job is to predict the house prices given certain parameters.

The data was scraped directly from the website using [this data collection notebook](https://www.kaggle.com/code/mcpenguin/malaysian-condominium-prices-data-collection). I might adapt the code to include houses as well in the future, but scraping the data takes a while due to having to wait for the website to load and having to timeout to account for CloudFlare's protections.

**Note:** This data is a lot less clean and organized than the data in the two datasets mentioned above. However, this is a good opportunity to practice data cleaning techniques, as this is something that is often overlooked on Kaggle. That being said, I made a [starter notebook](https://www.kaggle.com/code/mcpenguin/malaysian-condo-prices-data-cleaning) that goes through the data cleaning steps and outputs a fairly cleaned version of the dataset.

## Data Description

- `description`: The full (unfiltered) description for the unit listing.
- `Ad List`: The ID of the listing on the website.
- `Category`: The category of the listing. It will most likely be `Apartment / Condominium`.
- `Facilities`: The facilities that the apartment has, in a comma-separated list.
- `Building Name`: The name of the building.
- `Developer`: The developer for the building.
- `Tenure Type`: The type of tenure for the building.
- `Address`: The address of the building. You can refer to [this link](https://ling-app.com/ms/malay-addresses/#:~:text=Generally%2C%20a%20Malaysian%20address%20is,line%201%20and%20line%202.) for a description of what Malaysian addresses look like.
- `Completion Year`: The completion year of the building. If the building is still under construction, this is listed as `-`.
- `# of Floors`: The number of floors in the building.
- `Total Units`: The total number of units in the building.
- `Property Type`: The type of property.
- `Bedroom`: The number of bedrooms in the unit.
- `Bathroom`: The number of bathrooms in the unit.
- `Parking Lot`: The number of parking lots assigned to the unit, if any.
- `Floor Range`: The floor range for the building.
- `Property Size`: The size of the unit.
- `Land Title`: The title given to the land. This [link](https://properly.com.my/blog/a-guide-on-land-titles/) explains what land titles are.
- `Firm Type`: The type of firm who posted the listing.
- `Firm Number`: The ID of the firm who posted the listing.
- `REN Number`: The REN number of the firm who posted the listing. Refer to [this link](https://www.propertyguru.com.my/property-guides/how-to-check-ren-rea-number-property-agent-32516) for what REN numbers are.
- `price`: The price of the unit. This is what you are trying to predict.
- `Nearby School/School`: If there is a nearby school to the unit, which school it is.
- `Park`: If there is a nearby park to the unit, which park it is.
- `Nearby Railway Station`: If there is a nearby railway station to the unit, which railway station it is.
- `Bus Stop`: If there is a nearby bus stop to the unit, which station it is.
- `Nearby Mall/Mall`: If there is a nearby mall to the unit, which mall it is.
- `Highway`: If there is a nearby highway to the unit, which highway it is.",.csv
🏙️Discover Perfect ride:OLXScooty & Scooters🛵 🛴,1,discover-perfect-rideolxscooty-and-scooters,olx_scooters_data_web_3.csv,Apache 2.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F17226110%2F5f8e7dd47c4353bc25458cab39de9733%2F_9306befe-cf9f-4faa-b760-4640c08e48a3%20(1).jpg?generation=1715683141088324&alt=media)
Hi welcome to OLX Scooty & Scooters perfect ride Dataset
In this Dataset we delve deep into OLX scooties and scooters and explore the various aspects such as Title, pricing trends, locations, peak buying times of them.
By using this Dataset we can gain the comprehensive understanding about the Business in the Transportation sector.
The Individuals who can buy and sell the scooty&scooters can gain insights by exploring this Dataset

### **`About Columns:`**

`Title:` Name of the Olx scooty and scooters
`Price:` Price of the OLX scooty and Scooters

`Location:` specifies Name of the city at which the scooty&scooters are present

`Time:` The time at which scooty&scooters was listed for selling
",.csv
🏥Nation Medical Expenditure - 🩺Medical,1,nation-medical-expenditure-in-japan,National_Medical_Expenditure.csv,DbCL-1.0,"### Nation Medical Expenditure in Japan

National medical expenses are estimates of the costs required to treat injuries and illnesses that may be covered by health insurance at medical institutions, etc. within the fiscal year. It is an important indicator in insurance systems and medical economics.
National medical expenses provide the results of national medical expenses by system classification, financial resources, treatment type, age group, and gender, medical treatment and medical expenses by injury and disease classification, national medical expenses per capita, and national medical expenses by prefecture.
Japan is implementing a variety of cost-optimizing measures in order to suppress excessive increases in medical costs. Among them are Medical Cost Optimization Plans, which set out general targets and medical cost estimation methodology. In line with the targets and methods indicated in the National Medical Cost Optimization Basic Policies, each prefectural(regional) government must also prepare its own Medical Cost Optimization Plan.",.csv
🏦💳👨‍🦳👩‍ Credit scoring for borrowers in bank,1,bank-credit-scoring,bank.csv,Attribution 4.0 International (CC BY 4.0),"Dataset may have originated from an outside source *Bank Marketing. UC Irvine*
(https://archive.ics.uci.edu/dataset/222/bank+marketing)

# Split dataset into train and test and clean it from null values
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F10074224%2Fe9d5e3d04006047c5b0b770ef0b12b74%2FCibil-Score-1.jpg?generation=1690796339001538&alt=media)",.csv
🏫 Student Grades - Intermediate 🗃️ Dataset,1,student-grades-intermediate-dataset,Student_Grades.csv,other,"📊 The dataset comprises various attributes related to student performance, including hours of study, practice, teamwork involvement, midterm exam scores, final exam scores, overall scores, and corresponding grades. It offers insights into the factors influencing academic achievement and provides a basis for analyzing the correlations between study habits, collaborative activities, and examination outcomes.",.csv
🏫 US Colleges and Universities,1,us-colleges-and-universities,us-colleges-and-universities.csv,CC0-1.0,"# Context
The Colleges and Universities feature class/shapefile is composed of all Post Secondary Education facilities as defined by the Integrated Post Secondary Education System (IPEDS, http://nces.ed.gov/ipeds/), National Center for Education Statistics (NCES, https://nces.ed.gov/), US Department of Education for the 2018-2019 school year. Included are Doctoral/Research Universities, Masters Colleges and Universities, Baccalaureate Colleges, Associates Colleges, Theological seminaries, Medical Schools and other health care professions, Schools of engineering and technology, business and management, art, music, design, Law schools, Teachers colleges, Tribal colleges, and other specialized institutions. Overall, this data layer covers all 50 states, as well as Puerto Rico and other assorted U.S. territories. This feature class contains all MEDS/MEDS+ as approved by the National Geospatial-Intelligence Agency (NGA) Homeland Security Infrastructure Program (HSIP) Team. Complete field and attribute information is available in the ”Entities and Attributes” metadata section. Geographical coverage is depicted in the thumbnail above and detailed in the ""Place Keyword"" section of the metadata. This feature class does not have a relationship class but is related to Supplemental Colleges. Colleges and Universities that are not included in the NCES IPEDS data are added to the Supplemental Colleges feature class when found. This release includes the addition of 175 new records, the removal of 468 no longer reported by NCES, and modifications to the spatial location and/or attribution of 6682 records.

# Acknowlegement
Foto von <a href=""https://unsplash.com/de/@leonjaywu?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Leon Wu</a> auf <a href=""https://unsplash.com/de/fotos/drei-madchen-in-abschlusskleidern-halten-ihre-mutzen-in-die-luft-LLfRMRT-9AY?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv
🐧 Palmer Penguins for binary classification,1,palmer-penguins-for-binary-classification,penguins_binary_classification.csv,Attribution 4.0 International (CC BY 4.0),"This dataset, derived from the [Palmer's Penguins dataset](https://allisonhorst.github.io/palmerpenguins/articles/intro.html#meet-the-penguins), is intended to be a valuable resource for beginners in logistic regression. 

The idea is to classify Gentoo and Adelie penguins using lgistic regression but you can learn something about them too!! 🙂:

### Gentoo Penguins (Pygoscelis papua)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F3880940%2F544281eed175e6f70787192cdf2c90ac%2Fgentoo.jpeg?generation=1701019777180956&alt=media)
- **Habitat:** Predominantly found on the Antarctic Peninsula and nearby islands.
- **Physical Characteristics:** Recognizable by their bright orange-red bills and white stripe extending across the top of their heads. They are among the larger penguin species.
- **Diet:** Primarily feed on krill, though their diet also includes fish and squid.
- **Behavior:** Known for their fast swimming ability and long, deep dives while foraging.

### Adelie Penguins (Pygoscelis adeliae)
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F3880940%2Faddfdad600743788f1cd44d3f474a5f3%2Fa-pair-of-adelie-penguins-photo-from-june-1984-all-hands-magazine-d14147-1024.jpeg?generation=1701019849646979&alt=media)
- **Habitat:** Widely distributed along the entire Antarctic coast.
- **Physical Characteristics:** Smaller than Gentoo penguins, with distinctive black and white plumage and a blue-black bill.
- **Diet:** Mainly eat krill, along with some fish and squid.
- **Behavior:** Highly social and known for their loud calls and aggressive behavior during the breeding season.

The dataset was collected in Palmer Archipelago:
A group of islands off the northwestern coast of the Antarctic Peninsula. Home to a diverse range of wildlife, including several species of penguins, seals, and seabirds.
This archipielago is characterized by cold temperatures, strong winds, and significant ice cover, although it's one of the most rapidly warming areas on Earth.

## Usage Scenarios for the Dataset
**Educational Use:** Ideal for teaching logistic regression in data science and statistics courses. Students can learn how to handle categorical and numerical data, as well as binary classification.
   
**Ecological Research:** Researchers can use the dataset to study penguin population dynamics, diet preferences, and the impact of climate change on habitat and species distribution.

**Conservation Efforts:** Conservationists could analyze trends in penguin populations and health indicators (like body mass) to inform protection strategies.

**Data Visualization Projects:** The dataset is suitable for creating visual representations of data, such as scatter plots or heat maps, to illustrate differences between species or changes over time.

**Machine Learning Model Development:** Beginners in machine learning can use this dataset to build and validate logistic regression models, before moving on to more complex algorithms.

**Statistical Analysis:** The dataset can be used to perform statistical tests to understand correlations between different physical characteristics of penguins and their environment or diet.

This dataset provides a unique opportunity for a wide range of users, from educators and students to researchers and conservationists, to explore and understand the fascinating world of these Antarctic penguins.",.csv
👔 Shein Men’s 1K Fashion Insights,1,shein-mens-1k-fashion-insights,shein_mens_fashion.csv,ODC Attribution License (ODC-By),"**Dataset Overview:** This dataset, titled ""👔 Shein Men's 1K Fashion Insights"", provides a comprehensive look into the fashion trends of Shein's men's apparel. It contains 1000 entries, each representing a unique product with detailed attributes.

**Data Science Applications:** This dataset is a valuable resource for data scientists interested in fashion trends, consumer behavior, and retail analytics. It can be used for exploratory data analysis, trend forecasting, customer segmentation, and recommendation systems.

**Column Descriptors:** The dataset includes columns such as 'product_id', 'sku', 'url', 'title', 'color', 'sale_price', 'retail_price', 'discount_percentage', 'category_name', 'category_id', 'description', 'reviews_count', and 'average_rating'. Each column provides specific information about the product, from its ID and SKU to its color, price details, category, and customer reviews.

**Ethically Mined Data:** The data has been ethically mined, ensuring respect for privacy norms and adherence to data protection regulations. No personal customer information is included in this dataset.

**Acknowledgements:** We extend our gratitude to Shein for making their product data accessible, and to Kaggle for providing a platform for sharing and exploring such datasets. Their contributions to the data science community are invaluable. 

Please note that this description is intended to be a concise overview. For a more detailed analysis, please refer to the dataset directly.",.csv
👩‍🏫 Student Scores - Simple 🗃️ Dataset,1,student-scores-simple-dataset,student_scores.csv,Apache 2.0,"This dataset provides invaluable insights into the relationship between students' study hours and their academic performance. Comprising just two columns, it captures the essence of diligent study efforts and their corresponding impact on student scores. The first column meticulously records the number of hours each student dedicated to their studies, offering a granular view of their study habits. The second column, equally significant, portrays the outcomes of these hours in the form of student scores. With a simple yet profound focus on these two key variables, the dataset serves as a fundamental resource for uncovering patterns, correlations, and strategies that can significantly influence students' educational success. Whether you are an educator, researcher, or student seeking to enhance your learning strategies, this dataset offers a wealth of possibilities for exploration and analysis.",.csv
👮The Number of Crimes - 🗞️Social Issues,1,crime-numbers-in-japan-by-2016,crime_numbers_in_japan.csv,DbCL-1.0,"## The number of reported cases and cleared cases by crime categories in Japan from 2006 to 2016.  
  
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F2993575%2F57d7a551a24bc7b1566fe16c0093fbfc%2F2023-12-13%20193002.png?generation=1702463439057680&alt=media)
  
### Files
`crime_numbers_in_japan.csv`  

### Data source  
[Japanese Government Statistics Portal](https://www.e-stat.go.jp/)
",.csv
👮‍♂️🔫US Police Shootings from 2015- Sep 2022,1,us-police-shootings-from-20152022,US Police shootings in from 2015-22.csv,U.S. Government Works,"**About Dataset:**

## Don't Forget to Upvote the dataset.

![](https://upload.wikimedia.org/wikipedia/commons/thumb/2/2f/Police_killings_in_the_USA_in_2018.svg/220px-Police_killings_in_the_USA_in_2018.svg.png)

Below are lists of people killed by law enforcement in the United States, both on duty and off duty. Although Congress instructed the Attorney General in 1994 to compile and publish annual statistics on police use of excessive force, this was never carried out, and the Federal Bureau of Investigation does not collect these data.


Deaths by age group in 2015, according to The Counted

Column Details:

|COLUMN NAME   |  INFO |
| --- | --- |
|id   | SERIAL NO  |
|name | NAME OF VICTIM THAT GOT SHOT OR TASERED BY POLICE|
|date | DATE IN WHICH HE GOT VICTIMIZED|
|manner_of_death | TYPE OF MANNER IN WHICH HE DIED  |
|armed | THE VICTIM WAS ARMED OR NOT  |
|age | AGE OF VICTIM  |
|gender | GENDER OF VICTIM |
|race | RACE,ETHICITY OF VICTIM  |
| city | CITY IN THE USA IN which he/she DIED  |
|state | STATE IN THE USA IN which he/she DIED |
|signs_of_mental_illness   | VICTIM SHOWS SIGN OF ILLNESS  |
|threat_level   | LEVEL OF THREAT ON POLICE |
|flee  | VICTIM FLEE OR DIE |
|body_camera   | BODY CAMERA WAS ON POLICE OR NOT  |
|longitude   | LONGITUDE OF LOCATION |
|latitude   |   LATITUDE OF LOCATION  |
|is_geocoding_exact  |    LOCATION AVAILABLE  EXACT OR NOT     |


TO KNOW MORE FROM WIKIPEDIA :https://en.wikipedia.org/wiki/Lists_of_killings_by_law_enforcement_officers_in_the_United_States",.csv
👵🏻 Japan life expectancy,1,japan-life-expectancy,Japan_life_expectancy.csv,CC0-1.0,"**Japan** stands out as one of the countries with the **highest population longevity**, from a global perspective 🌏, having the highest estimated life expectancy at birth of 84.26 years. The longevity of Japanese women is notable, ranking first worldwide with a life expectancy of 86.94 years, while Japanese men rank second with 81.49 years [(World Health Organization, 2020)](https://www.who.int/data/gho/data/indicators/indicator-details/GHO/life-expectancy-at-birth-(years)). Japan's high life expectancy can be attributed to various factors. Technological progress, especially in the medical field, along with the country's accelerated economic development, in recent decades, have inevitably led to an increase in the average life expectancy of the population.

The dataset contains information about life expectancy and economic&social variables for Japan's prefectures as of 2020.
- Life expectancy data source: [Ministry of Health, Labour and Welfare, Japan](https://www.mhlw.go.jp/toukei/saikin/hw/life/tdfk20/dl/tdfk20-10.pdf)
- Independent variables data source: [Japanese Government Statistics](https://www.e-stat.go.jp/en/stat-search/files?page=1&layout=datalist&toukei=00200502&tstat=000001201620&cycle=0&year=20230&month=0&tclass1=000001201621&tclass2val=0)
- Geospatial prefecture data: [GitHub](https://github.com/dataofjapan/land/blob/master/japan.geojson)",.csv
💊 Drug Consumption Classification,1,drug-consumption-classification,drug_consumption.csv,other,"🚨 **Read Attribute Information to understand the column values** 🚨

🚨 **Also check the [starter notebook](https://www.kaggle.com/code/mexwell/starter-notebook-convert-column-values) where I converted the column values into more meaningful values** 🚨

# Context
Database contains records for 1885 respondents. For each respondent 12 attributes are known: Personality measurements which include NEO-FFI-R (neuroticism, extraversion, openness to experience, agreeableness, and conscientiousness), BIS-11 (impulsivity), and ImpSS (sensation seeking), level of education, age, gender, country of residence and ethnicity. All input attributes are originally categorical and are quantified. After quantification values of all input features can be considered as real-valued. In addition, participants were questioned concerning their use of 18 legal and illegal drugs (alcohol, amphetamines, amyl nitrite, benzodiazepine, cannabis, chocolate, cocaine, caffeine, crack, ecstasy, heroin, ketamine, legal highs, LSD, methadone, mushrooms, nicotine and volatile substance abuse and one fictitious drug (Semeron) which was introduced to identify over-claimers. For each drug they have to select one of the answers: never used the drug, used it over a decade ago, or in the last decade, year, month, week, or day. Database contains 18 classification problems. Each of independent label variables contains seven classes: ""Never Used"", ""Used over a Decade Ago"", ""Used in Last Decade"", ""Used in Last Year"", ""Used in Last Month"", ""Used in Last Week"", and ""Used in Last Day"".

### Attribute Information
&gt; **ID:** ID is number of record in original database. Cannot be related to participant. It can be used for reference only.



&gt;**Age:** Age is the age of participant and has one of the values: 

|   Value  |    Meaning   |  Cases  |  Fraction  |
|----------|--------------|---------|------------|
| -0.95197 |    18 - 24   |   643   |   34.11%   |
| -0.07854 |    25 - 34   |   481   |   25.52%   |
|  0.49788 |    35 - 44   |   356   |   18.89%   |
|  1.09449 |    45 - 54   |   294   |   15.60%   |
|  1.82213 |    55 - 64   |   93    |    4.93%   |
|  2.59171 |    65+       |   18    |    0.95%   |


&gt;**Gender:** Gender is gender of participant:

|   Value  |    Meaning   |  Cases  |  Fraction  |
|----------|--------------|---------|------------|
|  0.48246 |    Female    |   942   |   49.97%   |
| -0.48246 |    Male      |   943   |   50.03%   |


&gt; **Education:**  Education is level of education of participant and has one of the values: 

|   Value  |                  Meaning              |  Cases  |  Fraction  |
|----------|:-------------------------------------:|:---------|------------|
| -2.43591 |      Left School Before 16 years      |   28    |    1.49%   |
| -1.73790 |      Left School at 16 years          |   99    |    5.25%   |
| -1.43719 |      Left School at 17 years          |   30    |    1.59%   |
| -1.22751 |      Left School at 18 years          |   100   |    5.31%   |
| -0.61113 | Some College,No Certificate Or Degree |   506   |   26.84%   |
| -0.05921 |    Professional Certificate/ Diploma  |   270   |   14.32%   |
|  0.45468 |            University Degree          |   480   |   25.46%   |
|  1.16365 |              Masters Degree           |   283   |   15.01%   |
|  1.98437 |             Doctorate Degree          |   89    |    4.72%   |



&gt; **Country:** Country is country of current residence of participant and has one of the values:

|   Value  |         Meaning         |  Cases  |  Fraction  |
|----------|-------------------------|---------|------------|
| -0.09765 |         Australia       |   54    |   2.86%    |
|  0.24923 |          Canada         |   87    |   4.62%    |
| -0.46841 |        New Zealand      |    5    |   0.27%    | 
| -0.28519 |          Other          |  118    |   6.26%    | 
|  0.21128 |   Republic of Ireland   |   20    |   1.06%    |
|  0.96082 |            UK           |  1044   |   55.38%   | 
| -0.57009 |           USA           |   557   |   29.55%   |



&gt; **Ethnicity:** Ethnicity is ethnicity of participant and has one of the values: 

|   Value  |         Meaning         |  Cases  |  Fraction  |
|----------|-------------------------|---------|------------|
| -0.50212 |        Asian            |    26   |   1.38%    |
| -1.10702 |        Black            |    33   |   1.75%    |
|  1.90725 |    Mixed-Black/Asian    |     3   |   0.16%    | 
|  0.12600 |    Mixed-White/Asian    |    20   |   1.06%    |
| -0.22166 |    Mixed-White/Black    |    20   |   1.06%    |
|  0.11440 |         Other           |    63   |   3.34%    |
| -0.31685 |         White           |  1720   |  91.25%    |



&gt; **Nscore:** Nscore is NEO-FFI-R Neuroticism. Neuroticism is one of the Big Five higher-order personality traits in the study of psychology. Individuals who score high on neuroticism are more likely than average to be moody and to experience such feelings as anxiety, worry, fear, anger, frustration, envy, jealousy, guilt, depressed mood, and loneliness. Possible values are presented in table below:   

|Nscore|  Value | Nscore|  Value | Nscore|  Value | Nscore|  Value | 
|------|--------|-------|--------|-------|--------|-------|--------|
|  12  |-3.46436|  24   |-1.32828|  36   |0.04257 |  48   |1.23461 |
|  13  |-3.15735|  25   |-1.19430|  37   |0.13606 |  49   |1.37297 | 
|  14  |-2.75696|  26   |-1.05308|  38   |0.22393 |  50   |1.49158 |
|  15  |-2.52197|  27   |-0.92104|  39   |0.31287 |  51   |1.60383 | 
|  16  |-2.42317|  28   |-0.79151|  40   |0.41667 |  52   |1.72012 |
|  17  |-2.34360|  29   |-0.67825|  41   |0.52135 |  53   |1.83990 |
|  18  |-2.21844|  30   |-0.58016|  42   |0.62967 |  54   |1.98437 |
|  19  |-2.05048|  31   |-0.46725|  43   |0.73545 |  55   |2.12700 |
|  20  |-1.86962|  32   |-0.34799|  44   |0.82562 |  56   |2.28554 |
|  21  |-1.69163|  33   |-0.24649|  45   |0.91093 |  57   |2.46262 |
|  22  |-1.55078|  34   |-0.14882|  46   |1.02119 |  58   |2.61139 |
|  23  |-1.43907|  35   |-0.05188|  47   |1.13281 |  59   |2.82196 |
|   -  |    -   |   -   |    -   |   -   |    -   |  60   |3.27393 |



&gt; **EScore:** Escore (Real) is NEO-FFI-R Extraversion. Extraversion is one of the five personality traits of the Big Five personality theory. It indicates how outgoing and social a person is. A person who scores high in extraversion on a personality test is the life of the party. They enjoy being with people, participating in social gatherings, and are full of energy. Possible values are presented in table below: 

|Escore|  Value | Escore|  Value | Escore|  Value | Escore|  Value | 
|------|--------|-------|--------|-------|--------|-------|--------|
|  16  |-3.27393|   27  |-1.76250|   38  |-0.30033|   49  | 1.45421| 
|  17  |-3.00537|   28  |-1.63340|   39  |-0.15487|   50  | 1.58487| 
|  18  |-3.00537|   29  |-1.50796|   40  | 0.00332|   51  | 1.74091| 
|  19  |-2.72827|   30  |-1.37639|   41  | 0.16767|   52  | 1.93886| 
|  20  |-2.53830|   31  |-1.23177|   42  | 0.32197|   53  | 2.12700|  
|  21  |-2.44904|   32  |-1.09207|   43  | 0.47617|   54  | 2.32338|  
|  22  |-2.32338|   33  |-0.94779|   44  | 0.63779|   55  | 2.57309|  
|  23  |-2.21069|   34  |-0.80615|   45  | 0.80523|   56  | 2.85950|  
|  24  |-2.11437|   35  |-0.69509|   46  | 0.96248|   57  | 2.85950| 
|  25  |-2.03972|   36  |-0.57545|   47  | 1.11406|   58  | 3.00537| 
|  26  |-1.92173|   37  |-0.43999|   48  | 1.28610|   59  | 3.27393|




&gt; **Oscore:** Oscore (Real) is NEO-FFI-R Openness to experience. Openness is one of the five personality traits of the Big Five personality theory. It indicates how open-minded a person is. A person with a high level of openness to experience in a personality test enjoys trying new things. They are imaginative, curious, and open-minded. Individuals who are low in openness to experience would rather not try new things. They are close-minded, literal and enjoy having a routine. Possible values are presented in table below:

|Oscore|  Value | Oscore|  Value | Oscore|  Value | 
|------|--------|-------|--------|-------|--------|
|  24  |-3.27393|   38  |-1.11902|   50  | 0.58331| 
|  26  |-2.85950|   39  |-0.97631|   51  | 0.72330|
|  28  |-2.63199|   40  |-0.84732|   52  | 0.88309| 
|  29  |-2.39883|   41  |-0.71727|   53  | 1.06238| 
|  30  |-2.21069|   42  |-0.58331|   54  | 1.24033| 
|  31  |-2.09015|   43  |-0.45174|   55  | 1.43533| 
|  32  |-1.97495|   44  |-0.31776|   56  | 1.65653| 
|  33  |-1.82919|   45  |-0.17779|   57  | 1.88511| 
|  34  |-1.68062|   46  |-0.01928|   58  | 1.15324| 
|  35  |-1.55521|   47  | 0.14143|   59  | 2.44904| 
|  36  |-1.42424|   48  | 0.29338|   60  | 2.90161| 
|  37  |-1.27553|   49  | 0.44585|  NaN  |  NaN   | 



&gt; **Ascore:**  Ascore(Real) is NEO-FFI-R Agreeableness. Agreeableness is one of the five personality traits of the Big Five personality theory. A person with a high level of agreeableness in a personality test is usually warm, friendly, and tactful. They generally have an optimistic view of human nature and get along well with others. Possible values are presented in table below: 

|Ascore|  Value | Ascore|  Value | Ascore|  Value | 
|------|--------|-------|--------|-------|--------|
|  12  |-3.46436|   34  |-1.34289|   48  | 0.76096| 
|  16  |-3.15735|   35  |-1.21213|   49  | 0.94156| 
|  18  |-3.00537|   36  |-1.07533|   50  | 1.11406| 
|  23  |-2.90161|   37  |-0.91699|   51  | 1.2861 |
|  24  |-2.78793|   38  |-0.76096|   52  | 1.45039| 
|  25  |-2.70172|   39  |-0.60633|   53  | 1.61108| 
|  26  |-2.53830|   40  |-0.45321|   54  | 1.81866| 
|  27  |-2.35413|   41  |-0.30172|   55  | 2.03972| 
|  28  |-2.21844|   42  |-0.15487|   56  | 2.23427| 
|  29  |-2.07848|   43  |-0.01729|   57  | 2.46262| 
|  30  |-1.92595|   44  | 0.13136|   58  | 2.75696| 
|  31  |-1.77200|   45  | 0.28783|   59  | 3.15735| 
|  32  |-1.62090|   46  | 0.43852|   60  | 3.46436| 
|  33  |-1.47955|   47  | 0.59042|  NaN  |  NaN   |



&gt; **Cscore:** Cscore (Real) is NEO-FFI-R Conscientiousness. Conscientiousness is one of the five personality traits of the Big Five personality theory. A person scoring high in conscientiousness usually has a high level of self-discipline. These individuals prefer to follow a plan, rather than act spontaneously. Their methodic planning and perseverance usually makes them highly successful in their chosen occupation. Possible values are presented in table below: 

|Cscore|  Value | Cscore|  Value | Cscore|  Value | 
|------|--------|-------|--------|-------|--------|
|  17  |-3.46436|   32  |-1.25773|   46  | 0.58489| 
|  19  |-3.15735|   33  |-1.13788|   47  | 0.7583 |
|  20  |-2.90161|   34  |-1.01450|   48  | 0.93949| 
|  21  |-2.72827|   35  |-0.89891|   49  | 1.13407| 
|  22  |-2.57309|   36  |-0.78155|   50  | 1.30612| 
|  23  |-2.42317|   37  |-0.65253|   51  | 1.46191| 
|  24  |-2.30408|   38  |-0.52745|   52  | 1.63088| 
|  25  |-2.18109|   39  |-0.40581|   53  | 1.81175| 
|  26  |-2.04506|   40  |-0.27607|   54  | 2.04506| 
|  27  |-1.92173|   41  |-0.14277|   55  | 2.33337| 
|  28  |-1.78169|   42  |-0.00665|   56  | 2.63199|
|  29  |-1.64101|   43  | 0.12331|   57  | 3.00537| 
|  30  |-1.51840|   44  | 0.25953|   59  | 3.46436| 
|  31  |-1.38502|   45  | 0.41594|  NaN  |  NaN   |



&gt; **Impulsive:** Impulsive (Real) is impulsiveness measured by BIS-11. In psychology, impulsivity (or impulsiveness) is a tendency to act on a whim, displaying behavior characterized by little or no forethought, reflection, or consideration of the consequences. If you describe someone as impulsive, you mean that they do things suddenly without thinking about them carefully first. Possible values are presented in table below: 

|Impulsiveness| Cases |  Fraction  | 
|-------------|-------|------------|
|   -2.55524  |   20  |    1.06%   |
|   -1.37983  |  276  |   14.64%   | 
|   -0.71126  |  307  |   16.29%   | 
|   -0.21712  |  355  |   18.83%   | 
|    0.19268  |  257  |   13.63%   | 
|    0.52975  |  216  |   11.46%   | 
|    0.88113  |  195  |   10.34%   | 
|    1.29221  |  148  |    7.85%   | 
|    1.86203  |  104  |    5.52%   | 
|    2.90161  |    7  |    0.37%   | 



&gt; **Sensation:** SS(Real) is sensation seeing measured by ImpSS. Sensation is input about the physical world obtained by our sensory receptors, and perception is the process by which the brain selects, organizes, and interprets these sensations. In other words, senses are the physiological basis of perception. Possible values are presented in table below: 

|      SS     | Cases |  Fraction  | 
|-------------|-------|------------|
|   -2.07848  |   71  |    3.77%   |
|   -1.54858  |   87  |    4.62%   |
|   -1.18084  |  132  |    7.00%   | 
|   -0.84637  |  169  |    8.97%   | 
|   -0.52593  |  211  |   11.19%   | 
|   -0.21575  |  223  |   11.83%   | 
|    0.07987  |  219  |   11.62%   | 
|    0.40148  |  249  |   13.21%   | 
|    0.76540  |  211  |   11.19%   | 
|    1.22470  |  210  |   11.14%   | 
|    1.92173  |  103  |    5.46%   |


&gt; The remaining columns are divided inti 7 classes:

|  Value  |    Description   |
|---------|-------------------------|
|   CL0   |       Never Used        |
|   CL1   |  Used over a Decade Ago |
|   CL2   |    Used in Last Decade  |
|   CL3   |     Used in Last Year   | 
|   CL4   |     Used in Last Month  | 
|   CL5   |     Used in Last Week   | 
|   CL6   |     Used in Last Day    |
",.csv
💡 Worldwide Average IQ Levels 🧠,1,worldwide-average-iq-levels,IQ_level.csv,CC0-1.0,"Explore the ""Worldwide Average IQ Levels and Socioeconomic Factors Dataset"" to gain insights into the intelligence quotient (IQ) levels of different countries and their related socioeconomic factors. 

![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F13571604%2Fcafb91359a30d54df8806c37d39994ff%2FScreenshot%202023-10-15%20030515.png?generation=1697363277060138&alt=media)",.csv
💬 Telegram Spam or Ham,1,telegram-spam-or-ham,dataset.csv,CC0-1.0,"Classify if text is spam or ham. 

[Original Data](https://huggingface.co/datasets/thehamkercat/telegram-spam-ham/blob/dbf0a97b4b8cb0a8223378c85b6fc7e4526d43fb/dataset.csv)

# Acknowlegement

Foto von <a href=""https://unsplash.com/de/@solomin_d?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Dima Solomin</a> auf <a href=""https://unsplash.com/de/fotos/eine-blaue-schaltflache-mit-einem-weissen-pfeil-darauf-4_BbIPL8KOI?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv
💰 Data Science Salary 💰  2021 to 2023,1,data-science-salary-2021-to-2023,Data Science Salary 2021 to 2023.csv,CC0-1.0,"Introducing the Dataset: Data Science Salary Trends 2023

This dataset aims to shed light on the salary trends in the field of Data Science for the years 2021 to 2023. With a focus on various aspects of employment, including work experience, job titles, and company locations, this dataset provides valuable insights into salary distributions within the industry.

Data Fields:
- work_year: Representing the specific year of salary data collection.
- Experience_level: The level of work experience of the employees, categorized as EN (Entry-Level), EX (Experienced), MI (Mid-Level), SE (Senior).
- Employment_type: The type of employment, labelled as FT (Full-Time), CT (Contractor), FL (Freelancer), PT (Part-Time).
- Job_title: The job titles of the employees, such as ""Applied Scientist"", ""Data Quality Analyst""
, etc.
- Salary: The salary figures in their respective currency formats.
- Salary_currency: The currency code representing the salary.
- Salary_in_usd: The converted salary figures in USD for uniform comparison.
- Company_location: The location of the companies, specified as country codes (e.g., ""US"" for the United States and ""NG"" for Nigeria).
- Company_size: The size of the companies, classified as ""L"" (Large), ""M"" (Medium), and ""S"" (Small).

With this dataset, data enthusiasts and analysts can delve into the salary dynamics of Data Science professionals in 2023, identifying trends across different experience levels, job titles, and company sizes. It can be a valuable resource for understanding the economic landscape in the Data Science job market and making informed decisions for both job seekers and employers alike.

**Potential Problem Statements. **
1. Optimal Hiring Decisions: Analyze the dataset to determine the best employment type and experience level for hiring data science professionals for maximum cost-effectiveness.
2. Salary Trends over Time: Utilize the dataset to visualize and interpret data science salary trends from 2021 to 2023.
3. Job Title Recommendation: Recommend suitable job titles for candidates based on their experience level and desired salary range.


Kindly, upvote if you find the dataset interesting. Thank you.
",.csv
💰 Gender Pay Gap - Europe (2010-2021),1,gender-pay-gap-europe-2010-2021,pay_gap_Europe.csv,EU ODP Legal Notice,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F9401378%2F3ed264a08b3bec2ebb008752c72232d3%2Fdescrcare.jpg?generation=1679750241484193&alt=media)

This dataset aims to shed light on **gender equality** 👩‍⚕️👨‍⚕️ in the European labor market by examining the gender pay gap across multiple countries and industries from 2010 to 2021. In addition to pay gap data, the dataset includes information on **GDP per capita, urbanization rates, and economic sector breakdowns**, providing a comprehensive view of the factors that may contribute to gender-based pay disparities. This dataset aims to increase understanding of gender equity issues in the workplace and to promote efforts towards creating more inclusive and equitable societies.


❗**The unadjusted gender pay gap (GPG)** represents the difference between average gross hourly earnings of male paid employees and of female paid employees as a percentage of average gross hourly earnings of male paid employees. ([Eurostat](https://ec.europa.eu/eurostat/cache/metadata/en/earn_grgpg2_esms.htm))",.csv
💳 Credit Card Data- Intermediate 🗃️ Dataset,1,credit-card-data-intermediate-dataset,Customer_Data.csv,other,"The ""Credit Card Clustering Dataset"" provides insights into patterns within credit card usage through clustering analysis. With detailed information on credit card transactions and customer behavior, this dataset enables researchers and analysts to uncover meaningful segments and trends. Ideal for exploring customer segmentation strategies and developing targeted marketing approaches within the credit card industry.",.csv
💳Visa Stock Dataset: Unveiling Market Trends📈,1,visa-stock-dataset-unveiling-market-trends,visa_stock_data.csv,Apache 2.0,"&gt; About dataset

### Visa, Inc. Stock Data

*Source:*
- The data is obtained from Yahoo Finance using the Yfinance Python library.

*Period:*
- Data is collected from January 1, 2020, to January 1, 2023. However, it's important to note that there might be missing data or gaps due to occasional errors during fetching or missing trading days.

*Features:*
1. *Date:* The date of the trading day.
2. *Open:* The price at which the stock first traded upon the opening of the market on that day.
3. *High:* The highest price at which the stock traded during the trading day.
4. *Low:* The lowest price at which the stock traded during the trading day.
5. *Close:* The price at which the stock last traded upon the close of the market on that day.
6. *Volume:* The number of shares traded during the day.
7. *Adjusted Close:* The closing price adjusted for any corporate actions, such as dividends and stock splits, that occurred before the next day's open.
8. *Year:* The year extracted from the date.

*Data Cleaning:*
- Any rows with missing values are dropped to ensure the dataset's integrity and consistency.

*CSV File:*
- The processed dataset is saved to a CSV file named 'visa_stock_data.csv' for further analysis and future reference.

*Purpose:*
- The dataset can be used for various purposes such as:
  - Analyzing Visa's stock performance over the specified period.
  - Studying trends, patterns, and volatility in Visa's stock prices.
  - Building predictive models to forecast Visa's future stock prices.
  - Conducting correlation analysis with other financial instruments or economic indicators.

This dataset provides valuable insights into the historical performance of Visa, Inc. stock, which can aid investors, analysts, and researchers in making informed decisions and conducting in-depth financial analysis.",.csv
📈 Bitcoin Price Dataset: Explore Daily Dynamics!,1,bitcoin-daily,BTC-USD.csv,Apache 2.0,"## About This Dataset 🚀

**Explore the Pulse of Bitcoin!** This meticulously curated dataset offers a detailed view of Bitcoin's USD value, capturing the highs, lows, and everything in between. With data spanning over a decade, analysts, researchers, and enthusiasts can delve into the nuances of market trends, perform predictive analytics, and unearth insights into the cryptocurrency's volatile nature.

### What's Inside? 📊
- **Date:** Track Bitcoin's price movements day by day for precise temporal analysis.
- **Open, High, Low, Close:** Uncover daily trading patterns with detailed price points.
- **Adjusted Close:** Get a more accurate reflection of Bitcoin's closing price, adjusted for external market factors.
- **Volume:** Measure market sentiment and trading intensity with comprehensive volume data.

### Perfect for:
- **Academic Research:** Ideal for econometrics studies, financial models, and cryptocurrency research.
- **Machine Learning Projects:** Ready-to-use data for forecasting models, trend analysis, and pattern recognition.
- **Financial Analysis:** Essential for investors and financial analysts focusing on cryptocurrency markets.

### Get Started with Our Analysis Notebook! 📘✨
Ready to dive deeper? Check out our starter notebook designed to help you kickstart your analysis using this dataset. Whether you're new to data science or an experienced analyst, this notebook will guide you through a comprehensive exploration of Bitcoin's daily prices, equipping you with the tools to start your own analysis.

👉 [Start Analyzing Bitcoin Daily Prices Now!](https://www.kaggle.com/code/pawelkauf/bitcoin-daily-prices-kickstart-your-analysis)

Utilize this dataset as a foundation for your research, analysis, and predictions. Happy exploring!
",.csv
📈 Ethereum Price Dataset: Explore Daily Dynamics!,1,ethereum-price-dataset-explore-daily-dynamics,ETH-USD.csv,Apache 2.0,"## About This Dataset 🚀

**Dive Into the Dynamics of Ethereum!** This expertly crafted dataset provides a thorough view of Ethereum's USD value, tracking the peaks, troughs, and all the fluctuations in between. With comprehensive data on Ethereum's trading history, analysts, researchers, and crypto enthusiasts can explore market trends, engage in predictive analytics, and uncover insights into the cryptocurrency's fluctuating nature.

### What's Inside? 📊
- **Date:** Monitor Ethereum's price movements on a daily basis for precise temporal analysis.
- **Open, High, Low, Close:** Explore daily trading dynamics with detailed price data.
- **Adjusted Close:** Access a more precise measure of Ethereum's closing price, adjusted for external market factors.
- **Volume:** Assess market sentiment and trading activity with extensive volume data.

### Perfect for:
- **Academic Research:** Perfect for econometrics studies, financial modeling, and cryptocurrency investigations.
- **Machine Learning Projects:** Packed with data suitable for forecasting models, trend analysis, and recognizing patterns.
- **Financial Analysis:** Crucial for investors and financial analysts who focus on cryptocurrency markets.

### Get Started with Our Analysis Notebook! 📘✨
Are you ready to explore further? Take a look at our starter notebook designed to launch your analysis of this dataset. Whether you are a newcomer to data science or a seasoned analyst, this notebook will walk you through a detailed examination of Ethereum's daily prices, providing you with the tools to initiate your own studies.

👉 [Start Analyzing Ethereum Daily Prices Now!](https://www.kaggle.com/code/pawelkauf/ethereum-daily-prices-kickstart-your-analysi/notebook)

Leverage this dataset as a basis for your research, analysis, and forecasting endeavors. Enjoy your exploration!",.csv
📈 WMT Stock Data Insights and Trends 📊,1,wmt-stock-data-insights-and-trends,wmt_stock_data.csv,other,"## A Detailed Examination of Netflix's Stock Data from 2023 to the Previous Trading Day

### Overview
This analysis focuses on Netflix Inc. (NFLX) stock performance over the period spanning from January 1, 2023, to the previous trading day. By analyzing daily stock data, we aim to provide insights into Netflix's financial trends, volatility, and factors influencing its stock price over the past year.

### Column Names
1. **Date:** The date of the stock data.
2. **Open:** The opening price of Netflix stock on the given date.
3. **High:** The highest price of Netflix stock during the trading day.
4. **Low:** The lowest price of Netflix stock during the trading day.
5. **Close:** The closing price of Netflix stock on the given date.
6. **Adj Close:** The adjusted closing price of Netflix stock, accounting for any corporate actions such as dividends or stock splits.
7. **Volume:** The trading volume of Netflix stock on the given date.",.csv
📈Diffusion Index - 💰Economics,1,diffusion-index-in-japan,diffusion_index_in_japan.csv,DbCL-1.0,"### Diffusion Index in Japan
The purpose of the Business Watchers Survey is to obtain an accurate and prompt understanding of economic trends in each region with the cooperation of those in a position to observe movements closely related to the local economy, and to provide basic data for making decisions on economic trends.   
The survey is conducted from the 25th of each month to the end of the month among 2,050 respondents in 12 regions of the country, selected from appropriate occupations in industries where they can observe phenomena that sensitively reflect trends in representative economic activity items, such as household trends, business trends and employment.   
The survey items are: the current condition and outlook of the economy (two to three months ahead compared to the current situation).  ",.csv
📈Tesla Ticker | Historical Stock Price Dataset📊 ,1,tesla-stock-insights-and-predictions,tesla_stock_data.csv,Apache 2.0,"### About the Dataset:

- **Title**: Tesla Stock Price Dataset
- **Description**: Explore the fascinating journey of Tesla's stock performance with this comprehensive dataset. It provides a detailed record of daily stock prices, allowing you to delve into the dynamic world of financial markets and uncover valuable insights.
- **Contents**: 
  - Open, high, low, and close prices
  - Trading volume
- **Insights**:
  - Analyze historical trends in Tesla's stock price
  - Forecast future stock price movements
- **Format**: CSV (Comma Separated Values)
- **Size**: Approximately 15 KB
- **Source**: Acquired from the Yahoo Finance library
",.csv
📊 NHANES 2017-2018 Height Weight Data,1,nhanes-2017-2018-height-weight-data,NHANES-2017-2018-height-weight.csv,Attribution 4.0 International (CC BY 4.0),"This is the age, height, and weight data extracted from the NHANES 2017-2018 survey dataset.

# Acknowlegement

Foto von <a href=""https://unsplash.com/de/@siora18?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Siora Photography</a> auf <a href=""https://unsplash.com/de/fotos/selektive-fokusfotografie-von-massbandern-cixohzDpNIo?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv
📊Google Workspace Marketplace Apps Dataset💡📊,1,google-workspace-marketplace-apps-dataset,extract-apps-list-from-google-workspace-marketplace_app-list_captured-list_2024-05-09_769f6211-efe0-475f-b8d8-e156ed3a0a8a.csv,Apache 2.0,"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F17226110%2Fe826a425925813f767aafc3486ea3e2b%2F_3f1d1a16-e462-4c95-a7b6-5fe057bbcaca.jpg?generation=1715345922215493&alt=media)

* This Dataset  comprises List of inventory of Apps that is produced by comprehensive compilation of applications integrated with Google Workspace Marketplace.
* It is a valuable resource for the users to explore the Google workspace Marketplace Apps list and to analyze that which App has highest Rating, Downloads and popularity.
* It is also useful for the developers who can utilized this Dataset to gain the information about the features and characteristics of Top Rating Apps to create new apps or improve existing ones.

## About Columns:
`Position`: The position or rank of the application.
`Name`: The name of the application integrated with Google Workspace Marketplace.
`Publisher`: The entity or company that developed the application.
`Description`: A brief description of the functionality of the application.
`Rating`: The Rating or score given to the application by users.
`Download count`: The total number of downloads or installations of the application.
`Image`: A link of an image  associated with the application
`Link`: A direct link or URL to access the applications",.csv
📝Visa Application by Nationality - 🛩️Traveling,1,visa-issuance-by-nationality-and-region-in-japan,visa_number_in_japan.csv,DbCL-1.0,"
## The number of reported visa application and the place where they are from and the purpose of visiting to Japan from 2006 to 2017.
  
![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F2993575%2Ffcab1a335af4520862db5c88ed18594d%2F2023-12-13%20185629.png?generation=1702461417494756&alt=media)
  
  
### Files
1. Reported numbers of visa application and those purposes   
`visa_number_in_japan.csv`  
  

### Data source  
[Japanese Government Statistics Portal](https://www.e-stat.go.jp/)  ",.csv
📰 Daily Mail Articles and Highlights Dataset📰,1,article,article_highlights.csv,MIT,"```
Welcome to the Daily Mail Articles Dataset! This dataset comprises a collection of 8176 articles scraped from the Daily Mail website (https://www.dailymail.co.uk/home/index.html). Each article is accompanied by highlights, making it ideal for text summarization tasks.
```
# 🔍 About the Dataset:

* Total Articles: 8176
* Data Source: Daily Mail website
* Content: Articles and corresponding highlights
* Purpose: Text summarization, NLP tasks, and more

# 💡 Key Features:

* Article Text: Full content of each article scraped from Daily Mail.
* Highlights: Summaries or key points extracted from each article.
* Variety: Diverse topics and subjects covered in the dataset.
* Scope: Suitable for training and evaluating text summarization models.

# 🎯 Potential Applications:

* Text Summarization: Generate concise summaries of lengthy articles.
* NLP Research: Analyze language patterns and structures in news articles.
* Content Recommendation: Enhance recommendation systems with summarized content.
* Sentiment Analysis: Explore sentiments expressed in articles and highlights.

# Dataset Usage:

* Explore the articles and highlights to understand different writing styles and topics.
* Train machine learning models for text summarization or other NLP tasks.
* Contribute to the research community by developing innovative solutions using this dataset.

# 🌟 Why Use This Dataset?

* Rich Content: Detailed articles provide ample material for summarization.
* Real-world Data: Reflects real news articles and highlights from a popular news source.
* Versatility: Can be used for various NLP tasks beyond text summarization.

# 🚀 Get Started:

* Download the dataset from Kaggle.
* Explore the articles and highlights to familiarize yourself with the data.
* Preprocess the text data and design your text summarization model.
* Train and evaluate your model using this dataset.
* Share your findings and contribute to the NLP community

# 📚 References:

### Daily Mail website: https://www.dailymail.co.uk/home/index.html

```
Let's embark on a journey of text summarization and NLP exploration with the Daily Mail Articles Dataset 📝💬
```







",.csv
📺 Top 1000 Youtubers statistics 📺,1,top1000youtubers,youtubers_df.csv,Community Data License Agreement - Sharing - Version 1.0,"
# **Description**

The dataset, obtained through data extraction from top YouTube streamers using the HypeAuditor platform, contains valuable information related to the presence and performance of these content creators on the world's largest video-sharing platform. Below is a description of each of the variables included in the dataset:


- **Rank**: This variable indicates the position or ranking of the streamer on the list of top YouTube streamers. A lower number signifies a higher ranking.

- **Username**: It is the streamer's username on YouTube, allowing for the unique identification of each content creator.

- **Categories**: Represents the categories in which the streamer has tagged their content. Categories can span a wide variety of topics, including gaming, beauty, fashion, travel, comedy, and more.

- **Subscribers**: Indicates the average number of subscribers the streamer's YouTube channel has. This value represents the regular following of content by the audience.

- **Country**: Country where the content creator is located. This can provide insights into the primary audience of the creator and their base of operations.

- **Visits**: This variable records the average number of accumulated visits to the streamer's channel. It represents the average number of times the creator's videos have been viewed by viewers.

- **Likes**: Indicates the average number of ""Likes"" received on the streamer's videos. ""Likes"" are an engagement metric that shows how many viewers appreciate the content.

- **Comments**: Reflects the average number of comments left on the streamer's videos. Comments are an important form of audience interaction and participation.

- **Links**: Provides links or URLs to the streamer's YouTube channels, allowing direct access to their content.

# **Potential Uses of the Dataset:**

- **Trend Analysis**: The data can be used to identify emerging trends in the most popular content categories and the growth of new streamers on the platform.

- **Audience Study**: It helps in understanding the average geography of the audience and content preferences in different regions worldwide.

- **Marketing Strategy**: Brands and companies can use this data to identify suitable streamers for collaborations and marketing campaigns based on their average performance metrics.

- **Benchmarking**: Streamers can compare their average performance with that of other creators in terms of subscribers, visits, likes, and comments.

- **Content Creator Community Research**: Researchers can utilize this dataset to study the YouTube content creator community and its impact on the platform.

- **Content Recommendations**: Recommendation platforms can use this data to enhance video recommendations to users based on average categories and performance metric averages.

- **Audience Engagement Analysis**: Average comments and likes can be analyzed to gain insights into average audience participation and engagement.

**You can check the scraping code [here](https://github.com/ComputingVictor/TopYoutubersScraper/)**",.csv
🗣️ Depressive/Non-Depressive Tweets Data,1,depressivenon-depressive-tweets-data,clean_tweet_Dec19ToDec20.csv,Attribution 4.0 International (CC BY 4.0),"Depressive/Non-depressive tweets  between December 2019 and December 2020 originated largely from India and parts of Indian subcontinent. Sentiment Scores alloted using text blob. Tweets are extracted specifically keeping in mind the top 250 most frequently used negative lexicons and positive lexicons accesed using SentiWord and various research publications.

# Acknowlegement
Foto von <a href=""https://unsplash.com/de/@sseeker?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Stormseeker</a> auf <a href=""https://unsplash.com/de/fotos/ein-mensch-ertrinkt-unter-wasser-rX12B5uX7QM?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv
🗺️ Holiday_Package_Prediction,1,holiday-package-purchase-prediction,Travel.csv,CC0-1.0,"### Context

""Trips & Travel.Com"" company wants to enable and establish a viable business model to expand the customer base. One of the ways to expand the customer base is to introduce a new offering of packages. Currently, there are 5 types of packages the company is offering - Basic, Standard, Deluxe, Super Deluxe, King. Looking at the data of the last year, we observed that 18% of the customers purchased the packages. However, the marketing cost was quite high because customers were contacted at random without looking at the available information. The company is now planning to launch a new product i.e. Wellness Tourism Package. Wellness Tourism is defined as Travel that allows the traveler to maintain, enhance or kick-start a healthy lifestyle, and support or increase one's sense of well-being. However, this time company wants to harness the available data of existing and potential customers to make the marketing expenditure more efficient.


### Content

What's inside is more than just rows and columns. Make it easy for others to get started by describing how you acquired the data and what time period it represents, too.
- Most important features that have an impact on Product taken: Designation, Passport, Tier City, Martial status, occupation
- Customers with Designation as Executive should be the target customers for the company .Customers who have passport and are from tier 3 city and are single or unmarried, have large business such customers have higher chances of taking new package.
- Customers monthly income in range of 15000- 25000, and age range 15-30, prefer 5 star properties also have higher chances of taking new package based on EDA.


### Inspiration
We need to analyze the customers' data and information to provide recommendations to the Policy Maker and Marketing Team and also build a model to predict the potential customer who is going to purchase the newly introduced travel package.


### Tasks to Solve :

To predict which customer is more likely to purchase the newly introduced travel package
Which variables are most significant.
Which segment of customers should be targeted more.",.csv
🗺️ World Air Quality,1,world-air-quality,openaq.csv,Attribution 4.0 International (CC BY 4.0),"# Context

OpenAQ has collected 231,965,688 air quality measurements from 8,469 locations in 65 countries. Data are aggregated from 105 government level and research-grade sources.

# Disclaimers
- Some records contain encoding issues on specific characters; those issues are present in the raw API data and were not corrected.
- Some dates are set in the future: those issues also come from the original data and were not corrected.

# Acknowlegement

Foto von <a href=""https://unsplash.com/de/@juniperphoton?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">JuniperPhoton</a> auf <a href=""https://unsplash.com/de/fotos/rauch-kommt-aus-dem-schornstein-der-industriefabrik-KKFKrOu3BVc?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv
🚀 Explore Datascience Opportunities on LinkedIn🔍,1,explore-exciting-opportunities-on-linkedin,extract-job-listings-information-from-linkedin_jobs_captured-list_2024-05-06_06496522-fb61-45ce-886f-84223370cb0a.csv,Apache 2.0,"This Dataset provides valuable and treasure of information about Datascience and AI opportunities on LinkedIn.
With detailed insights about companies, job descriptions, locations it provides a detailed and comprehensive view about the Datascience and AI Jobs.
This dataset equips with the great knowledge needed to navigate the job market effectively and make effective career decisions.
Lets Dive in and unlock the potential of Data Science journey!",.csv
🚂 Mumbai Local Train Dataset 🚆,1,mumbai-local-train-dataset,Mumbai Local Train Dataset.csv,CC0-1.0,"This dataset contains information about Mumbai Local Train Network, including the routes, stations, and distance covered. The data is in CSV format and contains textual information which is sourced from Wikipedia. It is a valuable resource for anyone interested in the History of Mumbai Local Trains and for those analysts that are seeking data to explore NLP techniques. Distance covered and time taken between stations and the Lines information is procured from the M-indicator application.
",.csv
🚘 Car's specifications - Intermediate 🗃️ Dataset,1,cars-specifications-intermediate-dataset,Car_Data.csv,other,"This dataset provides comprehensive information about various car specifications, including Selling_Price, Present_Price, Fuel_Type, Seller_Type, and more, all organized in a structured table format. It offers valuable insights into the performance, features, and characteristics of different car models, making it a valuable resource for automotive enthusiasts, researchers, and industry professionals alike.",.csv
🚘Mercedes-Benz | Historical Stock Dataset📈,1,mercedes-benz-historical-stock-dataset,MBG.DE.csv,Apache 2.0,"# **Description:**

This dataset contains historical stock price data for Mercedes-Benz Group AG (MBG) from [Jan/01/2020] to [May/01/2024]. The dataset includes daily opening, high, low, and closing prices, as well as adjusted closing prices and volume.

## **About Column:**

- Date:
- Open:
- High:
- Low:
- Close:
- Adj Close:
- Volume:

### **Used by:**

- Predicting stock prices
- Building stock forecasting models
- Analyzing stock market trends
- Backtesting investment strategies
- Comparing machine learning models for stock prediction


  This dataset is perfect for data scientists, analytics, and students looking to practice their skills in:

- Time series analysis
- Stock market analysis
- Predictive modeling
- Machine learning

**Get started:** Download the dataset and start exploring!

",.csv
"🚬 The Tax Burden on Tobacco, 1970-2019",1,the-tax-burden-on-tobacco-1970-2019,The_Tax_Burden_on_Tobacco__1970-2019_20240321.csv,other,"# Context
1970-2019. Orzechowski and Walker. Tax Burden on Tobacco. Tax burden data was obtained from the annual compendium on tobacco revenue and industry statistics, The Tax Burden on Tobacco. Data are reported on an annual basis; Data include federal and state-level information regarding taxes applied to the price of a pack of cigarettes.

[Original Data](https://data.cdc.gov/Policy/The-Tax-Burden-on-Tobacco-1970-2019/7nwe-3aj9/about_data)

# Acknowlegement
Foto von <a href=""https://unsplash.com/de/@mehdiimanii?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Mehdi Imani</a> auf <a href=""https://unsplash.com/de/fotos/brauner-runder-holzbehalter-auf-schwarz-weissem-textil--G-J8qK78Zs?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv
🚬 UK Smoking Data,1,uk-smoking-data,smoking.csv,other,"Survey data on smoking habits from the UK. The data set can be used for analyzing the demographic characteristics of smokers and types of tobacco consumed.

A data frame with 1691 observations on the following 12 variables.

# Acknowlegement

Foto von <a href=""https://unsplash.com/de/@matmacq?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Mathew MacQuarrie</a> auf <a href=""https://unsplash.com/de/fotos/einzelne-zigarettenstange-mit-aschestabchen-lzcKZlVPYaU?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash"">Unsplash</a>
  ",.csv
🤝 Bank Loan - Intermediate 🗃️ Dataset,1,bank-loan-intermediate-dataset,Bank_Personal_Loan_Modelling.csv,other,"The ""Bank Personal Loan Modelling"" dataset comprises a comprehensive numerical table aimed at assisting banks in tailoring loan offerings to individual clients. It encompasses key demographic and financial indicators, including age, experience, income, and ZIP code, among others. By leveraging this dataset, banks can analyze client profiles with precision, identifying optimal loan products tailored to specific financial circumstances and risk profiles. With insights gleaned from this dataset, financial institutions can enhance their decision-making processes, ensuring that clients receive personalized loan recommendations that align with their unique needs and financial capabilities.",.csv
🦈  Shark Tank Australia dataset 🇦🇺,1,shark-tank-australia-dataset,Shark Tank Australia dataset.csv,CC0-1.0,"SharkTank dataset of Australia business reality television series.

Currently, the data set has information from SharkTank season 1 to Shark Tank Australia season 5. The dataset has 52 fields/columns and 220+ records.

Below are the features/fields in the dataset:

- Season Number - Season number
- Startup Name - Company name or product name or idea name
- Episode Number - Episode number within the season
- Pitch Number - Overall pitch number
- Season Start - Season first aired date
- Season End - Season last aired date
- Original Air Date - Episode original/first aired date, on OTT/TV
- Industry - Industry name or type
- Business Description - Business Description
- Company Website - Website of startup/company
- Pitchers Gender - Gender of pitchers
- Pitchers City - AU city of pitchers or place where company head office exists
- Pitchers State - AU state or country of pitchers, two letter shortcut of AU state where company head office exists
- Pitchers Average Age - Average age of all pitchers, &lt;30 young, 30-50 middle, &gt;50 old
- Entrepreneur Names - Pitcher names
- Multiple Entrepreneurs - Multiple entrepreneurs are present ?  1-yes, 0-no
- Viewers - Viewership in AU
- Original Ask Amount - Original Ask Amount, in AUD
- Original Offered Equity - Original Offered Equity, in percentages
- Valuation Requested - Valuation Requested, in AUD
- Received Offer - Received offer or not, 1-received, 0-not received
- Accepted Offer - Accepted offer or not, 1-accepted, 0-rejected
- Total Deal Amount - Total Deal Amount, in AUD, including debt/loan amount
- Total Deal Equity - Total Deal Equity, in percentages
- Deal Valuation - Deal Valuation, in AUD
- Number of Sharks in Deal - Number of sharks in deal
- Investment Amount Per Shark - Investment Amount Per Shark
- Equity Per Shark - Equity received by each Shark
- Royalty Deal - If Royalty deal, Royalty amount per item
- Advisory Shares Equity - Deal with Advisory shares or equity, in percentages
- Loan - Loan/debt (line of credit) amount given by sharks, in AUD
- Deal Has Conditions - Deal has conditions or not? (yes or no)
- Mentorship - Shark names who has offered mentorship
- Steve Investment Amount - Amount Invested by Steve
- Steve Investment Equity - Equity received by Steve
- Janine Investment Amount - Amount Invested by Janine
- Janine Investment Equity - Equity received by Janine
- Andrew Investment Amount - Amount Invested by Andrew
- Andrew Investment Equity - Equity received by Andrew
- Naomi Investment Amount - Amount Invested by Naomi
- Naomi Investment Equity - Equity received by Naomi
- Glen Investment Amount - Amount Invested by Glen
- Glen Investment Equity - Equity received by Glen
- Guest Investment Amount - Amount Invested by Guests
- Guest Investment Equity - Equity received by Guests
- Guest Name - Name of Guest shark(s), if invested in deal
- Steve Present - Whether Steve present in episode or not
- Janine Present - Whether Janine present in episode or not
- Andrew Present - Whether Andrew present in episode or not
- Naomi Present - Whether Naomi present in episode or not
- Glen Present - Whether Glen present in episode or not
- Guest Present - Whether Guest(s) present in episode or not",.csv
🦈 Shark Tank India dataset 🇮🇳,1,shark-tank-india,Shark Tank India.csv,CC0-1.0,"# Shark Tank India Data set.

**Shark Tank India** - Season 1, Season 2 and Season 3 information, with **78 fields/columns** and *430+ records*.

All seasons of 🦈  SHARKTANK INDIA 🇮🇳 were broadcasted on SonyLiv OTT/Sony TV.


Here is the data dictionary for Shark Tank (India) season's dataset.

- Season Number - Season number
- Startup Name - Company name or product name
- Episode Number - Episode number within the season
- Pitch Number - Overall pitch number
- Season Start - Season first aired date
- Season End - Season last aired date
- Original Air Date - Episode original/first aired date, on OTT/TV
- Episode Title - Episode title in SonyLiv
- Anchor - Name of the episode presenter/host
- Industry - Industry name or type
- Business Description - Business Description
- Company Website - Company Website URL
- Started in - Year in which startup was started/incorporated
- Number of Presenters - Number of presenters
- Male Presenters - Number of male presenters
- Female Presenters - Number of female presenters
- Transgender Presenters - Number of transgender/LGBTQ presenters
- Couple Presenters - Are presenters wife/husband ? 1-yes, 0-no
- Pitchers Average Age - All pitchers average age, &lt;30 young, 30-50 middle, &gt;50 old
- Pitchers City - Presenter's town/city or city where company head office exists
- Pitchers State - Indian state pitcher hails from or state where company head office exists
- Yearly Revenue - Yearly revenue, in lakhs INR, -1 means negative revenue, 0 means pre-revenue
- Monthly Sales - Total monthly sales, in lakhs
- Gross Margin - Gross margin/profit of company, in percentages
- Net Margin - Net margin/profit of company, in percentages
- EBITDA - Earnings Before Interest, Taxes, Depreciation, and Amortization
- Cash Burn - In loss; burning/paying money from their pocket (yes/no)
- SKUs - Stock Keeping Units or number of varieties, at the time of pitch
- Has Patents - Pitcher has Patents/Intellectual property (filed/granted), at the time of pitch
- Bootstrapped - Startup is bootstrapped or not (yes/no)
- Original Ask Amount - Original Ask Amount, in lakhs INR
- Original Offered Equity - Original Offered Equity, in percentages
- Valuation Requested - Valuation Requested, in lakhs INR
- Received Offer - Received offer or not, 1-received, 0-not received
- Accepted Offer - Accepted offer or not, 1-accepted, 0-rejected
- Total Deal Amount - Total Deal Amount, in lakhs INR
- Total Deal Equity - Total Deal Equity, in percentages
- Total Deal Debt - Total Deal debt/loan amount, in lakhs INR
- Debt Interest - Debt interest rate, in percentages
- Deal Valuation - Deal Valuation, in lakhs INR
- Number of sharks in deal - Number of sharks involved in deal
- Deal has conditions - Deal has conditions or not? (yes or no)
- Royalty Deal - Is it royalty deal or not (1-yes)
- Advisory Shares Equity - Deal with Advisory shares or equity, in percentages
- Namita Investment Amount - Namita Investment Amount, in lakhs INR
- Namita Investment Equity - Namita Investment Equity, in percentages
- Namita Debt Amount - Namita Debt Amount, in lakhs INR
- Vineeta Investment Amount - Vineeta Investment Amount, in lakhs INR
- Vineeta Investment Equity - Vineeta Investment Equity, in percentages
- Vineeta Debt Amount - Vineeta Debt Amount, in lakhs INR
- Anupam Investment Amount - Anupam Investment Amount, in lakhs INR
- Anupam Investment Equity - Anupam Investment Equity, in percentages
- Anupam Debt Amount - Anupam Debt Amount, in lakhs INR
- Aman Investment Amount - Aman Investment Amount, in lakhs INR
- Aman Investment Equity - Aman Investment Equity, in percentages
- Aman Debt Amount - Aman Debt Amount, in lakhs INR
- Peyush Investment Amount - Peyush Investment Amount, in lakhs INR
- Peyush Investment Equity - Peyush Investment Equity, in percentages
- Peyush Debt Amount - Peyush Debt Amount, in lakhs INR
- Amit Investment Amount - Amit Investment Amount, in lakhs INR
- Amit Investment Equity - Amit Investment Equity, in percentages
- Amit Debt Amount - Amit Debt Amount, in lakhs INR
- Ashneer Investment Amount - Ashneer Investment Amount, in lakhs INR
- Ashneer Investment Equity - Ashneer Investment Equity, in percentages
- Ashneer Debt Amount - Ashneer Debt Amount, in lakhs INR
- Guest Investment Amount - Guest Investment Amount, in lakhs INR
- Guest Investment Equity - Guest Investment Equity, in percentages
- Guest Debt Amount - Guest Debt Amount, in lakhs INR
- Invested Guest Name - Name of the guest who invested in deal
- All Guest Names - Name of all guests, who are present in episode
- Namita Present - Whether Namita present in episode or not
- Anupam Present - Whether Anupam present in episode or not
- Vineeta Present - Whether Vineeta present in episode or not
- Aman Present - Whether Aman present in episode or not
- Peyush Present - Whether Peyush present in episode or not
- Amit Present - Whether Amit present in episode or not
- Ashneer Present - Whether Ashneer present in episode or not
- Guest Present - Whether Guest(s) present in episode or not",.csv
🦈 Shark Tank US dataset 🇺🇸,1,shark-tank-us-dataset,Shark Tank US dataset.csv,CC0-1.0,"**SharkTank** dataset of USA/American business reality television series.
Currently, the data set has information from SharkTank season 1 to Shark Tank US season 15.
The dataset has **53 fields/columns and 1330+** records.

Below are the features/fields in the dataset:

- Season Number - Season number
- Startup Name - Company name or product name
- Episode Number - Episode number within the season
- Pitch Number - Overall pitch number
- Season Start - Season first aired date
- Season End - Season last aired date
- Original Air Date - Episode original/first aired date, on OTT/TV
- Industry - Industry name or type
- Business Description - Business Description
- Company Website - Website of startup/company
- Pitchers Gender - Gender of pitchers
- Pitchers City - US city of pitchers
- Pitchers State - US state or country of pitchers, two letter shortcut
- Pitchers Average Age - Average age of all pitchers, &lt;30 young, 30-50 middle, &gt;50 old
- Entrepreneur Names - Pitcher names
- Multiple Entrepreneurs - Multiple entrepreneurs are present ?  1-yes, 0-no
- US Viewership - Viewership in US, TRP rating, in millions
- Original Ask Amount - Original Ask Amount, in USD
- Original Offered Equity - Original Offered Equity, in percentages
- Valuation Requested - Valuation Requested, in USD
- Got Deal - Got the deal or not,  1-yes, 0-no
- Total Deal Amount - Total Deal Amount, in USD, including debt/loan amount
- Total Deal Equity - Total Deal Equity, in percentages
- Deal Valuation - Deal Valuation, in USD
- Number of sharks in deal - Number of sharks in deal
- Investment Amount Per Shark - Investment Amount Per Shark
- Equity Per Shark - Equity received by each Shark
- Royalty Deal - Is it royalty deal or not (1-yes)
- Advisory Shares Equity - Deal with Advisory shares or equity, in percentages
- Loan - Loan/debt (line of credit) amount given by sharks, in USD
- Deal has conditions - Deal has conditions or not? (yes or no)
- Barbara Corcoran Investment Amount - Amount Invested by Barbara Corcoran
- Barbara Corcoran Investment Equity - Equity received by Barbara Corcoran
- Mark Cuban Investment Amount - Amount Invested by Mark Cuban
- Mark Cuban Investment Equity - Equity received by Mark Cuban
- Lori Greiner Investment Amount - Amount Invested by Lori Greiner
- Lori Greiner Investment Equity - Equity received by Lori Greiner
- Robert Herjavec Investment Amount - Amount Invested by Robert Herjavec
- Robert Herjavec Investment Equity - Equity received by Robert Herjavec
- Daymond John Investment Amount - Amount Invested by Daymond John
- Daymond John Investment Equity - Equity received by Daymond John
- Kevin O Leary Investment Amount - Amount Invested by Kevin O'Leary
- Kevin O Leary Investment Equity - Equity received by Kevin O'Leary
- Guest Investment Amount - Amount Invested by Guests
- Guest Investment Equity - Equity received by Guests
- Guest Name - Name of Guest shark, if invested in deal
- Barbara Corcoran Present - Whether Barbara Corcoran present in episode or not
- Mark Cuban Present - Whether Mark Cuban present in episode or not
- Lori Greiner Present - Whether Lori Greiner present in episode or not
- Robert Herjavec Present - Whether Robert Herjavec present in episode or not
- Daymond John Present - Whether Daymond John present in episode or not
- Kevin O Leary Present - Whether Kevin O Leary present in episode or not
- Guest Present - Whether Guest present in episode or not",.csv
🧬 Gene Expression - Bioinformatics 🗃️ Dataset,1,gene-expression-bioinformatics-dataset,Spellman.csv,other,The knowledge of gene behavior is necessary to understand the nature of cellular functions. Most data mining algorithms developed for microarray gene expression data address the challenge of clustering. Cluster analysis of gene expression data helps identify co-expressed genes. Analysis of these datasets reveals genes with unknown functions and discovers functional relationships between genes. Co-expressed genes can be grouped into clusters based on their expression patterns.,.csv
🩸 Diabetes - Intermediate 🗃️ Dataset,1,diabetes-intermediate-dataset,Diabetes.csv,other,"Dive into the intricate realm of diabetes research with this meticulously curated dataset. Offering a wealth of information and variables related to diabetes, this dataset serves as a cornerstone for understanding the multifaceted nature of the condition. From patient demographics and medical history to vital diagnostic metrics and treatment outcomes, each data point provides valuable insights into the disease's epidemiology, progression, and management. Whether you're an aspiring researcher, healthcare professional, or data enthusiast, this dataset empowers you to unravel the complexities of diabetes and drive innovative solutions towards improving patient care and outcomes.",.csv
🩺Healthcare Dataset 🧪,1,healthcare-dataset,healthcare_dataset.csv,CC0-1.0,"# ```Context:```

This synthetic healthcare dataset has been created to serve as a valuable resource for data science, machine learning, and data analysis enthusiasts. It is designed to mimic real-world healthcare data, enabling users to practice, develop, and showcase their data manipulation and analysis skills in the context of the healthcare industry.

# ```Inspiration:```

The inspiration behind this dataset is rooted in the need for practical and diverse healthcare data for educational and research purposes. Healthcare data is often sensitive and subject to privacy regulations, making it challenging to access for learning and experimentation. To address this gap, I have leveraged Python's Faker library to generate a dataset that mirrors the structure and attributes commonly found in healthcare records. By providing this synthetic data, I hope to foster innovation, learning, and knowledge sharing in the healthcare analytics domain.

# ``` Dataset Information:```
Each column provides specific information about the patient, their admission, and the healthcare services provided, making this dataset suitable for various data analysis and modeling tasks in the healthcare domain. Here's a brief explanation of each column in the dataset -
- **Name:** This column represents the name of the patient associated with the healthcare record.
- **Age:** The age of the patient at the time of admission, expressed in years.
- **Gender:** Indicates the gender of the patient, either ""Male"" or ""Female.""
- **Blood Type:** The patient's blood type, which can be one of the common blood types (e.g., ""A+"", ""O-"", etc.).
- **Medical Condition:** This column specifies the primary medical condition or diagnosis associated with the patient, such as ""Diabetes,"" ""Hypertension,"" ""Asthma,"" and more.
- **Date of Admission:** The date on which the patient was admitted to the healthcare facility.
- **Doctor:** The name of the doctor responsible for the patient's care during their admission.
- **Hospital:** Identifies the healthcare facility or hospital where the patient was admitted.
- **Insurance Provider:** This column indicates the patient's insurance provider, which can be one of several options, including ""Aetna,"" ""Blue Cross,"" ""Cigna,"" ""UnitedHealthcare,"" and ""Medicare.""
- **Billing Amount:** The amount of money billed for the patient's healthcare services during their admission. This is expressed as a floating-point number.
- **Room Number:** The room number where the patient was accommodated during their admission.
- **Admission Type:** Specifies the type of admission, which can be ""Emergency,"" ""Elective,"" or ""Urgent,"" reflecting the circumstances of the admission.
- **Discharge Date:** The date on which the patient was discharged from the healthcare facility, based on the admission date and a random number of days within a realistic range.
- **Medication:** Identifies a medication prescribed or administered to the patient during their admission. Examples include ""Aspirin,"" ""Ibuprofen,"" ""Penicillin,"" ""Paracetamol,"" and ""Lipitor.""
- **Test Results:** Describes the results of a medical test conducted during the patient's admission. Possible values include ""Normal,"" ""Abnormal,"" or ""Inconclusive,"" indicating the outcome of the test.

# ``` Usage Scenarios:```

This dataset can be utilized for a wide range of purposes, including:
- Developing and testing healthcare predictive models.
- Practicing data cleaning, transformation, and analysis techniques.
- Creating data visualizations to gain insights into healthcare trends.
- Learning and teaching data science and machine learning concepts in a healthcare context.
- You can treat it as a Multi-Class Classification Problem and solve it for  **Test Results** which contains 3 categories(Normal, Abnormal, and Inconclusive).

# ``` Acknowledgments:```

- I acknowledge the importance of healthcare data privacy and security and emphasize that this dataset is entirely synthetic. It does not contain any real patient information or violate any privacy regulations.
- I hope that this dataset contributes to the advancement of data science and healthcare analytics and inspires new ideas. Feel free to explore, analyze, and share your findings with the Kaggle community.

# ``` Image Credit: ```
Image by BC Y from Pixabay
",.csv
